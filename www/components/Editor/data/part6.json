{"files_changed":{"files":[[2008,"use super::*;\n\nuse std::boxed::Box;\nuse std::cell::RefCell;\nuse std::clone::Clone;\nuse std::convert::{From, TryInto};\nuse std::mem::drop;\nuse std::option::Option::{self, None, Some};\nuse std::result::Result::{Err, Ok};\n\n#[test]\nfn test_clone() {\n    let x = Rc::new(RefCell::new(5));\n    let y = x.clone();\n    *x.borrow_mut() = 20;\n    assert_eq!(*y.borrow(), 20);\n}\n\n#[test]\nfn test_simple() {\n    let x = Rc::new(5);\n    assert_eq!(*x, 5);\n}\n\n#[test]\nfn test_simple_clone() {\n    let x = Rc::new(5);\n    let y = x.clone();\n    assert_eq!(*x, 5);\n    assert_eq!(*y, 5);\n}\n\n#[test]\nfn test_destructor() {\n    let x: Rc<Box<_>> = Rc::new(box 5);\n    assert_eq!(**x, 5);\n}\n\n#[test]\nfn test_live() {\n    let x = Rc::new(5);\n    let y = Rc::downgrade(&x);\n    assert!(y.upgrade().is_some());\n}\n\n#[test]\nfn test_dead() {\n    let x = Rc::new(5);\n    let y = Rc::downgrade(&x);\n    drop(x);\n    assert!(y.upgrade().is_none());\n}\n\n#[test]\nfn weak_self_cyclic() {\n    struct Cycle {\n        x: RefCell<Option<Weak<Cycle>>>,\n    }\n\n    let a = Rc::new(Cycle { x: RefCell::new(None) });\n    let b = Rc::downgrade(&a.clone());\n    *a.x.borrow_mut() = Some(b);\n\n    // hopefully we don't double-free (or leak)...\n}\n\n#[test]\nfn is_unique() {\n    let x = Rc::new(3);\n    assert!(Rc::is_unique(&x));\n    let y = x.clone();\n    assert!(!Rc::is_unique(&x));\n    drop(y);\n    assert!(Rc::is_unique(&x));\n    let w = Rc::downgrade(&x);\n    assert!(!Rc::is_unique(&x));\n    drop(w);\n    assert!(Rc::is_unique(&x));\n}\n\n#[test]\nfn test_strong_count() {\n    let a = Rc::new(0);\n    assert!(Rc::strong_count(&a) == 1);\n    let w = Rc::downgrade(&a);\n    assert!(Rc::strong_count(&a) == 1);\n    let b = w.upgrade().expect(\"upgrade of live rc failed\");\n    assert!(Rc::strong_count(&b) == 2);\n    assert!(Rc::strong_count(&a) == 2);\n    drop(w);\n    drop(a);\n    assert!(Rc::strong_count(&b) == 1);\n    let c = b.clone();\n    assert!(Rc::strong_count(&b) == 2);\n    assert!(Rc::strong_count(&c) == 2);\n}\n\n#[test]\nfn test_weak_count() {\n    let a = Rc::new(0);\n    assert!(Rc::strong_count(&a) == 1);\n    assert!(Rc::weak_count(&a) == 0);\n    let w = Rc::downgrade(&a);\n    assert!(Rc::strong_count(&a) == 1);\n    assert!(Rc::weak_count(&a) == 1);\n    drop(w);\n    assert!(Rc::strong_count(&a) == 1);\n    assert!(Rc::weak_count(&a) == 0);\n    let c = a.clone();\n    assert!(Rc::strong_count(&a) == 2);\n    assert!(Rc::weak_count(&a) == 0);\n    drop(c);\n}\n\n#[test]\nfn weak_counts() {\n    assert_eq!(Weak::weak_count(&Weak::<u64>::new()), 0);\n    assert_eq!(Weak::strong_count(&Weak::<u64>::new()), 0);\n\n    let a = Rc::new(0);\n    let w = Rc::downgrade(&a);\n    assert_eq!(Weak::strong_count(&w), 1);\n    assert_eq!(Weak::weak_count(&w), 1);\n    let w2 = w.clone();\n    assert_eq!(Weak::strong_count(&w), 1);\n    assert_eq!(Weak::weak_count(&w), 2);\n    assert_eq!(Weak::strong_count(&w2), 1);\n    assert_eq!(Weak::weak_count(&w2), 2);\n    drop(w);\n    assert_eq!(Weak::strong_count(&w2), 1);\n    assert_eq!(Weak::weak_count(&w2), 1);\n    let a2 = a.clone();\n    assert_eq!(Weak::strong_count(&w2), 2);\n    assert_eq!(Weak::weak_count(&w2), 1);\n    drop(a2);\n    drop(a);\n    assert_eq!(Weak::strong_count(&w2), 0);\n    assert_eq!(Weak::weak_count(&w2), 0);\n    drop(w2);\n}\n\n#[test]\nfn try_unwrap() {\n    let x = Rc::new(3);\n    assert_eq!(Rc::try_unwrap(x), Ok(3));\n    let x = Rc::new(4);\n    let _y = x.clone();\n    assert_eq!(Rc::try_unwrap(x), Err(Rc::new(4)));\n    let x = Rc::new(5);\n    let _w = Rc::downgrade(&x);\n    assert_eq!(Rc::try_unwrap(x), Ok(5));\n}\n\n#[test]\nfn into_from_raw() {\n    let x = Rc::new(box \"hello\");\n    let y = x.clone();\n\n    let x_ptr = Rc::into_raw(x);\n    drop(y);\n    unsafe {\n        assert_eq!(**x_ptr, \"hello\");\n\n        let x = Rc::from_raw(x_ptr);\n        assert_eq!(**x, \"hello\");\n\n        assert_eq!(Rc::try_unwrap(x).map(|x| *x), Ok(\"hello\"));\n    }\n}\n\n#[test]\nfn test_into_from_raw_unsized() {\n    use std::fmt::Display;\n    use std::string::ToString;\n\n    let rc: Rc<str> = Rc::from(\"foo\");\n\n    let ptr = Rc::into_raw(rc.clone());\n    let rc2 = unsafe { Rc::from_raw(ptr) };\n\n    assert_eq!(unsafe { &*ptr }, \"foo\");\n    assert_eq!(rc, rc2);\n\n    let rc: Rc<dyn Display> = Rc::new(123);\n\n    let ptr = Rc::into_raw(rc.clone());\n    let rc2 = unsafe { Rc::from_raw(ptr) };\n\n    assert_eq!(unsafe { &*ptr }.to_string(), \"123\");\n    assert_eq!(rc2.to_string(), \"123\");\n}\n\n#[test]\nfn into_from_weak_raw() {\n    let x = Rc::new(box \"hello\");\n    let y = Rc::downgrade(&x);\n\n    let y_ptr = Weak::into_raw(y);\n    unsafe {\n        assert_eq!(**y_ptr, \"hello\");\n\n        let y = Weak::from_raw(y_ptr);\n        let y_up = Weak::upgrade(&y).unwrap();\n        assert_eq!(**y_up, \"hello\");\n        drop(y_up);\n\n        assert_eq!(Rc::try_unwrap(x).map(|x| *x), Ok(\"hello\"));\n    }\n}\n\n#[test]\nfn test_into_from_weak_raw_unsized() {\n    use std::fmt::Display;\n    use std::string::ToString;\n\n    let arc: Rc<str> = Rc::from(\"foo\");\n    let weak: Weak<str> = Rc::downgrade(&arc);\n\n    let ptr = Weak::into_raw(weak.clone());\n    let weak2 = unsafe { Weak::from_raw(ptr) };\n\n    assert_eq!(unsafe { &*ptr }, \"foo\");\n    assert!(weak.ptr_eq(&weak2));\n\n    let arc: Rc<dyn Display> = Rc::new(123);\n    let weak: Weak<dyn Display> = Rc::downgrade(&arc);\n\n    let ptr = Weak::into_raw(weak.clone());\n    let weak2 = unsafe { Weak::from_raw(ptr) };\n\n    assert_eq!(unsafe { &*ptr }.to_string(), \"123\");\n    assert!(weak.ptr_eq(&weak2));\n}\n\n#[test]\nfn get_mut() {\n    let mut x = Rc::new(3);\n    *Rc::get_mut(&mut x).unwrap() = 4;\n    assert_eq!(*x, 4);\n    let y = x.clone();\n    assert!(Rc::get_mut(&mut x).is_none());\n    drop(y);\n    assert!(Rc::get_mut(&mut x).is_some());\n    let _w = Rc::downgrade(&x);\n    assert!(Rc::get_mut(&mut x).is_none());\n}\n\n#[test]\nfn test_cowrc_clone_make_unique() {\n    let mut cow0 = Rc::new(75);\n    let mut cow1 = cow0.clone();\n    let mut cow2 = cow1.clone();\n\n    assert!(75 == *Rc::make_mut(&mut cow0));\n    assert!(75 == *Rc::make_mut(&mut cow1));\n    assert!(75 == *Rc::make_mut(&mut cow2));\n\n    *Rc::make_mut(&mut cow0) += 1;\n    *Rc::make_mut(&mut cow1) += 2;\n    *Rc::make_mut(&mut cow2) += 3;\n\n    assert!(76 == *cow0);\n    assert!(77 == *cow1);\n    assert!(78 == *cow2);\n\n    // none should point to the same backing memory\n    assert!(*cow0 != *cow1);\n    assert!(*cow0 != *cow2);\n    assert!(*cow1 != *cow2);\n}\n\n#[test]\nfn test_cowrc_clone_unique2() {\n    let mut cow0 = Rc::new(75);\n    let cow1 = cow0.clone();\n    let cow2 = cow1.clone();\n\n    assert!(75 == *cow0);\n    assert!(75 == *cow1);\n    assert!(75 == *cow2);\n\n    *Rc::make_mut(&mut cow0) += 1;\n\n    assert!(76 == *cow0);\n    assert!(75 == *cow1);\n    assert!(75 == *cow2);\n\n    // cow1 and cow2 should share the same contents\n    // cow0 should have a unique reference\n    assert!(*cow0 != *cow1);\n    assert!(*cow0 != *cow2);\n    assert!(*cow1 == *cow2);\n}\n\n#[test]\nfn test_cowrc_clone_weak() {\n    let mut cow0 = Rc::new(75);\n    let cow1_weak = Rc::downgrade(&cow0);\n\n    assert!(75 == *cow0);\n    assert!(75 == *cow1_weak.upgrade().unwrap());\n\n    *Rc::make_mut(&mut cow0) += 1;\n\n    assert!(76 == *cow0);\n    assert!(cow1_weak.upgrade().is_none());\n}\n\n#[test]\nfn test_show() {\n    let foo = Rc::new(75);\n    assert_eq!(format!(\"{:?}\", foo), \"75\");\n}\n\n#[test]\nfn test_unsized() {\n    let foo: Rc<[i32]> = Rc::new([1, 2, 3]);\n    assert_eq!(foo, foo.clone());\n}\n\n#[test]\nfn test_maybe_thin_unsized() {\n    // If/when custom thin DSTs exist, this test should be updated to use one\n    use std::ffi::{CStr, CString};\n\n    let x: Rc<CStr> = Rc::from(CString::new(\"swordfish\").unwrap().into_boxed_c_str());\n    assert_eq!(format!(\"{:?}\", x), \"\\\"swordfish\\\"\");\n    let y: Weak<CStr> = Rc::downgrade(&x);\n    drop(x);\n\n    // At this point, the weak points to a dropped DST\n    assert!(y.upgrade().is_none());\n    // But we still need to be able to get the alloc layout to drop.\n    // CStr has no drop glue, but custom DSTs might, and need to work.\n    drop(y);\n}\n\n#[test]\nfn test_from_owned() {\n    let foo = 123;\n    let foo_rc = Rc::from(foo);\n    assert!(123 == *foo_rc);\n}\n\n#[test]\nfn test_new_weak() {\n    let foo: Weak<usize> = Weak::new();\n    assert!(foo.upgrade().is_none());\n}\n\n#[test]\nfn test_ptr_eq() {\n    let five = Rc::new(5);\n    let same_five = five.clone();\n    let other_five = Rc::new(5);\n\n    assert!(Rc::ptr_eq(&five, &same_five));\n    assert!(!Rc::ptr_eq(&five, &other_five));\n}\n\n#[test]\nfn test_from_str() {\n    let r: Rc<str> = Rc::from(\"foo\");\n\n    assert_eq!(&r[..], \"foo\");\n}\n\n#[test]\nfn test_copy_from_slice() {\n    let s: &[u32] = &[1, 2, 3];\n    let r: Rc<[u32]> = Rc::from(s);\n\n    assert_eq!(&r[..], [1, 2, 3]);\n}\n\n#[test]\nfn test_clone_from_slice() {\n    #[derive(Clone, Debug, Eq, PartialEq)]\n    struct X(u32);\n\n    let s: &[X] = &[X(1), X(2), X(3)];\n    let r: Rc<[X]> = Rc::from(s);\n\n    assert_eq!(&r[..], s);\n}\n\n#[test]\n#[should_panic]\nfn test_clone_from_slice_panic() {\n    use std::string::{String, ToString};\n\n    struct Fail(u32, String);\n\n    impl Clone for Fail {\n        fn clone(&self) -> Fail {\n            if self.0 == 2 {\n                panic!();\n            }\n            Fail(self.0, self.1.clone())\n        }\n    }\n\n    let s: &[Fail] =\n        &[Fail(0, \"foo\".to_string()), Fail(1, \"bar\".to_string()), Fail(2, \"baz\".to_string())];\n\n    // Should panic, but not cause memory corruption\n    let _r: Rc<[Fail]> = Rc::from(s);\n}\n\n#[test]\nfn test_from_box() {\n    let b: Box<u32> = box 123;\n    let r: Rc<u32> = Rc::from(b);\n\n    assert_eq!(*r, 123);\n}\n\n#[test]\nfn test_from_box_str() {\n    use std::string::String;\n\n    let s = String::from(\"foo\").into_boxed_str();\n    let r: Rc<str> = Rc::from(s);\n\n    assert_eq!(&r[..], \"foo\");\n}\n\n#[test]\nfn test_from_box_slice() {\n    let s = vec![1, 2, 3].into_boxed_slice();\n    let r: Rc<[u32]> = Rc::from(s);\n\n    assert_eq!(&r[..], [1, 2, 3]);\n}\n\n#[test]\nfn test_from_box_trait() {\n    use std::fmt::Display;\n    use std::string::ToString;\n\n    let b: Box<dyn Display> = box 123;\n    let r: Rc<dyn Display> = Rc::from(b);\n\n    assert_eq!(r.to_string(), \"123\");\n}\n\n#[test]\nfn test_from_box_trait_zero_sized() {\n    use std::fmt::Debug;\n\n    let b: Box<dyn Debug> = box ();\n    let r: Rc<dyn Debug> = Rc::from(b);\n\n    assert_eq!(format!(\"{:?}\", r), \"()\");\n}\n\n#[test]\nfn test_from_vec() {\n    let v = vec![1, 2, 3];\n    let r: Rc<[u32]> = Rc::from(v);\n\n    assert_eq!(&r[..], [1, 2, 3]);\n}\n\n#[test]\nfn test_downcast() {\n    use std::any::Any;\n\n    let r1: Rc<dyn Any> = Rc::new(i32::MAX);\n    let r2: Rc<dyn Any> = Rc::new(\"abc\");\n\n    assert!(r1.clone().downcast::<u32>().is_err());\n\n    let r1i32 = r1.downcast::<i32>();\n    assert!(r1i32.is_ok());\n    assert_eq!(r1i32.unwrap(), Rc::new(i32::MAX));\n\n    assert!(r2.clone().downcast::<i32>().is_err());\n\n    let r2str = r2.downcast::<&'static str>();\n    assert!(r2str.is_ok());\n    assert_eq!(r2str.unwrap(), Rc::new(\"abc\"));\n}\n\n#[test]\nfn test_array_from_slice() {\n    let v = vec![1, 2, 3];\n    let r: Rc<[u32]> = Rc::from(v);\n\n    let a: Result<Rc<[u32; 3]>, _> = r.clone().try_into();\n    assert!(a.is_ok());\n\n    let a: Result<Rc<[u32; 2]>, _> = r.clone().try_into();\n    assert!(a.is_err());\n}\n\n#[test]\nfn test_rc_cyclic_with_zero_refs() {\n    struct ZeroRefs {\n        inner: Weak<ZeroRefs>,\n    }\n\n    let zero_refs = Rc::new_cyclic(|inner| {\n        assert_eq!(inner.strong_count(), 0);\n        assert!(inner.upgrade().is_none());\n        ZeroRefs { inner: Weak::new() }\n    });\n\n    assert_eq!(Rc::strong_count(&zero_refs), 1);\n    assert_eq!(Rc::weak_count(&zero_refs), 0);\n    assert_eq!(zero_refs.inner.strong_count(), 0);\n    assert_eq!(zero_refs.inner.weak_count(), 0);\n}\n\n#[test]\nfn test_rc_cyclic_with_one_ref() {\n    struct OneRef {\n        inner: Weak<OneRef>,\n    }\n\n    let one_ref = Rc::new_cyclic(|inner| {\n        assert_eq!(inner.strong_count(), 0);\n        assert!(inner.upgrade().is_none());\n        OneRef { inner: inner.clone() }\n    });\n\n    assert_eq!(Rc::strong_count(&one_ref), 1);\n    assert_eq!(Rc::weak_count(&one_ref), 1);\n\n    let one_ref2 = Weak::upgrade(&one_ref.inner).unwrap();\n    assert!(Rc::ptr_eq(&one_ref, &one_ref2));\n\n    assert_eq!(one_ref.inner.strong_count(), 2);\n    assert_eq!(one_ref.inner.weak_count(), 1);\n}\n\n#[test]\nfn test_rc_cyclic_with_two_ref() {\n    struct TwoRefs {\n        inner: Weak<TwoRefs>,\n        inner1: Weak<TwoRefs>,\n    }\n\n    let two_refs = Rc::new_cyclic(|inner| {\n        assert_eq!(inner.strong_count(), 0);\n        assert!(inner.upgrade().is_none());\n        TwoRefs { inner: inner.clone(), inner1: inner.clone() }\n    });\n\n    assert_eq!(Rc::strong_count(&two_refs), 1);\n    assert_eq!(Rc::weak_count(&two_refs), 2);\n\n    let two_ref3 = Weak::upgrade(&two_refs.inner).unwrap();\n    assert!(Rc::ptr_eq(&two_refs, &two_ref3));\n\n    let two_ref2 = Weak::upgrade(&two_refs.inner1).unwrap();\n    assert!(Rc::ptr_eq(&two_refs, &two_ref2));\n\n    assert_eq!(Rc::strong_count(&two_refs), 3);\n    assert_eq!(Rc::weak_count(&two_refs), 2);\n}\n"],[2009,"//! A pointer type for heap allocation.\n//!\n//! [`Box<T>`], casually referred to as a 'box', provides the simplest form of\n//! heap allocation in Rust. Boxes provide ownership for this allocation, and\n//! drop their contents when they go out of scope. Boxes also ensure that they\n//! never allocate more than `isize::MAX` bytes.\n//!\n//! # Examples\n//!\n//! Move a value from the stack to the heap by creating a [`Box`]:\n//!\n//! ```\n//! let val: u8 = 5;\n//! let boxed: Box<u8> = Box::new(val);\n//! ```\n//!\n//! Move a value from a [`Box`] back to the stack by [dereferencing]:\n//!\n//! ```\n//! let boxed: Box<u8> = Box::new(5);\n//! let val: u8 = *boxed;\n//! ```\n//!\n//! Creating a recursive data structure:\n//!\n//! ```\n//! #[derive(Debug)]\n//! enum List<T> {\n//!     Cons(T, Box<List<T>>),\n//!     Nil,\n//! }\n//!\n//! let list: List<i32> = List::Cons(1, Box::new(List::Cons(2, Box::new(List::Nil))));\n//! println!(\"{:?}\", list);\n//! ```\n//!\n//! This will print `Cons(1, Cons(2, Nil))`.\n//!\n//! Recursive structures must be boxed, because if the definition of `Cons`\n//! looked like this:\n//!\n//! ```compile_fail,E0072\n//! # enum List<T> {\n//! Cons(T, List<T>),\n//! # }\n//! ```\n//!\n//! It wouldn't work. This is because the size of a `List` depends on how many\n//! elements are in the list, and so we don't know how much memory to allocate\n//! for a `Cons`. By introducing a [`Box<T>`], which has a defined size, we know how\n//! big `Cons` needs to be.\n//!\n//! # Memory layout\n//!\n//! For non-zero-sized values, a [`Box`] will use the [`Global`] allocator for\n//! its allocation. It is valid to convert both ways between a [`Box`] and a\n//! raw pointer allocated with the [`Global`] allocator, given that the\n//! [`Layout`] used with the allocator is correct for the type. More precisely,\n//! a `value: *mut T` that has been allocated with the [`Global`] allocator\n//! with `Layout::for_value(&*value)` may be converted into a box using\n//! [`Box::<T>::from_raw(value)`]. Conversely, the memory backing a `value: *mut\n//! T` obtained from [`Box::<T>::into_raw`] may be deallocated using the\n//! [`Global`] allocator with [`Layout::for_value(&*value)`].\n//!\n//! For zero-sized values, the `Box` pointer still has to be [valid] for reads\n//! and writes and sufficiently aligned. In particular, casting any aligned\n//! non-zero integer literal to a raw pointer produces a valid pointer, but a\n//! pointer pointing into previously allocated memory that since got freed is\n//! not valid. The recommended way to build a Box to a ZST if `Box::new` cannot\n//! be used is to use [`ptr::NonNull::dangling`].\n//!\n//! So long as `T: Sized`, a `Box<T>` is guaranteed to be represented\n//! as a single pointer and is also ABI-compatible with C pointers\n//! (i.e. the C type `T*`). This means that if you have extern \"C\"\n//! Rust functions that will be called from C, you can define those\n//! Rust functions using `Box<T>` types, and use `T*` as corresponding\n//! type on the C side. As an example, consider this C header which\n//! declares functions that create and destroy some kind of `Foo`\n//! value:\n//!\n//! ```c\n//! /* C header */\n//!\n//! /* Returns ownership to the caller */\n//! struct Foo* foo_new(void);\n//!\n//! /* Takes ownership from the caller; no-op when invoked with null */\n//! void foo_delete(struct Foo*);\n//! ```\n//!\n//! These two functions might be implemented in Rust as follows. Here, the\n//! `struct Foo*` type from C is translated to `Box<Foo>`, which captures\n//! the ownership constraints. Note also that the nullable argument to\n//! `foo_delete` is represented in Rust as `Option<Box<Foo>>`, since `Box<Foo>`\n//! cannot be null.\n//!\n//! ```\n//! #[repr(C)]\n//! pub struct Foo;\n//!\n//! #[no_mangle]\n//! pub extern \"C\" fn foo_new() -> Box<Foo> {\n//!     Box::new(Foo)\n//! }\n//!\n//! #[no_mangle]\n//! pub extern \"C\" fn foo_delete(_: Option<Box<Foo>>) {}\n//! ```\n//!\n//! Even though `Box<T>` has the same representation and C ABI as a C pointer,\n//! this does not mean that you can convert an arbitrary `T*` into a `Box<T>`\n//! and expect things to work. `Box<T>` values will always be fully aligned,\n//! non-null pointers. Moreover, the destructor for `Box<T>` will attempt to\n//! free the value with the global allocator. In general, the best practice\n//! is to only use `Box<T>` for pointers that originated from the global\n//! allocator.\n//!\n//! **Important.** At least at present, you should avoid using\n//! `Box<T>` types for functions that are defined in C but invoked\n//! from Rust. In those cases, you should directly mirror the C types\n//! as closely as possible. Using types like `Box<T>` where the C\n//! definition is just using `T*` can lead to undefined behavior, as\n//! described in [rust-lang/unsafe-code-guidelines#198][ucg#198].\n//!\n//! [ucg#198]: https://github.com/rust-lang/unsafe-code-guidelines/issues/198\n//! [dereferencing]: core::ops::Deref\n//! [`Box::<T>::from_raw(value)`]: Box::from_raw\n//! [`Global`]: crate::alloc::Global\n//! [`Layout`]: crate::alloc::Layout\n//! [`Layout::for_value(&*value)`]: crate::alloc::Layout::for_value\n//! [valid]: ptr#safety\n\n#![stable(feature = \"rust1\", since = \"1.0.0\")]\n\nuse core::any::Any;\nuse core::borrow;\nuse core::cmp::Ordering;\nuse core::convert::{From, TryFrom};\nuse core::fmt;\nuse core::future::Future;\nuse core::hash::{Hash, Hasher};\n#[cfg(not(no_global_oom_handling))]\nuse core::iter::FromIterator;\nuse core::iter::{FusedIterator, Iterator};\nuse core::marker::{Unpin, Unsize};\nuse core::mem;\nuse core::ops::{\n    CoerceUnsized, Deref, DerefMut, DispatchFromDyn, Generator, GeneratorState, Receiver,\n};\nuse core::pin::Pin;\nuse core::ptr::{self, Unique};\nuse core::stream::Stream;\nuse core::task::{Context, Poll};\n\n#[cfg(not(no_global_oom_handling))]\nuse crate::alloc::{handle_alloc_error, WriteCloneIntoRaw};\nuse crate::alloc::{AllocError, Allocator, Global, Layout};\n#[cfg(not(no_global_oom_handling))]\nuse crate::borrow::Cow;\n#[cfg(not(no_global_oom_handling))]\nuse crate::raw_vec::RawVec;\n#[cfg(not(no_global_oom_handling))]\nuse crate::str::from_boxed_utf8_unchecked;\n#[cfg(not(no_global_oom_handling))]\nuse crate::vec::Vec;\n\n/// A pointer type for heap allocation.\n///\n/// See the [module-level documentation](../../std/boxed/index.html) for more.\n#[lang = \"owned_box\"]\n#[fundamental]\n#[stable(feature = \"rust1\", since = \"1.0.0\")]\npub struct Box<\n    T: ?Sized,\n    #[unstable(feature = \"allocator_api\", issue = \"32838\")] A: Allocator = Global,\n>(Unique<T>, A);\n\nimpl<T> Box<T> {\n    /// Allocates memory on the heap and then places `x` into it.\n    ///\n    /// This doesn't actually allocate if `T` is zero-sized.\n    ///\n    /// # Examples\n    ///\n    /// ```\n    /// let five = Box::new(5);\n    /// ```\n    #[cfg(not(no_global_oom_handling))]\n    #[inline(always)]\n    #[doc(alias = \"alloc\")]\n    #[doc(alias = \"malloc\")]\n    #[stable(feature = \"rust1\", since = \"1.0.0\")]\n    pub fn new(x: T) -> Self {\n        box x\n    }\n\n    /// Constructs a new box with uninitialized contents.\n    ///\n    /// # Examples\n    ///\n    /// ```\n    /// #![feature(new_uninit)]\n    ///\n    /// let mut five = Box::<u32>::new_uninit();\n    ///\n    /// let five = unsafe {\n    ///     // Deferred initialization:\n    ///     five.as_mut_ptr().write(5);\n    ///\n    ///     five.assume_init()\n    /// };\n    ///\n    /// assert_eq!(*five, 5)\n    /// ```\n    #[cfg(not(no_global_oom_handling))]\n    #[unstable(feature = \"new_uninit\", issue = \"63291\")]\n    #[inline]\n    pub fn new_uninit() -> Box<mem::MaybeUninit<T>> {\n        Self::new_uninit_in(Global)\n    }\n\n    /// Constructs a new `Box` with uninitialized contents, with the memory\n    /// being filled with `0` bytes.\n    ///\n    /// See [`MaybeUninit::zeroed`][zeroed] for examples of correct and incorrect usage\n    /// of this method.\n    ///\n    /// # Examples\n    ///\n    /// ```\n    /// #![feature(new_uninit)]\n    ///\n    /// let zero = Box::<u32>::new_zeroed();\n    /// let zero = unsafe { zero.assume_init() };\n    ///\n    /// assert_eq!(*zero, 0)\n    /// ```\n    ///\n    /// [zeroed]: mem::MaybeUninit::zeroed\n    #[cfg(not(no_global_oom_handling))]\n    #[inline]\n    #[doc(alias = \"calloc\")]\n    #[unstable(feature = \"new_uninit\", issue = \"63291\")]\n    pub fn new_zeroed() -> Box<mem::MaybeUninit<T>> {\n        Self::new_zeroed_in(Global)\n    }\n\n    /// Constructs a new `Pin<Box<T>>`. If `T` does not implement `Unpin`, then\n    /// `x` will be pinned in memory and unable to be moved.\n    #[cfg(not(no_global_oom_handling))]\n    #[stable(feature = \"pin\", since = \"1.33.0\")]\n    #[inline(always)]\n    pub fn pin(x: T) -> Pin<Box<T>> {\n        (box x).into()\n    }\n\n    /// Allocates memory on the heap then places `x` into it,\n    /// returning an error if the allocation fails\n    ///\n    /// This doesn't actually allocate if `T` is zero-sized.\n    ///\n    /// # Examples\n    ///\n    /// ```\n    /// #![feature(allocator_api)]\n    ///\n    /// let five = Box::try_new(5)?;\n    /// # Ok::<(), std::alloc::AllocError>(())\n    /// ```\n    #[unstable(feature = \"allocator_api\", issue = \"32838\")]\n    #[inline]\n    pub fn try_new(x: T) -> Result<Self, AllocError> {\n        Self::try_new_in(x, Global)\n    }\n\n    /// Constructs a new box with uninitialized contents on the heap,\n    /// returning an error if the allocation fails\n    ///\n    /// # Examples\n    ///\n    /// ```\n    /// #![feature(allocator_api, new_uninit)]\n    ///\n    /// let mut five = Box::<u32>::try_new_uninit()?;\n    ///\n    /// let five = unsafe {\n    ///     // Deferred initialization:\n    ///     five.as_mut_ptr().write(5);\n    ///\n    ///     five.assume_init()\n    /// };\n    ///\n    /// assert_eq!(*five, 5);\n    /// # Ok::<(), std::alloc::AllocError>(())\n    /// ```\n    #[unstable(feature = \"allocator_api\", issue = \"32838\")]\n    // #[unstable(feature = \"new_uninit\", issue = \"63291\")]\n    #[inline]\n    pub fn try_new_uninit() -> Result<Box<mem::MaybeUninit<T>>, AllocError> {\n        Box::try_new_uninit_in(Global)\n    }\n\n    /// Constructs a new `Box` with uninitialized contents, with the memory\n    /// being filled with `0` bytes on the heap\n    ///\n    /// See [`MaybeUninit::zeroed`][zeroed] for examples of correct and incorrect usage\n    /// of this method.\n    ///\n    /// # Examples\n    ///\n    /// ```\n    /// #![feature(allocator_api, new_uninit)]\n    ///\n    /// let zero = Box::<u32>::try_new_zeroed()?;\n    /// let zero = unsafe { zero.assume_init() };\n    ///\n    /// assert_eq!(*zero, 0);\n    /// # Ok::<(), std::alloc::AllocError>(())\n    /// ```\n    ///\n    /// [zeroed]: mem::MaybeUninit::zeroed\n    #[unstable(feature = \"allocator_api\", issue = \"32838\")]\n    // #[unstable(feature = \"new_uninit\", issue = \"63291\")]\n    #[inline]\n    pub fn try_new_zeroed() -> Result<Box<mem::MaybeUninit<T>>, AllocError> {\n        Box::try_new_zeroed_in(Global)\n    }\n}\n\nimpl<T, A: Allocator> Box<T, A> {\n    /// Allocates memory in the given allocator then places `x` into it.\n    ///\n    /// This doesn't actually allocate if `T` is zero-sized.\n    ///\n    /// # Examples\n    ///\n    /// ```\n    /// #![feature(allocator_api)]\n    ///\n    /// use std::alloc::System;\n    ///\n    /// let five = Box::new_in(5, System);\n    /// ```\n    #[cfg(not(no_global_oom_handling))]\n    #[unstable(feature = \"allocator_api\", issue = \"32838\")]\n    #[inline]\n    pub fn new_in(x: T, alloc: A) -> Self {\n        let mut boxed = Self::new_uninit_in(alloc);\n        unsafe {\n            boxed.as_mut_ptr().write(x);\n            boxed.assume_init()\n        }\n    }\n\n    /// Allocates memory in the given allocator then places `x` into it,\n    /// returning an error if the allocation fails\n    ///\n    /// This doesn't actually allocate if `T` is zero-sized.\n    ///\n    /// # Examples\n    ///\n    /// ```\n    /// #![feature(allocator_api)]\n    ///\n    /// use std::alloc::System;\n    ///\n    /// let five = Box::try_new_in(5, System)?;\n    /// # Ok::<(), std::alloc::AllocError>(())\n    /// ```\n    #[unstable(feature = \"allocator_api\", issue = \"32838\")]\n    #[inline]\n    pub fn try_new_in(x: T, alloc: A) -> Result<Self, AllocError> {\n        let mut boxed = Self::try_new_uninit_in(alloc)?;\n        unsafe {\n            boxed.as_mut_ptr().write(x);\n            Ok(boxed.assume_init())\n        }\n    }\n\n    /// Constructs a new box with uninitialized contents in the provided allocator.\n    ///\n    /// # Examples\n    ///\n    /// ```\n    /// #![feature(allocator_api, new_uninit)]\n    ///\n    /// use std::alloc::System;\n    ///\n    /// let mut five = Box::<u32, _>::new_uninit_in(System);\n    ///\n    /// let five = unsafe {\n    ///     // Deferred initialization:\n    ///     five.as_mut_ptr().write(5);\n    ///\n    ///     five.assume_init()\n    /// };\n    ///\n    /// assert_eq!(*five, 5)\n    /// ```\n    #[unstable(feature = \"allocator_api\", issue = \"32838\")]\n    #[cfg(not(no_global_oom_handling))]\n    // #[unstable(feature = \"new_uninit\", issue = \"63291\")]\n    pub fn new_uninit_in(alloc: A) -> Box<mem::MaybeUninit<T>, A> {\n        let layout = Layout::new::<mem::MaybeUninit<T>>();\n        // NOTE: Prefer match over unwrap_or_else since closure sometimes not inlineable.\n        // That would make code size bigger.\n        match Box::try_new_uninit_in(alloc) {\n            Ok(m) => m,\n            Err(_) => handle_alloc_error(layout),\n        }\n    }\n\n    /// Constructs a new box with uninitialized contents in the provided allocator,\n    /// returning an error if the allocation fails\n    ///\n    /// # Examples\n    ///\n    /// ```\n    /// #![feature(allocator_api, new_uninit)]\n    ///\n    /// use std::alloc::System;\n    ///\n    /// let mut five = Box::<u32, _>::try_new_uninit_in(System)?;\n    ///\n    /// let five = unsafe {\n    ///     // Deferred initialization:\n    ///     five.as_mut_ptr().write(5);\n    ///\n    ///     five.assume_init()\n    /// };\n    ///\n    /// assert_eq!(*five, 5);\n    /// # Ok::<(), std::alloc::AllocError>(())\n    /// ```\n    #[unstable(feature = \"allocator_api\", issue = \"32838\")]\n    // #[unstable(feature = \"new_uninit\", issue = \"63291\")]\n    pub fn try_new_uninit_in(alloc: A) -> Result<Box<mem::MaybeUninit<T>, A>, AllocError> {\n        let layout = Layout::new::<mem::MaybeUninit<T>>();\n        let ptr = alloc.allocate(layout)?.cast();\n        unsafe { Ok(Box::from_raw_in(ptr.as_ptr(), alloc)) }\n    }\n\n    /// Constructs a new `Box` with uninitialized contents, with the memory\n    /// being filled with `0` bytes in the provided allocator.\n    ///\n    /// See [`MaybeUninit::zeroed`][zeroed] for examples of correct and incorrect usage\n    /// of this method.\n    ///\n    /// # Examples\n    ///\n    /// ```\n    /// #![feature(allocator_api, new_uninit)]\n    ///\n    /// use std::alloc::System;\n    ///\n    /// let zero = Box::<u32, _>::new_zeroed_in(System);\n    /// let zero = unsafe { zero.assume_init() };\n    ///\n    /// assert_eq!(*zero, 0)\n    /// ```\n    ///\n    /// [zeroed]: mem::MaybeUninit::zeroed\n    #[unstable(feature = \"allocator_api\", issue = \"32838\")]\n    #[cfg(not(no_global_oom_handling))]\n    // #[unstable(feature = \"new_uninit\", issue = \"63291\")]\n    pub fn new_zeroed_in(alloc: A) -> Box<mem::MaybeUninit<T>, A> {\n        let layout = Layout::new::<mem::MaybeUninit<T>>();\n        // NOTE: Prefer match over unwrap_or_else since closure sometimes not inlineable.\n        // That would make code size bigger.\n        match Box::try_new_zeroed_in(alloc) {\n            Ok(m) => m,\n            Err(_) => handle_alloc_error(layout),\n        }\n    }\n\n    /// Constructs a new `Box` with uninitialized contents, with the memory\n    /// being filled with `0` bytes in the provided allocator,\n    /// returning an error if the allocation fails,\n    ///\n    /// See [`MaybeUninit::zeroed`][zeroed] for examples of correct and incorrect usage\n    /// of this method.\n    ///\n    /// # Examples\n    ///\n    /// ```\n    /// #![feature(allocator_api, new_uninit)]\n    ///\n    /// use std::alloc::System;\n    ///\n    /// let zero = Box::<u32, _>::try_new_zeroed_in(System)?;\n    /// let zero = unsafe { zero.assume_init() };\n    ///\n    /// assert_eq!(*zero, 0);\n    /// # Ok::<(), std::alloc::AllocError>(())\n    /// ```\n    ///\n    /// [zeroed]: mem::MaybeUninit::zeroed\n    #[unstable(feature = \"allocator_api\", issue = \"32838\")]\n    // #[unstable(feature = \"new_uninit\", issue = \"63291\")]\n    pub fn try_new_zeroed_in(alloc: A) -> Result<Box<mem::MaybeUninit<T>, A>, AllocError> {\n        let layout = Layout::new::<mem::MaybeUninit<T>>();\n        let ptr = alloc.allocate_zeroed(layout)?.cast();\n        unsafe { Ok(Box::from_raw_in(ptr.as_ptr(), alloc)) }\n    }\n\n    /// Constructs a new `Pin<Box<T, A>>`. If `T` does not implement `Unpin`, then\n    /// `x` will be pinned in memory and unable to be moved.\n    #[cfg(not(no_global_oom_handling))]\n    #[unstable(feature = \"allocator_api\", issue = \"32838\")]\n    #[inline(always)]\n    pub fn pin_in(x: T, alloc: A) -> Pin<Self>\n    where\n        A: 'static,\n    {\n        Self::new_in(x, alloc).into()\n    }\n\n    /// Converts a `Box<T>` into a `Box<[T]>`\n    ///\n    /// This conversion does not allocate on the heap and happens in place.\n    #[unstable(feature = \"box_into_boxed_slice\", issue = \"71582\")]\n    pub fn into_boxed_slice(boxed: Self) -> Box<[T], A> {\n        let (raw, alloc) = Box::into_raw_with_allocator(boxed);\n        unsafe { Box::from_raw_in(raw as *mut [T; 1], alloc) }\n    }\n\n    /// Consumes the `Box`, returning the wrapped value.\n    ///\n    /// # Examples\n    ///\n    /// ```\n    /// #![feature(box_into_inner)]\n    ///\n    /// let c = Box::new(5);\n    ///\n    /// assert_eq!(Box::into_inner(c), 5);\n    /// ```\n    #[unstable(feature = \"box_into_inner\", issue = \"80437\")]\n    #[inline]\n    pub fn into_inner(boxed: Self) -> T {\n        *boxed\n    }\n}\n\nimpl<T> Box<[T]> {\n    /// Constructs a new boxed slice with uninitialized contents.\n    ///\n    /// # Examples\n    ///\n    /// ```\n    /// #![feature(new_uninit)]\n    ///\n    /// let mut values = Box::<[u32]>::new_uninit_slice(3);\n    ///\n    /// let values = unsafe {\n    ///     // Deferred initialization:\n    ///     values[0].as_mut_ptr().write(1);\n    ///     values[1].as_mut_ptr().write(2);\n    ///     values[2].as_mut_ptr().write(3);\n    ///\n    ///     values.assume_init()\n    /// };\n    ///\n    /// assert_eq!(*values, [1, 2, 3])\n    /// ```\n    #[cfg(not(no_global_oom_handling))]\n    #[unstable(feature = \"new_uninit\", issue = \"63291\")]\n    pub fn new_uninit_slice(len: usize) -> Box<[mem::MaybeUninit<T>]> {\n        unsafe { RawVec::with_capacity(len).into_box(len) }\n    }\n\n    /// Constructs a new boxed slice with uninitialized contents, with the memory\n    /// being filled with `0` bytes.\n    ///\n    /// See [`MaybeUninit::zeroed`][zeroed] for examples of correct and incorrect usage\n    /// of this method.\n    ///\n    /// # Examples\n    ///\n    /// ```\n    /// #![feature(new_uninit)]\n    ///\n    /// let values = Box::<[u32]>::new_zeroed_slice(3);\n    /// let values = unsafe { values.assume_init() };\n    ///\n    /// assert_eq!(*values, [0, 0, 0])\n    /// ```\n    ///\n    /// [zeroed]: mem::MaybeUninit::zeroed\n    #[cfg(not(no_global_oom_handling))]\n    #[unstable(feature = \"new_uninit\", issue = \"63291\")]\n    pub fn new_zeroed_slice(len: usize) -> Box<[mem::MaybeUninit<T>]> {\n        unsafe { RawVec::with_capacity_zeroed(len).into_box(len) }\n    }\n}\n\nimpl<T, A: Allocator> Box<[T], A> {\n    /// Constructs a new boxed slice with uninitialized contents in the provided allocator.\n    ///\n    /// # Examples\n    ///\n    /// ```\n    /// #![feature(allocator_api, new_uninit)]\n    ///\n    /// use std::alloc::System;\n    ///\n    /// let mut values = Box::<[u32], _>::new_uninit_slice_in(3, System);\n    ///\n    /// let values = unsafe {\n    ///     // Deferred initialization:\n    ///     values[0].as_mut_ptr().write(1);\n    ///     values[1].as_mut_ptr().write(2);\n    ///     values[2].as_mut_ptr().write(3);\n    ///\n    ///     values.assume_init()\n    /// };\n    ///\n    /// assert_eq!(*values, [1, 2, 3])\n    /// ```\n    #[cfg(not(no_global_oom_handling))]\n    #[unstable(feature = \"allocator_api\", issue = \"32838\")]\n    // #[unstable(feature = \"new_uninit\", issue = \"63291\")]\n    pub fn new_uninit_slice_in(len: usize, alloc: A) -> Box<[mem::MaybeUninit<T>], A> {\n        unsafe { RawVec::with_capacity_in(len, alloc).into_box(len) }\n    }\n\n    /// Constructs a new boxed slice with uninitialized contents in the provided allocator,\n    /// with the memory being filled with `0` bytes.\n    ///\n    /// See [`MaybeUninit::zeroed`][zeroed] for examples of correct and incorrect usage\n    /// of this method.\n    ///\n    /// # Examples\n    ///\n    /// ```\n    /// #![feature(allocator_api, new_uninit)]\n    ///\n    /// use std::alloc::System;\n    ///\n    /// let values = Box::<[u32], _>::new_zeroed_slice_in(3, System);\n    /// let values = unsafe { values.assume_init() };\n    ///\n    /// assert_eq!(*values, [0, 0, 0])\n    /// ```\n    ///\n    /// [zeroed]: mem::MaybeUninit::zeroed\n    #[cfg(not(no_global_oom_handling))]\n    #[unstable(feature = \"allocator_api\", issue = \"32838\")]\n    // #[unstable(feature = \"new_uninit\", issue = \"63291\")]\n    pub fn new_zeroed_slice_in(len: usize, alloc: A) -> Box<[mem::MaybeUninit<T>], A> {\n        unsafe { RawVec::with_capacity_zeroed_in(len, alloc).into_box(len) }\n    }\n}\n\nimpl<T, A: Allocator> Box<mem::MaybeUninit<T>, A> {\n    /// Converts to `Box<T, A>`.\n    ///\n    /// # Safety\n    ///\n    /// As with [`MaybeUninit::assume_init`],\n    /// it is up to the caller to guarantee that the value\n    /// really is in an initialized state.\n    /// Calling this when the content is not yet fully initialized\n    /// causes immediate undefined behavior.\n    ///\n    /// [`MaybeUninit::assume_init`]: mem::MaybeUninit::assume_init\n    ///\n    /// # Examples\n    ///\n    /// ```\n    /// #![feature(new_uninit)]\n    ///\n    /// let mut five = Box::<u32>::new_uninit();\n    ///\n    /// let five: Box<u32> = unsafe {\n    ///     // Deferred initialization:\n    ///     five.as_mut_ptr().write(5);\n    ///\n    ///     five.assume_init()\n    /// };\n    ///\n    /// assert_eq!(*five, 5)\n    /// ```\n    #[unstable(feature = \"new_uninit\", issue = \"63291\")]\n    #[inline]\n    pub unsafe fn assume_init(self) -> Box<T, A> {\n        let (raw, alloc) = Box::into_raw_with_allocator(self);\n        unsafe { Box::from_raw_in(raw as *mut T, alloc) }\n    }\n}\n\nimpl<T, A: Allocator> Box<[mem::MaybeUninit<T>], A> {\n    /// Converts to `Box<[T], A>`.\n    ///\n    /// # Safety\n    ///\n    /// As with [`MaybeUninit::assume_init`],\n    /// it is up to the caller to guarantee that the values\n    /// really are in an initialized state.\n    /// Calling this when the content is not yet fully initialized\n    /// causes immediate undefined behavior.\n    ///\n    /// [`MaybeUninit::assume_init`]: mem::MaybeUninit::assume_init\n    ///\n    /// # Examples\n    ///\n    /// ```\n    /// #![feature(new_uninit)]\n    ///\n    /// let mut values = Box::<[u32]>::new_uninit_slice(3);\n    ///\n    /// let values = unsafe {\n    ///     // Deferred initialization:\n    ///     values[0].as_mut_ptr().write(1);\n    ///     values[1].as_mut_ptr().write(2);\n    ///     values[2].as_mut_ptr().write(3);\n    ///\n    ///     values.assume_init()\n    /// };\n    ///\n    /// assert_eq!(*values, [1, 2, 3])\n    /// ```\n    #[unstable(feature = \"new_uninit\", issue = \"63291\")]\n    #[inline]\n    pub unsafe fn assume_init(self) -> Box<[T], A> {\n        let (raw, alloc) = Box::into_raw_with_allocator(self);\n        unsafe { Box::from_raw_in(raw as *mut [T], alloc) }\n    }\n}\n\nimpl<T: ?Sized> Box<T> {\n    /// Constructs a box from a raw pointer.\n    ///\n    /// After calling this function, the raw pointer is owned by the\n    /// resulting `Box`. Specifically, the `Box` destructor will call\n    /// the destructor of `T` and free the allocated memory. For this\n    /// to be safe, the memory must have been allocated in accordance\n    /// with the [memory layout] used by `Box` .\n    ///\n    /// # Safety\n    ///\n    /// This function is unsafe because improper use may lead to\n    /// memory problems. For example, a double-free may occur if the\n    /// function is called twice on the same raw pointer.\n    ///\n    /// The safety conditions are described in the [memory layout] section.\n    ///\n    /// # Examples\n    ///\n    /// Recreate a `Box` which was previously converted to a raw pointer\n    /// using [`Box::into_raw`]:\n    /// ```\n    /// let x = Box::new(5);\n    /// let ptr = Box::into_raw(x);\n    /// let x = unsafe { Box::from_raw(ptr) };\n    /// ```\n    /// Manually create a `Box` from scratch by using the global allocator:\n    /// ```\n    /// use std::alloc::{alloc, Layout};\n    ///\n    /// unsafe {\n    ///     let ptr = alloc(Layout::new::<i32>()) as *mut i32;\n    ///     // In general .write is required to avoid attempting to destruct\n    ///     // the (uninitialized) previous contents of `ptr`, though for this\n    ///     // simple example `*ptr = 5` would have worked as well.\n    ///     ptr.write(5);\n    ///     let x = Box::from_raw(ptr);\n    /// }\n    /// ```\n    ///\n    /// [memory layout]: self#memory-layout\n    /// [`Layout`]: crate::Layout\n    #[stable(feature = \"box_raw\", since = \"1.4.0\")]\n    #[inline]\n    pub unsafe fn from_raw(raw: *mut T) -> Self {\n        unsafe { Self::from_raw_in(raw, Global) }\n    }\n}\n\nimpl<T: ?Sized, A: Allocator> Box<T, A> {\n    /// Constructs a box from a raw pointer in the given allocator.\n    ///\n    /// After calling this function, the raw pointer is owned by the\n    /// resulting `Box`. Specifically, the `Box` destructor will call\n    /// the destructor of `T` and free the allocated memory. For this\n    /// to be safe, the memory must have been allocated in accordance\n    /// with the [memory layout] used by `Box` .\n    ///\n    /// # Safety\n    ///\n    /// This function is unsafe because improper use may lead to\n    /// memory problems. For example, a double-free may occur if the\n    /// function is called twice on the same raw pointer.\n    ///\n    ///\n    /// # Examples\n    ///\n    /// Recreate a `Box` which was previously converted to a raw pointer\n    /// using [`Box::into_raw_with_allocator`]:\n    /// ```\n    /// #![feature(allocator_api)]\n    ///\n    /// use std::alloc::System;\n    ///\n    /// let x = Box::new_in(5, System);\n    /// let (ptr, alloc) = Box::into_raw_with_allocator(x);\n    /// let x = unsafe { Box::from_raw_in(ptr, alloc) };\n    /// ```\n    /// Manually create a `Box` from scratch by using the system allocator:\n    /// ```\n    /// #![feature(allocator_api, slice_ptr_get)]\n    ///\n    /// use std::alloc::{Allocator, Layout, System};\n    ///\n    /// unsafe {\n    ///     let ptr = System.allocate(Layout::new::<i32>())?.as_mut_ptr() as *mut i32;\n    ///     // In general .write is required to avoid attempting to destruct\n    ///     // the (uninitialized) previous contents of `ptr`, though for this\n    ///     // simple example `*ptr = 5` would have worked as well.\n    ///     ptr.write(5);\n    ///     let x = Box::from_raw_in(ptr, System);\n    /// }\n    /// # Ok::<(), std::alloc::AllocError>(())\n    /// ```\n    ///\n    /// [memory layout]: self#memory-layout\n    /// [`Layout`]: crate::Layout\n    #[unstable(feature = \"allocator_api\", issue = \"32838\")]\n    #[inline]\n    pub unsafe fn from_raw_in(raw: *mut T, alloc: A) -> Self {\n        Box(unsafe { Unique::new_unchecked(raw) }, alloc)\n    }\n\n    /// Consumes the `Box`, returning a wrapped raw pointer.\n    ///\n    /// The pointer will be properly aligned and non-null.\n    ///\n    /// After calling this function, the caller is responsible for the\n    /// memory previously managed by the `Box`. In particular, the\n    /// caller should properly destroy `T` and release the memory, taking\n    /// into account the [memory layout] used by `Box`. The easiest way to\n    /// do this is to convert the raw pointer back into a `Box` with the\n    /// [`Box::from_raw`] function, allowing the `Box` destructor to perform\n    /// the cleanup.\n    ///\n    /// Note: this is an associated function, which means that you have\n    /// to call it as `Box::into_raw(b)` instead of `b.into_raw()`. This\n    /// is so that there is no conflict with a method on the inner type.\n    ///\n    /// # Examples\n    /// Converting the raw pointer back into a `Box` with [`Box::from_raw`]\n    /// for automatic cleanup:\n    /// ```\n    /// let x = Box::new(String::from(\"Hello\"));\n    /// let ptr = Box::into_raw(x);\n    /// let x = unsafe { Box::from_raw(ptr) };\n    /// ```\n    /// Manual cleanup by explicitly running the destructor and deallocating\n    /// the memory:\n    /// ```\n    /// use std::alloc::{dealloc, Layout};\n    /// use std::ptr;\n    ///\n    /// let x = Box::new(String::from(\"Hello\"));\n    /// let p = Box::into_raw(x);\n    /// unsafe {\n    ///     ptr::drop_in_place(p);\n    ///     dealloc(p as *mut u8, Layout::new::<String>());\n    /// }\n    /// ```\n    ///\n    /// [memory layout]: self#memory-layout\n    #[stable(feature = \"box_raw\", since = \"1.4.0\")]\n    #[inline]\n    pub fn into_raw(b: Self) -> *mut T {\n        Self::into_raw_with_allocator(b).0\n    }\n\n    /// Consumes the `Box`, returning a wrapped raw pointer and the allocator.\n    ///\n    /// The pointer will be properly aligned and non-null.\n    ///\n    /// After calling this function, the caller is responsible for the\n    /// memory previously managed by the `Box`. In particular, the\n    /// caller should properly destroy `T` and release the memory, taking\n    /// into account the [memory layout] used by `Box`. The easiest way to\n    /// do this is to convert the raw pointer back into a `Box` with the\n    /// [`Box::from_raw_in`] function, allowing the `Box` destructor to perform\n    /// the cleanup.\n    ///\n    /// Note: this is an associated function, which means that you have\n    /// to call it as `Box::into_raw_with_allocator(b)` instead of `b.into_raw_with_allocator()`. This\n    /// is so that there is no conflict with a method on the inner type.\n    ///\n    /// # Examples\n    /// Converting the raw pointer back into a `Box` with [`Box::from_raw_in`]\n    /// for automatic cleanup:\n    /// ```\n    /// #![feature(allocator_api)]\n    ///\n    /// use std::alloc::System;\n    ///\n    /// let x = Box::new_in(String::from(\"Hello\"), System);\n    /// let (ptr, alloc) = Box::into_raw_with_allocator(x);\n    /// let x = unsafe { Box::from_raw_in(ptr, alloc) };\n    /// ```\n    /// Manual cleanup by explicitly running the destructor and deallocating\n    /// the memory:\n    /// ```\n    /// #![feature(allocator_api)]\n    ///\n    /// use std::alloc::{Allocator, Layout, System};\n    /// use std::ptr::{self, NonNull};\n    ///\n    /// let x = Box::new_in(String::from(\"Hello\"), System);\n    /// let (ptr, alloc) = Box::into_raw_with_allocator(x);\n    /// unsafe {\n    ///     ptr::drop_in_place(ptr);\n    ///     let non_null = NonNull::new_unchecked(ptr);\n    ///     alloc.deallocate(non_null.cast(), Layout::new::<String>());\n    /// }\n    /// ```\n    ///\n    /// [memory layout]: self#memory-layout\n    #[unstable(feature = \"allocator_api\", issue = \"32838\")]\n    #[inline]\n    pub fn into_raw_with_allocator(b: Self) -> (*mut T, A) {\n        let (leaked, alloc) = Box::into_unique(b);\n        (leaked.as_ptr(), alloc)\n    }\n\n    #[unstable(\n        feature = \"ptr_internals\",\n        issue = \"none\",\n        reason = \"use `Box::leak(b).into()` or `Unique::from(Box::leak(b))` instead\"\n    )]\n    #[inline]\n    #[doc(hidden)]\n    pub fn into_unique(b: Self) -> (Unique<T>, A) {\n        // Box is recognized as a \"unique pointer\" by Stacked Borrows, but internally it is a\n        // raw pointer for the type system. Turning it directly into a raw pointer would not be\n        // recognized as \"releasing\" the unique pointer to permit aliased raw accesses,\n        // so all raw pointer methods have to go through `Box::leak`. Turning *that* to a raw pointer\n        // behaves correctly.\n        let alloc = unsafe { ptr::read(&b.1) };\n        (Unique::from(Box::leak(b)), alloc)\n    }\n\n    /// Returns a reference to the underlying allocator.\n    ///\n    /// Note: this is an associated function, which means that you have\n    /// to call it as `Box::allocator(&b)` instead of `b.allocator()`. This\n    /// is so that there is no conflict with a method on the inner type.\n    #[unstable(feature = \"allocator_api\", issue = \"32838\")]\n    #[inline]\n    pub fn allocator(b: &Self) -> &A {\n        &b.1\n    }\n\n    /// Consumes and leaks the `Box`, returning a mutable reference,\n    /// `&'a mut T`. Note that the type `T` must outlive the chosen lifetime\n    /// `'a`. If the type has only static references, or none at all, then this\n    /// may be chosen to be `'static`.\n    ///\n    /// This function is mainly useful for data that lives for the remainder of\n    /// the program's life. Dropping the returned reference will cause a memory\n    /// leak. If this is not acceptable, the reference should first be wrapped\n    /// with the [`Box::from_raw`] function producing a `Box`. This `Box` can\n    /// then be dropped which will properly destroy `T` and release the\n    /// allocated memory.\n    ///\n    /// Note: this is an associated function, which means that you have\n    /// to call it as `Box::leak(b)` instead of `b.leak()`. This\n    /// is so that there is no conflict with a method on the inner type.\n    ///\n    /// # Examples\n    ///\n    /// Simple usage:\n    ///\n    /// ```\n    /// let x = Box::new(41);\n    /// let static_ref: &'static mut usize = Box::leak(x);\n    /// *static_ref += 1;\n    /// assert_eq!(*static_ref, 42);\n    /// ```\n    ///\n    /// Unsized data:\n    ///\n    /// ```\n    /// let x = vec![1, 2, 3].into_boxed_slice();\n    /// let static_ref = Box::leak(x);\n    /// static_ref[0] = 4;\n    /// assert_eq!(*static_ref, [4, 2, 3]);\n    /// ```\n    #[stable(feature = \"box_leak\", since = \"1.26.0\")]\n    #[inline]\n    pub fn leak<'a>(b: Self) -> &'a mut T\n    where\n        A: 'a,\n    {\n        unsafe { &mut *mem::ManuallyDrop::new(b).0.as_ptr() }\n    }\n\n    /// Converts a `Box<T>` into a `Pin<Box<T>>`\n    ///\n    /// This conversion does not allocate on the heap and happens in place.\n    ///\n    /// This is also available via [`From`].\n    #[unstable(feature = \"box_into_pin\", issue = \"62370\")]\n    pub fn into_pin(boxed: Self) -> Pin<Self>\n    where\n        A: 'static,\n    {\n        // It's not possible to move or replace the insides of a `Pin<Box<T>>`\n        // when `T: !Unpin`,  so it's safe to pin it directly without any\n        // additional requirements.\n        unsafe { Pin::new_unchecked(boxed) }\n    }\n}\n\n#[stable(feature = \"rust1\", since = \"1.0.0\")]\nunsafe impl<#[may_dangle] T: ?Sized, A: Allocator> Drop for Box<T, A> {\n    fn drop(&mut self) {\n        // FIXME: Do nothing, drop is currently performed by compiler.\n    }\n}\n\n#[stable(feature = \"rust1\", since = \"1.0.0\")]\nimpl<T: Default> Default for Box<T> {\n    /// Creates a `Box<T>`, with the `Default` value for T.\n    fn default() -> Self {\n        box T::default()\n    }\n}\n\n#[cfg(not(no_global_oom_handling))]\n#[stable(feature = \"rust1\", since = \"1.0.0\")]\nimpl<T> Default for Box<[T]> {\n    fn default() -> Self {\n        Box::<[T; 0]>::new([])\n    }\n}\n\n#[cfg(not(no_global_oom_handling))]\n#[stable(feature = \"default_box_extra\", since = \"1.17.0\")]\nimpl Default for Box<str> {\n    fn default() -> Self {\n        unsafe { from_boxed_utf8_unchecked(Default::default()) }\n    }\n}\n\n#[cfg(not(no_global_oom_handling))]\n#[stable(feature = \"rust1\", since = \"1.0.0\")]\nimpl<T: Clone, A: Allocator + Clone> Clone for Box<T, A> {\n    /// Returns a new box with a `clone()` of this box's contents.\n    ///\n    /// # Examples\n    ///\n    /// ```\n    /// let x = Box::new(5);\n    /// let y = x.clone();\n    ///\n    /// // The value is the same\n    /// assert_eq!(x, y);\n    ///\n    /// // But they are unique objects\n    /// assert_ne!(&*x as *const i32, &*y as *const i32);\n    /// ```\n    #[inline]\n    fn clone(&self) -> Self {\n        // Pre-allocate memory to allow writing the cloned value directly.\n        let mut boxed = Self::new_uninit_in(self.1.clone());\n        unsafe {\n            (**self).write_clone_into_raw(boxed.as_mut_ptr());\n            boxed.assume_init()\n        }\n    }\n\n    /// Copies `source`'s contents into `self` without creating a new allocation.\n    ///\n    /// # Examples\n    ///\n    /// ```\n    /// let x = Box::new(5);\n    /// let mut y = Box::new(10);\n    /// let yp: *const i32 = &*y;\n    ///\n    /// y.clone_from(&x);\n    ///\n    /// // The value is the same\n    /// assert_eq!(x, y);\n    ///\n    /// // And no allocation occurred\n    /// assert_eq!(yp, &*y);\n    /// ```\n    #[inline]\n    fn clone_from(&mut self, source: &Self) {\n        (**self).clone_from(&(**source));\n    }\n}\n\n#[cfg(not(no_global_oom_handling))]\n#[stable(feature = \"box_slice_clone\", since = \"1.3.0\")]\nimpl Clone for Box<str> {\n    fn clone(&self) -> Self {\n        // this makes a copy of the data\n        let buf: Box<[u8]> = self.as_bytes().into();\n        unsafe { from_boxed_utf8_unchecked(buf) }\n    }\n}\n\n#[stable(feature = \"rust1\", since = \"1.0.0\")]\nimpl<T: ?Sized + PartialEq, A: Allocator> PartialEq for Box<T, A> {\n    #[inline]\n    fn eq(&self, other: &Self) -> bool {\n        PartialEq::eq(&**self, &**other)\n    }\n    #[inline]\n    fn ne(&self, other: &Self) -> bool {\n        PartialEq::ne(&**self, &**other)\n    }\n}\n#[stable(feature = \"rust1\", since = \"1.0.0\")]\nimpl<T: ?Sized + PartialOrd, A: Allocator> PartialOrd for Box<T, A> {\n    #[inline]\n    fn partial_cmp(&self, other: &Self) -> Option<Ordering> {\n        PartialOrd::partial_cmp(&**self, &**other)\n    }\n    #[inline]\n    fn lt(&self, other: &Self) -> bool {\n        PartialOrd::lt(&**self, &**other)\n    }\n    #[inline]\n    fn le(&self, other: &Self) -> bool {\n        PartialOrd::le(&**self, &**other)\n    }\n    #[inline]\n    fn ge(&self, other: &Self) -> bool {\n        PartialOrd::ge(&**self, &**other)\n    }\n    #[inline]\n    fn gt(&self, other: &Self) -> bool {\n        PartialOrd::gt(&**self, &**other)\n    }\n}\n#[stable(feature = \"rust1\", since = \"1.0.0\")]\nimpl<T: ?Sized + Ord, A: Allocator> Ord for Box<T, A> {\n    #[inline]\n    fn cmp(&self, other: &Self) -> Ordering {\n        Ord::cmp(&**self, &**other)\n    }\n}\n#[stable(feature = \"rust1\", since = \"1.0.0\")]\nimpl<T: ?Sized + Eq, A: Allocator> Eq for Box<T, A> {}\n\n#[stable(feature = \"rust1\", since = \"1.0.0\")]\nimpl<T: ?Sized + Hash, A: Allocator> Hash for Box<T, A> {\n    fn hash<H: Hasher>(&self, state: &mut H) {\n        (**self).hash(state);\n    }\n}\n\n#[stable(feature = \"indirect_hasher_impl\", since = \"1.22.0\")]\nimpl<T: ?Sized + Hasher, A: Allocator> Hasher for Box<T, A> {\n    fn finish(&self) -> u64 {\n        (**self).finish()\n    }\n    fn write(&mut self, bytes: &[u8]) {\n        (**self).write(bytes)\n    }\n    fn write_u8(&mut self, i: u8) {\n        (**self).write_u8(i)\n    }\n    fn write_u16(&mut self, i: u16) {\n        (**self).write_u16(i)\n    }\n    fn write_u32(&mut self, i: u32) {\n        (**self).write_u32(i)\n    }\n    fn write_u64(&mut self, i: u64) {\n        (**self).write_u64(i)\n    }\n    fn write_u128(&mut self, i: u128) {\n        (**self).write_u128(i)\n    }\n    fn write_usize(&mut self, i: usize) {\n        (**self).write_usize(i)\n    }\n    fn write_i8(&mut self, i: i8) {\n        (**self).write_i8(i)\n    }\n    fn write_i16(&mut self, i: i16) {\n        (**self).write_i16(i)\n    }\n    fn write_i32(&mut self, i: i32) {\n        (**self).write_i32(i)\n    }\n    fn write_i64(&mut self, i: i64) {\n        (**self).write_i64(i)\n    }\n    fn write_i128(&mut self, i: i128) {\n        (**self).write_i128(i)\n    }\n    fn write_isize(&mut self, i: isize) {\n        (**self).write_isize(i)\n    }\n}\n\n#[cfg(not(no_global_oom_handling))]\n#[stable(feature = \"from_for_ptrs\", since = \"1.6.0\")]\nimpl<T> From<T> for Box<T> {\n    /// Converts a `T` into a `Box<T>`\n    ///\n    /// The conversion allocates on the heap and moves `t`\n    /// from the stack into it.\n    ///\n    /// # Examples\n    /// ```rust\n    /// let x = 5;\n    /// let boxed = Box::new(5);\n    ///\n    /// assert_eq!(Box::from(x), boxed);\n    /// ```\n    fn from(t: T) -> Self {\n        Box::new(t)\n    }\n}\n\n#[stable(feature = \"pin\", since = \"1.33.0\")]\nimpl<T: ?Sized, A: Allocator> From<Box<T, A>> for Pin<Box<T, A>>\nwhere\n    A: 'static,\n{\n    /// Converts a `Box<T>` into a `Pin<Box<T>>`\n    ///\n    /// This conversion does not allocate on the heap and happens in place.\n    fn from(boxed: Box<T, A>) -> Self {\n        Box::into_pin(boxed)\n    }\n}\n\n#[cfg(not(no_global_oom_handling))]\n#[stable(feature = \"box_from_slice\", since = \"1.17.0\")]\nimpl<T: Copy> From<&[T]> for Box<[T]> {\n    /// Converts a `&[T]` into a `Box<[T]>`\n    ///\n    /// This conversion allocates on the heap\n    /// and performs a copy of `slice`.\n    ///\n    /// # Examples\n    /// ```rust\n    /// // create a &[u8] which will be used to create a Box<[u8]>\n    /// let slice: &[u8] = &[104, 101, 108, 108, 111];\n    /// let boxed_slice: Box<[u8]> = Box::from(slice);\n    ///\n    /// println!(\"{:?}\", boxed_slice);\n    /// ```\n    fn from(slice: &[T]) -> Box<[T]> {\n        let len = slice.len();\n        let buf = RawVec::with_capacity(len);\n        unsafe {\n            ptr::copy_nonoverlapping(slice.as_ptr(), buf.ptr(), len);\n            buf.into_box(slice.len()).assume_init()\n        }\n    }\n}\n\n#[cfg(not(no_global_oom_handling))]\n#[stable(feature = \"box_from_cow\", since = \"1.45.0\")]\nimpl<T: Copy> From<Cow<'_, [T]>> for Box<[T]> {\n    #[inline]\n    fn from(cow: Cow<'_, [T]>) -> Box<[T]> {\n        match cow {\n            Cow::Borrowed(slice) => Box::from(slice),\n            Cow::Owned(slice) => Box::from(slice),\n        }\n    }\n}\n\n#[cfg(not(no_global_oom_handling))]\n#[stable(feature = \"box_from_slice\", since = \"1.17.0\")]\nimpl From<&str> for Box<str> {\n    /// Converts a `&str` into a `Box<str>`\n    ///\n    /// This conversion allocates on the heap\n    /// and performs a copy of `s`.\n    ///\n    /// # Examples\n    /// ```rust\n    /// let boxed: Box<str> = Box::from(\"hello\");\n    /// println!(\"{}\", boxed);\n    /// ```\n    #[inline]\n    fn from(s: &str) -> Box<str> {\n        unsafe { from_boxed_utf8_unchecked(Box::from(s.as_bytes())) }\n    }\n}\n\n#[cfg(not(no_global_oom_handling))]\n#[stable(feature = \"box_from_cow\", since = \"1.45.0\")]\nimpl From<Cow<'_, str>> for Box<str> {\n    #[inline]\n    fn from(cow: Cow<'_, str>) -> Box<str> {\n        match cow {\n            Cow::Borrowed(s) => Box::from(s),\n            Cow::Owned(s) => Box::from(s),\n        }\n    }\n}\n\n#[stable(feature = \"boxed_str_conv\", since = \"1.19.0\")]\nimpl<A: Allocator> From<Box<str, A>> for Box<[u8], A> {\n    /// Converts a `Box<str>` into a `Box<[u8]>`\n    ///\n    /// This conversion does not allocate on the heap and happens in place.\n    ///\n    /// # Examples\n    /// ```rust\n    /// // create a Box<str> which will be used to create a Box<[u8]>\n    /// let boxed: Box<str> = Box::from(\"hello\");\n    /// let boxed_str: Box<[u8]> = Box::from(boxed);\n    ///\n    /// // create a &[u8] which will be used to create a Box<[u8]>\n    /// let slice: &[u8] = &[104, 101, 108, 108, 111];\n    /// let boxed_slice = Box::from(slice);\n    ///\n    /// assert_eq!(boxed_slice, boxed_str);\n    /// ```\n    #[inline]\n    fn from(s: Box<str, A>) -> Self {\n        let (raw, alloc) = Box::into_raw_with_allocator(s);\n        unsafe { Box::from_raw_in(raw as *mut [u8], alloc) }\n    }\n}\n\n#[stable(feature = \"box_from_array\", since = \"1.45.0\")]\nimpl<T, const N: usize> From<[T; N]> for Box<[T]> {\n    /// Converts a `[T; N]` into a `Box<[T]>`\n    ///\n    /// This conversion moves the array to newly heap-allocated memory.\n    ///\n    /// # Examples\n    /// ```rust\n    /// let boxed: Box<[u8]> = Box::from([4, 2]);\n    /// println!(\"{:?}\", boxed);\n    /// ```\n    fn from(array: [T; N]) -> Box<[T]> {\n        box array\n    }\n}\n\n#[stable(feature = \"boxed_slice_try_from\", since = \"1.43.0\")]\nimpl<T, const N: usize> TryFrom<Box<[T]>> for Box<[T; N]> {\n    type Error = Box<[T]>;\n\n    fn try_from(boxed_slice: Box<[T]>) -> Result<Self, Self::Error> {\n        if boxed_slice.len() == N {\n            Ok(unsafe { Box::from_raw(Box::into_raw(boxed_slice) as *mut [T; N]) })\n        } else {\n            Err(boxed_slice)\n        }\n    }\n}\n\nimpl<A: Allocator> Box<dyn Any, A> {\n    #[inline]\n    #[stable(feature = \"rust1\", since = \"1.0.0\")]\n    /// Attempt to downcast the box to a concrete type.\n    ///\n    /// # Examples\n    ///\n    /// ```\n    /// use std::any::Any;\n    ///\n    /// fn print_if_string(value: Box<dyn Any>) {\n    ///     if let Ok(string) = value.downcast::<String>() {\n    ///         println!(\"String ({}): {}\", string.len(), string);\n    ///     }\n    /// }\n    ///\n    /// let my_string = \"Hello World\".to_string();\n    /// print_if_string(Box::new(my_string));\n    /// print_if_string(Box::new(0i8));\n    /// ```\n    pub fn downcast<T: Any>(self) -> Result<Box<T, A>, Self> {\n        if self.is::<T>() {\n            unsafe {\n                let (raw, alloc): (*mut dyn Any, _) = Box::into_raw_with_allocator(self);\n                Ok(Box::from_raw_in(raw as *mut T, alloc))\n            }\n        } else {\n            Err(self)\n        }\n    }\n}\n\nimpl<A: Allocator> Box<dyn Any + Send, A> {\n    #[inline]\n    #[stable(feature = \"rust1\", since = \"1.0.0\")]\n    /// Attempt to downcast the box to a concrete type.\n    ///\n    /// # Examples\n    ///\n    /// ```\n    /// use std::any::Any;\n    ///\n    /// fn print_if_string(value: Box<dyn Any + Send>) {\n    ///     if let Ok(string) = value.downcast::<String>() {\n    ///         println!(\"String ({}): {}\", string.len(), string);\n    ///     }\n    /// }\n    ///\n    /// let my_string = \"Hello World\".to_string();\n    /// print_if_string(Box::new(my_string));\n    /// print_if_string(Box::new(0i8));\n    /// ```\n    pub fn downcast<T: Any>(self) -> Result<Box<T, A>, Self> {\n        if self.is::<T>() {\n            unsafe {\n                let (raw, alloc): (*mut (dyn Any + Send), _) = Box::into_raw_with_allocator(self);\n                Ok(Box::from_raw_in(raw as *mut T, alloc))\n            }\n        } else {\n            Err(self)\n        }\n    }\n}\n\nimpl<A: Allocator> Box<dyn Any + Send + Sync, A> {\n    #[inline]\n    #[stable(feature = \"box_send_sync_any_downcast\", since = \"1.51.0\")]\n    /// Attempt to downcast the box to a concrete type.\n    ///\n    /// # Examples\n    ///\n    /// ```\n    /// use std::any::Any;\n    ///\n    /// fn print_if_string(value: Box<dyn Any + Send + Sync>) {\n    ///     if let Ok(string) = value.downcast::<String>() {\n    ///         println!(\"String ({}): {}\", string.len(), string);\n    ///     }\n    /// }\n    ///\n    /// let my_string = \"Hello World\".to_string();\n    /// print_if_string(Box::new(my_string));\n    /// print_if_string(Box::new(0i8));\n    /// ```\n    pub fn downcast<T: Any>(self) -> Result<Box<T, A>, Self> {\n        if self.is::<T>() {\n            unsafe {\n                let (raw, alloc): (*mut (dyn Any + Send + Sync), _) =\n                    Box::into_raw_with_allocator(self);\n                Ok(Box::from_raw_in(raw as *mut T, alloc))\n            }\n        } else {\n            Err(self)\n        }\n    }\n}\n\n#[stable(feature = \"rust1\", since = \"1.0.0\")]\nimpl<T: fmt::Display + ?Sized, A: Allocator> fmt::Display for Box<T, A> {\n    fn fmt(&self, f: &mut fmt::Formatter<'_>) -> fmt::Result {\n        fmt::Display::fmt(&**self, f)\n    }\n}\n\n#[stable(feature = \"rust1\", since = \"1.0.0\")]\nimpl<T: fmt::Debug + ?Sized, A: Allocator> fmt::Debug for Box<T, A> {\n    fn fmt(&self, f: &mut fmt::Formatter<'_>) -> fmt::Result {\n        fmt::Debug::fmt(&**self, f)\n    }\n}\n\n#[stable(feature = \"rust1\", since = \"1.0.0\")]\nimpl<T: ?Sized, A: Allocator> fmt::Pointer for Box<T, A> {\n    fn fmt(&self, f: &mut fmt::Formatter<'_>) -> fmt::Result {\n        // It's not possible to extract the inner Uniq directly from the Box,\n        // instead we cast it to a *const which aliases the Unique\n        let ptr: *const T = &**self;\n        fmt::Pointer::fmt(&ptr, f)\n    }\n}\n\n#[stable(feature = \"rust1\", since = \"1.0.0\")]\nimpl<T: ?Sized, A: Allocator> Deref for Box<T, A> {\n    type Target = T;\n\n    fn deref(&self) -> &T {\n        &**self\n    }\n}\n\n#[stable(feature = \"rust1\", since = \"1.0.0\")]\nimpl<T: ?Sized, A: Allocator> DerefMut for Box<T, A> {\n    fn deref_mut(&mut self) -> &mut T {\n        &mut **self\n    }\n}\n\n#[unstable(feature = \"receiver_trait\", issue = \"none\")]\nimpl<T: ?Sized, A: Allocator> Receiver for Box<T, A> {}\n\n#[stable(feature = \"rust1\", since = \"1.0.0\")]\nimpl<I: Iterator + ?Sized, A: Allocator> Iterator for Box<I, A> {\n    type Item = I::Item;\n    fn next(&mut self) -> Option<I::Item> {\n        (**self).next()\n    }\n    fn size_hint(&self) -> (usize, Option<usize>) {\n        (**self).size_hint()\n    }\n    fn nth(&mut self, n: usize) -> Option<I::Item> {\n        (**self).nth(n)\n    }\n    fn last(self) -> Option<I::Item> {\n        BoxIter::last(self)\n    }\n}\n\ntrait BoxIter {\n    type Item;\n    fn last(self) -> Option<Self::Item>;\n}\n\nimpl<I: Iterator + ?Sized, A: Allocator> BoxIter for Box<I, A> {\n    type Item = I::Item;\n    default fn last(self) -> Option<I::Item> {\n        #[inline]\n        fn some<T>(_: Option<T>, x: T) -> Option<T> {\n            Some(x)\n        }\n\n        self.fold(None, some)\n    }\n}\n\n/// Specialization for sized `I`s that uses `I`s implementation of `last()`\n/// instead of the default.\n#[stable(feature = \"rust1\", since = \"1.0.0\")]\nimpl<I: Iterator, A: Allocator> BoxIter for Box<I, A> {\n    fn last(self) -> Option<I::Item> {\n        (*self).last()\n    }\n}\n\n#[stable(feature = \"rust1\", since = \"1.0.0\")]\nimpl<I: DoubleEndedIterator + ?Sized, A: Allocator> DoubleEndedIterator for Box<I, A> {\n    fn next_back(&mut self) -> Option<I::Item> {\n        (**self).next_back()\n    }\n    fn nth_back(&mut self, n: usize) -> Option<I::Item> {\n        (**self).nth_back(n)\n    }\n}\n#[stable(feature = \"rust1\", since = \"1.0.0\")]\nimpl<I: ExactSizeIterator + ?Sized, A: Allocator> ExactSizeIterator for Box<I, A> {\n    fn len(&self) -> usize {\n        (**self).len()\n    }\n    fn is_empty(&self) -> bool {\n        (**self).is_empty()\n    }\n}\n\n#[stable(feature = \"fused\", since = \"1.26.0\")]\nimpl<I: FusedIterator + ?Sized, A: Allocator> FusedIterator for Box<I, A> {}\n\n#[stable(feature = \"boxed_closure_impls\", since = \"1.35.0\")]\nimpl<Args, F: FnOnce<Args> + ?Sized, A: Allocator> FnOnce<Args> for Box<F, A> {\n    type Output = <F as FnOnce<Args>>::Output;\n\n    extern \"rust-call\" fn call_once(self, args: Args) -> Self::Output {\n        <F as FnOnce<Args>>::call_once(*self, args)\n    }\n}\n\n#[stable(feature = \"boxed_closure_impls\", since = \"1.35.0\")]\nimpl<Args, F: FnMut<Args> + ?Sized, A: Allocator> FnMut<Args> for Box<F, A> {\n    extern \"rust-call\" fn call_mut(&mut self, args: Args) -> Self::Output {\n        <F as FnMut<Args>>::call_mut(self, args)\n    }\n}\n\n#[stable(feature = \"boxed_closure_impls\", since = \"1.35.0\")]\nimpl<Args, F: Fn<Args> + ?Sized, A: Allocator> Fn<Args> for Box<F, A> {\n    extern \"rust-call\" fn call(&self, args: Args) -> Self::Output {\n        <F as Fn<Args>>::call(self, args)\n    }\n}\n\n#[unstable(feature = \"coerce_unsized\", issue = \"27732\")]\nimpl<T: ?Sized + Unsize<U>, U: ?Sized, A: Allocator> CoerceUnsized<Box<U, A>> for Box<T, A> {}\n\n#[unstable(feature = \"dispatch_from_dyn\", issue = \"none\")]\nimpl<T: ?Sized + Unsize<U>, U: ?Sized> DispatchFromDyn<Box<U>> for Box<T, Global> {}\n\n#[cfg(not(no_global_oom_handling))]\n#[stable(feature = \"boxed_slice_from_iter\", since = \"1.32.0\")]\nimpl<I> FromIterator<I> for Box<[I]> {\n    fn from_iter<T: IntoIterator<Item = I>>(iter: T) -> Self {\n        iter.into_iter().collect::<Vec<_>>().into_boxed_slice()\n    }\n}\n\n#[cfg(not(no_global_oom_handling))]\n#[stable(feature = \"box_slice_clone\", since = \"1.3.0\")]\nimpl<T: Clone, A: Allocator + Clone> Clone for Box<[T], A> {\n    fn clone(&self) -> Self {\n        let alloc = Box::allocator(self).clone();\n        self.to_vec_in(alloc).into_boxed_slice()\n    }\n\n    fn clone_from(&mut self, other: &Self) {\n        if self.len() == other.len() {\n            self.clone_from_slice(&other);\n        } else {\n            *self = other.clone();\n        }\n    }\n}\n\n#[stable(feature = \"box_borrow\", since = \"1.1.0\")]\nimpl<T: ?Sized, A: Allocator> borrow::Borrow<T> for Box<T, A> {\n    fn borrow(&self) -> &T {\n        &**self\n    }\n}\n\n#[stable(feature = \"box_borrow\", since = \"1.1.0\")]\nimpl<T: ?Sized, A: Allocator> borrow::BorrowMut<T> for Box<T, A> {\n    fn borrow_mut(&mut self) -> &mut T {\n        &mut **self\n    }\n}\n\n#[stable(since = \"1.5.0\", feature = \"smart_ptr_as_ref\")]\nimpl<T: ?Sized, A: Allocator> AsRef<T> for Box<T, A> {\n    fn as_ref(&self) -> &T {\n        &**self\n    }\n}\n\n#[stable(since = \"1.5.0\", feature = \"smart_ptr_as_ref\")]\nimpl<T: ?Sized, A: Allocator> AsMut<T> for Box<T, A> {\n    fn as_mut(&mut self) -> &mut T {\n        &mut **self\n    }\n}\n\n/* Nota bene\n *\n *  We could have chosen not to add this impl, and instead have written a\n *  function of Pin<Box<T>> to Pin<T>. Such a function would not be sound,\n *  because Box<T> implements Unpin even when T does not, as a result of\n *  this impl.\n *\n *  We chose this API instead of the alternative for a few reasons:\n *      - Logically, it is helpful to understand pinning in regard to the\n *        memory region being pointed to. For this reason none of the\n *        standard library pointer types support projecting through a pin\n *        (Box<T> is the only pointer type in std for which this would be\n *        safe.)\n *      - It is in practice very useful to have Box<T> be unconditionally\n *        Unpin because of trait objects, for which the structural auto\n *        trait functionality does not apply (e.g., Box<dyn Foo> would\n *        otherwise not be Unpin).\n *\n *  Another type with the same semantics as Box but only a conditional\n *  implementation of `Unpin` (where `T: Unpin`) would be valid/safe, and\n *  could have a method to project a Pin<T> from it.\n */\n#[stable(feature = \"pin\", since = \"1.33.0\")]\nimpl<T: ?Sized, A: Allocator> Unpin for Box<T, A> where A: 'static {}\n\n#[unstable(feature = \"generator_trait\", issue = \"43122\")]\nimpl<G: ?Sized + Generator<R> + Unpin, R, A: Allocator> Generator<R> for Box<G, A>\nwhere\n    A: 'static,\n{\n    type Yield = G::Yield;\n    type Return = G::Return;\n\n    fn resume(mut self: Pin<&mut Self>, arg: R) -> GeneratorState<Self::Yield, Self::Return> {\n        G::resume(Pin::new(&mut *self), arg)\n    }\n}\n\n#[unstable(feature = \"generator_trait\", issue = \"43122\")]\nimpl<G: ?Sized + Generator<R>, R, A: Allocator> Generator<R> for Pin<Box<G, A>>\nwhere\n    A: 'static,\n{\n    type Yield = G::Yield;\n    type Return = G::Return;\n\n    fn resume(mut self: Pin<&mut Self>, arg: R) -> GeneratorState<Self::Yield, Self::Return> {\n        G::resume((*self).as_mut(), arg)\n    }\n}\n\n#[stable(feature = \"futures_api\", since = \"1.36.0\")]\nimpl<F: ?Sized + Future + Unpin, A: Allocator> Future for Box<F, A>\nwhere\n    A: 'static,\n{\n    type Output = F::Output;\n\n    fn poll(mut self: Pin<&mut Self>, cx: &mut Context<'_>) -> Poll<Self::Output> {\n        F::poll(Pin::new(&mut *self), cx)\n    }\n}\n\n#[unstable(feature = \"async_stream\", issue = \"79024\")]\nimpl<S: ?Sized + Stream + Unpin> Stream for Box<S> {\n    type Item = S::Item;\n\n    fn poll_next(mut self: Pin<&mut Self>, cx: &mut Context<'_>) -> Poll<Option<Self::Item>> {\n        Pin::new(&mut **self).poll_next(cx)\n    }\n\n    fn size_hint(&self) -> (usize, Option<usize>) {\n        (**self).size_hint()\n    }\n}\n"],[2010,"use super::*;\n\nextern crate test;\nuse crate::boxed::Box;\nuse test::Bencher;\n\n#[test]\nfn allocate_zeroed() {\n    unsafe {\n        let layout = Layout::from_size_align(1024, 1).unwrap();\n        let ptr =\n            Global.allocate_zeroed(layout.clone()).unwrap_or_else(|_| handle_alloc_error(layout));\n\n        let mut i = ptr.as_non_null_ptr().as_ptr();\n        let end = i.add(layout.size());\n        while i < end {\n            assert_eq!(*i, 0);\n            i = i.offset(1);\n        }\n        Global.deallocate(ptr.as_non_null_ptr(), layout);\n    }\n}\n\n#[bench]\n#[cfg_attr(miri, ignore)] // isolated Miri does not support benchmarks\nfn alloc_owned_small(b: &mut Bencher) {\n    b.iter(|| {\n        let _: Box<_> = box 10;\n    })\n}\n"],[2011,"//! Single-threaded reference-counting pointers. 'Rc' stands for 'Reference\n//! Counted'.\n//!\n//! The type [`Rc<T>`][`Rc`] provides shared ownership of a value of type `T`,\n//! allocated in the heap. Invoking [`clone`][clone] on [`Rc`] produces a new\n//! pointer to the same allocation in the heap. When the last [`Rc`] pointer to a\n//! given allocation is destroyed, the value stored in that allocation (often\n//! referred to as \"inner value\") is also dropped.\n//!\n//! Shared references in Rust disallow mutation by default, and [`Rc`]\n//! is no exception: you cannot generally obtain a mutable reference to\n//! something inside an [`Rc`]. If you need mutability, put a [`Cell`]\n//! or [`RefCell`] inside the [`Rc`]; see [an example of mutability\n//! inside an `Rc`][mutability].\n//!\n//! [`Rc`] uses non-atomic reference counting. This means that overhead is very\n//! low, but an [`Rc`] cannot be sent between threads, and consequently [`Rc`]\n//! does not implement [`Send`][send]. As a result, the Rust compiler\n//! will check *at compile time* that you are not sending [`Rc`]s between\n//! threads. If you need multi-threaded, atomic reference counting, use\n//! [`sync::Arc`][arc].\n//!\n//! The [`downgrade`][downgrade] method can be used to create a non-owning\n//! [`Weak`] pointer. A [`Weak`] pointer can be [`upgrade`][upgrade]d\n//! to an [`Rc`], but this will return [`None`] if the value stored in the allocation has\n//! already been dropped. In other words, `Weak` pointers do not keep the value\n//! inside the allocation alive; however, they *do* keep the allocation\n//! (the backing store for the inner value) alive.\n//!\n//! A cycle between [`Rc`] pointers will never be deallocated. For this reason,\n//! [`Weak`] is used to break cycles. For example, a tree could have strong\n//! [`Rc`] pointers from parent nodes to children, and [`Weak`] pointers from\n//! children back to their parents.\n//!\n//! `Rc<T>` automatically dereferences to `T` (via the [`Deref`] trait),\n//! so you can call `T`'s methods on a value of type [`Rc<T>`][`Rc`]. To avoid name\n//! clashes with `T`'s methods, the methods of [`Rc<T>`][`Rc`] itself are associated\n//! functions, called using [fully qualified syntax]:\n//!\n//! ```\n//! use std::rc::Rc;\n//!\n//! let my_rc = Rc::new(());\n//! Rc::downgrade(&my_rc);\n//! ```\n//!\n//! `Rc<T>`'s implementations of traits like `Clone` may also be called using\n//! fully qualified syntax. Some people prefer to use fully qualified syntax,\n//! while others prefer using method-call syntax.\n//!\n//! ```\n//! use std::rc::Rc;\n//!\n//! let rc = Rc::new(());\n//! // Method-call syntax\n//! let rc2 = rc.clone();\n//! // Fully qualified syntax\n//! let rc3 = Rc::clone(&rc);\n//! ```\n//!\n//! [`Weak<T>`][`Weak`] does not auto-dereference to `T`, because the inner value may have\n//! already been dropped.\n//!\n//! # Cloning references\n//!\n//! Creating a new reference to the same allocation as an existing reference counted pointer\n//! is done using the `Clone` trait implemented for [`Rc<T>`][`Rc`] and [`Weak<T>`][`Weak`].\n//!\n//! ```\n//! use std::rc::Rc;\n//!\n//! let foo = Rc::new(vec![1.0, 2.0, 3.0]);\n//! // The two syntaxes below are equivalent.\n//! let a = foo.clone();\n//! let b = Rc::clone(&foo);\n//! // a and b both point to the same memory location as foo.\n//! ```\n//!\n//! The `Rc::clone(&from)` syntax is the most idiomatic because it conveys more explicitly\n//! the meaning of the code. In the example above, this syntax makes it easier to see that\n//! this code is creating a new reference rather than copying the whole content of foo.\n//!\n//! # Examples\n//!\n//! Consider a scenario where a set of `Gadget`s are owned by a given `Owner`.\n//! We want to have our `Gadget`s point to their `Owner`. We can't do this with\n//! unique ownership, because more than one gadget may belong to the same\n//! `Owner`. [`Rc`] allows us to share an `Owner` between multiple `Gadget`s,\n//! and have the `Owner` remain allocated as long as any `Gadget` points at it.\n//!\n//! ```\n//! use std::rc::Rc;\n//!\n//! struct Owner {\n//!     name: String,\n//!     // ...other fields\n//! }\n//!\n//! struct Gadget {\n//!     id: i32,\n//!     owner: Rc<Owner>,\n//!     // ...other fields\n//! }\n//!\n//! fn main() {\n//!     // Create a reference-counted `Owner`.\n//!     let gadget_owner: Rc<Owner> = Rc::new(\n//!         Owner {\n//!             name: \"Gadget Man\".to_string(),\n//!         }\n//!     );\n//!\n//!     // Create `Gadget`s belonging to `gadget_owner`. Cloning the `Rc<Owner>`\n//!     // gives us a new pointer to the same `Owner` allocation, incrementing\n//!     // the reference count in the process.\n//!     let gadget1 = Gadget {\n//!         id: 1,\n//!         owner: Rc::clone(&gadget_owner),\n//!     };\n//!     let gadget2 = Gadget {\n//!         id: 2,\n//!         owner: Rc::clone(&gadget_owner),\n//!     };\n//!\n//!     // Dispose of our local variable `gadget_owner`.\n//!     drop(gadget_owner);\n//!\n//!     // Despite dropping `gadget_owner`, we're still able to print out the name\n//!     // of the `Owner` of the `Gadget`s. This is because we've only dropped a\n//!     // single `Rc<Owner>`, not the `Owner` it points to. As long as there are\n//!     // other `Rc<Owner>` pointing at the same `Owner` allocation, it will remain\n//!     // live. The field projection `gadget1.owner.name` works because\n//!     // `Rc<Owner>` automatically dereferences to `Owner`.\n//!     println!(\"Gadget {} owned by {}\", gadget1.id, gadget1.owner.name);\n//!     println!(\"Gadget {} owned by {}\", gadget2.id, gadget2.owner.name);\n//!\n//!     // At the end of the function, `gadget1` and `gadget2` are destroyed, and\n//!     // with them the last counted references to our `Owner`. Gadget Man now\n//!     // gets destroyed as well.\n//! }\n//! ```\n//!\n//! If our requirements change, and we also need to be able to traverse from\n//! `Owner` to `Gadget`, we will run into problems. An [`Rc`] pointer from `Owner`\n//! to `Gadget` introduces a cycle. This means that their\n//! reference counts can never reach 0, and the allocation will never be destroyed:\n//! a memory leak. In order to get around this, we can use [`Weak`]\n//! pointers.\n//!\n//! Rust actually makes it somewhat difficult to produce this loop in the first\n//! place. In order to end up with two values that point at each other, one of\n//! them needs to be mutable. This is difficult because [`Rc`] enforces\n//! memory safety by only giving out shared references to the value it wraps,\n//! and these don't allow direct mutation. We need to wrap the part of the\n//! value we wish to mutate in a [`RefCell`], which provides *interior\n//! mutability*: a method to achieve mutability through a shared reference.\n//! [`RefCell`] enforces Rust's borrowing rules at runtime.\n//!\n//! ```\n//! use std::rc::Rc;\n//! use std::rc::Weak;\n//! use std::cell::RefCell;\n//!\n//! struct Owner {\n//!     name: String,\n//!     gadgets: RefCell<Vec<Weak<Gadget>>>,\n//!     // ...other fields\n//! }\n//!\n//! struct Gadget {\n//!     id: i32,\n//!     owner: Rc<Owner>,\n//!     // ...other fields\n//! }\n//!\n//! fn main() {\n//!     // Create a reference-counted `Owner`. Note that we've put the `Owner`'s\n//!     // vector of `Gadget`s inside a `RefCell` so that we can mutate it through\n//!     // a shared reference.\n//!     let gadget_owner: Rc<Owner> = Rc::new(\n//!         Owner {\n//!             name: \"Gadget Man\".to_string(),\n//!             gadgets: RefCell::new(vec![]),\n//!         }\n//!     );\n//!\n//!     // Create `Gadget`s belonging to `gadget_owner`, as before.\n//!     let gadget1 = Rc::new(\n//!         Gadget {\n//!             id: 1,\n//!             owner: Rc::clone(&gadget_owner),\n//!         }\n//!     );\n//!     let gadget2 = Rc::new(\n//!         Gadget {\n//!             id: 2,\n//!             owner: Rc::clone(&gadget_owner),\n//!         }\n//!     );\n//!\n//!     // Add the `Gadget`s to their `Owner`.\n//!     {\n//!         let mut gadgets = gadget_owner.gadgets.borrow_mut();\n//!         gadgets.push(Rc::downgrade(&gadget1));\n//!         gadgets.push(Rc::downgrade(&gadget2));\n//!\n//!         // `RefCell` dynamic borrow ends here.\n//!     }\n//!\n//!     // Iterate over our `Gadget`s, printing their details out.\n//!     for gadget_weak in gadget_owner.gadgets.borrow().iter() {\n//!\n//!         // `gadget_weak` is a `Weak<Gadget>`. Since `Weak` pointers can't\n//!         // guarantee the allocation still exists, we need to call\n//!         // `upgrade`, which returns an `Option<Rc<Gadget>>`.\n//!         //\n//!         // In this case we know the allocation still exists, so we simply\n//!         // `unwrap` the `Option`. In a more complicated program, you might\n//!         // need graceful error handling for a `None` result.\n//!\n//!         let gadget = gadget_weak.upgrade().unwrap();\n//!         println!(\"Gadget {} owned by {}\", gadget.id, gadget.owner.name);\n//!     }\n//!\n//!     // At the end of the function, `gadget_owner`, `gadget1`, and `gadget2`\n//!     // are destroyed. There are now no strong (`Rc`) pointers to the\n//!     // gadgets, so they are destroyed. This zeroes the reference count on\n//!     // Gadget Man, so he gets destroyed as well.\n//! }\n//! ```\n//!\n//! [clone]: Clone::clone\n//! [`Cell`]: core::cell::Cell\n//! [`RefCell`]: core::cell::RefCell\n//! [send]: core::marker::Send\n//! [arc]: crate::sync::Arc\n//! [`Deref`]: core::ops::Deref\n//! [downgrade]: Rc::downgrade\n//! [upgrade]: Weak::upgrade\n//! [mutability]: core::cell#introducing-mutability-inside-of-something-immutable\n//! [fully qualified syntax]: https://doc.rust-lang.org/book/ch19-03-advanced-traits.html#fully-qualified-syntax-for-disambiguation-calling-methods-with-the-same-name\n\n#![stable(feature = \"rust1\", since = \"1.0.0\")]\n\n#[cfg(not(test))]\nuse crate::boxed::Box;\n#[cfg(test)]\nuse std::boxed::Box;\n\nuse core::any::Any;\nuse core::borrow;\nuse core::cell::Cell;\nuse core::cmp::Ordering;\nuse core::convert::{From, TryFrom};\nuse core::fmt;\nuse core::hash::{Hash, Hasher};\nuse core::intrinsics::abort;\n#[cfg(not(no_global_oom_handling))]\nuse core::iter;\nuse core::marker::{self, PhantomData, Unpin, Unsize};\n#[cfg(not(no_global_oom_handling))]\nuse core::mem::size_of_val;\nuse core::mem::{self, align_of_val_raw, forget};\nuse core::ops::{CoerceUnsized, Deref, DispatchFromDyn, Receiver};\nuse core::pin::Pin;\nuse core::ptr::{self, NonNull};\n#[cfg(not(no_global_oom_handling))]\nuse core::slice::from_raw_parts_mut;\n\n#[cfg(not(no_global_oom_handling))]\nuse crate::alloc::handle_alloc_error;\n#[cfg(not(no_global_oom_handling))]\nuse crate::alloc::{box_free, WriteCloneIntoRaw};\nuse crate::alloc::{AllocError, Allocator, Global, Layout};\nuse crate::borrow::{Cow, ToOwned};\n#[cfg(not(no_global_oom_handling))]\nuse crate::string::String;\n#[cfg(not(no_global_oom_handling))]\nuse crate::vec::Vec;\n\n#[cfg(test)]\nmod tests;\n\n// This is repr(C) to future-proof against possible field-reordering, which\n// would interfere with otherwise safe [into|from]_raw() of transmutable\n// inner types.\n#[repr(C)]\nstruct RcBox<T: ?Sized> {\n    strong: Cell<usize>,\n    weak: Cell<usize>,\n    value: T,\n}\n\n/// A single-threaded reference-counting pointer. 'Rc' stands for 'Reference\n/// Counted'.\n///\n/// See the [module-level documentation](./index.html) for more details.\n///\n/// The inherent methods of `Rc` are all associated functions, which means\n/// that you have to call them as e.g., [`Rc::get_mut(&mut value)`][get_mut] instead of\n/// `value.get_mut()`. This avoids conflicts with methods of the inner type `T`.\n///\n/// [get_mut]: Rc::get_mut\n#[cfg_attr(not(test), rustc_diagnostic_item = \"Rc\")]\n#[stable(feature = \"rust1\", since = \"1.0.0\")]\npub struct Rc<T: ?Sized> {\n    ptr: NonNull<RcBox<T>>,\n    phantom: PhantomData<RcBox<T>>,\n}\n\n#[stable(feature = \"rust1\", since = \"1.0.0\")]\nimpl<T: ?Sized> !marker::Send for Rc<T> {}\n#[stable(feature = \"rust1\", since = \"1.0.0\")]\nimpl<T: ?Sized> !marker::Sync for Rc<T> {}\n\n#[unstable(feature = \"coerce_unsized\", issue = \"27732\")]\nimpl<T: ?Sized + Unsize<U>, U: ?Sized> CoerceUnsized<Rc<U>> for Rc<T> {}\n\n#[unstable(feature = \"dispatch_from_dyn\", issue = \"none\")]\nimpl<T: ?Sized + Unsize<U>, U: ?Sized> DispatchFromDyn<Rc<U>> for Rc<T> {}\n\nimpl<T: ?Sized> Rc<T> {\n    #[inline(always)]\n    fn inner(&self) -> &RcBox<T> {\n        // This unsafety is ok because while this Rc is alive we're guaranteed\n        // that the inner pointer is valid.\n        unsafe { self.ptr.as_ref() }\n    }\n\n    fn from_inner(ptr: NonNull<RcBox<T>>) -> Self {\n        Self { ptr, phantom: PhantomData }\n    }\n\n    unsafe fn from_ptr(ptr: *mut RcBox<T>) -> Self {\n        Self::from_inner(unsafe { NonNull::new_unchecked(ptr) })\n    }\n}\n\nimpl<T> Rc<T> {\n    /// Constructs a new `Rc<T>`.\n    ///\n    /// # Examples\n    ///\n    /// ```\n    /// use std::rc::Rc;\n    ///\n    /// let five = Rc::new(5);\n    /// ```\n    #[stable(feature = \"rust1\", since = \"1.0.0\")]\n    pub fn new(value: T) -> Rc<T> {\n        // There is an implicit weak pointer owned by all the strong\n        // pointers, which ensures that the weak destructor never frees\n        // the allocation while the strong destructor is running, even\n        // if the weak pointer is stored inside the strong one.\n        Self::from_inner(\n            Box::leak(box RcBox { strong: Cell::new(1), weak: Cell::new(1), value }).into(),\n        )\n    }\n\n    /// Constructs a new `Rc<T>` using a weak reference to itself. Attempting\n    /// to upgrade the weak reference before this function returns will result\n    /// in a `None` value. However, the weak reference may be cloned freely and\n    /// stored for use at a later time.\n    ///\n    /// # Examples\n    ///\n    /// ```\n    /// #![feature(arc_new_cyclic)]\n    /// #![allow(dead_code)]\n    /// use std::rc::{Rc, Weak};\n    ///\n    /// struct Gadget {\n    ///     self_weak: Weak<Self>,\n    ///     // ... more fields\n    /// }\n    /// impl Gadget {\n    ///     pub fn new() -> Rc<Self> {\n    ///         Rc::new_cyclic(|self_weak| {\n    ///             Gadget { self_weak: self_weak.clone(), /* ... */ }\n    ///         })\n    ///     }\n    /// }\n    /// ```\n    #[unstable(feature = \"arc_new_cyclic\", issue = \"75861\")]\n    pub fn new_cyclic(data_fn: impl FnOnce(&Weak<T>) -> T) -> Rc<T> {\n        // Construct the inner in the \"uninitialized\" state with a single\n        // weak reference.\n        let uninit_ptr: NonNull<_> = Box::leak(box RcBox {\n            strong: Cell::new(0),\n            weak: Cell::new(1),\n            value: mem::MaybeUninit::<T>::uninit(),\n        })\n        .into();\n\n        let init_ptr: NonNull<RcBox<T>> = uninit_ptr.cast();\n\n        let weak = Weak { ptr: init_ptr };\n\n        // It's important we don't give up ownership of the weak pointer, or\n        // else the memory might be freed by the time `data_fn` returns. If\n        // we really wanted to pass ownership, we could create an additional\n        // weak pointer for ourselves, but this would result in additional\n        // updates to the weak reference count which might not be necessary\n        // otherwise.\n        let data = data_fn(&weak);\n\n        unsafe {\n            let inner = init_ptr.as_ptr();\n            ptr::write(ptr::addr_of_mut!((*inner).value), data);\n\n            let prev_value = (*inner).strong.get();\n            debug_assert_eq!(prev_value, 0, \"No prior strong references should exist\");\n            (*inner).strong.set(1);\n        }\n\n        let strong = Rc::from_inner(init_ptr);\n\n        // Strong references should collectively own a shared weak reference,\n        // so don't run the destructor for our old weak reference.\n        mem::forget(weak);\n        strong\n    }\n\n    /// Constructs a new `Rc` with uninitialized contents.\n    ///\n    /// # Examples\n    ///\n    /// ```\n    /// #![feature(new_uninit)]\n    /// #![feature(get_mut_unchecked)]\n    ///\n    /// use std::rc::Rc;\n    ///\n    /// let mut five = Rc::<u32>::new_uninit();\n    ///\n    /// let five = unsafe {\n    ///     // Deferred initialization:\n    ///     Rc::get_mut_unchecked(&mut five).as_mut_ptr().write(5);\n    ///\n    ///     five.assume_init()\n    /// };\n    ///\n    /// assert_eq!(*five, 5)\n    /// ```\n    #[cfg(not(no_global_oom_handling))]\n    #[unstable(feature = \"new_uninit\", issue = \"63291\")]\n    pub fn new_uninit() -> Rc<mem::MaybeUninit<T>> {\n        unsafe {\n            Rc::from_ptr(Rc::allocate_for_layout(\n                Layout::new::<T>(),\n                |layout| Global.allocate(layout),\n                |mem| mem as *mut RcBox<mem::MaybeUninit<T>>,\n            ))\n        }\n    }\n\n    /// Constructs a new `Rc` with uninitialized contents, with the memory\n    /// being filled with `0` bytes.\n    ///\n    /// See [`MaybeUninit::zeroed`][zeroed] for examples of correct and\n    /// incorrect usage of this method.\n    ///\n    /// # Examples\n    ///\n    /// ```\n    /// #![feature(new_uninit)]\n    ///\n    /// use std::rc::Rc;\n    ///\n    /// let zero = Rc::<u32>::new_zeroed();\n    /// let zero = unsafe { zero.assume_init() };\n    ///\n    /// assert_eq!(*zero, 0)\n    /// ```\n    ///\n    /// [zeroed]: mem::MaybeUninit::zeroed\n    #[cfg(not(no_global_oom_handling))]\n    #[unstable(feature = \"new_uninit\", issue = \"63291\")]\n    pub fn new_zeroed() -> Rc<mem::MaybeUninit<T>> {\n        unsafe {\n            Rc::from_ptr(Rc::allocate_for_layout(\n                Layout::new::<T>(),\n                |layout| Global.allocate_zeroed(layout),\n                |mem| mem as *mut RcBox<mem::MaybeUninit<T>>,\n            ))\n        }\n    }\n\n    /// Constructs a new `Rc<T>`, returning an error if the allocation fails\n    ///\n    /// # Examples\n    ///\n    /// ```\n    /// #![feature(allocator_api)]\n    /// use std::rc::Rc;\n    ///\n    /// let five = Rc::try_new(5);\n    /// # Ok::<(), std::alloc::AllocError>(())\n    /// ```\n    #[unstable(feature = \"allocator_api\", issue = \"32838\")]\n    pub fn try_new(value: T) -> Result<Rc<T>, AllocError> {\n        // There is an implicit weak pointer owned by all the strong\n        // pointers, which ensures that the weak destructor never frees\n        // the allocation while the strong destructor is running, even\n        // if the weak pointer is stored inside the strong one.\n        Ok(Self::from_inner(\n            Box::leak(Box::try_new(RcBox { strong: Cell::new(1), weak: Cell::new(1), value })?)\n                .into(),\n        ))\n    }\n\n    /// Constructs a new `Rc` with uninitialized contents, returning an error if the allocation fails\n    ///\n    /// # Examples\n    ///\n    /// ```\n    /// #![feature(allocator_api, new_uninit)]\n    /// #![feature(get_mut_unchecked)]\n    ///\n    /// use std::rc::Rc;\n    ///\n    /// let mut five = Rc::<u32>::try_new_uninit()?;\n    ///\n    /// let five = unsafe {\n    ///     // Deferred initialization:\n    ///     Rc::get_mut_unchecked(&mut five).as_mut_ptr().write(5);\n    ///\n    ///     five.assume_init()\n    /// };\n    ///\n    /// assert_eq!(*five, 5);\n    /// # Ok::<(), std::alloc::AllocError>(())\n    /// ```\n    #[unstable(feature = \"allocator_api\", issue = \"32838\")]\n    // #[unstable(feature = \"new_uninit\", issue = \"63291\")]\n    pub fn try_new_uninit() -> Result<Rc<mem::MaybeUninit<T>>, AllocError> {\n        unsafe {\n            Ok(Rc::from_ptr(Rc::try_allocate_for_layout(\n                Layout::new::<T>(),\n                |layout| Global.allocate(layout),\n                |mem| mem as *mut RcBox<mem::MaybeUninit<T>>,\n            )?))\n        }\n    }\n\n    /// Constructs a new `Rc` with uninitialized contents, with the memory\n    /// being filled with `0` bytes, returning an error if the allocation fails\n    ///\n    /// See [`MaybeUninit::zeroed`][zeroed] for examples of correct and\n    /// incorrect usage of this method.\n    ///\n    /// # Examples\n    ///\n    /// ```\n    /// #![feature(allocator_api, new_uninit)]\n    ///\n    /// use std::rc::Rc;\n    ///\n    /// let zero = Rc::<u32>::try_new_zeroed()?;\n    /// let zero = unsafe { zero.assume_init() };\n    ///\n    /// assert_eq!(*zero, 0);\n    /// # Ok::<(), std::alloc::AllocError>(())\n    /// ```\n    ///\n    /// [zeroed]: mem::MaybeUninit::zeroed\n    #[unstable(feature = \"allocator_api\", issue = \"32838\")]\n    //#[unstable(feature = \"new_uninit\", issue = \"63291\")]\n    pub fn try_new_zeroed() -> Result<Rc<mem::MaybeUninit<T>>, AllocError> {\n        unsafe {\n            Ok(Rc::from_ptr(Rc::try_allocate_for_layout(\n                Layout::new::<T>(),\n                |layout| Global.allocate_zeroed(layout),\n                |mem| mem as *mut RcBox<mem::MaybeUninit<T>>,\n            )?))\n        }\n    }\n    /// Constructs a new `Pin<Rc<T>>`. If `T` does not implement `Unpin`, then\n    /// `value` will be pinned in memory and unable to be moved.\n    #[stable(feature = \"pin\", since = \"1.33.0\")]\n    pub fn pin(value: T) -> Pin<Rc<T>> {\n        unsafe { Pin::new_unchecked(Rc::new(value)) }\n    }\n\n    /// Returns the inner value, if the `Rc` has exactly one strong reference.\n    ///\n    /// Otherwise, an [`Err`] is returned with the same `Rc` that was\n    /// passed in.\n    ///\n    /// This will succeed even if there are outstanding weak references.\n    ///\n    /// # Examples\n    ///\n    /// ```\n    /// use std::rc::Rc;\n    ///\n    /// let x = Rc::new(3);\n    /// assert_eq!(Rc::try_unwrap(x), Ok(3));\n    ///\n    /// let x = Rc::new(4);\n    /// let _y = Rc::clone(&x);\n    /// assert_eq!(*Rc::try_unwrap(x).unwrap_err(), 4);\n    /// ```\n    #[inline]\n    #[stable(feature = \"rc_unique\", since = \"1.4.0\")]\n    pub fn try_unwrap(this: Self) -> Result<T, Self> {\n        if Rc::strong_count(&this) == 1 {\n            unsafe {\n                let val = ptr::read(&*this); // copy the contained object\n\n                // Indicate to Weaks that they can't be promoted by decrementing\n                // the strong count, and then remove the implicit \"strong weak\"\n                // pointer while also handling drop logic by just crafting a\n                // fake Weak.\n                this.inner().dec_strong();\n                let _weak = Weak { ptr: this.ptr };\n                forget(this);\n                Ok(val)\n            }\n        } else {\n            Err(this)\n        }\n    }\n}\n\nimpl<T> Rc<[T]> {\n    /// Constructs a new reference-counted slice with uninitialized contents.\n    ///\n    /// # Examples\n    ///\n    /// ```\n    /// #![feature(new_uninit)]\n    /// #![feature(get_mut_unchecked)]\n    ///\n    /// use std::rc::Rc;\n    ///\n    /// let mut values = Rc::<[u32]>::new_uninit_slice(3);\n    ///\n    /// let values = unsafe {\n    ///     // Deferred initialization:\n    ///     Rc::get_mut_unchecked(&mut values)[0].as_mut_ptr().write(1);\n    ///     Rc::get_mut_unchecked(&mut values)[1].as_mut_ptr().write(2);\n    ///     Rc::get_mut_unchecked(&mut values)[2].as_mut_ptr().write(3);\n    ///\n    ///     values.assume_init()\n    /// };\n    ///\n    /// assert_eq!(*values, [1, 2, 3])\n    /// ```\n    #[cfg(not(no_global_oom_handling))]\n    #[unstable(feature = \"new_uninit\", issue = \"63291\")]\n    pub fn new_uninit_slice(len: usize) -> Rc<[mem::MaybeUninit<T>]> {\n        unsafe { Rc::from_ptr(Rc::allocate_for_slice(len)) }\n    }\n\n    /// Constructs a new reference-counted slice with uninitialized contents, with the memory being\n    /// filled with `0` bytes.\n    ///\n    /// See [`MaybeUninit::zeroed`][zeroed] for examples of correct and\n    /// incorrect usage of this method.\n    ///\n    /// # Examples\n    ///\n    /// ```\n    /// #![feature(new_uninit)]\n    ///\n    /// use std::rc::Rc;\n    ///\n    /// let values = Rc::<[u32]>::new_zeroed_slice(3);\n    /// let values = unsafe { values.assume_init() };\n    ///\n    /// assert_eq!(*values, [0, 0, 0])\n    /// ```\n    ///\n    /// [zeroed]: mem::MaybeUninit::zeroed\n    #[cfg(not(no_global_oom_handling))]\n    #[unstable(feature = \"new_uninit\", issue = \"63291\")]\n    pub fn new_zeroed_slice(len: usize) -> Rc<[mem::MaybeUninit<T>]> {\n        unsafe {\n            Rc::from_ptr(Rc::allocate_for_layout(\n                Layout::array::<T>(len).unwrap(),\n                |layout| Global.allocate_zeroed(layout),\n                |mem| {\n                    ptr::slice_from_raw_parts_mut(mem as *mut T, len)\n                        as *mut RcBox<[mem::MaybeUninit<T>]>\n                },\n            ))\n        }\n    }\n}\n\nimpl<T> Rc<mem::MaybeUninit<T>> {\n    /// Converts to `Rc<T>`.\n    ///\n    /// # Safety\n    ///\n    /// As with [`MaybeUninit::assume_init`],\n    /// it is up to the caller to guarantee that the inner value\n    /// really is in an initialized state.\n    /// Calling this when the content is not yet fully initialized\n    /// causes immediate undefined behavior.\n    ///\n    /// [`MaybeUninit::assume_init`]: mem::MaybeUninit::assume_init\n    ///\n    /// # Examples\n    ///\n    /// ```\n    /// #![feature(new_uninit)]\n    /// #![feature(get_mut_unchecked)]\n    ///\n    /// use std::rc::Rc;\n    ///\n    /// let mut five = Rc::<u32>::new_uninit();\n    ///\n    /// let five = unsafe {\n    ///     // Deferred initialization:\n    ///     Rc::get_mut_unchecked(&mut five).as_mut_ptr().write(5);\n    ///\n    ///     five.assume_init()\n    /// };\n    ///\n    /// assert_eq!(*five, 5)\n    /// ```\n    #[unstable(feature = \"new_uninit\", issue = \"63291\")]\n    #[inline]\n    pub unsafe fn assume_init(self) -> Rc<T> {\n        Rc::from_inner(mem::ManuallyDrop::new(self).ptr.cast())\n    }\n}\n\nimpl<T> Rc<[mem::MaybeUninit<T>]> {\n    /// Converts to `Rc<[T]>`.\n    ///\n    /// # Safety\n    ///\n    /// As with [`MaybeUninit::assume_init`],\n    /// it is up to the caller to guarantee that the inner value\n    /// really is in an initialized state.\n    /// Calling this when the content is not yet fully initialized\n    /// causes immediate undefined behavior.\n    ///\n    /// [`MaybeUninit::assume_init`]: mem::MaybeUninit::assume_init\n    ///\n    /// # Examples\n    ///\n    /// ```\n    /// #![feature(new_uninit)]\n    /// #![feature(get_mut_unchecked)]\n    ///\n    /// use std::rc::Rc;\n    ///\n    /// let mut values = Rc::<[u32]>::new_uninit_slice(3);\n    ///\n    /// let values = unsafe {\n    ///     // Deferred initialization:\n    ///     Rc::get_mut_unchecked(&mut values)[0].as_mut_ptr().write(1);\n    ///     Rc::get_mut_unchecked(&mut values)[1].as_mut_ptr().write(2);\n    ///     Rc::get_mut_unchecked(&mut values)[2].as_mut_ptr().write(3);\n    ///\n    ///     values.assume_init()\n    /// };\n    ///\n    /// assert_eq!(*values, [1, 2, 3])\n    /// ```\n    #[unstable(feature = \"new_uninit\", issue = \"63291\")]\n    #[inline]\n    pub unsafe fn assume_init(self) -> Rc<[T]> {\n        unsafe { Rc::from_ptr(mem::ManuallyDrop::new(self).ptr.as_ptr() as _) }\n    }\n}\n\nimpl<T: ?Sized> Rc<T> {\n    /// Consumes the `Rc`, returning the wrapped pointer.\n    ///\n    /// To avoid a memory leak the pointer must be converted back to an `Rc` using\n    /// [`Rc::from_raw`][from_raw].\n    ///\n    /// [from_raw]: Rc::from_raw\n    ///\n    /// # Examples\n    ///\n    /// ```\n    /// use std::rc::Rc;\n    ///\n    /// let x = Rc::new(\"hello\".to_owned());\n    /// let x_ptr = Rc::into_raw(x);\n    /// assert_eq!(unsafe { &*x_ptr }, \"hello\");\n    /// ```\n    #[stable(feature = \"rc_raw\", since = \"1.17.0\")]\n    pub fn into_raw(this: Self) -> *const T {\n        let ptr = Self::as_ptr(&this);\n        mem::forget(this);\n        ptr\n    }\n\n    /// Provides a raw pointer to the data.\n    ///\n    /// The counts are not affected in any way and the `Rc` is not consumed. The pointer is valid\n    /// for as long there are strong counts in the `Rc`.\n    ///\n    /// # Examples\n    ///\n    /// ```\n    /// use std::rc::Rc;\n    ///\n    /// let x = Rc::new(\"hello\".to_owned());\n    /// let y = Rc::clone(&x);\n    /// let x_ptr = Rc::as_ptr(&x);\n    /// assert_eq!(x_ptr, Rc::as_ptr(&y));\n    /// assert_eq!(unsafe { &*x_ptr }, \"hello\");\n    /// ```\n    #[stable(feature = \"weak_into_raw\", since = \"1.45.0\")]\n    pub fn as_ptr(this: &Self) -> *const T {\n        let ptr: *mut RcBox<T> = NonNull::as_ptr(this.ptr);\n\n        // SAFETY: This cannot go through Deref::deref or Rc::inner because\n        // this is required to retain raw/mut provenance such that e.g. `get_mut` can\n        // write through the pointer after the Rc is recovered through `from_raw`.\n        unsafe { ptr::addr_of_mut!((*ptr).value) }\n    }\n\n    /// Constructs an `Rc<T>` from a raw pointer.\n    ///\n    /// The raw pointer must have been previously returned by a call to\n    /// [`Rc<U>::into_raw`][into_raw] where `U` must have the same size\n    /// and alignment as `T`. This is trivially true if `U` is `T`.\n    /// Note that if `U` is not `T` but has the same size and alignment, this is\n    /// basically like transmuting references of different types. See\n    /// [`mem::transmute`][transmute] for more information on what\n    /// restrictions apply in this case.\n    ///\n    /// The user of `from_raw` has to make sure a specific value of `T` is only\n    /// dropped once.\n    ///\n    /// This function is unsafe because improper use may lead to memory unsafety,\n    /// even if the returned `Rc<T>` is never accessed.\n    ///\n    /// [into_raw]: Rc::into_raw\n    /// [transmute]: core::mem::transmute\n    ///\n    /// # Examples\n    ///\n    /// ```\n    /// use std::rc::Rc;\n    ///\n    /// let x = Rc::new(\"hello\".to_owned());\n    /// let x_ptr = Rc::into_raw(x);\n    ///\n    /// unsafe {\n    ///     // Convert back to an `Rc` to prevent leak.\n    ///     let x = Rc::from_raw(x_ptr);\n    ///     assert_eq!(&*x, \"hello\");\n    ///\n    ///     // Further calls to `Rc::from_raw(x_ptr)` would be memory-unsafe.\n    /// }\n    ///\n    /// // The memory was freed when `x` went out of scope above, so `x_ptr` is now dangling!\n    /// ```\n    #[stable(feature = \"rc_raw\", since = \"1.17.0\")]\n    pub unsafe fn from_raw(ptr: *const T) -> Self {\n        let offset = unsafe { data_offset(ptr) };\n\n        // Reverse the offset to find the original RcBox.\n        let rc_ptr =\n            unsafe { (ptr as *mut RcBox<T>).set_ptr_value((ptr as *mut u8).offset(-offset)) };\n\n        unsafe { Self::from_ptr(rc_ptr) }\n    }\n\n    /// Creates a new [`Weak`] pointer to this allocation.\n    ///\n    /// # Examples\n    ///\n    /// ```\n    /// use std::rc::Rc;\n    ///\n    /// let five = Rc::new(5);\n    ///\n    /// let weak_five = Rc::downgrade(&five);\n    /// ```\n    #[stable(feature = \"rc_weak\", since = \"1.4.0\")]\n    pub fn downgrade(this: &Self) -> Weak<T> {\n        this.inner().inc_weak();\n        // Make sure we do not create a dangling Weak\n        debug_assert!(!is_dangling(this.ptr.as_ptr()));\n        Weak { ptr: this.ptr }\n    }\n\n    /// Gets the number of [`Weak`] pointers to this allocation.\n    ///\n    /// # Examples\n    ///\n    /// ```\n    /// use std::rc::Rc;\n    ///\n    /// let five = Rc::new(5);\n    /// let _weak_five = Rc::downgrade(&five);\n    ///\n    /// assert_eq!(1, Rc::weak_count(&five));\n    /// ```\n    #[inline]\n    #[stable(feature = \"rc_counts\", since = \"1.15.0\")]\n    pub fn weak_count(this: &Self) -> usize {\n        this.inner().weak() - 1\n    }\n\n    /// Gets the number of strong (`Rc`) pointers to this allocation.\n    ///\n    /// # Examples\n    ///\n    /// ```\n    /// use std::rc::Rc;\n    ///\n    /// let five = Rc::new(5);\n    /// let _also_five = Rc::clone(&five);\n    ///\n    /// assert_eq!(2, Rc::strong_count(&five));\n    /// ```\n    #[inline]\n    #[stable(feature = \"rc_counts\", since = \"1.15.0\")]\n    pub fn strong_count(this: &Self) -> usize {\n        this.inner().strong()\n    }\n\n    /// Increments the strong reference count on the `Rc<T>` associated with the\n    /// provided pointer by one.\n    ///\n    /// # Safety\n    ///\n    /// The pointer must have been obtained through `Rc::into_raw`, and the\n    /// associated `Rc` instance must be valid (i.e. the strong count must be at\n    /// least 1) for the duration of this method.\n    ///\n    /// # Examples\n    ///\n    /// ```\n    /// use std::rc::Rc;\n    ///\n    /// let five = Rc::new(5);\n    ///\n    /// unsafe {\n    ///     let ptr = Rc::into_raw(five);\n    ///     Rc::increment_strong_count(ptr);\n    ///\n    ///     let five = Rc::from_raw(ptr);\n    ///     assert_eq!(2, Rc::strong_count(&five));\n    /// }\n    /// ```\n    #[inline]\n    #[stable(feature = \"rc_mutate_strong_count\", since = \"1.53.0\")]\n    pub unsafe fn increment_strong_count(ptr: *const T) {\n        // Retain Rc, but don't touch refcount by wrapping in ManuallyDrop\n        let rc = unsafe { mem::ManuallyDrop::new(Rc::<T>::from_raw(ptr)) };\n        // Now increase refcount, but don't drop new refcount either\n        let _rc_clone: mem::ManuallyDrop<_> = rc.clone();\n    }\n\n    /// Decrements the strong reference count on the `Rc<T>` associated with the\n    /// provided pointer by one.\n    ///\n    /// # Safety\n    ///\n    /// The pointer must have been obtained through `Rc::into_raw`, and the\n    /// associated `Rc` instance must be valid (i.e. the strong count must be at\n    /// least 1) when invoking this method. This method can be used to release\n    /// the final `Rc` and backing storage, but **should not** be called after\n    /// the final `Rc` has been released.\n    ///\n    /// # Examples\n    ///\n    /// ```\n    /// use std::rc::Rc;\n    ///\n    /// let five = Rc::new(5);\n    ///\n    /// unsafe {\n    ///     let ptr = Rc::into_raw(five);\n    ///     Rc::increment_strong_count(ptr);\n    ///\n    ///     let five = Rc::from_raw(ptr);\n    ///     assert_eq!(2, Rc::strong_count(&five));\n    ///     Rc::decrement_strong_count(ptr);\n    ///     assert_eq!(1, Rc::strong_count(&five));\n    /// }\n    /// ```\n    #[inline]\n    #[stable(feature = \"rc_mutate_strong_count\", since = \"1.53.0\")]\n    pub unsafe fn decrement_strong_count(ptr: *const T) {\n        unsafe { mem::drop(Rc::from_raw(ptr)) };\n    }\n\n    /// Returns `true` if there are no other `Rc` or [`Weak`] pointers to\n    /// this allocation.\n    #[inline]\n    fn is_unique(this: &Self) -> bool {\n        Rc::weak_count(this) == 0 && Rc::strong_count(this) == 1\n    }\n\n    /// Returns a mutable reference into the given `Rc`, if there are\n    /// no other `Rc` or [`Weak`] pointers to the same allocation.\n    ///\n    /// Returns [`None`] otherwise, because it is not safe to\n    /// mutate a shared value.\n    ///\n    /// See also [`make_mut`][make_mut], which will [`clone`][clone]\n    /// the inner value when there are other pointers.\n    ///\n    /// [make_mut]: Rc::make_mut\n    /// [clone]: Clone::clone\n    ///\n    /// # Examples\n    ///\n    /// ```\n    /// use std::rc::Rc;\n    ///\n    /// let mut x = Rc::new(3);\n    /// *Rc::get_mut(&mut x).unwrap() = 4;\n    /// assert_eq!(*x, 4);\n    ///\n    /// let _y = Rc::clone(&x);\n    /// assert!(Rc::get_mut(&mut x).is_none());\n    /// ```\n    #[inline]\n    #[stable(feature = \"rc_unique\", since = \"1.4.0\")]\n    pub fn get_mut(this: &mut Self) -> Option<&mut T> {\n        if Rc::is_unique(this) { unsafe { Some(Rc::get_mut_unchecked(this)) } } else { None }\n    }\n\n    /// Returns a mutable reference into the given `Rc`,\n    /// without any check.\n    ///\n    /// See also [`get_mut`], which is safe and does appropriate checks.\n    ///\n    /// [`get_mut`]: Rc::get_mut\n    ///\n    /// # Safety\n    ///\n    /// Any other `Rc` or [`Weak`] pointers to the same allocation must not be dereferenced\n    /// for the duration of the returned borrow.\n    /// This is trivially the case if no such pointers exist,\n    /// for example immediately after `Rc::new`.\n    ///\n    /// # Examples\n    ///\n    /// ```\n    /// #![feature(get_mut_unchecked)]\n    ///\n    /// use std::rc::Rc;\n    ///\n    /// let mut x = Rc::new(String::new());\n    /// unsafe {\n    ///     Rc::get_mut_unchecked(&mut x).push_str(\"foo\")\n    /// }\n    /// assert_eq!(*x, \"foo\");\n    /// ```\n    #[inline]\n    #[unstable(feature = \"get_mut_unchecked\", issue = \"63292\")]\n    pub unsafe fn get_mut_unchecked(this: &mut Self) -> &mut T {\n        // We are careful to *not* create a reference covering the \"count\" fields, as\n        // this would conflict with accesses to the reference counts (e.g. by `Weak`).\n        unsafe { &mut (*this.ptr.as_ptr()).value }\n    }\n\n    #[inline]\n    #[stable(feature = \"ptr_eq\", since = \"1.17.0\")]\n    /// Returns `true` if the two `Rc`s point to the same allocation\n    /// (in a vein similar to [`ptr::eq`]).\n    ///\n    /// # Examples\n    ///\n    /// ```\n    /// use std::rc::Rc;\n    ///\n    /// let five = Rc::new(5);\n    /// let same_five = Rc::clone(&five);\n    /// let other_five = Rc::new(5);\n    ///\n    /// assert!(Rc::ptr_eq(&five, &same_five));\n    /// assert!(!Rc::ptr_eq(&five, &other_five));\n    /// ```\n    ///\n    /// [`ptr::eq`]: core::ptr::eq\n    pub fn ptr_eq(this: &Self, other: &Self) -> bool {\n        this.ptr.as_ptr() == other.ptr.as_ptr()\n    }\n}\n\nimpl<T: Clone> Rc<T> {\n    /// Makes a mutable reference into the given `Rc`.\n    ///\n    /// If there are other `Rc` pointers to the same allocation, then `make_mut` will\n    /// [`clone`] the inner value to a new allocation to ensure unique ownership.  This is also\n    /// referred to as clone-on-write.\n    ///\n    /// If there are no other `Rc` pointers to this allocation, then [`Weak`]\n    /// pointers to this allocation will be disassociated.\n    ///\n    /// See also [`get_mut`], which will fail rather than cloning.\n    ///\n    /// [`clone`]: Clone::clone\n    /// [`get_mut`]: Rc::get_mut\n    ///\n    /// # Examples\n    ///\n    /// ```\n    /// use std::rc::Rc;\n    ///\n    /// let mut data = Rc::new(5);\n    ///\n    /// *Rc::make_mut(&mut data) += 1;        // Won't clone anything\n    /// let mut other_data = Rc::clone(&data);    // Won't clone inner data\n    /// *Rc::make_mut(&mut data) += 1;        // Clones inner data\n    /// *Rc::make_mut(&mut data) += 1;        // Won't clone anything\n    /// *Rc::make_mut(&mut other_data) *= 2;  // Won't clone anything\n    ///\n    /// // Now `data` and `other_data` point to different allocations.\n    /// assert_eq!(*data, 8);\n    /// assert_eq!(*other_data, 12);\n    /// ```\n    ///\n    /// [`Weak`] pointers will be disassociated:\n    ///\n    /// ```\n    /// use std::rc::Rc;\n    ///\n    /// let mut data = Rc::new(75);\n    /// let weak = Rc::downgrade(&data);\n    ///\n    /// assert!(75 == *data);\n    /// assert!(75 == *weak.upgrade().unwrap());\n    ///\n    /// *Rc::make_mut(&mut data) += 1;\n    ///\n    /// assert!(76 == *data);\n    /// assert!(weak.upgrade().is_none());\n    /// ```\n    #[cfg(not(no_global_oom_handling))]\n    #[inline]\n    #[stable(feature = \"rc_unique\", since = \"1.4.0\")]\n    pub fn make_mut(this: &mut Self) -> &mut T {\n        if Rc::strong_count(this) != 1 {\n            // Gotta clone the data, there are other Rcs.\n            // Pre-allocate memory to allow writing the cloned value directly.\n            let mut rc = Self::new_uninit();\n            unsafe {\n                let data = Rc::get_mut_unchecked(&mut rc);\n                (**this).write_clone_into_raw(data.as_mut_ptr());\n                *this = rc.assume_init();\n            }\n        } else if Rc::weak_count(this) != 0 {\n            // Can just steal the data, all that's left is Weaks\n            let mut rc = Self::new_uninit();\n            unsafe {\n                let data = Rc::get_mut_unchecked(&mut rc);\n                data.as_mut_ptr().copy_from_nonoverlapping(&**this, 1);\n\n                this.inner().dec_strong();\n                // Remove implicit strong-weak ref (no need to craft a fake\n                // Weak here -- we know other Weaks can clean up for us)\n                this.inner().dec_weak();\n                ptr::write(this, rc.assume_init());\n            }\n        }\n        // This unsafety is ok because we're guaranteed that the pointer\n        // returned is the *only* pointer that will ever be returned to T. Our\n        // reference count is guaranteed to be 1 at this point, and we required\n        // the `Rc<T>` itself to be `mut`, so we're returning the only possible\n        // reference to the allocation.\n        unsafe { &mut this.ptr.as_mut().value }\n    }\n}\n\nimpl Rc<dyn Any> {\n    #[inline]\n    #[stable(feature = \"rc_downcast\", since = \"1.29.0\")]\n    /// Attempt to downcast the `Rc<dyn Any>` to a concrete type.\n    ///\n    /// # Examples\n    ///\n    /// ```\n    /// use std::any::Any;\n    /// use std::rc::Rc;\n    ///\n    /// fn print_if_string(value: Rc<dyn Any>) {\n    ///     if let Ok(string) = value.downcast::<String>() {\n    ///         println!(\"String ({}): {}\", string.len(), string);\n    ///     }\n    /// }\n    ///\n    /// let my_string = \"Hello World\".to_string();\n    /// print_if_string(Rc::new(my_string));\n    /// print_if_string(Rc::new(0i8));\n    /// ```\n    pub fn downcast<T: Any>(self) -> Result<Rc<T>, Rc<dyn Any>> {\n        if (*self).is::<T>() {\n            let ptr = self.ptr.cast::<RcBox<T>>();\n            forget(self);\n            Ok(Rc::from_inner(ptr))\n        } else {\n            Err(self)\n        }\n    }\n}\n\nimpl<T: ?Sized> Rc<T> {\n    /// Allocates an `RcBox<T>` with sufficient space for\n    /// a possibly-unsized inner value where the value has the layout provided.\n    ///\n    /// The function `mem_to_rcbox` is called with the data pointer\n    /// and must return back a (potentially fat)-pointer for the `RcBox<T>`.\n    #[cfg(not(no_global_oom_handling))]\n    unsafe fn allocate_for_layout(\n        value_layout: Layout,\n        allocate: impl FnOnce(Layout) -> Result<NonNull<[u8]>, AllocError>,\n        mem_to_rcbox: impl FnOnce(*mut u8) -> *mut RcBox<T>,\n    ) -> *mut RcBox<T> {\n        // Calculate layout using the given value layout.\n        // Previously, layout was calculated on the expression\n        // `&*(ptr as *const RcBox<T>)`, but this created a misaligned\n        // reference (see #54908).\n        let layout = Layout::new::<RcBox<()>>().extend(value_layout).unwrap().0.pad_to_align();\n        unsafe {\n            Rc::try_allocate_for_layout(value_layout, allocate, mem_to_rcbox)\n                .unwrap_or_else(|_| handle_alloc_error(layout))\n        }\n    }\n\n    /// Allocates an `RcBox<T>` with sufficient space for\n    /// a possibly-unsized inner value where the value has the layout provided,\n    /// returning an error if allocation fails.\n    ///\n    /// The function `mem_to_rcbox` is called with the data pointer\n    /// and must return back a (potentially fat)-pointer for the `RcBox<T>`.\n    #[inline]\n    unsafe fn try_allocate_for_layout(\n        value_layout: Layout,\n        allocate: impl FnOnce(Layout) -> Result<NonNull<[u8]>, AllocError>,\n        mem_to_rcbox: impl FnOnce(*mut u8) -> *mut RcBox<T>,\n    ) -> Result<*mut RcBox<T>, AllocError> {\n        // Calculate layout using the given value layout.\n        // Previously, layout was calculated on the expression\n        // `&*(ptr as *const RcBox<T>)`, but this created a misaligned\n        // reference (see #54908).\n        let layout = Layout::new::<RcBox<()>>().extend(value_layout).unwrap().0.pad_to_align();\n\n        // Allocate for the layout.\n        let ptr = allocate(layout)?;\n\n        // Initialize the RcBox\n        let inner = mem_to_rcbox(ptr.as_non_null_ptr().as_ptr());\n        unsafe {\n            debug_assert_eq!(Layout::for_value(&*inner), layout);\n\n            ptr::write(&mut (*inner).strong, Cell::new(1));\n            ptr::write(&mut (*inner).weak, Cell::new(1));\n        }\n\n        Ok(inner)\n    }\n\n    /// Allocates an `RcBox<T>` with sufficient space for an unsized inner value\n    #[cfg(not(no_global_oom_handling))]\n    unsafe fn allocate_for_ptr(ptr: *const T) -> *mut RcBox<T> {\n        // Allocate for the `RcBox<T>` using the given value.\n        unsafe {\n            Self::allocate_for_layout(\n                Layout::for_value(&*ptr),\n                |layout| Global.allocate(layout),\n                |mem| (ptr as *mut RcBox<T>).set_ptr_value(mem),\n            )\n        }\n    }\n\n    #[cfg(not(no_global_oom_handling))]\n    fn from_box(v: Box<T>) -> Rc<T> {\n        unsafe {\n            let (box_unique, alloc) = Box::into_unique(v);\n            let bptr = box_unique.as_ptr();\n\n            let value_size = size_of_val(&*bptr);\n            let ptr = Self::allocate_for_ptr(bptr);\n\n            // Copy value as bytes\n            ptr::copy_nonoverlapping(\n                bptr as *const T as *const u8,\n                &mut (*ptr).value as *mut _ as *mut u8,\n                value_size,\n            );\n\n            // Free the allocation without dropping its contents\n            box_free(box_unique, alloc);\n\n            Self::from_ptr(ptr)\n        }\n    }\n}\n\nimpl<T> Rc<[T]> {\n    /// Allocates an `RcBox<[T]>` with the given length.\n    #[cfg(not(no_global_oom_handling))]\n    unsafe fn allocate_for_slice(len: usize) -> *mut RcBox<[T]> {\n        unsafe {\n            Self::allocate_for_layout(\n                Layout::array::<T>(len).unwrap(),\n                |layout| Global.allocate(layout),\n                |mem| ptr::slice_from_raw_parts_mut(mem as *mut T, len) as *mut RcBox<[T]>,\n            )\n        }\n    }\n\n    /// Copy elements from slice into newly allocated Rc<\\[T\\]>\n    ///\n    /// Unsafe because the caller must either take ownership or bind `T: Copy`\n    #[cfg(not(no_global_oom_handling))]\n    unsafe fn copy_from_slice(v: &[T]) -> Rc<[T]> {\n        unsafe {\n            let ptr = Self::allocate_for_slice(v.len());\n            ptr::copy_nonoverlapping(v.as_ptr(), &mut (*ptr).value as *mut [T] as *mut T, v.len());\n            Self::from_ptr(ptr)\n        }\n    }\n\n    /// Constructs an `Rc<[T]>` from an iterator known to be of a certain size.\n    ///\n    /// Behavior is undefined should the size be wrong.\n    #[cfg(not(no_global_oom_handling))]\n    unsafe fn from_iter_exact(iter: impl iter::Iterator<Item = T>, len: usize) -> Rc<[T]> {\n        // Panic guard while cloning T elements.\n        // In the event of a panic, elements that have been written\n        // into the new RcBox will be dropped, then the memory freed.\n        struct Guard<T> {\n            mem: NonNull<u8>,\n            elems: *mut T,\n            layout: Layout,\n            n_elems: usize,\n        }\n\n        impl<T> Drop for Guard<T> {\n            fn drop(&mut self) {\n                unsafe {\n                    let slice = from_raw_parts_mut(self.elems, self.n_elems);\n                    ptr::drop_in_place(slice);\n\n                    Global.deallocate(self.mem, self.layout);\n                }\n            }\n        }\n\n        unsafe {\n            let ptr = Self::allocate_for_slice(len);\n\n            let mem = ptr as *mut _ as *mut u8;\n            let layout = Layout::for_value(&*ptr);\n\n            // Pointer to first element\n            let elems = &mut (*ptr).value as *mut [T] as *mut T;\n\n            let mut guard = Guard { mem: NonNull::new_unchecked(mem), elems, layout, n_elems: 0 };\n\n            for (i, item) in iter.enumerate() {\n                ptr::write(elems.add(i), item);\n                guard.n_elems += 1;\n            }\n\n            // All clear. Forget the guard so it doesn't free the new RcBox.\n            forget(guard);\n\n            Self::from_ptr(ptr)\n        }\n    }\n}\n\n/// Specialization trait used for `From<&[T]>`.\ntrait RcFromSlice<T> {\n    fn from_slice(slice: &[T]) -> Self;\n}\n\n#[cfg(not(no_global_oom_handling))]\nimpl<T: Clone> RcFromSlice<T> for Rc<[T]> {\n    #[inline]\n    default fn from_slice(v: &[T]) -> Self {\n        unsafe { Self::from_iter_exact(v.iter().cloned(), v.len()) }\n    }\n}\n\n#[cfg(not(no_global_oom_handling))]\nimpl<T: Copy> RcFromSlice<T> for Rc<[T]> {\n    #[inline]\n    fn from_slice(v: &[T]) -> Self {\n        unsafe { Rc::copy_from_slice(v) }\n    }\n}\n\n#[stable(feature = \"rust1\", since = \"1.0.0\")]\nimpl<T: ?Sized> Deref for Rc<T> {\n    type Target = T;\n\n    #[inline(always)]\n    fn deref(&self) -> &T {\n        &self.inner().value\n    }\n}\n\n#[unstable(feature = \"receiver_trait\", issue = \"none\")]\nimpl<T: ?Sized> Receiver for Rc<T> {}\n\n#[stable(feature = \"rust1\", since = \"1.0.0\")]\nunsafe impl<#[may_dangle] T: ?Sized> Drop for Rc<T> {\n    /// Drops the `Rc`.\n    ///\n    /// This will decrement the strong reference count. If the strong reference\n    /// count reaches zero then the only other references (if any) are\n    /// [`Weak`], so we `drop` the inner value.\n    ///\n    /// # Examples\n    ///\n    /// ```\n    /// use std::rc::Rc;\n    ///\n    /// struct Foo;\n    ///\n    /// impl Drop for Foo {\n    ///     fn drop(&mut self) {\n    ///         println!(\"dropped!\");\n    ///     }\n    /// }\n    ///\n    /// let foo  = Rc::new(Foo);\n    /// let foo2 = Rc::clone(&foo);\n    ///\n    /// drop(foo);    // Doesn't print anything\n    /// drop(foo2);   // Prints \"dropped!\"\n    /// ```\n    fn drop(&mut self) {\n        unsafe {\n            self.inner().dec_strong();\n            if self.inner().strong() == 0 {\n                // destroy the contained object\n                ptr::drop_in_place(Self::get_mut_unchecked(self));\n\n                // remove the implicit \"strong weak\" pointer now that we've\n                // destroyed the contents.\n                self.inner().dec_weak();\n\n                if self.inner().weak() == 0 {\n                    Global.deallocate(self.ptr.cast(), Layout::for_value(self.ptr.as_ref()));\n                }\n            }\n        }\n    }\n}\n\n#[stable(feature = \"rust1\", since = \"1.0.0\")]\nimpl<T: ?Sized> Clone for Rc<T> {\n    /// Makes a clone of the `Rc` pointer.\n    ///\n    /// This creates another pointer to the same allocation, increasing the\n    /// strong reference count.\n    ///\n    /// # Examples\n    ///\n    /// ```\n    /// use std::rc::Rc;\n    ///\n    /// let five = Rc::new(5);\n    ///\n    /// let _ = Rc::clone(&five);\n    /// ```\n    #[inline]\n    fn clone(&self) -> Rc<T> {\n        self.inner().inc_strong();\n        Self::from_inner(self.ptr)\n    }\n}\n\n#[stable(feature = \"rust1\", since = \"1.0.0\")]\nimpl<T: Default> Default for Rc<T> {\n    /// Creates a new `Rc<T>`, with the `Default` value for `T`.\n    ///\n    /// # Examples\n    ///\n    /// ```\n    /// use std::rc::Rc;\n    ///\n    /// let x: Rc<i32> = Default::default();\n    /// assert_eq!(*x, 0);\n    /// ```\n    #[inline]\n    fn default() -> Rc<T> {\n        Rc::new(Default::default())\n    }\n}\n\n#[stable(feature = \"rust1\", since = \"1.0.0\")]\ntrait RcEqIdent<T: ?Sized + PartialEq> {\n    fn eq(&self, other: &Rc<T>) -> bool;\n    fn ne(&self, other: &Rc<T>) -> bool;\n}\n\n#[stable(feature = \"rust1\", since = \"1.0.0\")]\nimpl<T: ?Sized + PartialEq> RcEqIdent<T> for Rc<T> {\n    #[inline]\n    default fn eq(&self, other: &Rc<T>) -> bool {\n        **self == **other\n    }\n\n    #[inline]\n    default fn ne(&self, other: &Rc<T>) -> bool {\n        **self != **other\n    }\n}\n\n// Hack to allow specializing on `Eq` even though `Eq` has a method.\n#[rustc_unsafe_specialization_marker]\npub(crate) trait MarkerEq: PartialEq<Self> {}\n\nimpl<T: Eq> MarkerEq for T {}\n\n/// We're doing this specialization here, and not as a more general optimization on `&T`, because it\n/// would otherwise add a cost to all equality checks on refs. We assume that `Rc`s are used to\n/// store large values, that are slow to clone, but also heavy to check for equality, causing this\n/// cost to pay off more easily. It's also more likely to have two `Rc` clones, that point to\n/// the same value, than two `&T`s.\n///\n/// We can only do this when `T: Eq` as a `PartialEq` might be deliberately irreflexive.\n#[stable(feature = \"rust1\", since = \"1.0.0\")]\nimpl<T: ?Sized + MarkerEq> RcEqIdent<T> for Rc<T> {\n    #[inline]\n    fn eq(&self, other: &Rc<T>) -> bool {\n        Rc::ptr_eq(self, other) || **self == **other\n    }\n\n    #[inline]\n    fn ne(&self, other: &Rc<T>) -> bool {\n        !Rc::ptr_eq(self, other) && **self != **other\n    }\n}\n\n#[stable(feature = \"rust1\", since = \"1.0.0\")]\nimpl<T: ?Sized + PartialEq> PartialEq for Rc<T> {\n    /// Equality for two `Rc`s.\n    ///\n    /// Two `Rc`s are equal if their inner values are equal, even if they are\n    /// stored in different allocation.\n    ///\n    /// If `T` also implements `Eq` (implying reflexivity of equality),\n    /// two `Rc`s that point to the same allocation are\n    /// always equal.\n    ///\n    /// # Examples\n    ///\n    /// ```\n    /// use std::rc::Rc;\n    ///\n    /// let five = Rc::new(5);\n    ///\n    /// assert!(five == Rc::new(5));\n    /// ```\n    #[inline]\n    fn eq(&self, other: &Rc<T>) -> bool {\n        RcEqIdent::eq(self, other)\n    }\n\n    /// Inequality for two `Rc`s.\n    ///\n    /// Two `Rc`s are unequal if their inner values are unequal.\n    ///\n    /// If `T` also implements `Eq` (implying reflexivity of equality),\n    /// two `Rc`s that point to the same allocation are\n    /// never unequal.\n    ///\n    /// # Examples\n    ///\n    /// ```\n    /// use std::rc::Rc;\n    ///\n    /// let five = Rc::new(5);\n    ///\n    /// assert!(five != Rc::new(6));\n    /// ```\n    #[inline]\n    fn ne(&self, other: &Rc<T>) -> bool {\n        RcEqIdent::ne(self, other)\n    }\n}\n\n#[stable(feature = \"rust1\", since = \"1.0.0\")]\nimpl<T: ?Sized + Eq> Eq for Rc<T> {}\n\n#[stable(feature = \"rust1\", since = \"1.0.0\")]\nimpl<T: ?Sized + PartialOrd> PartialOrd for Rc<T> {\n    /// Partial comparison for two `Rc`s.\n    ///\n    /// The two are compared by calling `partial_cmp()` on their inner values.\n    ///\n    /// # Examples\n    ///\n    /// ```\n    /// use std::rc::Rc;\n    /// use std::cmp::Ordering;\n    ///\n    /// let five = Rc::new(5);\n    ///\n    /// assert_eq!(Some(Ordering::Less), five.partial_cmp(&Rc::new(6)));\n    /// ```\n    #[inline(always)]\n    fn partial_cmp(&self, other: &Rc<T>) -> Option<Ordering> {\n        (**self).partial_cmp(&**other)\n    }\n\n    /// Less-than comparison for two `Rc`s.\n    ///\n    /// The two are compared by calling `<` on their inner values.\n    ///\n    /// # Examples\n    ///\n    /// ```\n    /// use std::rc::Rc;\n    ///\n    /// let five = Rc::new(5);\n    ///\n    /// assert!(five < Rc::new(6));\n    /// ```\n    #[inline(always)]\n    fn lt(&self, other: &Rc<T>) -> bool {\n        **self < **other\n    }\n\n    /// 'Less than or equal to' comparison for two `Rc`s.\n    ///\n    /// The two are compared by calling `<=` on their inner values.\n    ///\n    /// # Examples\n    ///\n    /// ```\n    /// use std::rc::Rc;\n    ///\n    /// let five = Rc::new(5);\n    ///\n    /// assert!(five <= Rc::new(5));\n    /// ```\n    #[inline(always)]\n    fn le(&self, other: &Rc<T>) -> bool {\n        **self <= **other\n    }\n\n    /// Greater-than comparison for two `Rc`s.\n    ///\n    /// The two are compared by calling `>` on their inner values.\n    ///\n    /// # Examples\n    ///\n    /// ```\n    /// use std::rc::Rc;\n    ///\n    /// let five = Rc::new(5);\n    ///\n    /// assert!(five > Rc::new(4));\n    /// ```\n    #[inline(always)]\n    fn gt(&self, other: &Rc<T>) -> bool {\n        **self > **other\n    }\n\n    /// 'Greater than or equal to' comparison for two `Rc`s.\n    ///\n    /// The two are compared by calling `>=` on their inner values.\n    ///\n    /// # Examples\n    ///\n    /// ```\n    /// use std::rc::Rc;\n    ///\n    /// let five = Rc::new(5);\n    ///\n    /// assert!(five >= Rc::new(5));\n    /// ```\n    #[inline(always)]\n    fn ge(&self, other: &Rc<T>) -> bool {\n        **self >= **other\n    }\n}\n\n#[stable(feature = \"rust1\", since = \"1.0.0\")]\nimpl<T: ?Sized + Ord> Ord for Rc<T> {\n    /// Comparison for two `Rc`s.\n    ///\n    /// The two are compared by calling `cmp()` on their inner values.\n    ///\n    /// # Examples\n    ///\n    /// ```\n    /// use std::rc::Rc;\n    /// use std::cmp::Ordering;\n    ///\n    /// let five = Rc::new(5);\n    ///\n    /// assert_eq!(Ordering::Less, five.cmp(&Rc::new(6)));\n    /// ```\n    #[inline]\n    fn cmp(&self, other: &Rc<T>) -> Ordering {\n        (**self).cmp(&**other)\n    }\n}\n\n#[stable(feature = \"rust1\", since = \"1.0.0\")]\nimpl<T: ?Sized + Hash> Hash for Rc<T> {\n    fn hash<H: Hasher>(&self, state: &mut H) {\n        (**self).hash(state);\n    }\n}\n\n#[stable(feature = \"rust1\", since = \"1.0.0\")]\nimpl<T: ?Sized + fmt::Display> fmt::Display for Rc<T> {\n    fn fmt(&self, f: &mut fmt::Formatter<'_>) -> fmt::Result {\n        fmt::Display::fmt(&**self, f)\n    }\n}\n\n#[stable(feature = \"rust1\", since = \"1.0.0\")]\nimpl<T: ?Sized + fmt::Debug> fmt::Debug for Rc<T> {\n    fn fmt(&self, f: &mut fmt::Formatter<'_>) -> fmt::Result {\n        fmt::Debug::fmt(&**self, f)\n    }\n}\n\n#[stable(feature = \"rust1\", since = \"1.0.0\")]\nimpl<T: ?Sized> fmt::Pointer for Rc<T> {\n    fn fmt(&self, f: &mut fmt::Formatter<'_>) -> fmt::Result {\n        fmt::Pointer::fmt(&(&**self as *const T), f)\n    }\n}\n\n#[stable(feature = \"from_for_ptrs\", since = \"1.6.0\")]\nimpl<T> From<T> for Rc<T> {\n    /// Converts a generic type `T` into a `Rc<T>`\n    ///\n    /// The conversion allocates on the heap and moves `t`\n    /// from the stack into it.\n    ///\n    /// # Example\n    /// ```rust\n    /// # use std::rc::Rc;\n    /// let x = 5;\n    /// let rc = Rc::new(5);\n    ///\n    /// assert_eq!(Rc::from(x), rc);\n    /// ```\n    fn from(t: T) -> Self {\n        Rc::new(t)\n    }\n}\n\n#[cfg(not(no_global_oom_handling))]\n#[stable(feature = \"shared_from_slice\", since = \"1.21.0\")]\nimpl<T: Clone> From<&[T]> for Rc<[T]> {\n    /// Allocate a reference-counted slice and fill it by cloning `v`'s items.\n    ///\n    /// # Example\n    ///\n    /// ```\n    /// # use std::rc::Rc;\n    /// let original: &[i32] = &[1, 2, 3];\n    /// let shared: Rc<[i32]> = Rc::from(original);\n    /// assert_eq!(&[1, 2, 3], &shared[..]);\n    /// ```\n    #[inline]\n    fn from(v: &[T]) -> Rc<[T]> {\n        <Self as RcFromSlice<T>>::from_slice(v)\n    }\n}\n\n#[cfg(not(no_global_oom_handling))]\n#[stable(feature = \"shared_from_slice\", since = \"1.21.0\")]\nimpl From<&str> for Rc<str> {\n    /// Allocate a reference-counted string slice and copy `v` into it.\n    ///\n    /// # Example\n    ///\n    /// ```\n    /// # use std::rc::Rc;\n    /// let shared: Rc<str> = Rc::from(\"statue\");\n    /// assert_eq!(\"statue\", &shared[..]);\n    /// ```\n    #[inline]\n    fn from(v: &str) -> Rc<str> {\n        let rc = Rc::<[u8]>::from(v.as_bytes());\n        unsafe { Rc::from_raw(Rc::into_raw(rc) as *const str) }\n    }\n}\n\n#[cfg(not(no_global_oom_handling))]\n#[stable(feature = \"shared_from_slice\", since = \"1.21.0\")]\nimpl From<String> for Rc<str> {\n    /// Allocate a reference-counted string slice and copy `v` into it.\n    ///\n    /// # Example\n    ///\n    /// ```\n    /// # use std::rc::Rc;\n    /// let original: String = \"statue\".to_owned();\n    /// let shared: Rc<str> = Rc::from(original);\n    /// assert_eq!(\"statue\", &shared[..]);\n    /// ```\n    #[inline]\n    fn from(v: String) -> Rc<str> {\n        Rc::from(&v[..])\n    }\n}\n\n#[cfg(not(no_global_oom_handling))]\n#[stable(feature = \"shared_from_slice\", since = \"1.21.0\")]\nimpl<T: ?Sized> From<Box<T>> for Rc<T> {\n    /// Move a boxed object to a new, reference counted, allocation.\n    ///\n    /// # Example\n    ///\n    /// ```\n    /// # use std::rc::Rc;\n    /// let original: Box<i32> = Box::new(1);\n    /// let shared: Rc<i32> = Rc::from(original);\n    /// assert_eq!(1, *shared);\n    /// ```\n    #[inline]\n    fn from(v: Box<T>) -> Rc<T> {\n        Rc::from_box(v)\n    }\n}\n\n#[cfg(not(no_global_oom_handling))]\n#[stable(feature = \"shared_from_slice\", since = \"1.21.0\")]\nimpl<T> From<Vec<T>> for Rc<[T]> {\n    /// Allocate a reference-counted slice and move `v`'s items into it.\n    ///\n    /// # Example\n    ///\n    /// ```\n    /// # use std::rc::Rc;\n    /// let original: Box<Vec<i32>> = Box::new(vec![1, 2, 3]);\n    /// let shared: Rc<Vec<i32>> = Rc::from(original);\n    /// assert_eq!(vec![1, 2, 3], *shared);\n    /// ```\n    #[inline]\n    fn from(mut v: Vec<T>) -> Rc<[T]> {\n        unsafe {\n            let rc = Rc::copy_from_slice(&v);\n\n            // Allow the Vec to free its memory, but not destroy its contents\n            v.set_len(0);\n\n            rc\n        }\n    }\n}\n\n#[stable(feature = \"shared_from_cow\", since = \"1.45.0\")]\nimpl<'a, B> From<Cow<'a, B>> for Rc<B>\nwhere\n    B: ToOwned + ?Sized,\n    Rc<B>: From<&'a B> + From<B::Owned>,\n{\n    /// Create a reference-counted pointer from\n    /// a clone-on-write pointer by copying its content.\n    ///\n    /// # Example\n    ///\n    /// ```rust\n    /// # use std::rc::Rc;\n    /// # use std::borrow::Cow;\n    /// let cow: Cow<str> = Cow::Borrowed(\"eggplant\");\n    /// let shared: Rc<str> = Rc::from(cow);\n    /// assert_eq!(\"eggplant\", &shared[..]);\n    /// ```\n    #[inline]\n    fn from(cow: Cow<'a, B>) -> Rc<B> {\n        match cow {\n            Cow::Borrowed(s) => Rc::from(s),\n            Cow::Owned(s) => Rc::from(s),\n        }\n    }\n}\n\n#[stable(feature = \"boxed_slice_try_from\", since = \"1.43.0\")]\nimpl<T, const N: usize> TryFrom<Rc<[T]>> for Rc<[T; N]> {\n    type Error = Rc<[T]>;\n\n    fn try_from(boxed_slice: Rc<[T]>) -> Result<Self, Self::Error> {\n        if boxed_slice.len() == N {\n            Ok(unsafe { Rc::from_raw(Rc::into_raw(boxed_slice) as *mut [T; N]) })\n        } else {\n            Err(boxed_slice)\n        }\n    }\n}\n\n#[cfg(not(no_global_oom_handling))]\n#[stable(feature = \"shared_from_iter\", since = \"1.37.0\")]\nimpl<T> iter::FromIterator<T> for Rc<[T]> {\n    /// Takes each element in the `Iterator` and collects it into an `Rc<[T]>`.\n    ///\n    /// # Performance characteristics\n    ///\n    /// ## The general case\n    ///\n    /// In the general case, collecting into `Rc<[T]>` is done by first\n    /// collecting into a `Vec<T>`. That is, when writing the following:\n    ///\n    /// ```rust\n    /// # use std::rc::Rc;\n    /// let evens: Rc<[u8]> = (0..10).filter(|&x| x % 2 == 0).collect();\n    /// # assert_eq!(&*evens, &[0, 2, 4, 6, 8]);\n    /// ```\n    ///\n    /// this behaves as if we wrote:\n    ///\n    /// ```rust\n    /// # use std::rc::Rc;\n    /// let evens: Rc<[u8]> = (0..10).filter(|&x| x % 2 == 0)\n    ///     .collect::<Vec<_>>() // The first set of allocations happens here.\n    ///     .into(); // A second allocation for `Rc<[T]>` happens here.\n    /// # assert_eq!(&*evens, &[0, 2, 4, 6, 8]);\n    /// ```\n    ///\n    /// This will allocate as many times as needed for constructing the `Vec<T>`\n    /// and then it will allocate once for turning the `Vec<T>` into the `Rc<[T]>`.\n    ///\n    /// ## Iterators of known length\n    ///\n    /// When your `Iterator` implements `TrustedLen` and is of an exact size,\n    /// a single allocation will be made for the `Rc<[T]>`. For example:\n    ///\n    /// ```rust\n    /// # use std::rc::Rc;\n    /// let evens: Rc<[u8]> = (0..10).collect(); // Just a single allocation happens here.\n    /// # assert_eq!(&*evens, &*(0..10).collect::<Vec<_>>());\n    /// ```\n    fn from_iter<I: iter::IntoIterator<Item = T>>(iter: I) -> Self {\n        ToRcSlice::to_rc_slice(iter.into_iter())\n    }\n}\n\n/// Specialization trait used for collecting into `Rc<[T]>`.\n#[cfg(not(no_global_oom_handling))]\ntrait ToRcSlice<T>: Iterator<Item = T> + Sized {\n    fn to_rc_slice(self) -> Rc<[T]>;\n}\n\n#[cfg(not(no_global_oom_handling))]\nimpl<T, I: Iterator<Item = T>> ToRcSlice<T> for I {\n    default fn to_rc_slice(self) -> Rc<[T]> {\n        self.collect::<Vec<T>>().into()\n    }\n}\n\n#[cfg(not(no_global_oom_handling))]\nimpl<T, I: iter::TrustedLen<Item = T>> ToRcSlice<T> for I {\n    fn to_rc_slice(self) -> Rc<[T]> {\n        // This is the case for a `TrustedLen` iterator.\n        let (low, high) = self.size_hint();\n        if let Some(high) = high {\n            debug_assert_eq!(\n                low,\n                high,\n                \"TrustedLen iterator's size hint is not exact: {:?}\",\n                (low, high)\n            );\n\n            unsafe {\n                // SAFETY: We need to ensure that the iterator has an exact length and we have.\n                Rc::from_iter_exact(self, low)\n            }\n        } else {\n            // TrustedLen contract guarantees that `upper_bound == `None` implies an iterator\n            // length exceeding `usize::MAX`.\n            // The default implementation would collect into a vec which would panic.\n            // Thus we panic here immediately without invoking `Vec` code.\n            panic!(\"capacity overflow\");\n        }\n    }\n}\n\n/// `Weak` is a version of [`Rc`] that holds a non-owning reference to the\n/// managed allocation. The allocation is accessed by calling [`upgrade`] on the `Weak`\n/// pointer, which returns an [`Option`]`<`[`Rc`]`<T>>`.\n///\n/// Since a `Weak` reference does not count towards ownership, it will not\n/// prevent the value stored in the allocation from being dropped, and `Weak` itself makes no\n/// guarantees about the value still being present. Thus it may return [`None`]\n/// when [`upgrade`]d. Note however that a `Weak` reference *does* prevent the allocation\n/// itself (the backing store) from being deallocated.\n///\n/// A `Weak` pointer is useful for keeping a temporary reference to the allocation\n/// managed by [`Rc`] without preventing its inner value from being dropped. It is also used to\n/// prevent circular references between [`Rc`] pointers, since mutual owning references\n/// would never allow either [`Rc`] to be dropped. For example, a tree could\n/// have strong [`Rc`] pointers from parent nodes to children, and `Weak`\n/// pointers from children back to their parents.\n///\n/// The typical way to obtain a `Weak` pointer is to call [`Rc::downgrade`].\n///\n/// [`upgrade`]: Weak::upgrade\n#[stable(feature = \"rc_weak\", since = \"1.4.0\")]\npub struct Weak<T: ?Sized> {\n    // This is a `NonNull` to allow optimizing the size of this type in enums,\n    // but it is not necessarily a valid pointer.\n    // `Weak::new` sets this to `usize::MAX` so that it doesn’t need\n    // to allocate space on the heap.  That's not a value a real pointer\n    // will ever have because RcBox has alignment at least 2.\n    // This is only possible when `T: Sized`; unsized `T` never dangle.\n    ptr: NonNull<RcBox<T>>,\n}\n\n#[stable(feature = \"rc_weak\", since = \"1.4.0\")]\nimpl<T: ?Sized> !marker::Send for Weak<T> {}\n#[stable(feature = \"rc_weak\", since = \"1.4.0\")]\nimpl<T: ?Sized> !marker::Sync for Weak<T> {}\n\n#[unstable(feature = \"coerce_unsized\", issue = \"27732\")]\nimpl<T: ?Sized + Unsize<U>, U: ?Sized> CoerceUnsized<Weak<U>> for Weak<T> {}\n\n#[unstable(feature = \"dispatch_from_dyn\", issue = \"none\")]\nimpl<T: ?Sized + Unsize<U>, U: ?Sized> DispatchFromDyn<Weak<U>> for Weak<T> {}\n\nimpl<T> Weak<T> {\n    /// Constructs a new `Weak<T>`, without allocating any memory.\n    /// Calling [`upgrade`] on the return value always gives [`None`].\n    ///\n    /// [`upgrade`]: Weak::upgrade\n    ///\n    /// # Examples\n    ///\n    /// ```\n    /// use std::rc::Weak;\n    ///\n    /// let empty: Weak<i64> = Weak::new();\n    /// assert!(empty.upgrade().is_none());\n    /// ```\n    #[stable(feature = \"downgraded_weak\", since = \"1.10.0\")]\n    pub fn new() -> Weak<T> {\n        Weak { ptr: NonNull::new(usize::MAX as *mut RcBox<T>).expect(\"MAX is not 0\") }\n    }\n}\n\npub(crate) fn is_dangling<T: ?Sized>(ptr: *mut T) -> bool {\n    let address = ptr as *mut () as usize;\n    address == usize::MAX\n}\n\n/// Helper type to allow accessing the reference counts without\n/// making any assertions about the data field.\nstruct WeakInner<'a> {\n    weak: &'a Cell<usize>,\n    strong: &'a Cell<usize>,\n}\n\nimpl<T: ?Sized> Weak<T> {\n    /// Returns a raw pointer to the object `T` pointed to by this `Weak<T>`.\n    ///\n    /// The pointer is valid only if there are some strong references. The pointer may be dangling,\n    /// unaligned or even [`null`] otherwise.\n    ///\n    /// # Examples\n    ///\n    /// ```\n    /// use std::rc::Rc;\n    /// use std::ptr;\n    ///\n    /// let strong = Rc::new(\"hello\".to_owned());\n    /// let weak = Rc::downgrade(&strong);\n    /// // Both point to the same object\n    /// assert!(ptr::eq(&*strong, weak.as_ptr()));\n    /// // The strong here keeps it alive, so we can still access the object.\n    /// assert_eq!(\"hello\", unsafe { &*weak.as_ptr() });\n    ///\n    /// drop(strong);\n    /// // But not any more. We can do weak.as_ptr(), but accessing the pointer would lead to\n    /// // undefined behaviour.\n    /// // assert_eq!(\"hello\", unsafe { &*weak.as_ptr() });\n    /// ```\n    ///\n    /// [`null`]: core::ptr::null\n    #[stable(feature = \"rc_as_ptr\", since = \"1.45.0\")]\n    pub fn as_ptr(&self) -> *const T {\n        let ptr: *mut RcBox<T> = NonNull::as_ptr(self.ptr);\n\n        if is_dangling(ptr) {\n            // If the pointer is dangling, we return the sentinel directly. This cannot be\n            // a valid payload address, as the payload is at least as aligned as RcBox (usize).\n            ptr as *const T\n        } else {\n            // SAFETY: if is_dangling returns false, then the pointer is dereferencable.\n            // The payload may be dropped at this point, and we have to maintain provenance,\n            // so use raw pointer manipulation.\n            unsafe { ptr::addr_of_mut!((*ptr).value) }\n        }\n    }\n\n    /// Consumes the `Weak<T>` and turns it into a raw pointer.\n    ///\n    /// This converts the weak pointer into a raw pointer, while still preserving the ownership of\n    /// one weak reference (the weak count is not modified by this operation). It can be turned\n    /// back into the `Weak<T>` with [`from_raw`].\n    ///\n    /// The same restrictions of accessing the target of the pointer as with\n    /// [`as_ptr`] apply.\n    ///\n    /// # Examples\n    ///\n    /// ```\n    /// use std::rc::{Rc, Weak};\n    ///\n    /// let strong = Rc::new(\"hello\".to_owned());\n    /// let weak = Rc::downgrade(&strong);\n    /// let raw = weak.into_raw();\n    ///\n    /// assert_eq!(1, Rc::weak_count(&strong));\n    /// assert_eq!(\"hello\", unsafe { &*raw });\n    ///\n    /// drop(unsafe { Weak::from_raw(raw) });\n    /// assert_eq!(0, Rc::weak_count(&strong));\n    /// ```\n    ///\n    /// [`from_raw`]: Weak::from_raw\n    /// [`as_ptr`]: Weak::as_ptr\n    #[stable(feature = \"weak_into_raw\", since = \"1.45.0\")]\n    pub fn into_raw(self) -> *const T {\n        let result = self.as_ptr();\n        mem::forget(self);\n        result\n    }\n\n    /// Converts a raw pointer previously created by [`into_raw`] back into `Weak<T>`.\n    ///\n    /// This can be used to safely get a strong reference (by calling [`upgrade`]\n    /// later) or to deallocate the weak count by dropping the `Weak<T>`.\n    ///\n    /// It takes ownership of one weak reference (with the exception of pointers created by [`new`],\n    /// as these don't own anything; the method still works on them).\n    ///\n    /// # Safety\n    ///\n    /// The pointer must have originated from the [`into_raw`] and must still own its potential\n    /// weak reference.\n    ///\n    /// It is allowed for the strong count to be 0 at the time of calling this. Nevertheless, this\n    /// takes ownership of one weak reference currently represented as a raw pointer (the weak\n    /// count is not modified by this operation) and therefore it must be paired with a previous\n    /// call to [`into_raw`].\n    ///\n    /// # Examples\n    ///\n    /// ```\n    /// use std::rc::{Rc, Weak};\n    ///\n    /// let strong = Rc::new(\"hello\".to_owned());\n    ///\n    /// let raw_1 = Rc::downgrade(&strong).into_raw();\n    /// let raw_2 = Rc::downgrade(&strong).into_raw();\n    ///\n    /// assert_eq!(2, Rc::weak_count(&strong));\n    ///\n    /// assert_eq!(\"hello\", &*unsafe { Weak::from_raw(raw_1) }.upgrade().unwrap());\n    /// assert_eq!(1, Rc::weak_count(&strong));\n    ///\n    /// drop(strong);\n    ///\n    /// // Decrement the last weak count.\n    /// assert!(unsafe { Weak::from_raw(raw_2) }.upgrade().is_none());\n    /// ```\n    ///\n    /// [`into_raw`]: Weak::into_raw\n    /// [`upgrade`]: Weak::upgrade\n    /// [`new`]: Weak::new\n    #[stable(feature = \"weak_into_raw\", since = \"1.45.0\")]\n    pub unsafe fn from_raw(ptr: *const T) -> Self {\n        // See Weak::as_ptr for context on how the input pointer is derived.\n\n        let ptr = if is_dangling(ptr as *mut T) {\n            // This is a dangling Weak.\n            ptr as *mut RcBox<T>\n        } else {\n            // Otherwise, we're guaranteed the pointer came from a nondangling Weak.\n            // SAFETY: data_offset is safe to call, as ptr references a real (potentially dropped) T.\n            let offset = unsafe { data_offset(ptr) };\n            // Thus, we reverse the offset to get the whole RcBox.\n            // SAFETY: the pointer originated from a Weak, so this offset is safe.\n            unsafe { (ptr as *mut RcBox<T>).set_ptr_value((ptr as *mut u8).offset(-offset)) }\n        };\n\n        // SAFETY: we now have recovered the original Weak pointer, so can create the Weak.\n        Weak { ptr: unsafe { NonNull::new_unchecked(ptr) } }\n    }\n\n    /// Attempts to upgrade the `Weak` pointer to an [`Rc`], delaying\n    /// dropping of the inner value if successful.\n    ///\n    /// Returns [`None`] if the inner value has since been dropped.\n    ///\n    /// # Examples\n    ///\n    /// ```\n    /// use std::rc::Rc;\n    ///\n    /// let five = Rc::new(5);\n    ///\n    /// let weak_five = Rc::downgrade(&five);\n    ///\n    /// let strong_five: Option<Rc<_>> = weak_five.upgrade();\n    /// assert!(strong_five.is_some());\n    ///\n    /// // Destroy all strong pointers.\n    /// drop(strong_five);\n    /// drop(five);\n    ///\n    /// assert!(weak_five.upgrade().is_none());\n    /// ```\n    #[stable(feature = \"rc_weak\", since = \"1.4.0\")]\n    pub fn upgrade(&self) -> Option<Rc<T>> {\n        let inner = self.inner()?;\n        if inner.strong() == 0 {\n            None\n        } else {\n            inner.inc_strong();\n            Some(Rc::from_inner(self.ptr))\n        }\n    }\n\n    /// Gets the number of strong (`Rc`) pointers pointing to this allocation.\n    ///\n    /// If `self` was created using [`Weak::new`], this will return 0.\n    #[stable(feature = \"weak_counts\", since = \"1.41.0\")]\n    pub fn strong_count(&self) -> usize {\n        if let Some(inner) = self.inner() { inner.strong() } else { 0 }\n    }\n\n    /// Gets the number of `Weak` pointers pointing to this allocation.\n    ///\n    /// If no strong pointers remain, this will return zero.\n    #[stable(feature = \"weak_counts\", since = \"1.41.0\")]\n    pub fn weak_count(&self) -> usize {\n        self.inner()\n            .map(|inner| {\n                if inner.strong() > 0 {\n                    inner.weak() - 1 // subtract the implicit weak ptr\n                } else {\n                    0\n                }\n            })\n            .unwrap_or(0)\n    }\n\n    /// Returns `None` when the pointer is dangling and there is no allocated `RcBox`,\n    /// (i.e., when this `Weak` was created by `Weak::new`).\n    #[inline]\n    fn inner(&self) -> Option<WeakInner<'_>> {\n        if is_dangling(self.ptr.as_ptr()) {\n            None\n        } else {\n            // We are careful to *not* create a reference covering the \"data\" field, as\n            // the field may be mutated concurrently (for example, if the last `Rc`\n            // is dropped, the data field will be dropped in-place).\n            Some(unsafe {\n                let ptr = self.ptr.as_ptr();\n                WeakInner { strong: &(*ptr).strong, weak: &(*ptr).weak }\n            })\n        }\n    }\n\n    /// Returns `true` if the two `Weak`s point to the same allocation (similar to\n    /// [`ptr::eq`]), or if both don't point to any allocation\n    /// (because they were created with `Weak::new()`).\n    ///\n    /// # Notes\n    ///\n    /// Since this compares pointers it means that `Weak::new()` will equal each\n    /// other, even though they don't point to any allocation.\n    ///\n    /// # Examples\n    ///\n    /// ```\n    /// use std::rc::Rc;\n    ///\n    /// let first_rc = Rc::new(5);\n    /// let first = Rc::downgrade(&first_rc);\n    /// let second = Rc::downgrade(&first_rc);\n    ///\n    /// assert!(first.ptr_eq(&second));\n    ///\n    /// let third_rc = Rc::new(5);\n    /// let third = Rc::downgrade(&third_rc);\n    ///\n    /// assert!(!first.ptr_eq(&third));\n    /// ```\n    ///\n    /// Comparing `Weak::new`.\n    ///\n    /// ```\n    /// use std::rc::{Rc, Weak};\n    ///\n    /// let first = Weak::new();\n    /// let second = Weak::new();\n    /// assert!(first.ptr_eq(&second));\n    ///\n    /// let third_rc = Rc::new(());\n    /// let third = Rc::downgrade(&third_rc);\n    /// assert!(!first.ptr_eq(&third));\n    /// ```\n    ///\n    /// [`ptr::eq`]: core::ptr::eq\n    #[inline]\n    #[stable(feature = \"weak_ptr_eq\", since = \"1.39.0\")]\n    pub fn ptr_eq(&self, other: &Self) -> bool {\n        self.ptr.as_ptr() == other.ptr.as_ptr()\n    }\n}\n\n#[stable(feature = \"rc_weak\", since = \"1.4.0\")]\nunsafe impl<#[may_dangle] T: ?Sized> Drop for Weak<T> {\n    /// Drops the `Weak` pointer.\n    ///\n    /// # Examples\n    ///\n    /// ```\n    /// use std::rc::{Rc, Weak};\n    ///\n    /// struct Foo;\n    ///\n    /// impl Drop for Foo {\n    ///     fn drop(&mut self) {\n    ///         println!(\"dropped!\");\n    ///     }\n    /// }\n    ///\n    /// let foo = Rc::new(Foo);\n    /// let weak_foo = Rc::downgrade(&foo);\n    /// let other_weak_foo = Weak::clone(&weak_foo);\n    ///\n    /// drop(weak_foo);   // Doesn't print anything\n    /// drop(foo);        // Prints \"dropped!\"\n    ///\n    /// assert!(other_weak_foo.upgrade().is_none());\n    /// ```\n    fn drop(&mut self) {\n        let inner = if let Some(inner) = self.inner() { inner } else { return };\n\n        inner.dec_weak();\n        // the weak count starts at 1, and will only go to zero if all\n        // the strong pointers have disappeared.\n        if inner.weak() == 0 {\n            unsafe {\n                Global.deallocate(self.ptr.cast(), Layout::for_value_raw(self.ptr.as_ptr()));\n            }\n        }\n    }\n}\n\n#[stable(feature = \"rc_weak\", since = \"1.4.0\")]\nimpl<T: ?Sized> Clone for Weak<T> {\n    /// Makes a clone of the `Weak` pointer that points to the same allocation.\n    ///\n    /// # Examples\n    ///\n    /// ```\n    /// use std::rc::{Rc, Weak};\n    ///\n    /// let weak_five = Rc::downgrade(&Rc::new(5));\n    ///\n    /// let _ = Weak::clone(&weak_five);\n    /// ```\n    #[inline]\n    fn clone(&self) -> Weak<T> {\n        if let Some(inner) = self.inner() {\n            inner.inc_weak()\n        }\n        Weak { ptr: self.ptr }\n    }\n}\n\n#[stable(feature = \"rc_weak\", since = \"1.4.0\")]\nimpl<T: ?Sized + fmt::Debug> fmt::Debug for Weak<T> {\n    fn fmt(&self, f: &mut fmt::Formatter<'_>) -> fmt::Result {\n        write!(f, \"(Weak)\")\n    }\n}\n\n#[stable(feature = \"downgraded_weak\", since = \"1.10.0\")]\nimpl<T> Default for Weak<T> {\n    /// Constructs a new `Weak<T>`, without allocating any memory.\n    /// Calling [`upgrade`] on the return value always gives [`None`].\n    ///\n    /// [`None`]: Option\n    /// [`upgrade`]: Weak::upgrade\n    ///\n    /// # Examples\n    ///\n    /// ```\n    /// use std::rc::Weak;\n    ///\n    /// let empty: Weak<i64> = Default::default();\n    /// assert!(empty.upgrade().is_none());\n    /// ```\n    fn default() -> Weak<T> {\n        Weak::new()\n    }\n}\n\n// NOTE: We checked_add here to deal with mem::forget safely. In particular\n// if you mem::forget Rcs (or Weaks), the ref-count can overflow, and then\n// you can free the allocation while outstanding Rcs (or Weaks) exist.\n// We abort because this is such a degenerate scenario that we don't care about\n// what happens -- no real program should ever experience this.\n//\n// This should have negligible overhead since you don't actually need to\n// clone these much in Rust thanks to ownership and move-semantics.\n\n#[doc(hidden)]\ntrait RcInnerPtr {\n    fn weak_ref(&self) -> &Cell<usize>;\n    fn strong_ref(&self) -> &Cell<usize>;\n\n    #[inline]\n    fn strong(&self) -> usize {\n        self.strong_ref().get()\n    }\n\n    #[inline]\n    fn inc_strong(&self) {\n        let strong = self.strong();\n\n        // We want to abort on overflow instead of dropping the value.\n        // The reference count will never be zero when this is called;\n        // nevertheless, we insert an abort here to hint LLVM at\n        // an otherwise missed optimization.\n        if strong == 0 || strong == usize::MAX {\n            abort();\n        }\n        self.strong_ref().set(strong + 1);\n    }\n\n    #[inline]\n    fn dec_strong(&self) {\n        self.strong_ref().set(self.strong() - 1);\n    }\n\n    #[inline]\n    fn weak(&self) -> usize {\n        self.weak_ref().get()\n    }\n\n    #[inline]\n    fn inc_weak(&self) {\n        let weak = self.weak();\n\n        // We want to abort on overflow instead of dropping the value.\n        // The reference count will never be zero when this is called;\n        // nevertheless, we insert an abort here to hint LLVM at\n        // an otherwise missed optimization.\n        if weak == 0 || weak == usize::MAX {\n            abort();\n        }\n        self.weak_ref().set(weak + 1);\n    }\n\n    #[inline]\n    fn dec_weak(&self) {\n        self.weak_ref().set(self.weak() - 1);\n    }\n}\n\nimpl<T: ?Sized> RcInnerPtr for RcBox<T> {\n    #[inline(always)]\n    fn weak_ref(&self) -> &Cell<usize> {\n        &self.weak\n    }\n\n    #[inline(always)]\n    fn strong_ref(&self) -> &Cell<usize> {\n        &self.strong\n    }\n}\n\nimpl<'a> RcInnerPtr for WeakInner<'a> {\n    #[inline(always)]\n    fn weak_ref(&self) -> &Cell<usize> {\n        self.weak\n    }\n\n    #[inline(always)]\n    fn strong_ref(&self) -> &Cell<usize> {\n        self.strong\n    }\n}\n\n#[stable(feature = \"rust1\", since = \"1.0.0\")]\nimpl<T: ?Sized> borrow::Borrow<T> for Rc<T> {\n    fn borrow(&self) -> &T {\n        &**self\n    }\n}\n\n#[stable(since = \"1.5.0\", feature = \"smart_ptr_as_ref\")]\nimpl<T: ?Sized> AsRef<T> for Rc<T> {\n    fn as_ref(&self) -> &T {\n        &**self\n    }\n}\n\n#[stable(feature = \"pin\", since = \"1.33.0\")]\nimpl<T: ?Sized> Unpin for Rc<T> {}\n\n/// Get the offset within an `RcBox` for the payload behind a pointer.\n///\n/// # Safety\n///\n/// The pointer must point to (and have valid metadata for) a previously\n/// valid instance of T, but the T is allowed to be dropped.\nunsafe fn data_offset<T: ?Sized>(ptr: *const T) -> isize {\n    // Align the unsized value to the end of the RcBox.\n    // Because RcBox is repr(C), it will always be the last field in memory.\n    // SAFETY: since the only unsized types possible are slices, trait objects,\n    // and extern types, the input safety requirement is currently enough to\n    // satisfy the requirements of align_of_val_raw; this is an implementation\n    // detail of the language that may not be relied upon outside of std.\n    unsafe { data_offset_align(align_of_val_raw(ptr)) }\n}\n\n#[inline]\nfn data_offset_align(align: usize) -> isize {\n    let layout = Layout::new::<RcBox<()>>();\n    (layout.size() + layout.padding_needed_for(align)) as isize\n}\n"],[2012,"//! A UTF-8–encoded, growable string.\n//!\n//! This module contains the [`String`] type, the [`ToString`] trait for\n//! converting to strings, and several error types that may result from\n//! working with [`String`]s.\n//!\n//! # Examples\n//!\n//! There are multiple ways to create a new [`String`] from a string literal:\n//!\n//! ```\n//! let s = \"Hello\".to_string();\n//!\n//! let s = String::from(\"world\");\n//! let s: String = \"also this\".into();\n//! ```\n//!\n//! You can create a new [`String`] from an existing one by concatenating with\n//! `+`:\n//!\n//! ```\n//! let s = \"Hello\".to_string();\n//!\n//! let message = s + \" world!\";\n//! ```\n//!\n//! If you have a vector of valid UTF-8 bytes, you can make a [`String`] out of\n//! it. You can do the reverse too.\n//!\n//! ```\n//! let sparkle_heart = vec![240, 159, 146, 150];\n//!\n//! // We know these bytes are valid, so we'll use `unwrap()`.\n//! let sparkle_heart = String::from_utf8(sparkle_heart).unwrap();\n//!\n//! assert_eq!(\"💖\", sparkle_heart);\n//!\n//! let bytes = sparkle_heart.into_bytes();\n//!\n//! assert_eq!(bytes, [240, 159, 146, 150]);\n//! ```\n\n#![stable(feature = \"rust1\", since = \"1.0.0\")]\n\n#[cfg(not(no_global_oom_handling))]\nuse core::char::{decode_utf16, REPLACEMENT_CHARACTER};\nuse core::fmt;\nuse core::hash;\n#[cfg(not(no_global_oom_handling))]\nuse core::iter::FromIterator;\nuse core::iter::{from_fn, FusedIterator};\n#[cfg(not(no_global_oom_handling))]\nuse core::ops::Add;\n#[cfg(not(no_global_oom_handling))]\nuse core::ops::AddAssign;\n#[cfg(not(no_global_oom_handling))]\nuse core::ops::Bound::{Excluded, Included, Unbounded};\nuse core::ops::{self, Index, IndexMut, Range, RangeBounds};\nuse core::ptr;\nuse core::slice;\n#[cfg(not(no_global_oom_handling))]\nuse core::str::lossy;\nuse core::str::pattern::Pattern;\n\n#[cfg(not(no_global_oom_handling))]\nuse crate::borrow::{Cow, ToOwned};\nuse crate::boxed::Box;\nuse crate::collections::TryReserveError;\nuse crate::str::{self, Chars, Utf8Error};\n#[cfg(not(no_global_oom_handling))]\nuse crate::str::{from_boxed_utf8_unchecked, FromStr};\nuse crate::vec::Vec;\n\n/// A UTF-8–encoded, growable string.\n///\n/// The `String` type is the most common string type that has ownership over the\n/// contents of the string. It has a close relationship with its borrowed\n/// counterpart, the primitive [`str`].\n///\n/// # Examples\n///\n/// You can create a `String` from [a literal string][`str`] with [`String::from`]:\n///\n/// [`String::from`]: From::from\n///\n/// ```\n/// let hello = String::from(\"Hello, world!\");\n/// ```\n///\n/// You can append a [`char`] to a `String` with the [`push`] method, and\n/// append a [`&str`] with the [`push_str`] method:\n///\n/// ```\n/// let mut hello = String::from(\"Hello, \");\n///\n/// hello.push('w');\n/// hello.push_str(\"orld!\");\n/// ```\n///\n/// [`push`]: String::push\n/// [`push_str`]: String::push_str\n///\n/// If you have a vector of UTF-8 bytes, you can create a `String` from it with\n/// the [`from_utf8`] method:\n///\n/// ```\n/// // some bytes, in a vector\n/// let sparkle_heart = vec![240, 159, 146, 150];\n///\n/// // We know these bytes are valid, so we'll use `unwrap()`.\n/// let sparkle_heart = String::from_utf8(sparkle_heart).unwrap();\n///\n/// assert_eq!(\"💖\", sparkle_heart);\n/// ```\n///\n/// [`from_utf8`]: String::from_utf8\n///\n/// # UTF-8\n///\n/// `String`s are always valid UTF-8. This has a few implications, the first of\n/// which is that if you need a non-UTF-8 string, consider [`OsString`]. It is\n/// similar, but without the UTF-8 constraint. The second implication is that\n/// you cannot index into a `String`:\n///\n/// ```compile_fail,E0277\n/// let s = \"hello\";\n///\n/// println!(\"The first letter of s is {}\", s[0]); // ERROR!!!\n/// ```\n///\n/// [`OsString`]: ../../std/ffi/struct.OsString.html\n///\n/// Indexing is intended to be a constant-time operation, but UTF-8 encoding\n/// does not allow us to do this. Furthermore, it's not clear what sort of\n/// thing the index should return: a byte, a codepoint, or a grapheme cluster.\n/// The [`bytes`] and [`chars`] methods return iterators over the first\n/// two, respectively.\n///\n/// [`bytes`]: str::bytes\n/// [`chars`]: str::chars\n///\n/// # Deref\n///\n/// `String`s implement [`Deref`]`<Target=str>`, and so inherit all of [`str`]'s\n/// methods. In addition, this means that you can pass a `String` to a\n/// function which takes a [`&str`] by using an ampersand (`&`):\n///\n/// ```\n/// fn takes_str(s: &str) { }\n///\n/// let s = String::from(\"Hello\");\n///\n/// takes_str(&s);\n/// ```\n///\n/// This will create a [`&str`] from the `String` and pass it in. This\n/// conversion is very inexpensive, and so generally, functions will accept\n/// [`&str`]s as arguments unless they need a `String` for some specific\n/// reason.\n///\n/// In certain cases Rust doesn't have enough information to make this\n/// conversion, known as [`Deref`] coercion. In the following example a string\n/// slice [`&'a str`][`&str`] implements the trait `TraitExample`, and the function\n/// `example_func` takes anything that implements the trait. In this case Rust\n/// would need to make two implicit conversions, which Rust doesn't have the\n/// means to do. For that reason, the following example will not compile.\n///\n/// ```compile_fail,E0277\n/// trait TraitExample {}\n///\n/// impl<'a> TraitExample for &'a str {}\n///\n/// fn example_func<A: TraitExample>(example_arg: A) {}\n///\n/// let example_string = String::from(\"example_string\");\n/// example_func(&example_string);\n/// ```\n///\n/// There are two options that would work instead. The first would be to\n/// change the line `example_func(&example_string);` to\n/// `example_func(example_string.as_str());`, using the method [`as_str()`]\n/// to explicitly extract the string slice containing the string. The second\n/// way changes `example_func(&example_string);` to\n/// `example_func(&*example_string);`. In this case we are dereferencing a\n/// `String` to a [`str`][`&str`], then referencing the [`str`][`&str`] back to\n/// [`&str`]. The second way is more idiomatic, however both work to do the\n/// conversion explicitly rather than relying on the implicit conversion.\n///\n/// # Representation\n///\n/// A `String` is made up of three components: a pointer to some bytes, a\n/// length, and a capacity. The pointer points to an internal buffer `String`\n/// uses to store its data. The length is the number of bytes currently stored\n/// in the buffer, and the capacity is the size of the buffer in bytes. As such,\n/// the length will always be less than or equal to the capacity.\n///\n/// This buffer is always stored on the heap.\n///\n/// You can look at these with the [`as_ptr`], [`len`], and [`capacity`]\n/// methods:\n///\n/// ```\n/// use std::mem;\n///\n/// let story = String::from(\"Once upon a time...\");\n///\n// FIXME Update this when vec_into_raw_parts is stabilized\n/// // Prevent automatically dropping the String's data\n/// let mut story = mem::ManuallyDrop::new(story);\n///\n/// let ptr = story.as_mut_ptr();\n/// let len = story.len();\n/// let capacity = story.capacity();\n///\n/// // story has nineteen bytes\n/// assert_eq!(19, len);\n///\n/// // We can re-build a String out of ptr, len, and capacity. This is all\n/// // unsafe because we are responsible for making sure the components are\n/// // valid:\n/// let s = unsafe { String::from_raw_parts(ptr, len, capacity) } ;\n///\n/// assert_eq!(String::from(\"Once upon a time...\"), s);\n/// ```\n///\n/// [`as_ptr`]: str::as_ptr\n/// [`len`]: String::len\n/// [`capacity`]: String::capacity\n///\n/// If a `String` has enough capacity, adding elements to it will not\n/// re-allocate. For example, consider this program:\n///\n/// ```\n/// let mut s = String::new();\n///\n/// println!(\"{}\", s.capacity());\n///\n/// for _ in 0..5 {\n///     s.push_str(\"hello\");\n///     println!(\"{}\", s.capacity());\n/// }\n/// ```\n///\n/// This will output the following:\n///\n/// ```text\n/// 0\n/// 5\n/// 10\n/// 20\n/// 20\n/// 40\n/// ```\n///\n/// At first, we have no memory allocated at all, but as we append to the\n/// string, it increases its capacity appropriately. If we instead use the\n/// [`with_capacity`] method to allocate the correct capacity initially:\n///\n/// ```\n/// let mut s = String::with_capacity(25);\n///\n/// println!(\"{}\", s.capacity());\n///\n/// for _ in 0..5 {\n///     s.push_str(\"hello\");\n///     println!(\"{}\", s.capacity());\n/// }\n/// ```\n///\n/// [`with_capacity`]: String::with_capacity\n///\n/// We end up with a different output:\n///\n/// ```text\n/// 25\n/// 25\n/// 25\n/// 25\n/// 25\n/// 25\n/// ```\n///\n/// Here, there's no need to allocate more memory inside the loop.\n///\n/// [`str`]: prim@str\n/// [`&str`]: prim@str\n/// [`Deref`]: core::ops::Deref\n/// [`as_str()`]: String::as_str\n#[derive(PartialOrd, Eq, Ord)]\n#[cfg_attr(not(test), rustc_diagnostic_item = \"string_type\")]\n#[stable(feature = \"rust1\", since = \"1.0.0\")]\npub struct String {\n    vec: Vec<u8>,\n}\n\n/// A possible error value when converting a `String` from a UTF-8 byte vector.\n///\n/// This type is the error type for the [`from_utf8`] method on [`String`]. It\n/// is designed in such a way to carefully avoid reallocations: the\n/// [`into_bytes`] method will give back the byte vector that was used in the\n/// conversion attempt.\n///\n/// [`from_utf8`]: String::from_utf8\n/// [`into_bytes`]: FromUtf8Error::into_bytes\n///\n/// The [`Utf8Error`] type provided by [`std::str`] represents an error that may\n/// occur when converting a slice of [`u8`]s to a [`&str`]. In this sense, it's\n/// an analogue to `FromUtf8Error`, and you can get one from a `FromUtf8Error`\n/// through the [`utf8_error`] method.\n///\n/// [`Utf8Error`]: core::str::Utf8Error\n/// [`std::str`]: core::str\n/// [`&str`]: prim@str\n/// [`utf8_error`]: Self::utf8_error\n///\n/// # Examples\n///\n/// Basic usage:\n///\n/// ```\n/// // some invalid bytes, in a vector\n/// let bytes = vec![0, 159];\n///\n/// let value = String::from_utf8(bytes);\n///\n/// assert!(value.is_err());\n/// assert_eq!(vec![0, 159], value.unwrap_err().into_bytes());\n/// ```\n#[stable(feature = \"rust1\", since = \"1.0.0\")]\n#[cfg_attr(not(no_global_oom_handling), derive(Clone))]\n#[derive(Debug, PartialEq, Eq)]\npub struct FromUtf8Error {\n    bytes: Vec<u8>,\n    error: Utf8Error,\n}\n\n/// A possible error value when converting a `String` from a UTF-16 byte slice.\n///\n/// This type is the error type for the [`from_utf16`] method on [`String`].\n///\n/// [`from_utf16`]: String::from_utf16\n/// # Examples\n///\n/// Basic usage:\n///\n/// ```\n/// // 𝄞mu<invalid>ic\n/// let v = &[0xD834, 0xDD1E, 0x006d, 0x0075,\n///           0xD800, 0x0069, 0x0063];\n///\n/// assert!(String::from_utf16(v).is_err());\n/// ```\n#[stable(feature = \"rust1\", since = \"1.0.0\")]\n#[derive(Debug)]\npub struct FromUtf16Error(());\n\nimpl String {\n    /// Creates a new empty `String`.\n    ///\n    /// Given that the `String` is empty, this will not allocate any initial\n    /// buffer. While that means that this initial operation is very\n    /// inexpensive, it may cause excessive allocation later when you add\n    /// data. If you have an idea of how much data the `String` will hold,\n    /// consider the [`with_capacity`] method to prevent excessive\n    /// re-allocation.\n    ///\n    /// [`with_capacity`]: String::with_capacity\n    ///\n    /// # Examples\n    ///\n    /// Basic usage:\n    ///\n    /// ```\n    /// let s = String::new();\n    /// ```\n    #[inline]\n    #[rustc_const_stable(feature = \"const_string_new\", since = \"1.39.0\")]\n    #[stable(feature = \"rust1\", since = \"1.0.0\")]\n    pub const fn new() -> String {\n        String { vec: Vec::new() }\n    }\n\n    /// Creates a new empty `String` with a particular capacity.\n    ///\n    /// `String`s have an internal buffer to hold their data. The capacity is\n    /// the length of that buffer, and can be queried with the [`capacity`]\n    /// method. This method creates an empty `String`, but one with an initial\n    /// buffer that can hold `capacity` bytes. This is useful when you may be\n    /// appending a bunch of data to the `String`, reducing the number of\n    /// reallocations it needs to do.\n    ///\n    /// [`capacity`]: String::capacity\n    ///\n    /// If the given capacity is `0`, no allocation will occur, and this method\n    /// is identical to the [`new`] method.\n    ///\n    /// [`new`]: String::new\n    ///\n    /// # Examples\n    ///\n    /// Basic usage:\n    ///\n    /// ```\n    /// let mut s = String::with_capacity(10);\n    ///\n    /// // The String contains no chars, even though it has capacity for more\n    /// assert_eq!(s.len(), 0);\n    ///\n    /// // These are all done without reallocating...\n    /// let cap = s.capacity();\n    /// for _ in 0..10 {\n    ///     s.push('a');\n    /// }\n    ///\n    /// assert_eq!(s.capacity(), cap);\n    ///\n    /// // ...but this may make the string reallocate\n    /// s.push('a');\n    /// ```\n    #[cfg(not(no_global_oom_handling))]\n    #[inline]\n    #[doc(alias = \"alloc\")]\n    #[doc(alias = \"malloc\")]\n    #[stable(feature = \"rust1\", since = \"1.0.0\")]\n    pub fn with_capacity(capacity: usize) -> String {\n        String { vec: Vec::with_capacity(capacity) }\n    }\n\n    // HACK(japaric): with cfg(test) the inherent `[T]::to_vec` method, which is\n    // required for this method definition, is not available. Since we don't\n    // require this method for testing purposes, I'll just stub it\n    // NB see the slice::hack module in slice.rs for more information\n    #[inline]\n    #[cfg(test)]\n    pub fn from_str(_: &str) -> String {\n        panic!(\"not available with cfg(test)\");\n    }\n\n    /// Converts a vector of bytes to a `String`.\n    ///\n    /// A string ([`String`]) is made of bytes ([`u8`]), and a vector of bytes\n    /// ([`Vec<u8>`]) is made of bytes, so this function converts between the\n    /// two. Not all byte slices are valid `String`s, however: `String`\n    /// requires that it is valid UTF-8. `from_utf8()` checks to ensure that\n    /// the bytes are valid UTF-8, and then does the conversion.\n    ///\n    /// If you are sure that the byte slice is valid UTF-8, and you don't want\n    /// to incur the overhead of the validity check, there is an unsafe version\n    /// of this function, [`from_utf8_unchecked`], which has the same behavior\n    /// but skips the check.\n    ///\n    /// This method will take care to not copy the vector, for efficiency's\n    /// sake.\n    ///\n    /// If you need a [`&str`] instead of a `String`, consider\n    /// [`str::from_utf8`].\n    ///\n    /// The inverse of this method is [`into_bytes`].\n    ///\n    /// # Errors\n    ///\n    /// Returns [`Err`] if the slice is not UTF-8 with a description as to why the\n    /// provided bytes are not UTF-8. The vector you moved in is also included.\n    ///\n    /// # Examples\n    ///\n    /// Basic usage:\n    ///\n    /// ```\n    /// // some bytes, in a vector\n    /// let sparkle_heart = vec![240, 159, 146, 150];\n    ///\n    /// // We know these bytes are valid, so we'll use `unwrap()`.\n    /// let sparkle_heart = String::from_utf8(sparkle_heart).unwrap();\n    ///\n    /// assert_eq!(\"💖\", sparkle_heart);\n    /// ```\n    ///\n    /// Incorrect bytes:\n    ///\n    /// ```\n    /// // some invalid bytes, in a vector\n    /// let sparkle_heart = vec![0, 159, 146, 150];\n    ///\n    /// assert!(String::from_utf8(sparkle_heart).is_err());\n    /// ```\n    ///\n    /// See the docs for [`FromUtf8Error`] for more details on what you can do\n    /// with this error.\n    ///\n    /// [`from_utf8_unchecked`]: String::from_utf8_unchecked\n    /// [`Vec<u8>`]: crate::vec::Vec\n    /// [`&str`]: prim@str\n    /// [`into_bytes`]: String::into_bytes\n    #[inline]\n    #[stable(feature = \"rust1\", since = \"1.0.0\")]\n    pub fn from_utf8(vec: Vec<u8>) -> Result<String, FromUtf8Error> {\n        match str::from_utf8(&vec) {\n            Ok(..) => Ok(String { vec }),\n            Err(e) => Err(FromUtf8Error { bytes: vec, error: e }),\n        }\n    }\n\n    /// Converts a slice of bytes to a string, including invalid characters.\n    ///\n    /// Strings are made of bytes ([`u8`]), and a slice of bytes\n    /// ([`&[u8]`][byteslice]) is made of bytes, so this function converts\n    /// between the two. Not all byte slices are valid strings, however: strings\n    /// are required to be valid UTF-8. During this conversion,\n    /// `from_utf8_lossy()` will replace any invalid UTF-8 sequences with\n    /// [`U+FFFD REPLACEMENT CHARACTER`][U+FFFD], which looks like this: �\n    ///\n    /// [byteslice]: prim@slice\n    /// [U+FFFD]: core::char::REPLACEMENT_CHARACTER\n    ///\n    /// If you are sure that the byte slice is valid UTF-8, and you don't want\n    /// to incur the overhead of the conversion, there is an unsafe version\n    /// of this function, [`from_utf8_unchecked`], which has the same behavior\n    /// but skips the checks.\n    ///\n    /// [`from_utf8_unchecked`]: String::from_utf8_unchecked\n    ///\n    /// This function returns a [`Cow<'a, str>`]. If our byte slice is invalid\n    /// UTF-8, then we need to insert the replacement characters, which will\n    /// change the size of the string, and hence, require a `String`. But if\n    /// it's already valid UTF-8, we don't need a new allocation. This return\n    /// type allows us to handle both cases.\n    ///\n    /// [`Cow<'a, str>`]: crate::borrow::Cow\n    ///\n    /// # Examples\n    ///\n    /// Basic usage:\n    ///\n    /// ```\n    /// // some bytes, in a vector\n    /// let sparkle_heart = vec![240, 159, 146, 150];\n    ///\n    /// let sparkle_heart = String::from_utf8_lossy(&sparkle_heart);\n    ///\n    /// assert_eq!(\"💖\", sparkle_heart);\n    /// ```\n    ///\n    /// Incorrect bytes:\n    ///\n    /// ```\n    /// // some invalid bytes\n    /// let input = b\"Hello \\xF0\\x90\\x80World\";\n    /// let output = String::from_utf8_lossy(input);\n    ///\n    /// assert_eq!(\"Hello �World\", output);\n    /// ```\n    #[cfg(not(no_global_oom_handling))]\n    #[stable(feature = \"rust1\", since = \"1.0.0\")]\n    pub fn from_utf8_lossy(v: &[u8]) -> Cow<'_, str> {\n        let mut iter = lossy::Utf8Lossy::from_bytes(v).chunks();\n\n        let (first_valid, first_broken) = if let Some(chunk) = iter.next() {\n            let lossy::Utf8LossyChunk { valid, broken } = chunk;\n            if valid.len() == v.len() {\n                debug_assert!(broken.is_empty());\n                return Cow::Borrowed(valid);\n            }\n            (valid, broken)\n        } else {\n            return Cow::Borrowed(\"\");\n        };\n\n        const REPLACEMENT: &str = \"\\u{FFFD}\";\n\n        let mut res = String::with_capacity(v.len());\n        res.push_str(first_valid);\n        if !first_broken.is_empty() {\n            res.push_str(REPLACEMENT);\n        }\n\n        for lossy::Utf8LossyChunk { valid, broken } in iter {\n            res.push_str(valid);\n            if !broken.is_empty() {\n                res.push_str(REPLACEMENT);\n            }\n        }\n\n        Cow::Owned(res)\n    }\n\n    /// Decode a UTF-16–encoded vector `v` into a `String`, returning [`Err`]\n    /// if `v` contains any invalid data.\n    ///\n    /// # Examples\n    ///\n    /// Basic usage:\n    ///\n    /// ```\n    /// // 𝄞music\n    /// let v = &[0xD834, 0xDD1E, 0x006d, 0x0075,\n    ///           0x0073, 0x0069, 0x0063];\n    /// assert_eq!(String::from(\"𝄞music\"),\n    ///            String::from_utf16(v).unwrap());\n    ///\n    /// // 𝄞mu<invalid>ic\n    /// let v = &[0xD834, 0xDD1E, 0x006d, 0x0075,\n    ///           0xD800, 0x0069, 0x0063];\n    /// assert!(String::from_utf16(v).is_err());\n    /// ```\n    #[cfg(not(no_global_oom_handling))]\n    #[stable(feature = \"rust1\", since = \"1.0.0\")]\n    pub fn from_utf16(v: &[u16]) -> Result<String, FromUtf16Error> {\n        // This isn't done via collect::<Result<_, _>>() for performance reasons.\n        // FIXME: the function can be simplified again when #48994 is closed.\n        let mut ret = String::with_capacity(v.len());\n        for c in decode_utf16(v.iter().cloned()) {\n            if let Ok(c) = c {\n                ret.push(c);\n            } else {\n                return Err(FromUtf16Error(()));\n            }\n        }\n        Ok(ret)\n    }\n\n    /// Decode a UTF-16–encoded slice `v` into a `String`, replacing\n    /// invalid data with [the replacement character (`U+FFFD`)][U+FFFD].\n    ///\n    /// Unlike [`from_utf8_lossy`] which returns a [`Cow<'a, str>`],\n    /// `from_utf16_lossy` returns a `String` since the UTF-16 to UTF-8\n    /// conversion requires a memory allocation.\n    ///\n    /// [`from_utf8_lossy`]: String::from_utf8_lossy\n    /// [`Cow<'a, str>`]: crate::borrow::Cow\n    /// [U+FFFD]: core::char::REPLACEMENT_CHARACTER\n    ///\n    /// # Examples\n    ///\n    /// Basic usage:\n    ///\n    /// ```\n    /// // 𝄞mus<invalid>ic<invalid>\n    /// let v = &[0xD834, 0xDD1E, 0x006d, 0x0075,\n    ///           0x0073, 0xDD1E, 0x0069, 0x0063,\n    ///           0xD834];\n    ///\n    /// assert_eq!(String::from(\"𝄞mus\\u{FFFD}ic\\u{FFFD}\"),\n    ///            String::from_utf16_lossy(v));\n    /// ```\n    #[cfg(not(no_global_oom_handling))]\n    #[inline]\n    #[stable(feature = \"rust1\", since = \"1.0.0\")]\n    pub fn from_utf16_lossy(v: &[u16]) -> String {\n        decode_utf16(v.iter().cloned()).map(|r| r.unwrap_or(REPLACEMENT_CHARACTER)).collect()\n    }\n\n    /// Decomposes a `String` into its raw components.\n    ///\n    /// Returns the raw pointer to the underlying data, the length of\n    /// the string (in bytes), and the allocated capacity of the data\n    /// (in bytes). These are the same arguments in the same order as\n    /// the arguments to [`from_raw_parts`].\n    ///\n    /// After calling this function, the caller is responsible for the\n    /// memory previously managed by the `String`. The only way to do\n    /// this is to convert the raw pointer, length, and capacity back\n    /// into a `String` with the [`from_raw_parts`] function, allowing\n    /// the destructor to perform the cleanup.\n    ///\n    /// [`from_raw_parts`]: String::from_raw_parts\n    ///\n    /// # Examples\n    ///\n    /// ```\n    /// #![feature(vec_into_raw_parts)]\n    /// let s = String::from(\"hello\");\n    ///\n    /// let (ptr, len, cap) = s.into_raw_parts();\n    ///\n    /// let rebuilt = unsafe { String::from_raw_parts(ptr, len, cap) };\n    /// assert_eq!(rebuilt, \"hello\");\n    /// ```\n    #[unstable(feature = \"vec_into_raw_parts\", reason = \"new API\", issue = \"65816\")]\n    pub fn into_raw_parts(self) -> (*mut u8, usize, usize) {\n        self.vec.into_raw_parts()\n    }\n\n    /// Creates a new `String` from a length, capacity, and pointer.\n    ///\n    /// # Safety\n    ///\n    /// This is highly unsafe, due to the number of invariants that aren't\n    /// checked:\n    ///\n    /// * The memory at `buf` needs to have been previously allocated by the\n    ///   same allocator the standard library uses, with a required alignment of exactly 1.\n    /// * `length` needs to be less than or equal to `capacity`.\n    /// * `capacity` needs to be the correct value.\n    /// * The first `length` bytes at `buf` need to be valid UTF-8.\n    ///\n    /// Violating these may cause problems like corrupting the allocator's\n    /// internal data structures.\n    ///\n    /// The ownership of `buf` is effectively transferred to the\n    /// `String` which may then deallocate, reallocate or change the\n    /// contents of memory pointed to by the pointer at will. Ensure\n    /// that nothing else uses the pointer after calling this\n    /// function.\n    ///\n    /// # Examples\n    ///\n    /// Basic usage:\n    ///\n    /// ```\n    /// use std::mem;\n    ///\n    /// unsafe {\n    ///     let s = String::from(\"hello\");\n    ///\n    // FIXME Update this when vec_into_raw_parts is stabilized\n    ///     // Prevent automatically dropping the String's data\n    ///     let mut s = mem::ManuallyDrop::new(s);\n    ///\n    ///     let ptr = s.as_mut_ptr();\n    ///     let len = s.len();\n    ///     let capacity = s.capacity();\n    ///\n    ///     let s = String::from_raw_parts(ptr, len, capacity);\n    ///\n    ///     assert_eq!(String::from(\"hello\"), s);\n    /// }\n    /// ```\n    #[inline]\n    #[stable(feature = \"rust1\", since = \"1.0.0\")]\n    pub unsafe fn from_raw_parts(buf: *mut u8, length: usize, capacity: usize) -> String {\n        unsafe { String { vec: Vec::from_raw_parts(buf, length, capacity) } }\n    }\n\n    /// Converts a vector of bytes to a `String` without checking that the\n    /// string contains valid UTF-8.\n    ///\n    /// See the safe version, [`from_utf8`], for more details.\n    ///\n    /// [`from_utf8`]: String::from_utf8\n    ///\n    /// # Safety\n    ///\n    /// This function is unsafe because it does not check that the bytes passed\n    /// to it are valid UTF-8. If this constraint is violated, it may cause\n    /// memory unsafety issues with future users of the `String`, as the rest of\n    /// the standard library assumes that `String`s are valid UTF-8.\n    ///\n    /// # Examples\n    ///\n    /// Basic usage:\n    ///\n    /// ```\n    /// // some bytes, in a vector\n    /// let sparkle_heart = vec![240, 159, 146, 150];\n    ///\n    /// let sparkle_heart = unsafe {\n    ///     String::from_utf8_unchecked(sparkle_heart)\n    /// };\n    ///\n    /// assert_eq!(\"💖\", sparkle_heart);\n    /// ```\n    #[inline]\n    #[stable(feature = \"rust1\", since = \"1.0.0\")]\n    pub unsafe fn from_utf8_unchecked(bytes: Vec<u8>) -> String {\n        String { vec: bytes }\n    }\n\n    /// Converts a `String` into a byte vector.\n    ///\n    /// This consumes the `String`, so we do not need to copy its contents.\n    ///\n    /// # Examples\n    ///\n    /// Basic usage:\n    ///\n    /// ```\n    /// let s = String::from(\"hello\");\n    /// let bytes = s.into_bytes();\n    ///\n    /// assert_eq!(&[104, 101, 108, 108, 111][..], &bytes[..]);\n    /// ```\n    #[inline]\n    #[stable(feature = \"rust1\", since = \"1.0.0\")]\n    pub fn into_bytes(self) -> Vec<u8> {\n        self.vec\n    }\n\n    /// Extracts a string slice containing the entire `String`.\n    ///\n    /// # Examples\n    ///\n    /// Basic usage:\n    ///\n    /// ```\n    /// let s = String::from(\"foo\");\n    ///\n    /// assert_eq!(\"foo\", s.as_str());\n    /// ```\n    #[inline]\n    #[stable(feature = \"string_as_str\", since = \"1.7.0\")]\n    pub fn as_str(&self) -> &str {\n        self\n    }\n\n    /// Converts a `String` into a mutable string slice.\n    ///\n    /// # Examples\n    ///\n    /// Basic usage:\n    ///\n    /// ```\n    /// let mut s = String::from(\"foobar\");\n    /// let s_mut_str = s.as_mut_str();\n    ///\n    /// s_mut_str.make_ascii_uppercase();\n    ///\n    /// assert_eq!(\"FOOBAR\", s_mut_str);\n    /// ```\n    #[inline]\n    #[stable(feature = \"string_as_str\", since = \"1.7.0\")]\n    pub fn as_mut_str(&mut self) -> &mut str {\n        self\n    }\n\n    /// Appends a given string slice onto the end of this `String`.\n    ///\n    /// # Examples\n    ///\n    /// Basic usage:\n    ///\n    /// ```\n    /// let mut s = String::from(\"foo\");\n    ///\n    /// s.push_str(\"bar\");\n    ///\n    /// assert_eq!(\"foobar\", s);\n    /// ```\n    #[cfg(not(no_global_oom_handling))]\n    #[inline]\n    #[stable(feature = \"rust1\", since = \"1.0.0\")]\n    pub fn push_str(&mut self, string: &str) {\n        self.vec.extend_from_slice(string.as_bytes())\n    }\n\n    /// Copies elements from `src` range to the end of the string.\n    ///\n    /// ## Panics\n    ///\n    /// Panics if the starting point or end point do not lie on a [`char`]\n    /// boundary, or if they're out of bounds.\n    ///\n    /// ## Examples\n    ///\n    /// ```\n    /// #![feature(string_extend_from_within)]\n    /// let mut string = String::from(\"abcde\");\n    ///\n    /// string.extend_from_within(2..);\n    /// assert_eq!(string, \"abcdecde\");\n    ///\n    /// string.extend_from_within(..2);\n    /// assert_eq!(string, \"abcdecdeab\");\n    ///\n    /// string.extend_from_within(4..8);\n    /// assert_eq!(string, \"abcdecdeabecde\");\n    /// ```\n    #[cfg(not(no_global_oom_handling))]\n    #[unstable(feature = \"string_extend_from_within\", issue = \"none\")]\n    pub fn extend_from_within<R>(&mut self, src: R)\n    where\n        R: RangeBounds<usize>,\n    {\n        let src @ Range { start, end } = slice::range(src, ..self.len());\n\n        assert!(self.is_char_boundary(start));\n        assert!(self.is_char_boundary(end));\n\n        self.vec.extend_from_within(src);\n    }\n\n    /// Returns this `String`'s capacity, in bytes.\n    ///\n    /// # Examples\n    ///\n    /// Basic usage:\n    ///\n    /// ```\n    /// let s = String::with_capacity(10);\n    ///\n    /// assert!(s.capacity() >= 10);\n    /// ```\n    #[inline]\n    #[stable(feature = \"rust1\", since = \"1.0.0\")]\n    pub fn capacity(&self) -> usize {\n        self.vec.capacity()\n    }\n\n    /// Ensures that this `String`'s capacity is at least `additional` bytes\n    /// larger than its length.\n    ///\n    /// The capacity may be increased by more than `additional` bytes if it\n    /// chooses, to prevent frequent reallocations.\n    ///\n    /// If you do not want this \"at least\" behavior, see the [`reserve_exact`]\n    /// method.\n    ///\n    /// # Panics\n    ///\n    /// Panics if the new capacity overflows [`usize`].\n    ///\n    /// [`reserve_exact`]: String::reserve_exact\n    ///\n    /// # Examples\n    ///\n    /// Basic usage:\n    ///\n    /// ```\n    /// let mut s = String::new();\n    ///\n    /// s.reserve(10);\n    ///\n    /// assert!(s.capacity() >= 10);\n    /// ```\n    ///\n    /// This may not actually increase the capacity:\n    ///\n    /// ```\n    /// let mut s = String::with_capacity(10);\n    /// s.push('a');\n    /// s.push('b');\n    ///\n    /// // s now has a length of 2 and a capacity of 10\n    /// assert_eq!(2, s.len());\n    /// assert_eq!(10, s.capacity());\n    ///\n    /// // Since we already have an extra 8 capacity, calling this...\n    /// s.reserve(8);\n    ///\n    /// // ... doesn't actually increase.\n    /// assert_eq!(10, s.capacity());\n    /// ```\n    #[cfg(not(no_global_oom_handling))]\n    #[inline]\n    #[stable(feature = \"rust1\", since = \"1.0.0\")]\n    pub fn reserve(&mut self, additional: usize) {\n        self.vec.reserve(additional)\n    }\n\n    /// Ensures that this `String`'s capacity is `additional` bytes\n    /// larger than its length.\n    ///\n    /// Consider using the [`reserve`] method unless you absolutely know\n    /// better than the allocator.\n    ///\n    /// [`reserve`]: String::reserve\n    ///\n    /// # Panics\n    ///\n    /// Panics if the new capacity overflows `usize`.\n    ///\n    /// # Examples\n    ///\n    /// Basic usage:\n    ///\n    /// ```\n    /// let mut s = String::new();\n    ///\n    /// s.reserve_exact(10);\n    ///\n    /// assert!(s.capacity() >= 10);\n    /// ```\n    ///\n    /// This may not actually increase the capacity:\n    ///\n    /// ```\n    /// let mut s = String::with_capacity(10);\n    /// s.push('a');\n    /// s.push('b');\n    ///\n    /// // s now has a length of 2 and a capacity of 10\n    /// assert_eq!(2, s.len());\n    /// assert_eq!(10, s.capacity());\n    ///\n    /// // Since we already have an extra 8 capacity, calling this...\n    /// s.reserve_exact(8);\n    ///\n    /// // ... doesn't actually increase.\n    /// assert_eq!(10, s.capacity());\n    /// ```\n    #[cfg(not(no_global_oom_handling))]\n    #[inline]\n    #[stable(feature = \"rust1\", since = \"1.0.0\")]\n    pub fn reserve_exact(&mut self, additional: usize) {\n        self.vec.reserve_exact(additional)\n    }\n\n    /// Tries to reserve capacity for at least `additional` more elements to be inserted\n    /// in the given `String`. The collection may reserve more space to avoid\n    /// frequent reallocations. After calling `reserve`, capacity will be\n    /// greater than or equal to `self.len() + additional`. Does nothing if\n    /// capacity is already sufficient.\n    ///\n    /// # Errors\n    ///\n    /// If the capacity overflows, or the allocator reports a failure, then an error\n    /// is returned.\n    ///\n    /// # Examples\n    ///\n    /// ```\n    /// #![feature(try_reserve)]\n    /// use std::collections::TryReserveError;\n    ///\n    /// fn process_data(data: &str) -> Result<String, TryReserveError> {\n    ///     let mut output = String::new();\n    ///\n    ///     // Pre-reserve the memory, exiting if we can't\n    ///     output.try_reserve(data.len())?;\n    ///\n    ///     // Now we know this can't OOM in the middle of our complex work\n    ///     output.push_str(data);\n    ///\n    ///     Ok(output)\n    /// }\n    /// # process_data(\"rust\").expect(\"why is the test harness OOMing on 4 bytes?\");\n    /// ```\n    #[unstable(feature = \"try_reserve\", reason = \"new API\", issue = \"48043\")]\n    pub fn try_reserve(&mut self, additional: usize) -> Result<(), TryReserveError> {\n        self.vec.try_reserve(additional)\n    }\n\n    /// Tries to reserve the minimum capacity for exactly `additional` more elements to\n    /// be inserted in the given `String`. After calling `reserve_exact`,\n    /// capacity will be greater than or equal to `self.len() + additional`.\n    /// Does nothing if the capacity is already sufficient.\n    ///\n    /// Note that the allocator may give the collection more space than it\n    /// requests. Therefore, capacity can not be relied upon to be precisely\n    /// minimal. Prefer `reserve` if future insertions are expected.\n    ///\n    /// # Errors\n    ///\n    /// If the capacity overflows, or the allocator reports a failure, then an error\n    /// is returned.\n    ///\n    /// # Examples\n    ///\n    /// ```\n    /// #![feature(try_reserve)]\n    /// use std::collections::TryReserveError;\n    ///\n    /// fn process_data(data: &str) -> Result<String, TryReserveError> {\n    ///     let mut output = String::new();\n    ///\n    ///     // Pre-reserve the memory, exiting if we can't\n    ///     output.try_reserve(data.len())?;\n    ///\n    ///     // Now we know this can't OOM in the middle of our complex work\n    ///     output.push_str(data);\n    ///\n    ///     Ok(output)\n    /// }\n    /// # process_data(\"rust\").expect(\"why is the test harness OOMing on 4 bytes?\");\n    /// ```\n    #[unstable(feature = \"try_reserve\", reason = \"new API\", issue = \"48043\")]\n    pub fn try_reserve_exact(&mut self, additional: usize) -> Result<(), TryReserveError> {\n        self.vec.try_reserve_exact(additional)\n    }\n\n    /// Shrinks the capacity of this `String` to match its length.\n    ///\n    /// # Examples\n    ///\n    /// Basic usage:\n    ///\n    /// ```\n    /// let mut s = String::from(\"foo\");\n    ///\n    /// s.reserve(100);\n    /// assert!(s.capacity() >= 100);\n    ///\n    /// s.shrink_to_fit();\n    /// assert_eq!(3, s.capacity());\n    /// ```\n    #[cfg(not(no_global_oom_handling))]\n    #[inline]\n    #[stable(feature = \"rust1\", since = \"1.0.0\")]\n    pub fn shrink_to_fit(&mut self) {\n        self.vec.shrink_to_fit()\n    }\n\n    /// Shrinks the capacity of this `String` with a lower bound.\n    ///\n    /// The capacity will remain at least as large as both the length\n    /// and the supplied value.\n    ///\n    /// If the current capacity is less than the lower limit, this is a no-op.\n    ///\n    /// # Examples\n    ///\n    /// ```\n    /// #![feature(shrink_to)]\n    /// let mut s = String::from(\"foo\");\n    ///\n    /// s.reserve(100);\n    /// assert!(s.capacity() >= 100);\n    ///\n    /// s.shrink_to(10);\n    /// assert!(s.capacity() >= 10);\n    /// s.shrink_to(0);\n    /// assert!(s.capacity() >= 3);\n    /// ```\n    #[cfg(not(no_global_oom_handling))]\n    #[inline]\n    #[unstable(feature = \"shrink_to\", reason = \"new API\", issue = \"56431\")]\n    pub fn shrink_to(&mut self, min_capacity: usize) {\n        self.vec.shrink_to(min_capacity)\n    }\n\n    /// Appends the given [`char`] to the end of this `String`.\n    ///\n    /// # Examples\n    ///\n    /// Basic usage:\n    ///\n    /// ```\n    /// let mut s = String::from(\"abc\");\n    ///\n    /// s.push('1');\n    /// s.push('2');\n    /// s.push('3');\n    ///\n    /// assert_eq!(\"abc123\", s);\n    /// ```\n    #[cfg(not(no_global_oom_handling))]\n    #[inline]\n    #[stable(feature = \"rust1\", since = \"1.0.0\")]\n    pub fn push(&mut self, ch: char) {\n        match ch.len_utf8() {\n            1 => self.vec.push(ch as u8),\n            _ => self.vec.extend_from_slice(ch.encode_utf8(&mut [0; 4]).as_bytes()),\n        }\n    }\n\n    /// Returns a byte slice of this `String`'s contents.\n    ///\n    /// The inverse of this method is [`from_utf8`].\n    ///\n    /// [`from_utf8`]: String::from_utf8\n    ///\n    /// # Examples\n    ///\n    /// Basic usage:\n    ///\n    /// ```\n    /// let s = String::from(\"hello\");\n    ///\n    /// assert_eq!(&[104, 101, 108, 108, 111], s.as_bytes());\n    /// ```\n    #[inline]\n    #[stable(feature = \"rust1\", since = \"1.0.0\")]\n    pub fn as_bytes(&self) -> &[u8] {\n        &self.vec\n    }\n\n    /// Shortens this `String` to the specified length.\n    ///\n    /// If `new_len` is greater than the string's current length, this has no\n    /// effect.\n    ///\n    /// Note that this method has no effect on the allocated capacity\n    /// of the string\n    ///\n    /// # Panics\n    ///\n    /// Panics if `new_len` does not lie on a [`char`] boundary.\n    ///\n    /// # Examples\n    ///\n    /// Basic usage:\n    ///\n    /// ```\n    /// let mut s = String::from(\"hello\");\n    ///\n    /// s.truncate(2);\n    ///\n    /// assert_eq!(\"he\", s);\n    /// ```\n    #[inline]\n    #[stable(feature = \"rust1\", since = \"1.0.0\")]\n    pub fn truncate(&mut self, new_len: usize) {\n        if new_len <= self.len() {\n            assert!(self.is_char_boundary(new_len));\n            self.vec.truncate(new_len)\n        }\n    }\n\n    /// Removes the last character from the string buffer and returns it.\n    ///\n    /// Returns [`None`] if this `String` is empty.\n    ///\n    /// # Examples\n    ///\n    /// Basic usage:\n    ///\n    /// ```\n    /// let mut s = String::from(\"foo\");\n    ///\n    /// assert_eq!(s.pop(), Some('o'));\n    /// assert_eq!(s.pop(), Some('o'));\n    /// assert_eq!(s.pop(), Some('f'));\n    ///\n    /// assert_eq!(s.pop(), None);\n    /// ```\n    #[inline]\n    #[stable(feature = \"rust1\", since = \"1.0.0\")]\n    pub fn pop(&mut self) -> Option<char> {\n        let ch = self.chars().rev().next()?;\n        let newlen = self.len() - ch.len_utf8();\n        unsafe {\n            self.vec.set_len(newlen);\n        }\n        Some(ch)\n    }\n\n    /// Removes a [`char`] from this `String` at a byte position and returns it.\n    ///\n    /// This is an *O*(*n*) operation, as it requires copying every element in the\n    /// buffer.\n    ///\n    /// # Panics\n    ///\n    /// Panics if `idx` is larger than or equal to the `String`'s length,\n    /// or if it does not lie on a [`char`] boundary.\n    ///\n    /// # Examples\n    ///\n    /// Basic usage:\n    ///\n    /// ```\n    /// let mut s = String::from(\"foo\");\n    ///\n    /// assert_eq!(s.remove(0), 'f');\n    /// assert_eq!(s.remove(1), 'o');\n    /// assert_eq!(s.remove(0), 'o');\n    /// ```\n    #[inline]\n    #[stable(feature = \"rust1\", since = \"1.0.0\")]\n    pub fn remove(&mut self, idx: usize) -> char {\n        let ch = match self[idx..].chars().next() {\n            Some(ch) => ch,\n            None => panic!(\"cannot remove a char from the end of a string\"),\n        };\n\n        let next = idx + ch.len_utf8();\n        let len = self.len();\n        unsafe {\n            ptr::copy(self.vec.as_ptr().add(next), self.vec.as_mut_ptr().add(idx), len - next);\n            self.vec.set_len(len - (next - idx));\n        }\n        ch\n    }\n\n    /// Remove all matches of pattern `pat` in the `String`.\n    ///\n    /// # Examples\n    ///\n    /// ```\n    /// #![feature(string_remove_matches)]\n    /// let mut s = String::from(\"Trees are not green, the sky is not blue.\");\n    /// s.remove_matches(\"not \");\n    /// assert_eq!(\"Trees are green, the sky is blue.\", s);\n    /// ```\n    ///\n    /// Matches will be detected and removed iteratively, so in cases where\n    /// patterns overlap, only the first pattern will be removed:\n    ///\n    /// ```\n    /// #![feature(string_remove_matches)]\n    /// let mut s = String::from(\"banana\");\n    /// s.remove_matches(\"ana\");\n    /// assert_eq!(\"bna\", s);\n    /// ```\n    #[cfg(not(no_global_oom_handling))]\n    #[unstable(feature = \"string_remove_matches\", reason = \"new API\", issue = \"72826\")]\n    pub fn remove_matches<'a, P>(&'a mut self, pat: P)\n    where\n        P: for<'x> Pattern<'x>,\n    {\n        use core::str::pattern::Searcher;\n\n        let rejections = {\n            let mut searcher = pat.into_searcher(self);\n            // Per Searcher::next:\n            //\n            // A Match result needs to contain the whole matched pattern,\n            // however Reject results may be split up into arbitrary many\n            // adjacent fragments. Both ranges may have zero length.\n            //\n            // In practice the implementation of Searcher::next_match tends to\n            // be more efficient, so we use it here and do some work to invert\n            // matches into rejections since that's what we want to copy below.\n            let mut front = 0;\n            let rejections: Vec<_> = from_fn(|| {\n                let (start, end) = searcher.next_match()?;\n                let prev_front = front;\n                front = end;\n                Some((prev_front, start))\n            })\n            .collect();\n            rejections.into_iter().chain(core::iter::once((front, self.len())))\n        };\n\n        let mut len = 0;\n        let ptr = self.vec.as_mut_ptr();\n\n        for (start, end) in rejections {\n            let count = end - start;\n            if start != len {\n                // SAFETY: per Searcher::next:\n                //\n                // The stream of Match and Reject values up to a Done will\n                // contain index ranges that are adjacent, non-overlapping,\n                // covering the whole haystack, and laying on utf8\n                // boundaries.\n                unsafe {\n                    ptr::copy(ptr.add(start), ptr.add(len), count);\n                }\n            }\n            len += count;\n        }\n\n        unsafe {\n            self.vec.set_len(len);\n        }\n    }\n\n    /// Retains only the characters specified by the predicate.\n    ///\n    /// In other words, remove all characters `c` such that `f(c)` returns `false`.\n    /// This method operates in place, visiting each character exactly once in the\n    /// original order, and preserves the order of the retained characters.\n    ///\n    /// # Examples\n    ///\n    /// ```\n    /// let mut s = String::from(\"f_o_ob_ar\");\n    ///\n    /// s.retain(|c| c != '_');\n    ///\n    /// assert_eq!(s, \"foobar\");\n    /// ```\n    ///\n    /// The exact order may be useful for tracking external state, like an index.\n    ///\n    /// ```\n    /// let mut s = String::from(\"abcde\");\n    /// let keep = [false, true, true, false, true];\n    /// let mut i = 0;\n    /// s.retain(|_| (keep[i], i += 1).0);\n    /// assert_eq!(s, \"bce\");\n    /// ```\n    #[inline]\n    #[stable(feature = \"string_retain\", since = \"1.26.0\")]\n    pub fn retain<F>(&mut self, mut f: F)\n    where\n        F: FnMut(char) -> bool,\n    {\n        struct SetLenOnDrop<'a> {\n            s: &'a mut String,\n            idx: usize,\n            del_bytes: usize,\n        }\n\n        impl<'a> Drop for SetLenOnDrop<'a> {\n            fn drop(&mut self) {\n                let new_len = self.idx - self.del_bytes;\n                debug_assert!(new_len <= self.s.len());\n                unsafe { self.s.vec.set_len(new_len) };\n            }\n        }\n\n        let len = self.len();\n        let mut guard = SetLenOnDrop { s: self, idx: 0, del_bytes: 0 };\n\n        while guard.idx < len {\n            let ch = unsafe { guard.s.get_unchecked(guard.idx..len).chars().next().unwrap() };\n            let ch_len = ch.len_utf8();\n\n            if !f(ch) {\n                guard.del_bytes += ch_len;\n            } else if guard.del_bytes > 0 {\n                unsafe {\n                    ptr::copy(\n                        guard.s.vec.as_ptr().add(guard.idx),\n                        guard.s.vec.as_mut_ptr().add(guard.idx - guard.del_bytes),\n                        ch_len,\n                    );\n                }\n            }\n\n            // Point idx to the next char\n            guard.idx += ch_len;\n        }\n\n        drop(guard);\n    }\n\n    /// Inserts a character into this `String` at a byte position.\n    ///\n    /// This is an *O*(*n*) operation as it requires copying every element in the\n    /// buffer.\n    ///\n    /// # Panics\n    ///\n    /// Panics if `idx` is larger than the `String`'s length, or if it does not\n    /// lie on a [`char`] boundary.\n    ///\n    /// # Examples\n    ///\n    /// Basic usage:\n    ///\n    /// ```\n    /// let mut s = String::with_capacity(3);\n    ///\n    /// s.insert(0, 'f');\n    /// s.insert(1, 'o');\n    /// s.insert(2, 'o');\n    ///\n    /// assert_eq!(\"foo\", s);\n    /// ```\n    #[cfg(not(no_global_oom_handling))]\n    #[inline]\n    #[stable(feature = \"rust1\", since = \"1.0.0\")]\n    pub fn insert(&mut self, idx: usize, ch: char) {\n        assert!(self.is_char_boundary(idx));\n        let mut bits = [0; 4];\n        let bits = ch.encode_utf8(&mut bits).as_bytes();\n\n        unsafe {\n            self.insert_bytes(idx, bits);\n        }\n    }\n\n    #[cfg(not(no_global_oom_handling))]\n    unsafe fn insert_bytes(&mut self, idx: usize, bytes: &[u8]) {\n        let len = self.len();\n        let amt = bytes.len();\n        self.vec.reserve(amt);\n\n        unsafe {\n            ptr::copy(self.vec.as_ptr().add(idx), self.vec.as_mut_ptr().add(idx + amt), len - idx);\n            ptr::copy_nonoverlapping(bytes.as_ptr(), self.vec.as_mut_ptr().add(idx), amt);\n            self.vec.set_len(len + amt);\n        }\n    }\n\n    /// Inserts a string slice into this `String` at a byte position.\n    ///\n    /// This is an *O*(*n*) operation as it requires copying every element in the\n    /// buffer.\n    ///\n    /// # Panics\n    ///\n    /// Panics if `idx` is larger than the `String`'s length, or if it does not\n    /// lie on a [`char`] boundary.\n    ///\n    /// # Examples\n    ///\n    /// Basic usage:\n    ///\n    /// ```\n    /// let mut s = String::from(\"bar\");\n    ///\n    /// s.insert_str(0, \"foo\");\n    ///\n    /// assert_eq!(\"foobar\", s);\n    /// ```\n    #[cfg(not(no_global_oom_handling))]\n    #[inline]\n    #[stable(feature = \"insert_str\", since = \"1.16.0\")]\n    pub fn insert_str(&mut self, idx: usize, string: &str) {\n        assert!(self.is_char_boundary(idx));\n\n        unsafe {\n            self.insert_bytes(idx, string.as_bytes());\n        }\n    }\n\n    /// Returns a mutable reference to the contents of this `String`.\n    ///\n    /// # Safety\n    ///\n    /// This function is unsafe because it does not check that the bytes passed\n    /// to it are valid UTF-8. If this constraint is violated, it may cause\n    /// memory unsafety issues with future users of the `String`, as the rest of\n    /// the standard library assumes that `String`s are valid UTF-8.\n    ///\n    /// # Examples\n    ///\n    /// Basic usage:\n    ///\n    /// ```\n    /// let mut s = String::from(\"hello\");\n    ///\n    /// unsafe {\n    ///     let vec = s.as_mut_vec();\n    ///     assert_eq!(&[104, 101, 108, 108, 111][..], &vec[..]);\n    ///\n    ///     vec.reverse();\n    /// }\n    /// assert_eq!(s, \"olleh\");\n    /// ```\n    #[inline]\n    #[stable(feature = \"rust1\", since = \"1.0.0\")]\n    pub unsafe fn as_mut_vec(&mut self) -> &mut Vec<u8> {\n        &mut self.vec\n    }\n\n    /// Returns the length of this `String`, in bytes, not [`char`]s or\n    /// graphemes. In other words, it may not be what a human considers the\n    /// length of the string.\n    ///\n    /// # Examples\n    ///\n    /// Basic usage:\n    ///\n    /// ```\n    /// let a = String::from(\"foo\");\n    /// assert_eq!(a.len(), 3);\n    ///\n    /// let fancy_f = String::from(\"ƒoo\");\n    /// assert_eq!(fancy_f.len(), 4);\n    /// assert_eq!(fancy_f.chars().count(), 3);\n    /// ```\n    #[doc(alias = \"length\")]\n    #[inline]\n    #[stable(feature = \"rust1\", since = \"1.0.0\")]\n    pub fn len(&self) -> usize {\n        self.vec.len()\n    }\n\n    /// Returns `true` if this `String` has a length of zero, and `false` otherwise.\n    ///\n    /// # Examples\n    ///\n    /// Basic usage:\n    ///\n    /// ```\n    /// let mut v = String::new();\n    /// assert!(v.is_empty());\n    ///\n    /// v.push('a');\n    /// assert!(!v.is_empty());\n    /// ```\n    #[inline]\n    #[stable(feature = \"rust1\", since = \"1.0.0\")]\n    pub fn is_empty(&self) -> bool {\n        self.len() == 0\n    }\n\n    /// Splits the string into two at the given byte index.\n    ///\n    /// Returns a newly allocated `String`. `self` contains bytes `[0, at)`, and\n    /// the returned `String` contains bytes `[at, len)`. `at` must be on the\n    /// boundary of a UTF-8 code point.\n    ///\n    /// Note that the capacity of `self` does not change.\n    ///\n    /// # Panics\n    ///\n    /// Panics if `at` is not on a `UTF-8` code point boundary, or if it is beyond the last\n    /// code point of the string.\n    ///\n    /// # Examples\n    ///\n    /// ```\n    /// # fn main() {\n    /// let mut hello = String::from(\"Hello, World!\");\n    /// let world = hello.split_off(7);\n    /// assert_eq!(hello, \"Hello, \");\n    /// assert_eq!(world, \"World!\");\n    /// # }\n    /// ```\n    #[cfg(not(no_global_oom_handling))]\n    #[inline]\n    #[stable(feature = \"string_split_off\", since = \"1.16.0\")]\n    #[must_use = \"use `.truncate()` if you don't need the other half\"]\n    pub fn split_off(&mut self, at: usize) -> String {\n        assert!(self.is_char_boundary(at));\n        let other = self.vec.split_off(at);\n        unsafe { String::from_utf8_unchecked(other) }\n    }\n\n    /// Truncates this `String`, removing all contents.\n    ///\n    /// While this means the `String` will have a length of zero, it does not\n    /// touch its capacity.\n    ///\n    /// # Examples\n    ///\n    /// Basic usage:\n    ///\n    /// ```\n    /// let mut s = String::from(\"foo\");\n    ///\n    /// s.clear();\n    ///\n    /// assert!(s.is_empty());\n    /// assert_eq!(0, s.len());\n    /// assert_eq!(3, s.capacity());\n    /// ```\n    #[inline]\n    #[stable(feature = \"rust1\", since = \"1.0.0\")]\n    pub fn clear(&mut self) {\n        self.vec.clear()\n    }\n\n    /// Creates a draining iterator that removes the specified range in the `String`\n    /// and yields the removed `chars`.\n    ///\n    /// Note: The element range is removed even if the iterator is not\n    /// consumed until the end.\n    ///\n    /// # Panics\n    ///\n    /// Panics if the starting point or end point do not lie on a [`char`]\n    /// boundary, or if they're out of bounds.\n    ///\n    /// # Examples\n    ///\n    /// Basic usage:\n    ///\n    /// ```\n    /// let mut s = String::from(\"α is alpha, β is beta\");\n    /// let beta_offset = s.find('β').unwrap_or(s.len());\n    ///\n    /// // Remove the range up until the β from the string\n    /// let t: String = s.drain(..beta_offset).collect();\n    /// assert_eq!(t, \"α is alpha, \");\n    /// assert_eq!(s, \"β is beta\");\n    ///\n    /// // A full range clears the string\n    /// s.drain(..);\n    /// assert_eq!(s, \"\");\n    /// ```\n    #[stable(feature = \"drain\", since = \"1.6.0\")]\n    pub fn drain<R>(&mut self, range: R) -> Drain<'_>\n    where\n        R: RangeBounds<usize>,\n    {\n        // Memory safety\n        //\n        // The String version of Drain does not have the memory safety issues\n        // of the vector version. The data is just plain bytes.\n        // Because the range removal happens in Drop, if the Drain iterator is leaked,\n        // the removal will not happen.\n        let Range { start, end } = slice::range(range, ..self.len());\n        assert!(self.is_char_boundary(start));\n        assert!(self.is_char_boundary(end));\n\n        // Take out two simultaneous borrows. The &mut String won't be accessed\n        // until iteration is over, in Drop.\n        let self_ptr = self as *mut _;\n        // SAFETY: `slice::range` and `is_char_boundary` do the appropriate bounds checks.\n        let chars_iter = unsafe { self.get_unchecked(start..end) }.chars();\n\n        Drain { start, end, iter: chars_iter, string: self_ptr }\n    }\n\n    /// Removes the specified range in the string,\n    /// and replaces it with the given string.\n    /// The given string doesn't need to be the same length as the range.\n    ///\n    /// # Panics\n    ///\n    /// Panics if the starting point or end point do not lie on a [`char`]\n    /// boundary, or if they're out of bounds.\n    ///\n    /// # Examples\n    ///\n    /// Basic usage:\n    ///\n    /// ```\n    /// let mut s = String::from(\"α is alpha, β is beta\");\n    /// let beta_offset = s.find('β').unwrap_or(s.len());\n    ///\n    /// // Replace the range up until the β from the string\n    /// s.replace_range(..beta_offset, \"Α is capital alpha; \");\n    /// assert_eq!(s, \"Α is capital alpha; β is beta\");\n    /// ```\n    #[cfg(not(no_global_oom_handling))]\n    #[stable(feature = \"splice\", since = \"1.27.0\")]\n    pub fn replace_range<R>(&mut self, range: R, replace_with: &str)\n    where\n        R: RangeBounds<usize>,\n    {\n        // Memory safety\n        //\n        // Replace_range does not have the memory safety issues of a vector Splice.\n        // of the vector version. The data is just plain bytes.\n\n        // WARNING: Inlining this variable would be unsound (#81138)\n        let start = range.start_bound();\n        match start {\n            Included(&n) => assert!(self.is_char_boundary(n)),\n            Excluded(&n) => assert!(self.is_char_boundary(n + 1)),\n            Unbounded => {}\n        };\n        // WARNING: Inlining this variable would be unsound (#81138)\n        let end = range.end_bound();\n        match end {\n            Included(&n) => assert!(self.is_char_boundary(n + 1)),\n            Excluded(&n) => assert!(self.is_char_boundary(n)),\n            Unbounded => {}\n        };\n\n        // Using `range` again would be unsound (#81138)\n        // We assume the bounds reported by `range` remain the same, but\n        // an adversarial implementation could change between calls\n        unsafe { self.as_mut_vec() }.splice((start, end), replace_with.bytes());\n    }\n\n    /// Converts this `String` into a [`Box`]`<`[`str`]`>`.\n    ///\n    /// This will drop any excess capacity.\n    ///\n    /// [`str`]: prim@str\n    ///\n    /// # Examples\n    ///\n    /// Basic usage:\n    ///\n    /// ```\n    /// let s = String::from(\"hello\");\n    ///\n    /// let b = s.into_boxed_str();\n    /// ```\n    #[cfg(not(no_global_oom_handling))]\n    #[stable(feature = \"box_str\", since = \"1.4.0\")]\n    #[inline]\n    pub fn into_boxed_str(self) -> Box<str> {\n        let slice = self.vec.into_boxed_slice();\n        unsafe { from_boxed_utf8_unchecked(slice) }\n    }\n}\n\nimpl FromUtf8Error {\n    /// Returns a slice of [`u8`]s bytes that were attempted to convert to a `String`.\n    ///\n    /// # Examples\n    ///\n    /// Basic usage:\n    ///\n    /// ```\n    /// // some invalid bytes, in a vector\n    /// let bytes = vec![0, 159];\n    ///\n    /// let value = String::from_utf8(bytes);\n    ///\n    /// assert_eq!(&[0, 159], value.unwrap_err().as_bytes());\n    /// ```\n    #[stable(feature = \"from_utf8_error_as_bytes\", since = \"1.26.0\")]\n    pub fn as_bytes(&self) -> &[u8] {\n        &self.bytes[..]\n    }\n\n    /// Returns the bytes that were attempted to convert to a `String`.\n    ///\n    /// This method is carefully constructed to avoid allocation. It will\n    /// consume the error, moving out the bytes, so that a copy of the bytes\n    /// does not need to be made.\n    ///\n    /// # Examples\n    ///\n    /// Basic usage:\n    ///\n    /// ```\n    /// // some invalid bytes, in a vector\n    /// let bytes = vec![0, 159];\n    ///\n    /// let value = String::from_utf8(bytes);\n    ///\n    /// assert_eq!(vec![0, 159], value.unwrap_err().into_bytes());\n    /// ```\n    #[stable(feature = \"rust1\", since = \"1.0.0\")]\n    pub fn into_bytes(self) -> Vec<u8> {\n        self.bytes\n    }\n\n    /// Fetch a `Utf8Error` to get more details about the conversion failure.\n    ///\n    /// The [`Utf8Error`] type provided by [`std::str`] represents an error that may\n    /// occur when converting a slice of [`u8`]s to a [`&str`]. In this sense, it's\n    /// an analogue to `FromUtf8Error`. See its documentation for more details\n    /// on using it.\n    ///\n    /// [`std::str`]: core::str\n    /// [`&str`]: prim@str\n    ///\n    /// # Examples\n    ///\n    /// Basic usage:\n    ///\n    /// ```\n    /// // some invalid bytes, in a vector\n    /// let bytes = vec![0, 159];\n    ///\n    /// let error = String::from_utf8(bytes).unwrap_err().utf8_error();\n    ///\n    /// // the first byte is invalid here\n    /// assert_eq!(1, error.valid_up_to());\n    /// ```\n    #[stable(feature = \"rust1\", since = \"1.0.0\")]\n    pub fn utf8_error(&self) -> Utf8Error {\n        self.error\n    }\n}\n\n#[stable(feature = \"rust1\", since = \"1.0.0\")]\nimpl fmt::Display for FromUtf8Error {\n    fn fmt(&self, f: &mut fmt::Formatter<'_>) -> fmt::Result {\n        fmt::Display::fmt(&self.error, f)\n    }\n}\n\n#[stable(feature = \"rust1\", since = \"1.0.0\")]\nimpl fmt::Display for FromUtf16Error {\n    fn fmt(&self, f: &mut fmt::Formatter<'_>) -> fmt::Result {\n        fmt::Display::fmt(\"invalid utf-16: lone surrogate found\", f)\n    }\n}\n\n#[cfg(not(no_global_oom_handling))]\n#[stable(feature = \"rust1\", since = \"1.0.0\")]\nimpl Clone for String {\n    fn clone(&self) -> Self {\n        String { vec: self.vec.clone() }\n    }\n\n    fn clone_from(&mut self, source: &Self) {\n        self.vec.clone_from(&source.vec);\n    }\n}\n\n#[cfg(not(no_global_oom_handling))]\n#[stable(feature = \"rust1\", since = \"1.0.0\")]\nimpl FromIterator<char> for String {\n    fn from_iter<I: IntoIterator<Item = char>>(iter: I) -> String {\n        let mut buf = String::new();\n        buf.extend(iter);\n        buf\n    }\n}\n\n#[cfg(not(no_global_oom_handling))]\n#[stable(feature = \"string_from_iter_by_ref\", since = \"1.17.0\")]\nimpl<'a> FromIterator<&'a char> for String {\n    fn from_iter<I: IntoIterator<Item = &'a char>>(iter: I) -> String {\n        let mut buf = String::new();\n        buf.extend(iter);\n        buf\n    }\n}\n\n#[cfg(not(no_global_oom_handling))]\n#[stable(feature = \"rust1\", since = \"1.0.0\")]\nimpl<'a> FromIterator<&'a str> for String {\n    fn from_iter<I: IntoIterator<Item = &'a str>>(iter: I) -> String {\n        let mut buf = String::new();\n        buf.extend(iter);\n        buf\n    }\n}\n\n#[cfg(not(no_global_oom_handling))]\n#[stable(feature = \"extend_string\", since = \"1.4.0\")]\nimpl FromIterator<String> for String {\n    fn from_iter<I: IntoIterator<Item = String>>(iter: I) -> String {\n        let mut iterator = iter.into_iter();\n\n        // Because we're iterating over `String`s, we can avoid at least\n        // one allocation by getting the first string from the iterator\n        // and appending to it all the subsequent strings.\n        match iterator.next() {\n            None => String::new(),\n            Some(mut buf) => {\n                buf.extend(iterator);\n                buf\n            }\n        }\n    }\n}\n\n#[cfg(not(no_global_oom_handling))]\n#[stable(feature = \"box_str2\", since = \"1.45.0\")]\nimpl FromIterator<Box<str>> for String {\n    fn from_iter<I: IntoIterator<Item = Box<str>>>(iter: I) -> String {\n        let mut buf = String::new();\n        buf.extend(iter);\n        buf\n    }\n}\n\n#[cfg(not(no_global_oom_handling))]\n#[stable(feature = \"herd_cows\", since = \"1.19.0\")]\nimpl<'a> FromIterator<Cow<'a, str>> for String {\n    fn from_iter<I: IntoIterator<Item = Cow<'a, str>>>(iter: I) -> String {\n        let mut iterator = iter.into_iter();\n\n        // Because we're iterating over CoWs, we can (potentially) avoid at least\n        // one allocation by getting the first item and appending to it all the\n        // subsequent items.\n        match iterator.next() {\n            None => String::new(),\n            Some(cow) => {\n                let mut buf = cow.into_owned();\n                buf.extend(iterator);\n                buf\n            }\n        }\n    }\n}\n\n#[cfg(not(no_global_oom_handling))]\n#[stable(feature = \"rust1\", since = \"1.0.0\")]\nimpl Extend<char> for String {\n    fn extend<I: IntoIterator<Item = char>>(&mut self, iter: I) {\n        let iterator = iter.into_iter();\n        let (lower_bound, _) = iterator.size_hint();\n        self.reserve(lower_bound);\n        iterator.for_each(move |c| self.push(c));\n    }\n\n    #[inline]\n    fn extend_one(&mut self, c: char) {\n        self.push(c);\n    }\n\n    #[inline]\n    fn extend_reserve(&mut self, additional: usize) {\n        self.reserve(additional);\n    }\n}\n\n#[cfg(not(no_global_oom_handling))]\n#[stable(feature = \"extend_ref\", since = \"1.2.0\")]\nimpl<'a> Extend<&'a char> for String {\n    fn extend<I: IntoIterator<Item = &'a char>>(&mut self, iter: I) {\n        self.extend(iter.into_iter().cloned());\n    }\n\n    #[inline]\n    fn extend_one(&mut self, &c: &'a char) {\n        self.push(c);\n    }\n\n    #[inline]\n    fn extend_reserve(&mut self, additional: usize) {\n        self.reserve(additional);\n    }\n}\n\n#[cfg(not(no_global_oom_handling))]\n#[stable(feature = \"rust1\", since = \"1.0.0\")]\nimpl<'a> Extend<&'a str> for String {\n    fn extend<I: IntoIterator<Item = &'a str>>(&mut self, iter: I) {\n        iter.into_iter().for_each(move |s| self.push_str(s));\n    }\n\n    #[inline]\n    fn extend_one(&mut self, s: &'a str) {\n        self.push_str(s);\n    }\n}\n\n#[cfg(not(no_global_oom_handling))]\n#[stable(feature = \"box_str2\", since = \"1.45.0\")]\nimpl Extend<Box<str>> for String {\n    fn extend<I: IntoIterator<Item = Box<str>>>(&mut self, iter: I) {\n        iter.into_iter().for_each(move |s| self.push_str(&s));\n    }\n}\n\n#[cfg(not(no_global_oom_handling))]\n#[stable(feature = \"extend_string\", since = \"1.4.0\")]\nimpl Extend<String> for String {\n    fn extend<I: IntoIterator<Item = String>>(&mut self, iter: I) {\n        iter.into_iter().for_each(move |s| self.push_str(&s));\n    }\n\n    #[inline]\n    fn extend_one(&mut self, s: String) {\n        self.push_str(&s);\n    }\n}\n\n#[cfg(not(no_global_oom_handling))]\n#[stable(feature = \"herd_cows\", since = \"1.19.0\")]\nimpl<'a> Extend<Cow<'a, str>> for String {\n    fn extend<I: IntoIterator<Item = Cow<'a, str>>>(&mut self, iter: I) {\n        iter.into_iter().for_each(move |s| self.push_str(&s));\n    }\n\n    #[inline]\n    fn extend_one(&mut self, s: Cow<'a, str>) {\n        self.push_str(&s);\n    }\n}\n\n/// A convenience impl that delegates to the impl for `&str`.\n///\n/// # Examples\n///\n/// ```\n/// assert_eq!(String::from(\"Hello world\").find(\"world\"), Some(6));\n/// ```\n#[unstable(\n    feature = \"pattern\",\n    reason = \"API not fully fleshed out and ready to be stabilized\",\n    issue = \"27721\"\n)]\nimpl<'a, 'b> Pattern<'a> for &'b String {\n    type Searcher = <&'b str as Pattern<'a>>::Searcher;\n\n    fn into_searcher(self, haystack: &'a str) -> <&'b str as Pattern<'a>>::Searcher {\n        self[..].into_searcher(haystack)\n    }\n\n    #[inline]\n    fn is_contained_in(self, haystack: &'a str) -> bool {\n        self[..].is_contained_in(haystack)\n    }\n\n    #[inline]\n    fn is_prefix_of(self, haystack: &'a str) -> bool {\n        self[..].is_prefix_of(haystack)\n    }\n\n    #[inline]\n    fn strip_prefix_of(self, haystack: &'a str) -> Option<&'a str> {\n        self[..].strip_prefix_of(haystack)\n    }\n\n    #[inline]\n    fn is_suffix_of(self, haystack: &'a str) -> bool {\n        self[..].is_suffix_of(haystack)\n    }\n\n    #[inline]\n    fn strip_suffix_of(self, haystack: &'a str) -> Option<&'a str> {\n        self[..].strip_suffix_of(haystack)\n    }\n}\n\n#[stable(feature = \"rust1\", since = \"1.0.0\")]\nimpl PartialEq for String {\n    #[inline]\n    fn eq(&self, other: &String) -> bool {\n        PartialEq::eq(&self[..], &other[..])\n    }\n    #[inline]\n    fn ne(&self, other: &String) -> bool {\n        PartialEq::ne(&self[..], &other[..])\n    }\n}\n\nmacro_rules! impl_eq {\n    ($lhs:ty, $rhs: ty) => {\n        #[stable(feature = \"rust1\", since = \"1.0.0\")]\n        #[allow(unused_lifetimes)]\n        impl<'a, 'b> PartialEq<$rhs> for $lhs {\n            #[inline]\n            fn eq(&self, other: &$rhs) -> bool {\n                PartialEq::eq(&self[..], &other[..])\n            }\n            #[inline]\n            fn ne(&self, other: &$rhs) -> bool {\n                PartialEq::ne(&self[..], &other[..])\n            }\n        }\n\n        #[stable(feature = \"rust1\", since = \"1.0.0\")]\n        #[allow(unused_lifetimes)]\n        impl<'a, 'b> PartialEq<$lhs> for $rhs {\n            #[inline]\n            fn eq(&self, other: &$lhs) -> bool {\n                PartialEq::eq(&self[..], &other[..])\n            }\n            #[inline]\n            fn ne(&self, other: &$lhs) -> bool {\n                PartialEq::ne(&self[..], &other[..])\n            }\n        }\n    };\n}\n\nimpl_eq! { String, str }\nimpl_eq! { String, &'a str }\n#[cfg(not(no_global_oom_handling))]\nimpl_eq! { Cow<'a, str>, str }\n#[cfg(not(no_global_oom_handling))]\nimpl_eq! { Cow<'a, str>, &'b str }\n#[cfg(not(no_global_oom_handling))]\nimpl_eq! { Cow<'a, str>, String }\n\n#[stable(feature = \"rust1\", since = \"1.0.0\")]\nimpl Default for String {\n    /// Creates an empty `String`.\n    #[inline]\n    fn default() -> String {\n        String::new()\n    }\n}\n\n#[stable(feature = \"rust1\", since = \"1.0.0\")]\nimpl fmt::Display for String {\n    #[inline]\n    fn fmt(&self, f: &mut fmt::Formatter<'_>) -> fmt::Result {\n        fmt::Display::fmt(&**self, f)\n    }\n}\n\n#[stable(feature = \"rust1\", since = \"1.0.0\")]\nimpl fmt::Debug for String {\n    #[inline]\n    fn fmt(&self, f: &mut fmt::Formatter<'_>) -> fmt::Result {\n        fmt::Debug::fmt(&**self, f)\n    }\n}\n\n#[stable(feature = \"rust1\", since = \"1.0.0\")]\nimpl hash::Hash for String {\n    #[inline]\n    fn hash<H: hash::Hasher>(&self, hasher: &mut H) {\n        (**self).hash(hasher)\n    }\n}\n\n/// Implements the `+` operator for concatenating two strings.\n///\n/// This consumes the `String` on the left-hand side and re-uses its buffer (growing it if\n/// necessary). This is done to avoid allocating a new `String` and copying the entire contents on\n/// every operation, which would lead to *O*(*n*^2) running time when building an *n*-byte string by\n/// repeated concatenation.\n///\n/// The string on the right-hand side is only borrowed; its contents are copied into the returned\n/// `String`.\n///\n/// # Examples\n///\n/// Concatenating two `String`s takes the first by value and borrows the second:\n///\n/// ```\n/// let a = String::from(\"hello\");\n/// let b = String::from(\" world\");\n/// let c = a + &b;\n/// // `a` is moved and can no longer be used here.\n/// ```\n///\n/// If you want to keep using the first `String`, you can clone it and append to the clone instead:\n///\n/// ```\n/// let a = String::from(\"hello\");\n/// let b = String::from(\" world\");\n/// let c = a.clone() + &b;\n/// // `a` is still valid here.\n/// ```\n///\n/// Concatenating `&str` slices can be done by converting the first to a `String`:\n///\n/// ```\n/// let a = \"hello\";\n/// let b = \" world\";\n/// let c = a.to_string() + b;\n/// ```\n#[cfg(not(no_global_oom_handling))]\n#[stable(feature = \"rust1\", since = \"1.0.0\")]\nimpl Add<&str> for String {\n    type Output = String;\n\n    #[inline]\n    fn add(mut self, other: &str) -> String {\n        self.push_str(other);\n        self\n    }\n}\n\n/// Implements the `+=` operator for appending to a `String`.\n///\n/// This has the same behavior as the [`push_str`][String::push_str] method.\n#[cfg(not(no_global_oom_handling))]\n#[stable(feature = \"stringaddassign\", since = \"1.12.0\")]\nimpl AddAssign<&str> for String {\n    #[inline]\n    fn add_assign(&mut self, other: &str) {\n        self.push_str(other);\n    }\n}\n\n#[stable(feature = \"rust1\", since = \"1.0.0\")]\nimpl ops::Index<ops::Range<usize>> for String {\n    type Output = str;\n\n    #[inline]\n    fn index(&self, index: ops::Range<usize>) -> &str {\n        &self[..][index]\n    }\n}\n#[stable(feature = \"rust1\", since = \"1.0.0\")]\nimpl ops::Index<ops::RangeTo<usize>> for String {\n    type Output = str;\n\n    #[inline]\n    fn index(&self, index: ops::RangeTo<usize>) -> &str {\n        &self[..][index]\n    }\n}\n#[stable(feature = \"rust1\", since = \"1.0.0\")]\nimpl ops::Index<ops::RangeFrom<usize>> for String {\n    type Output = str;\n\n    #[inline]\n    fn index(&self, index: ops::RangeFrom<usize>) -> &str {\n        &self[..][index]\n    }\n}\n#[stable(feature = \"rust1\", since = \"1.0.0\")]\nimpl ops::Index<ops::RangeFull> for String {\n    type Output = str;\n\n    #[inline]\n    fn index(&self, _index: ops::RangeFull) -> &str {\n        unsafe { str::from_utf8_unchecked(&self.vec) }\n    }\n}\n#[stable(feature = \"inclusive_range\", since = \"1.26.0\")]\nimpl ops::Index<ops::RangeInclusive<usize>> for String {\n    type Output = str;\n\n    #[inline]\n    fn index(&self, index: ops::RangeInclusive<usize>) -> &str {\n        Index::index(&**self, index)\n    }\n}\n#[stable(feature = \"inclusive_range\", since = \"1.26.0\")]\nimpl ops::Index<ops::RangeToInclusive<usize>> for String {\n    type Output = str;\n\n    #[inline]\n    fn index(&self, index: ops::RangeToInclusive<usize>) -> &str {\n        Index::index(&**self, index)\n    }\n}\n\n#[stable(feature = \"derefmut_for_string\", since = \"1.3.0\")]\nimpl ops::IndexMut<ops::Range<usize>> for String {\n    #[inline]\n    fn index_mut(&mut self, index: ops::Range<usize>) -> &mut str {\n        &mut self[..][index]\n    }\n}\n#[stable(feature = \"derefmut_for_string\", since = \"1.3.0\")]\nimpl ops::IndexMut<ops::RangeTo<usize>> for String {\n    #[inline]\n    fn index_mut(&mut self, index: ops::RangeTo<usize>) -> &mut str {\n        &mut self[..][index]\n    }\n}\n#[stable(feature = \"derefmut_for_string\", since = \"1.3.0\")]\nimpl ops::IndexMut<ops::RangeFrom<usize>> for String {\n    #[inline]\n    fn index_mut(&mut self, index: ops::RangeFrom<usize>) -> &mut str {\n        &mut self[..][index]\n    }\n}\n#[stable(feature = \"derefmut_for_string\", since = \"1.3.0\")]\nimpl ops::IndexMut<ops::RangeFull> for String {\n    #[inline]\n    fn index_mut(&mut self, _index: ops::RangeFull) -> &mut str {\n        unsafe { str::from_utf8_unchecked_mut(&mut *self.vec) }\n    }\n}\n#[stable(feature = \"inclusive_range\", since = \"1.26.0\")]\nimpl ops::IndexMut<ops::RangeInclusive<usize>> for String {\n    #[inline]\n    fn index_mut(&mut self, index: ops::RangeInclusive<usize>) -> &mut str {\n        IndexMut::index_mut(&mut **self, index)\n    }\n}\n#[stable(feature = \"inclusive_range\", since = \"1.26.0\")]\nimpl ops::IndexMut<ops::RangeToInclusive<usize>> for String {\n    #[inline]\n    fn index_mut(&mut self, index: ops::RangeToInclusive<usize>) -> &mut str {\n        IndexMut::index_mut(&mut **self, index)\n    }\n}\n\n#[stable(feature = \"rust1\", since = \"1.0.0\")]\nimpl ops::Deref for String {\n    type Target = str;\n\n    #[inline]\n    fn deref(&self) -> &str {\n        unsafe { str::from_utf8_unchecked(&self.vec) }\n    }\n}\n\n#[stable(feature = \"derefmut_for_string\", since = \"1.3.0\")]\nimpl ops::DerefMut for String {\n    #[inline]\n    fn deref_mut(&mut self) -> &mut str {\n        unsafe { str::from_utf8_unchecked_mut(&mut *self.vec) }\n    }\n}\n\n/// A type alias for [`Infallible`].\n///\n/// This alias exists for backwards compatibility, and may be eventually deprecated.\n///\n/// [`Infallible`]: core::convert::Infallible\n#[stable(feature = \"str_parse_error\", since = \"1.5.0\")]\npub type ParseError = core::convert::Infallible;\n\n#[cfg(not(no_global_oom_handling))]\n#[stable(feature = \"rust1\", since = \"1.0.0\")]\nimpl FromStr for String {\n    type Err = core::convert::Infallible;\n    #[inline]\n    fn from_str(s: &str) -> Result<String, Self::Err> {\n        Ok(String::from(s))\n    }\n}\n\n/// A trait for converting a value to a `String`.\n///\n/// This trait is automatically implemented for any type which implements the\n/// [`Display`] trait. As such, `ToString` shouldn't be implemented directly:\n/// [`Display`] should be implemented instead, and you get the `ToString`\n/// implementation for free.\n///\n/// [`Display`]: fmt::Display\n#[cfg_attr(not(test), rustc_diagnostic_item = \"ToString\")]\n#[stable(feature = \"rust1\", since = \"1.0.0\")]\npub trait ToString {\n    /// Converts the given value to a `String`.\n    ///\n    /// # Examples\n    ///\n    /// Basic usage:\n    ///\n    /// ```\n    /// let i = 5;\n    /// let five = String::from(\"5\");\n    ///\n    /// assert_eq!(five, i.to_string());\n    /// ```\n    #[rustc_conversion_suggestion]\n    #[stable(feature = \"rust1\", since = \"1.0.0\")]\n    fn to_string(&self) -> String;\n}\n\n/// # Panics\n///\n/// In this implementation, the `to_string` method panics\n/// if the `Display` implementation returns an error.\n/// This indicates an incorrect `Display` implementation\n/// since `fmt::Write for String` never returns an error itself.\n#[cfg(not(no_global_oom_handling))]\n#[stable(feature = \"rust1\", since = \"1.0.0\")]\nimpl<T: fmt::Display + ?Sized> ToString for T {\n    // A common guideline is to not inline generic functions. However,\n    // removing `#[inline]` from this method causes non-negligible regressions.\n    // See <https://github.com/rust-lang/rust/pull/74852>, the last attempt\n    // to try to remove it.\n    #[inline]\n    default fn to_string(&self) -> String {\n        let mut buf = String::new();\n        let mut formatter = core::fmt::Formatter::new(&mut buf);\n        // Bypass format_args!() to avoid write_str with zero-length strs\n        fmt::Display::fmt(self, &mut formatter)\n            .expect(\"a Display implementation returned an error unexpectedly\");\n        buf\n    }\n}\n\n#[cfg(not(no_global_oom_handling))]\n#[stable(feature = \"char_to_string_specialization\", since = \"1.46.0\")]\nimpl ToString for char {\n    #[inline]\n    fn to_string(&self) -> String {\n        String::from(self.encode_utf8(&mut [0; 4]))\n    }\n}\n\n#[cfg(not(no_global_oom_handling))]\n#[stable(feature = \"u8_to_string_specialization\", since = \"1.54.0\")]\nimpl ToString for u8 {\n    #[inline]\n    fn to_string(&self) -> String {\n        let mut buf = String::with_capacity(3);\n        let mut n = *self;\n        if n >= 10 {\n            if n >= 100 {\n                buf.push((b'0' + n / 100) as char);\n                n %= 100;\n            }\n            buf.push((b'0' + n / 10) as char);\n            n %= 10;\n        }\n        buf.push((b'0' + n) as char);\n        buf\n    }\n}\n\n#[cfg(not(no_global_oom_handling))]\n#[stable(feature = \"i8_to_string_specialization\", since = \"1.54.0\")]\nimpl ToString for i8 {\n    #[inline]\n    fn to_string(&self) -> String {\n        let mut buf = String::with_capacity(4);\n        if self.is_negative() {\n            buf.push('-');\n        }\n        let mut n = self.unsigned_abs();\n        if n >= 10 {\n            if n >= 100 {\n                buf.push('1');\n                n -= 100;\n            }\n            buf.push((b'0' + n / 10) as char);\n            n %= 10;\n        }\n        buf.push((b'0' + n) as char);\n        buf\n    }\n}\n\n#[cfg(not(no_global_oom_handling))]\n#[stable(feature = \"str_to_string_specialization\", since = \"1.9.0\")]\nimpl ToString for str {\n    #[inline]\n    fn to_string(&self) -> String {\n        String::from(self)\n    }\n}\n\n#[cfg(not(no_global_oom_handling))]\n#[stable(feature = \"cow_str_to_string_specialization\", since = \"1.17.0\")]\nimpl ToString for Cow<'_, str> {\n    #[inline]\n    fn to_string(&self) -> String {\n        self[..].to_owned()\n    }\n}\n\n#[cfg(not(no_global_oom_handling))]\n#[stable(feature = \"string_to_string_specialization\", since = \"1.17.0\")]\nimpl ToString for String {\n    #[inline]\n    fn to_string(&self) -> String {\n        self.to_owned()\n    }\n}\n\n#[stable(feature = \"rust1\", since = \"1.0.0\")]\nimpl AsRef<str> for String {\n    #[inline]\n    fn as_ref(&self) -> &str {\n        self\n    }\n}\n\n#[stable(feature = \"string_as_mut\", since = \"1.43.0\")]\nimpl AsMut<str> for String {\n    #[inline]\n    fn as_mut(&mut self) -> &mut str {\n        self\n    }\n}\n\n#[stable(feature = \"rust1\", since = \"1.0.0\")]\nimpl AsRef<[u8]> for String {\n    #[inline]\n    fn as_ref(&self) -> &[u8] {\n        self.as_bytes()\n    }\n}\n\n#[cfg(not(no_global_oom_handling))]\n#[stable(feature = \"rust1\", since = \"1.0.0\")]\nimpl From<&str> for String {\n    /// Converts a `&str` into a [`String`].\n    ///\n    /// The result is allocated on the heap.\n    #[inline]\n    fn from(s: &str) -> String {\n        s.to_owned()\n    }\n}\n\n#[cfg(not(no_global_oom_handling))]\n#[stable(feature = \"from_mut_str_for_string\", since = \"1.44.0\")]\nimpl From<&mut str> for String {\n    /// Converts a `&mut str` into a [`String`].\n    ///\n    /// The result is allocated on the heap.\n    #[inline]\n    fn from(s: &mut str) -> String {\n        s.to_owned()\n    }\n}\n\n#[cfg(not(no_global_oom_handling))]\n#[stable(feature = \"from_ref_string\", since = \"1.35.0\")]\nimpl From<&String> for String {\n    /// Converts a `&String` into a [`String`].\n    ///\n    /// This clones `s` and returns the clone.\n    #[inline]\n    fn from(s: &String) -> String {\n        s.clone()\n    }\n}\n\n// note: test pulls in libstd, which causes errors here\n#[cfg(not(test))]\n#[stable(feature = \"string_from_box\", since = \"1.18.0\")]\nimpl From<Box<str>> for String {\n    /// Converts the given boxed `str` slice to a [`String`].\n    /// It is notable that the `str` slice is owned.\n    ///\n    /// # Examples\n    ///\n    /// Basic usage:\n    ///\n    /// ```\n    /// let s1: String = String::from(\"hello world\");\n    /// let s2: Box<str> = s1.into_boxed_str();\n    /// let s3: String = String::from(s2);\n    ///\n    /// assert_eq!(\"hello world\", s3)\n    /// ```\n    fn from(s: Box<str>) -> String {\n        s.into_string()\n    }\n}\n\n#[cfg(not(no_global_oom_handling))]\n#[stable(feature = \"box_from_str\", since = \"1.20.0\")]\nimpl From<String> for Box<str> {\n    /// Converts the given [`String`] to a boxed `str` slice that is owned.\n    ///\n    /// # Examples\n    ///\n    /// Basic usage:\n    ///\n    /// ```\n    /// let s1: String = String::from(\"hello world\");\n    /// let s2: Box<str> = Box::from(s1);\n    /// let s3: String = String::from(s2);\n    ///\n    /// assert_eq!(\"hello world\", s3)\n    /// ```\n    fn from(s: String) -> Box<str> {\n        s.into_boxed_str()\n    }\n}\n\n#[cfg(not(no_global_oom_handling))]\n#[stable(feature = \"string_from_cow_str\", since = \"1.14.0\")]\nimpl<'a> From<Cow<'a, str>> for String {\n    /// Converts a clone-on-write string to an owned\n    /// instance of [`String`].\n    ///\n    /// This extracts the owned string,\n    /// clones the string if it is not already owned.\n    ///\n    /// # Example\n    ///\n    /// ```\n    /// # use std::borrow::Cow;\n    /// // If the string is not owned...\n    /// let cow: Cow<str> = Cow::Borrowed(\"eggplant\");\n    /// // It will allocate on the heap and copy the string.\n    /// let owned: String = String::from(cow);\n    /// assert_eq!(&owned[..], \"eggplant\");\n    /// ```\n    fn from(s: Cow<'a, str>) -> String {\n        s.into_owned()\n    }\n}\n\n#[cfg(not(no_global_oom_handling))]\n#[stable(feature = \"rust1\", since = \"1.0.0\")]\nimpl<'a> From<&'a str> for Cow<'a, str> {\n    /// Converts a string slice into a [`Borrowed`] variant.\n    /// No heap allocation is performed, and the string\n    /// is not copied.\n    ///\n    /// # Example\n    ///\n    /// ```\n    /// # use std::borrow::Cow;\n    /// assert_eq!(Cow::from(\"eggplant\"), Cow::Borrowed(\"eggplant\"));\n    /// ```\n    ///\n    /// [`Borrowed`]: crate::borrow::Cow::Borrowed\n    #[inline]\n    fn from(s: &'a str) -> Cow<'a, str> {\n        Cow::Borrowed(s)\n    }\n}\n\n#[cfg(not(no_global_oom_handling))]\n#[stable(feature = \"rust1\", since = \"1.0.0\")]\nimpl<'a> From<String> for Cow<'a, str> {\n    /// Converts a [`String`] into an [`Owned`] variant.\n    /// No heap allocation is performed, and the string\n    /// is not copied.\n    ///\n    /// # Example\n    ///\n    /// ```\n    /// # use std::borrow::Cow;\n    /// let s = \"eggplant\".to_string();\n    /// let s2 = \"eggplant\".to_string();\n    /// assert_eq!(Cow::from(s), Cow::<'static, str>::Owned(s2));\n    /// ```\n    ///\n    /// [`Owned`]: crate::borrow::Cow::Owned\n    #[inline]\n    fn from(s: String) -> Cow<'a, str> {\n        Cow::Owned(s)\n    }\n}\n\n#[cfg(not(no_global_oom_handling))]\n#[stable(feature = \"cow_from_string_ref\", since = \"1.28.0\")]\nimpl<'a> From<&'a String> for Cow<'a, str> {\n    /// Converts a [`String`] reference into a [`Borrowed`] variant.\n    /// No heap allocation is performed, and the string\n    /// is not copied.\n    ///\n    /// # Example\n    ///\n    /// ```\n    /// # use std::borrow::Cow;\n    /// let s = \"eggplant\".to_string();\n    /// assert_eq!(Cow::from(&s), Cow::Borrowed(\"eggplant\"));\n    /// ```\n    ///\n    /// [`Borrowed`]: crate::borrow::Cow::Borrowed\n    #[inline]\n    fn from(s: &'a String) -> Cow<'a, str> {\n        Cow::Borrowed(s.as_str())\n    }\n}\n\n#[cfg(not(no_global_oom_handling))]\n#[stable(feature = \"cow_str_from_iter\", since = \"1.12.0\")]\nimpl<'a> FromIterator<char> for Cow<'a, str> {\n    fn from_iter<I: IntoIterator<Item = char>>(it: I) -> Cow<'a, str> {\n        Cow::Owned(FromIterator::from_iter(it))\n    }\n}\n\n#[cfg(not(no_global_oom_handling))]\n#[stable(feature = \"cow_str_from_iter\", since = \"1.12.0\")]\nimpl<'a, 'b> FromIterator<&'b str> for Cow<'a, str> {\n    fn from_iter<I: IntoIterator<Item = &'b str>>(it: I) -> Cow<'a, str> {\n        Cow::Owned(FromIterator::from_iter(it))\n    }\n}\n\n#[cfg(not(no_global_oom_handling))]\n#[stable(feature = \"cow_str_from_iter\", since = \"1.12.0\")]\nimpl<'a> FromIterator<String> for Cow<'a, str> {\n    fn from_iter<I: IntoIterator<Item = String>>(it: I) -> Cow<'a, str> {\n        Cow::Owned(FromIterator::from_iter(it))\n    }\n}\n\n#[stable(feature = \"from_string_for_vec_u8\", since = \"1.14.0\")]\nimpl From<String> for Vec<u8> {\n    /// Converts the given [`String`] to a vector [`Vec`] that holds values of type [`u8`].\n    ///\n    /// # Examples\n    ///\n    /// Basic usage:\n    ///\n    /// ```\n    /// let s1 = String::from(\"hello world\");\n    /// let v1 = Vec::from(s1);\n    ///\n    /// for b in v1 {\n    ///     println!(\"{}\", b);\n    /// }\n    /// ```\n    fn from(string: String) -> Vec<u8> {\n        string.into_bytes()\n    }\n}\n\n#[cfg(not(no_global_oom_handling))]\n#[stable(feature = \"rust1\", since = \"1.0.0\")]\nimpl fmt::Write for String {\n    #[inline]\n    fn write_str(&mut self, s: &str) -> fmt::Result {\n        self.push_str(s);\n        Ok(())\n    }\n\n    #[inline]\n    fn write_char(&mut self, c: char) -> fmt::Result {\n        self.push(c);\n        Ok(())\n    }\n}\n\n/// A draining iterator for `String`.\n///\n/// This struct is created by the [`drain`] method on [`String`]. See its\n/// documentation for more.\n///\n/// [`drain`]: String::drain\n#[stable(feature = \"drain\", since = \"1.6.0\")]\npub struct Drain<'a> {\n    /// Will be used as &'a mut String in the destructor\n    string: *mut String,\n    /// Start of part to remove\n    start: usize,\n    /// End of part to remove\n    end: usize,\n    /// Current remaining range to remove\n    iter: Chars<'a>,\n}\n\n#[stable(feature = \"collection_debug\", since = \"1.17.0\")]\nimpl fmt::Debug for Drain<'_> {\n    fn fmt(&self, f: &mut fmt::Formatter<'_>) -> fmt::Result {\n        f.debug_tuple(\"Drain\").field(&self.as_str()).finish()\n    }\n}\n\n#[stable(feature = \"drain\", since = \"1.6.0\")]\nunsafe impl Sync for Drain<'_> {}\n#[stable(feature = \"drain\", since = \"1.6.0\")]\nunsafe impl Send for Drain<'_> {}\n\n#[stable(feature = \"drain\", since = \"1.6.0\")]\nimpl Drop for Drain<'_> {\n    fn drop(&mut self) {\n        unsafe {\n            // Use Vec::drain. \"Reaffirm\" the bounds checks to avoid\n            // panic code being inserted again.\n            let self_vec = (*self.string).as_mut_vec();\n            if self.start <= self.end && self.end <= self_vec.len() {\n                self_vec.drain(self.start..self.end);\n            }\n        }\n    }\n}\n\nimpl<'a> Drain<'a> {\n    /// Returns the remaining (sub)string of this iterator as a slice.\n    ///\n    /// # Examples\n    ///\n    /// ```\n    /// #![feature(string_drain_as_str)]\n    /// let mut s = String::from(\"abc\");\n    /// let mut drain = s.drain(..);\n    /// assert_eq!(drain.as_str(), \"abc\");\n    /// let _ = drain.next().unwrap();\n    /// assert_eq!(drain.as_str(), \"bc\");\n    /// ```\n    #[unstable(feature = \"string_drain_as_str\", issue = \"76905\")] // Note: uncomment AsRef impls below when stabilizing.\n    pub fn as_str(&self) -> &str {\n        self.iter.as_str()\n    }\n}\n\n// Uncomment when stabilizing `string_drain_as_str`.\n// #[unstable(feature = \"string_drain_as_str\", issue = \"76905\")]\n// impl<'a> AsRef<str> for Drain<'a> {\n//     fn as_ref(&self) -> &str {\n//         self.as_str()\n//     }\n// }\n//\n// #[unstable(feature = \"string_drain_as_str\", issue = \"76905\")]\n// impl<'a> AsRef<[u8]> for Drain<'a> {\n//     fn as_ref(&self) -> &[u8] {\n//         self.as_str().as_bytes()\n//     }\n// }\n\n#[stable(feature = \"drain\", since = \"1.6.0\")]\nimpl Iterator for Drain<'_> {\n    type Item = char;\n\n    #[inline]\n    fn next(&mut self) -> Option<char> {\n        self.iter.next()\n    }\n\n    fn size_hint(&self) -> (usize, Option<usize>) {\n        self.iter.size_hint()\n    }\n\n    #[inline]\n    fn last(mut self) -> Option<char> {\n        self.next_back()\n    }\n}\n\n#[stable(feature = \"drain\", since = \"1.6.0\")]\nimpl DoubleEndedIterator for Drain<'_> {\n    #[inline]\n    fn next_back(&mut self) -> Option<char> {\n        self.iter.next_back()\n    }\n}\n\n#[stable(feature = \"fused\", since = \"1.26.0\")]\nimpl FusedIterator for Drain<'_> {}\n\n#[cfg(not(no_global_oom_handling))]\n#[stable(feature = \"from_char_for_string\", since = \"1.46.0\")]\nimpl From<char> for String {\n    /// Allocates an owned [`String`] from a single character.\n    ///\n    /// # Example\n    /// ```rust\n    /// let c: char = 'a';\n    /// let s: String = String::from(c);\n    /// assert_eq!(\"a\", &s[..]);\n    /// ```\n    #[inline]\n    fn from(c: char) -> Self {\n        c.to_string()\n    }\n}\n"],[2013,"//! A doubly-linked list with owned nodes.\n//!\n//! The `LinkedList` allows pushing and popping elements at either end\n//! in constant time.\n//!\n//! NOTE: It is almost always better to use [`Vec`] or [`VecDeque`] because\n//! array-based containers are generally faster,\n//! more memory efficient, and make better use of CPU cache.\n//!\n//! [`Vec`]: crate::vec::Vec\n//! [`VecDeque`]: super::vec_deque::VecDeque\n\n#![stable(feature = \"rust1\", since = \"1.0.0\")]\n\nuse core::cmp::Ordering;\nuse core::fmt;\nuse core::hash::{Hash, Hasher};\nuse core::iter::{FromIterator, FusedIterator};\nuse core::marker::PhantomData;\nuse core::mem;\nuse core::ptr::NonNull;\n\nuse super::SpecExtend;\nuse crate::boxed::Box;\n\n#[cfg(test)]\nmod tests;\n\n/// A doubly-linked list with owned nodes.\n///\n/// The `LinkedList` allows pushing and popping elements at either end\n/// in constant time.\n///\n/// NOTE: It is almost always better to use `Vec` or `VecDeque` because\n/// array-based containers are generally faster,\n/// more memory efficient, and make better use of CPU cache.\n#[stable(feature = \"rust1\", since = \"1.0.0\")]\n#[cfg_attr(not(test), rustc_diagnostic_item = \"LinkedList\")]\npub struct LinkedList<T> {\n    head: Option<NonNull<Node<T>>>,\n    tail: Option<NonNull<Node<T>>>,\n    len: usize,\n    marker: PhantomData<Box<Node<T>>>,\n}\n\nstruct Node<T> {\n    next: Option<NonNull<Node<T>>>,\n    prev: Option<NonNull<Node<T>>>,\n    element: T,\n}\n\n/// An iterator over the elements of a `LinkedList`.\n///\n/// This `struct` is created by [`LinkedList::iter()`]. See its\n/// documentation for more.\n#[stable(feature = \"rust1\", since = \"1.0.0\")]\npub struct Iter<'a, T: 'a> {\n    head: Option<NonNull<Node<T>>>,\n    tail: Option<NonNull<Node<T>>>,\n    len: usize,\n    marker: PhantomData<&'a Node<T>>,\n}\n\n#[stable(feature = \"collection_debug\", since = \"1.17.0\")]\nimpl<T: fmt::Debug> fmt::Debug for Iter<'_, T> {\n    fn fmt(&self, f: &mut fmt::Formatter<'_>) -> fmt::Result {\n        f.debug_tuple(\"Iter\")\n            .field(&*mem::ManuallyDrop::new(LinkedList {\n                head: self.head,\n                tail: self.tail,\n                len: self.len,\n                marker: PhantomData,\n            }))\n            .field(&self.len)\n            .finish()\n    }\n}\n\n// FIXME(#26925) Remove in favor of `#[derive(Clone)]`\n#[stable(feature = \"rust1\", since = \"1.0.0\")]\nimpl<T> Clone for Iter<'_, T> {\n    fn clone(&self) -> Self {\n        Iter { ..*self }\n    }\n}\n\n/// A mutable iterator over the elements of a `LinkedList`.\n///\n/// This `struct` is created by [`LinkedList::iter_mut()`]. See its\n/// documentation for more.\n#[stable(feature = \"rust1\", since = \"1.0.0\")]\npub struct IterMut<'a, T: 'a> {\n    head: Option<NonNull<Node<T>>>,\n    tail: Option<NonNull<Node<T>>>,\n    len: usize,\n    marker: PhantomData<&'a mut Node<T>>,\n}\n\n#[stable(feature = \"collection_debug\", since = \"1.17.0\")]\nimpl<T: fmt::Debug> fmt::Debug for IterMut<'_, T> {\n    fn fmt(&self, f: &mut fmt::Formatter<'_>) -> fmt::Result {\n        f.debug_tuple(\"IterMut\")\n            .field(&*mem::ManuallyDrop::new(LinkedList {\n                head: self.head,\n                tail: self.tail,\n                len: self.len,\n                marker: PhantomData,\n            }))\n            .field(&self.len)\n            .finish()\n    }\n}\n\n/// An owning iterator over the elements of a `LinkedList`.\n///\n/// This `struct` is created by the [`into_iter`] method on [`LinkedList`]\n/// (provided by the `IntoIterator` trait). See its documentation for more.\n///\n/// [`into_iter`]: LinkedList::into_iter\n#[derive(Clone)]\n#[stable(feature = \"rust1\", since = \"1.0.0\")]\npub struct IntoIter<T> {\n    list: LinkedList<T>,\n}\n\n#[stable(feature = \"collection_debug\", since = \"1.17.0\")]\nimpl<T: fmt::Debug> fmt::Debug for IntoIter<T> {\n    fn fmt(&self, f: &mut fmt::Formatter<'_>) -> fmt::Result {\n        f.debug_tuple(\"IntoIter\").field(&self.list).finish()\n    }\n}\n\nimpl<T> Node<T> {\n    fn new(element: T) -> Self {\n        Node { next: None, prev: None, element }\n    }\n\n    fn into_element(self: Box<Self>) -> T {\n        self.element\n    }\n}\n\n// private methods\nimpl<T> LinkedList<T> {\n    /// Adds the given node to the front of the list.\n    #[inline]\n    fn push_front_node(&mut self, mut node: Box<Node<T>>) {\n        // This method takes care not to create mutable references to whole nodes,\n        // to maintain validity of aliasing pointers into `element`.\n        unsafe {\n            node.next = self.head;\n            node.prev = None;\n            let node = Some(Box::leak(node).into());\n\n            match self.head {\n                None => self.tail = node,\n                // Not creating new mutable (unique!) references overlapping `element`.\n                Some(head) => (*head.as_ptr()).prev = node,\n            }\n\n            self.head = node;\n            self.len += 1;\n        }\n    }\n\n    /// Removes and returns the node at the front of the list.\n    #[inline]\n    fn pop_front_node(&mut self) -> Option<Box<Node<T>>> {\n        // This method takes care not to create mutable references to whole nodes,\n        // to maintain validity of aliasing pointers into `element`.\n        self.head.map(|node| unsafe {\n            let node = Box::from_raw(node.as_ptr());\n            self.head = node.next;\n\n            match self.head {\n                None => self.tail = None,\n                // Not creating new mutable (unique!) references overlapping `element`.\n                Some(head) => (*head.as_ptr()).prev = None,\n            }\n\n            self.len -= 1;\n            node\n        })\n    }\n\n    /// Adds the given node to the back of the list.\n    #[inline]\n    fn push_back_node(&mut self, mut node: Box<Node<T>>) {\n        // This method takes care not to create mutable references to whole nodes,\n        // to maintain validity of aliasing pointers into `element`.\n        unsafe {\n            node.next = None;\n            node.prev = self.tail;\n            let node = Some(Box::leak(node).into());\n\n            match self.tail {\n                None => self.head = node,\n                // Not creating new mutable (unique!) references overlapping `element`.\n                Some(tail) => (*tail.as_ptr()).next = node,\n            }\n\n            self.tail = node;\n            self.len += 1;\n        }\n    }\n\n    /// Removes and returns the node at the back of the list.\n    #[inline]\n    fn pop_back_node(&mut self) -> Option<Box<Node<T>>> {\n        // This method takes care not to create mutable references to whole nodes,\n        // to maintain validity of aliasing pointers into `element`.\n        self.tail.map(|node| unsafe {\n            let node = Box::from_raw(node.as_ptr());\n            self.tail = node.prev;\n\n            match self.tail {\n                None => self.head = None,\n                // Not creating new mutable (unique!) references overlapping `element`.\n                Some(tail) => (*tail.as_ptr()).next = None,\n            }\n\n            self.len -= 1;\n            node\n        })\n    }\n\n    /// Unlinks the specified node from the current list.\n    ///\n    /// Warning: this will not check that the provided node belongs to the current list.\n    ///\n    /// This method takes care not to create mutable references to `element`, to\n    /// maintain validity of aliasing pointers.\n    #[inline]\n    unsafe fn unlink_node(&mut self, mut node: NonNull<Node<T>>) {\n        let node = unsafe { node.as_mut() }; // this one is ours now, we can create an &mut.\n\n        // Not creating new mutable (unique!) references overlapping `element`.\n        match node.prev {\n            Some(prev) => unsafe { (*prev.as_ptr()).next = node.next },\n            // this node is the head node\n            None => self.head = node.next,\n        };\n\n        match node.next {\n            Some(next) => unsafe { (*next.as_ptr()).prev = node.prev },\n            // this node is the tail node\n            None => self.tail = node.prev,\n        };\n\n        self.len -= 1;\n    }\n\n    /// Splices a series of nodes between two existing nodes.\n    ///\n    /// Warning: this will not check that the provided node belongs to the two existing lists.\n    #[inline]\n    unsafe fn splice_nodes(\n        &mut self,\n        existing_prev: Option<NonNull<Node<T>>>,\n        existing_next: Option<NonNull<Node<T>>>,\n        mut splice_start: NonNull<Node<T>>,\n        mut splice_end: NonNull<Node<T>>,\n        splice_length: usize,\n    ) {\n        // This method takes care not to create multiple mutable references to whole nodes at the same time,\n        // to maintain validity of aliasing pointers into `element`.\n        if let Some(mut existing_prev) = existing_prev {\n            unsafe {\n                existing_prev.as_mut().next = Some(splice_start);\n            }\n        } else {\n            self.head = Some(splice_start);\n        }\n        if let Some(mut existing_next) = existing_next {\n            unsafe {\n                existing_next.as_mut().prev = Some(splice_end);\n            }\n        } else {\n            self.tail = Some(splice_end);\n        }\n        unsafe {\n            splice_start.as_mut().prev = existing_prev;\n            splice_end.as_mut().next = existing_next;\n        }\n\n        self.len += splice_length;\n    }\n\n    /// Detaches all nodes from a linked list as a series of nodes.\n    #[inline]\n    fn detach_all_nodes(mut self) -> Option<(NonNull<Node<T>>, NonNull<Node<T>>, usize)> {\n        let head = self.head.take();\n        let tail = self.tail.take();\n        let len = mem::replace(&mut self.len, 0);\n        if let Some(head) = head {\n            let tail = tail.unwrap_or_else(|| unsafe { core::hint::unreachable_unchecked() });\n            Some((head, tail, len))\n        } else {\n            None\n        }\n    }\n\n    #[inline]\n    unsafe fn split_off_before_node(\n        &mut self,\n        split_node: Option<NonNull<Node<T>>>,\n        at: usize,\n    ) -> Self {\n        // The split node is the new head node of the second part\n        if let Some(mut split_node) = split_node {\n            let first_part_head;\n            let first_part_tail;\n            unsafe {\n                first_part_tail = split_node.as_mut().prev.take();\n            }\n            if let Some(mut tail) = first_part_tail {\n                unsafe {\n                    tail.as_mut().next = None;\n                }\n                first_part_head = self.head;\n            } else {\n                first_part_head = None;\n            }\n\n            let first_part = LinkedList {\n                head: first_part_head,\n                tail: first_part_tail,\n                len: at,\n                marker: PhantomData,\n            };\n\n            // Fix the head ptr of the second part\n            self.head = Some(split_node);\n            self.len = self.len - at;\n\n            first_part\n        } else {\n            mem::replace(self, LinkedList::new())\n        }\n    }\n\n    #[inline]\n    unsafe fn split_off_after_node(\n        &mut self,\n        split_node: Option<NonNull<Node<T>>>,\n        at: usize,\n    ) -> Self {\n        // The split node is the new tail node of the first part and owns\n        // the head of the second part.\n        if let Some(mut split_node) = split_node {\n            let second_part_head;\n            let second_part_tail;\n            unsafe {\n                second_part_head = split_node.as_mut().next.take();\n            }\n            if let Some(mut head) = second_part_head {\n                unsafe {\n                    head.as_mut().prev = None;\n                }\n                second_part_tail = self.tail;\n            } else {\n                second_part_tail = None;\n            }\n\n            let second_part = LinkedList {\n                head: second_part_head,\n                tail: second_part_tail,\n                len: self.len - at,\n                marker: PhantomData,\n            };\n\n            // Fix the tail ptr of the first part\n            self.tail = Some(split_node);\n            self.len = at;\n\n            second_part\n        } else {\n            mem::replace(self, LinkedList::new())\n        }\n    }\n}\n\n#[stable(feature = \"rust1\", since = \"1.0.0\")]\nimpl<T> Default for LinkedList<T> {\n    /// Creates an empty `LinkedList<T>`.\n    #[inline]\n    fn default() -> Self {\n        Self::new()\n    }\n}\n\nimpl<T> LinkedList<T> {\n    /// Creates an empty `LinkedList`.\n    ///\n    /// # Examples\n    ///\n    /// ```\n    /// use std::collections::LinkedList;\n    ///\n    /// let list: LinkedList<u32> = LinkedList::new();\n    /// ```\n    #[inline]\n    #[rustc_const_stable(feature = \"const_linked_list_new\", since = \"1.32.0\")]\n    #[stable(feature = \"rust1\", since = \"1.0.0\")]\n    pub const fn new() -> Self {\n        LinkedList { head: None, tail: None, len: 0, marker: PhantomData }\n    }\n\n    /// Moves all elements from `other` to the end of the list.\n    ///\n    /// This reuses all the nodes from `other` and moves them into `self`. After\n    /// this operation, `other` becomes empty.\n    ///\n    /// This operation should compute in *O*(1) time and *O*(1) memory.\n    ///\n    /// # Examples\n    ///\n    /// ```\n    /// use std::collections::LinkedList;\n    ///\n    /// let mut list1 = LinkedList::new();\n    /// list1.push_back('a');\n    ///\n    /// let mut list2 = LinkedList::new();\n    /// list2.push_back('b');\n    /// list2.push_back('c');\n    ///\n    /// list1.append(&mut list2);\n    ///\n    /// let mut iter = list1.iter();\n    /// assert_eq!(iter.next(), Some(&'a'));\n    /// assert_eq!(iter.next(), Some(&'b'));\n    /// assert_eq!(iter.next(), Some(&'c'));\n    /// assert!(iter.next().is_none());\n    ///\n    /// assert!(list2.is_empty());\n    /// ```\n    #[stable(feature = \"rust1\", since = \"1.0.0\")]\n    pub fn append(&mut self, other: &mut Self) {\n        match self.tail {\n            None => mem::swap(self, other),\n            Some(mut tail) => {\n                // `as_mut` is okay here because we have exclusive access to the entirety\n                // of both lists.\n                if let Some(mut other_head) = other.head.take() {\n                    unsafe {\n                        tail.as_mut().next = Some(other_head);\n                        other_head.as_mut().prev = Some(tail);\n                    }\n\n                    self.tail = other.tail.take();\n                    self.len += mem::replace(&mut other.len, 0);\n                }\n            }\n        }\n    }\n\n    /// Provides a forward iterator.\n    ///\n    /// # Examples\n    ///\n    /// ```\n    /// use std::collections::LinkedList;\n    ///\n    /// let mut list: LinkedList<u32> = LinkedList::new();\n    ///\n    /// list.push_back(0);\n    /// list.push_back(1);\n    /// list.push_back(2);\n    ///\n    /// let mut iter = list.iter();\n    /// assert_eq!(iter.next(), Some(&0));\n    /// assert_eq!(iter.next(), Some(&1));\n    /// assert_eq!(iter.next(), Some(&2));\n    /// assert_eq!(iter.next(), None);\n    /// ```\n    #[inline]\n    #[stable(feature = \"rust1\", since = \"1.0.0\")]\n    pub fn iter(&self) -> Iter<'_, T> {\n        Iter { head: self.head, tail: self.tail, len: self.len, marker: PhantomData }\n    }\n\n    /// Provides a forward iterator with mutable references.\n    ///\n    /// # Examples\n    ///\n    /// ```\n    /// use std::collections::LinkedList;\n    ///\n    /// let mut list: LinkedList<u32> = LinkedList::new();\n    ///\n    /// list.push_back(0);\n    /// list.push_back(1);\n    /// list.push_back(2);\n    ///\n    /// for element in list.iter_mut() {\n    ///     *element += 10;\n    /// }\n    ///\n    /// let mut iter = list.iter();\n    /// assert_eq!(iter.next(), Some(&10));\n    /// assert_eq!(iter.next(), Some(&11));\n    /// assert_eq!(iter.next(), Some(&12));\n    /// assert_eq!(iter.next(), None);\n    /// ```\n    #[inline]\n    #[stable(feature = \"rust1\", since = \"1.0.0\")]\n    pub fn iter_mut(&mut self) -> IterMut<'_, T> {\n        IterMut { head: self.head, tail: self.tail, len: self.len, marker: PhantomData }\n    }\n\n    /// Provides a cursor at the front element.\n    ///\n    /// The cursor is pointing to the \"ghost\" non-element if the list is empty.\n    #[inline]\n    #[unstable(feature = \"linked_list_cursors\", issue = \"58533\")]\n    pub fn cursor_front(&self) -> Cursor<'_, T> {\n        Cursor { index: 0, current: self.head, list: self }\n    }\n\n    /// Provides a cursor with editing operations at the front element.\n    ///\n    /// The cursor is pointing to the \"ghost\" non-element if the list is empty.\n    #[inline]\n    #[unstable(feature = \"linked_list_cursors\", issue = \"58533\")]\n    pub fn cursor_front_mut(&mut self) -> CursorMut<'_, T> {\n        CursorMut { index: 0, current: self.head, list: self }\n    }\n\n    /// Provides a cursor at the back element.\n    ///\n    /// The cursor is pointing to the \"ghost\" non-element if the list is empty.\n    #[inline]\n    #[unstable(feature = \"linked_list_cursors\", issue = \"58533\")]\n    pub fn cursor_back(&self) -> Cursor<'_, T> {\n        Cursor { index: self.len.checked_sub(1).unwrap_or(0), current: self.tail, list: self }\n    }\n\n    /// Provides a cursor with editing operations at the back element.\n    ///\n    /// The cursor is pointing to the \"ghost\" non-element if the list is empty.\n    #[inline]\n    #[unstable(feature = \"linked_list_cursors\", issue = \"58533\")]\n    pub fn cursor_back_mut(&mut self) -> CursorMut<'_, T> {\n        CursorMut { index: self.len.checked_sub(1).unwrap_or(0), current: self.tail, list: self }\n    }\n\n    /// Returns `true` if the `LinkedList` is empty.\n    ///\n    /// This operation should compute in *O*(1) time.\n    ///\n    /// # Examples\n    ///\n    /// ```\n    /// use std::collections::LinkedList;\n    ///\n    /// let mut dl = LinkedList::new();\n    /// assert!(dl.is_empty());\n    ///\n    /// dl.push_front(\"foo\");\n    /// assert!(!dl.is_empty());\n    /// ```\n    #[inline]\n    #[stable(feature = \"rust1\", since = \"1.0.0\")]\n    pub fn is_empty(&self) -> bool {\n        self.head.is_none()\n    }\n\n    /// Returns the length of the `LinkedList`.\n    ///\n    /// This operation should compute in *O*(1) time.\n    ///\n    /// # Examples\n    ///\n    /// ```\n    /// use std::collections::LinkedList;\n    ///\n    /// let mut dl = LinkedList::new();\n    ///\n    /// dl.push_front(2);\n    /// assert_eq!(dl.len(), 1);\n    ///\n    /// dl.push_front(1);\n    /// assert_eq!(dl.len(), 2);\n    ///\n    /// dl.push_back(3);\n    /// assert_eq!(dl.len(), 3);\n    /// ```\n    #[doc(alias = \"length\")]\n    #[inline]\n    #[stable(feature = \"rust1\", since = \"1.0.0\")]\n    pub fn len(&self) -> usize {\n        self.len\n    }\n\n    /// Removes all elements from the `LinkedList`.\n    ///\n    /// This operation should compute in *O*(*n*) time.\n    ///\n    /// # Examples\n    ///\n    /// ```\n    /// use std::collections::LinkedList;\n    ///\n    /// let mut dl = LinkedList::new();\n    ///\n    /// dl.push_front(2);\n    /// dl.push_front(1);\n    /// assert_eq!(dl.len(), 2);\n    /// assert_eq!(dl.front(), Some(&1));\n    ///\n    /// dl.clear();\n    /// assert_eq!(dl.len(), 0);\n    /// assert_eq!(dl.front(), None);\n    /// ```\n    #[inline]\n    #[stable(feature = \"rust1\", since = \"1.0.0\")]\n    pub fn clear(&mut self) {\n        *self = Self::new();\n    }\n\n    /// Returns `true` if the `LinkedList` contains an element equal to the\n    /// given value.\n    ///\n    /// # Examples\n    ///\n    /// ```\n    /// use std::collections::LinkedList;\n    ///\n    /// let mut list: LinkedList<u32> = LinkedList::new();\n    ///\n    /// list.push_back(0);\n    /// list.push_back(1);\n    /// list.push_back(2);\n    ///\n    /// assert_eq!(list.contains(&0), true);\n    /// assert_eq!(list.contains(&10), false);\n    /// ```\n    #[stable(feature = \"linked_list_contains\", since = \"1.12.0\")]\n    pub fn contains(&self, x: &T) -> bool\n    where\n        T: PartialEq<T>,\n    {\n        self.iter().any(|e| e == x)\n    }\n\n    /// Provides a reference to the front element, or `None` if the list is\n    /// empty.\n    ///\n    /// # Examples\n    ///\n    /// ```\n    /// use std::collections::LinkedList;\n    ///\n    /// let mut dl = LinkedList::new();\n    /// assert_eq!(dl.front(), None);\n    ///\n    /// dl.push_front(1);\n    /// assert_eq!(dl.front(), Some(&1));\n    /// ```\n    #[inline]\n    #[stable(feature = \"rust1\", since = \"1.0.0\")]\n    pub fn front(&self) -> Option<&T> {\n        unsafe { self.head.as_ref().map(|node| &node.as_ref().element) }\n    }\n\n    /// Provides a mutable reference to the front element, or `None` if the list\n    /// is empty.\n    ///\n    /// # Examples\n    ///\n    /// ```\n    /// use std::collections::LinkedList;\n    ///\n    /// let mut dl = LinkedList::new();\n    /// assert_eq!(dl.front(), None);\n    ///\n    /// dl.push_front(1);\n    /// assert_eq!(dl.front(), Some(&1));\n    ///\n    /// match dl.front_mut() {\n    ///     None => {},\n    ///     Some(x) => *x = 5,\n    /// }\n    /// assert_eq!(dl.front(), Some(&5));\n    /// ```\n    #[inline]\n    #[stable(feature = \"rust1\", since = \"1.0.0\")]\n    pub fn front_mut(&mut self) -> Option<&mut T> {\n        unsafe { self.head.as_mut().map(|node| &mut node.as_mut().element) }\n    }\n\n    /// Provides a reference to the back element, or `None` if the list is\n    /// empty.\n    ///\n    /// # Examples\n    ///\n    /// ```\n    /// use std::collections::LinkedList;\n    ///\n    /// let mut dl = LinkedList::new();\n    /// assert_eq!(dl.back(), None);\n    ///\n    /// dl.push_back(1);\n    /// assert_eq!(dl.back(), Some(&1));\n    /// ```\n    #[inline]\n    #[stable(feature = \"rust1\", since = \"1.0.0\")]\n    pub fn back(&self) -> Option<&T> {\n        unsafe { self.tail.as_ref().map(|node| &node.as_ref().element) }\n    }\n\n    /// Provides a mutable reference to the back element, or `None` if the list\n    /// is empty.\n    ///\n    /// # Examples\n    ///\n    /// ```\n    /// use std::collections::LinkedList;\n    ///\n    /// let mut dl = LinkedList::new();\n    /// assert_eq!(dl.back(), None);\n    ///\n    /// dl.push_back(1);\n    /// assert_eq!(dl.back(), Some(&1));\n    ///\n    /// match dl.back_mut() {\n    ///     None => {},\n    ///     Some(x) => *x = 5,\n    /// }\n    /// assert_eq!(dl.back(), Some(&5));\n    /// ```\n    #[inline]\n    #[stable(feature = \"rust1\", since = \"1.0.0\")]\n    pub fn back_mut(&mut self) -> Option<&mut T> {\n        unsafe { self.tail.as_mut().map(|node| &mut node.as_mut().element) }\n    }\n\n    /// Adds an element first in the list.\n    ///\n    /// This operation should compute in *O*(1) time.\n    ///\n    /// # Examples\n    ///\n    /// ```\n    /// use std::collections::LinkedList;\n    ///\n    /// let mut dl = LinkedList::new();\n    ///\n    /// dl.push_front(2);\n    /// assert_eq!(dl.front().unwrap(), &2);\n    ///\n    /// dl.push_front(1);\n    /// assert_eq!(dl.front().unwrap(), &1);\n    /// ```\n    #[stable(feature = \"rust1\", since = \"1.0.0\")]\n    pub fn push_front(&mut self, elt: T) {\n        self.push_front_node(box Node::new(elt));\n    }\n\n    /// Removes the first element and returns it, or `None` if the list is\n    /// empty.\n    ///\n    /// This operation should compute in *O*(1) time.\n    ///\n    /// # Examples\n    ///\n    /// ```\n    /// use std::collections::LinkedList;\n    ///\n    /// let mut d = LinkedList::new();\n    /// assert_eq!(d.pop_front(), None);\n    ///\n    /// d.push_front(1);\n    /// d.push_front(3);\n    /// assert_eq!(d.pop_front(), Some(3));\n    /// assert_eq!(d.pop_front(), Some(1));\n    /// assert_eq!(d.pop_front(), None);\n    /// ```\n    #[stable(feature = \"rust1\", since = \"1.0.0\")]\n    pub fn pop_front(&mut self) -> Option<T> {\n        self.pop_front_node().map(Node::into_element)\n    }\n\n    /// Appends an element to the back of a list.\n    ///\n    /// This operation should compute in *O*(1) time.\n    ///\n    /// # Examples\n    ///\n    /// ```\n    /// use std::collections::LinkedList;\n    ///\n    /// let mut d = LinkedList::new();\n    /// d.push_back(1);\n    /// d.push_back(3);\n    /// assert_eq!(3, *d.back().unwrap());\n    /// ```\n    #[stable(feature = \"rust1\", since = \"1.0.0\")]\n    pub fn push_back(&mut self, elt: T) {\n        self.push_back_node(box Node::new(elt));\n    }\n\n    /// Removes the last element from a list and returns it, or `None` if\n    /// it is empty.\n    ///\n    /// This operation should compute in *O*(1) time.\n    ///\n    /// # Examples\n    ///\n    /// ```\n    /// use std::collections::LinkedList;\n    ///\n    /// let mut d = LinkedList::new();\n    /// assert_eq!(d.pop_back(), None);\n    /// d.push_back(1);\n    /// d.push_back(3);\n    /// assert_eq!(d.pop_back(), Some(3));\n    /// ```\n    #[stable(feature = \"rust1\", since = \"1.0.0\")]\n    pub fn pop_back(&mut self) -> Option<T> {\n        self.pop_back_node().map(Node::into_element)\n    }\n\n    /// Splits the list into two at the given index. Returns everything after the given index,\n    /// including the index.\n    ///\n    /// This operation should compute in *O*(*n*) time.\n    ///\n    /// # Panics\n    ///\n    /// Panics if `at > len`.\n    ///\n    /// # Examples\n    ///\n    /// ```\n    /// use std::collections::LinkedList;\n    ///\n    /// let mut d = LinkedList::new();\n    ///\n    /// d.push_front(1);\n    /// d.push_front(2);\n    /// d.push_front(3);\n    ///\n    /// let mut split = d.split_off(2);\n    ///\n    /// assert_eq!(split.pop_front(), Some(1));\n    /// assert_eq!(split.pop_front(), None);\n    /// ```\n    #[stable(feature = \"rust1\", since = \"1.0.0\")]\n    pub fn split_off(&mut self, at: usize) -> LinkedList<T> {\n        let len = self.len();\n        assert!(at <= len, \"Cannot split off at a nonexistent index\");\n        if at == 0 {\n            return mem::take(self);\n        } else if at == len {\n            return Self::new();\n        }\n\n        // Below, we iterate towards the `i-1`th node, either from the start or the end,\n        // depending on which would be faster.\n        let split_node = if at - 1 <= len - 1 - (at - 1) {\n            let mut iter = self.iter_mut();\n            // instead of skipping using .skip() (which creates a new struct),\n            // we skip manually so we can access the head field without\n            // depending on implementation details of Skip\n            for _ in 0..at - 1 {\n                iter.next();\n            }\n            iter.head\n        } else {\n            // better off starting from the end\n            let mut iter = self.iter_mut();\n            for _ in 0..len - 1 - (at - 1) {\n                iter.next_back();\n            }\n            iter.tail\n        };\n        unsafe { self.split_off_after_node(split_node, at) }\n    }\n\n    /// Removes the element at the given index and returns it.\n    ///\n    /// This operation should compute in *O*(*n*) time.\n    ///\n    /// # Panics\n    /// Panics if at >= len\n    ///\n    /// # Examples\n    ///\n    /// ```\n    /// #![feature(linked_list_remove)]\n    /// use std::collections::LinkedList;\n    ///\n    /// let mut d = LinkedList::new();\n    ///\n    /// d.push_front(1);\n    /// d.push_front(2);\n    /// d.push_front(3);\n    ///\n    /// assert_eq!(d.remove(1), 2);\n    /// assert_eq!(d.remove(0), 3);\n    /// assert_eq!(d.remove(0), 1);\n    /// ```\n    #[unstable(feature = \"linked_list_remove\", issue = \"69210\")]\n    pub fn remove(&mut self, at: usize) -> T {\n        let len = self.len();\n        assert!(at < len, \"Cannot remove at an index outside of the list bounds\");\n\n        // Below, we iterate towards the node at the given index, either from\n        // the start or the end, depending on which would be faster.\n        let offset_from_end = len - at - 1;\n        if at <= offset_from_end {\n            let mut cursor = self.cursor_front_mut();\n            for _ in 0..at {\n                cursor.move_next();\n            }\n            cursor.remove_current().unwrap()\n        } else {\n            let mut cursor = self.cursor_back_mut();\n            for _ in 0..offset_from_end {\n                cursor.move_prev();\n            }\n            cursor.remove_current().unwrap()\n        }\n    }\n\n    /// Creates an iterator which uses a closure to determine if an element should be removed.\n    ///\n    /// If the closure returns true, then the element is removed and yielded.\n    /// If the closure returns false, the element will remain in the list and will not be yielded\n    /// by the iterator.\n    ///\n    /// Note that `drain_filter` lets you mutate every element in the filter closure, regardless of\n    /// whether you choose to keep or remove it.\n    ///\n    /// # Examples\n    ///\n    /// Splitting a list into evens and odds, reusing the original list:\n    ///\n    /// ```\n    /// #![feature(drain_filter)]\n    /// use std::collections::LinkedList;\n    ///\n    /// let mut numbers: LinkedList<u32> = LinkedList::new();\n    /// numbers.extend(&[1, 2, 3, 4, 5, 6, 8, 9, 11, 13, 14, 15]);\n    ///\n    /// let evens = numbers.drain_filter(|x| *x % 2 == 0).collect::<LinkedList<_>>();\n    /// let odds = numbers;\n    ///\n    /// assert_eq!(evens.into_iter().collect::<Vec<_>>(), vec![2, 4, 6, 8, 14]);\n    /// assert_eq!(odds.into_iter().collect::<Vec<_>>(), vec![1, 3, 5, 9, 11, 13, 15]);\n    /// ```\n    #[unstable(feature = \"drain_filter\", reason = \"recently added\", issue = \"43244\")]\n    pub fn drain_filter<F>(&mut self, filter: F) -> DrainFilter<'_, T, F>\n    where\n        F: FnMut(&mut T) -> bool,\n    {\n        // avoid borrow issues.\n        let it = self.head;\n        let old_len = self.len;\n\n        DrainFilter { list: self, it, pred: filter, idx: 0, old_len }\n    }\n}\n\n#[stable(feature = \"rust1\", since = \"1.0.0\")]\nunsafe impl<#[may_dangle] T> Drop for LinkedList<T> {\n    fn drop(&mut self) {\n        struct DropGuard<'a, T>(&'a mut LinkedList<T>);\n\n        impl<'a, T> Drop for DropGuard<'a, T> {\n            fn drop(&mut self) {\n                // Continue the same loop we do below. This only runs when a destructor has\n                // panicked. If another one panics this will abort.\n                while self.0.pop_front_node().is_some() {}\n            }\n        }\n\n        while let Some(node) = self.pop_front_node() {\n            let guard = DropGuard(self);\n            drop(node);\n            mem::forget(guard);\n        }\n    }\n}\n\n#[stable(feature = \"rust1\", since = \"1.0.0\")]\nimpl<'a, T> Iterator for Iter<'a, T> {\n    type Item = &'a T;\n\n    #[inline]\n    fn next(&mut self) -> Option<&'a T> {\n        if self.len == 0 {\n            None\n        } else {\n            self.head.map(|node| unsafe {\n                // Need an unbound lifetime to get 'a\n                let node = &*node.as_ptr();\n                self.len -= 1;\n                self.head = node.next;\n                &node.element\n            })\n        }\n    }\n\n    #[inline]\n    fn size_hint(&self) -> (usize, Option<usize>) {\n        (self.len, Some(self.len))\n    }\n\n    #[inline]\n    fn last(mut self) -> Option<&'a T> {\n        self.next_back()\n    }\n}\n\n#[stable(feature = \"rust1\", since = \"1.0.0\")]\nimpl<'a, T> DoubleEndedIterator for Iter<'a, T> {\n    #[inline]\n    fn next_back(&mut self) -> Option<&'a T> {\n        if self.len == 0 {\n            None\n        } else {\n            self.tail.map(|node| unsafe {\n                // Need an unbound lifetime to get 'a\n                let node = &*node.as_ptr();\n                self.len -= 1;\n                self.tail = node.prev;\n                &node.element\n            })\n        }\n    }\n}\n\n#[stable(feature = \"rust1\", since = \"1.0.0\")]\nimpl<T> ExactSizeIterator for Iter<'_, T> {}\n\n#[stable(feature = \"fused\", since = \"1.26.0\")]\nimpl<T> FusedIterator for Iter<'_, T> {}\n\n#[stable(feature = \"rust1\", since = \"1.0.0\")]\nimpl<'a, T> Iterator for IterMut<'a, T> {\n    type Item = &'a mut T;\n\n    #[inline]\n    fn next(&mut self) -> Option<&'a mut T> {\n        if self.len == 0 {\n            None\n        } else {\n            self.head.map(|node| unsafe {\n                // Need an unbound lifetime to get 'a\n                let node = &mut *node.as_ptr();\n                self.len -= 1;\n                self.head = node.next;\n                &mut node.element\n            })\n        }\n    }\n\n    #[inline]\n    fn size_hint(&self) -> (usize, Option<usize>) {\n        (self.len, Some(self.len))\n    }\n\n    #[inline]\n    fn last(mut self) -> Option<&'a mut T> {\n        self.next_back()\n    }\n}\n\n#[stable(feature = \"rust1\", since = \"1.0.0\")]\nimpl<'a, T> DoubleEndedIterator for IterMut<'a, T> {\n    #[inline]\n    fn next_back(&mut self) -> Option<&'a mut T> {\n        if self.len == 0 {\n            None\n        } else {\n            self.tail.map(|node| unsafe {\n                // Need an unbound lifetime to get 'a\n                let node = &mut *node.as_ptr();\n                self.len -= 1;\n                self.tail = node.prev;\n                &mut node.element\n            })\n        }\n    }\n}\n\n#[stable(feature = \"rust1\", since = \"1.0.0\")]\nimpl<T> ExactSizeIterator for IterMut<'_, T> {}\n\n#[stable(feature = \"fused\", since = \"1.26.0\")]\nimpl<T> FusedIterator for IterMut<'_, T> {}\n\n/// A cursor over a `LinkedList`.\n///\n/// A `Cursor` is like an iterator, except that it can freely seek back-and-forth.\n///\n/// Cursors always rest between two elements in the list, and index in a logically circular way.\n/// To accommodate this, there is a \"ghost\" non-element that yields `None` between the head and\n/// tail of the list.\n///\n/// When created, cursors start at the front of the list, or the \"ghost\" non-element if the list is empty.\n#[unstable(feature = \"linked_list_cursors\", issue = \"58533\")]\npub struct Cursor<'a, T: 'a> {\n    index: usize,\n    current: Option<NonNull<Node<T>>>,\n    list: &'a LinkedList<T>,\n}\n\n#[unstable(feature = \"linked_list_cursors\", issue = \"58533\")]\nimpl<T> Clone for Cursor<'_, T> {\n    fn clone(&self) -> Self {\n        let Cursor { index, current, list } = *self;\n        Cursor { index, current, list }\n    }\n}\n\n#[unstable(feature = \"linked_list_cursors\", issue = \"58533\")]\nimpl<T: fmt::Debug> fmt::Debug for Cursor<'_, T> {\n    fn fmt(&self, f: &mut fmt::Formatter<'_>) -> fmt::Result {\n        f.debug_tuple(\"Cursor\").field(&self.list).field(&self.index()).finish()\n    }\n}\n\n/// A cursor over a `LinkedList` with editing operations.\n///\n/// A `Cursor` is like an iterator, except that it can freely seek back-and-forth, and can\n/// safely mutate the list during iteration. This is because the lifetime of its yielded\n/// references is tied to its own lifetime, instead of just the underlying list. This means\n/// cursors cannot yield multiple elements at once.\n///\n/// Cursors always rest between two elements in the list, and index in a logically circular way.\n/// To accommodate this, there is a \"ghost\" non-element that yields `None` between the head and\n/// tail of the list.\n#[unstable(feature = \"linked_list_cursors\", issue = \"58533\")]\npub struct CursorMut<'a, T: 'a> {\n    index: usize,\n    current: Option<NonNull<Node<T>>>,\n    list: &'a mut LinkedList<T>,\n}\n\n#[unstable(feature = \"linked_list_cursors\", issue = \"58533\")]\nimpl<T: fmt::Debug> fmt::Debug for CursorMut<'_, T> {\n    fn fmt(&self, f: &mut fmt::Formatter<'_>) -> fmt::Result {\n        f.debug_tuple(\"CursorMut\").field(&self.list).field(&self.index()).finish()\n    }\n}\n\nimpl<'a, T> Cursor<'a, T> {\n    /// Returns the cursor position index within the `LinkedList`.\n    ///\n    /// This returns `None` if the cursor is currently pointing to the\n    /// \"ghost\" non-element.\n    #[unstable(feature = \"linked_list_cursors\", issue = \"58533\")]\n    pub fn index(&self) -> Option<usize> {\n        let _ = self.current?;\n        Some(self.index)\n    }\n\n    /// Moves the cursor to the next element of the `LinkedList`.\n    ///\n    /// If the cursor is pointing to the \"ghost\" non-element then this will move it to\n    /// the first element of the `LinkedList`. If it is pointing to the last\n    /// element of the `LinkedList` then this will move it to the \"ghost\" non-element.\n    #[unstable(feature = \"linked_list_cursors\", issue = \"58533\")]\n    pub fn move_next(&mut self) {\n        match self.current.take() {\n            // We had no current element; the cursor was sitting at the start position\n            // Next element should be the head of the list\n            None => {\n                self.current = self.list.head;\n                self.index = 0;\n            }\n            // We had a previous element, so let's go to its next\n            Some(current) => unsafe {\n                self.current = current.as_ref().next;\n                self.index += 1;\n            },\n        }\n    }\n\n    /// Moves the cursor to the previous element of the `LinkedList`.\n    ///\n    /// If the cursor is pointing to the \"ghost\" non-element then this will move it to\n    /// the last element of the `LinkedList`. If it is pointing to the first\n    /// element of the `LinkedList` then this will move it to the \"ghost\" non-element.\n    #[unstable(feature = \"linked_list_cursors\", issue = \"58533\")]\n    pub fn move_prev(&mut self) {\n        match self.current.take() {\n            // No current. We're at the start of the list. Yield None and jump to the end.\n            None => {\n                self.current = self.list.tail;\n                self.index = self.list.len().checked_sub(1).unwrap_or(0);\n            }\n            // Have a prev. Yield it and go to the previous element.\n            Some(current) => unsafe {\n                self.current = current.as_ref().prev;\n                self.index = self.index.checked_sub(1).unwrap_or_else(|| self.list.len());\n            },\n        }\n    }\n\n    /// Returns a reference to the element that the cursor is currently\n    /// pointing to.\n    ///\n    /// This returns `None` if the cursor is currently pointing to the\n    /// \"ghost\" non-element.\n    #[unstable(feature = \"linked_list_cursors\", issue = \"58533\")]\n    pub fn current(&self) -> Option<&'a T> {\n        unsafe { self.current.map(|current| &(*current.as_ptr()).element) }\n    }\n\n    /// Returns a reference to the next element.\n    ///\n    /// If the cursor is pointing to the \"ghost\" non-element then this returns\n    /// the first element of the `LinkedList`. If it is pointing to the last\n    /// element of the `LinkedList` then this returns `None`.\n    #[unstable(feature = \"linked_list_cursors\", issue = \"58533\")]\n    pub fn peek_next(&self) -> Option<&'a T> {\n        unsafe {\n            let next = match self.current {\n                None => self.list.head,\n                Some(current) => current.as_ref().next,\n            };\n            next.map(|next| &(*next.as_ptr()).element)\n        }\n    }\n\n    /// Returns a reference to the previous element.\n    ///\n    /// If the cursor is pointing to the \"ghost\" non-element then this returns\n    /// the last element of the `LinkedList`. If it is pointing to the first\n    /// element of the `LinkedList` then this returns `None`.\n    #[unstable(feature = \"linked_list_cursors\", issue = \"58533\")]\n    pub fn peek_prev(&self) -> Option<&'a T> {\n        unsafe {\n            let prev = match self.current {\n                None => self.list.tail,\n                Some(current) => current.as_ref().prev,\n            };\n            prev.map(|prev| &(*prev.as_ptr()).element)\n        }\n    }\n}\n\nimpl<'a, T> CursorMut<'a, T> {\n    /// Returns the cursor position index within the `LinkedList`.\n    ///\n    /// This returns `None` if the cursor is currently pointing to the\n    /// \"ghost\" non-element.\n    #[unstable(feature = \"linked_list_cursors\", issue = \"58533\")]\n    pub fn index(&self) -> Option<usize> {\n        let _ = self.current?;\n        Some(self.index)\n    }\n\n    /// Moves the cursor to the next element of the `LinkedList`.\n    ///\n    /// If the cursor is pointing to the \"ghost\" non-element then this will move it to\n    /// the first element of the `LinkedList`. If it is pointing to the last\n    /// element of the `LinkedList` then this will move it to the \"ghost\" non-element.\n    #[unstable(feature = \"linked_list_cursors\", issue = \"58533\")]\n    pub fn move_next(&mut self) {\n        match self.current.take() {\n            // We had no current element; the cursor was sitting at the start position\n            // Next element should be the head of the list\n            None => {\n                self.current = self.list.head;\n                self.index = 0;\n            }\n            // We had a previous element, so let's go to its next\n            Some(current) => unsafe {\n                self.current = current.as_ref().next;\n                self.index += 1;\n            },\n        }\n    }\n\n    /// Moves the cursor to the previous element of the `LinkedList`.\n    ///\n    /// If the cursor is pointing to the \"ghost\" non-element then this will move it to\n    /// the last element of the `LinkedList`. If it is pointing to the first\n    /// element of the `LinkedList` then this will move it to the \"ghost\" non-element.\n    #[unstable(feature = \"linked_list_cursors\", issue = \"58533\")]\n    pub fn move_prev(&mut self) {\n        match self.current.take() {\n            // No current. We're at the start of the list. Yield None and jump to the end.\n            None => {\n                self.current = self.list.tail;\n                self.index = self.list.len().checked_sub(1).unwrap_or(0);\n            }\n            // Have a prev. Yield it and go to the previous element.\n            Some(current) => unsafe {\n                self.current = current.as_ref().prev;\n                self.index = self.index.checked_sub(1).unwrap_or_else(|| self.list.len());\n            },\n        }\n    }\n\n    /// Returns a reference to the element that the cursor is currently\n    /// pointing to.\n    ///\n    /// This returns `None` if the cursor is currently pointing to the\n    /// \"ghost\" non-element.\n    #[unstable(feature = \"linked_list_cursors\", issue = \"58533\")]\n    pub fn current(&mut self) -> Option<&mut T> {\n        unsafe { self.current.map(|current| &mut (*current.as_ptr()).element) }\n    }\n\n    /// Returns a reference to the next element.\n    ///\n    /// If the cursor is pointing to the \"ghost\" non-element then this returns\n    /// the first element of the `LinkedList`. If it is pointing to the last\n    /// element of the `LinkedList` then this returns `None`.\n    #[unstable(feature = \"linked_list_cursors\", issue = \"58533\")]\n    pub fn peek_next(&mut self) -> Option<&mut T> {\n        unsafe {\n            let next = match self.current {\n                None => self.list.head,\n                Some(current) => current.as_ref().next,\n            };\n            next.map(|next| &mut (*next.as_ptr()).element)\n        }\n    }\n\n    /// Returns a reference to the previous element.\n    ///\n    /// If the cursor is pointing to the \"ghost\" non-element then this returns\n    /// the last element of the `LinkedList`. If it is pointing to the first\n    /// element of the `LinkedList` then this returns `None`.\n    #[unstable(feature = \"linked_list_cursors\", issue = \"58533\")]\n    pub fn peek_prev(&mut self) -> Option<&mut T> {\n        unsafe {\n            let prev = match self.current {\n                None => self.list.tail,\n                Some(current) => current.as_ref().prev,\n            };\n            prev.map(|prev| &mut (*prev.as_ptr()).element)\n        }\n    }\n\n    /// Returns a read-only cursor pointing to the current element.\n    ///\n    /// The lifetime of the returned `Cursor` is bound to that of the\n    /// `CursorMut`, which means it cannot outlive the `CursorMut` and that the\n    /// `CursorMut` is frozen for the lifetime of the `Cursor`.\n    #[unstable(feature = \"linked_list_cursors\", issue = \"58533\")]\n    pub fn as_cursor(&self) -> Cursor<'_, T> {\n        Cursor { list: self.list, current: self.current, index: self.index }\n    }\n}\n\n// Now the list editing operations\n\nimpl<'a, T> CursorMut<'a, T> {\n    /// Inserts a new element into the `LinkedList` after the current one.\n    ///\n    /// If the cursor is pointing at the \"ghost\" non-element then the new element is\n    /// inserted at the front of the `LinkedList`.\n    #[unstable(feature = \"linked_list_cursors\", issue = \"58533\")]\n    pub fn insert_after(&mut self, item: T) {\n        unsafe {\n            let spliced_node = Box::leak(Box::new(Node::new(item))).into();\n            let node_next = match self.current {\n                None => self.list.head,\n                Some(node) => node.as_ref().next,\n            };\n            self.list.splice_nodes(self.current, node_next, spliced_node, spliced_node, 1);\n            if self.current.is_none() {\n                // The \"ghost\" non-element's index has changed.\n                self.index = self.list.len;\n            }\n        }\n    }\n\n    /// Inserts a new element into the `LinkedList` before the current one.\n    ///\n    /// If the cursor is pointing at the \"ghost\" non-element then the new element is\n    /// inserted at the end of the `LinkedList`.\n    #[unstable(feature = \"linked_list_cursors\", issue = \"58533\")]\n    pub fn insert_before(&mut self, item: T) {\n        unsafe {\n            let spliced_node = Box::leak(Box::new(Node::new(item))).into();\n            let node_prev = match self.current {\n                None => self.list.tail,\n                Some(node) => node.as_ref().prev,\n            };\n            self.list.splice_nodes(node_prev, self.current, spliced_node, spliced_node, 1);\n            self.index += 1;\n        }\n    }\n\n    /// Removes the current element from the `LinkedList`.\n    ///\n    /// The element that was removed is returned, and the cursor is\n    /// moved to point to the next element in the `LinkedList`.\n    ///\n    /// If the cursor is currently pointing to the \"ghost\" non-element then no element\n    /// is removed and `None` is returned.\n    #[unstable(feature = \"linked_list_cursors\", issue = \"58533\")]\n    pub fn remove_current(&mut self) -> Option<T> {\n        let unlinked_node = self.current?;\n        unsafe {\n            self.current = unlinked_node.as_ref().next;\n            self.list.unlink_node(unlinked_node);\n            let unlinked_node = Box::from_raw(unlinked_node.as_ptr());\n            Some(unlinked_node.element)\n        }\n    }\n\n    /// Removes the current element from the `LinkedList` without deallocating the list node.\n    ///\n    /// The node that was removed is returned as a new `LinkedList` containing only this node.\n    /// The cursor is moved to point to the next element in the current `LinkedList`.\n    ///\n    /// If the cursor is currently pointing to the \"ghost\" non-element then no element\n    /// is removed and `None` is returned.\n    #[unstable(feature = \"linked_list_cursors\", issue = \"58533\")]\n    pub fn remove_current_as_list(&mut self) -> Option<LinkedList<T>> {\n        let mut unlinked_node = self.current?;\n        unsafe {\n            self.current = unlinked_node.as_ref().next;\n            self.list.unlink_node(unlinked_node);\n\n            unlinked_node.as_mut().prev = None;\n            unlinked_node.as_mut().next = None;\n            Some(LinkedList {\n                head: Some(unlinked_node),\n                tail: Some(unlinked_node),\n                len: 1,\n                marker: PhantomData,\n            })\n        }\n    }\n\n    /// Inserts the elements from the given `LinkedList` after the current one.\n    ///\n    /// If the cursor is pointing at the \"ghost\" non-element then the new elements are\n    /// inserted at the start of the `LinkedList`.\n    #[unstable(feature = \"linked_list_cursors\", issue = \"58533\")]\n    pub fn splice_after(&mut self, list: LinkedList<T>) {\n        unsafe {\n            let (splice_head, splice_tail, splice_len) = match list.detach_all_nodes() {\n                Some(parts) => parts,\n                _ => return,\n            };\n            let node_next = match self.current {\n                None => self.list.head,\n                Some(node) => node.as_ref().next,\n            };\n            self.list.splice_nodes(self.current, node_next, splice_head, splice_tail, splice_len);\n            if self.current.is_none() {\n                // The \"ghost\" non-element's index has changed.\n                self.index = self.list.len;\n            }\n        }\n    }\n\n    /// Inserts the elements from the given `LinkedList` before the current one.\n    ///\n    /// If the cursor is pointing at the \"ghost\" non-element then the new elements are\n    /// inserted at the end of the `LinkedList`.\n    #[unstable(feature = \"linked_list_cursors\", issue = \"58533\")]\n    pub fn splice_before(&mut self, list: LinkedList<T>) {\n        unsafe {\n            let (splice_head, splice_tail, splice_len) = match list.detach_all_nodes() {\n                Some(parts) => parts,\n                _ => return,\n            };\n            let node_prev = match self.current {\n                None => self.list.tail,\n                Some(node) => node.as_ref().prev,\n            };\n            self.list.splice_nodes(node_prev, self.current, splice_head, splice_tail, splice_len);\n            self.index += splice_len;\n        }\n    }\n\n    /// Splits the list into two after the current element. This will return a\n    /// new list consisting of everything after the cursor, with the original\n    /// list retaining everything before.\n    ///\n    /// If the cursor is pointing at the \"ghost\" non-element then the entire contents\n    /// of the `LinkedList` are moved.\n    #[unstable(feature = \"linked_list_cursors\", issue = \"58533\")]\n    pub fn split_after(&mut self) -> LinkedList<T> {\n        let split_off_idx = if self.index == self.list.len { 0 } else { self.index + 1 };\n        if self.index == self.list.len {\n            // The \"ghost\" non-element's index has changed to 0.\n            self.index = 0;\n        }\n        unsafe { self.list.split_off_after_node(self.current, split_off_idx) }\n    }\n\n    /// Splits the list into two before the current element. This will return a\n    /// new list consisting of everything before the cursor, with the original\n    /// list retaining everything after.\n    ///\n    /// If the cursor is pointing at the \"ghost\" non-element then the entire contents\n    /// of the `LinkedList` are moved.\n    #[unstable(feature = \"linked_list_cursors\", issue = \"58533\")]\n    pub fn split_before(&mut self) -> LinkedList<T> {\n        let split_off_idx = self.index;\n        self.index = 0;\n        unsafe { self.list.split_off_before_node(self.current, split_off_idx) }\n    }\n}\n\n/// An iterator produced by calling `drain_filter` on LinkedList.\n#[unstable(feature = \"drain_filter\", reason = \"recently added\", issue = \"43244\")]\npub struct DrainFilter<'a, T: 'a, F: 'a>\nwhere\n    F: FnMut(&mut T) -> bool,\n{\n    list: &'a mut LinkedList<T>,\n    it: Option<NonNull<Node<T>>>,\n    pred: F,\n    idx: usize,\n    old_len: usize,\n}\n\n#[unstable(feature = \"drain_filter\", reason = \"recently added\", issue = \"43244\")]\nimpl<T, F> Iterator for DrainFilter<'_, T, F>\nwhere\n    F: FnMut(&mut T) -> bool,\n{\n    type Item = T;\n\n    fn next(&mut self) -> Option<T> {\n        while let Some(mut node) = self.it {\n            unsafe {\n                self.it = node.as_ref().next;\n                self.idx += 1;\n\n                if (self.pred)(&mut node.as_mut().element) {\n                    // `unlink_node` is okay with aliasing `element` references.\n                    self.list.unlink_node(node);\n                    return Some(Box::from_raw(node.as_ptr()).element);\n                }\n            }\n        }\n\n        None\n    }\n\n    fn size_hint(&self) -> (usize, Option<usize>) {\n        (0, Some(self.old_len - self.idx))\n    }\n}\n\n#[unstable(feature = \"drain_filter\", reason = \"recently added\", issue = \"43244\")]\nimpl<T, F> Drop for DrainFilter<'_, T, F>\nwhere\n    F: FnMut(&mut T) -> bool,\n{\n    fn drop(&mut self) {\n        struct DropGuard<'r, 'a, T, F>(&'r mut DrainFilter<'a, T, F>)\n        where\n            F: FnMut(&mut T) -> bool;\n\n        impl<'r, 'a, T, F> Drop for DropGuard<'r, 'a, T, F>\n        where\n            F: FnMut(&mut T) -> bool,\n        {\n            fn drop(&mut self) {\n                self.0.for_each(drop);\n            }\n        }\n\n        while let Some(item) = self.next() {\n            let guard = DropGuard(self);\n            drop(item);\n            mem::forget(guard);\n        }\n    }\n}\n\n#[unstable(feature = \"drain_filter\", reason = \"recently added\", issue = \"43244\")]\nimpl<T: fmt::Debug, F> fmt::Debug for DrainFilter<'_, T, F>\nwhere\n    F: FnMut(&mut T) -> bool,\n{\n    fn fmt(&self, f: &mut fmt::Formatter<'_>) -> fmt::Result {\n        f.debug_tuple(\"DrainFilter\").field(&self.list).finish()\n    }\n}\n\n#[stable(feature = \"rust1\", since = \"1.0.0\")]\nimpl<T> Iterator for IntoIter<T> {\n    type Item = T;\n\n    #[inline]\n    fn next(&mut self) -> Option<T> {\n        self.list.pop_front()\n    }\n\n    #[inline]\n    fn size_hint(&self) -> (usize, Option<usize>) {\n        (self.list.len, Some(self.list.len))\n    }\n}\n\n#[stable(feature = \"rust1\", since = \"1.0.0\")]\nimpl<T> DoubleEndedIterator for IntoIter<T> {\n    #[inline]\n    fn next_back(&mut self) -> Option<T> {\n        self.list.pop_back()\n    }\n}\n\n#[stable(feature = \"rust1\", since = \"1.0.0\")]\nimpl<T> ExactSizeIterator for IntoIter<T> {}\n\n#[stable(feature = \"fused\", since = \"1.26.0\")]\nimpl<T> FusedIterator for IntoIter<T> {}\n\n#[stable(feature = \"rust1\", since = \"1.0.0\")]\nimpl<T> FromIterator<T> for LinkedList<T> {\n    fn from_iter<I: IntoIterator<Item = T>>(iter: I) -> Self {\n        let mut list = Self::new();\n        list.extend(iter);\n        list\n    }\n}\n\n#[stable(feature = \"rust1\", since = \"1.0.0\")]\nimpl<T> IntoIterator for LinkedList<T> {\n    type Item = T;\n    type IntoIter = IntoIter<T>;\n\n    /// Consumes the list into an iterator yielding elements by value.\n    #[inline]\n    fn into_iter(self) -> IntoIter<T> {\n        IntoIter { list: self }\n    }\n}\n\n#[stable(feature = \"rust1\", since = \"1.0.0\")]\nimpl<'a, T> IntoIterator for &'a LinkedList<T> {\n    type Item = &'a T;\n    type IntoIter = Iter<'a, T>;\n\n    fn into_iter(self) -> Iter<'a, T> {\n        self.iter()\n    }\n}\n\n#[stable(feature = \"rust1\", since = \"1.0.0\")]\nimpl<'a, T> IntoIterator for &'a mut LinkedList<T> {\n    type Item = &'a mut T;\n    type IntoIter = IterMut<'a, T>;\n\n    fn into_iter(self) -> IterMut<'a, T> {\n        self.iter_mut()\n    }\n}\n\n#[stable(feature = \"rust1\", since = \"1.0.0\")]\nimpl<T> Extend<T> for LinkedList<T> {\n    fn extend<I: IntoIterator<Item = T>>(&mut self, iter: I) {\n        <Self as SpecExtend<I>>::spec_extend(self, iter);\n    }\n\n    #[inline]\n    fn extend_one(&mut self, elem: T) {\n        self.push_back(elem);\n    }\n}\n\nimpl<I: IntoIterator> SpecExtend<I> for LinkedList<I::Item> {\n    default fn spec_extend(&mut self, iter: I) {\n        iter.into_iter().for_each(move |elt| self.push_back(elt));\n    }\n}\n\nimpl<T> SpecExtend<LinkedList<T>> for LinkedList<T> {\n    fn spec_extend(&mut self, ref mut other: LinkedList<T>) {\n        self.append(other);\n    }\n}\n\n#[stable(feature = \"extend_ref\", since = \"1.2.0\")]\nimpl<'a, T: 'a + Copy> Extend<&'a T> for LinkedList<T> {\n    fn extend<I: IntoIterator<Item = &'a T>>(&mut self, iter: I) {\n        self.extend(iter.into_iter().cloned());\n    }\n\n    #[inline]\n    fn extend_one(&mut self, &elem: &'a T) {\n        self.push_back(elem);\n    }\n}\n\n#[stable(feature = \"rust1\", since = \"1.0.0\")]\nimpl<T: PartialEq> PartialEq for LinkedList<T> {\n    fn eq(&self, other: &Self) -> bool {\n        self.len() == other.len() && self.iter().eq(other)\n    }\n\n    fn ne(&self, other: &Self) -> bool {\n        self.len() != other.len() || self.iter().ne(other)\n    }\n}\n\n#[stable(feature = \"rust1\", since = \"1.0.0\")]\nimpl<T: Eq> Eq for LinkedList<T> {}\n\n#[stable(feature = \"rust1\", since = \"1.0.0\")]\nimpl<T: PartialOrd> PartialOrd for LinkedList<T> {\n    fn partial_cmp(&self, other: &Self) -> Option<Ordering> {\n        self.iter().partial_cmp(other)\n    }\n}\n\n#[stable(feature = \"rust1\", since = \"1.0.0\")]\nimpl<T: Ord> Ord for LinkedList<T> {\n    #[inline]\n    fn cmp(&self, other: &Self) -> Ordering {\n        self.iter().cmp(other)\n    }\n}\n\n#[stable(feature = \"rust1\", since = \"1.0.0\")]\nimpl<T: Clone> Clone for LinkedList<T> {\n    fn clone(&self) -> Self {\n        self.iter().cloned().collect()\n    }\n\n    fn clone_from(&mut self, other: &Self) {\n        let mut iter_other = other.iter();\n        if self.len() > other.len() {\n            self.split_off(other.len());\n        }\n        for (elem, elem_other) in self.iter_mut().zip(&mut iter_other) {\n            elem.clone_from(elem_other);\n        }\n        if !iter_other.is_empty() {\n            self.extend(iter_other.cloned());\n        }\n    }\n}\n\n#[stable(feature = \"rust1\", since = \"1.0.0\")]\nimpl<T: fmt::Debug> fmt::Debug for LinkedList<T> {\n    fn fmt(&self, f: &mut fmt::Formatter<'_>) -> fmt::Result {\n        f.debug_list().entries(self).finish()\n    }\n}\n\n#[stable(feature = \"rust1\", since = \"1.0.0\")]\nimpl<T: Hash> Hash for LinkedList<T> {\n    fn hash<H: Hasher>(&self, state: &mut H) {\n        self.len().hash(state);\n        for elt in self {\n            elt.hash(state);\n        }\n    }\n}\n\n// Ensure that `LinkedList` and its read-only iterators are covariant in their type parameters.\n#[allow(dead_code)]\nfn assert_covariance() {\n    fn a<'a>(x: LinkedList<&'static str>) -> LinkedList<&'a str> {\n        x\n    }\n    fn b<'i, 'a>(x: Iter<'i, &'static str>) -> Iter<'i, &'a str> {\n        x\n    }\n    fn c<'a>(x: IntoIter<&'static str>) -> IntoIter<&'a str> {\n        x\n    }\n}\n\n#[stable(feature = \"rust1\", since = \"1.0.0\")]\nunsafe impl<T: Send> Send for LinkedList<T> {}\n\n#[stable(feature = \"rust1\", since = \"1.0.0\")]\nunsafe impl<T: Sync> Sync for LinkedList<T> {}\n\n#[stable(feature = \"rust1\", since = \"1.0.0\")]\nunsafe impl<T: Sync> Send for Iter<'_, T> {}\n\n#[stable(feature = \"rust1\", since = \"1.0.0\")]\nunsafe impl<T: Sync> Sync for Iter<'_, T> {}\n\n#[stable(feature = \"rust1\", since = \"1.0.0\")]\nunsafe impl<T: Send> Send for IterMut<'_, T> {}\n\n#[stable(feature = \"rust1\", since = \"1.0.0\")]\nunsafe impl<T: Sync> Sync for IterMut<'_, T> {}\n\n#[unstable(feature = \"linked_list_cursors\", issue = \"58533\")]\nunsafe impl<T: Sync> Send for Cursor<'_, T> {}\n\n#[unstable(feature = \"linked_list_cursors\", issue = \"58533\")]\nunsafe impl<T: Sync> Sync for Cursor<'_, T> {}\n\n#[unstable(feature = \"linked_list_cursors\", issue = \"58533\")]\nunsafe impl<T: Send> Send for CursorMut<'_, T> {}\n\n#[unstable(feature = \"linked_list_cursors\", issue = \"58533\")]\nunsafe impl<T: Sync> Sync for CursorMut<'_, T> {}\n"],[2014,"//! Collection types.\n\n#![stable(feature = \"rust1\", since = \"1.0.0\")]\n\n#[cfg(not(no_global_oom_handling))]\npub mod binary_heap;\n#[cfg(not(no_global_oom_handling))]\nmod btree;\n#[cfg(not(no_global_oom_handling))]\npub mod linked_list;\n#[cfg(not(no_global_oom_handling))]\npub mod vec_deque;\n\n#[cfg(not(no_global_oom_handling))]\n#[stable(feature = \"rust1\", since = \"1.0.0\")]\npub mod btree_map {\n    //! A map based on a B-Tree.\n    #[stable(feature = \"rust1\", since = \"1.0.0\")]\n    pub use super::btree::map::*;\n}\n\n#[cfg(not(no_global_oom_handling))]\n#[stable(feature = \"rust1\", since = \"1.0.0\")]\npub mod btree_set {\n    //! A set based on a B-Tree.\n    #[stable(feature = \"rust1\", since = \"1.0.0\")]\n    pub use super::btree::set::*;\n}\n\n#[cfg(not(no_global_oom_handling))]\n#[stable(feature = \"rust1\", since = \"1.0.0\")]\n#[doc(no_inline)]\npub use binary_heap::BinaryHeap;\n\n#[cfg(not(no_global_oom_handling))]\n#[stable(feature = \"rust1\", since = \"1.0.0\")]\n#[doc(no_inline)]\npub use btree_map::BTreeMap;\n\n#[cfg(not(no_global_oom_handling))]\n#[stable(feature = \"rust1\", since = \"1.0.0\")]\n#[doc(no_inline)]\npub use btree_set::BTreeSet;\n\n#[cfg(not(no_global_oom_handling))]\n#[stable(feature = \"rust1\", since = \"1.0.0\")]\n#[doc(no_inline)]\npub use linked_list::LinkedList;\n\n#[cfg(not(no_global_oom_handling))]\n#[stable(feature = \"rust1\", since = \"1.0.0\")]\n#[doc(no_inline)]\npub use vec_deque::VecDeque;\n\nuse crate::alloc::{Layout, LayoutError};\nuse core::fmt::Display;\n\n/// The error type for `try_reserve` methods.\n#[derive(Clone, PartialEq, Eq, Debug)]\n#[unstable(feature = \"try_reserve\", reason = \"new API\", issue = \"48043\")]\npub enum TryReserveError {\n    /// Error due to the computed capacity exceeding the collection's maximum\n    /// (usually `isize::MAX` bytes).\n    CapacityOverflow,\n\n    /// The memory allocator returned an error\n    AllocError {\n        /// The layout of allocation request that failed\n        layout: Layout,\n\n        #[doc(hidden)]\n        #[unstable(\n            feature = \"container_error_extra\",\n            issue = \"none\",\n            reason = \"\\\n            Enable exposing the allocator’s custom error value \\\n            if an associated type is added in the future: \\\n            https://github.com/rust-lang/wg-allocators/issues/23\"\n        )]\n        non_exhaustive: (),\n    },\n}\n\n#[unstable(feature = \"try_reserve\", reason = \"new API\", issue = \"48043\")]\nimpl From<LayoutError> for TryReserveError {\n    #[inline]\n    fn from(_: LayoutError) -> Self {\n        TryReserveError::CapacityOverflow\n    }\n}\n\n#[unstable(feature = \"try_reserve\", reason = \"new API\", issue = \"48043\")]\nimpl Display for TryReserveError {\n    fn fmt(\n        &self,\n        fmt: &mut core::fmt::Formatter<'_>,\n    ) -> core::result::Result<(), core::fmt::Error> {\n        fmt.write_str(\"memory allocation failed\")?;\n        let reason = match &self {\n            TryReserveError::CapacityOverflow => {\n                \" because the computed capacity exceeded the collection's maximum\"\n            }\n            TryReserveError::AllocError { .. } => \" because the memory allocator returned a error\",\n        };\n        fmt.write_str(reason)\n    }\n}\n\n/// An intermediate trait for specialization of `Extend`.\n#[doc(hidden)]\ntrait SpecExtend<I: IntoIterator> {\n    /// Extends `self` with the contents of the given iterator.\n    fn spec_extend(&mut self, iter: I);\n}\n"],[2015,"use super::*;\n\n#[bench]\n#[cfg_attr(miri, ignore)] // isolated Miri does not support benchmarks\nfn bench_push_back_100(b: &mut test::Bencher) {\n    let mut deq = VecDeque::with_capacity(101);\n    b.iter(|| {\n        for i in 0..100 {\n            deq.push_back(i);\n        }\n        deq.head = 0;\n        deq.tail = 0;\n    })\n}\n\n#[bench]\n#[cfg_attr(miri, ignore)] // isolated Miri does not support benchmarks\nfn bench_push_front_100(b: &mut test::Bencher) {\n    let mut deq = VecDeque::with_capacity(101);\n    b.iter(|| {\n        for i in 0..100 {\n            deq.push_front(i);\n        }\n        deq.head = 0;\n        deq.tail = 0;\n    })\n}\n\n#[bench]\n#[cfg_attr(miri, ignore)] // isolated Miri does not support benchmarks\nfn bench_pop_back_100(b: &mut test::Bencher) {\n    let mut deq = VecDeque::<i32>::with_capacity(101);\n\n    b.iter(|| {\n        deq.head = 100;\n        deq.tail = 0;\n        while !deq.is_empty() {\n            test::black_box(deq.pop_back());\n        }\n    })\n}\n\n#[bench]\n#[cfg_attr(miri, ignore)] // isolated Miri does not support benchmarks\nfn bench_pop_front_100(b: &mut test::Bencher) {\n    let mut deq = VecDeque::<i32>::with_capacity(101);\n\n    b.iter(|| {\n        deq.head = 100;\n        deq.tail = 0;\n        while !deq.is_empty() {\n            test::black_box(deq.pop_front());\n        }\n    })\n}\n\n#[test]\nfn test_swap_front_back_remove() {\n    fn test(back: bool) {\n        // This test checks that every single combination of tail position and length is tested.\n        // Capacity 15 should be large enough to cover every case.\n        let mut tester = VecDeque::with_capacity(15);\n        let usable_cap = tester.capacity();\n        let final_len = usable_cap / 2;\n\n        for len in 0..final_len {\n            let expected: VecDeque<_> =\n                if back { (0..len).collect() } else { (0..len).rev().collect() };\n            for tail_pos in 0..usable_cap {\n                tester.tail = tail_pos;\n                tester.head = tail_pos;\n                if back {\n                    for i in 0..len * 2 {\n                        tester.push_front(i);\n                    }\n                    for i in 0..len {\n                        assert_eq!(tester.swap_remove_back(i), Some(len * 2 - 1 - i));\n                    }\n                } else {\n                    for i in 0..len * 2 {\n                        tester.push_back(i);\n                    }\n                    for i in 0..len {\n                        let idx = tester.len() - 1 - i;\n                        assert_eq!(tester.swap_remove_front(idx), Some(len * 2 - 1 - i));\n                    }\n                }\n                assert!(tester.tail < tester.cap());\n                assert!(tester.head < tester.cap());\n                assert_eq!(tester, expected);\n            }\n        }\n    }\n    test(true);\n    test(false);\n}\n\n#[test]\nfn test_insert() {\n    // This test checks that every single combination of tail position, length, and\n    // insertion position is tested. Capacity 15 should be large enough to cover every case.\n\n    let mut tester = VecDeque::with_capacity(15);\n    // can't guarantee we got 15, so have to get what we got.\n    // 15 would be great, but we will definitely get 2^k - 1, for k >= 4, or else\n    // this test isn't covering what it wants to\n    let cap = tester.capacity();\n\n    // len is the length *after* insertion\n    let minlen = if cfg!(miri) { cap - 1 } else { 1 }; // Miri is too slow\n    for len in minlen..cap {\n        // 0, 1, 2, .., len - 1\n        let expected = (0..).take(len).collect::<VecDeque<_>>();\n        for tail_pos in 0..cap {\n            for to_insert in 0..len {\n                tester.tail = tail_pos;\n                tester.head = tail_pos;\n                for i in 0..len {\n                    if i != to_insert {\n                        tester.push_back(i);\n                    }\n                }\n                tester.insert(to_insert, to_insert);\n                assert!(tester.tail < tester.cap());\n                assert!(tester.head < tester.cap());\n                assert_eq!(tester, expected);\n            }\n        }\n    }\n}\n\n#[test]\nfn make_contiguous_big_tail() {\n    let mut tester = VecDeque::with_capacity(15);\n\n    for i in 0..3 {\n        tester.push_back(i);\n    }\n\n    for i in 3..10 {\n        tester.push_front(i);\n    }\n\n    // 012......9876543\n    assert_eq!(tester.capacity(), 15);\n    assert_eq!((&[9, 8, 7, 6, 5, 4, 3] as &[_], &[0, 1, 2] as &[_]), tester.as_slices());\n\n    let expected_start = tester.head;\n    tester.make_contiguous();\n    assert_eq!(tester.tail, expected_start);\n    assert_eq!((&[9, 8, 7, 6, 5, 4, 3, 0, 1, 2] as &[_], &[] as &[_]), tester.as_slices());\n}\n\n#[test]\nfn make_contiguous_big_head() {\n    let mut tester = VecDeque::with_capacity(15);\n\n    for i in 0..8 {\n        tester.push_back(i);\n    }\n\n    for i in 8..10 {\n        tester.push_front(i);\n    }\n\n    // 01234567......98\n    let expected_start = 0;\n    tester.make_contiguous();\n    assert_eq!(tester.tail, expected_start);\n    assert_eq!((&[9, 8, 0, 1, 2, 3, 4, 5, 6, 7] as &[_], &[] as &[_]), tester.as_slices());\n}\n\n#[test]\nfn make_contiguous_small_free() {\n    let mut tester = VecDeque::with_capacity(15);\n\n    for i in 'A' as u8..'I' as u8 {\n        tester.push_back(i as char);\n    }\n\n    for i in 'I' as u8..'N' as u8 {\n        tester.push_front(i as char);\n    }\n\n    // ABCDEFGH...MLKJI\n    let expected_start = 0;\n    tester.make_contiguous();\n    assert_eq!(tester.tail, expected_start);\n    assert_eq!(\n        (&['M', 'L', 'K', 'J', 'I', 'A', 'B', 'C', 'D', 'E', 'F', 'G', 'H'] as &[_], &[] as &[_]),\n        tester.as_slices()\n    );\n\n    tester.clear();\n    for i in 'I' as u8..'N' as u8 {\n        tester.push_back(i as char);\n    }\n\n    for i in 'A' as u8..'I' as u8 {\n        tester.push_front(i as char);\n    }\n\n    // IJKLM...HGFEDCBA\n    let expected_start = 0;\n    tester.make_contiguous();\n    assert_eq!(tester.tail, expected_start);\n    assert_eq!(\n        (&['H', 'G', 'F', 'E', 'D', 'C', 'B', 'A', 'I', 'J', 'K', 'L', 'M'] as &[_], &[] as &[_]),\n        tester.as_slices()\n    );\n}\n\n#[test]\nfn make_contiguous_head_to_end() {\n    let mut dq = VecDeque::with_capacity(3);\n    dq.push_front('B');\n    dq.push_front('A');\n    dq.push_back('C');\n    dq.make_contiguous();\n    let expected_tail = 0;\n    let expected_head = 3;\n    assert_eq!(expected_tail, dq.tail);\n    assert_eq!(expected_head, dq.head);\n    assert_eq!((&['A', 'B', 'C'] as &[_], &[] as &[_]), dq.as_slices());\n}\n\n#[test]\nfn make_contiguous_head_to_end_2() {\n    // Another test case for #79808, taken from #80293.\n\n    let mut dq = VecDeque::from_iter(0..6);\n    dq.pop_front();\n    dq.pop_front();\n    dq.push_back(6);\n    dq.push_back(7);\n    dq.push_back(8);\n    dq.make_contiguous();\n    let collected: Vec<_> = dq.iter().copied().collect();\n    assert_eq!(dq.as_slices(), (&collected[..], &[] as &[_]));\n}\n\n#[test]\nfn test_remove() {\n    // This test checks that every single combination of tail position, length, and\n    // removal position is tested. Capacity 15 should be large enough to cover every case.\n\n    let mut tester = VecDeque::with_capacity(15);\n    // can't guarantee we got 15, so have to get what we got.\n    // 15 would be great, but we will definitely get 2^k - 1, for k >= 4, or else\n    // this test isn't covering what it wants to\n    let cap = tester.capacity();\n\n    // len is the length *after* removal\n    let minlen = if cfg!(miri) { cap - 2 } else { 0 }; // Miri is too slow\n    for len in minlen..cap - 1 {\n        // 0, 1, 2, .., len - 1\n        let expected = (0..).take(len).collect::<VecDeque<_>>();\n        for tail_pos in 0..cap {\n            for to_remove in 0..=len {\n                tester.tail = tail_pos;\n                tester.head = tail_pos;\n                for i in 0..len {\n                    if i == to_remove {\n                        tester.push_back(1234);\n                    }\n                    tester.push_back(i);\n                }\n                if to_remove == len {\n                    tester.push_back(1234);\n                }\n                tester.remove(to_remove);\n                assert!(tester.tail < tester.cap());\n                assert!(tester.head < tester.cap());\n                assert_eq!(tester, expected);\n            }\n        }\n    }\n}\n\n#[test]\nfn test_range() {\n    let mut tester: VecDeque<usize> = VecDeque::with_capacity(7);\n\n    let cap = tester.capacity();\n    let minlen = if cfg!(miri) { cap - 1 } else { 0 }; // Miri is too slow\n    for len in minlen..=cap {\n        for tail in 0..=cap {\n            for start in 0..=len {\n                for end in start..=len {\n                    tester.tail = tail;\n                    tester.head = tail;\n                    for i in 0..len {\n                        tester.push_back(i);\n                    }\n\n                    // Check that we iterate over the correct values\n                    let range: VecDeque<_> = tester.range(start..end).copied().collect();\n                    let expected: VecDeque<_> = (start..end).collect();\n                    assert_eq!(range, expected);\n                }\n            }\n        }\n    }\n}\n\n#[test]\nfn test_range_mut() {\n    let mut tester: VecDeque<usize> = VecDeque::with_capacity(7);\n\n    let cap = tester.capacity();\n    for len in 0..=cap {\n        for tail in 0..=cap {\n            for start in 0..=len {\n                for end in start..=len {\n                    tester.tail = tail;\n                    tester.head = tail;\n                    for i in 0..len {\n                        tester.push_back(i);\n                    }\n\n                    let head_was = tester.head;\n                    let tail_was = tester.tail;\n\n                    // Check that we iterate over the correct values\n                    let range: VecDeque<_> = tester.range_mut(start..end).map(|v| *v).collect();\n                    let expected: VecDeque<_> = (start..end).collect();\n                    assert_eq!(range, expected);\n\n                    // We shouldn't have changed the capacity or made the\n                    // head or tail out of bounds\n                    assert_eq!(tester.capacity(), cap);\n                    assert_eq!(tester.tail, tail_was);\n                    assert_eq!(tester.head, head_was);\n                }\n            }\n        }\n    }\n}\n\n#[test]\nfn test_drain() {\n    let mut tester: VecDeque<usize> = VecDeque::with_capacity(7);\n\n    let cap = tester.capacity();\n    for len in 0..=cap {\n        for tail in 0..=cap {\n            for drain_start in 0..=len {\n                for drain_end in drain_start..=len {\n                    tester.tail = tail;\n                    tester.head = tail;\n                    for i in 0..len {\n                        tester.push_back(i);\n                    }\n\n                    // Check that we drain the correct values\n                    let drained: VecDeque<_> = tester.drain(drain_start..drain_end).collect();\n                    let drained_expected: VecDeque<_> = (drain_start..drain_end).collect();\n                    assert_eq!(drained, drained_expected);\n\n                    // We shouldn't have changed the capacity or made the\n                    // head or tail out of bounds\n                    assert_eq!(tester.capacity(), cap);\n                    assert!(tester.tail < tester.cap());\n                    assert!(tester.head < tester.cap());\n\n                    // We should see the correct values in the VecDeque\n                    let expected: VecDeque<_> = (0..drain_start).chain(drain_end..len).collect();\n                    assert_eq!(expected, tester);\n                }\n            }\n        }\n    }\n}\n\n#[test]\nfn test_shrink_to_fit() {\n    // This test checks that every single combination of head and tail position,\n    // is tested. Capacity 15 should be large enough to cover every case.\n\n    let mut tester = VecDeque::with_capacity(15);\n    // can't guarantee we got 15, so have to get what we got.\n    // 15 would be great, but we will definitely get 2^k - 1, for k >= 4, or else\n    // this test isn't covering what it wants to\n    let cap = tester.capacity();\n    tester.reserve(63);\n    let max_cap = tester.capacity();\n\n    for len in 0..=cap {\n        // 0, 1, 2, .., len - 1\n        let expected = (0..).take(len).collect::<VecDeque<_>>();\n        for tail_pos in 0..=max_cap {\n            tester.tail = tail_pos;\n            tester.head = tail_pos;\n            tester.reserve(63);\n            for i in 0..len {\n                tester.push_back(i);\n            }\n            tester.shrink_to_fit();\n            assert!(tester.capacity() <= cap);\n            assert!(tester.tail < tester.cap());\n            assert!(tester.head < tester.cap());\n            assert_eq!(tester, expected);\n        }\n    }\n}\n\n#[test]\nfn test_split_off() {\n    // This test checks that every single combination of tail position, length, and\n    // split position is tested. Capacity 15 should be large enough to cover every case.\n\n    let mut tester = VecDeque::with_capacity(15);\n    // can't guarantee we got 15, so have to get what we got.\n    // 15 would be great, but we will definitely get 2^k - 1, for k >= 4, or else\n    // this test isn't covering what it wants to\n    let cap = tester.capacity();\n\n    // len is the length *before* splitting\n    let minlen = if cfg!(miri) { cap - 1 } else { 0 }; // Miri is too slow\n    for len in minlen..cap {\n        // index to split at\n        for at in 0..=len {\n            // 0, 1, 2, .., at - 1 (may be empty)\n            let expected_self = (0..).take(at).collect::<VecDeque<_>>();\n            // at, at + 1, .., len - 1 (may be empty)\n            let expected_other = (at..).take(len - at).collect::<VecDeque<_>>();\n\n            for tail_pos in 0..cap {\n                tester.tail = tail_pos;\n                tester.head = tail_pos;\n                for i in 0..len {\n                    tester.push_back(i);\n                }\n                let result = tester.split_off(at);\n                assert!(tester.tail < tester.cap());\n                assert!(tester.head < tester.cap());\n                assert!(result.tail < result.cap());\n                assert!(result.head < result.cap());\n                assert_eq!(tester, expected_self);\n                assert_eq!(result, expected_other);\n            }\n        }\n    }\n}\n\n#[test]\nfn test_from_vec() {\n    use crate::vec::Vec;\n    for cap in 0..35 {\n        for len in 0..=cap {\n            let mut vec = Vec::with_capacity(cap);\n            vec.extend(0..len);\n\n            let vd = VecDeque::from(vec.clone());\n            assert!(vd.cap().is_power_of_two());\n            assert_eq!(vd.len(), vec.len());\n            assert!(vd.into_iter().eq(vec));\n        }\n    }\n\n    let vec = Vec::from([(); MAXIMUM_ZST_CAPACITY - 1]);\n    let vd = VecDeque::from(vec.clone());\n    assert!(vd.cap().is_power_of_two());\n    assert_eq!(vd.len(), vec.len());\n}\n\n#[test]\n#[should_panic = \"capacity overflow\"]\nfn test_from_vec_zst_overflow() {\n    use crate::vec::Vec;\n    let vec = Vec::from([(); MAXIMUM_ZST_CAPACITY]);\n    let vd = VecDeque::from(vec.clone()); // no room for +1\n    assert!(vd.cap().is_power_of_two());\n    assert_eq!(vd.len(), vec.len());\n}\n\n#[test]\nfn test_vec_from_vecdeque() {\n    use crate::vec::Vec;\n\n    fn create_vec_and_test_convert(capacity: usize, offset: usize, len: usize) {\n        let mut vd = VecDeque::with_capacity(capacity);\n        for _ in 0..offset {\n            vd.push_back(0);\n            vd.pop_front();\n        }\n        vd.extend(0..len);\n\n        let vec: Vec<_> = Vec::from(vd.clone());\n        assert_eq!(vec.len(), vd.len());\n        assert!(vec.into_iter().eq(vd));\n    }\n\n    // Miri is too slow\n    let max_pwr = if cfg!(miri) { 5 } else { 7 };\n\n    for cap_pwr in 0..max_pwr {\n        // Make capacity as a (2^x)-1, so that the ring size is 2^x\n        let cap = (2i32.pow(cap_pwr) - 1) as usize;\n\n        // In these cases there is enough free space to solve it with copies\n        for len in 0..((cap + 1) / 2) {\n            // Test contiguous cases\n            for offset in 0..(cap - len) {\n                create_vec_and_test_convert(cap, offset, len)\n            }\n\n            // Test cases where block at end of buffer is bigger than block at start\n            for offset in (cap - len)..(cap - (len / 2)) {\n                create_vec_and_test_convert(cap, offset, len)\n            }\n\n            // Test cases where block at start of buffer is bigger than block at end\n            for offset in (cap - (len / 2))..cap {\n                create_vec_and_test_convert(cap, offset, len)\n            }\n        }\n\n        // Now there's not (necessarily) space to straighten the ring with simple copies,\n        // the ring will use swapping when:\n        // (cap + 1 - offset) > (cap + 1 - len) && (len - (cap + 1 - offset)) > (cap + 1 - len))\n        //  right block size  >   free space    &&      left block size       >    free space\n        for len in ((cap + 1) / 2)..cap {\n            // Test contiguous cases\n            for offset in 0..(cap - len) {\n                create_vec_and_test_convert(cap, offset, len)\n            }\n\n            // Test cases where block at end of buffer is bigger than block at start\n            for offset in (cap - len)..(cap - (len / 2)) {\n                create_vec_and_test_convert(cap, offset, len)\n            }\n\n            // Test cases where block at start of buffer is bigger than block at end\n            for offset in (cap - (len / 2))..cap {\n                create_vec_and_test_convert(cap, offset, len)\n            }\n        }\n    }\n}\n\n#[test]\nfn test_clone_from() {\n    let m = vec![1; 8];\n    let n = vec![2; 12];\n    let limit = if cfg!(miri) { 4 } else { 8 }; // Miri is too slow\n    for pfv in 0..limit {\n        for pfu in 0..limit {\n            for longer in 0..2 {\n                let (vr, ur) = if longer == 0 { (&m, &n) } else { (&n, &m) };\n                let mut v = VecDeque::from(vr.clone());\n                for _ in 0..pfv {\n                    v.push_front(1);\n                }\n                let mut u = VecDeque::from(ur.clone());\n                for _ in 0..pfu {\n                    u.push_front(2);\n                }\n                v.clone_from(&u);\n                assert_eq!(&v, &u);\n            }\n        }\n    }\n}\n\n#[test]\nfn test_vec_deque_truncate_drop() {\n    static mut DROPS: u32 = 0;\n    #[derive(Clone)]\n    struct Elem(i32);\n    impl Drop for Elem {\n        fn drop(&mut self) {\n            unsafe {\n                DROPS += 1;\n            }\n        }\n    }\n\n    let v = vec![Elem(1), Elem(2), Elem(3), Elem(4), Elem(5)];\n    for push_front in 0..=v.len() {\n        let v = v.clone();\n        let mut tester = VecDeque::with_capacity(5);\n        for (index, elem) in v.into_iter().enumerate() {\n            if index < push_front {\n                tester.push_front(elem);\n            } else {\n                tester.push_back(elem);\n            }\n        }\n        assert_eq!(unsafe { DROPS }, 0);\n        tester.truncate(3);\n        assert_eq!(unsafe { DROPS }, 2);\n        tester.truncate(0);\n        assert_eq!(unsafe { DROPS }, 5);\n        unsafe {\n            DROPS = 0;\n        }\n    }\n}\n\n#[test]\nfn issue_53529() {\n    use crate::boxed::Box;\n\n    let mut dst = VecDeque::new();\n    dst.push_front(Box::new(1));\n    dst.push_front(Box::new(2));\n    assert_eq!(*dst.pop_back().unwrap(), 1);\n\n    let mut src = VecDeque::new();\n    src.push_front(Box::new(2));\n    dst.append(&mut src);\n    for a in dst {\n        assert_eq!(*a, 2);\n    }\n}\n\n#[test]\nfn issue_80303() {\n    use core::iter;\n    use core::num::Wrapping;\n\n    // This is a valid, albeit rather bad hash function implementation.\n    struct SimpleHasher(Wrapping<u64>);\n\n    impl Hasher for SimpleHasher {\n        fn finish(&self) -> u64 {\n            self.0.0\n        }\n\n        fn write(&mut self, bytes: &[u8]) {\n            // This particular implementation hashes value 24 in addition to bytes.\n            // Such an implementation is valid as Hasher only guarantees equivalence\n            // for the exact same set of calls to its methods.\n            for &v in iter::once(&24).chain(bytes) {\n                self.0 = Wrapping(31) * self.0 + Wrapping(u64::from(v));\n            }\n        }\n    }\n\n    fn hash_code(value: impl Hash) -> u64 {\n        let mut hasher = SimpleHasher(Wrapping(1));\n        value.hash(&mut hasher);\n        hasher.finish()\n    }\n\n    // This creates two deques for which values returned by as_slices\n    // method differ.\n    let vda: VecDeque<u8> = (0..10).collect();\n    let mut vdb = VecDeque::with_capacity(10);\n    vdb.extend(5..10);\n    (0..5).rev().for_each(|elem| vdb.push_front(elem));\n    assert_ne!(vda.as_slices(), vdb.as_slices());\n    assert_eq!(vda, vdb);\n    assert_eq!(hash_code(vda), hash_code(vdb));\n}\n"],[2016,"use core::ptr::{self};\n\n/// Returns the two slices that cover the `VecDeque`'s valid range\npub trait RingSlices: Sized {\n    fn slice(self, from: usize, to: usize) -> Self;\n    fn split_at(self, i: usize) -> (Self, Self);\n\n    fn ring_slices(buf: Self, head: usize, tail: usize) -> (Self, Self) {\n        let contiguous = tail <= head;\n        if contiguous {\n            let (empty, buf) = buf.split_at(0);\n            (buf.slice(tail, head), empty)\n        } else {\n            let (mid, right) = buf.split_at(tail);\n            let (left, _) = mid.split_at(head);\n            (right, left)\n        }\n    }\n}\n\nimpl<T> RingSlices for &[T] {\n    fn slice(self, from: usize, to: usize) -> Self {\n        &self[from..to]\n    }\n    fn split_at(self, i: usize) -> (Self, Self) {\n        (*self).split_at(i)\n    }\n}\n\nimpl<T> RingSlices for &mut [T] {\n    fn slice(self, from: usize, to: usize) -> Self {\n        &mut self[from..to]\n    }\n    fn split_at(self, i: usize) -> (Self, Self) {\n        (*self).split_at_mut(i)\n    }\n}\n\nimpl<T> RingSlices for *mut [T] {\n    fn slice(self, from: usize, to: usize) -> Self {\n        assert!(from <= to && to < self.len());\n        // Not using `get_unchecked_mut` to keep this a safe operation.\n        let len = to - from;\n        ptr::slice_from_raw_parts_mut(self.as_mut_ptr().wrapping_add(from), len)\n    }\n\n    fn split_at(self, mid: usize) -> (Self, Self) {\n        let len = self.len();\n        let ptr = self.as_mut_ptr();\n        assert!(mid <= len);\n        (\n            ptr::slice_from_raw_parts_mut(ptr, mid),\n            ptr::slice_from_raw_parts_mut(ptr.wrapping_add(mid), len - mid),\n        )\n    }\n}\n"],[2017,"use core::fmt;\nuse core::iter::{FusedIterator, TrustedLen, TrustedRandomAccess};\n\nuse super::VecDeque;\n\n/// An owning iterator over the elements of a `VecDeque`.\n///\n/// This `struct` is created by the [`into_iter`] method on [`VecDeque`]\n/// (provided by the `IntoIterator` trait). See its documentation for more.\n///\n/// [`into_iter`]: VecDeque::into_iter\n#[derive(Clone)]\n#[stable(feature = \"rust1\", since = \"1.0.0\")]\npub struct IntoIter<T> {\n    pub(crate) inner: VecDeque<T>,\n}\n\n#[stable(feature = \"collection_debug\", since = \"1.17.0\")]\nimpl<T: fmt::Debug> fmt::Debug for IntoIter<T> {\n    fn fmt(&self, f: &mut fmt::Formatter<'_>) -> fmt::Result {\n        f.debug_tuple(\"IntoIter\").field(&self.inner).finish()\n    }\n}\n\n#[stable(feature = \"rust1\", since = \"1.0.0\")]\nimpl<T> Iterator for IntoIter<T> {\n    type Item = T;\n\n    #[inline]\n    fn next(&mut self) -> Option<T> {\n        self.inner.pop_front()\n    }\n\n    #[inline]\n    fn size_hint(&self) -> (usize, Option<usize>) {\n        let len = self.inner.len();\n        (len, Some(len))\n    }\n\n    #[inline]\n    #[doc(hidden)]\n    unsafe fn __iterator_get_unchecked(&mut self, idx: usize) -> Self::Item\n    where\n        Self: TrustedRandomAccess,\n    {\n        // Safety: The TrustedRandomAccess contract requires that callers only pass an index\n        // that is in bounds.\n        // Additionally Self: TrustedRandomAccess is only implemented for T: Copy which means even\n        // multiple repeated reads of the same index would be safe and the\n        // values are !Drop, thus won't suffer from double drops.\n        unsafe {\n            let idx = self.inner.wrap_add(self.inner.tail, idx);\n            self.inner.buffer_read(idx)\n        }\n    }\n}\n\n#[stable(feature = \"rust1\", since = \"1.0.0\")]\nimpl<T> DoubleEndedIterator for IntoIter<T> {\n    #[inline]\n    fn next_back(&mut self) -> Option<T> {\n        self.inner.pop_back()\n    }\n}\n\n#[stable(feature = \"rust1\", since = \"1.0.0\")]\nimpl<T> ExactSizeIterator for IntoIter<T> {\n    fn is_empty(&self) -> bool {\n        self.inner.is_empty()\n    }\n}\n\n#[stable(feature = \"fused\", since = \"1.26.0\")]\nimpl<T> FusedIterator for IntoIter<T> {}\n\n#[unstable(feature = \"trusted_len\", issue = \"37572\")]\nunsafe impl<T> TrustedLen for IntoIter<T> {}\n\n#[doc(hidden)]\n#[unstable(feature = \"trusted_random_access\", issue = \"none\")]\n// T: Copy as approximation for !Drop since get_unchecked does not update the pointers\n// and thus we can't implement drop-handling\nunsafe impl<T> TrustedRandomAccess for IntoIter<T>\nwhere\n    T: Copy,\n{\n    const MAY_HAVE_SIDE_EFFECT: bool = false;\n}\n"],[2018,"//! A double-ended queue implemented with a growable ring buffer.\n//!\n//! This queue has *O*(1) amortized inserts and removals from both ends of the\n//! container. It also has *O*(1) indexing like a vector. The contained elements\n//! are not required to be copyable, and the queue will be sendable if the\n//! contained type is sendable.\n\n#![stable(feature = \"rust1\", since = \"1.0.0\")]\n\nuse core::cmp::{self, Ordering};\nuse core::fmt;\nuse core::hash::{Hash, Hasher};\nuse core::iter::{repeat_with, FromIterator};\nuse core::marker::PhantomData;\nuse core::mem::{self, ManuallyDrop};\nuse core::ops::{Index, IndexMut, Range, RangeBounds};\nuse core::ptr::{self, NonNull};\nuse core::slice;\n\nuse crate::collections::TryReserveError;\nuse crate::raw_vec::RawVec;\nuse crate::vec::Vec;\n\n#[macro_use]\nmod macros;\n\n#[stable(feature = \"drain\", since = \"1.6.0\")]\npub use self::drain::Drain;\n\nmod drain;\n\n#[stable(feature = \"rust1\", since = \"1.0.0\")]\npub use self::iter_mut::IterMut;\n\nmod iter_mut;\n\n#[stable(feature = \"rust1\", since = \"1.0.0\")]\npub use self::into_iter::IntoIter;\n\nmod into_iter;\n\n#[stable(feature = \"rust1\", since = \"1.0.0\")]\npub use self::iter::Iter;\n\nmod iter;\n\nuse self::pair_slices::PairSlices;\n\nmod pair_slices;\n\nuse self::ring_slices::RingSlices;\n\nmod ring_slices;\n\n#[cfg(test)]\nmod tests;\n\nconst INITIAL_CAPACITY: usize = 7; // 2^3 - 1\nconst MINIMUM_CAPACITY: usize = 1; // 2 - 1\n\nconst MAXIMUM_ZST_CAPACITY: usize = 1 << (usize::BITS - 1); // Largest possible power of two\n\n/// A double-ended queue implemented with a growable ring buffer.\n///\n/// The \"default\" usage of this type as a queue is to use [`push_back`] to add to\n/// the queue, and [`pop_front`] to remove from the queue. [`extend`] and [`append`]\n/// push onto the back in this manner, and iterating over `VecDeque` goes front\n/// to back.\n///\n/// Since `VecDeque` is a ring buffer, its elements are not necessarily contiguous\n/// in memory. If you want to access the elements as a single slice, such as for\n/// efficient sorting, you can use [`make_contiguous`]. It rotates the `VecDeque`\n/// so that its elements do not wrap, and returns a mutable slice to the\n/// now-contiguous element sequence.\n///\n/// [`push_back`]: VecDeque::push_back\n/// [`pop_front`]: VecDeque::pop_front\n/// [`extend`]: VecDeque::extend\n/// [`append`]: VecDeque::append\n/// [`make_contiguous`]: VecDeque::make_contiguous\n#[cfg_attr(not(test), rustc_diagnostic_item = \"vecdeque_type\")]\n#[stable(feature = \"rust1\", since = \"1.0.0\")]\npub struct VecDeque<T> {\n    // tail and head are pointers into the buffer. Tail always points\n    // to the first element that could be read, Head always points\n    // to where data should be written.\n    // If tail == head the buffer is empty. The length of the ringbuffer\n    // is defined as the distance between the two.\n    tail: usize,\n    head: usize,\n    buf: RawVec<T>,\n}\n\n#[stable(feature = \"rust1\", since = \"1.0.0\")]\nimpl<T: Clone> Clone for VecDeque<T> {\n    fn clone(&self) -> VecDeque<T> {\n        self.iter().cloned().collect()\n    }\n\n    fn clone_from(&mut self, other: &Self) {\n        self.truncate(other.len());\n\n        let mut iter = PairSlices::from(self, other);\n        while let Some((dst, src)) = iter.next() {\n            dst.clone_from_slice(&src);\n        }\n\n        if iter.has_remainder() {\n            for remainder in iter.remainder() {\n                self.extend(remainder.iter().cloned());\n            }\n        }\n    }\n}\n\n#[stable(feature = \"rust1\", since = \"1.0.0\")]\nunsafe impl<#[may_dangle] T> Drop for VecDeque<T> {\n    fn drop(&mut self) {\n        /// Runs the destructor for all items in the slice when it gets dropped (normally or\n        /// during unwinding).\n        struct Dropper<'a, T>(&'a mut [T]);\n\n        impl<'a, T> Drop for Dropper<'a, T> {\n            fn drop(&mut self) {\n                unsafe {\n                    ptr::drop_in_place(self.0);\n                }\n            }\n        }\n\n        let (front, back) = self.as_mut_slices();\n        unsafe {\n            let _back_dropper = Dropper(back);\n            // use drop for [T]\n            ptr::drop_in_place(front);\n        }\n        // RawVec handles deallocation\n    }\n}\n\n#[stable(feature = \"rust1\", since = \"1.0.0\")]\nimpl<T> Default for VecDeque<T> {\n    /// Creates an empty `VecDeque<T>`.\n    #[inline]\n    fn default() -> VecDeque<T> {\n        VecDeque::new()\n    }\n}\n\nimpl<T> VecDeque<T> {\n    /// Marginally more convenient\n    #[inline]\n    fn ptr(&self) -> *mut T {\n        self.buf.ptr()\n    }\n\n    /// Marginally more convenient\n    #[inline]\n    fn cap(&self) -> usize {\n        if mem::size_of::<T>() == 0 {\n            // For zero sized types, we are always at maximum capacity\n            MAXIMUM_ZST_CAPACITY\n        } else {\n            self.buf.capacity()\n        }\n    }\n\n    /// Turn ptr into a slice\n    #[inline]\n    unsafe fn buffer_as_slice(&self) -> &[T] {\n        unsafe { slice::from_raw_parts(self.ptr(), self.cap()) }\n    }\n\n    /// Turn ptr into a mut slice\n    #[inline]\n    unsafe fn buffer_as_mut_slice(&mut self) -> &mut [T] {\n        unsafe { slice::from_raw_parts_mut(self.ptr(), self.cap()) }\n    }\n\n    /// Moves an element out of the buffer\n    #[inline]\n    unsafe fn buffer_read(&mut self, off: usize) -> T {\n        unsafe { ptr::read(self.ptr().add(off)) }\n    }\n\n    /// Writes an element into the buffer, moving it.\n    #[inline]\n    unsafe fn buffer_write(&mut self, off: usize, value: T) {\n        unsafe {\n            ptr::write(self.ptr().add(off), value);\n        }\n    }\n\n    /// Returns `true` if the buffer is at full capacity.\n    #[inline]\n    fn is_full(&self) -> bool {\n        self.cap() - self.len() == 1\n    }\n\n    /// Returns the index in the underlying buffer for a given logical element\n    /// index.\n    #[inline]\n    fn wrap_index(&self, idx: usize) -> usize {\n        wrap_index(idx, self.cap())\n    }\n\n    /// Returns the index in the underlying buffer for a given logical element\n    /// index + addend.\n    #[inline]\n    fn wrap_add(&self, idx: usize, addend: usize) -> usize {\n        wrap_index(idx.wrapping_add(addend), self.cap())\n    }\n\n    /// Returns the index in the underlying buffer for a given logical element\n    /// index - subtrahend.\n    #[inline]\n    fn wrap_sub(&self, idx: usize, subtrahend: usize) -> usize {\n        wrap_index(idx.wrapping_sub(subtrahend), self.cap())\n    }\n\n    /// Copies a contiguous block of memory len long from src to dst\n    #[inline]\n    unsafe fn copy(&self, dst: usize, src: usize, len: usize) {\n        debug_assert!(\n            dst + len <= self.cap(),\n            \"cpy dst={} src={} len={} cap={}\",\n            dst,\n            src,\n            len,\n            self.cap()\n        );\n        debug_assert!(\n            src + len <= self.cap(),\n            \"cpy dst={} src={} len={} cap={}\",\n            dst,\n            src,\n            len,\n            self.cap()\n        );\n        unsafe {\n            ptr::copy(self.ptr().add(src), self.ptr().add(dst), len);\n        }\n    }\n\n    /// Copies a contiguous block of memory len long from src to dst\n    #[inline]\n    unsafe fn copy_nonoverlapping(&self, dst: usize, src: usize, len: usize) {\n        debug_assert!(\n            dst + len <= self.cap(),\n            \"cno dst={} src={} len={} cap={}\",\n            dst,\n            src,\n            len,\n            self.cap()\n        );\n        debug_assert!(\n            src + len <= self.cap(),\n            \"cno dst={} src={} len={} cap={}\",\n            dst,\n            src,\n            len,\n            self.cap()\n        );\n        unsafe {\n            ptr::copy_nonoverlapping(self.ptr().add(src), self.ptr().add(dst), len);\n        }\n    }\n\n    /// Copies a potentially wrapping block of memory len long from src to dest.\n    /// (abs(dst - src) + len) must be no larger than cap() (There must be at\n    /// most one continuous overlapping region between src and dest).\n    unsafe fn wrap_copy(&self, dst: usize, src: usize, len: usize) {\n        #[allow(dead_code)]\n        fn diff(a: usize, b: usize) -> usize {\n            if a <= b { b - a } else { a - b }\n        }\n        debug_assert!(\n            cmp::min(diff(dst, src), self.cap() - diff(dst, src)) + len <= self.cap(),\n            \"wrc dst={} src={} len={} cap={}\",\n            dst,\n            src,\n            len,\n            self.cap()\n        );\n\n        if src == dst || len == 0 {\n            return;\n        }\n\n        let dst_after_src = self.wrap_sub(dst, src) < len;\n\n        let src_pre_wrap_len = self.cap() - src;\n        let dst_pre_wrap_len = self.cap() - dst;\n        let src_wraps = src_pre_wrap_len < len;\n        let dst_wraps = dst_pre_wrap_len < len;\n\n        match (dst_after_src, src_wraps, dst_wraps) {\n            (_, false, false) => {\n                // src doesn't wrap, dst doesn't wrap\n                //\n                //        S . . .\n                // 1 [_ _ A A B B C C _]\n                // 2 [_ _ A A A A B B _]\n                //            D . . .\n                //\n                unsafe {\n                    self.copy(dst, src, len);\n                }\n            }\n            (false, false, true) => {\n                // dst before src, src doesn't wrap, dst wraps\n                //\n                //    S . . .\n                // 1 [A A B B _ _ _ C C]\n                // 2 [A A B B _ _ _ A A]\n                // 3 [B B B B _ _ _ A A]\n                //    . .           D .\n                //\n                unsafe {\n                    self.copy(dst, src, dst_pre_wrap_len);\n                    self.copy(0, src + dst_pre_wrap_len, len - dst_pre_wrap_len);\n                }\n            }\n            (true, false, true) => {\n                // src before dst, src doesn't wrap, dst wraps\n                //\n                //              S . . .\n                // 1 [C C _ _ _ A A B B]\n                // 2 [B B _ _ _ A A B B]\n                // 3 [B B _ _ _ A A A A]\n                //    . .           D .\n                //\n                unsafe {\n                    self.copy(0, src + dst_pre_wrap_len, len - dst_pre_wrap_len);\n                    self.copy(dst, src, dst_pre_wrap_len);\n                }\n            }\n            (false, true, false) => {\n                // dst before src, src wraps, dst doesn't wrap\n                //\n                //    . .           S .\n                // 1 [C C _ _ _ A A B B]\n                // 2 [C C _ _ _ B B B B]\n                // 3 [C C _ _ _ B B C C]\n                //              D . . .\n                //\n                unsafe {\n                    self.copy(dst, src, src_pre_wrap_len);\n                    self.copy(dst + src_pre_wrap_len, 0, len - src_pre_wrap_len);\n                }\n            }\n            (true, true, false) => {\n                // src before dst, src wraps, dst doesn't wrap\n                //\n                //    . .           S .\n                // 1 [A A B B _ _ _ C C]\n                // 2 [A A A A _ _ _ C C]\n                // 3 [C C A A _ _ _ C C]\n                //    D . . .\n                //\n                unsafe {\n                    self.copy(dst + src_pre_wrap_len, 0, len - src_pre_wrap_len);\n                    self.copy(dst, src, src_pre_wrap_len);\n                }\n            }\n            (false, true, true) => {\n                // dst before src, src wraps, dst wraps\n                //\n                //    . . .         S .\n                // 1 [A B C D _ E F G H]\n                // 2 [A B C D _ E G H H]\n                // 3 [A B C D _ E G H A]\n                // 4 [B C C D _ E G H A]\n                //    . .         D . .\n                //\n                debug_assert!(dst_pre_wrap_len > src_pre_wrap_len);\n                let delta = dst_pre_wrap_len - src_pre_wrap_len;\n                unsafe {\n                    self.copy(dst, src, src_pre_wrap_len);\n                    self.copy(dst + src_pre_wrap_len, 0, delta);\n                    self.copy(0, delta, len - dst_pre_wrap_len);\n                }\n            }\n            (true, true, true) => {\n                // src before dst, src wraps, dst wraps\n                //\n                //    . .         S . .\n                // 1 [A B C D _ E F G H]\n                // 2 [A A B D _ E F G H]\n                // 3 [H A B D _ E F G H]\n                // 4 [H A B D _ E F F G]\n                //    . . .         D .\n                //\n                debug_assert!(src_pre_wrap_len > dst_pre_wrap_len);\n                let delta = src_pre_wrap_len - dst_pre_wrap_len;\n                unsafe {\n                    self.copy(delta, 0, len - src_pre_wrap_len);\n                    self.copy(0, self.cap() - delta, delta);\n                    self.copy(dst, src, dst_pre_wrap_len);\n                }\n            }\n        }\n    }\n\n    /// Frobs the head and tail sections around to handle the fact that we\n    /// just reallocated. Unsafe because it trusts old_capacity.\n    #[inline]\n    unsafe fn handle_capacity_increase(&mut self, old_capacity: usize) {\n        let new_capacity = self.cap();\n\n        // Move the shortest contiguous section of the ring buffer\n        //    T             H\n        //   [o o o o o o o . ]\n        //    T             H\n        // A [o o o o o o o . . . . . . . . . ]\n        //        H T\n        //   [o o . o o o o o ]\n        //          T             H\n        // B [. . . o o o o o o o . . . . . . ]\n        //              H T\n        //   [o o o o o . o o ]\n        //              H                 T\n        // C [o o o o o . . . . . . . . . o o ]\n\n        if self.tail <= self.head {\n            // A\n            // Nop\n        } else if self.head < old_capacity - self.tail {\n            // B\n            unsafe {\n                self.copy_nonoverlapping(old_capacity, 0, self.head);\n            }\n            self.head += old_capacity;\n            debug_assert!(self.head > self.tail);\n        } else {\n            // C\n            let new_tail = new_capacity - (old_capacity - self.tail);\n            unsafe {\n                self.copy_nonoverlapping(new_tail, self.tail, old_capacity - self.tail);\n            }\n            self.tail = new_tail;\n            debug_assert!(self.head < self.tail);\n        }\n        debug_assert!(self.head < self.cap());\n        debug_assert!(self.tail < self.cap());\n        debug_assert!(self.cap().count_ones() == 1);\n    }\n}\n\nimpl<T> VecDeque<T> {\n    /// Creates an empty `VecDeque`.\n    ///\n    /// # Examples\n    ///\n    /// ```\n    /// use std::collections::VecDeque;\n    ///\n    /// let vector: VecDeque<u32> = VecDeque::new();\n    /// ```\n    #[stable(feature = \"rust1\", since = \"1.0.0\")]\n    pub fn new() -> VecDeque<T> {\n        VecDeque::with_capacity(INITIAL_CAPACITY)\n    }\n\n    /// Creates an empty `VecDeque` with space for at least `capacity` elements.\n    ///\n    /// # Examples\n    ///\n    /// ```\n    /// use std::collections::VecDeque;\n    ///\n    /// let vector: VecDeque<u32> = VecDeque::with_capacity(10);\n    /// ```\n    #[stable(feature = \"rust1\", since = \"1.0.0\")]\n    pub fn with_capacity(capacity: usize) -> VecDeque<T> {\n        // +1 since the ringbuffer always leaves one space empty\n        let cap = cmp::max(capacity + 1, MINIMUM_CAPACITY + 1).next_power_of_two();\n        assert!(cap > capacity, \"capacity overflow\");\n\n        VecDeque { tail: 0, head: 0, buf: RawVec::with_capacity(cap) }\n    }\n\n    /// Provides a reference to the element at the given index.\n    ///\n    /// Element at index 0 is the front of the queue.\n    ///\n    /// # Examples\n    ///\n    /// ```\n    /// use std::collections::VecDeque;\n    ///\n    /// let mut buf = VecDeque::new();\n    /// buf.push_back(3);\n    /// buf.push_back(4);\n    /// buf.push_back(5);\n    /// assert_eq!(buf.get(1), Some(&4));\n    /// ```\n    #[stable(feature = \"rust1\", since = \"1.0.0\")]\n    pub fn get(&self, index: usize) -> Option<&T> {\n        if index < self.len() {\n            let idx = self.wrap_add(self.tail, index);\n            unsafe { Some(&*self.ptr().add(idx)) }\n        } else {\n            None\n        }\n    }\n\n    /// Provides a mutable reference to the element at the given index.\n    ///\n    /// Element at index 0 is the front of the queue.\n    ///\n    /// # Examples\n    ///\n    /// ```\n    /// use std::collections::VecDeque;\n    ///\n    /// let mut buf = VecDeque::new();\n    /// buf.push_back(3);\n    /// buf.push_back(4);\n    /// buf.push_back(5);\n    /// if let Some(elem) = buf.get_mut(1) {\n    ///     *elem = 7;\n    /// }\n    ///\n    /// assert_eq!(buf[1], 7);\n    /// ```\n    #[stable(feature = \"rust1\", since = \"1.0.0\")]\n    pub fn get_mut(&mut self, index: usize) -> Option<&mut T> {\n        if index < self.len() {\n            let idx = self.wrap_add(self.tail, index);\n            unsafe { Some(&mut *self.ptr().add(idx)) }\n        } else {\n            None\n        }\n    }\n\n    /// Swaps elements at indices `i` and `j`.\n    ///\n    /// `i` and `j` may be equal.\n    ///\n    /// Element at index 0 is the front of the queue.\n    ///\n    /// # Panics\n    ///\n    /// Panics if either index is out of bounds.\n    ///\n    /// # Examples\n    ///\n    /// ```\n    /// use std::collections::VecDeque;\n    ///\n    /// let mut buf = VecDeque::new();\n    /// buf.push_back(3);\n    /// buf.push_back(4);\n    /// buf.push_back(5);\n    /// assert_eq!(buf, [3, 4, 5]);\n    /// buf.swap(0, 2);\n    /// assert_eq!(buf, [5, 4, 3]);\n    /// ```\n    #[stable(feature = \"rust1\", since = \"1.0.0\")]\n    pub fn swap(&mut self, i: usize, j: usize) {\n        assert!(i < self.len());\n        assert!(j < self.len());\n        let ri = self.wrap_add(self.tail, i);\n        let rj = self.wrap_add(self.tail, j);\n        unsafe { ptr::swap(self.ptr().add(ri), self.ptr().add(rj)) }\n    }\n\n    /// Returns the number of elements the `VecDeque` can hold without\n    /// reallocating.\n    ///\n    /// # Examples\n    ///\n    /// ```\n    /// use std::collections::VecDeque;\n    ///\n    /// let buf: VecDeque<i32> = VecDeque::with_capacity(10);\n    /// assert!(buf.capacity() >= 10);\n    /// ```\n    #[inline]\n    #[stable(feature = \"rust1\", since = \"1.0.0\")]\n    pub fn capacity(&self) -> usize {\n        self.cap() - 1\n    }\n\n    /// Reserves the minimum capacity for exactly `additional` more elements to be inserted in the\n    /// given `VecDeque`. Does nothing if the capacity is already sufficient.\n    ///\n    /// Note that the allocator may give the collection more space than it requests. Therefore\n    /// capacity can not be relied upon to be precisely minimal. Prefer [`reserve`] if future\n    /// insertions are expected.\n    ///\n    /// # Panics\n    ///\n    /// Panics if the new capacity overflows `usize`.\n    ///\n    /// # Examples\n    ///\n    /// ```\n    /// use std::collections::VecDeque;\n    ///\n    /// let mut buf: VecDeque<i32> = vec![1].into_iter().collect();\n    /// buf.reserve_exact(10);\n    /// assert!(buf.capacity() >= 11);\n    /// ```\n    ///\n    /// [`reserve`]: VecDeque::reserve\n    #[stable(feature = \"rust1\", since = \"1.0.0\")]\n    pub fn reserve_exact(&mut self, additional: usize) {\n        self.reserve(additional);\n    }\n\n    /// Reserves capacity for at least `additional` more elements to be inserted in the given\n    /// `VecDeque`. The collection may reserve more space to avoid frequent reallocations.\n    ///\n    /// # Panics\n    ///\n    /// Panics if the new capacity overflows `usize`.\n    ///\n    /// # Examples\n    ///\n    /// ```\n    /// use std::collections::VecDeque;\n    ///\n    /// let mut buf: VecDeque<i32> = vec![1].into_iter().collect();\n    /// buf.reserve(10);\n    /// assert!(buf.capacity() >= 11);\n    /// ```\n    #[stable(feature = \"rust1\", since = \"1.0.0\")]\n    pub fn reserve(&mut self, additional: usize) {\n        let old_cap = self.cap();\n        let used_cap = self.len() + 1;\n        let new_cap = used_cap\n            .checked_add(additional)\n            .and_then(|needed_cap| needed_cap.checked_next_power_of_two())\n            .expect(\"capacity overflow\");\n\n        if new_cap > old_cap {\n            self.buf.reserve_exact(used_cap, new_cap - used_cap);\n            unsafe {\n                self.handle_capacity_increase(old_cap);\n            }\n        }\n    }\n\n    /// Tries to reserve the minimum capacity for exactly `additional` more elements to\n    /// be inserted in the given `VecDeque<T>`. After calling `try_reserve_exact`,\n    /// capacity will be greater than or equal to `self.len() + additional`.\n    /// Does nothing if the capacity is already sufficient.\n    ///\n    /// Note that the allocator may give the collection more space than it\n    /// requests. Therefore, capacity can not be relied upon to be precisely\n    /// minimal. Prefer `reserve` if future insertions are expected.\n    ///\n    /// # Errors\n    ///\n    /// If the capacity overflows `usize`, or the allocator reports a failure, then an error\n    /// is returned.\n    ///\n    /// # Examples\n    ///\n    /// ```\n    /// #![feature(try_reserve)]\n    /// use std::collections::TryReserveError;\n    /// use std::collections::VecDeque;\n    ///\n    /// fn process_data(data: &[u32]) -> Result<VecDeque<u32>, TryReserveError> {\n    ///     let mut output = VecDeque::new();\n    ///\n    ///     // Pre-reserve the memory, exiting if we can't\n    ///     output.try_reserve_exact(data.len())?;\n    ///\n    ///     // Now we know this can't OOM(Out-Of-Memory) in the middle of our complex work\n    ///     output.extend(data.iter().map(|&val| {\n    ///         val * 2 + 5 // very complicated\n    ///     }));\n    ///\n    ///     Ok(output)\n    /// }\n    /// # process_data(&[1, 2, 3]).expect(\"why is the test harness OOMing on 12 bytes?\");\n    /// ```\n    #[unstable(feature = \"try_reserve\", reason = \"new API\", issue = \"48043\")]\n    pub fn try_reserve_exact(&mut self, additional: usize) -> Result<(), TryReserveError> {\n        self.try_reserve(additional)\n    }\n\n    /// Tries to reserve capacity for at least `additional` more elements to be inserted\n    /// in the given `VecDeque<T>`. The collection may reserve more space to avoid\n    /// frequent reallocations. After calling `try_reserve`, capacity will be\n    /// greater than or equal to `self.len() + additional`. Does nothing if\n    /// capacity is already sufficient.\n    ///\n    /// # Errors\n    ///\n    /// If the capacity overflows `usize`, or the allocator reports a failure, then an error\n    /// is returned.\n    ///\n    /// # Examples\n    ///\n    /// ```\n    /// #![feature(try_reserve)]\n    /// use std::collections::TryReserveError;\n    /// use std::collections::VecDeque;\n    ///\n    /// fn process_data(data: &[u32]) -> Result<VecDeque<u32>, TryReserveError> {\n    ///     let mut output = VecDeque::new();\n    ///\n    ///     // Pre-reserve the memory, exiting if we can't\n    ///     output.try_reserve(data.len())?;\n    ///\n    ///     // Now we know this can't OOM in the middle of our complex work\n    ///     output.extend(data.iter().map(|&val| {\n    ///         val * 2 + 5 // very complicated\n    ///     }));\n    ///\n    ///     Ok(output)\n    /// }\n    /// # process_data(&[1, 2, 3]).expect(\"why is the test harness OOMing on 12 bytes?\");\n    /// ```\n    #[unstable(feature = \"try_reserve\", reason = \"new API\", issue = \"48043\")]\n    pub fn try_reserve(&mut self, additional: usize) -> Result<(), TryReserveError> {\n        let old_cap = self.cap();\n        let used_cap = self.len() + 1;\n        let new_cap = used_cap\n            .checked_add(additional)\n            .and_then(|needed_cap| needed_cap.checked_next_power_of_two())\n            .ok_or(TryReserveError::CapacityOverflow)?;\n\n        if new_cap > old_cap {\n            self.buf.try_reserve_exact(used_cap, new_cap - used_cap)?;\n            unsafe {\n                self.handle_capacity_increase(old_cap);\n            }\n        }\n        Ok(())\n    }\n\n    /// Shrinks the capacity of the `VecDeque` as much as possible.\n    ///\n    /// It will drop down as close as possible to the length but the allocator may still inform the\n    /// `VecDeque` that there is space for a few more elements.\n    ///\n    /// # Examples\n    ///\n    /// ```\n    /// use std::collections::VecDeque;\n    ///\n    /// let mut buf = VecDeque::with_capacity(15);\n    /// buf.extend(0..4);\n    /// assert_eq!(buf.capacity(), 15);\n    /// buf.shrink_to_fit();\n    /// assert!(buf.capacity() >= 4);\n    /// ```\n    #[stable(feature = \"deque_extras_15\", since = \"1.5.0\")]\n    pub fn shrink_to_fit(&mut self) {\n        self.shrink_to(0);\n    }\n\n    /// Shrinks the capacity of the `VecDeque` with a lower bound.\n    ///\n    /// The capacity will remain at least as large as both the length\n    /// and the supplied value.\n    ///\n    /// If the current capacity is less than the lower limit, this is a no-op.\n    ///\n    /// # Examples\n    ///\n    /// ```\n    /// #![feature(shrink_to)]\n    /// use std::collections::VecDeque;\n    ///\n    /// let mut buf = VecDeque::with_capacity(15);\n    /// buf.extend(0..4);\n    /// assert_eq!(buf.capacity(), 15);\n    /// buf.shrink_to(6);\n    /// assert!(buf.capacity() >= 6);\n    /// buf.shrink_to(0);\n    /// assert!(buf.capacity() >= 4);\n    /// ```\n    #[unstable(feature = \"shrink_to\", reason = \"new API\", issue = \"56431\")]\n    pub fn shrink_to(&mut self, min_capacity: usize) {\n        let min_capacity = cmp::min(min_capacity, self.capacity());\n        // We don't have to worry about an overflow as neither `self.len()` nor `self.capacity()`\n        // can ever be `usize::MAX`. +1 as the ringbuffer always leaves one space empty.\n        let target_cap = cmp::max(cmp::max(min_capacity, self.len()) + 1, MINIMUM_CAPACITY + 1)\n            .next_power_of_two();\n\n        if target_cap < self.cap() {\n            // There are three cases of interest:\n            //   All elements are out of desired bounds\n            //   Elements are contiguous, and head is out of desired bounds\n            //   Elements are discontiguous, and tail is out of desired bounds\n            //\n            // At all other times, element positions are unaffected.\n            //\n            // Indicates that elements at the head should be moved.\n            let head_outside = self.head == 0 || self.head >= target_cap;\n            // Move elements from out of desired bounds (positions after target_cap)\n            if self.tail >= target_cap && head_outside {\n                //                    T             H\n                //   [. . . . . . . . o o o o o o o . ]\n                //    T             H\n                //   [o o o o o o o . ]\n                unsafe {\n                    self.copy_nonoverlapping(0, self.tail, self.len());\n                }\n                self.head = self.len();\n                self.tail = 0;\n            } else if self.tail != 0 && self.tail < target_cap && head_outside {\n                //          T             H\n                //   [. . . o o o o o o o . . . . . . ]\n                //        H T\n                //   [o o . o o o o o ]\n                let len = self.wrap_sub(self.head, target_cap);\n                unsafe {\n                    self.copy_nonoverlapping(0, target_cap, len);\n                }\n                self.head = len;\n                debug_assert!(self.head < self.tail);\n            } else if self.tail >= target_cap {\n                //              H                 T\n                //   [o o o o o . . . . . . . . . o o ]\n                //              H T\n                //   [o o o o o . o o ]\n                debug_assert!(self.wrap_sub(self.head, 1) < target_cap);\n                let len = self.cap() - self.tail;\n                let new_tail = target_cap - len;\n                unsafe {\n                    self.copy_nonoverlapping(new_tail, self.tail, len);\n                }\n                self.tail = new_tail;\n                debug_assert!(self.head < self.tail);\n            }\n\n            self.buf.shrink_to_fit(target_cap);\n\n            debug_assert!(self.head < self.cap());\n            debug_assert!(self.tail < self.cap());\n            debug_assert!(self.cap().count_ones() == 1);\n        }\n    }\n\n    /// Shortens the `VecDeque`, keeping the first `len` elements and dropping\n    /// the rest.\n    ///\n    /// If `len` is greater than the `VecDeque`'s current length, this has no\n    /// effect.\n    ///\n    /// # Examples\n    ///\n    /// ```\n    /// use std::collections::VecDeque;\n    ///\n    /// let mut buf = VecDeque::new();\n    /// buf.push_back(5);\n    /// buf.push_back(10);\n    /// buf.push_back(15);\n    /// assert_eq!(buf, [5, 10, 15]);\n    /// buf.truncate(1);\n    /// assert_eq!(buf, [5]);\n    /// ```\n    #[stable(feature = \"deque_extras\", since = \"1.16.0\")]\n    pub fn truncate(&mut self, len: usize) {\n        /// Runs the destructor for all items in the slice when it gets dropped (normally or\n        /// during unwinding).\n        struct Dropper<'a, T>(&'a mut [T]);\n\n        impl<'a, T> Drop for Dropper<'a, T> {\n            fn drop(&mut self) {\n                unsafe {\n                    ptr::drop_in_place(self.0);\n                }\n            }\n        }\n\n        // Safe because:\n        //\n        // * Any slice passed to `drop_in_place` is valid; the second case has\n        //   `len <= front.len()` and returning on `len > self.len()` ensures\n        //   `begin <= back.len()` in the first case\n        // * The head of the VecDeque is moved before calling `drop_in_place`,\n        //   so no value is dropped twice if `drop_in_place` panics\n        unsafe {\n            if len > self.len() {\n                return;\n            }\n            let num_dropped = self.len() - len;\n            let (front, back) = self.as_mut_slices();\n            if len > front.len() {\n                let begin = len - front.len();\n                let drop_back = back.get_unchecked_mut(begin..) as *mut _;\n                self.head = self.wrap_sub(self.head, num_dropped);\n                ptr::drop_in_place(drop_back);\n            } else {\n                let drop_back = back as *mut _;\n                let drop_front = front.get_unchecked_mut(len..) as *mut _;\n                self.head = self.wrap_sub(self.head, num_dropped);\n\n                // Make sure the second half is dropped even when a destructor\n                // in the first one panics.\n                let _back_dropper = Dropper(&mut *drop_back);\n                ptr::drop_in_place(drop_front);\n            }\n        }\n    }\n\n    /// Returns a front-to-back iterator.\n    ///\n    /// # Examples\n    ///\n    /// ```\n    /// use std::collections::VecDeque;\n    ///\n    /// let mut buf = VecDeque::new();\n    /// buf.push_back(5);\n    /// buf.push_back(3);\n    /// buf.push_back(4);\n    /// let b: &[_] = &[&5, &3, &4];\n    /// let c: Vec<&i32> = buf.iter().collect();\n    /// assert_eq!(&c[..], b);\n    /// ```\n    #[stable(feature = \"rust1\", since = \"1.0.0\")]\n    pub fn iter(&self) -> Iter<'_, T> {\n        Iter { tail: self.tail, head: self.head, ring: unsafe { self.buffer_as_slice() } }\n    }\n\n    /// Returns a front-to-back iterator that returns mutable references.\n    ///\n    /// # Examples\n    ///\n    /// ```\n    /// use std::collections::VecDeque;\n    ///\n    /// let mut buf = VecDeque::new();\n    /// buf.push_back(5);\n    /// buf.push_back(3);\n    /// buf.push_back(4);\n    /// for num in buf.iter_mut() {\n    ///     *num = *num - 2;\n    /// }\n    /// let b: &[_] = &[&mut 3, &mut 1, &mut 2];\n    /// assert_eq!(&buf.iter_mut().collect::<Vec<&mut i32>>()[..], b);\n    /// ```\n    #[stable(feature = \"rust1\", since = \"1.0.0\")]\n    pub fn iter_mut(&mut self) -> IterMut<'_, T> {\n        // SAFETY: The internal `IterMut` safety invariant is established because the\n        // `ring` we create is a dereferencable slice for lifetime '_.\n        IterMut {\n            tail: self.tail,\n            head: self.head,\n            ring: ptr::slice_from_raw_parts_mut(self.ptr(), self.cap()),\n            phantom: PhantomData,\n        }\n    }\n\n    /// Returns a pair of slices which contain, in order, the contents of the\n    /// `VecDeque`.\n    ///\n    /// If [`make_contiguous`] was previously called, all elements of the\n    /// `VecDeque` will be in the first slice and the second slice will be empty.\n    ///\n    /// [`make_contiguous`]: VecDeque::make_contiguous\n    ///\n    /// # Examples\n    ///\n    /// ```\n    /// use std::collections::VecDeque;\n    ///\n    /// let mut vector = VecDeque::new();\n    ///\n    /// vector.push_back(0);\n    /// vector.push_back(1);\n    /// vector.push_back(2);\n    ///\n    /// assert_eq!(vector.as_slices(), (&[0, 1, 2][..], &[][..]));\n    ///\n    /// vector.push_front(10);\n    /// vector.push_front(9);\n    ///\n    /// assert_eq!(vector.as_slices(), (&[9, 10][..], &[0, 1, 2][..]));\n    /// ```\n    #[inline]\n    #[stable(feature = \"deque_extras_15\", since = \"1.5.0\")]\n    pub fn as_slices(&self) -> (&[T], &[T]) {\n        unsafe {\n            let buf = self.buffer_as_slice();\n            RingSlices::ring_slices(buf, self.head, self.tail)\n        }\n    }\n\n    /// Returns a pair of slices which contain, in order, the contents of the\n    /// `VecDeque`.\n    ///\n    /// If [`make_contiguous`] was previously called, all elements of the\n    /// `VecDeque` will be in the first slice and the second slice will be empty.\n    ///\n    /// [`make_contiguous`]: VecDeque::make_contiguous\n    ///\n    /// # Examples\n    ///\n    /// ```\n    /// use std::collections::VecDeque;\n    ///\n    /// let mut vector = VecDeque::new();\n    ///\n    /// vector.push_back(0);\n    /// vector.push_back(1);\n    ///\n    /// vector.push_front(10);\n    /// vector.push_front(9);\n    ///\n    /// vector.as_mut_slices().0[0] = 42;\n    /// vector.as_mut_slices().1[0] = 24;\n    /// assert_eq!(vector.as_slices(), (&[42, 10][..], &[24, 1][..]));\n    /// ```\n    #[inline]\n    #[stable(feature = \"deque_extras_15\", since = \"1.5.0\")]\n    pub fn as_mut_slices(&mut self) -> (&mut [T], &mut [T]) {\n        unsafe {\n            let head = self.head;\n            let tail = self.tail;\n            let buf = self.buffer_as_mut_slice();\n            RingSlices::ring_slices(buf, head, tail)\n        }\n    }\n\n    /// Returns the number of elements in the `VecDeque`.\n    ///\n    /// # Examples\n    ///\n    /// ```\n    /// use std::collections::VecDeque;\n    ///\n    /// let mut v = VecDeque::new();\n    /// assert_eq!(v.len(), 0);\n    /// v.push_back(1);\n    /// assert_eq!(v.len(), 1);\n    /// ```\n    #[doc(alias = \"length\")]\n    #[stable(feature = \"rust1\", since = \"1.0.0\")]\n    pub fn len(&self) -> usize {\n        count(self.tail, self.head, self.cap())\n    }\n\n    /// Returns `true` if the `VecDeque` is empty.\n    ///\n    /// # Examples\n    ///\n    /// ```\n    /// use std::collections::VecDeque;\n    ///\n    /// let mut v = VecDeque::new();\n    /// assert!(v.is_empty());\n    /// v.push_front(1);\n    /// assert!(!v.is_empty());\n    /// ```\n    #[stable(feature = \"rust1\", since = \"1.0.0\")]\n    pub fn is_empty(&self) -> bool {\n        self.tail == self.head\n    }\n\n    fn range_tail_head<R>(&self, range: R) -> (usize, usize)\n    where\n        R: RangeBounds<usize>,\n    {\n        let Range { start, end } = slice::range(range, ..self.len());\n        let tail = self.wrap_add(self.tail, start);\n        let head = self.wrap_add(self.tail, end);\n        (tail, head)\n    }\n\n    /// Creates an iterator that covers the specified range in the `VecDeque`.\n    ///\n    /// # Panics\n    ///\n    /// Panics if the starting point is greater than the end point or if\n    /// the end point is greater than the length of the vector.\n    ///\n    /// # Examples\n    ///\n    /// ```\n    /// use std::collections::VecDeque;\n    ///\n    /// let v: VecDeque<_> = vec![1, 2, 3].into_iter().collect();\n    /// let range = v.range(2..).copied().collect::<VecDeque<_>>();\n    /// assert_eq!(range, [3]);\n    ///\n    /// // A full range covers all contents\n    /// let all = v.range(..);\n    /// assert_eq!(all.len(), 3);\n    /// ```\n    #[inline]\n    #[stable(feature = \"deque_range\", since = \"1.51.0\")]\n    pub fn range<R>(&self, range: R) -> Iter<'_, T>\n    where\n        R: RangeBounds<usize>,\n    {\n        let (tail, head) = self.range_tail_head(range);\n        Iter {\n            tail,\n            head,\n            // The shared reference we have in &self is maintained in the '_ of Iter.\n            ring: unsafe { self.buffer_as_slice() },\n        }\n    }\n\n    /// Creates an iterator that covers the specified mutable range in the `VecDeque`.\n    ///\n    /// # Panics\n    ///\n    /// Panics if the starting point is greater than the end point or if\n    /// the end point is greater than the length of the vector.\n    ///\n    /// # Examples\n    ///\n    /// ```\n    /// use std::collections::VecDeque;\n    ///\n    /// let mut v: VecDeque<_> = vec![1, 2, 3].into_iter().collect();\n    /// for v in v.range_mut(2..) {\n    ///   *v *= 2;\n    /// }\n    /// assert_eq!(v, vec![1, 2, 6]);\n    ///\n    /// // A full range covers all contents\n    /// for v in v.range_mut(..) {\n    ///   *v *= 2;\n    /// }\n    /// assert_eq!(v, vec![2, 4, 12]);\n    /// ```\n    #[inline]\n    #[stable(feature = \"deque_range\", since = \"1.51.0\")]\n    pub fn range_mut<R>(&mut self, range: R) -> IterMut<'_, T>\n    where\n        R: RangeBounds<usize>,\n    {\n        let (tail, head) = self.range_tail_head(range);\n\n        // SAFETY: The internal `IterMut` safety invariant is established because the\n        // `ring` we create is a dereferencable slice for lifetime '_.\n        IterMut {\n            tail,\n            head,\n            ring: ptr::slice_from_raw_parts_mut(self.ptr(), self.cap()),\n            phantom: PhantomData,\n        }\n    }\n\n    /// Creates a draining iterator that removes the specified range in the\n    /// `VecDeque` and yields the removed items.\n    ///\n    /// Note 1: The element range is removed even if the iterator is not\n    /// consumed until the end.\n    ///\n    /// Note 2: It is unspecified how many elements are removed from the deque,\n    /// if the `Drain` value is not dropped, but the borrow it holds expires\n    /// (e.g., due to `mem::forget`).\n    ///\n    /// # Panics\n    ///\n    /// Panics if the starting point is greater than the end point or if\n    /// the end point is greater than the length of the vector.\n    ///\n    /// # Examples\n    ///\n    /// ```\n    /// use std::collections::VecDeque;\n    ///\n    /// let mut v: VecDeque<_> = vec![1, 2, 3].into_iter().collect();\n    /// let drained = v.drain(2..).collect::<VecDeque<_>>();\n    /// assert_eq!(drained, [3]);\n    /// assert_eq!(v, [1, 2]);\n    ///\n    /// // A full range clears all contents\n    /// v.drain(..);\n    /// assert!(v.is_empty());\n    /// ```\n    #[inline]\n    #[stable(feature = \"drain\", since = \"1.6.0\")]\n    pub fn drain<R>(&mut self, range: R) -> Drain<'_, T>\n    where\n        R: RangeBounds<usize>,\n    {\n        // Memory safety\n        //\n        // When the Drain is first created, the source deque is shortened to\n        // make sure no uninitialized or moved-from elements are accessible at\n        // all if the Drain's destructor never gets to run.\n        //\n        // Drain will ptr::read out the values to remove.\n        // When finished, the remaining data will be copied back to cover the hole,\n        // and the head/tail values will be restored correctly.\n        //\n        let (drain_tail, drain_head) = self.range_tail_head(range);\n\n        // The deque's elements are parted into three segments:\n        // * self.tail  -> drain_tail\n        // * drain_tail -> drain_head\n        // * drain_head -> self.head\n        //\n        // T = self.tail; H = self.head; t = drain_tail; h = drain_head\n        //\n        // We store drain_tail as self.head, and drain_head and self.head as\n        // after_tail and after_head respectively on the Drain. This also\n        // truncates the effective array such that if the Drain is leaked, we\n        // have forgotten about the potentially moved values after the start of\n        // the drain.\n        //\n        //        T   t   h   H\n        // [. . . o o x x o o . . .]\n        //\n        let head = self.head;\n\n        // \"forget\" about the values after the start of the drain until after\n        // the drain is complete and the Drain destructor is run.\n        self.head = drain_tail;\n\n        Drain {\n            deque: NonNull::from(&mut *self),\n            after_tail: drain_head,\n            after_head: head,\n            iter: Iter {\n                tail: drain_tail,\n                head: drain_head,\n                // Crucially, we only create shared references from `self` here and read from\n                // it.  We do not write to `self` nor reborrow to a mutable reference.\n                // Hence the raw pointer we created above, for `deque`, remains valid.\n                ring: unsafe { self.buffer_as_slice() },\n            },\n        }\n    }\n\n    /// Clears the `VecDeque`, removing all values.\n    ///\n    /// # Examples\n    ///\n    /// ```\n    /// use std::collections::VecDeque;\n    ///\n    /// let mut v = VecDeque::new();\n    /// v.push_back(1);\n    /// v.clear();\n    /// assert!(v.is_empty());\n    /// ```\n    #[stable(feature = \"rust1\", since = \"1.0.0\")]\n    #[inline]\n    pub fn clear(&mut self) {\n        self.truncate(0);\n    }\n\n    /// Returns `true` if the `VecDeque` contains an element equal to the\n    /// given value.\n    ///\n    /// # Examples\n    ///\n    /// ```\n    /// use std::collections::VecDeque;\n    ///\n    /// let mut vector: VecDeque<u32> = VecDeque::new();\n    ///\n    /// vector.push_back(0);\n    /// vector.push_back(1);\n    ///\n    /// assert_eq!(vector.contains(&1), true);\n    /// assert_eq!(vector.contains(&10), false);\n    /// ```\n    #[stable(feature = \"vec_deque_contains\", since = \"1.12.0\")]\n    pub fn contains(&self, x: &T) -> bool\n    where\n        T: PartialEq<T>,\n    {\n        let (a, b) = self.as_slices();\n        a.contains(x) || b.contains(x)\n    }\n\n    /// Provides a reference to the front element, or `None` if the `VecDeque` is\n    /// empty.\n    ///\n    /// # Examples\n    ///\n    /// ```\n    /// use std::collections::VecDeque;\n    ///\n    /// let mut d = VecDeque::new();\n    /// assert_eq!(d.front(), None);\n    ///\n    /// d.push_back(1);\n    /// d.push_back(2);\n    /// assert_eq!(d.front(), Some(&1));\n    /// ```\n    #[stable(feature = \"rust1\", since = \"1.0.0\")]\n    pub fn front(&self) -> Option<&T> {\n        self.get(0)\n    }\n\n    /// Provides a mutable reference to the front element, or `None` if the\n    /// `VecDeque` is empty.\n    ///\n    /// # Examples\n    ///\n    /// ```\n    /// use std::collections::VecDeque;\n    ///\n    /// let mut d = VecDeque::new();\n    /// assert_eq!(d.front_mut(), None);\n    ///\n    /// d.push_back(1);\n    /// d.push_back(2);\n    /// match d.front_mut() {\n    ///     Some(x) => *x = 9,\n    ///     None => (),\n    /// }\n    /// assert_eq!(d.front(), Some(&9));\n    /// ```\n    #[stable(feature = \"rust1\", since = \"1.0.0\")]\n    pub fn front_mut(&mut self) -> Option<&mut T> {\n        self.get_mut(0)\n    }\n\n    /// Provides a reference to the back element, or `None` if the `VecDeque` is\n    /// empty.\n    ///\n    /// # Examples\n    ///\n    /// ```\n    /// use std::collections::VecDeque;\n    ///\n    /// let mut d = VecDeque::new();\n    /// assert_eq!(d.back(), None);\n    ///\n    /// d.push_back(1);\n    /// d.push_back(2);\n    /// assert_eq!(d.back(), Some(&2));\n    /// ```\n    #[stable(feature = \"rust1\", since = \"1.0.0\")]\n    pub fn back(&self) -> Option<&T> {\n        self.get(self.len().wrapping_sub(1))\n    }\n\n    /// Provides a mutable reference to the back element, or `None` if the\n    /// `VecDeque` is empty.\n    ///\n    /// # Examples\n    ///\n    /// ```\n    /// use std::collections::VecDeque;\n    ///\n    /// let mut d = VecDeque::new();\n    /// assert_eq!(d.back(), None);\n    ///\n    /// d.push_back(1);\n    /// d.push_back(2);\n    /// match d.back_mut() {\n    ///     Some(x) => *x = 9,\n    ///     None => (),\n    /// }\n    /// assert_eq!(d.back(), Some(&9));\n    /// ```\n    #[stable(feature = \"rust1\", since = \"1.0.0\")]\n    pub fn back_mut(&mut self) -> Option<&mut T> {\n        self.get_mut(self.len().wrapping_sub(1))\n    }\n\n    /// Removes the first element and returns it, or `None` if the `VecDeque` is\n    /// empty.\n    ///\n    /// # Examples\n    ///\n    /// ```\n    /// use std::collections::VecDeque;\n    ///\n    /// let mut d = VecDeque::new();\n    /// d.push_back(1);\n    /// d.push_back(2);\n    ///\n    /// assert_eq!(d.pop_front(), Some(1));\n    /// assert_eq!(d.pop_front(), Some(2));\n    /// assert_eq!(d.pop_front(), None);\n    /// ```\n    #[stable(feature = \"rust1\", since = \"1.0.0\")]\n    pub fn pop_front(&mut self) -> Option<T> {\n        if self.is_empty() {\n            None\n        } else {\n            let tail = self.tail;\n            self.tail = self.wrap_add(self.tail, 1);\n            unsafe { Some(self.buffer_read(tail)) }\n        }\n    }\n\n    /// Removes the last element from the `VecDeque` and returns it, or `None` if\n    /// it is empty.\n    ///\n    /// # Examples\n    ///\n    /// ```\n    /// use std::collections::VecDeque;\n    ///\n    /// let mut buf = VecDeque::new();\n    /// assert_eq!(buf.pop_back(), None);\n    /// buf.push_back(1);\n    /// buf.push_back(3);\n    /// assert_eq!(buf.pop_back(), Some(3));\n    /// ```\n    #[stable(feature = \"rust1\", since = \"1.0.0\")]\n    pub fn pop_back(&mut self) -> Option<T> {\n        if self.is_empty() {\n            None\n        } else {\n            self.head = self.wrap_sub(self.head, 1);\n            let head = self.head;\n            unsafe { Some(self.buffer_read(head)) }\n        }\n    }\n\n    /// Prepends an element to the `VecDeque`.\n    ///\n    /// # Examples\n    ///\n    /// ```\n    /// use std::collections::VecDeque;\n    ///\n    /// let mut d = VecDeque::new();\n    /// d.push_front(1);\n    /// d.push_front(2);\n    /// assert_eq!(d.front(), Some(&2));\n    /// ```\n    #[stable(feature = \"rust1\", since = \"1.0.0\")]\n    pub fn push_front(&mut self, value: T) {\n        if self.is_full() {\n            self.grow();\n        }\n\n        self.tail = self.wrap_sub(self.tail, 1);\n        let tail = self.tail;\n        unsafe {\n            self.buffer_write(tail, value);\n        }\n    }\n\n    /// Appends an element to the back of the `VecDeque`.\n    ///\n    /// # Examples\n    ///\n    /// ```\n    /// use std::collections::VecDeque;\n    ///\n    /// let mut buf = VecDeque::new();\n    /// buf.push_back(1);\n    /// buf.push_back(3);\n    /// assert_eq!(3, *buf.back().unwrap());\n    /// ```\n    #[stable(feature = \"rust1\", since = \"1.0.0\")]\n    pub fn push_back(&mut self, value: T) {\n        if self.is_full() {\n            self.grow();\n        }\n\n        let head = self.head;\n        self.head = self.wrap_add(self.head, 1);\n        unsafe { self.buffer_write(head, value) }\n    }\n\n    #[inline]\n    fn is_contiguous(&self) -> bool {\n        // FIXME: Should we consider `head == 0` to mean\n        // that `self` is contiguous?\n        self.tail <= self.head\n    }\n\n    /// Removes an element from anywhere in the `VecDeque` and returns it,\n    /// replacing it with the first element.\n    ///\n    /// This does not preserve ordering, but is *O*(1).\n    ///\n    /// Returns `None` if `index` is out of bounds.\n    ///\n    /// Element at index 0 is the front of the queue.\n    ///\n    /// # Examples\n    ///\n    /// ```\n    /// use std::collections::VecDeque;\n    ///\n    /// let mut buf = VecDeque::new();\n    /// assert_eq!(buf.swap_remove_front(0), None);\n    /// buf.push_back(1);\n    /// buf.push_back(2);\n    /// buf.push_back(3);\n    /// assert_eq!(buf, [1, 2, 3]);\n    ///\n    /// assert_eq!(buf.swap_remove_front(2), Some(3));\n    /// assert_eq!(buf, [2, 1]);\n    /// ```\n    #[stable(feature = \"deque_extras_15\", since = \"1.5.0\")]\n    pub fn swap_remove_front(&mut self, index: usize) -> Option<T> {\n        let length = self.len();\n        if length > 0 && index < length && index != 0 {\n            self.swap(index, 0);\n        } else if index >= length {\n            return None;\n        }\n        self.pop_front()\n    }\n\n    /// Removes an element from anywhere in the `VecDeque` and returns it, replacing it with the\n    /// last element.\n    ///\n    /// This does not preserve ordering, but is *O*(1).\n    ///\n    /// Returns `None` if `index` is out of bounds.\n    ///\n    /// Element at index 0 is the front of the queue.\n    ///\n    /// # Examples\n    ///\n    /// ```\n    /// use std::collections::VecDeque;\n    ///\n    /// let mut buf = VecDeque::new();\n    /// assert_eq!(buf.swap_remove_back(0), None);\n    /// buf.push_back(1);\n    /// buf.push_back(2);\n    /// buf.push_back(3);\n    /// assert_eq!(buf, [1, 2, 3]);\n    ///\n    /// assert_eq!(buf.swap_remove_back(0), Some(1));\n    /// assert_eq!(buf, [3, 2]);\n    /// ```\n    #[stable(feature = \"deque_extras_15\", since = \"1.5.0\")]\n    pub fn swap_remove_back(&mut self, index: usize) -> Option<T> {\n        let length = self.len();\n        if length > 0 && index < length - 1 {\n            self.swap(index, length - 1);\n        } else if index >= length {\n            return None;\n        }\n        self.pop_back()\n    }\n\n    /// Inserts an element at `index` within the `VecDeque`, shifting all elements with indices\n    /// greater than or equal to `index` towards the back.\n    ///\n    /// Element at index 0 is the front of the queue.\n    ///\n    /// # Panics\n    ///\n    /// Panics if `index` is greater than `VecDeque`'s length\n    ///\n    /// # Examples\n    ///\n    /// ```\n    /// use std::collections::VecDeque;\n    ///\n    /// let mut vec_deque = VecDeque::new();\n    /// vec_deque.push_back('a');\n    /// vec_deque.push_back('b');\n    /// vec_deque.push_back('c');\n    /// assert_eq!(vec_deque, &['a', 'b', 'c']);\n    ///\n    /// vec_deque.insert(1, 'd');\n    /// assert_eq!(vec_deque, &['a', 'd', 'b', 'c']);\n    /// ```\n    #[stable(feature = \"deque_extras_15\", since = \"1.5.0\")]\n    pub fn insert(&mut self, index: usize, value: T) {\n        assert!(index <= self.len(), \"index out of bounds\");\n        if self.is_full() {\n            self.grow();\n        }\n\n        // Move the least number of elements in the ring buffer and insert\n        // the given object\n        //\n        // At most len/2 - 1 elements will be moved. O(min(n, n-i))\n        //\n        // There are three main cases:\n        //  Elements are contiguous\n        //      - special case when tail is 0\n        //  Elements are discontiguous and the insert is in the tail section\n        //  Elements are discontiguous and the insert is in the head section\n        //\n        // For each of those there are two more cases:\n        //  Insert is closer to tail\n        //  Insert is closer to head\n        //\n        // Key: H - self.head\n        //      T - self.tail\n        //      o - Valid element\n        //      I - Insertion element\n        //      A - The element that should be after the insertion point\n        //      M - Indicates element was moved\n\n        let idx = self.wrap_add(self.tail, index);\n\n        let distance_to_tail = index;\n        let distance_to_head = self.len() - index;\n\n        let contiguous = self.is_contiguous();\n\n        match (contiguous, distance_to_tail <= distance_to_head, idx >= self.tail) {\n            (true, true, _) if index == 0 => {\n                // push_front\n                //\n                //       T\n                //       I             H\n                //      [A o o o o o o . . . . . . . . .]\n                //\n                //                       H         T\n                //      [A o o o o o o o . . . . . I]\n                //\n\n                self.tail = self.wrap_sub(self.tail, 1);\n            }\n            (true, true, _) => {\n                unsafe {\n                    // contiguous, insert closer to tail:\n                    //\n                    //             T   I         H\n                    //      [. . . o o A o o o o . . . . . .]\n                    //\n                    //           T               H\n                    //      [. . o o I A o o o o . . . . . .]\n                    //           M M\n                    //\n                    // contiguous, insert closer to tail and tail is 0:\n                    //\n                    //\n                    //       T   I         H\n                    //      [o o A o o o o . . . . . . . . .]\n                    //\n                    //                       H             T\n                    //      [o I A o o o o o . . . . . . . o]\n                    //       M                             M\n\n                    let new_tail = self.wrap_sub(self.tail, 1);\n\n                    self.copy(new_tail, self.tail, 1);\n                    // Already moved the tail, so we only copy `index - 1` elements.\n                    self.copy(self.tail, self.tail + 1, index - 1);\n\n                    self.tail = new_tail;\n                }\n            }\n            (true, false, _) => {\n                unsafe {\n                    //  contiguous, insert closer to head:\n                    //\n                    //             T       I     H\n                    //      [. . . o o o o A o o . . . . . .]\n                    //\n                    //             T               H\n                    //      [. . . o o o o I A o o . . . . .]\n                    //                       M M M\n\n                    self.copy(idx + 1, idx, self.head - idx);\n                    self.head = self.wrap_add(self.head, 1);\n                }\n            }\n            (false, true, true) => {\n                unsafe {\n                    // discontiguous, insert closer to tail, tail section:\n                    //\n                    //                   H         T   I\n                    //      [o o o o o o . . . . . o o A o o]\n                    //\n                    //                   H       T\n                    //      [o o o o o o . . . . o o I A o o]\n                    //                           M M\n\n                    self.copy(self.tail - 1, self.tail, index);\n                    self.tail -= 1;\n                }\n            }\n            (false, false, true) => {\n                unsafe {\n                    // discontiguous, insert closer to head, tail section:\n                    //\n                    //           H             T         I\n                    //      [o o . . . . . . . o o o o o A o]\n                    //\n                    //             H           T\n                    //      [o o o . . . . . . o o o o o I A]\n                    //       M M M                         M\n\n                    // copy elements up to new head\n                    self.copy(1, 0, self.head);\n\n                    // copy last element into empty spot at bottom of buffer\n                    self.copy(0, self.cap() - 1, 1);\n\n                    // move elements from idx to end forward not including ^ element\n                    self.copy(idx + 1, idx, self.cap() - 1 - idx);\n\n                    self.head += 1;\n                }\n            }\n            (false, true, false) if idx == 0 => {\n                unsafe {\n                    // discontiguous, insert is closer to tail, head section,\n                    // and is at index zero in the internal buffer:\n                    //\n                    //       I                   H     T\n                    //      [A o o o o o o o o o . . . o o o]\n                    //\n                    //                           H   T\n                    //      [A o o o o o o o o o . . o o o I]\n                    //                               M M M\n\n                    // copy elements up to new tail\n                    self.copy(self.tail - 1, self.tail, self.cap() - self.tail);\n\n                    // copy last element into empty spot at bottom of buffer\n                    self.copy(self.cap() - 1, 0, 1);\n\n                    self.tail -= 1;\n                }\n            }\n            (false, true, false) => {\n                unsafe {\n                    // discontiguous, insert closer to tail, head section:\n                    //\n                    //             I             H     T\n                    //      [o o o A o o o o o o . . . o o o]\n                    //\n                    //                           H   T\n                    //      [o o I A o o o o o o . . o o o o]\n                    //       M M                     M M M M\n\n                    // copy elements up to new tail\n                    self.copy(self.tail - 1, self.tail, self.cap() - self.tail);\n\n                    // copy last element into empty spot at bottom of buffer\n                    self.copy(self.cap() - 1, 0, 1);\n\n                    // move elements from idx-1 to end forward not including ^ element\n                    self.copy(0, 1, idx - 1);\n\n                    self.tail -= 1;\n                }\n            }\n            (false, false, false) => {\n                unsafe {\n                    // discontiguous, insert closer to head, head section:\n                    //\n                    //               I     H           T\n                    //      [o o o o A o o . . . . . . o o o]\n                    //\n                    //                     H           T\n                    //      [o o o o I A o o . . . . . o o o]\n                    //                 M M M\n\n                    self.copy(idx + 1, idx, self.head - idx);\n                    self.head += 1;\n                }\n            }\n        }\n\n        // tail might've been changed so we need to recalculate\n        let new_idx = self.wrap_add(self.tail, index);\n        unsafe {\n            self.buffer_write(new_idx, value);\n        }\n    }\n\n    /// Removes and returns the element at `index` from the `VecDeque`.\n    /// Whichever end is closer to the removal point will be moved to make\n    /// room, and all the affected elements will be moved to new positions.\n    /// Returns `None` if `index` is out of bounds.\n    ///\n    /// Element at index 0 is the front of the queue.\n    ///\n    /// # Examples\n    ///\n    /// ```\n    /// use std::collections::VecDeque;\n    ///\n    /// let mut buf = VecDeque::new();\n    /// buf.push_back(1);\n    /// buf.push_back(2);\n    /// buf.push_back(3);\n    /// assert_eq!(buf, [1, 2, 3]);\n    ///\n    /// assert_eq!(buf.remove(1), Some(2));\n    /// assert_eq!(buf, [1, 3]);\n    /// ```\n    #[stable(feature = \"rust1\", since = \"1.0.0\")]\n    pub fn remove(&mut self, index: usize) -> Option<T> {\n        if self.is_empty() || self.len() <= index {\n            return None;\n        }\n\n        // There are three main cases:\n        //  Elements are contiguous\n        //  Elements are discontiguous and the removal is in the tail section\n        //  Elements are discontiguous and the removal is in the head section\n        //      - special case when elements are technically contiguous,\n        //        but self.head = 0\n        //\n        // For each of those there are two more cases:\n        //  Insert is closer to tail\n        //  Insert is closer to head\n        //\n        // Key: H - self.head\n        //      T - self.tail\n        //      o - Valid element\n        //      x - Element marked for removal\n        //      R - Indicates element that is being removed\n        //      M - Indicates element was moved\n\n        let idx = self.wrap_add(self.tail, index);\n\n        let elem = unsafe { Some(self.buffer_read(idx)) };\n\n        let distance_to_tail = index;\n        let distance_to_head = self.len() - index;\n\n        let contiguous = self.is_contiguous();\n\n        match (contiguous, distance_to_tail <= distance_to_head, idx >= self.tail) {\n            (true, true, _) => {\n                unsafe {\n                    // contiguous, remove closer to tail:\n                    //\n                    //             T   R         H\n                    //      [. . . o o x o o o o . . . . . .]\n                    //\n                    //               T           H\n                    //      [. . . . o o o o o o . . . . . .]\n                    //               M M\n\n                    self.copy(self.tail + 1, self.tail, index);\n                    self.tail += 1;\n                }\n            }\n            (true, false, _) => {\n                unsafe {\n                    // contiguous, remove closer to head:\n                    //\n                    //             T       R     H\n                    //      [. . . o o o o x o o . . . . . .]\n                    //\n                    //             T           H\n                    //      [. . . o o o o o o . . . . . . .]\n                    //                     M M\n\n                    self.copy(idx, idx + 1, self.head - idx - 1);\n                    self.head -= 1;\n                }\n            }\n            (false, true, true) => {\n                unsafe {\n                    // discontiguous, remove closer to tail, tail section:\n                    //\n                    //                   H         T   R\n                    //      [o o o o o o . . . . . o o x o o]\n                    //\n                    //                   H           T\n                    //      [o o o o o o . . . . . . o o o o]\n                    //                               M M\n\n                    self.copy(self.tail + 1, self.tail, index);\n                    self.tail = self.wrap_add(self.tail, 1);\n                }\n            }\n            (false, false, false) => {\n                unsafe {\n                    // discontiguous, remove closer to head, head section:\n                    //\n                    //               R     H           T\n                    //      [o o o o x o o . . . . . . o o o]\n                    //\n                    //                   H             T\n                    //      [o o o o o o . . . . . . . o o o]\n                    //               M M\n\n                    self.copy(idx, idx + 1, self.head - idx - 1);\n                    self.head -= 1;\n                }\n            }\n            (false, false, true) => {\n                unsafe {\n                    // discontiguous, remove closer to head, tail section:\n                    //\n                    //             H           T         R\n                    //      [o o o . . . . . . o o o o o x o]\n                    //\n                    //           H             T\n                    //      [o o . . . . . . . o o o o o o o]\n                    //       M M                         M M\n                    //\n                    // or quasi-discontiguous, remove next to head, tail section:\n                    //\n                    //       H                 T         R\n                    //      [. . . . . . . . . o o o o o x o]\n                    //\n                    //                         T           H\n                    //      [. . . . . . . . . o o o o o o .]\n                    //                                   M\n\n                    // draw in elements in the tail section\n                    self.copy(idx, idx + 1, self.cap() - idx - 1);\n\n                    // Prevents underflow.\n                    if self.head != 0 {\n                        // copy first element into empty spot\n                        self.copy(self.cap() - 1, 0, 1);\n\n                        // move elements in the head section backwards\n                        self.copy(0, 1, self.head - 1);\n                    }\n\n                    self.head = self.wrap_sub(self.head, 1);\n                }\n            }\n            (false, true, false) => {\n                unsafe {\n                    // discontiguous, remove closer to tail, head section:\n                    //\n                    //           R               H     T\n                    //      [o o x o o o o o o o . . . o o o]\n                    //\n                    //                           H       T\n                    //      [o o o o o o o o o o . . . . o o]\n                    //       M M M                       M M\n\n                    // draw in elements up to idx\n                    self.copy(1, 0, idx);\n\n                    // copy last element into empty spot\n                    self.copy(0, self.cap() - 1, 1);\n\n                    // move elements from tail to end forward, excluding the last one\n                    self.copy(self.tail + 1, self.tail, self.cap() - self.tail - 1);\n\n                    self.tail = self.wrap_add(self.tail, 1);\n                }\n            }\n        }\n\n        elem\n    }\n\n    /// Splits the `VecDeque` into two at the given index.\n    ///\n    /// Returns a newly allocated `VecDeque`. `self` contains elements `[0, at)`,\n    /// and the returned `VecDeque` contains elements `[at, len)`.\n    ///\n    /// Note that the capacity of `self` does not change.\n    ///\n    /// Element at index 0 is the front of the queue.\n    ///\n    /// # Panics\n    ///\n    /// Panics if `at > len`.\n    ///\n    /// # Examples\n    ///\n    /// ```\n    /// use std::collections::VecDeque;\n    ///\n    /// let mut buf: VecDeque<_> = vec![1, 2, 3].into_iter().collect();\n    /// let buf2 = buf.split_off(1);\n    /// assert_eq!(buf, [1]);\n    /// assert_eq!(buf2, [2, 3]);\n    /// ```\n    #[inline]\n    #[must_use = \"use `.truncate()` if you don't need the other half\"]\n    #[stable(feature = \"split_off\", since = \"1.4.0\")]\n    pub fn split_off(&mut self, at: usize) -> Self {\n        let len = self.len();\n        assert!(at <= len, \"`at` out of bounds\");\n\n        let other_len = len - at;\n        let mut other = VecDeque::with_capacity(other_len);\n\n        unsafe {\n            let (first_half, second_half) = self.as_slices();\n\n            let first_len = first_half.len();\n            let second_len = second_half.len();\n            if at < first_len {\n                // `at` lies in the first half.\n                let amount_in_first = first_len - at;\n\n                ptr::copy_nonoverlapping(first_half.as_ptr().add(at), other.ptr(), amount_in_first);\n\n                // just take all of the second half.\n                ptr::copy_nonoverlapping(\n                    second_half.as_ptr(),\n                    other.ptr().add(amount_in_first),\n                    second_len,\n                );\n            } else {\n                // `at` lies in the second half, need to factor in the elements we skipped\n                // in the first half.\n                let offset = at - first_len;\n                let amount_in_second = second_len - offset;\n                ptr::copy_nonoverlapping(\n                    second_half.as_ptr().add(offset),\n                    other.ptr(),\n                    amount_in_second,\n                );\n            }\n        }\n\n        // Cleanup where the ends of the buffers are\n        self.head = self.wrap_sub(self.head, other_len);\n        other.head = other.wrap_index(other_len);\n\n        other\n    }\n\n    /// Moves all the elements of `other` into `self`, leaving `other` empty.\n    ///\n    /// # Panics\n    ///\n    /// Panics if the new number of elements in self overflows a `usize`.\n    ///\n    /// # Examples\n    ///\n    /// ```\n    /// use std::collections::VecDeque;\n    ///\n    /// let mut buf: VecDeque<_> = vec![1, 2].into_iter().collect();\n    /// let mut buf2: VecDeque<_> = vec![3, 4].into_iter().collect();\n    /// buf.append(&mut buf2);\n    /// assert_eq!(buf, [1, 2, 3, 4]);\n    /// assert_eq!(buf2, []);\n    /// ```\n    #[inline]\n    #[stable(feature = \"append\", since = \"1.4.0\")]\n    pub fn append(&mut self, other: &mut Self) {\n        // naive impl\n        self.extend(other.drain(..));\n    }\n\n    /// Retains only the elements specified by the predicate.\n    ///\n    /// In other words, remove all elements `e` such that `f(&e)` returns false.\n    /// This method operates in place, visiting each element exactly once in the\n    /// original order, and preserves the order of the retained elements.\n    ///\n    /// # Examples\n    ///\n    /// ```\n    /// use std::collections::VecDeque;\n    ///\n    /// let mut buf = VecDeque::new();\n    /// buf.extend(1..5);\n    /// buf.retain(|&x| x % 2 == 0);\n    /// assert_eq!(buf, [2, 4]);\n    /// ```\n    ///\n    /// The exact order may be useful for tracking external state, like an index.\n    ///\n    /// ```\n    /// use std::collections::VecDeque;\n    ///\n    /// let mut buf = VecDeque::new();\n    /// buf.extend(1..6);\n    ///\n    /// let keep = [false, true, true, false, true];\n    /// let mut i = 0;\n    /// buf.retain(|_| (keep[i], i += 1).0);\n    /// assert_eq!(buf, [2, 3, 5]);\n    /// ```\n    #[stable(feature = \"vec_deque_retain\", since = \"1.4.0\")]\n    pub fn retain<F>(&mut self, mut f: F)\n    where\n        F: FnMut(&T) -> bool,\n    {\n        let len = self.len();\n        let mut del = 0;\n        for i in 0..len {\n            if !f(&self[i]) {\n                del += 1;\n            } else if del > 0 {\n                self.swap(i - del, i);\n            }\n        }\n        if del > 0 {\n            self.truncate(len - del);\n        }\n    }\n\n    // This may panic or abort\n    #[inline(never)]\n    fn grow(&mut self) {\n        if self.is_full() {\n            let old_cap = self.cap();\n            // Double the buffer size.\n            self.buf.reserve_exact(old_cap, old_cap);\n            assert!(self.cap() == old_cap * 2);\n            unsafe {\n                self.handle_capacity_increase(old_cap);\n            }\n            debug_assert!(!self.is_full());\n        }\n    }\n\n    /// Modifies the `VecDeque` in-place so that `len()` is equal to `new_len`,\n    /// either by removing excess elements from the back or by appending\n    /// elements generated by calling `generator` to the back.\n    ///\n    /// # Examples\n    ///\n    /// ```\n    /// use std::collections::VecDeque;\n    ///\n    /// let mut buf = VecDeque::new();\n    /// buf.push_back(5);\n    /// buf.push_back(10);\n    /// buf.push_back(15);\n    /// assert_eq!(buf, [5, 10, 15]);\n    ///\n    /// buf.resize_with(5, Default::default);\n    /// assert_eq!(buf, [5, 10, 15, 0, 0]);\n    ///\n    /// buf.resize_with(2, || unreachable!());\n    /// assert_eq!(buf, [5, 10]);\n    ///\n    /// let mut state = 100;\n    /// buf.resize_with(5, || { state += 1; state });\n    /// assert_eq!(buf, [5, 10, 101, 102, 103]);\n    /// ```\n    #[stable(feature = \"vec_resize_with\", since = \"1.33.0\")]\n    pub fn resize_with(&mut self, new_len: usize, generator: impl FnMut() -> T) {\n        let len = self.len();\n\n        if new_len > len {\n            self.extend(repeat_with(generator).take(new_len - len))\n        } else {\n            self.truncate(new_len);\n        }\n    }\n\n    /// Rearranges the internal storage of this deque so it is one contiguous\n    /// slice, which is then returned.\n    ///\n    /// This method does not allocate and does not change the order of the\n    /// inserted elements. As it returns a mutable slice, this can be used to\n    /// sort a deque.\n    ///\n    /// Once the internal storage is contiguous, the [`as_slices`] and\n    /// [`as_mut_slices`] methods will return the entire contents of the\n    /// `VecDeque` in a single slice.\n    ///\n    /// [`as_slices`]: VecDeque::as_slices\n    /// [`as_mut_slices`]: VecDeque::as_mut_slices\n    ///\n    /// # Examples\n    ///\n    /// Sorting the content of a deque.\n    ///\n    /// ```\n    /// use std::collections::VecDeque;\n    ///\n    /// let mut buf = VecDeque::with_capacity(15);\n    ///\n    /// buf.push_back(2);\n    /// buf.push_back(1);\n    /// buf.push_front(3);\n    ///\n    /// // sorting the deque\n    /// buf.make_contiguous().sort();\n    /// assert_eq!(buf.as_slices(), (&[1, 2, 3] as &[_], &[] as &[_]));\n    ///\n    /// // sorting it in reverse order\n    /// buf.make_contiguous().sort_by(|a, b| b.cmp(a));\n    /// assert_eq!(buf.as_slices(), (&[3, 2, 1] as &[_], &[] as &[_]));\n    /// ```\n    ///\n    /// Getting immutable access to the contiguous slice.\n    ///\n    /// ```rust\n    /// use std::collections::VecDeque;\n    ///\n    /// let mut buf = VecDeque::new();\n    ///\n    /// buf.push_back(2);\n    /// buf.push_back(1);\n    /// buf.push_front(3);\n    ///\n    /// buf.make_contiguous();\n    /// if let (slice, &[]) = buf.as_slices() {\n    ///     // we can now be sure that `slice` contains all elements of the deque,\n    ///     // while still having immutable access to `buf`.\n    ///     assert_eq!(buf.len(), slice.len());\n    ///     assert_eq!(slice, &[3, 2, 1] as &[_]);\n    /// }\n    /// ```\n    #[stable(feature = \"deque_make_contiguous\", since = \"1.48.0\")]\n    pub fn make_contiguous(&mut self) -> &mut [T] {\n        if self.is_contiguous() {\n            let tail = self.tail;\n            let head = self.head;\n            return unsafe { RingSlices::ring_slices(self.buffer_as_mut_slice(), head, tail).0 };\n        }\n\n        let buf = self.buf.ptr();\n        let cap = self.cap();\n        let len = self.len();\n\n        let free = self.tail - self.head;\n        let tail_len = cap - self.tail;\n\n        if free >= tail_len {\n            // there is enough free space to copy the tail in one go,\n            // this means that we first shift the head backwards, and then\n            // copy the tail to the correct position.\n            //\n            // from: DEFGH....ABC\n            // to:   ABCDEFGH....\n            unsafe {\n                ptr::copy(buf, buf.add(tail_len), self.head);\n                // ...DEFGH.ABC\n                ptr::copy_nonoverlapping(buf.add(self.tail), buf, tail_len);\n                // ABCDEFGH....\n\n                self.tail = 0;\n                self.head = len;\n            }\n        } else if free > self.head {\n            // FIXME: We currently do not consider ....ABCDEFGH\n            // to be contiguous because `head` would be `0` in this\n            // case. While we probably want to change this it\n            // isn't trivial as a few places expect `is_contiguous`\n            // to mean that we can just slice using `buf[tail..head]`.\n\n            // there is enough free space to copy the head in one go,\n            // this means that we first shift the tail forwards, and then\n            // copy the head to the correct position.\n            //\n            // from: FGH....ABCDE\n            // to:   ...ABCDEFGH.\n            unsafe {\n                ptr::copy(buf.add(self.tail), buf.add(self.head), tail_len);\n                // FGHABCDE....\n                ptr::copy_nonoverlapping(buf, buf.add(self.head + tail_len), self.head);\n                // ...ABCDEFGH.\n\n                self.tail = self.head;\n                self.head = self.wrap_add(self.tail, len);\n            }\n        } else {\n            // free is smaller than both head and tail,\n            // this means we have to slowly \"swap\" the tail and the head.\n            //\n            // from: EFGHI...ABCD or HIJK.ABCDEFG\n            // to:   ABCDEFGHI... or ABCDEFGHIJK.\n            let mut left_edge: usize = 0;\n            let mut right_edge: usize = self.tail;\n            unsafe {\n                // The general problem looks like this\n                // GHIJKLM...ABCDEF - before any swaps\n                // ABCDEFM...GHIJKL - after 1 pass of swaps\n                // ABCDEFGHIJM...KL - swap until the left edge reaches the temp store\n                //                  - then restart the algorithm with a new (smaller) store\n                // Sometimes the temp store is reached when the right edge is at the end\n                // of the buffer - this means we've hit the right order with fewer swaps!\n                // E.g\n                // EF..ABCD\n                // ABCDEF.. - after four only swaps we've finished\n                while left_edge < len && right_edge != cap {\n                    let mut right_offset = 0;\n                    for i in left_edge..right_edge {\n                        right_offset = (i - left_edge) % (cap - right_edge);\n                        let src: isize = (right_edge + right_offset) as isize;\n                        ptr::swap(buf.add(i), buf.offset(src));\n                    }\n                    let n_ops = right_edge - left_edge;\n                    left_edge += n_ops;\n                    right_edge += right_offset + 1;\n                }\n\n                self.tail = 0;\n                self.head = len;\n            }\n        }\n\n        let tail = self.tail;\n        let head = self.head;\n        unsafe { RingSlices::ring_slices(self.buffer_as_mut_slice(), head, tail).0 }\n    }\n\n    /// Rotates the double-ended queue `mid` places to the left.\n    ///\n    /// Equivalently,\n    /// - Rotates item `mid` into the first position.\n    /// - Pops the first `mid` items and pushes them to the end.\n    /// - Rotates `len() - mid` places to the right.\n    ///\n    /// # Panics\n    ///\n    /// If `mid` is greater than `len()`. Note that `mid == len()`\n    /// does _not_ panic and is a no-op rotation.\n    ///\n    /// # Complexity\n    ///\n    /// Takes `*O*(min(mid, len() - mid))` time and no extra space.\n    ///\n    /// # Examples\n    ///\n    /// ```\n    /// use std::collections::VecDeque;\n    ///\n    /// let mut buf: VecDeque<_> = (0..10).collect();\n    ///\n    /// buf.rotate_left(3);\n    /// assert_eq!(buf, [3, 4, 5, 6, 7, 8, 9, 0, 1, 2]);\n    ///\n    /// for i in 1..10 {\n    ///     assert_eq!(i * 3 % 10, buf[0]);\n    ///     buf.rotate_left(3);\n    /// }\n    /// assert_eq!(buf, [0, 1, 2, 3, 4, 5, 6, 7, 8, 9]);\n    /// ```\n    #[stable(feature = \"vecdeque_rotate\", since = \"1.36.0\")]\n    pub fn rotate_left(&mut self, mid: usize) {\n        assert!(mid <= self.len());\n        let k = self.len() - mid;\n        if mid <= k {\n            unsafe { self.rotate_left_inner(mid) }\n        } else {\n            unsafe { self.rotate_right_inner(k) }\n        }\n    }\n\n    /// Rotates the double-ended queue `k` places to the right.\n    ///\n    /// Equivalently,\n    /// - Rotates the first item into position `k`.\n    /// - Pops the last `k` items and pushes them to the front.\n    /// - Rotates `len() - k` places to the left.\n    ///\n    /// # Panics\n    ///\n    /// If `k` is greater than `len()`. Note that `k == len()`\n    /// does _not_ panic and is a no-op rotation.\n    ///\n    /// # Complexity\n    ///\n    /// Takes `*O*(min(k, len() - k))` time and no extra space.\n    ///\n    /// # Examples\n    ///\n    /// ```\n    /// use std::collections::VecDeque;\n    ///\n    /// let mut buf: VecDeque<_> = (0..10).collect();\n    ///\n    /// buf.rotate_right(3);\n    /// assert_eq!(buf, [7, 8, 9, 0, 1, 2, 3, 4, 5, 6]);\n    ///\n    /// for i in 1..10 {\n    ///     assert_eq!(0, buf[i * 3 % 10]);\n    ///     buf.rotate_right(3);\n    /// }\n    /// assert_eq!(buf, [0, 1, 2, 3, 4, 5, 6, 7, 8, 9]);\n    /// ```\n    #[stable(feature = \"vecdeque_rotate\", since = \"1.36.0\")]\n    pub fn rotate_right(&mut self, k: usize) {\n        assert!(k <= self.len());\n        let mid = self.len() - k;\n        if k <= mid {\n            unsafe { self.rotate_right_inner(k) }\n        } else {\n            unsafe { self.rotate_left_inner(mid) }\n        }\n    }\n\n    // SAFETY: the following two methods require that the rotation amount\n    // be less than half the length of the deque.\n    //\n    // `wrap_copy` requires that `min(x, cap() - x) + copy_len <= cap()`,\n    // but than `min` is never more than half the capacity, regardless of x,\n    // so it's sound to call here because we're calling with something\n    // less than half the length, which is never above half the capacity.\n\n    unsafe fn rotate_left_inner(&mut self, mid: usize) {\n        debug_assert!(mid * 2 <= self.len());\n        unsafe {\n            self.wrap_copy(self.head, self.tail, mid);\n        }\n        self.head = self.wrap_add(self.head, mid);\n        self.tail = self.wrap_add(self.tail, mid);\n    }\n\n    unsafe fn rotate_right_inner(&mut self, k: usize) {\n        debug_assert!(k * 2 <= self.len());\n        self.head = self.wrap_sub(self.head, k);\n        self.tail = self.wrap_sub(self.tail, k);\n        unsafe {\n            self.wrap_copy(self.tail, self.head, k);\n        }\n    }\n\n    /// Binary searches this sorted `VecDeque` for a given element.\n    ///\n    /// If the value is found then [`Result::Ok`] is returned, containing the\n    /// index of the matching element. If there are multiple matches, then any\n    /// one of the matches could be returned. If the value is not found then\n    /// [`Result::Err`] is returned, containing the index where a matching\n    /// element could be inserted while maintaining sorted order.\n    ///\n    /// See also [`binary_search_by`], [`binary_search_by_key`], and [`partition_point`].\n    ///\n    /// [`binary_search_by`]: VecDeque::binary_search_by\n    /// [`binary_search_by_key`]: VecDeque::binary_search_by_key\n    /// [`partition_point`]: VecDeque::partition_point\n    ///\n    /// # Examples\n    ///\n    /// Looks up a series of four elements. The first is found, with a\n    /// uniquely determined position; the second and third are not\n    /// found; the fourth could match any position in `[1, 4]`.\n    ///\n    /// ```\n    /// use std::collections::VecDeque;\n    ///\n    /// let deque: VecDeque<_> = vec![0, 1, 1, 1, 1, 2, 3, 5, 8, 13, 21, 34, 55].into();\n    ///\n    /// assert_eq!(deque.binary_search(&13),  Ok(9));\n    /// assert_eq!(deque.binary_search(&4),   Err(7));\n    /// assert_eq!(deque.binary_search(&100), Err(13));\n    /// let r = deque.binary_search(&1);\n    /// assert!(matches!(r, Ok(1..=4)));\n    /// ```\n    ///\n    /// If you want to insert an item to a sorted `VecDeque`, while maintaining\n    /// sort order:\n    ///\n    /// ```\n    /// use std::collections::VecDeque;\n    ///\n    /// let mut deque: VecDeque<_> = vec![0, 1, 1, 1, 1, 2, 3, 5, 8, 13, 21, 34, 55].into();\n    /// let num = 42;\n    /// let idx = deque.binary_search(&num).unwrap_or_else(|x| x);\n    /// deque.insert(idx, num);\n    /// assert_eq!(deque, &[0, 1, 1, 1, 1, 2, 3, 5, 8, 13, 21, 34, 42, 55]);\n    /// ```\n    #[stable(feature = \"vecdeque_binary_search\", since = \"1.54.0\")]\n    #[inline]\n    pub fn binary_search(&self, x: &T) -> Result<usize, usize>\n    where\n        T: Ord,\n    {\n        self.binary_search_by(|e| e.cmp(x))\n    }\n\n    /// Binary searches this sorted `VecDeque` with a comparator function.\n    ///\n    /// The comparator function should implement an order consistent\n    /// with the sort order of the underlying `VecDeque`, returning an\n    /// order code that indicates whether its argument is `Less`,\n    /// `Equal` or `Greater` than the desired target.\n    ///\n    /// If the value is found then [`Result::Ok`] is returned, containing the\n    /// index of the matching element. If there are multiple matches, then any\n    /// one of the matches could be returned. If the value is not found then\n    /// [`Result::Err`] is returned, containing the index where a matching\n    /// element could be inserted while maintaining sorted order.\n    ///\n    /// See also [`binary_search`], [`binary_search_by_key`], and [`partition_point`].\n    ///\n    /// [`binary_search`]: VecDeque::binary_search\n    /// [`binary_search_by_key`]: VecDeque::binary_search_by_key\n    /// [`partition_point`]: VecDeque::partition_point\n    ///\n    /// # Examples\n    ///\n    /// Looks up a series of four elements. The first is found, with a\n    /// uniquely determined position; the second and third are not\n    /// found; the fourth could match any position in `[1, 4]`.\n    ///\n    /// ```\n    /// use std::collections::VecDeque;\n    ///\n    /// let deque: VecDeque<_> = vec![0, 1, 1, 1, 1, 2, 3, 5, 8, 13, 21, 34, 55].into();\n    ///\n    /// assert_eq!(deque.binary_search_by(|x| x.cmp(&13)),  Ok(9));\n    /// assert_eq!(deque.binary_search_by(|x| x.cmp(&4)),   Err(7));\n    /// assert_eq!(deque.binary_search_by(|x| x.cmp(&100)), Err(13));\n    /// let r = deque.binary_search_by(|x| x.cmp(&1));\n    /// assert!(matches!(r, Ok(1..=4)));\n    /// ```\n    #[stable(feature = \"vecdeque_binary_search\", since = \"1.54.0\")]\n    pub fn binary_search_by<'a, F>(&'a self, mut f: F) -> Result<usize, usize>\n    where\n        F: FnMut(&'a T) -> Ordering,\n    {\n        let (front, back) = self.as_slices();\n        let cmp_back = back.first().map(|elem| f(elem));\n\n        if let Some(Ordering::Equal) = cmp_back {\n            Ok(front.len())\n        } else if let Some(Ordering::Less) = cmp_back {\n            back.binary_search_by(f).map(|idx| idx + front.len()).map_err(|idx| idx + front.len())\n        } else {\n            front.binary_search_by(f)\n        }\n    }\n\n    /// Binary searches this sorted `VecDeque` with a key extraction function.\n    ///\n    /// Assumes that the `VecDeque` is sorted by the key, for instance with\n    /// [`make_contiguous().sort_by_key()`] using the same key extraction function.\n    ///\n    /// If the value is found then [`Result::Ok`] is returned, containing the\n    /// index of the matching element. If there are multiple matches, then any\n    /// one of the matches could be returned. If the value is not found then\n    /// [`Result::Err`] is returned, containing the index where a matching\n    /// element could be inserted while maintaining sorted order.\n    ///\n    /// See also [`binary_search`], [`binary_search_by`], and [`partition_point`].\n    ///\n    /// [`make_contiguous().sort_by_key()`]: VecDeque::make_contiguous\n    /// [`binary_search`]: VecDeque::binary_search\n    /// [`binary_search_by`]: VecDeque::binary_search_by\n    /// [`partition_point`]: VecDeque::partition_point\n    ///\n    /// # Examples\n    ///\n    /// Looks up a series of four elements in a slice of pairs sorted by\n    /// their second elements. The first is found, with a uniquely\n    /// determined position; the second and third are not found; the\n    /// fourth could match any position in `[1, 4]`.\n    ///\n    /// ```\n    /// use std::collections::VecDeque;\n    ///\n    /// let deque: VecDeque<_> = vec![(0, 0), (2, 1), (4, 1), (5, 1),\n    ///          (3, 1), (1, 2), (2, 3), (4, 5), (5, 8), (3, 13),\n    ///          (1, 21), (2, 34), (4, 55)].into();\n    ///\n    /// assert_eq!(deque.binary_search_by_key(&13, |&(a, b)| b),  Ok(9));\n    /// assert_eq!(deque.binary_search_by_key(&4, |&(a, b)| b),   Err(7));\n    /// assert_eq!(deque.binary_search_by_key(&100, |&(a, b)| b), Err(13));\n    /// let r = deque.binary_search_by_key(&1, |&(a, b)| b);\n    /// assert!(matches!(r, Ok(1..=4)));\n    /// ```\n    #[stable(feature = \"vecdeque_binary_search\", since = \"1.54.0\")]\n    #[inline]\n    pub fn binary_search_by_key<'a, B, F>(&'a self, b: &B, mut f: F) -> Result<usize, usize>\n    where\n        F: FnMut(&'a T) -> B,\n        B: Ord,\n    {\n        self.binary_search_by(|k| f(k).cmp(b))\n    }\n\n    /// Returns the index of the partition point according to the given predicate\n    /// (the index of the first element of the second partition).\n    ///\n    /// The deque is assumed to be partitioned according to the given predicate.\n    /// This means that all elements for which the predicate returns true are at the start of the deque\n    /// and all elements for which the predicate returns false are at the end.\n    /// For example, [7, 15, 3, 5, 4, 12, 6] is a partitioned under the predicate x % 2 != 0\n    /// (all odd numbers are at the start, all even at the end).\n    ///\n    /// If this deque is not partitioned, the returned result is unspecified and meaningless,\n    /// as this method performs a kind of binary search.\n    ///\n    /// See also [`binary_search`], [`binary_search_by`], and [`binary_search_by_key`].\n    ///\n    /// [`binary_search`]: VecDeque::binary_search\n    /// [`binary_search_by`]: VecDeque::binary_search_by\n    /// [`binary_search_by_key`]: VecDeque::binary_search_by_key\n    ///\n    /// # Examples\n    ///\n    /// ```\n    /// use std::collections::VecDeque;\n    ///\n    /// let deque: VecDeque<_> = vec![1, 2, 3, 3, 5, 6, 7].into();\n    /// let i = deque.partition_point(|&x| x < 5);\n    ///\n    /// assert_eq!(i, 4);\n    /// assert!(deque.iter().take(i).all(|&x| x < 5));\n    /// assert!(deque.iter().skip(i).all(|&x| !(x < 5)));\n    /// ```\n    #[stable(feature = \"vecdeque_binary_search\", since = \"1.54.0\")]\n    pub fn partition_point<P>(&self, mut pred: P) -> usize\n    where\n        P: FnMut(&T) -> bool,\n    {\n        let (front, back) = self.as_slices();\n\n        if let Some(true) = back.first().map(|v| pred(v)) {\n            back.partition_point(pred) + front.len()\n        } else {\n            front.partition_point(pred)\n        }\n    }\n}\n\nimpl<T: Clone> VecDeque<T> {\n    /// Modifies the `VecDeque` in-place so that `len()` is equal to new_len,\n    /// either by removing excess elements from the back or by appending clones of `value`\n    /// to the back.\n    ///\n    /// # Examples\n    ///\n    /// ```\n    /// use std::collections::VecDeque;\n    ///\n    /// let mut buf = VecDeque::new();\n    /// buf.push_back(5);\n    /// buf.push_back(10);\n    /// buf.push_back(15);\n    /// assert_eq!(buf, [5, 10, 15]);\n    ///\n    /// buf.resize(2, 0);\n    /// assert_eq!(buf, [5, 10]);\n    ///\n    /// buf.resize(5, 20);\n    /// assert_eq!(buf, [5, 10, 20, 20, 20]);\n    /// ```\n    #[stable(feature = \"deque_extras\", since = \"1.16.0\")]\n    pub fn resize(&mut self, new_len: usize, value: T) {\n        self.resize_with(new_len, || value.clone());\n    }\n}\n\n/// Returns the index in the underlying buffer for a given logical element index.\n#[inline]\nfn wrap_index(index: usize, size: usize) -> usize {\n    // size is always a power of 2\n    debug_assert!(size.is_power_of_two());\n    index & (size - 1)\n}\n\n/// Calculate the number of elements left to be read in the buffer\n#[inline]\nfn count(tail: usize, head: usize, size: usize) -> usize {\n    // size is always a power of 2\n    (head.wrapping_sub(tail)) & (size - 1)\n}\n\n#[stable(feature = \"rust1\", since = \"1.0.0\")]\nimpl<A: PartialEq> PartialEq for VecDeque<A> {\n    fn eq(&self, other: &VecDeque<A>) -> bool {\n        if self.len() != other.len() {\n            return false;\n        }\n        let (sa, sb) = self.as_slices();\n        let (oa, ob) = other.as_slices();\n        if sa.len() == oa.len() {\n            sa == oa && sb == ob\n        } else if sa.len() < oa.len() {\n            // Always divisible in three sections, for example:\n            // self:  [a b c|d e f]\n            // other: [0 1 2 3|4 5]\n            // front = 3, mid = 1,\n            // [a b c] == [0 1 2] && [d] == [3] && [e f] == [4 5]\n            let front = sa.len();\n            let mid = oa.len() - front;\n\n            let (oa_front, oa_mid) = oa.split_at(front);\n            let (sb_mid, sb_back) = sb.split_at(mid);\n            debug_assert_eq!(sa.len(), oa_front.len());\n            debug_assert_eq!(sb_mid.len(), oa_mid.len());\n            debug_assert_eq!(sb_back.len(), ob.len());\n            sa == oa_front && sb_mid == oa_mid && sb_back == ob\n        } else {\n            let front = oa.len();\n            let mid = sa.len() - front;\n\n            let (sa_front, sa_mid) = sa.split_at(front);\n            let (ob_mid, ob_back) = ob.split_at(mid);\n            debug_assert_eq!(sa_front.len(), oa.len());\n            debug_assert_eq!(sa_mid.len(), ob_mid.len());\n            debug_assert_eq!(sb.len(), ob_back.len());\n            sa_front == oa && sa_mid == ob_mid && sb == ob_back\n        }\n    }\n}\n\n#[stable(feature = \"rust1\", since = \"1.0.0\")]\nimpl<A: Eq> Eq for VecDeque<A> {}\n\n__impl_slice_eq1! { [] VecDeque<A>, Vec<B>, }\n__impl_slice_eq1! { [] VecDeque<A>, &[B], }\n__impl_slice_eq1! { [] VecDeque<A>, &mut [B], }\n__impl_slice_eq1! { [const N: usize] VecDeque<A>, [B; N], }\n__impl_slice_eq1! { [const N: usize] VecDeque<A>, &[B; N], }\n__impl_slice_eq1! { [const N: usize] VecDeque<A>, &mut [B; N], }\n\n#[stable(feature = \"rust1\", since = \"1.0.0\")]\nimpl<A: PartialOrd> PartialOrd for VecDeque<A> {\n    fn partial_cmp(&self, other: &VecDeque<A>) -> Option<Ordering> {\n        self.iter().partial_cmp(other.iter())\n    }\n}\n\n#[stable(feature = \"rust1\", since = \"1.0.0\")]\nimpl<A: Ord> Ord for VecDeque<A> {\n    #[inline]\n    fn cmp(&self, other: &VecDeque<A>) -> Ordering {\n        self.iter().cmp(other.iter())\n    }\n}\n\n#[stable(feature = \"rust1\", since = \"1.0.0\")]\nimpl<A: Hash> Hash for VecDeque<A> {\n    fn hash<H: Hasher>(&self, state: &mut H) {\n        self.len().hash(state);\n        // It's not possible to use Hash::hash_slice on slices\n        // returned by as_slices method as their length can vary\n        // in otherwise identical deques.\n        //\n        // Hasher only guarantees equivalence for the exact same\n        // set of calls to its methods.\n        self.iter().for_each(|elem| elem.hash(state));\n    }\n}\n\n#[stable(feature = \"rust1\", since = \"1.0.0\")]\nimpl<A> Index<usize> for VecDeque<A> {\n    type Output = A;\n\n    #[inline]\n    fn index(&self, index: usize) -> &A {\n        self.get(index).expect(\"Out of bounds access\")\n    }\n}\n\n#[stable(feature = \"rust1\", since = \"1.0.0\")]\nimpl<A> IndexMut<usize> for VecDeque<A> {\n    #[inline]\n    fn index_mut(&mut self, index: usize) -> &mut A {\n        self.get_mut(index).expect(\"Out of bounds access\")\n    }\n}\n\n#[stable(feature = \"rust1\", since = \"1.0.0\")]\nimpl<A> FromIterator<A> for VecDeque<A> {\n    fn from_iter<T: IntoIterator<Item = A>>(iter: T) -> VecDeque<A> {\n        let iterator = iter.into_iter();\n        let (lower, _) = iterator.size_hint();\n        let mut deq = VecDeque::with_capacity(lower);\n        deq.extend(iterator);\n        deq\n    }\n}\n\n#[stable(feature = \"rust1\", since = \"1.0.0\")]\nimpl<T> IntoIterator for VecDeque<T> {\n    type Item = T;\n    type IntoIter = IntoIter<T>;\n\n    /// Consumes the `VecDeque` into a front-to-back iterator yielding elements by\n    /// value.\n    fn into_iter(self) -> IntoIter<T> {\n        IntoIter { inner: self }\n    }\n}\n\n#[stable(feature = \"rust1\", since = \"1.0.0\")]\nimpl<'a, T> IntoIterator for &'a VecDeque<T> {\n    type Item = &'a T;\n    type IntoIter = Iter<'a, T>;\n\n    fn into_iter(self) -> Iter<'a, T> {\n        self.iter()\n    }\n}\n\n#[stable(feature = \"rust1\", since = \"1.0.0\")]\nimpl<'a, T> IntoIterator for &'a mut VecDeque<T> {\n    type Item = &'a mut T;\n    type IntoIter = IterMut<'a, T>;\n\n    fn into_iter(self) -> IterMut<'a, T> {\n        self.iter_mut()\n    }\n}\n\n#[stable(feature = \"rust1\", since = \"1.0.0\")]\nimpl<A> Extend<A> for VecDeque<A> {\n    fn extend<T: IntoIterator<Item = A>>(&mut self, iter: T) {\n        // This function should be the moral equivalent of:\n        //\n        //      for item in iter.into_iter() {\n        //          self.push_back(item);\n        //      }\n        let mut iter = iter.into_iter();\n        while let Some(element) = iter.next() {\n            if self.len() == self.capacity() {\n                let (lower, _) = iter.size_hint();\n                self.reserve(lower.saturating_add(1));\n            }\n\n            let head = self.head;\n            self.head = self.wrap_add(self.head, 1);\n            unsafe {\n                self.buffer_write(head, element);\n            }\n        }\n    }\n\n    #[inline]\n    fn extend_one(&mut self, elem: A) {\n        self.push_back(elem);\n    }\n\n    #[inline]\n    fn extend_reserve(&mut self, additional: usize) {\n        self.reserve(additional);\n    }\n}\n\n#[stable(feature = \"extend_ref\", since = \"1.2.0\")]\nimpl<'a, T: 'a + Copy> Extend<&'a T> for VecDeque<T> {\n    fn extend<I: IntoIterator<Item = &'a T>>(&mut self, iter: I) {\n        self.extend(iter.into_iter().cloned());\n    }\n\n    #[inline]\n    fn extend_one(&mut self, &elem: &T) {\n        self.push_back(elem);\n    }\n\n    #[inline]\n    fn extend_reserve(&mut self, additional: usize) {\n        self.reserve(additional);\n    }\n}\n\n#[stable(feature = \"rust1\", since = \"1.0.0\")]\nimpl<T: fmt::Debug> fmt::Debug for VecDeque<T> {\n    fn fmt(&self, f: &mut fmt::Formatter<'_>) -> fmt::Result {\n        f.debug_list().entries(self).finish()\n    }\n}\n\n#[stable(feature = \"vecdeque_vec_conversions\", since = \"1.10.0\")]\nimpl<T> From<Vec<T>> for VecDeque<T> {\n    /// Turn a [`Vec<T>`] into a [`VecDeque<T>`].\n    ///\n    /// [`Vec<T>`]: crate::vec::Vec\n    /// [`VecDeque<T>`]: crate::collections::VecDeque\n    ///\n    /// This avoids reallocating where possible, but the conditions for that are\n    /// strict, and subject to change, and so shouldn't be relied upon unless the\n    /// `Vec<T>` came from `From<VecDeque<T>>` and hasn't been reallocated.\n    fn from(mut other: Vec<T>) -> Self {\n        let len = other.len();\n        if mem::size_of::<T>() == 0 {\n            // There's no actual allocation for ZSTs to worry about capacity,\n            // but `VecDeque` can't handle as much length as `Vec`.\n            assert!(len < MAXIMUM_ZST_CAPACITY, \"capacity overflow\");\n        } else {\n            // We need to resize if the capacity is not a power of two, too small or\n            // doesn't have at least one free space. We do this while it's still in\n            // the `Vec` so the items will drop on panic.\n            let min_cap = cmp::max(MINIMUM_CAPACITY, len) + 1;\n            let cap = cmp::max(min_cap, other.capacity()).next_power_of_two();\n            if other.capacity() != cap {\n                other.reserve_exact(cap - len);\n            }\n        }\n\n        unsafe {\n            let (other_buf, len, capacity) = other.into_raw_parts();\n            let buf = RawVec::from_raw_parts(other_buf, capacity);\n            VecDeque { tail: 0, head: len, buf }\n        }\n    }\n}\n\n#[stable(feature = \"vecdeque_vec_conversions\", since = \"1.10.0\")]\nimpl<T> From<VecDeque<T>> for Vec<T> {\n    /// Turn a [`VecDeque<T>`] into a [`Vec<T>`].\n    ///\n    /// [`Vec<T>`]: crate::vec::Vec\n    /// [`VecDeque<T>`]: crate::collections::VecDeque\n    ///\n    /// This never needs to re-allocate, but does need to do *O*(*n*) data movement if\n    /// the circular buffer doesn't happen to be at the beginning of the allocation.\n    ///\n    /// # Examples\n    ///\n    /// ```\n    /// use std::collections::VecDeque;\n    ///\n    /// // This one is *O*(1).\n    /// let deque: VecDeque<_> = (1..5).collect();\n    /// let ptr = deque.as_slices().0.as_ptr();\n    /// let vec = Vec::from(deque);\n    /// assert_eq!(vec, [1, 2, 3, 4]);\n    /// assert_eq!(vec.as_ptr(), ptr);\n    ///\n    /// // This one needs data rearranging.\n    /// let mut deque: VecDeque<_> = (1..5).collect();\n    /// deque.push_front(9);\n    /// deque.push_front(8);\n    /// let ptr = deque.as_slices().1.as_ptr();\n    /// let vec = Vec::from(deque);\n    /// assert_eq!(vec, [8, 9, 1, 2, 3, 4]);\n    /// assert_eq!(vec.as_ptr(), ptr);\n    /// ```\n    fn from(mut other: VecDeque<T>) -> Self {\n        other.make_contiguous();\n\n        unsafe {\n            let other = ManuallyDrop::new(other);\n            let buf = other.buf.ptr();\n            let len = other.len();\n            let cap = other.cap();\n\n            if other.tail != 0 {\n                ptr::copy(buf.add(other.tail), buf, len);\n            }\n            Vec::from_raw_parts(buf, len, cap)\n        }\n    }\n}\n"],[2019,"use core::cmp::{self};\nuse core::mem::replace;\n\nuse super::VecDeque;\n\n/// PairSlices pairs up equal length slice parts of two deques\n///\n/// For example, given deques \"A\" and \"B\" with the following division into slices:\n///\n/// A: [0 1 2] [3 4 5]\n/// B: [a b] [c d e]\n///\n/// It produces the following sequence of matching slices:\n///\n/// ([0 1], [a b])\n/// (\\[2\\], \\[c\\])\n/// ([3 4], [d e])\n///\n/// and the uneven remainder of either A or B is skipped.\npub struct PairSlices<'a, 'b, T> {\n    pub(crate) a0: &'a mut [T],\n    pub(crate) a1: &'a mut [T],\n    pub(crate) b0: &'b [T],\n    pub(crate) b1: &'b [T],\n}\n\nimpl<'a, 'b, T> PairSlices<'a, 'b, T> {\n    pub fn from(to: &'a mut VecDeque<T>, from: &'b VecDeque<T>) -> Self {\n        let (a0, a1) = to.as_mut_slices();\n        let (b0, b1) = from.as_slices();\n        PairSlices { a0, a1, b0, b1 }\n    }\n\n    pub fn has_remainder(&self) -> bool {\n        !self.b0.is_empty()\n    }\n\n    pub fn remainder(self) -> impl Iterator<Item = &'b [T]> {\n        IntoIterator::into_iter([self.b0, self.b1])\n    }\n}\n\nimpl<'a, 'b, T> Iterator for PairSlices<'a, 'b, T> {\n    type Item = (&'a mut [T], &'b [T]);\n    fn next(&mut self) -> Option<Self::Item> {\n        // Get next part length\n        let part = cmp::min(self.a0.len(), self.b0.len());\n        if part == 0 {\n            return None;\n        }\n        let (p0, p1) = replace(&mut self.a0, &mut []).split_at_mut(part);\n        let (q0, q1) = self.b0.split_at(part);\n\n        // Move a1 into a0, if it's empty (and b1, b0 the same way).\n        self.a0 = p1;\n        self.b0 = q1;\n        if self.a0.is_empty() {\n            self.a0 = replace(&mut self.a1, &mut []);\n        }\n        if self.b0.is_empty() {\n            self.b0 = replace(&mut self.b1, &[]);\n        }\n        Some((p0, q0))\n    }\n}\n"],[2020,"macro_rules! __impl_slice_eq1 {\n    ([$($vars:tt)*] $lhs:ty, $rhs:ty, $($constraints:tt)*) => {\n        #[stable(feature = \"vec_deque_partial_eq_slice\", since = \"1.17.0\")]\n        impl<A, B, $($vars)*> PartialEq<$rhs> for $lhs\n        where\n            A: PartialEq<B>,\n            $($constraints)*\n        {\n            fn eq(&self, other: &$rhs) -> bool {\n                if self.len() != other.len() {\n                    return false;\n                }\n                let (sa, sb) = self.as_slices();\n                let (oa, ob) = other[..].split_at(sa.len());\n                sa == oa && sb == ob\n            }\n        }\n    }\n}\n"],[2021,"use core::fmt;\nuse core::iter::{FusedIterator, TrustedLen, TrustedRandomAccess};\nuse core::ops::Try;\n\nuse super::{count, wrap_index, RingSlices};\n\n/// An iterator over the elements of a `VecDeque`.\n///\n/// This `struct` is created by the [`iter`] method on [`super::VecDeque`]. See its\n/// documentation for more.\n///\n/// [`iter`]: super::VecDeque::iter\n#[stable(feature = \"rust1\", since = \"1.0.0\")]\npub struct Iter<'a, T: 'a> {\n    pub(crate) ring: &'a [T],\n    pub(crate) tail: usize,\n    pub(crate) head: usize,\n}\n\n#[stable(feature = \"collection_debug\", since = \"1.17.0\")]\nimpl<T: fmt::Debug> fmt::Debug for Iter<'_, T> {\n    fn fmt(&self, f: &mut fmt::Formatter<'_>) -> fmt::Result {\n        let (front, back) = RingSlices::ring_slices(self.ring, self.head, self.tail);\n        f.debug_tuple(\"Iter\").field(&front).field(&back).finish()\n    }\n}\n\n// FIXME(#26925) Remove in favor of `#[derive(Clone)]`\n#[stable(feature = \"rust1\", since = \"1.0.0\")]\nimpl<T> Clone for Iter<'_, T> {\n    fn clone(&self) -> Self {\n        Iter { ring: self.ring, tail: self.tail, head: self.head }\n    }\n}\n\n#[stable(feature = \"rust1\", since = \"1.0.0\")]\nimpl<'a, T> Iterator for Iter<'a, T> {\n    type Item = &'a T;\n\n    #[inline]\n    fn next(&mut self) -> Option<&'a T> {\n        if self.tail == self.head {\n            return None;\n        }\n        let tail = self.tail;\n        self.tail = wrap_index(self.tail.wrapping_add(1), self.ring.len());\n        unsafe { Some(self.ring.get_unchecked(tail)) }\n    }\n\n    #[inline]\n    fn size_hint(&self) -> (usize, Option<usize>) {\n        let len = count(self.tail, self.head, self.ring.len());\n        (len, Some(len))\n    }\n\n    fn fold<Acc, F>(self, mut accum: Acc, mut f: F) -> Acc\n    where\n        F: FnMut(Acc, Self::Item) -> Acc,\n    {\n        let (front, back) = RingSlices::ring_slices(self.ring, self.head, self.tail);\n        accum = front.iter().fold(accum, &mut f);\n        back.iter().fold(accum, &mut f)\n    }\n\n    fn try_fold<B, F, R>(&mut self, init: B, mut f: F) -> R\n    where\n        Self: Sized,\n        F: FnMut(B, Self::Item) -> R,\n        R: Try<Output = B>,\n    {\n        let (mut iter, final_res);\n        if self.tail <= self.head {\n            // single slice self.ring[self.tail..self.head]\n            iter = self.ring[self.tail..self.head].iter();\n            final_res = iter.try_fold(init, &mut f);\n        } else {\n            // two slices: self.ring[self.tail..], self.ring[..self.head]\n            let (front, back) = self.ring.split_at(self.tail);\n            let mut back_iter = back.iter();\n            let res = back_iter.try_fold(init, &mut f);\n            let len = self.ring.len();\n            self.tail = (self.ring.len() - back_iter.len()) & (len - 1);\n            iter = front[..self.head].iter();\n            final_res = iter.try_fold(res?, &mut f);\n        }\n        self.tail = self.head - iter.len();\n        final_res\n    }\n\n    fn nth(&mut self, n: usize) -> Option<Self::Item> {\n        if n >= count(self.tail, self.head, self.ring.len()) {\n            self.tail = self.head;\n            None\n        } else {\n            self.tail = wrap_index(self.tail.wrapping_add(n), self.ring.len());\n            self.next()\n        }\n    }\n\n    #[inline]\n    fn last(mut self) -> Option<&'a T> {\n        self.next_back()\n    }\n\n    #[inline]\n    #[doc(hidden)]\n    unsafe fn __iterator_get_unchecked(&mut self, idx: usize) -> Self::Item\n    where\n        Self: TrustedRandomAccess,\n    {\n        // Safety: The TrustedRandomAccess contract requires that callers only  pass an index\n        // that is in bounds.\n        unsafe {\n            let idx = wrap_index(self.tail.wrapping_add(idx), self.ring.len());\n            self.ring.get_unchecked(idx)\n        }\n    }\n}\n\n#[stable(feature = \"rust1\", since = \"1.0.0\")]\nimpl<'a, T> DoubleEndedIterator for Iter<'a, T> {\n    #[inline]\n    fn next_back(&mut self) -> Option<&'a T> {\n        if self.tail == self.head {\n            return None;\n        }\n        self.head = wrap_index(self.head.wrapping_sub(1), self.ring.len());\n        unsafe { Some(self.ring.get_unchecked(self.head)) }\n    }\n\n    fn rfold<Acc, F>(self, mut accum: Acc, mut f: F) -> Acc\n    where\n        F: FnMut(Acc, Self::Item) -> Acc,\n    {\n        let (front, back) = RingSlices::ring_slices(self.ring, self.head, self.tail);\n        accum = back.iter().rfold(accum, &mut f);\n        front.iter().rfold(accum, &mut f)\n    }\n\n    fn try_rfold<B, F, R>(&mut self, init: B, mut f: F) -> R\n    where\n        Self: Sized,\n        F: FnMut(B, Self::Item) -> R,\n        R: Try<Output = B>,\n    {\n        let (mut iter, final_res);\n        if self.tail <= self.head {\n            // single slice self.ring[self.tail..self.head]\n            iter = self.ring[self.tail..self.head].iter();\n            final_res = iter.try_rfold(init, &mut f);\n        } else {\n            // two slices: self.ring[self.tail..], self.ring[..self.head]\n            let (front, back) = self.ring.split_at(self.tail);\n            let mut front_iter = front[..self.head].iter();\n            let res = front_iter.try_rfold(init, &mut f);\n            self.head = front_iter.len();\n            iter = back.iter();\n            final_res = iter.try_rfold(res?, &mut f);\n        }\n        self.head = self.tail + iter.len();\n        final_res\n    }\n}\n\n#[stable(feature = \"rust1\", since = \"1.0.0\")]\nimpl<T> ExactSizeIterator for Iter<'_, T> {\n    fn is_empty(&self) -> bool {\n        self.head == self.tail\n    }\n}\n\n#[stable(feature = \"fused\", since = \"1.26.0\")]\nimpl<T> FusedIterator for Iter<'_, T> {}\n\n#[unstable(feature = \"trusted_len\", issue = \"37572\")]\nunsafe impl<T> TrustedLen for Iter<'_, T> {}\n\n#[doc(hidden)]\n#[unstable(feature = \"trusted_random_access\", issue = \"none\")]\nunsafe impl<T> TrustedRandomAccess for Iter<'_, T> {\n    const MAY_HAVE_SIDE_EFFECT: bool = false;\n}\n"],[2022,"use core::iter::FusedIterator;\nuse core::ptr::{self, NonNull};\nuse core::{fmt, mem};\n\nuse super::{count, Iter, VecDeque};\n\n/// A draining iterator over the elements of a `VecDeque`.\n///\n/// This `struct` is created by the [`drain`] method on [`VecDeque`]. See its\n/// documentation for more.\n///\n/// [`drain`]: VecDeque::drain\n#[stable(feature = \"drain\", since = \"1.6.0\")]\npub struct Drain<'a, T: 'a> {\n    pub(crate) after_tail: usize,\n    pub(crate) after_head: usize,\n    pub(crate) iter: Iter<'a, T>,\n    pub(crate) deque: NonNull<VecDeque<T>>,\n}\n\n#[stable(feature = \"collection_debug\", since = \"1.17.0\")]\nimpl<T: fmt::Debug> fmt::Debug for Drain<'_, T> {\n    fn fmt(&self, f: &mut fmt::Formatter<'_>) -> fmt::Result {\n        f.debug_tuple(\"Drain\")\n            .field(&self.after_tail)\n            .field(&self.after_head)\n            .field(&self.iter)\n            .finish()\n    }\n}\n\n#[stable(feature = \"drain\", since = \"1.6.0\")]\nunsafe impl<T: Sync> Sync for Drain<'_, T> {}\n#[stable(feature = \"drain\", since = \"1.6.0\")]\nunsafe impl<T: Send> Send for Drain<'_, T> {}\n\n#[stable(feature = \"drain\", since = \"1.6.0\")]\nimpl<T> Drop for Drain<'_, T> {\n    fn drop(&mut self) {\n        struct DropGuard<'r, 'a, T>(&'r mut Drain<'a, T>);\n\n        impl<'r, 'a, T> Drop for DropGuard<'r, 'a, T> {\n            fn drop(&mut self) {\n                self.0.for_each(drop);\n\n                let source_deque = unsafe { self.0.deque.as_mut() };\n\n                // T = source_deque_tail; H = source_deque_head; t = drain_tail; h = drain_head\n                //\n                //        T   t   h   H\n                // [. . . o o x x o o . . .]\n                //\n                let orig_tail = source_deque.tail;\n                let drain_tail = source_deque.head;\n                let drain_head = self.0.after_tail;\n                let orig_head = self.0.after_head;\n\n                let tail_len = count(orig_tail, drain_tail, source_deque.cap());\n                let head_len = count(drain_head, orig_head, source_deque.cap());\n\n                // Restore the original head value\n                source_deque.head = orig_head;\n\n                match (tail_len, head_len) {\n                    (0, 0) => {\n                        source_deque.head = 0;\n                        source_deque.tail = 0;\n                    }\n                    (0, _) => {\n                        source_deque.tail = drain_head;\n                    }\n                    (_, 0) => {\n                        source_deque.head = drain_tail;\n                    }\n                    _ => unsafe {\n                        if tail_len <= head_len {\n                            source_deque.tail = source_deque.wrap_sub(drain_head, tail_len);\n                            source_deque.wrap_copy(source_deque.tail, orig_tail, tail_len);\n                        } else {\n                            source_deque.head = source_deque.wrap_add(drain_tail, head_len);\n                            source_deque.wrap_copy(drain_tail, drain_head, head_len);\n                        }\n                    },\n                }\n            }\n        }\n\n        while let Some(item) = self.next() {\n            let guard = DropGuard(self);\n            drop(item);\n            mem::forget(guard);\n        }\n\n        DropGuard(self);\n    }\n}\n\n#[stable(feature = \"drain\", since = \"1.6.0\")]\nimpl<T> Iterator for Drain<'_, T> {\n    type Item = T;\n\n    #[inline]\n    fn next(&mut self) -> Option<T> {\n        self.iter.next().map(|elt| unsafe { ptr::read(elt) })\n    }\n\n    #[inline]\n    fn size_hint(&self) -> (usize, Option<usize>) {\n        self.iter.size_hint()\n    }\n}\n\n#[stable(feature = \"drain\", since = \"1.6.0\")]\nimpl<T> DoubleEndedIterator for Drain<'_, T> {\n    #[inline]\n    fn next_back(&mut self) -> Option<T> {\n        self.iter.next_back().map(|elt| unsafe { ptr::read(elt) })\n    }\n}\n\n#[stable(feature = \"drain\", since = \"1.6.0\")]\nimpl<T> ExactSizeIterator for Drain<'_, T> {}\n\n#[stable(feature = \"fused\", since = \"1.26.0\")]\nimpl<T> FusedIterator for Drain<'_, T> {}\n"],[2023,"use core::fmt;\nuse core::iter::{FusedIterator, TrustedLen, TrustedRandomAccess};\nuse core::marker::PhantomData;\n\nuse super::{count, wrap_index, RingSlices};\n\n/// A mutable iterator over the elements of a `VecDeque`.\n///\n/// This `struct` is created by the [`iter_mut`] method on [`super::VecDeque`]. See its\n/// documentation for more.\n///\n/// [`iter_mut`]: super::VecDeque::iter_mut\n#[stable(feature = \"rust1\", since = \"1.0.0\")]\npub struct IterMut<'a, T: 'a> {\n    // Internal safety invariant: the entire slice is dereferencable.\n    pub(crate) ring: *mut [T],\n    pub(crate) tail: usize,\n    pub(crate) head: usize,\n    pub(crate) phantom: PhantomData<&'a mut [T]>,\n}\n\n// SAFETY: we do nothing thread-local and there is no interior mutability,\n// so the usual structural `Send`/`Sync` apply.\n#[stable(feature = \"rust1\", since = \"1.0.0\")]\nunsafe impl<T: Send> Send for IterMut<'_, T> {}\n#[stable(feature = \"rust1\", since = \"1.0.0\")]\nunsafe impl<T: Sync> Sync for IterMut<'_, T> {}\n\n#[stable(feature = \"collection_debug\", since = \"1.17.0\")]\nimpl<T: fmt::Debug> fmt::Debug for IterMut<'_, T> {\n    fn fmt(&self, f: &mut fmt::Formatter<'_>) -> fmt::Result {\n        let (front, back) = RingSlices::ring_slices(self.ring, self.head, self.tail);\n        // SAFETY: these are the elements we have not handed out yet, so aliasing is fine.\n        // The `IterMut` invariant also ensures everything is dereferencable.\n        let (front, back) = unsafe { (&*front, &*back) };\n        f.debug_tuple(\"IterMut\").field(&front).field(&back).finish()\n    }\n}\n\n#[stable(feature = \"rust1\", since = \"1.0.0\")]\nimpl<'a, T> Iterator for IterMut<'a, T> {\n    type Item = &'a mut T;\n\n    #[inline]\n    fn next(&mut self) -> Option<&'a mut T> {\n        if self.tail == self.head {\n            return None;\n        }\n        let tail = self.tail;\n        self.tail = wrap_index(self.tail.wrapping_add(1), self.ring.len());\n\n        unsafe {\n            let elem = self.ring.get_unchecked_mut(tail);\n            Some(&mut *elem)\n        }\n    }\n\n    #[inline]\n    fn size_hint(&self) -> (usize, Option<usize>) {\n        let len = count(self.tail, self.head, self.ring.len());\n        (len, Some(len))\n    }\n\n    fn fold<Acc, F>(self, mut accum: Acc, mut f: F) -> Acc\n    where\n        F: FnMut(Acc, Self::Item) -> Acc,\n    {\n        let (front, back) = RingSlices::ring_slices(self.ring, self.head, self.tail);\n        // SAFETY: these are the elements we have not handed out yet, so aliasing is fine.\n        // The `IterMut` invariant also ensures everything is dereferencable.\n        let (front, back) = unsafe { (&mut *front, &mut *back) };\n        accum = front.iter_mut().fold(accum, &mut f);\n        back.iter_mut().fold(accum, &mut f)\n    }\n\n    fn nth(&mut self, n: usize) -> Option<Self::Item> {\n        if n >= count(self.tail, self.head, self.ring.len()) {\n            self.tail = self.head;\n            None\n        } else {\n            self.tail = wrap_index(self.tail.wrapping_add(n), self.ring.len());\n            self.next()\n        }\n    }\n\n    #[inline]\n    fn last(mut self) -> Option<&'a mut T> {\n        self.next_back()\n    }\n\n    #[inline]\n    #[doc(hidden)]\n    unsafe fn __iterator_get_unchecked(&mut self, idx: usize) -> Self::Item\n    where\n        Self: TrustedRandomAccess,\n    {\n        // Safety: The TrustedRandomAccess contract requires that callers only  pass an index\n        // that is in bounds.\n        unsafe {\n            let idx = wrap_index(self.tail.wrapping_add(idx), self.ring.len());\n            &mut *self.ring.get_unchecked_mut(idx)\n        }\n    }\n}\n\n#[stable(feature = \"rust1\", since = \"1.0.0\")]\nimpl<'a, T> DoubleEndedIterator for IterMut<'a, T> {\n    #[inline]\n    fn next_back(&mut self) -> Option<&'a mut T> {\n        if self.tail == self.head {\n            return None;\n        }\n        self.head = wrap_index(self.head.wrapping_sub(1), self.ring.len());\n\n        unsafe {\n            let elem = self.ring.get_unchecked_mut(self.head);\n            Some(&mut *elem)\n        }\n    }\n\n    fn rfold<Acc, F>(self, mut accum: Acc, mut f: F) -> Acc\n    where\n        F: FnMut(Acc, Self::Item) -> Acc,\n    {\n        let (front, back) = RingSlices::ring_slices(self.ring, self.head, self.tail);\n        // SAFETY: these are the elements we have not handed out yet, so aliasing is fine.\n        // The `IterMut` invariant also ensures everything is dereferencable.\n        let (front, back) = unsafe { (&mut *front, &mut *back) };\n        accum = back.iter_mut().rfold(accum, &mut f);\n        front.iter_mut().rfold(accum, &mut f)\n    }\n}\n\n#[stable(feature = \"rust1\", since = \"1.0.0\")]\nimpl<T> ExactSizeIterator for IterMut<'_, T> {\n    fn is_empty(&self) -> bool {\n        self.head == self.tail\n    }\n}\n\n#[stable(feature = \"fused\", since = \"1.26.0\")]\nimpl<T> FusedIterator for IterMut<'_, T> {}\n\n#[unstable(feature = \"trusted_len\", issue = \"37572\")]\nunsafe impl<T> TrustedLen for IterMut<'_, T> {}\n\n#[doc(hidden)]\n#[unstable(feature = \"trusted_random_access\", issue = \"none\")]\nunsafe impl<T> TrustedRandomAccess for IterMut<'_, T> {\n    const MAY_HAVE_SIDE_EFFECT: bool = false;\n}\n"],[2024,"use super::*;\n\nuse std::thread;\nuse std::vec::Vec;\n\nuse rand::{thread_rng, RngCore};\n\nfn list_from<T: Clone>(v: &[T]) -> LinkedList<T> {\n    v.iter().cloned().collect()\n}\n\npub fn check_links<T>(list: &LinkedList<T>) {\n    unsafe {\n        let mut len = 0;\n        let mut last_ptr: Option<&Node<T>> = None;\n        let mut node_ptr: &Node<T>;\n        match list.head {\n            None => {\n                // tail node should also be None.\n                assert!(list.tail.is_none());\n                assert_eq!(0, list.len);\n                return;\n            }\n            Some(node) => node_ptr = &*node.as_ptr(),\n        }\n        loop {\n            match (last_ptr, node_ptr.prev) {\n                (None, None) => {}\n                (None, _) => panic!(\"prev link for head\"),\n                (Some(p), Some(pptr)) => {\n                    assert_eq!(p as *const Node<T>, pptr.as_ptr() as *const Node<T>);\n                }\n                _ => panic!(\"prev link is none, not good\"),\n            }\n            match node_ptr.next {\n                Some(next) => {\n                    last_ptr = Some(node_ptr);\n                    node_ptr = &*next.as_ptr();\n                    len += 1;\n                }\n                None => {\n                    len += 1;\n                    break;\n                }\n            }\n        }\n\n        // verify that the tail node points to the last node.\n        let tail = list.tail.as_ref().expect(\"some tail node\").as_ref();\n        assert_eq!(tail as *const Node<T>, node_ptr as *const Node<T>);\n        // check that len matches interior links.\n        assert_eq!(len, list.len);\n    }\n}\n\n#[test]\nfn test_append() {\n    // Empty to empty\n    {\n        let mut m = LinkedList::<i32>::new();\n        let mut n = LinkedList::new();\n        m.append(&mut n);\n        check_links(&m);\n        assert_eq!(m.len(), 0);\n        assert_eq!(n.len(), 0);\n    }\n    // Non-empty to empty\n    {\n        let mut m = LinkedList::new();\n        let mut n = LinkedList::new();\n        n.push_back(2);\n        m.append(&mut n);\n        check_links(&m);\n        assert_eq!(m.len(), 1);\n        assert_eq!(m.pop_back(), Some(2));\n        assert_eq!(n.len(), 0);\n        check_links(&m);\n    }\n    // Empty to non-empty\n    {\n        let mut m = LinkedList::new();\n        let mut n = LinkedList::new();\n        m.push_back(2);\n        m.append(&mut n);\n        check_links(&m);\n        assert_eq!(m.len(), 1);\n        assert_eq!(m.pop_back(), Some(2));\n        check_links(&m);\n    }\n\n    // Non-empty to non-empty\n    let v = vec![1, 2, 3, 4, 5];\n    let u = vec![9, 8, 1, 2, 3, 4, 5];\n    let mut m = list_from(&v);\n    let mut n = list_from(&u);\n    m.append(&mut n);\n    check_links(&m);\n    let mut sum = v;\n    sum.extend_from_slice(&u);\n    assert_eq!(sum.len(), m.len());\n    for elt in sum {\n        assert_eq!(m.pop_front(), Some(elt))\n    }\n    assert_eq!(n.len(), 0);\n    // Let's make sure it's working properly, since we\n    // did some direct changes to private members.\n    n.push_back(3);\n    assert_eq!(n.len(), 1);\n    assert_eq!(n.pop_front(), Some(3));\n    check_links(&n);\n}\n\n#[test]\nfn test_clone_from() {\n    // Short cloned from long\n    {\n        let v = vec![1, 2, 3, 4, 5];\n        let u = vec![8, 7, 6, 2, 3, 4, 5];\n        let mut m = list_from(&v);\n        let n = list_from(&u);\n        m.clone_from(&n);\n        check_links(&m);\n        assert_eq!(m, n);\n        for elt in u {\n            assert_eq!(m.pop_front(), Some(elt))\n        }\n    }\n    // Long cloned from short\n    {\n        let v = vec![1, 2, 3, 4, 5];\n        let u = vec![6, 7, 8];\n        let mut m = list_from(&v);\n        let n = list_from(&u);\n        m.clone_from(&n);\n        check_links(&m);\n        assert_eq!(m, n);\n        for elt in u {\n            assert_eq!(m.pop_front(), Some(elt))\n        }\n    }\n    // Two equal length lists\n    {\n        let v = vec![1, 2, 3, 4, 5];\n        let u = vec![9, 8, 1, 2, 3];\n        let mut m = list_from(&v);\n        let n = list_from(&u);\n        m.clone_from(&n);\n        check_links(&m);\n        assert_eq!(m, n);\n        for elt in u {\n            assert_eq!(m.pop_front(), Some(elt))\n        }\n    }\n}\n\n#[test]\n#[cfg_attr(target_os = \"emscripten\", ignore)]\nfn test_send() {\n    let n = list_from(&[1, 2, 3]);\n    thread::spawn(move || {\n        check_links(&n);\n        let a: &[_] = &[&1, &2, &3];\n        assert_eq!(a, &*n.iter().collect::<Vec<_>>());\n    })\n    .join()\n    .ok()\n    .unwrap();\n}\n\n#[test]\nfn test_fuzz() {\n    for _ in 0..25 {\n        fuzz_test(3);\n        fuzz_test(16);\n        #[cfg(not(miri))] // Miri is too slow\n        fuzz_test(189);\n    }\n}\n\n#[test]\nfn test_26021() {\n    // There was a bug in split_off that failed to null out the RHS's head's prev ptr.\n    // This caused the RHS's dtor to walk up into the LHS at drop and delete all of\n    // its nodes.\n    //\n    // https://github.com/rust-lang/rust/issues/26021\n    let mut v1 = LinkedList::new();\n    v1.push_front(1);\n    v1.push_front(1);\n    v1.push_front(1);\n    v1.push_front(1);\n    let _ = v1.split_off(3); // Dropping this now should not cause laundry consumption\n    assert_eq!(v1.len(), 3);\n\n    assert_eq!(v1.iter().len(), 3);\n    assert_eq!(v1.iter().collect::<Vec<_>>().len(), 3);\n}\n\n#[test]\nfn test_split_off() {\n    let mut v1 = LinkedList::new();\n    v1.push_front(1);\n    v1.push_front(1);\n    v1.push_front(1);\n    v1.push_front(1);\n\n    // test all splits\n    for ix in 0..1 + v1.len() {\n        let mut a = v1.clone();\n        let b = a.split_off(ix);\n        check_links(&a);\n        check_links(&b);\n        a.extend(b);\n        assert_eq!(v1, a);\n    }\n}\n\nfn fuzz_test(sz: i32) {\n    let mut m: LinkedList<_> = LinkedList::new();\n    let mut v = vec![];\n    for i in 0..sz {\n        check_links(&m);\n        let r: u8 = thread_rng().next_u32() as u8;\n        match r % 6 {\n            0 => {\n                m.pop_back();\n                v.pop();\n            }\n            1 => {\n                if !v.is_empty() {\n                    m.pop_front();\n                    v.remove(0);\n                }\n            }\n            2 | 4 => {\n                m.push_front(-i);\n                v.insert(0, -i);\n            }\n            3 | 5 | _ => {\n                m.push_back(i);\n                v.push(i);\n            }\n        }\n    }\n\n    check_links(&m);\n\n    let mut i = 0;\n    for (a, &b) in m.into_iter().zip(&v) {\n        i += 1;\n        assert_eq!(a, b);\n    }\n    assert_eq!(i, v.len());\n}\n\n#[test]\nfn drain_filter_test() {\n    let mut m: LinkedList<u32> = LinkedList::new();\n    m.extend(&[1, 2, 3, 4, 5, 6]);\n    let deleted = m.drain_filter(|v| *v < 4).collect::<Vec<_>>();\n\n    check_links(&m);\n\n    assert_eq!(deleted, &[1, 2, 3]);\n    assert_eq!(m.into_iter().collect::<Vec<_>>(), &[4, 5, 6]);\n}\n\n#[test]\nfn drain_to_empty_test() {\n    let mut m: LinkedList<u32> = LinkedList::new();\n    m.extend(&[1, 2, 3, 4, 5, 6]);\n    let deleted = m.drain_filter(|_| true).collect::<Vec<_>>();\n\n    check_links(&m);\n\n    assert_eq!(deleted, &[1, 2, 3, 4, 5, 6]);\n    assert_eq!(m.into_iter().collect::<Vec<_>>(), &[]);\n}\n\n#[test]\nfn test_cursor_move_peek() {\n    let mut m: LinkedList<u32> = LinkedList::new();\n    m.extend(&[1, 2, 3, 4, 5, 6]);\n    let mut cursor = m.cursor_front();\n    assert_eq!(cursor.current(), Some(&1));\n    assert_eq!(cursor.peek_next(), Some(&2));\n    assert_eq!(cursor.peek_prev(), None);\n    assert_eq!(cursor.index(), Some(0));\n    cursor.move_prev();\n    assert_eq!(cursor.current(), None);\n    assert_eq!(cursor.peek_next(), Some(&1));\n    assert_eq!(cursor.peek_prev(), Some(&6));\n    assert_eq!(cursor.index(), None);\n    cursor.move_next();\n    cursor.move_next();\n    assert_eq!(cursor.current(), Some(&2));\n    assert_eq!(cursor.peek_next(), Some(&3));\n    assert_eq!(cursor.peek_prev(), Some(&1));\n    assert_eq!(cursor.index(), Some(1));\n\n    let mut cursor = m.cursor_back();\n    assert_eq!(cursor.current(), Some(&6));\n    assert_eq!(cursor.peek_next(), None);\n    assert_eq!(cursor.peek_prev(), Some(&5));\n    assert_eq!(cursor.index(), Some(5));\n    cursor.move_next();\n    assert_eq!(cursor.current(), None);\n    assert_eq!(cursor.peek_next(), Some(&1));\n    assert_eq!(cursor.peek_prev(), Some(&6));\n    assert_eq!(cursor.index(), None);\n    cursor.move_prev();\n    cursor.move_prev();\n    assert_eq!(cursor.current(), Some(&5));\n    assert_eq!(cursor.peek_next(), Some(&6));\n    assert_eq!(cursor.peek_prev(), Some(&4));\n    assert_eq!(cursor.index(), Some(4));\n\n    let mut m: LinkedList<u32> = LinkedList::new();\n    m.extend(&[1, 2, 3, 4, 5, 6]);\n    let mut cursor = m.cursor_front_mut();\n    assert_eq!(cursor.current(), Some(&mut 1));\n    assert_eq!(cursor.peek_next(), Some(&mut 2));\n    assert_eq!(cursor.peek_prev(), None);\n    assert_eq!(cursor.index(), Some(0));\n    cursor.move_prev();\n    assert_eq!(cursor.current(), None);\n    assert_eq!(cursor.peek_next(), Some(&mut 1));\n    assert_eq!(cursor.peek_prev(), Some(&mut 6));\n    assert_eq!(cursor.index(), None);\n    cursor.move_next();\n    cursor.move_next();\n    assert_eq!(cursor.current(), Some(&mut 2));\n    assert_eq!(cursor.peek_next(), Some(&mut 3));\n    assert_eq!(cursor.peek_prev(), Some(&mut 1));\n    assert_eq!(cursor.index(), Some(1));\n    let mut cursor2 = cursor.as_cursor();\n    assert_eq!(cursor2.current(), Some(&2));\n    assert_eq!(cursor2.index(), Some(1));\n    cursor2.move_next();\n    assert_eq!(cursor2.current(), Some(&3));\n    assert_eq!(cursor2.index(), Some(2));\n    assert_eq!(cursor.current(), Some(&mut 2));\n    assert_eq!(cursor.index(), Some(1));\n\n    let mut m: LinkedList<u32> = LinkedList::new();\n    m.extend(&[1, 2, 3, 4, 5, 6]);\n    let mut cursor = m.cursor_back_mut();\n    assert_eq!(cursor.current(), Some(&mut 6));\n    assert_eq!(cursor.peek_next(), None);\n    assert_eq!(cursor.peek_prev(), Some(&mut 5));\n    assert_eq!(cursor.index(), Some(5));\n    cursor.move_next();\n    assert_eq!(cursor.current(), None);\n    assert_eq!(cursor.peek_next(), Some(&mut 1));\n    assert_eq!(cursor.peek_prev(), Some(&mut 6));\n    assert_eq!(cursor.index(), None);\n    cursor.move_prev();\n    cursor.move_prev();\n    assert_eq!(cursor.current(), Some(&mut 5));\n    assert_eq!(cursor.peek_next(), Some(&mut 6));\n    assert_eq!(cursor.peek_prev(), Some(&mut 4));\n    assert_eq!(cursor.index(), Some(4));\n    let mut cursor2 = cursor.as_cursor();\n    assert_eq!(cursor2.current(), Some(&5));\n    assert_eq!(cursor2.index(), Some(4));\n    cursor2.move_prev();\n    assert_eq!(cursor2.current(), Some(&4));\n    assert_eq!(cursor2.index(), Some(3));\n    assert_eq!(cursor.current(), Some(&mut 5));\n    assert_eq!(cursor.index(), Some(4));\n}\n\n#[test]\nfn test_cursor_mut_insert() {\n    let mut m: LinkedList<u32> = LinkedList::new();\n    m.extend(&[1, 2, 3, 4, 5, 6]);\n    let mut cursor = m.cursor_front_mut();\n    cursor.insert_before(7);\n    cursor.insert_after(8);\n    check_links(&m);\n    assert_eq!(m.iter().cloned().collect::<Vec<_>>(), &[7, 1, 8, 2, 3, 4, 5, 6]);\n    let mut cursor = m.cursor_front_mut();\n    cursor.move_prev();\n    cursor.insert_before(9);\n    cursor.insert_after(10);\n    check_links(&m);\n    assert_eq!(m.iter().cloned().collect::<Vec<_>>(), &[10, 7, 1, 8, 2, 3, 4, 5, 6, 9]);\n    let mut cursor = m.cursor_front_mut();\n    cursor.move_prev();\n    assert_eq!(cursor.remove_current(), None);\n    cursor.move_next();\n    cursor.move_next();\n    assert_eq!(cursor.remove_current(), Some(7));\n    cursor.move_prev();\n    cursor.move_prev();\n    cursor.move_prev();\n    assert_eq!(cursor.remove_current(), Some(9));\n    cursor.move_next();\n    assert_eq!(cursor.remove_current(), Some(10));\n    check_links(&m);\n    assert_eq!(m.iter().cloned().collect::<Vec<_>>(), &[1, 8, 2, 3, 4, 5, 6]);\n    let mut cursor = m.cursor_front_mut();\n    let mut p: LinkedList<u32> = LinkedList::new();\n    p.extend(&[100, 101, 102, 103]);\n    let mut q: LinkedList<u32> = LinkedList::new();\n    q.extend(&[200, 201, 202, 203]);\n    cursor.splice_after(p);\n    cursor.splice_before(q);\n    check_links(&m);\n    assert_eq!(\n        m.iter().cloned().collect::<Vec<_>>(),\n        &[200, 201, 202, 203, 1, 100, 101, 102, 103, 8, 2, 3, 4, 5, 6]\n    );\n    let mut cursor = m.cursor_front_mut();\n    cursor.move_prev();\n    let tmp = cursor.split_before();\n    assert_eq!(m.into_iter().collect::<Vec<_>>(), &[]);\n    m = tmp;\n    let mut cursor = m.cursor_front_mut();\n    cursor.move_next();\n    cursor.move_next();\n    cursor.move_next();\n    cursor.move_next();\n    cursor.move_next();\n    cursor.move_next();\n    let tmp = cursor.split_after();\n    assert_eq!(tmp.into_iter().collect::<Vec<_>>(), &[102, 103, 8, 2, 3, 4, 5, 6]);\n    check_links(&m);\n    assert_eq!(m.iter().cloned().collect::<Vec<_>>(), &[200, 201, 202, 203, 1, 100, 101]);\n}\n"],[2025,"//! A priority queue implemented with a binary heap.\n//!\n//! Insertion and popping the largest element have *O*(log(*n*)) time complexity.\n//! Checking the largest element is *O*(1). Converting a vector to a binary heap\n//! can be done in-place, and has *O*(*n*) complexity. A binary heap can also be\n//! converted to a sorted vector in-place, allowing it to be used for an *O*(*n* \\* log(*n*))\n//! in-place heapsort.\n//!\n//! # Examples\n//!\n//! This is a larger example that implements [Dijkstra's algorithm][dijkstra]\n//! to solve the [shortest path problem][sssp] on a [directed graph][dir_graph].\n//! It shows how to use [`BinaryHeap`] with custom types.\n//!\n//! [dijkstra]: https://en.wikipedia.org/wiki/Dijkstra%27s_algorithm\n//! [sssp]: https://en.wikipedia.org/wiki/Shortest_path_problem\n//! [dir_graph]: https://en.wikipedia.org/wiki/Directed_graph\n//!\n//! ```\n//! use std::cmp::Ordering;\n//! use std::collections::BinaryHeap;\n//!\n//! #[derive(Copy, Clone, Eq, PartialEq)]\n//! struct State {\n//!     cost: usize,\n//!     position: usize,\n//! }\n//!\n//! // The priority queue depends on `Ord`.\n//! // Explicitly implement the trait so the queue becomes a min-heap\n//! // instead of a max-heap.\n//! impl Ord for State {\n//!     fn cmp(&self, other: &Self) -> Ordering {\n//!         // Notice that the we flip the ordering on costs.\n//!         // In case of a tie we compare positions - this step is necessary\n//!         // to make implementations of `PartialEq` and `Ord` consistent.\n//!         other.cost.cmp(&self.cost)\n//!             .then_with(|| self.position.cmp(&other.position))\n//!     }\n//! }\n//!\n//! // `PartialOrd` needs to be implemented as well.\n//! impl PartialOrd for State {\n//!     fn partial_cmp(&self, other: &Self) -> Option<Ordering> {\n//!         Some(self.cmp(other))\n//!     }\n//! }\n//!\n//! // Each node is represented as an `usize`, for a shorter implementation.\n//! struct Edge {\n//!     node: usize,\n//!     cost: usize,\n//! }\n//!\n//! // Dijkstra's shortest path algorithm.\n//!\n//! // Start at `start` and use `dist` to track the current shortest distance\n//! // to each node. This implementation isn't memory-efficient as it may leave duplicate\n//! // nodes in the queue. It also uses `usize::MAX` as a sentinel value,\n//! // for a simpler implementation.\n//! fn shortest_path(adj_list: &Vec<Vec<Edge>>, start: usize, goal: usize) -> Option<usize> {\n//!     // dist[node] = current shortest distance from `start` to `node`\n//!     let mut dist: Vec<_> = (0..adj_list.len()).map(|_| usize::MAX).collect();\n//!\n//!     let mut heap = BinaryHeap::new();\n//!\n//!     // We're at `start`, with a zero cost\n//!     dist[start] = 0;\n//!     heap.push(State { cost: 0, position: start });\n//!\n//!     // Examine the frontier with lower cost nodes first (min-heap)\n//!     while let Some(State { cost, position }) = heap.pop() {\n//!         // Alternatively we could have continued to find all shortest paths\n//!         if position == goal { return Some(cost); }\n//!\n//!         // Important as we may have already found a better way\n//!         if cost > dist[position] { continue; }\n//!\n//!         // For each node we can reach, see if we can find a way with\n//!         // a lower cost going through this node\n//!         for edge in &adj_list[position] {\n//!             let next = State { cost: cost + edge.cost, position: edge.node };\n//!\n//!             // If so, add it to the frontier and continue\n//!             if next.cost < dist[next.position] {\n//!                 heap.push(next);\n//!                 // Relaxation, we have now found a better way\n//!                 dist[next.position] = next.cost;\n//!             }\n//!         }\n//!     }\n//!\n//!     // Goal not reachable\n//!     None\n//! }\n//!\n//! fn main() {\n//!     // This is the directed graph we're going to use.\n//!     // The node numbers correspond to the different states,\n//!     // and the edge weights symbolize the cost of moving\n//!     // from one node to another.\n//!     // Note that the edges are one-way.\n//!     //\n//!     //                  7\n//!     //          +-----------------+\n//!     //          |                 |\n//!     //          v   1        2    |  2\n//!     //          0 -----> 1 -----> 3 ---> 4\n//!     //          |        ^        ^      ^\n//!     //          |        | 1      |      |\n//!     //          |        |        | 3    | 1\n//!     //          +------> 2 -------+      |\n//!     //           10      |               |\n//!     //                   +---------------+\n//!     //\n//!     // The graph is represented as an adjacency list where each index,\n//!     // corresponding to a node value, has a list of outgoing edges.\n//!     // Chosen for its efficiency.\n//!     let graph = vec![\n//!         // Node 0\n//!         vec![Edge { node: 2, cost: 10 },\n//!              Edge { node: 1, cost: 1 }],\n//!         // Node 1\n//!         vec![Edge { node: 3, cost: 2 }],\n//!         // Node 2\n//!         vec![Edge { node: 1, cost: 1 },\n//!              Edge { node: 3, cost: 3 },\n//!              Edge { node: 4, cost: 1 }],\n//!         // Node 3\n//!         vec![Edge { node: 0, cost: 7 },\n//!              Edge { node: 4, cost: 2 }],\n//!         // Node 4\n//!         vec![]];\n//!\n//!     assert_eq!(shortest_path(&graph, 0, 1), Some(1));\n//!     assert_eq!(shortest_path(&graph, 0, 3), Some(3));\n//!     assert_eq!(shortest_path(&graph, 3, 0), Some(7));\n//!     assert_eq!(shortest_path(&graph, 0, 4), Some(5));\n//!     assert_eq!(shortest_path(&graph, 4, 0), None);\n//! }\n//! ```\n\n#![allow(missing_docs)]\n#![stable(feature = \"rust1\", since = \"1.0.0\")]\n\nuse core::fmt;\nuse core::iter::{FromIterator, FusedIterator, InPlaceIterable, SourceIter, TrustedLen};\nuse core::mem::{self, swap, ManuallyDrop};\nuse core::ops::{Deref, DerefMut};\nuse core::ptr;\n\nuse crate::slice;\nuse crate::vec::{self, AsIntoIter, Vec};\n\nuse super::SpecExtend;\n\n/// A priority queue implemented with a binary heap.\n///\n/// This will be a max-heap.\n///\n/// It is a logic error for an item to be modified in such a way that the\n/// item's ordering relative to any other item, as determined by the `Ord`\n/// trait, changes while it is in the heap. This is normally only possible\n/// through `Cell`, `RefCell`, global state, I/O, or unsafe code. The\n/// behavior resulting from such a logic error is not specified, but will\n/// not result in undefined behavior. This could include panics, incorrect\n/// results, aborts, memory leaks, and non-termination.\n///\n/// # Examples\n///\n/// ```\n/// use std::collections::BinaryHeap;\n///\n/// // Type inference lets us omit an explicit type signature (which\n/// // would be `BinaryHeap<i32>` in this example).\n/// let mut heap = BinaryHeap::new();\n///\n/// // We can use peek to look at the next item in the heap. In this case,\n/// // there's no items in there yet so we get None.\n/// assert_eq!(heap.peek(), None);\n///\n/// // Let's add some scores...\n/// heap.push(1);\n/// heap.push(5);\n/// heap.push(2);\n///\n/// // Now peek shows the most important item in the heap.\n/// assert_eq!(heap.peek(), Some(&5));\n///\n/// // We can check the length of a heap.\n/// assert_eq!(heap.len(), 3);\n///\n/// // We can iterate over the items in the heap, although they are returned in\n/// // a random order.\n/// for x in &heap {\n///     println!(\"{}\", x);\n/// }\n///\n/// // If we instead pop these scores, they should come back in order.\n/// assert_eq!(heap.pop(), Some(5));\n/// assert_eq!(heap.pop(), Some(2));\n/// assert_eq!(heap.pop(), Some(1));\n/// assert_eq!(heap.pop(), None);\n///\n/// // We can clear the heap of any remaining items.\n/// heap.clear();\n///\n/// // The heap should now be empty.\n/// assert!(heap.is_empty())\n/// ```\n///\n/// ## Min-heap\n///\n/// Either `std::cmp::Reverse` or a custom `Ord` implementation can be used to\n/// make `BinaryHeap` a min-heap. This makes `heap.pop()` return the smallest\n/// value instead of the greatest one.\n///\n/// ```\n/// use std::collections::BinaryHeap;\n/// use std::cmp::Reverse;\n///\n/// let mut heap = BinaryHeap::new();\n///\n/// // Wrap values in `Reverse`\n/// heap.push(Reverse(1));\n/// heap.push(Reverse(5));\n/// heap.push(Reverse(2));\n///\n/// // If we pop these scores now, they should come back in the reverse order.\n/// assert_eq!(heap.pop(), Some(Reverse(1)));\n/// assert_eq!(heap.pop(), Some(Reverse(2)));\n/// assert_eq!(heap.pop(), Some(Reverse(5)));\n/// assert_eq!(heap.pop(), None);\n/// ```\n///\n/// # Time complexity\n///\n/// | [push] | [pop]     | [peek]/[peek\\_mut] |\n/// |--------|-----------|--------------------|\n/// | O(1)~  | *O*(log(*n*)) | *O*(1)               |\n///\n/// The value for `push` is an expected cost; the method documentation gives a\n/// more detailed analysis.\n///\n/// [push]: BinaryHeap::push\n/// [pop]: BinaryHeap::pop\n/// [peek]: BinaryHeap::peek\n/// [peek\\_mut]: BinaryHeap::peek_mut\n#[stable(feature = \"rust1\", since = \"1.0.0\")]\n#[cfg_attr(not(test), rustc_diagnostic_item = \"BinaryHeap\")]\npub struct BinaryHeap<T> {\n    data: Vec<T>,\n}\n\n/// Structure wrapping a mutable reference to the greatest item on a\n/// `BinaryHeap`.\n///\n/// This `struct` is created by the [`peek_mut`] method on [`BinaryHeap`]. See\n/// its documentation for more.\n///\n/// [`peek_mut`]: BinaryHeap::peek_mut\n#[stable(feature = \"binary_heap_peek_mut\", since = \"1.12.0\")]\npub struct PeekMut<'a, T: 'a + Ord> {\n    heap: &'a mut BinaryHeap<T>,\n    sift: bool,\n}\n\n#[stable(feature = \"collection_debug\", since = \"1.17.0\")]\nimpl<T: Ord + fmt::Debug> fmt::Debug for PeekMut<'_, T> {\n    fn fmt(&self, f: &mut fmt::Formatter<'_>) -> fmt::Result {\n        f.debug_tuple(\"PeekMut\").field(&self.heap.data[0]).finish()\n    }\n}\n\n#[stable(feature = \"binary_heap_peek_mut\", since = \"1.12.0\")]\nimpl<T: Ord> Drop for PeekMut<'_, T> {\n    fn drop(&mut self) {\n        if self.sift {\n            // SAFETY: PeekMut is only instantiated for non-empty heaps.\n            unsafe { self.heap.sift_down(0) };\n        }\n    }\n}\n\n#[stable(feature = \"binary_heap_peek_mut\", since = \"1.12.0\")]\nimpl<T: Ord> Deref for PeekMut<'_, T> {\n    type Target = T;\n    fn deref(&self) -> &T {\n        debug_assert!(!self.heap.is_empty());\n        // SAFE: PeekMut is only instantiated for non-empty heaps\n        unsafe { self.heap.data.get_unchecked(0) }\n    }\n}\n\n#[stable(feature = \"binary_heap_peek_mut\", since = \"1.12.0\")]\nimpl<T: Ord> DerefMut for PeekMut<'_, T> {\n    fn deref_mut(&mut self) -> &mut T {\n        debug_assert!(!self.heap.is_empty());\n        self.sift = true;\n        // SAFE: PeekMut is only instantiated for non-empty heaps\n        unsafe { self.heap.data.get_unchecked_mut(0) }\n    }\n}\n\nimpl<'a, T: Ord> PeekMut<'a, T> {\n    /// Removes the peeked value from the heap and returns it.\n    #[stable(feature = \"binary_heap_peek_mut_pop\", since = \"1.18.0\")]\n    pub fn pop(mut this: PeekMut<'a, T>) -> T {\n        let value = this.heap.pop().unwrap();\n        this.sift = false;\n        value\n    }\n}\n\n#[stable(feature = \"rust1\", since = \"1.0.0\")]\nimpl<T: Clone> Clone for BinaryHeap<T> {\n    fn clone(&self) -> Self {\n        BinaryHeap { data: self.data.clone() }\n    }\n\n    fn clone_from(&mut self, source: &Self) {\n        self.data.clone_from(&source.data);\n    }\n}\n\n#[stable(feature = \"rust1\", since = \"1.0.0\")]\nimpl<T: Ord> Default for BinaryHeap<T> {\n    /// Creates an empty `BinaryHeap<T>`.\n    #[inline]\n    fn default() -> BinaryHeap<T> {\n        BinaryHeap::new()\n    }\n}\n\n#[stable(feature = \"binaryheap_debug\", since = \"1.4.0\")]\nimpl<T: fmt::Debug> fmt::Debug for BinaryHeap<T> {\n    fn fmt(&self, f: &mut fmt::Formatter<'_>) -> fmt::Result {\n        f.debug_list().entries(self.iter()).finish()\n    }\n}\n\nimpl<T: Ord> BinaryHeap<T> {\n    /// Creates an empty `BinaryHeap` as a max-heap.\n    ///\n    /// # Examples\n    ///\n    /// Basic usage:\n    ///\n    /// ```\n    /// use std::collections::BinaryHeap;\n    /// let mut heap = BinaryHeap::new();\n    /// heap.push(4);\n    /// ```\n    #[stable(feature = \"rust1\", since = \"1.0.0\")]\n    pub fn new() -> BinaryHeap<T> {\n        BinaryHeap { data: vec![] }\n    }\n\n    /// Creates an empty `BinaryHeap` with a specific capacity.\n    /// This preallocates enough memory for `capacity` elements,\n    /// so that the `BinaryHeap` does not have to be reallocated\n    /// until it contains at least that many values.\n    ///\n    /// # Examples\n    ///\n    /// Basic usage:\n    ///\n    /// ```\n    /// use std::collections::BinaryHeap;\n    /// let mut heap = BinaryHeap::with_capacity(10);\n    /// heap.push(4);\n    /// ```\n    #[stable(feature = \"rust1\", since = \"1.0.0\")]\n    pub fn with_capacity(capacity: usize) -> BinaryHeap<T> {\n        BinaryHeap { data: Vec::with_capacity(capacity) }\n    }\n\n    /// Returns a mutable reference to the greatest item in the binary heap, or\n    /// `None` if it is empty.\n    ///\n    /// Note: If the `PeekMut` value is leaked, the heap may be in an\n    /// inconsistent state.\n    ///\n    /// # Examples\n    ///\n    /// Basic usage:\n    ///\n    /// ```\n    /// use std::collections::BinaryHeap;\n    /// let mut heap = BinaryHeap::new();\n    /// assert!(heap.peek_mut().is_none());\n    ///\n    /// heap.push(1);\n    /// heap.push(5);\n    /// heap.push(2);\n    /// {\n    ///     let mut val = heap.peek_mut().unwrap();\n    ///     *val = 0;\n    /// }\n    /// assert_eq!(heap.peek(), Some(&2));\n    /// ```\n    ///\n    /// # Time complexity\n    ///\n    /// If the item is modified then the worst case time complexity is *O*(log(*n*)),\n    /// otherwise it's *O*(1).\n    #[stable(feature = \"binary_heap_peek_mut\", since = \"1.12.0\")]\n    pub fn peek_mut(&mut self) -> Option<PeekMut<'_, T>> {\n        if self.is_empty() { None } else { Some(PeekMut { heap: self, sift: false }) }\n    }\n\n    /// Removes the greatest item from the binary heap and returns it, or `None` if it\n    /// is empty.\n    ///\n    /// # Examples\n    ///\n    /// Basic usage:\n    ///\n    /// ```\n    /// use std::collections::BinaryHeap;\n    /// let mut heap = BinaryHeap::from(vec![1, 3]);\n    ///\n    /// assert_eq!(heap.pop(), Some(3));\n    /// assert_eq!(heap.pop(), Some(1));\n    /// assert_eq!(heap.pop(), None);\n    /// ```\n    ///\n    /// # Time complexity\n    ///\n    /// The worst case cost of `pop` on a heap containing *n* elements is *O*(log(*n*)).\n    #[stable(feature = \"rust1\", since = \"1.0.0\")]\n    pub fn pop(&mut self) -> Option<T> {\n        self.data.pop().map(|mut item| {\n            if !self.is_empty() {\n                swap(&mut item, &mut self.data[0]);\n                // SAFETY: !self.is_empty() means that self.len() > 0\n                unsafe { self.sift_down_to_bottom(0) };\n            }\n            item\n        })\n    }\n\n    /// Pushes an item onto the binary heap.\n    ///\n    /// # Examples\n    ///\n    /// Basic usage:\n    ///\n    /// ```\n    /// use std::collections::BinaryHeap;\n    /// let mut heap = BinaryHeap::new();\n    /// heap.push(3);\n    /// heap.push(5);\n    /// heap.push(1);\n    ///\n    /// assert_eq!(heap.len(), 3);\n    /// assert_eq!(heap.peek(), Some(&5));\n    /// ```\n    ///\n    /// # Time complexity\n    ///\n    /// The expected cost of `push`, averaged over every possible ordering of\n    /// the elements being pushed, and over a sufficiently large number of\n    /// pushes, is *O*(1). This is the most meaningful cost metric when pushing\n    /// elements that are *not* already in any sorted pattern.\n    ///\n    /// The time complexity degrades if elements are pushed in predominantly\n    /// ascending order. In the worst case, elements are pushed in ascending\n    /// sorted order and the amortized cost per push is *O*(log(*n*)) against a heap\n    /// containing *n* elements.\n    ///\n    /// The worst case cost of a *single* call to `push` is *O*(*n*). The worst case\n    /// occurs when capacity is exhausted and needs a resize. The resize cost\n    /// has been amortized in the previous figures.\n    #[stable(feature = \"rust1\", since = \"1.0.0\")]\n    pub fn push(&mut self, item: T) {\n        let old_len = self.len();\n        self.data.push(item);\n        // SAFETY: Since we pushed a new item it means that\n        //  old_len = self.len() - 1 < self.len()\n        unsafe { self.sift_up(0, old_len) };\n    }\n\n    /// Consumes the `BinaryHeap` and returns a vector in sorted\n    /// (ascending) order.\n    ///\n    /// # Examples\n    ///\n    /// Basic usage:\n    ///\n    /// ```\n    /// use std::collections::BinaryHeap;\n    ///\n    /// let mut heap = BinaryHeap::from(vec![1, 2, 4, 5, 7]);\n    /// heap.push(6);\n    /// heap.push(3);\n    ///\n    /// let vec = heap.into_sorted_vec();\n    /// assert_eq!(vec, [1, 2, 3, 4, 5, 6, 7]);\n    /// ```\n    #[stable(feature = \"binary_heap_extras_15\", since = \"1.5.0\")]\n    pub fn into_sorted_vec(mut self) -> Vec<T> {\n        let mut end = self.len();\n        while end > 1 {\n            end -= 1;\n            // SAFETY: `end` goes from `self.len() - 1` to 1 (both included),\n            //  so it's always a valid index to access.\n            //  It is safe to access index 0 (i.e. `ptr`), because\n            //  1 <= end < self.len(), which means self.len() >= 2.\n            unsafe {\n                let ptr = self.data.as_mut_ptr();\n                ptr::swap(ptr, ptr.add(end));\n            }\n            // SAFETY: `end` goes from `self.len() - 1` to 1 (both included) so:\n            //  0 < 1 <= end <= self.len() - 1 < self.len()\n            //  Which means 0 < end and end < self.len().\n            unsafe { self.sift_down_range(0, end) };\n        }\n        self.into_vec()\n    }\n\n    // The implementations of sift_up and sift_down use unsafe blocks in\n    // order to move an element out of the vector (leaving behind a\n    // hole), shift along the others and move the removed element back into the\n    // vector at the final location of the hole.\n    // The `Hole` type is used to represent this, and make sure\n    // the hole is filled back at the end of its scope, even on panic.\n    // Using a hole reduces the constant factor compared to using swaps,\n    // which involves twice as many moves.\n\n    /// # Safety\n    ///\n    /// The caller must guarantee that `pos < self.len()`.\n    unsafe fn sift_up(&mut self, start: usize, pos: usize) -> usize {\n        // Take out the value at `pos` and create a hole.\n        // SAFETY: The caller guarantees that pos < self.len()\n        let mut hole = unsafe { Hole::new(&mut self.data, pos) };\n\n        while hole.pos() > start {\n            let parent = (hole.pos() - 1) / 2;\n\n            // SAFETY: hole.pos() > start >= 0, which means hole.pos() > 0\n            //  and so hole.pos() - 1 can't underflow.\n            //  This guarantees that parent < hole.pos() so\n            //  it's a valid index and also != hole.pos().\n            if hole.element() <= unsafe { hole.get(parent) } {\n                break;\n            }\n\n            // SAFETY: Same as above\n            unsafe { hole.move_to(parent) };\n        }\n\n        hole.pos()\n    }\n\n    /// Take an element at `pos` and move it down the heap,\n    /// while its children are larger.\n    ///\n    /// # Safety\n    ///\n    /// The caller must guarantee that `pos < end <= self.len()`.\n    unsafe fn sift_down_range(&mut self, pos: usize, end: usize) {\n        // SAFETY: The caller guarantees that pos < end <= self.len().\n        let mut hole = unsafe { Hole::new(&mut self.data, pos) };\n        let mut child = 2 * hole.pos() + 1;\n\n        // Loop invariant: child == 2 * hole.pos() + 1.\n        while child <= end.saturating_sub(2) {\n            // compare with the greater of the two children\n            // SAFETY: child < end - 1 < self.len() and\n            //  child + 1 < end <= self.len(), so they're valid indexes.\n            //  child == 2 * hole.pos() + 1 != hole.pos() and\n            //  child + 1 == 2 * hole.pos() + 2 != hole.pos().\n            // FIXME: 2 * hole.pos() + 1 or 2 * hole.pos() + 2 could overflow\n            //  if T is a ZST\n            child += unsafe { hole.get(child) <= hole.get(child + 1) } as usize;\n\n            // if we are already in order, stop.\n            // SAFETY: child is now either the old child or the old child+1\n            //  We already proven that both are < self.len() and != hole.pos()\n            if hole.element() >= unsafe { hole.get(child) } {\n                return;\n            }\n\n            // SAFETY: same as above.\n            unsafe { hole.move_to(child) };\n            child = 2 * hole.pos() + 1;\n        }\n\n        // SAFETY: && short circuit, which means that in the\n        //  second condition it's already true that child == end - 1 < self.len().\n        if child == end - 1 && hole.element() < unsafe { hole.get(child) } {\n            // SAFETY: child is already proven to be a valid index and\n            //  child == 2 * hole.pos() + 1 != hole.pos().\n            unsafe { hole.move_to(child) };\n        }\n    }\n\n    /// # Safety\n    ///\n    /// The caller must guarantee that `pos < self.len()`.\n    unsafe fn sift_down(&mut self, pos: usize) {\n        let len = self.len();\n        // SAFETY: pos < len is guaranteed by the caller and\n        //  obviously len = self.len() <= self.len().\n        unsafe { self.sift_down_range(pos, len) };\n    }\n\n    /// Take an element at `pos` and move it all the way down the heap,\n    /// then sift it up to its position.\n    ///\n    /// Note: This is faster when the element is known to be large / should\n    /// be closer to the bottom.\n    ///\n    /// # Safety\n    ///\n    /// The caller must guarantee that `pos < self.len()`.\n    unsafe fn sift_down_to_bottom(&mut self, mut pos: usize) {\n        let end = self.len();\n        let start = pos;\n\n        // SAFETY: The caller guarantees that pos < self.len().\n        let mut hole = unsafe { Hole::new(&mut self.data, pos) };\n        let mut child = 2 * hole.pos() + 1;\n\n        // Loop invariant: child == 2 * hole.pos() + 1.\n        while child <= end.saturating_sub(2) {\n            // SAFETY: child < end - 1 < self.len() and\n            //  child + 1 < end <= self.len(), so they're valid indexes.\n            //  child == 2 * hole.pos() + 1 != hole.pos() and\n            //  child + 1 == 2 * hole.pos() + 2 != hole.pos().\n            // FIXME: 2 * hole.pos() + 1 or 2 * hole.pos() + 2 could overflow\n            //  if T is a ZST\n            child += unsafe { hole.get(child) <= hole.get(child + 1) } as usize;\n\n            // SAFETY: Same as above\n            unsafe { hole.move_to(child) };\n            child = 2 * hole.pos() + 1;\n        }\n\n        if child == end - 1 {\n            // SAFETY: child == end - 1 < self.len(), so it's a valid index\n            //  and child == 2 * hole.pos() + 1 != hole.pos().\n            unsafe { hole.move_to(child) };\n        }\n        pos = hole.pos();\n        drop(hole);\n\n        // SAFETY: pos is the position in the hole and was already proven\n        //  to be a valid index.\n        unsafe { self.sift_up(start, pos) };\n    }\n\n    /// Rebuild assuming data[0..start] is still a proper heap.\n    fn rebuild_tail(&mut self, start: usize) {\n        if start == self.len() {\n            return;\n        }\n\n        let tail_len = self.len() - start;\n\n        #[inline(always)]\n        fn log2_fast(x: usize) -> usize {\n            (usize::BITS - x.leading_zeros() - 1) as usize\n        }\n\n        // `rebuild` takes O(self.len()) operations\n        // and about 2 * self.len() comparisons in the worst case\n        // while repeating `sift_up` takes O(tail_len * log(start)) operations\n        // and about 1 * tail_len * log_2(start) comparisons in the worst case,\n        // assuming start >= tail_len. For larger heaps, the crossover point\n        // no longer follows this reasoning and was determined empirically.\n        let better_to_rebuild = if start < tail_len {\n            true\n        } else if self.len() <= 2048 {\n            2 * self.len() < tail_len * log2_fast(start)\n        } else {\n            2 * self.len() < tail_len * 11\n        };\n\n        if better_to_rebuild {\n            self.rebuild();\n        } else {\n            for i in start..self.len() {\n                // SAFETY: The index `i` is always less than self.len().\n                unsafe { self.sift_up(0, i) };\n            }\n        }\n    }\n\n    fn rebuild(&mut self) {\n        let mut n = self.len() / 2;\n        while n > 0 {\n            n -= 1;\n            // SAFETY: n starts from self.len() / 2 and goes down to 0.\n            //  The only case when !(n < self.len()) is if\n            //  self.len() == 0, but it's ruled out by the loop condition.\n            unsafe { self.sift_down(n) };\n        }\n    }\n\n    /// Moves all the elements of `other` into `self`, leaving `other` empty.\n    ///\n    /// # Examples\n    ///\n    /// Basic usage:\n    ///\n    /// ```\n    /// use std::collections::BinaryHeap;\n    ///\n    /// let v = vec![-10, 1, 2, 3, 3];\n    /// let mut a = BinaryHeap::from(v);\n    ///\n    /// let v = vec![-20, 5, 43];\n    /// let mut b = BinaryHeap::from(v);\n    ///\n    /// a.append(&mut b);\n    ///\n    /// assert_eq!(a.into_sorted_vec(), [-20, -10, 1, 2, 3, 3, 5, 43]);\n    /// assert!(b.is_empty());\n    /// ```\n    #[stable(feature = \"binary_heap_append\", since = \"1.11.0\")]\n    pub fn append(&mut self, other: &mut Self) {\n        if self.len() < other.len() {\n            swap(self, other);\n        }\n\n        let start = self.data.len();\n\n        self.data.append(&mut other.data);\n\n        self.rebuild_tail(start);\n    }\n\n    /// Returns an iterator which retrieves elements in heap order.\n    /// The retrieved elements are removed from the original heap.\n    /// The remaining elements will be removed on drop in heap order.\n    ///\n    /// Note:\n    /// * `.drain_sorted()` is *O*(*n* \\* log(*n*)); much slower than `.drain()`.\n    ///   You should use the latter for most cases.\n    ///\n    /// # Examples\n    ///\n    /// Basic usage:\n    ///\n    /// ```\n    /// #![feature(binary_heap_drain_sorted)]\n    /// use std::collections::BinaryHeap;\n    ///\n    /// let mut heap = BinaryHeap::from(vec![1, 2, 3, 4, 5]);\n    /// assert_eq!(heap.len(), 5);\n    ///\n    /// drop(heap.drain_sorted()); // removes all elements in heap order\n    /// assert_eq!(heap.len(), 0);\n    /// ```\n    #[inline]\n    #[unstable(feature = \"binary_heap_drain_sorted\", issue = \"59278\")]\n    pub fn drain_sorted(&mut self) -> DrainSorted<'_, T> {\n        DrainSorted { inner: self }\n    }\n\n    /// Retains only the elements specified by the predicate.\n    ///\n    /// In other words, remove all elements `e` such that `f(&e)` returns\n    /// `false`. The elements are visited in unsorted (and unspecified) order.\n    ///\n    /// # Examples\n    ///\n    /// Basic usage:\n    ///\n    /// ```\n    /// #![feature(binary_heap_retain)]\n    /// use std::collections::BinaryHeap;\n    ///\n    /// let mut heap = BinaryHeap::from(vec![-10, -5, 1, 2, 4, 13]);\n    ///\n    /// heap.retain(|x| x % 2 == 0); // only keep even numbers\n    ///\n    /// assert_eq!(heap.into_sorted_vec(), [-10, 2, 4])\n    /// ```\n    #[unstable(feature = \"binary_heap_retain\", issue = \"71503\")]\n    pub fn retain<F>(&mut self, mut f: F)\n    where\n        F: FnMut(&T) -> bool,\n    {\n        let mut first_removed = self.len();\n        let mut i = 0;\n        self.data.retain(|e| {\n            let keep = f(e);\n            if !keep && i < first_removed {\n                first_removed = i;\n            }\n            i += 1;\n            keep\n        });\n        // data[0..first_removed] is untouched, so we only need to rebuild the tail:\n        self.rebuild_tail(first_removed);\n    }\n}\n\nimpl<T> BinaryHeap<T> {\n    /// Returns an iterator visiting all values in the underlying vector, in\n    /// arbitrary order.\n    ///\n    /// # Examples\n    ///\n    /// Basic usage:\n    ///\n    /// ```\n    /// use std::collections::BinaryHeap;\n    /// let heap = BinaryHeap::from(vec![1, 2, 3, 4]);\n    ///\n    /// // Print 1, 2, 3, 4 in arbitrary order\n    /// for x in heap.iter() {\n    ///     println!(\"{}\", x);\n    /// }\n    /// ```\n    #[stable(feature = \"rust1\", since = \"1.0.0\")]\n    pub fn iter(&self) -> Iter<'_, T> {\n        Iter { iter: self.data.iter() }\n    }\n\n    /// Returns an iterator which retrieves elements in heap order.\n    /// This method consumes the original heap.\n    ///\n    /// # Examples\n    ///\n    /// Basic usage:\n    ///\n    /// ```\n    /// #![feature(binary_heap_into_iter_sorted)]\n    /// use std::collections::BinaryHeap;\n    /// let heap = BinaryHeap::from(vec![1, 2, 3, 4, 5]);\n    ///\n    /// assert_eq!(heap.into_iter_sorted().take(2).collect::<Vec<_>>(), vec![5, 4]);\n    /// ```\n    #[unstable(feature = \"binary_heap_into_iter_sorted\", issue = \"59278\")]\n    pub fn into_iter_sorted(self) -> IntoIterSorted<T> {\n        IntoIterSorted { inner: self }\n    }\n\n    /// Returns the greatest item in the binary heap, or `None` if it is empty.\n    ///\n    /// # Examples\n    ///\n    /// Basic usage:\n    ///\n    /// ```\n    /// use std::collections::BinaryHeap;\n    /// let mut heap = BinaryHeap::new();\n    /// assert_eq!(heap.peek(), None);\n    ///\n    /// heap.push(1);\n    /// heap.push(5);\n    /// heap.push(2);\n    /// assert_eq!(heap.peek(), Some(&5));\n    ///\n    /// ```\n    ///\n    /// # Time complexity\n    ///\n    /// Cost is *O*(1) in the worst case.\n    #[stable(feature = \"rust1\", since = \"1.0.0\")]\n    pub fn peek(&self) -> Option<&T> {\n        self.data.get(0)\n    }\n\n    /// Returns the number of elements the binary heap can hold without reallocating.\n    ///\n    /// # Examples\n    ///\n    /// Basic usage:\n    ///\n    /// ```\n    /// use std::collections::BinaryHeap;\n    /// let mut heap = BinaryHeap::with_capacity(100);\n    /// assert!(heap.capacity() >= 100);\n    /// heap.push(4);\n    /// ```\n    #[stable(feature = \"rust1\", since = \"1.0.0\")]\n    pub fn capacity(&self) -> usize {\n        self.data.capacity()\n    }\n\n    /// Reserves the minimum capacity for exactly `additional` more elements to be inserted in the\n    /// given `BinaryHeap`. Does nothing if the capacity is already sufficient.\n    ///\n    /// Note that the allocator may give the collection more space than it requests. Therefore\n    /// capacity can not be relied upon to be precisely minimal. Prefer [`reserve`] if future\n    /// insertions are expected.\n    ///\n    /// # Panics\n    ///\n    /// Panics if the new capacity overflows `usize`.\n    ///\n    /// # Examples\n    ///\n    /// Basic usage:\n    ///\n    /// ```\n    /// use std::collections::BinaryHeap;\n    /// let mut heap = BinaryHeap::new();\n    /// heap.reserve_exact(100);\n    /// assert!(heap.capacity() >= 100);\n    /// heap.push(4);\n    /// ```\n    ///\n    /// [`reserve`]: BinaryHeap::reserve\n    #[stable(feature = \"rust1\", since = \"1.0.0\")]\n    pub fn reserve_exact(&mut self, additional: usize) {\n        self.data.reserve_exact(additional);\n    }\n\n    /// Reserves capacity for at least `additional` more elements to be inserted in the\n    /// `BinaryHeap`. The collection may reserve more space to avoid frequent reallocations.\n    ///\n    /// # Panics\n    ///\n    /// Panics if the new capacity overflows `usize`.\n    ///\n    /// # Examples\n    ///\n    /// Basic usage:\n    ///\n    /// ```\n    /// use std::collections::BinaryHeap;\n    /// let mut heap = BinaryHeap::new();\n    /// heap.reserve(100);\n    /// assert!(heap.capacity() >= 100);\n    /// heap.push(4);\n    /// ```\n    #[stable(feature = \"rust1\", since = \"1.0.0\")]\n    pub fn reserve(&mut self, additional: usize) {\n        self.data.reserve(additional);\n    }\n\n    /// Discards as much additional capacity as possible.\n    ///\n    /// # Examples\n    ///\n    /// Basic usage:\n    ///\n    /// ```\n    /// use std::collections::BinaryHeap;\n    /// let mut heap: BinaryHeap<i32> = BinaryHeap::with_capacity(100);\n    ///\n    /// assert!(heap.capacity() >= 100);\n    /// heap.shrink_to_fit();\n    /// assert!(heap.capacity() == 0);\n    /// ```\n    #[stable(feature = \"rust1\", since = \"1.0.0\")]\n    pub fn shrink_to_fit(&mut self) {\n        self.data.shrink_to_fit();\n    }\n\n    /// Discards capacity with a lower bound.\n    ///\n    /// The capacity will remain at least as large as both the length\n    /// and the supplied value.\n    ///\n    /// If the current capacity is less than the lower limit, this is a no-op.\n    ///\n    /// # Examples\n    ///\n    /// ```\n    /// #![feature(shrink_to)]\n    /// use std::collections::BinaryHeap;\n    /// let mut heap: BinaryHeap<i32> = BinaryHeap::with_capacity(100);\n    ///\n    /// assert!(heap.capacity() >= 100);\n    /// heap.shrink_to(10);\n    /// assert!(heap.capacity() >= 10);\n    /// ```\n    #[inline]\n    #[unstable(feature = \"shrink_to\", reason = \"new API\", issue = \"56431\")]\n    pub fn shrink_to(&mut self, min_capacity: usize) {\n        self.data.shrink_to(min_capacity)\n    }\n\n    /// Returns a slice of all values in the underlying vector, in arbitrary\n    /// order.\n    ///\n    /// # Examples\n    ///\n    /// Basic usage:\n    ///\n    /// ```\n    /// #![feature(binary_heap_as_slice)]\n    /// use std::collections::BinaryHeap;\n    /// use std::io::{self, Write};\n    ///\n    /// let heap = BinaryHeap::from(vec![1, 2, 3, 4, 5, 6, 7]);\n    ///\n    /// io::sink().write(heap.as_slice()).unwrap();\n    /// ```\n    #[unstable(feature = \"binary_heap_as_slice\", issue = \"83659\")]\n    pub fn as_slice(&self) -> &[T] {\n        self.data.as_slice()\n    }\n\n    /// Consumes the `BinaryHeap` and returns the underlying vector\n    /// in arbitrary order.\n    ///\n    /// # Examples\n    ///\n    /// Basic usage:\n    ///\n    /// ```\n    /// use std::collections::BinaryHeap;\n    /// let heap = BinaryHeap::from(vec![1, 2, 3, 4, 5, 6, 7]);\n    /// let vec = heap.into_vec();\n    ///\n    /// // Will print in some order\n    /// for x in vec {\n    ///     println!(\"{}\", x);\n    /// }\n    /// ```\n    #[stable(feature = \"binary_heap_extras_15\", since = \"1.5.0\")]\n    pub fn into_vec(self) -> Vec<T> {\n        self.into()\n    }\n\n    /// Returns the length of the binary heap.\n    ///\n    /// # Examples\n    ///\n    /// Basic usage:\n    ///\n    /// ```\n    /// use std::collections::BinaryHeap;\n    /// let heap = BinaryHeap::from(vec![1, 3]);\n    ///\n    /// assert_eq!(heap.len(), 2);\n    /// ```\n    #[doc(alias = \"length\")]\n    #[stable(feature = \"rust1\", since = \"1.0.0\")]\n    pub fn len(&self) -> usize {\n        self.data.len()\n    }\n\n    /// Checks if the binary heap is empty.\n    ///\n    /// # Examples\n    ///\n    /// Basic usage:\n    ///\n    /// ```\n    /// use std::collections::BinaryHeap;\n    /// let mut heap = BinaryHeap::new();\n    ///\n    /// assert!(heap.is_empty());\n    ///\n    /// heap.push(3);\n    /// heap.push(5);\n    /// heap.push(1);\n    ///\n    /// assert!(!heap.is_empty());\n    /// ```\n    #[stable(feature = \"rust1\", since = \"1.0.0\")]\n    pub fn is_empty(&self) -> bool {\n        self.len() == 0\n    }\n\n    /// Clears the binary heap, returning an iterator over the removed elements.\n    ///\n    /// The elements are removed in arbitrary order.\n    ///\n    /// # Examples\n    ///\n    /// Basic usage:\n    ///\n    /// ```\n    /// use std::collections::BinaryHeap;\n    /// let mut heap = BinaryHeap::from(vec![1, 3]);\n    ///\n    /// assert!(!heap.is_empty());\n    ///\n    /// for x in heap.drain() {\n    ///     println!(\"{}\", x);\n    /// }\n    ///\n    /// assert!(heap.is_empty());\n    /// ```\n    #[inline]\n    #[stable(feature = \"drain\", since = \"1.6.0\")]\n    pub fn drain(&mut self) -> Drain<'_, T> {\n        Drain { iter: self.data.drain(..) }\n    }\n\n    /// Drops all items from the binary heap.\n    ///\n    /// # Examples\n    ///\n    /// Basic usage:\n    ///\n    /// ```\n    /// use std::collections::BinaryHeap;\n    /// let mut heap = BinaryHeap::from(vec![1, 3]);\n    ///\n    /// assert!(!heap.is_empty());\n    ///\n    /// heap.clear();\n    ///\n    /// assert!(heap.is_empty());\n    /// ```\n    #[stable(feature = \"rust1\", since = \"1.0.0\")]\n    pub fn clear(&mut self) {\n        self.drain();\n    }\n}\n\n/// Hole represents a hole in a slice i.e., an index without valid value\n/// (because it was moved from or duplicated).\n/// In drop, `Hole` will restore the slice by filling the hole\n/// position with the value that was originally removed.\nstruct Hole<'a, T: 'a> {\n    data: &'a mut [T],\n    elt: ManuallyDrop<T>,\n    pos: usize,\n}\n\nimpl<'a, T> Hole<'a, T> {\n    /// Create a new `Hole` at index `pos`.\n    ///\n    /// Unsafe because pos must be within the data slice.\n    #[inline]\n    unsafe fn new(data: &'a mut [T], pos: usize) -> Self {\n        debug_assert!(pos < data.len());\n        // SAFE: pos should be inside the slice\n        let elt = unsafe { ptr::read(data.get_unchecked(pos)) };\n        Hole { data, elt: ManuallyDrop::new(elt), pos }\n    }\n\n    #[inline]\n    fn pos(&self) -> usize {\n        self.pos\n    }\n\n    /// Returns a reference to the element removed.\n    #[inline]\n    fn element(&self) -> &T {\n        &self.elt\n    }\n\n    /// Returns a reference to the element at `index`.\n    ///\n    /// Unsafe because index must be within the data slice and not equal to pos.\n    #[inline]\n    unsafe fn get(&self, index: usize) -> &T {\n        debug_assert!(index != self.pos);\n        debug_assert!(index < self.data.len());\n        unsafe { self.data.get_unchecked(index) }\n    }\n\n    /// Move hole to new location\n    ///\n    /// Unsafe because index must be within the data slice and not equal to pos.\n    #[inline]\n    unsafe fn move_to(&mut self, index: usize) {\n        debug_assert!(index != self.pos);\n        debug_assert!(index < self.data.len());\n        unsafe {\n            let ptr = self.data.as_mut_ptr();\n            let index_ptr: *const _ = ptr.add(index);\n            let hole_ptr = ptr.add(self.pos);\n            ptr::copy_nonoverlapping(index_ptr, hole_ptr, 1);\n        }\n        self.pos = index;\n    }\n}\n\nimpl<T> Drop for Hole<'_, T> {\n    #[inline]\n    fn drop(&mut self) {\n        // fill the hole again\n        unsafe {\n            let pos = self.pos;\n            ptr::copy_nonoverlapping(&*self.elt, self.data.get_unchecked_mut(pos), 1);\n        }\n    }\n}\n\n/// An iterator over the elements of a `BinaryHeap`.\n///\n/// This `struct` is created by [`BinaryHeap::iter()`]. See its\n/// documentation for more.\n///\n/// [`iter`]: BinaryHeap::iter\n#[stable(feature = \"rust1\", since = \"1.0.0\")]\npub struct Iter<'a, T: 'a> {\n    iter: slice::Iter<'a, T>,\n}\n\n#[stable(feature = \"collection_debug\", since = \"1.17.0\")]\nimpl<T: fmt::Debug> fmt::Debug for Iter<'_, T> {\n    fn fmt(&self, f: &mut fmt::Formatter<'_>) -> fmt::Result {\n        f.debug_tuple(\"Iter\").field(&self.iter.as_slice()).finish()\n    }\n}\n\n// FIXME(#26925) Remove in favor of `#[derive(Clone)]`\n#[stable(feature = \"rust1\", since = \"1.0.0\")]\nimpl<T> Clone for Iter<'_, T> {\n    fn clone(&self) -> Self {\n        Iter { iter: self.iter.clone() }\n    }\n}\n\n#[stable(feature = \"rust1\", since = \"1.0.0\")]\nimpl<'a, T> Iterator for Iter<'a, T> {\n    type Item = &'a T;\n\n    #[inline]\n    fn next(&mut self) -> Option<&'a T> {\n        self.iter.next()\n    }\n\n    #[inline]\n    fn size_hint(&self) -> (usize, Option<usize>) {\n        self.iter.size_hint()\n    }\n\n    #[inline]\n    fn last(self) -> Option<&'a T> {\n        self.iter.last()\n    }\n}\n\n#[stable(feature = \"rust1\", since = \"1.0.0\")]\nimpl<'a, T> DoubleEndedIterator for Iter<'a, T> {\n    #[inline]\n    fn next_back(&mut self) -> Option<&'a T> {\n        self.iter.next_back()\n    }\n}\n\n#[stable(feature = \"rust1\", since = \"1.0.0\")]\nimpl<T> ExactSizeIterator for Iter<'_, T> {\n    fn is_empty(&self) -> bool {\n        self.iter.is_empty()\n    }\n}\n\n#[stable(feature = \"fused\", since = \"1.26.0\")]\nimpl<T> FusedIterator for Iter<'_, T> {}\n\n/// An owning iterator over the elements of a `BinaryHeap`.\n///\n/// This `struct` is created by [`BinaryHeap::into_iter()`]\n/// (provided by the `IntoIterator` trait). See its documentation for more.\n///\n/// [`into_iter`]: BinaryHeap::into_iter\n#[stable(feature = \"rust1\", since = \"1.0.0\")]\n#[derive(Clone)]\npub struct IntoIter<T> {\n    iter: vec::IntoIter<T>,\n}\n\n#[stable(feature = \"collection_debug\", since = \"1.17.0\")]\nimpl<T: fmt::Debug> fmt::Debug for IntoIter<T> {\n    fn fmt(&self, f: &mut fmt::Formatter<'_>) -> fmt::Result {\n        f.debug_tuple(\"IntoIter\").field(&self.iter.as_slice()).finish()\n    }\n}\n\n#[stable(feature = \"rust1\", since = \"1.0.0\")]\nimpl<T> Iterator for IntoIter<T> {\n    type Item = T;\n\n    #[inline]\n    fn next(&mut self) -> Option<T> {\n        self.iter.next()\n    }\n\n    #[inline]\n    fn size_hint(&self) -> (usize, Option<usize>) {\n        self.iter.size_hint()\n    }\n}\n\n#[stable(feature = \"rust1\", since = \"1.0.0\")]\nimpl<T> DoubleEndedIterator for IntoIter<T> {\n    #[inline]\n    fn next_back(&mut self) -> Option<T> {\n        self.iter.next_back()\n    }\n}\n\n#[stable(feature = \"rust1\", since = \"1.0.0\")]\nimpl<T> ExactSizeIterator for IntoIter<T> {\n    fn is_empty(&self) -> bool {\n        self.iter.is_empty()\n    }\n}\n\n#[stable(feature = \"fused\", since = \"1.26.0\")]\nimpl<T> FusedIterator for IntoIter<T> {}\n\n#[unstable(issue = \"none\", feature = \"inplace_iteration\")]\n#[doc(hidden)]\nunsafe impl<T> SourceIter for IntoIter<T> {\n    type Source = IntoIter<T>;\n\n    #[inline]\n    unsafe fn as_inner(&mut self) -> &mut Self::Source {\n        self\n    }\n}\n\n#[unstable(issue = \"none\", feature = \"inplace_iteration\")]\n#[doc(hidden)]\nunsafe impl<I> InPlaceIterable for IntoIter<I> {}\n\nimpl<I> AsIntoIter for IntoIter<I> {\n    type Item = I;\n\n    fn as_into_iter(&mut self) -> &mut vec::IntoIter<Self::Item> {\n        &mut self.iter\n    }\n}\n\n#[unstable(feature = \"binary_heap_into_iter_sorted\", issue = \"59278\")]\n#[derive(Clone, Debug)]\npub struct IntoIterSorted<T> {\n    inner: BinaryHeap<T>,\n}\n\n#[unstable(feature = \"binary_heap_into_iter_sorted\", issue = \"59278\")]\nimpl<T: Ord> Iterator for IntoIterSorted<T> {\n    type Item = T;\n\n    #[inline]\n    fn next(&mut self) -> Option<T> {\n        self.inner.pop()\n    }\n\n    #[inline]\n    fn size_hint(&self) -> (usize, Option<usize>) {\n        let exact = self.inner.len();\n        (exact, Some(exact))\n    }\n}\n\n#[unstable(feature = \"binary_heap_into_iter_sorted\", issue = \"59278\")]\nimpl<T: Ord> ExactSizeIterator for IntoIterSorted<T> {}\n\n#[unstable(feature = \"binary_heap_into_iter_sorted\", issue = \"59278\")]\nimpl<T: Ord> FusedIterator for IntoIterSorted<T> {}\n\n#[unstable(feature = \"trusted_len\", issue = \"37572\")]\nunsafe impl<T: Ord> TrustedLen for IntoIterSorted<T> {}\n\n/// A draining iterator over the elements of a `BinaryHeap`.\n///\n/// This `struct` is created by [`BinaryHeap::drain()`]. See its\n/// documentation for more.\n///\n/// [`drain`]: BinaryHeap::drain\n#[stable(feature = \"drain\", since = \"1.6.0\")]\n#[derive(Debug)]\npub struct Drain<'a, T: 'a> {\n    iter: vec::Drain<'a, T>,\n}\n\n#[stable(feature = \"drain\", since = \"1.6.0\")]\nimpl<T> Iterator for Drain<'_, T> {\n    type Item = T;\n\n    #[inline]\n    fn next(&mut self) -> Option<T> {\n        self.iter.next()\n    }\n\n    #[inline]\n    fn size_hint(&self) -> (usize, Option<usize>) {\n        self.iter.size_hint()\n    }\n}\n\n#[stable(feature = \"drain\", since = \"1.6.0\")]\nimpl<T> DoubleEndedIterator for Drain<'_, T> {\n    #[inline]\n    fn next_back(&mut self) -> Option<T> {\n        self.iter.next_back()\n    }\n}\n\n#[stable(feature = \"drain\", since = \"1.6.0\")]\nimpl<T> ExactSizeIterator for Drain<'_, T> {\n    fn is_empty(&self) -> bool {\n        self.iter.is_empty()\n    }\n}\n\n#[stable(feature = \"fused\", since = \"1.26.0\")]\nimpl<T> FusedIterator for Drain<'_, T> {}\n\n/// A draining iterator over the elements of a `BinaryHeap`.\n///\n/// This `struct` is created by [`BinaryHeap::drain_sorted()`]. See its\n/// documentation for more.\n///\n/// [`drain_sorted`]: BinaryHeap::drain_sorted\n#[unstable(feature = \"binary_heap_drain_sorted\", issue = \"59278\")]\n#[derive(Debug)]\npub struct DrainSorted<'a, T: Ord> {\n    inner: &'a mut BinaryHeap<T>,\n}\n\n#[unstable(feature = \"binary_heap_drain_sorted\", issue = \"59278\")]\nimpl<'a, T: Ord> Drop for DrainSorted<'a, T> {\n    /// Removes heap elements in heap order.\n    fn drop(&mut self) {\n        struct DropGuard<'r, 'a, T: Ord>(&'r mut DrainSorted<'a, T>);\n\n        impl<'r, 'a, T: Ord> Drop for DropGuard<'r, 'a, T> {\n            fn drop(&mut self) {\n                while self.0.inner.pop().is_some() {}\n            }\n        }\n\n        while let Some(item) = self.inner.pop() {\n            let guard = DropGuard(self);\n            drop(item);\n            mem::forget(guard);\n        }\n    }\n}\n\n#[unstable(feature = \"binary_heap_drain_sorted\", issue = \"59278\")]\nimpl<T: Ord> Iterator for DrainSorted<'_, T> {\n    type Item = T;\n\n    #[inline]\n    fn next(&mut self) -> Option<T> {\n        self.inner.pop()\n    }\n\n    #[inline]\n    fn size_hint(&self) -> (usize, Option<usize>) {\n        let exact = self.inner.len();\n        (exact, Some(exact))\n    }\n}\n\n#[unstable(feature = \"binary_heap_drain_sorted\", issue = \"59278\")]\nimpl<T: Ord> ExactSizeIterator for DrainSorted<'_, T> {}\n\n#[unstable(feature = \"binary_heap_drain_sorted\", issue = \"59278\")]\nimpl<T: Ord> FusedIterator for DrainSorted<'_, T> {}\n\n#[unstable(feature = \"trusted_len\", issue = \"37572\")]\nunsafe impl<T: Ord> TrustedLen for DrainSorted<'_, T> {}\n\n#[stable(feature = \"binary_heap_extras_15\", since = \"1.5.0\")]\nimpl<T: Ord> From<Vec<T>> for BinaryHeap<T> {\n    /// Converts a `Vec<T>` into a `BinaryHeap<T>`.\n    ///\n    /// This conversion happens in-place, and has *O*(*n*) time complexity.\n    fn from(vec: Vec<T>) -> BinaryHeap<T> {\n        let mut heap = BinaryHeap { data: vec };\n        heap.rebuild();\n        heap\n    }\n}\n\n#[stable(feature = \"binary_heap_extras_15\", since = \"1.5.0\")]\nimpl<T> From<BinaryHeap<T>> for Vec<T> {\n    /// Converts a `BinaryHeap<T>` into a `Vec<T>`.\n    ///\n    /// This conversion requires no data movement or allocation, and has\n    /// constant time complexity.\n    fn from(heap: BinaryHeap<T>) -> Vec<T> {\n        heap.data\n    }\n}\n\n#[stable(feature = \"rust1\", since = \"1.0.0\")]\nimpl<T: Ord> FromIterator<T> for BinaryHeap<T> {\n    fn from_iter<I: IntoIterator<Item = T>>(iter: I) -> BinaryHeap<T> {\n        BinaryHeap::from(iter.into_iter().collect::<Vec<_>>())\n    }\n}\n\n#[stable(feature = \"rust1\", since = \"1.0.0\")]\nimpl<T> IntoIterator for BinaryHeap<T> {\n    type Item = T;\n    type IntoIter = IntoIter<T>;\n\n    /// Creates a consuming iterator, that is, one that moves each value out of\n    /// the binary heap in arbitrary order. The binary heap cannot be used\n    /// after calling this.\n    ///\n    /// # Examples\n    ///\n    /// Basic usage:\n    ///\n    /// ```\n    /// use std::collections::BinaryHeap;\n    /// let heap = BinaryHeap::from(vec![1, 2, 3, 4]);\n    ///\n    /// // Print 1, 2, 3, 4 in arbitrary order\n    /// for x in heap.into_iter() {\n    ///     // x has type i32, not &i32\n    ///     println!(\"{}\", x);\n    /// }\n    /// ```\n    fn into_iter(self) -> IntoIter<T> {\n        IntoIter { iter: self.data.into_iter() }\n    }\n}\n\n#[stable(feature = \"rust1\", since = \"1.0.0\")]\nimpl<'a, T> IntoIterator for &'a BinaryHeap<T> {\n    type Item = &'a T;\n    type IntoIter = Iter<'a, T>;\n\n    fn into_iter(self) -> Iter<'a, T> {\n        self.iter()\n    }\n}\n\n#[stable(feature = \"rust1\", since = \"1.0.0\")]\nimpl<T: Ord> Extend<T> for BinaryHeap<T> {\n    #[inline]\n    fn extend<I: IntoIterator<Item = T>>(&mut self, iter: I) {\n        <Self as SpecExtend<I>>::spec_extend(self, iter);\n    }\n\n    #[inline]\n    fn extend_one(&mut self, item: T) {\n        self.push(item);\n    }\n\n    #[inline]\n    fn extend_reserve(&mut self, additional: usize) {\n        self.reserve(additional);\n    }\n}\n\nimpl<T: Ord, I: IntoIterator<Item = T>> SpecExtend<I> for BinaryHeap<T> {\n    default fn spec_extend(&mut self, iter: I) {\n        self.extend_desugared(iter.into_iter());\n    }\n}\n\nimpl<T: Ord> SpecExtend<BinaryHeap<T>> for BinaryHeap<T> {\n    fn spec_extend(&mut self, ref mut other: BinaryHeap<T>) {\n        self.append(other);\n    }\n}\n\nimpl<T: Ord> BinaryHeap<T> {\n    fn extend_desugared<I: IntoIterator<Item = T>>(&mut self, iter: I) {\n        let iterator = iter.into_iter();\n        let (lower, _) = iterator.size_hint();\n\n        self.reserve(lower);\n\n        iterator.for_each(move |elem| self.push(elem));\n    }\n}\n\n#[stable(feature = \"extend_ref\", since = \"1.2.0\")]\nimpl<'a, T: 'a + Ord + Copy> Extend<&'a T> for BinaryHeap<T> {\n    fn extend<I: IntoIterator<Item = &'a T>>(&mut self, iter: I) {\n        self.extend(iter.into_iter().cloned());\n    }\n\n    #[inline]\n    fn extend_one(&mut self, &item: &'a T) {\n        self.push(item);\n    }\n\n    #[inline]\n    fn extend_reserve(&mut self, additional: usize) {\n        self.reserve(additional);\n    }\n}\n"],[2026,"use super::merge_iter::MergeIterInner;\nuse super::node::{self, Root};\nuse core::iter::FusedIterator;\n\nimpl<K, V> Root<K, V> {\n    /// Appends all key-value pairs from the union of two ascending iterators,\n    /// incrementing a `length` variable along the way. The latter makes it\n    /// easier for the caller to avoid a leak when a drop handler panicks.\n    ///\n    /// If both iterators produce the same key, this method drops the pair from\n    /// the left iterator and appends the pair from the right iterator.\n    ///\n    /// If you want the tree to end up in a strictly ascending order, like for\n    /// a `BTreeMap`, both iterators should produce keys in strictly ascending\n    /// order, each greater than all keys in the tree, including any keys\n    /// already in the tree upon entry.\n    pub fn append_from_sorted_iters<I>(&mut self, left: I, right: I, length: &mut usize)\n    where\n        K: Ord,\n        I: Iterator<Item = (K, V)> + FusedIterator,\n    {\n        // We prepare to merge `left` and `right` into a sorted sequence in linear time.\n        let iter = MergeIter(MergeIterInner::new(left, right));\n\n        // Meanwhile, we build a tree from the sorted sequence in linear time.\n        self.bulk_push(iter, length)\n    }\n\n    /// Pushes all key-value pairs to the end of the tree, incrementing a\n    /// `length` variable along the way. The latter makes it easier for the\n    /// caller to avoid a leak when the iterator panicks.\n    pub fn bulk_push<I>(&mut self, iter: I, length: &mut usize)\n    where\n        I: Iterator<Item = (K, V)>,\n    {\n        let mut cur_node = self.borrow_mut().last_leaf_edge().into_node();\n        // Iterate through all key-value pairs, pushing them into nodes at the right level.\n        for (key, value) in iter {\n            // Try to push key-value pair into the current leaf node.\n            if cur_node.len() < node::CAPACITY {\n                cur_node.push(key, value);\n            } else {\n                // No space left, go up and push there.\n                let mut open_node;\n                let mut test_node = cur_node.forget_type();\n                loop {\n                    match test_node.ascend() {\n                        Ok(parent) => {\n                            let parent = parent.into_node();\n                            if parent.len() < node::CAPACITY {\n                                // Found a node with space left, push here.\n                                open_node = parent;\n                                break;\n                            } else {\n                                // Go up again.\n                                test_node = parent.forget_type();\n                            }\n                        }\n                        Err(_) => {\n                            // We are at the top, create a new root node and push there.\n                            open_node = self.push_internal_level();\n                            break;\n                        }\n                    }\n                }\n\n                // Push key-value pair and new right subtree.\n                let tree_height = open_node.height() - 1;\n                let mut right_tree = Root::new();\n                for _ in 0..tree_height {\n                    right_tree.push_internal_level();\n                }\n                open_node.push(key, value, right_tree);\n\n                // Go down to the right-most leaf again.\n                cur_node = open_node.forget_type().last_leaf_edge().into_node();\n            }\n\n            // Increment length every iteration, to make sure the map drops\n            // the appended elements even if advancing the iterator panicks.\n            *length += 1;\n        }\n        self.fix_right_border_of_plentiful();\n    }\n}\n\n// An iterator for merging two sorted sequences into one\nstruct MergeIter<K, V, I: Iterator<Item = (K, V)>>(MergeIterInner<I>);\n\nimpl<K: Ord, V, I> Iterator for MergeIter<K, V, I>\nwhere\n    I: Iterator<Item = (K, V)> + FusedIterator,\n{\n    type Item = (K, V);\n\n    /// If two keys are equal, returns the key-value pair from the right source.\n    fn next(&mut self) -> Option<(K, V)> {\n        let (a_next, b_next) = self.0.nexts(|a: &(K, V), b: &(K, V)| K::cmp(&a.0, &b.0));\n        b_next.or(a_next)\n    }\n}\n"],[2027,"use super::map::MIN_LEN;\nuse super::node::{marker, ForceResult::*, Handle, LeftOrRight::*, NodeRef};\n\nimpl<'a, K: 'a, V: 'a> Handle<NodeRef<marker::Mut<'a>, K, V, marker::LeafOrInternal>, marker::KV> {\n    /// Removes a key-value pair from the tree, and returns that pair, as well as\n    /// the leaf edge corresponding to that former pair. It's possible this empties\n    /// a root node that is internal, which the caller should pop from the map\n    /// holding the tree. The caller should also decrement the map's length.\n    pub fn remove_kv_tracking<F: FnOnce()>(\n        self,\n        handle_emptied_internal_root: F,\n    ) -> ((K, V), Handle<NodeRef<marker::Mut<'a>, K, V, marker::Leaf>, marker::Edge>) {\n        match self.force() {\n            Leaf(node) => node.remove_leaf_kv(handle_emptied_internal_root),\n            Internal(node) => node.remove_internal_kv(handle_emptied_internal_root),\n        }\n    }\n}\n\nimpl<'a, K: 'a, V: 'a> Handle<NodeRef<marker::Mut<'a>, K, V, marker::Leaf>, marker::KV> {\n    fn remove_leaf_kv<F: FnOnce()>(\n        self,\n        handle_emptied_internal_root: F,\n    ) -> ((K, V), Handle<NodeRef<marker::Mut<'a>, K, V, marker::Leaf>, marker::Edge>) {\n        let (old_kv, mut pos) = self.remove();\n        let len = pos.reborrow().into_node().len();\n        if len < MIN_LEN {\n            let idx = pos.idx();\n            // We have to temporarily forget the child type, because there is no\n            // distinct node type for the immediate parents of a leaf.\n            let new_pos = match pos.into_node().forget_type().choose_parent_kv() {\n                Ok(Left(left_parent_kv)) => {\n                    debug_assert!(left_parent_kv.right_child_len() == MIN_LEN - 1);\n                    if left_parent_kv.can_merge() {\n                        left_parent_kv.merge_tracking_child_edge(Right(idx))\n                    } else {\n                        debug_assert!(left_parent_kv.left_child_len() > MIN_LEN);\n                        left_parent_kv.steal_left(idx)\n                    }\n                }\n                Ok(Right(right_parent_kv)) => {\n                    debug_assert!(right_parent_kv.left_child_len() == MIN_LEN - 1);\n                    if right_parent_kv.can_merge() {\n                        right_parent_kv.merge_tracking_child_edge(Left(idx))\n                    } else {\n                        debug_assert!(right_parent_kv.right_child_len() > MIN_LEN);\n                        right_parent_kv.steal_right(idx)\n                    }\n                }\n                Err(pos) => unsafe { Handle::new_edge(pos, idx) },\n            };\n            // SAFETY: `new_pos` is the leaf we started from or a sibling.\n            pos = unsafe { new_pos.cast_to_leaf_unchecked() };\n\n            // Only if we merged, the parent (if any) has shrunk, but skipping\n            // the following step otherwise does not pay off in benchmarks.\n            //\n            // SAFETY: We won't destroy or rearrange the leaf where `pos` is at\n            // by handling its parent recursively; at worst we will destroy or\n            // rearrange the parent through the grandparent, thus change the\n            // link to the parent inside the leaf.\n            if let Ok(parent) = unsafe { pos.reborrow_mut() }.into_node().ascend() {\n                if !parent.into_node().forget_type().fix_node_and_affected_ancestors() {\n                    handle_emptied_internal_root();\n                }\n            }\n        }\n        (old_kv, pos)\n    }\n}\n\nimpl<'a, K: 'a, V: 'a> Handle<NodeRef<marker::Mut<'a>, K, V, marker::Internal>, marker::KV> {\n    fn remove_internal_kv<F: FnOnce()>(\n        self,\n        handle_emptied_internal_root: F,\n    ) -> ((K, V), Handle<NodeRef<marker::Mut<'a>, K, V, marker::Leaf>, marker::Edge>) {\n        // Remove an adjacent KV from its leaf and then put it back in place of\n        // the element we were asked to remove. Prefer the left adjacent KV,\n        // for the reasons listed in `choose_parent_kv`.\n        let left_leaf_kv = self.left_edge().descend().last_leaf_edge().left_kv();\n        let left_leaf_kv = unsafe { left_leaf_kv.ok().unwrap_unchecked() };\n        let (left_kv, left_hole) = left_leaf_kv.remove_leaf_kv(handle_emptied_internal_root);\n\n        // The internal node may have been stolen from or merged. Go back right\n        // to find where the original KV ended up.\n        let mut internal = unsafe { left_hole.next_kv().ok().unwrap_unchecked() };\n        let old_kv = internal.replace_kv(left_kv.0, left_kv.1);\n        let pos = internal.next_leaf_edge();\n        (old_kv, pos)\n    }\n}\n"],[2028,"/// XorShiftRng\npub struct DeterministicRng {\n    count: usize,\n    x: u32,\n    y: u32,\n    z: u32,\n    w: u32,\n}\n\nimpl DeterministicRng {\n    pub fn new() -> Self {\n        DeterministicRng { count: 0, x: 0x193a6754, y: 0xa8a7d469, z: 0x97830e05, w: 0x113ba7bb }\n    }\n\n    /// Guarantees that each returned number is unique.\n    pub fn next(&mut self) -> u32 {\n        self.count += 1;\n        assert!(self.count <= 70029);\n        let x = self.x;\n        let t = x ^ (x << 11);\n        self.x = self.y;\n        self.y = self.z;\n        self.z = self.w;\n        let w_ = self.w;\n        self.w = w_ ^ (w_ >> 19) ^ (t ^ (t >> 8));\n        self.w\n    }\n}\n"],[2029,"use std::cell::Cell;\nuse std::cmp::Ordering::{self, *};\nuse std::ptr;\n\n// Minimal type with an `Ord` implementation violating transitivity.\n#[derive(Debug)]\npub enum Cyclic3 {\n    A,\n    B,\n    C,\n}\nuse Cyclic3::*;\n\nimpl PartialOrd for Cyclic3 {\n    fn partial_cmp(&self, other: &Self) -> Option<Ordering> {\n        Some(self.cmp(other))\n    }\n}\n\nimpl Ord for Cyclic3 {\n    fn cmp(&self, other: &Self) -> Ordering {\n        match (self, other) {\n            (A, A) | (B, B) | (C, C) => Equal,\n            (A, B) | (B, C) | (C, A) => Less,\n            (A, C) | (B, A) | (C, B) => Greater,\n        }\n    }\n}\n\nimpl PartialEq for Cyclic3 {\n    fn eq(&self, other: &Self) -> bool {\n        self.cmp(&other) == Equal\n    }\n}\n\nimpl Eq for Cyclic3 {}\n\n// Controls the ordering of values wrapped by `Governed`.\n#[derive(Debug)]\npub struct Governor {\n    flipped: Cell<bool>,\n}\n\nimpl Governor {\n    pub fn new() -> Self {\n        Governor { flipped: Cell::new(false) }\n    }\n\n    pub fn flip(&self) {\n        self.flipped.set(!self.flipped.get());\n    }\n}\n\n// Type with an `Ord` implementation that forms a total order at any moment\n// (assuming that `T` respects total order), but can suddenly be made to invert\n// that total order.\n#[derive(Debug)]\npub struct Governed<'a, T>(pub T, pub &'a Governor);\n\nimpl<T: Ord> PartialOrd for Governed<'_, T> {\n    fn partial_cmp(&self, other: &Self) -> Option<Ordering> {\n        Some(self.cmp(other))\n    }\n}\n\nimpl<T: Ord> Ord for Governed<'_, T> {\n    fn cmp(&self, other: &Self) -> Ordering {\n        assert!(ptr::eq(self.1, other.1));\n        let ord = self.0.cmp(&other.0);\n        if self.1.flipped.get() { ord.reverse() } else { ord }\n    }\n}\n\nimpl<T: PartialEq> PartialEq for Governed<'_, T> {\n    fn eq(&self, other: &Self) -> bool {\n        assert!(ptr::eq(self.1, other.1));\n        self.0.eq(&other.0)\n    }\n}\n\nimpl<T: Eq> Eq for Governed<'_, T> {}\n"],[2030,"use crate::fmt::Debug;\nuse std::cmp::Ordering;\nuse std::sync::atomic::{AtomicUsize, Ordering::SeqCst};\n\n/// A blueprint for crash test dummy instances that monitor particular events.\n/// Some instances may be configured to panic at some point.\n/// Events are `clone`, `drop` or some anonymous `query`.\n///\n/// Crash test dummies are identified and ordered by an id, so they can be used\n/// as keys in a BTreeMap. The implementation intentionally uses does not rely\n/// on anything defined in the crate, apart from the `Debug` trait.\n#[derive(Debug)]\npub struct CrashTestDummy {\n    id: usize,\n    cloned: AtomicUsize,\n    dropped: AtomicUsize,\n    queried: AtomicUsize,\n}\n\nimpl CrashTestDummy {\n    /// Creates a crash test dummy design. The `id` determines order and equality of instances.\n    pub fn new(id: usize) -> CrashTestDummy {\n        CrashTestDummy {\n            id,\n            cloned: AtomicUsize::new(0),\n            dropped: AtomicUsize::new(0),\n            queried: AtomicUsize::new(0),\n        }\n    }\n\n    /// Creates an instance of a crash test dummy that records what events it experiences\n    /// and optionally panics.\n    pub fn spawn(&self, panic: Panic) -> Instance<'_> {\n        Instance { origin: self, panic }\n    }\n\n    /// Returns how many times instances of the dummy have been cloned.\n    pub fn cloned(&self) -> usize {\n        self.cloned.load(SeqCst)\n    }\n\n    /// Returns how many times instances of the dummy have been dropped.\n    pub fn dropped(&self) -> usize {\n        self.dropped.load(SeqCst)\n    }\n\n    /// Returns how many times instances of the dummy have had their `query` member invoked.\n    pub fn queried(&self) -> usize {\n        self.queried.load(SeqCst)\n    }\n}\n\n#[derive(Debug)]\npub struct Instance<'a> {\n    origin: &'a CrashTestDummy,\n    panic: Panic,\n}\n\n#[derive(Copy, Clone, Debug, PartialEq, Eq)]\npub enum Panic {\n    Never,\n    InClone,\n    InDrop,\n    InQuery,\n}\n\nimpl Instance<'_> {\n    pub fn id(&self) -> usize {\n        self.origin.id\n    }\n\n    /// Some anonymous query, the result of which is already given.\n    pub fn query<R>(&self, result: R) -> R {\n        self.origin.queried.fetch_add(1, SeqCst);\n        if self.panic == Panic::InQuery {\n            panic!(\"panic in `query`\");\n        }\n        result\n    }\n}\n\nimpl Clone for Instance<'_> {\n    fn clone(&self) -> Self {\n        self.origin.cloned.fetch_add(1, SeqCst);\n        if self.panic == Panic::InClone {\n            panic!(\"panic in `clone`\");\n        }\n        Self { origin: self.origin, panic: Panic::Never }\n    }\n}\n\nimpl Drop for Instance<'_> {\n    fn drop(&mut self) {\n        self.origin.dropped.fetch_add(1, SeqCst);\n        if self.panic == Panic::InDrop {\n            panic!(\"panic in `drop`\");\n        }\n    }\n}\n\nimpl PartialOrd for Instance<'_> {\n    fn partial_cmp(&self, other: &Self) -> Option<Ordering> {\n        self.id().partial_cmp(&other.id())\n    }\n}\n\nimpl Ord for Instance<'_> {\n    fn cmp(&self, other: &Self) -> Ordering {\n        self.id().cmp(&other.id())\n    }\n}\n\nimpl PartialEq for Instance<'_> {\n    fn eq(&self, other: &Self) -> bool {\n        self.id().eq(&other.id())\n    }\n}\n\nimpl Eq for Instance<'_> {}\n"],[2031,"pub mod crash_test;\npub mod ord_chaos;\npub mod rng;\n"],[2032,"use core::cmp::Ordering;\nuse core::fmt::{self, Debug};\nuse core::iter::FusedIterator;\n\n/// Core of an iterator that merges the output of two strictly ascending iterators,\n/// for instance a union or a symmetric difference.\npub struct MergeIterInner<I: Iterator> {\n    a: I,\n    b: I,\n    peeked: Option<Peeked<I>>,\n}\n\n/// Benchmarks faster than wrapping both iterators in a Peekable,\n/// probably because we can afford to impose a FusedIterator bound.\n#[derive(Clone, Debug)]\nenum Peeked<I: Iterator> {\n    A(I::Item),\n    B(I::Item),\n}\n\nimpl<I: Iterator> Clone for MergeIterInner<I>\nwhere\n    I: Clone,\n    I::Item: Clone,\n{\n    fn clone(&self) -> Self {\n        Self { a: self.a.clone(), b: self.b.clone(), peeked: self.peeked.clone() }\n    }\n}\n\nimpl<I: Iterator> Debug for MergeIterInner<I>\nwhere\n    I: Debug,\n    I::Item: Debug,\n{\n    fn fmt(&self, f: &mut fmt::Formatter<'_>) -> fmt::Result {\n        f.debug_tuple(\"MergeIterInner\").field(&self.a).field(&self.b).field(&self.peeked).finish()\n    }\n}\n\nimpl<I: Iterator> MergeIterInner<I> {\n    /// Creates a new core for an iterator merging a pair of sources.\n    pub fn new(a: I, b: I) -> Self {\n        MergeIterInner { a, b, peeked: None }\n    }\n\n    /// Returns the next pair of items stemming from the pair of sources\n    /// being merged. If both returned options contain a value, that value\n    /// is equal and occurs in both sources. If one of the returned options\n    /// contains a value, that value doesn't occur in the other source (or\n    /// the sources are not strictly ascending). If neither returned option\n    /// contains a value, iteration has finished and subsequent calls will\n    /// return the same empty pair.\n    pub fn nexts<Cmp: Fn(&I::Item, &I::Item) -> Ordering>(\n        &mut self,\n        cmp: Cmp,\n    ) -> (Option<I::Item>, Option<I::Item>)\n    where\n        I: FusedIterator,\n    {\n        let mut a_next;\n        let mut b_next;\n        match self.peeked.take() {\n            Some(Peeked::A(next)) => {\n                a_next = Some(next);\n                b_next = self.b.next();\n            }\n            Some(Peeked::B(next)) => {\n                b_next = Some(next);\n                a_next = self.a.next();\n            }\n            None => {\n                a_next = self.a.next();\n                b_next = self.b.next();\n            }\n        }\n        if let (Some(ref a1), Some(ref b1)) = (&a_next, &b_next) {\n            match cmp(a1, b1) {\n                Ordering::Less => self.peeked = b_next.take().map(Peeked::B),\n                Ordering::Greater => self.peeked = a_next.take().map(Peeked::A),\n                Ordering::Equal => (),\n            }\n        }\n        (a_next, b_next)\n    }\n\n    /// Returns a pair of upper bounds for the `size_hint` of the final iterator.\n    pub fn lens(&self) -> (usize, usize)\n    where\n        I: ExactSizeIterator,\n    {\n        match self.peeked {\n            Some(Peeked::A(_)) => (1 + self.a.len(), self.b.len()),\n            Some(Peeked::B(_)) => (self.a.len(), 1 + self.b.len()),\n            _ => (self.a.len(), self.b.len()),\n        }\n    }\n}\n"],[2033,"use core::borrow::Borrow;\nuse core::ops::RangeBounds;\nuse core::ptr;\n\nuse super::node::{marker, ForceResult::*, Handle, NodeRef};\n\n// `front` and `back` are always both `None` or both `Some`.\npub struct LeafRange<BorrowType, K, V> {\n    front: Option<Handle<NodeRef<BorrowType, K, V, marker::Leaf>, marker::Edge>>,\n    back: Option<Handle<NodeRef<BorrowType, K, V, marker::Leaf>, marker::Edge>>,\n}\n\nimpl<'a, K: 'a, V: 'a> Clone for LeafRange<marker::Immut<'a>, K, V> {\n    fn clone(&self) -> Self {\n        LeafRange { front: self.front.clone(), back: self.back.clone() }\n    }\n}\n\nimpl<BorrowType, K, V> LeafRange<BorrowType, K, V> {\n    pub fn none() -> Self {\n        LeafRange { front: None, back: None }\n    }\n\n    fn is_empty(&self) -> bool {\n        self.front == self.back\n    }\n\n    /// Temporarily takes out another, immutable equivalent of the same range.\n    pub fn reborrow(&self) -> LeafRange<marker::Immut<'_>, K, V> {\n        LeafRange {\n            front: self.front.as_ref().map(|f| f.reborrow()),\n            back: self.back.as_ref().map(|b| b.reborrow()),\n        }\n    }\n}\n\nimpl<'a, K, V> LeafRange<marker::Immut<'a>, K, V> {\n    #[inline]\n    pub fn next_checked(&mut self) -> Option<(&'a K, &'a V)> {\n        if self.is_empty() { None } else { Some(unsafe { self.next_unchecked() }) }\n    }\n\n    #[inline]\n    pub fn next_back_checked(&mut self) -> Option<(&'a K, &'a V)> {\n        if self.is_empty() { None } else { Some(unsafe { self.next_back_unchecked() }) }\n    }\n\n    #[inline]\n    pub unsafe fn next_unchecked(&mut self) -> (&'a K, &'a V) {\n        debug_assert!(self.front.is_some());\n        unsafe { self.front.as_mut().unwrap_unchecked().next_unchecked() }\n    }\n\n    #[inline]\n    pub unsafe fn next_back_unchecked(&mut self) -> (&'a K, &'a V) {\n        debug_assert!(self.back.is_some());\n        unsafe { self.back.as_mut().unwrap_unchecked().next_back_unchecked() }\n    }\n}\n\nimpl<'a, K, V> LeafRange<marker::ValMut<'a>, K, V> {\n    #[inline]\n    pub fn next_checked(&mut self) -> Option<(&'a K, &'a mut V)> {\n        if self.is_empty() { None } else { Some(unsafe { self.next_unchecked() }) }\n    }\n\n    #[inline]\n    pub fn next_back_checked(&mut self) -> Option<(&'a K, &'a mut V)> {\n        if self.is_empty() { None } else { Some(unsafe { self.next_back_unchecked() }) }\n    }\n\n    #[inline]\n    pub unsafe fn next_unchecked(&mut self) -> (&'a K, &'a mut V) {\n        debug_assert!(self.front.is_some());\n        unsafe { self.front.as_mut().unwrap_unchecked().next_unchecked() }\n    }\n\n    #[inline]\n    pub unsafe fn next_back_unchecked(&mut self) -> (&'a K, &'a mut V) {\n        debug_assert!(self.back.is_some());\n        unsafe { self.back.as_mut().unwrap_unchecked().next_back_unchecked() }\n    }\n}\n\nimpl<K, V> LeafRange<marker::Dying, K, V> {\n    #[inline]\n    pub fn take_front(\n        &mut self,\n    ) -> Option<Handle<NodeRef<marker::Dying, K, V, marker::Leaf>, marker::Edge>> {\n        self.front.take()\n    }\n\n    #[inline]\n    pub unsafe fn deallocating_next_unchecked(\n        &mut self,\n    ) -> Handle<NodeRef<marker::Dying, K, V, marker::LeafOrInternal>, marker::KV> {\n        debug_assert!(self.front.is_some());\n        let front = self.front.as_mut().unwrap();\n        unsafe { front.deallocating_next_unchecked() }\n    }\n\n    #[inline]\n    pub unsafe fn deallocating_next_back_unchecked(\n        &mut self,\n    ) -> Handle<NodeRef<marker::Dying, K, V, marker::LeafOrInternal>, marker::KV> {\n        debug_assert!(self.back.is_some());\n        let back = self.back.as_mut().unwrap();\n        unsafe { back.deallocating_next_back_unchecked() }\n    }\n}\n\nimpl<BorrowType: marker::BorrowType, K, V> NodeRef<BorrowType, K, V, marker::LeafOrInternal> {\n    /// Finds the distinct leaf edges delimiting a specified range in a tree.\n    ///\n    /// If such distinct edges exist, returns them in ascending order, meaning\n    /// that a non-zero number of calls to `next_unchecked` on the `front` of\n    /// the result and/or calls to `next_back_unchecked` on the `back` of the\n    /// result will eventually reach the same edge.\n    ///\n    /// If there are no such edges, i.e., if the tree contains no key within\n    /// the range, returns an empty `front` and `back`.\n    ///\n    /// # Safety\n    /// Unless `BorrowType` is `Immut`, do not use the handles to visit the same\n    /// KV twice.\n    unsafe fn find_leaf_edges_spanning_range<Q: ?Sized, R>(\n        self,\n        range: R,\n    ) -> LeafRange<BorrowType, K, V>\n    where\n        Q: Ord,\n        K: Borrow<Q>,\n        R: RangeBounds<Q>,\n    {\n        match self.search_tree_for_bifurcation(&range) {\n            Err(_) => LeafRange::none(),\n            Ok((\n                node,\n                lower_edge_idx,\n                upper_edge_idx,\n                mut lower_child_bound,\n                mut upper_child_bound,\n            )) => {\n                let mut lower_edge = unsafe { Handle::new_edge(ptr::read(&node), lower_edge_idx) };\n                let mut upper_edge = unsafe { Handle::new_edge(node, upper_edge_idx) };\n                loop {\n                    match (lower_edge.force(), upper_edge.force()) {\n                        (Leaf(f), Leaf(b)) => return LeafRange { front: Some(f), back: Some(b) },\n                        (Internal(f), Internal(b)) => {\n                            (lower_edge, lower_child_bound) =\n                                f.descend().find_lower_bound_edge(lower_child_bound);\n                            (upper_edge, upper_child_bound) =\n                                b.descend().find_upper_bound_edge(upper_child_bound);\n                        }\n                        _ => unreachable!(\"BTreeMap has different depths\"),\n                    }\n                }\n            }\n        }\n    }\n}\n\n/// Equivalent to `(root1.first_leaf_edge(), root2.last_leaf_edge())` but more efficient.\nfn full_range<BorrowType: marker::BorrowType, K, V>(\n    root1: NodeRef<BorrowType, K, V, marker::LeafOrInternal>,\n    root2: NodeRef<BorrowType, K, V, marker::LeafOrInternal>,\n) -> LeafRange<BorrowType, K, V> {\n    let mut min_node = root1;\n    let mut max_node = root2;\n    loop {\n        let front = min_node.first_edge();\n        let back = max_node.last_edge();\n        match (front.force(), back.force()) {\n            (Leaf(f), Leaf(b)) => {\n                return LeafRange { front: Some(f), back: Some(b) };\n            }\n            (Internal(min_int), Internal(max_int)) => {\n                min_node = min_int.descend();\n                max_node = max_int.descend();\n            }\n            _ => unreachable!(\"BTreeMap has different depths\"),\n        };\n    }\n}\n\nimpl<'a, K: 'a, V: 'a> NodeRef<marker::Immut<'a>, K, V, marker::LeafOrInternal> {\n    /// Finds the pair of leaf edges delimiting a specific range in a tree.\n    ///\n    /// The result is meaningful only if the tree is ordered by key, like the tree\n    /// in a `BTreeMap` is.\n    pub fn range_search<Q, R>(self, range: R) -> LeafRange<marker::Immut<'a>, K, V>\n    where\n        Q: ?Sized + Ord,\n        K: Borrow<Q>,\n        R: RangeBounds<Q>,\n    {\n        // SAFETY: our borrow type is immutable.\n        unsafe { self.find_leaf_edges_spanning_range(range) }\n    }\n\n    /// Finds the pair of leaf edges delimiting an entire tree.\n    pub fn full_range(self) -> LeafRange<marker::Immut<'a>, K, V> {\n        full_range(self, self)\n    }\n}\n\nimpl<'a, K: 'a, V: 'a> NodeRef<marker::ValMut<'a>, K, V, marker::LeafOrInternal> {\n    /// Splits a unique reference into a pair of leaf edges delimiting a specified range.\n    /// The result are non-unique references allowing (some) mutation, which must be used\n    /// carefully.\n    ///\n    /// The result is meaningful only if the tree is ordered by key, like the tree\n    /// in a `BTreeMap` is.\n    ///\n    /// # Safety\n    /// Do not use the duplicate handles to visit the same KV twice.\n    pub fn range_search<Q, R>(self, range: R) -> LeafRange<marker::ValMut<'a>, K, V>\n    where\n        Q: ?Sized + Ord,\n        K: Borrow<Q>,\n        R: RangeBounds<Q>,\n    {\n        unsafe { self.find_leaf_edges_spanning_range(range) }\n    }\n\n    /// Splits a unique reference into a pair of leaf edges delimiting the full range of the tree.\n    /// The results are non-unique references allowing mutation (of values only), so must be used\n    /// with care.\n    pub fn full_range(self) -> LeafRange<marker::ValMut<'a>, K, V> {\n        // We duplicate the root NodeRef here -- we will never visit the same KV\n        // twice, and never end up with overlapping value references.\n        let self2 = unsafe { ptr::read(&self) };\n        full_range(self, self2)\n    }\n}\n\nimpl<K, V> NodeRef<marker::Dying, K, V, marker::LeafOrInternal> {\n    /// Splits a unique reference into a pair of leaf edges delimiting the full range of the tree.\n    /// The results are non-unique references allowing massively destructive mutation, so must be\n    /// used with the utmost care.\n    pub fn full_range(self) -> LeafRange<marker::Dying, K, V> {\n        // We duplicate the root NodeRef here -- we will never access it in a way\n        // that overlaps references obtained from the root.\n        let self2 = unsafe { ptr::read(&self) };\n        full_range(self, self2)\n    }\n}\n\nimpl<BorrowType: marker::BorrowType, K, V>\n    Handle<NodeRef<BorrowType, K, V, marker::Leaf>, marker::Edge>\n{\n    /// Given a leaf edge handle, returns [`Result::Ok`] with a handle to the neighboring KV\n    /// on the right side, which is either in the same leaf node or in an ancestor node.\n    /// If the leaf edge is the last one in the tree, returns [`Result::Err`] with the root node.\n    pub fn next_kv(\n        self,\n    ) -> Result<\n        Handle<NodeRef<BorrowType, K, V, marker::LeafOrInternal>, marker::KV>,\n        NodeRef<BorrowType, K, V, marker::LeafOrInternal>,\n    > {\n        let mut edge = self.forget_node_type();\n        loop {\n            edge = match edge.right_kv() {\n                Ok(kv) => return Ok(kv),\n                Err(last_edge) => match last_edge.into_node().ascend() {\n                    Ok(parent_edge) => parent_edge.forget_node_type(),\n                    Err(root) => return Err(root),\n                },\n            }\n        }\n    }\n\n    /// Given a leaf edge handle, returns [`Result::Ok`] with a handle to the neighboring KV\n    /// on the left side, which is either in the same leaf node or in an ancestor node.\n    /// If the leaf edge is the first one in the tree, returns [`Result::Err`] with the root node.\n    fn next_back_kv(\n        self,\n    ) -> Result<\n        Handle<NodeRef<BorrowType, K, V, marker::LeafOrInternal>, marker::KV>,\n        NodeRef<BorrowType, K, V, marker::LeafOrInternal>,\n    > {\n        let mut edge = self.forget_node_type();\n        loop {\n            edge = match edge.left_kv() {\n                Ok(kv) => return Ok(kv),\n                Err(last_edge) => match last_edge.into_node().ascend() {\n                    Ok(parent_edge) => parent_edge.forget_node_type(),\n                    Err(root) => return Err(root),\n                },\n            }\n        }\n    }\n}\n\nimpl<BorrowType: marker::BorrowType, K, V>\n    Handle<NodeRef<BorrowType, K, V, marker::Internal>, marker::Edge>\n{\n    /// Given an internal edge handle, returns [`Result::Ok`] with a handle to the neighboring KV\n    /// on the right side, which is either in the same internal node or in an ancestor node.\n    /// If the internal edge is the last one in the tree, returns [`Result::Err`] with the root node.\n    fn next_kv(\n        self,\n    ) -> Result<\n        Handle<NodeRef<BorrowType, K, V, marker::Internal>, marker::KV>,\n        NodeRef<BorrowType, K, V, marker::Internal>,\n    > {\n        let mut edge = self;\n        loop {\n            edge = match edge.right_kv() {\n                Ok(internal_kv) => return Ok(internal_kv),\n                Err(last_edge) => match last_edge.into_node().ascend() {\n                    Ok(parent_edge) => parent_edge,\n                    Err(root) => return Err(root),\n                },\n            }\n        }\n    }\n}\n\nimpl<K, V> Handle<NodeRef<marker::Dying, K, V, marker::Leaf>, marker::Edge> {\n    /// Given a leaf edge handle into a dying tree, returns the next leaf edge\n    /// on the right side, and the key-value pair in between, if they exist.\n    ///\n    /// If the given edge is the last one in a leaf, this method deallocates\n    /// the leaf, as well as any ancestor nodes whose last edge was reached.\n    /// This implies that if no more key-value pair follows, the entire tree\n    /// will have been deallocated and there is nothing left to return.\n    ///\n    /// # Safety\n    /// - The given edge must not have been previously returned by counterpart\n    ///   `deallocating_next_back`.\n    /// - The returned KV handle is only valid to access the key and value,\n    ///   and only valid until the next call to this method or counterpart\n    ///   `deallocating_next_back`.\n    unsafe fn deallocating_next(\n        self,\n    ) -> Option<(Self, Handle<NodeRef<marker::Dying, K, V, marker::LeafOrInternal>, marker::KV>)>\n    {\n        let mut edge = self.forget_node_type();\n        loop {\n            edge = match edge.right_kv() {\n                Ok(kv) => return Some((unsafe { ptr::read(&kv) }.next_leaf_edge(), kv)),\n                Err(last_edge) => match unsafe { last_edge.into_node().deallocate_and_ascend() } {\n                    Some(parent_edge) => parent_edge.forget_node_type(),\n                    None => return None,\n                },\n            }\n        }\n    }\n\n    /// Given a leaf edge handle into a dying tree, returns the next leaf edge\n    /// on the left side, and the key-value pair in between, if they exist.\n    ///\n    /// If the given edge is the first one in a leaf, this method deallocates\n    /// the leaf, as well as any ancestor nodes whose first edge was reached.\n    /// This implies that if no more key-value pair follows, the entire tree\n    /// will have been deallocated and there is nothing left to return.\n    ///\n    /// # Safety\n    /// - The given edge must not have been previously returned by counterpart\n    ///   `deallocating_next`.\n    /// - The returned KV handle is only valid to access the key and value,\n    ///   and only valid until the next call to this method or counterpart\n    ///   `deallocating_next`.\n    unsafe fn deallocating_next_back(\n        self,\n    ) -> Option<(Self, Handle<NodeRef<marker::Dying, K, V, marker::LeafOrInternal>, marker::KV>)>\n    {\n        let mut edge = self.forget_node_type();\n        loop {\n            edge = match edge.left_kv() {\n                Ok(kv) => return Some((unsafe { ptr::read(&kv) }.next_back_leaf_edge(), kv)),\n                Err(last_edge) => match unsafe { last_edge.into_node().deallocate_and_ascend() } {\n                    Some(parent_edge) => parent_edge.forget_node_type(),\n                    None => return None,\n                },\n            }\n        }\n    }\n\n    /// Deallocates a pile of nodes from the leaf up to the root.\n    /// This is the only way to deallocate the remainder of a tree after\n    /// `deallocating_next` and `deallocating_next_back` have been nibbling at\n    /// both sides of the tree, and have hit the same edge. As it is intended\n    /// only to be called when all keys and values have been returned,\n    /// no cleanup is done on any of the keys or values.\n    pub fn deallocating_end(self) {\n        let mut edge = self.forget_node_type();\n        while let Some(parent_edge) = unsafe { edge.into_node().deallocate_and_ascend() } {\n            edge = parent_edge.forget_node_type();\n        }\n    }\n}\n\nimpl<'a, K, V> Handle<NodeRef<marker::Immut<'a>, K, V, marker::Leaf>, marker::Edge> {\n    /// Moves the leaf edge handle to the next leaf edge and returns references to the\n    /// key and value in between.\n    ///\n    /// # Safety\n    /// There must be another KV in the direction travelled.\n    unsafe fn next_unchecked(&mut self) -> (&'a K, &'a V) {\n        super::mem::replace(self, |leaf_edge| {\n            let kv = leaf_edge.next_kv();\n            debug_assert!(kv.is_ok());\n            let kv = unsafe { kv.ok().unwrap_unchecked() };\n            (kv.next_leaf_edge(), kv.into_kv())\n        })\n    }\n\n    /// Moves the leaf edge handle to the previous leaf edge and returns references to the\n    /// key and value in between.\n    ///\n    /// # Safety\n    /// There must be another KV in the direction travelled.\n    unsafe fn next_back_unchecked(&mut self) -> (&'a K, &'a V) {\n        super::mem::replace(self, |leaf_edge| {\n            let kv = leaf_edge.next_back_kv();\n            debug_assert!(kv.is_ok());\n            let kv = unsafe { kv.ok().unwrap_unchecked() };\n            (kv.next_back_leaf_edge(), kv.into_kv())\n        })\n    }\n}\n\nimpl<'a, K, V> Handle<NodeRef<marker::ValMut<'a>, K, V, marker::Leaf>, marker::Edge> {\n    /// Moves the leaf edge handle to the next leaf edge and returns references to the\n    /// key and value in between.\n    ///\n    /// # Safety\n    /// There must be another KV in the direction travelled.\n    unsafe fn next_unchecked(&mut self) -> (&'a K, &'a mut V) {\n        let kv = super::mem::replace(self, |leaf_edge| {\n            let kv = leaf_edge.next_kv();\n            debug_assert!(kv.is_ok());\n            let kv = unsafe { kv.ok().unwrap_unchecked() };\n            (unsafe { ptr::read(&kv) }.next_leaf_edge(), kv)\n        });\n        // Doing this last is faster, according to benchmarks.\n        kv.into_kv_valmut()\n    }\n\n    /// Moves the leaf edge handle to the previous leaf and returns references to the\n    /// key and value in between.\n    ///\n    /// # Safety\n    /// There must be another KV in the direction travelled.\n    unsafe fn next_back_unchecked(&mut self) -> (&'a K, &'a mut V) {\n        let kv = super::mem::replace(self, |leaf_edge| {\n            let kv = leaf_edge.next_back_kv();\n            debug_assert!(kv.is_ok());\n            let kv = unsafe { kv.ok().unwrap_unchecked() };\n            (unsafe { ptr::read(&kv) }.next_back_leaf_edge(), kv)\n        });\n        // Doing this last is faster, according to benchmarks.\n        kv.into_kv_valmut()\n    }\n}\n\nimpl<K, V> Handle<NodeRef<marker::Dying, K, V, marker::Leaf>, marker::Edge> {\n    /// Moves the leaf edge handle to the next leaf edge and returns the key and value\n    /// in between, deallocating any node left behind while leaving the corresponding\n    /// edge in its parent node dangling.\n    ///\n    /// # Safety\n    /// - There must be another KV in the direction travelled.\n    /// - That KV was not previously returned by counterpart\n    ///   `deallocating_next_back_unchecked` on any copy of the handles\n    ///   being used to traverse the tree.\n    ///\n    /// The only safe way to proceed with the updated handle is to compare it, drop it,\n    /// or call this method or counterpart `deallocating_next_back_unchecked` again.\n    pub unsafe fn deallocating_next_unchecked(\n        &mut self,\n    ) -> Handle<NodeRef<marker::Dying, K, V, marker::LeafOrInternal>, marker::KV> {\n        super::mem::replace(self, |leaf_edge| unsafe {\n            leaf_edge.deallocating_next().unwrap_unchecked()\n        })\n    }\n\n    /// Moves the leaf edge handle to the previous leaf edge and returns the key and value\n    /// in between, deallocating any node left behind while leaving the corresponding\n    /// edge in its parent node dangling.\n    ///\n    /// # Safety\n    /// - There must be another KV in the direction travelled.\n    /// - That leaf edge was not previously returned by counterpart\n    ///   `deallocating_next_unchecked` on any copy of the handles\n    ///   being used to traverse the tree.\n    ///\n    /// The only safe way to proceed with the updated handle is to compare it, drop it,\n    /// or call this method or counterpart `deallocating_next_unchecked` again.\n    unsafe fn deallocating_next_back_unchecked(\n        &mut self,\n    ) -> Handle<NodeRef<marker::Dying, K, V, marker::LeafOrInternal>, marker::KV> {\n        super::mem::replace(self, |leaf_edge| unsafe {\n            leaf_edge.deallocating_next_back().unwrap_unchecked()\n        })\n    }\n}\n\nimpl<BorrowType: marker::BorrowType, K, V> NodeRef<BorrowType, K, V, marker::LeafOrInternal> {\n    /// Returns the leftmost leaf edge in or underneath a node - in other words, the edge\n    /// you need first when navigating forward (or last when navigating backward).\n    #[inline]\n    pub fn first_leaf_edge(self) -> Handle<NodeRef<BorrowType, K, V, marker::Leaf>, marker::Edge> {\n        let mut node = self;\n        loop {\n            match node.force() {\n                Leaf(leaf) => return leaf.first_edge(),\n                Internal(internal) => node = internal.first_edge().descend(),\n            }\n        }\n    }\n\n    /// Returns the rightmost leaf edge in or underneath a node - in other words, the edge\n    /// you need last when navigating forward (or first when navigating backward).\n    #[inline]\n    pub fn last_leaf_edge(self) -> Handle<NodeRef<BorrowType, K, V, marker::Leaf>, marker::Edge> {\n        let mut node = self;\n        loop {\n            match node.force() {\n                Leaf(leaf) => return leaf.last_edge(),\n                Internal(internal) => node = internal.last_edge().descend(),\n            }\n        }\n    }\n}\n\npub enum Position<BorrowType, K, V> {\n    Leaf(NodeRef<BorrowType, K, V, marker::Leaf>),\n    Internal(NodeRef<BorrowType, K, V, marker::Internal>),\n    InternalKV(Handle<NodeRef<BorrowType, K, V, marker::Internal>, marker::KV>),\n}\n\nimpl<'a, K: 'a, V: 'a> NodeRef<marker::Immut<'a>, K, V, marker::LeafOrInternal> {\n    /// Visits leaf nodes and internal KVs in order of ascending keys, and also\n    /// visits internal nodes as a whole in a depth first order, meaning that\n    /// internal nodes precede their individual KVs and their child nodes.\n    pub fn visit_nodes_in_order<F>(self, mut visit: F)\n    where\n        F: FnMut(Position<marker::Immut<'a>, K, V>),\n    {\n        match self.force() {\n            Leaf(leaf) => visit(Position::Leaf(leaf)),\n            Internal(internal) => {\n                visit(Position::Internal(internal));\n                let mut edge = internal.first_edge();\n                loop {\n                    edge = match edge.descend().force() {\n                        Leaf(leaf) => {\n                            visit(Position::Leaf(leaf));\n                            match edge.next_kv() {\n                                Ok(kv) => {\n                                    visit(Position::InternalKV(kv));\n                                    kv.right_edge()\n                                }\n                                Err(_) => return,\n                            }\n                        }\n                        Internal(internal) => {\n                            visit(Position::Internal(internal));\n                            internal.first_edge()\n                        }\n                    }\n                }\n            }\n        }\n    }\n\n    /// Calculates the number of elements in a (sub)tree.\n    pub fn calc_length(self) -> usize {\n        let mut result = 0;\n        self.visit_nodes_in_order(|pos| match pos {\n            Position::Leaf(node) => result += node.len(),\n            Position::Internal(node) => result += node.len(),\n            Position::InternalKV(_) => (),\n        });\n        result\n    }\n}\n\nimpl<BorrowType: marker::BorrowType, K, V>\n    Handle<NodeRef<BorrowType, K, V, marker::LeafOrInternal>, marker::KV>\n{\n    /// Returns the leaf edge closest to a KV for forward navigation.\n    pub fn next_leaf_edge(self) -> Handle<NodeRef<BorrowType, K, V, marker::Leaf>, marker::Edge> {\n        match self.force() {\n            Leaf(leaf_kv) => leaf_kv.right_edge(),\n            Internal(internal_kv) => {\n                let next_internal_edge = internal_kv.right_edge();\n                next_internal_edge.descend().first_leaf_edge()\n            }\n        }\n    }\n\n    /// Returns the leaf edge closest to a KV for backward navigation.\n    fn next_back_leaf_edge(self) -> Handle<NodeRef<BorrowType, K, V, marker::Leaf>, marker::Edge> {\n        match self.force() {\n            Leaf(leaf_kv) => leaf_kv.left_edge(),\n            Internal(internal_kv) => {\n                let next_internal_edge = internal_kv.left_edge();\n                next_internal_edge.descend().last_leaf_edge()\n            }\n        }\n    }\n}\n"],[2034,"// This is an attempt at an implementation following the ideal\n//\n// ```\n// struct BTreeMap<K, V> {\n//     height: usize,\n//     root: Option<Box<Node<K, V, height>>>\n// }\n//\n// struct Node<K, V, height: usize> {\n//     keys: [K; 2 * B - 1],\n//     vals: [V; 2 * B - 1],\n//     edges: [if height > 0 { Box<Node<K, V, height - 1>> } else { () }; 2 * B],\n//     parent: Option<(NonNull<Node<K, V, height + 1>>, u16)>,\n//     len: u16,\n// }\n// ```\n//\n// Since Rust doesn't actually have dependent types and polymorphic recursion,\n// we make do with lots of unsafety.\n\n// A major goal of this module is to avoid complexity by treating the tree as a generic (if\n// weirdly shaped) container and avoiding dealing with most of the B-Tree invariants. As such,\n// this module doesn't care whether the entries are sorted, which nodes can be underfull, or\n// even what underfull means. However, we do rely on a few invariants:\n//\n// - Trees must have uniform depth/height. This means that every path down to a leaf from a\n//   given node has exactly the same length.\n// - A node of length `n` has `n` keys, `n` values, and `n + 1` edges.\n//   This implies that even an empty node has at least one edge.\n//   For a leaf node, \"having an edge\" only means we can identify a position in the node,\n//   since leaf edges are empty and need no data representation. In an internal node,\n//   an edge both identifies a position and contains a pointer to a child node.\n\nuse core::marker::PhantomData;\nuse core::mem::{self, MaybeUninit};\nuse core::ptr::{self, NonNull};\nuse core::slice::SliceIndex;\n\nuse crate::alloc::{Allocator, Global, Layout};\nuse crate::boxed::Box;\n\nconst B: usize = 6;\npub const CAPACITY: usize = 2 * B - 1;\npub const MIN_LEN_AFTER_SPLIT: usize = B - 1;\nconst KV_IDX_CENTER: usize = B - 1;\nconst EDGE_IDX_LEFT_OF_CENTER: usize = B - 1;\nconst EDGE_IDX_RIGHT_OF_CENTER: usize = B;\n\n/// The underlying representation of leaf nodes and part of the representation of internal nodes.\nstruct LeafNode<K, V> {\n    /// We want to be covariant in `K` and `V`.\n    parent: Option<NonNull<InternalNode<K, V>>>,\n\n    /// This node's index into the parent node's `edges` array.\n    /// `*node.parent.edges[node.parent_idx]` should be the same thing as `node`.\n    /// This is only guaranteed to be initialized when `parent` is non-null.\n    parent_idx: MaybeUninit<u16>,\n\n    /// The number of keys and values this node stores.\n    len: u16,\n\n    /// The arrays storing the actual data of the node. Only the first `len` elements of each\n    /// array are initialized and valid.\n    keys: [MaybeUninit<K>; CAPACITY],\n    vals: [MaybeUninit<V>; CAPACITY],\n}\n\nimpl<K, V> LeafNode<K, V> {\n    /// Initializes a new `LeafNode` in-place.\n    unsafe fn init(this: *mut Self) {\n        // As a general policy, we leave fields uninitialized if they can be, as this should\n        // be both slightly faster and easier to track in Valgrind.\n        unsafe {\n            // parent_idx, keys, and vals are all MaybeUninit\n            ptr::addr_of_mut!((*this).parent).write(None);\n            ptr::addr_of_mut!((*this).len).write(0);\n        }\n    }\n\n    /// Creates a new boxed `LeafNode`.\n    fn new() -> Box<Self> {\n        unsafe {\n            let mut leaf = Box::new_uninit();\n            LeafNode::init(leaf.as_mut_ptr());\n            leaf.assume_init()\n        }\n    }\n}\n\n/// The underlying representation of internal nodes. As with `LeafNode`s, these should be hidden\n/// behind `BoxedNode`s to prevent dropping uninitialized keys and values. Any pointer to an\n/// `InternalNode` can be directly cast to a pointer to the underlying `LeafNode` portion of the\n/// node, allowing code to act on leaf and internal nodes generically without having to even check\n/// which of the two a pointer is pointing at. This property is enabled by the use of `repr(C)`.\n#[repr(C)]\n// gdb_providers.py uses this type name for introspection.\nstruct InternalNode<K, V> {\n    data: LeafNode<K, V>,\n\n    /// The pointers to the children of this node. `len + 1` of these are considered\n    /// initialized and valid, except that near the end, while the tree is held\n    /// through borrow type `Dying`, some of these pointers are dangling.\n    edges: [MaybeUninit<BoxedNode<K, V>>; 2 * B],\n}\n\nimpl<K, V> InternalNode<K, V> {\n    /// Creates a new boxed `InternalNode`.\n    ///\n    /// # Safety\n    /// An invariant of internal nodes is that they have at least one\n    /// initialized and valid edge. This function does not set up\n    /// such an edge.\n    unsafe fn new() -> Box<Self> {\n        unsafe {\n            let mut node = Box::<Self>::new_uninit();\n            // We only need to initialize the data; the edges are MaybeUninit.\n            LeafNode::init(ptr::addr_of_mut!((*node.as_mut_ptr()).data));\n            node.assume_init()\n        }\n    }\n}\n\n/// A managed, non-null pointer to a node. This is either an owned pointer to\n/// `LeafNode<K, V>` or an owned pointer to `InternalNode<K, V>`.\n///\n/// However, `BoxedNode` contains no information as to which of the two types\n/// of nodes it actually contains, and, partially due to this lack of information,\n/// is not a separate type and has no destructor.\ntype BoxedNode<K, V> = NonNull<LeafNode<K, V>>;\n\n// N.B. `NodeRef` is always covariant in `K` and `V`, even when the `BorrowType`\n// is `Mut`. This is technically wrong, but cannot result in any unsafety due to\n// internal use of `NodeRef` because we stay completely generic over `K` and `V`.\n// However, whenever a public type wraps `NodeRef`, make sure that it has the\n// correct variance.\n///\n/// A reference to a node.\n///\n/// This type has a number of parameters that controls how it acts:\n/// - `BorrowType`: A dummy type that describes the kind of borrow and carries a lifetime.\n///    - When this is `Immut<'a>`, the `NodeRef` acts roughly like `&'a Node`.\n///    - When this is `ValMut<'a>`, the `NodeRef` acts roughly like `&'a Node`\n///      with respect to keys and tree structure, but also allows many\n///      mutable references to values throughout the tree to coexist.\n///    - When this is `Mut<'a>`, the `NodeRef` acts roughly like `&'a mut Node`,\n///      although insert methods allow a mutable pointer to a value to coexist.\n///    - When this is `Owned`, the `NodeRef` acts roughly like `Box<Node>`,\n///      but does not have a destructor, and must be cleaned up manually.\n///    - When this is `Dying`, the `NodeRef` still acts roughly like `Box<Node>`,\n///      but has methods to destroy the tree bit by bit, and ordinary methods,\n///      while not marked as unsafe to call, can invoke UB if called incorrectly.\n///   Since any `NodeRef` allows navigating through the tree, `BorrowType`\n///   effectively applies to the entire tree, not just to the node itself.\n/// - `K` and `V`: These are the types of keys and values stored in the nodes.\n/// - `Type`: This can be `Leaf`, `Internal`, or `LeafOrInternal`. When this is\n///   `Leaf`, the `NodeRef` points to a leaf node, when this is `Internal` the\n///   `NodeRef` points to an internal node, and when this is `LeafOrInternal` the\n///   `NodeRef` could be pointing to either type of node.\n///   `Type` is named `NodeType` when used outside `NodeRef`.\n///\n/// Both `BorrowType` and `NodeType` restrict what methods we implement, to\n/// exploit static type safety. There are limitations in the way we can apply\n/// such restrictions:\n/// - For each type parameter, we can only define a method either generically\n///   or for one particular type. For example, we cannot define a method like\n///   `into_kv` generically for all `BorrowType`, or once for all types that\n///   carry a lifetime, because we want it to return `&'a` references.\n///   Therefore, we define it only for the least powerful type `Immut<'a>`.\n/// - We cannot get implicit coercion from say `Mut<'a>` to `Immut<'a>`.\n///   Therefore, we have to explicitly call `reborrow` on a more powerful\n///   `NodeRef` in order to reach a method like `into_kv`.\n///\n/// All methods on `NodeRef` that return some kind of reference, either:\n/// - Take `self` by value, and return the lifetime carried by `BorrowType`.\n///   Sometimes, to invoke such a method, we need to call `reborrow_mut`.\n/// - Take `self` by reference, and (implicitly) return that reference's\n///   lifetime, instead of the lifetime carried by `BorrowType`. That way,\n///   the borrow checker guarantees that the `NodeRef` remains borrowed as long\n///   as the returned reference is used.\n///   The methods supporting insert bend this rule by returning a raw pointer,\n///   i.e., a reference without any lifetime.\npub struct NodeRef<BorrowType, K, V, Type> {\n    /// The number of levels that the node and the level of leaves are apart, a\n    /// constant of the node that cannot be entirely described by `Type`, and that\n    /// the node itself does not store. We only need to store the height of the root\n    /// node, and derive every other node's height from it.\n    /// Must be zero if `Type` is `Leaf` and non-zero if `Type` is `Internal`.\n    height: usize,\n    /// The pointer to the leaf or internal node. The definition of `InternalNode`\n    /// ensures that the pointer is valid either way.\n    node: NonNull<LeafNode<K, V>>,\n    _marker: PhantomData<(BorrowType, Type)>,\n}\n\n/// The root node of an owned tree.\n///\n/// Note that this does not have a destructor, and must be cleaned up manually.\npub type Root<K, V> = NodeRef<marker::Owned, K, V, marker::LeafOrInternal>;\n\nimpl<'a, K: 'a, V: 'a, Type> Copy for NodeRef<marker::Immut<'a>, K, V, Type> {}\nimpl<'a, K: 'a, V: 'a, Type> Clone for NodeRef<marker::Immut<'a>, K, V, Type> {\n    fn clone(&self) -> Self {\n        *self\n    }\n}\n\nunsafe impl<BorrowType, K: Sync, V: Sync, Type> Sync for NodeRef<BorrowType, K, V, Type> {}\n\nunsafe impl<'a, K: Sync + 'a, V: Sync + 'a, Type> Send for NodeRef<marker::Immut<'a>, K, V, Type> {}\nunsafe impl<'a, K: Send + 'a, V: Send + 'a, Type> Send for NodeRef<marker::Mut<'a>, K, V, Type> {}\nunsafe impl<'a, K: Send + 'a, V: Send + 'a, Type> Send for NodeRef<marker::ValMut<'a>, K, V, Type> {}\nunsafe impl<K: Send, V: Send, Type> Send for NodeRef<marker::Owned, K, V, Type> {}\nunsafe impl<K: Send, V: Send, Type> Send for NodeRef<marker::Dying, K, V, Type> {}\n\nimpl<K, V> NodeRef<marker::Owned, K, V, marker::Leaf> {\n    fn new_leaf() -> Self {\n        Self::from_new_leaf(LeafNode::new())\n    }\n\n    fn from_new_leaf(leaf: Box<LeafNode<K, V>>) -> Self {\n        NodeRef { height: 0, node: NonNull::from(Box::leak(leaf)), _marker: PhantomData }\n    }\n}\n\nimpl<K, V> NodeRef<marker::Owned, K, V, marker::Internal> {\n    fn new_internal(child: Root<K, V>) -> Self {\n        let mut new_node = unsafe { InternalNode::new() };\n        new_node.edges[0].write(child.node);\n        unsafe { NodeRef::from_new_internal(new_node, child.height + 1) }\n    }\n\n    /// # Safety\n    /// `height` must not be zero.\n    unsafe fn from_new_internal(internal: Box<InternalNode<K, V>>, height: usize) -> Self {\n        debug_assert!(height > 0);\n        let node = NonNull::from(Box::leak(internal)).cast();\n        let mut this = NodeRef { height, node, _marker: PhantomData };\n        this.borrow_mut().correct_all_childrens_parent_links();\n        this\n    }\n}\n\nimpl<BorrowType, K, V> NodeRef<BorrowType, K, V, marker::Internal> {\n    /// Unpack a node reference that was packed as `NodeRef::parent`.\n    fn from_internal(node: NonNull<InternalNode<K, V>>, height: usize) -> Self {\n        debug_assert!(height > 0);\n        NodeRef { height, node: node.cast(), _marker: PhantomData }\n    }\n}\n\nimpl<BorrowType, K, V> NodeRef<BorrowType, K, V, marker::Internal> {\n    /// Exposes the data of an internal node.\n    ///\n    /// Returns a raw ptr to avoid invalidating other references to this node.\n    fn as_internal_ptr(this: &Self) -> *mut InternalNode<K, V> {\n        // SAFETY: the static node type is `Internal`.\n        this.node.as_ptr() as *mut InternalNode<K, V>\n    }\n}\n\nimpl<'a, K, V> NodeRef<marker::Mut<'a>, K, V, marker::Internal> {\n    /// Borrows exclusive access to the data of an internal node.\n    fn as_internal_mut(&mut self) -> &mut InternalNode<K, V> {\n        let ptr = Self::as_internal_ptr(self);\n        unsafe { &mut *ptr }\n    }\n}\n\nimpl<BorrowType, K, V, Type> NodeRef<BorrowType, K, V, Type> {\n    /// Finds the length of the node. This is the number of keys or values.\n    /// The number of edges is `len() + 1`.\n    /// Note that, despite being safe, calling this function can have the side effect\n    /// of invalidating mutable references that unsafe code has created.\n    pub fn len(&self) -> usize {\n        // Crucially, we only access the `len` field here. If BorrowType is marker::ValMut,\n        // there might be outstanding mutable references to values that we must not invalidate.\n        unsafe { usize::from((*Self::as_leaf_ptr(self)).len) }\n    }\n\n    /// Returns the number of levels that the node and leaves are apart. Zero\n    /// height means the node is a leaf itself. If you picture trees with the\n    /// root on top, the number says at which elevation the node appears.\n    /// If you picture trees with leaves on top, the number says how high\n    /// the tree extends above the node.\n    pub fn height(&self) -> usize {\n        self.height\n    }\n\n    /// Temporarily takes out another, immutable reference to the same node.\n    pub fn reborrow(&self) -> NodeRef<marker::Immut<'_>, K, V, Type> {\n        NodeRef { height: self.height, node: self.node, _marker: PhantomData }\n    }\n\n    /// Exposes the leaf portion of any leaf or internal node.\n    ///\n    /// Returns a raw ptr to avoid invalidating other references to this node.\n    fn as_leaf_ptr(this: &Self) -> *mut LeafNode<K, V> {\n        // The node must be valid for at least the LeafNode portion.\n        // This is not a reference in the NodeRef type because we don't know if\n        // it should be unique or shared.\n        this.node.as_ptr()\n    }\n}\n\nimpl<BorrowType: marker::BorrowType, K, V, Type> NodeRef<BorrowType, K, V, Type> {\n    /// Finds the parent of the current node. Returns `Ok(handle)` if the current\n    /// node actually has a parent, where `handle` points to the edge of the parent\n    /// that points to the current node. Returns `Err(self)` if the current node has\n    /// no parent, giving back the original `NodeRef`.\n    ///\n    /// The method name assumes you picture trees with the root node on top.\n    ///\n    /// `edge.descend().ascend().unwrap()` and `node.ascend().unwrap().descend()` should\n    /// both, upon success, do nothing.\n    pub fn ascend(\n        self,\n    ) -> Result<Handle<NodeRef<BorrowType, K, V, marker::Internal>, marker::Edge>, Self> {\n        assert!(BorrowType::PERMITS_TRAVERSAL);\n        // We need to use raw pointers to nodes because, if BorrowType is marker::ValMut,\n        // there might be outstanding mutable references to values that we must not invalidate.\n        let leaf_ptr: *const _ = Self::as_leaf_ptr(&self);\n        unsafe { (*leaf_ptr).parent }\n            .as_ref()\n            .map(|parent| Handle {\n                node: NodeRef::from_internal(*parent, self.height + 1),\n                idx: unsafe { usize::from((*leaf_ptr).parent_idx.assume_init()) },\n                _marker: PhantomData,\n            })\n            .ok_or(self)\n    }\n\n    pub fn first_edge(self) -> Handle<Self, marker::Edge> {\n        unsafe { Handle::new_edge(self, 0) }\n    }\n\n    pub fn last_edge(self) -> Handle<Self, marker::Edge> {\n        let len = self.len();\n        unsafe { Handle::new_edge(self, len) }\n    }\n\n    /// Note that `self` must be nonempty.\n    pub fn first_kv(self) -> Handle<Self, marker::KV> {\n        let len = self.len();\n        assert!(len > 0);\n        unsafe { Handle::new_kv(self, 0) }\n    }\n\n    /// Note that `self` must be nonempty.\n    pub fn last_kv(self) -> Handle<Self, marker::KV> {\n        let len = self.len();\n        assert!(len > 0);\n        unsafe { Handle::new_kv(self, len - 1) }\n    }\n}\n\nimpl<BorrowType, K, V, Type> NodeRef<BorrowType, K, V, Type> {\n    /// Could be a public implementation of PartialEq, but only used in this module.\n    fn eq(&self, other: &Self) -> bool {\n        let Self { node, height, _marker } = self;\n        if node.eq(&other.node) {\n            debug_assert_eq!(*height, other.height);\n            true\n        } else {\n            false\n        }\n    }\n}\n\nimpl<'a, K: 'a, V: 'a, Type> NodeRef<marker::Immut<'a>, K, V, Type> {\n    /// Exposes the leaf portion of any leaf or internal node in an immutable tree.\n    fn into_leaf(self) -> &'a LeafNode<K, V> {\n        let ptr = Self::as_leaf_ptr(&self);\n        // SAFETY: there can be no mutable references into this tree borrowed as `Immut`.\n        unsafe { &*ptr }\n    }\n\n    /// Borrows a view into the keys stored in the node.\n    pub fn keys(&self) -> &[K] {\n        let leaf = self.into_leaf();\n        unsafe {\n            MaybeUninit::slice_assume_init_ref(leaf.keys.get_unchecked(..usize::from(leaf.len)))\n        }\n    }\n}\n\nimpl<K, V> NodeRef<marker::Dying, K, V, marker::LeafOrInternal> {\n    /// Similar to `ascend`, gets a reference to a node's parent node, but also\n    /// deallocates the current node in the process. This is unsafe because the\n    /// current node will still be accessible despite being deallocated.\n    pub unsafe fn deallocate_and_ascend(\n        self,\n    ) -> Option<Handle<NodeRef<marker::Dying, K, V, marker::Internal>, marker::Edge>> {\n        let height = self.height;\n        let node = self.node;\n        let ret = self.ascend().ok();\n        unsafe {\n            Global.deallocate(\n                node.cast(),\n                if height > 0 {\n                    Layout::new::<InternalNode<K, V>>()\n                } else {\n                    Layout::new::<LeafNode<K, V>>()\n                },\n            );\n        }\n        ret\n    }\n}\n\nimpl<'a, K, V, Type> NodeRef<marker::Mut<'a>, K, V, Type> {\n    /// Temporarily takes out another mutable reference to the same node. Beware, as\n    /// this method is very dangerous, doubly so since it may not immediately appear\n    /// dangerous.\n    ///\n    /// Because mutable pointers can roam anywhere around the tree, the returned\n    /// pointer can easily be used to make the original pointer dangling, out of\n    /// bounds, or invalid under stacked borrow rules.\n    // FIXME(@gereeter) consider adding yet another type parameter to `NodeRef`\n    // that restricts the use of navigation methods on reborrowed pointers,\n    // preventing this unsafety.\n    unsafe fn reborrow_mut(&mut self) -> NodeRef<marker::Mut<'_>, K, V, Type> {\n        NodeRef { height: self.height, node: self.node, _marker: PhantomData }\n    }\n\n    /// Borrows exclusive access to the leaf portion of a leaf or internal node.\n    fn as_leaf_mut(&mut self) -> &mut LeafNode<K, V> {\n        let ptr = Self::as_leaf_ptr(self);\n        // SAFETY: we have exclusive access to the entire node.\n        unsafe { &mut *ptr }\n    }\n\n    /// Offers exclusive access to the leaf portion of a leaf or internal node.\n    fn into_leaf_mut(mut self) -> &'a mut LeafNode<K, V> {\n        let ptr = Self::as_leaf_ptr(&mut self);\n        // SAFETY: we have exclusive access to the entire node.\n        unsafe { &mut *ptr }\n    }\n}\n\nimpl<K, V, Type> NodeRef<marker::Dying, K, V, Type> {\n    /// Borrows exclusive access to the leaf portion of a dying leaf or internal node.\n    fn as_leaf_dying(&mut self) -> &mut LeafNode<K, V> {\n        let ptr = Self::as_leaf_ptr(self);\n        // SAFETY: we have exclusive access to the entire node.\n        unsafe { &mut *ptr }\n    }\n}\n\nimpl<'a, K: 'a, V: 'a, Type> NodeRef<marker::Mut<'a>, K, V, Type> {\n    /// Borrows exclusive access to an element of the key storage area.\n    ///\n    /// # Safety\n    /// `index` is in bounds of 0..CAPACITY\n    unsafe fn key_area_mut<I, Output: ?Sized>(&mut self, index: I) -> &mut Output\n    where\n        I: SliceIndex<[MaybeUninit<K>], Output = Output>,\n    {\n        // SAFETY: the caller will not be able to call further methods on self\n        // until the key slice reference is dropped, as we have unique access\n        // for the lifetime of the borrow.\n        unsafe { self.as_leaf_mut().keys.as_mut_slice().get_unchecked_mut(index) }\n    }\n\n    /// Borrows exclusive access to an element or slice of the node's value storage area.\n    ///\n    /// # Safety\n    /// `index` is in bounds of 0..CAPACITY\n    unsafe fn val_area_mut<I, Output: ?Sized>(&mut self, index: I) -> &mut Output\n    where\n        I: SliceIndex<[MaybeUninit<V>], Output = Output>,\n    {\n        // SAFETY: the caller will not be able to call further methods on self\n        // until the value slice reference is dropped, as we have unique access\n        // for the lifetime of the borrow.\n        unsafe { self.as_leaf_mut().vals.as_mut_slice().get_unchecked_mut(index) }\n    }\n}\n\nimpl<'a, K: 'a, V: 'a> NodeRef<marker::Mut<'a>, K, V, marker::Internal> {\n    /// Borrows exclusive access to an element or slice of the node's storage area for edge contents.\n    ///\n    /// # Safety\n    /// `index` is in bounds of 0..CAPACITY + 1\n    unsafe fn edge_area_mut<I, Output: ?Sized>(&mut self, index: I) -> &mut Output\n    where\n        I: SliceIndex<[MaybeUninit<BoxedNode<K, V>>], Output = Output>,\n    {\n        // SAFETY: the caller will not be able to call further methods on self\n        // until the edge slice reference is dropped, as we have unique access\n        // for the lifetime of the borrow.\n        unsafe { self.as_internal_mut().edges.as_mut_slice().get_unchecked_mut(index) }\n    }\n}\n\nimpl<'a, K, V, Type> NodeRef<marker::ValMut<'a>, K, V, Type> {\n    /// # Safety\n    /// - The node has more than `idx` initialized elements.\n    unsafe fn into_key_val_mut_at(mut self, idx: usize) -> (&'a K, &'a mut V) {\n        // We only create a reference to the one element we are interested in,\n        // to avoid aliasing with outstanding references to other elements,\n        // in particular, those returned to the caller in earlier iterations.\n        let leaf = Self::as_leaf_ptr(&mut self);\n        let keys = unsafe { ptr::addr_of!((*leaf).keys) };\n        let vals = unsafe { ptr::addr_of_mut!((*leaf).vals) };\n        // We must coerce to unsized array pointers because of Rust issue #74679.\n        let keys: *const [_] = keys;\n        let vals: *mut [_] = vals;\n        let key = unsafe { (&*keys.get_unchecked(idx)).assume_init_ref() };\n        let val = unsafe { (&mut *vals.get_unchecked_mut(idx)).assume_init_mut() };\n        (key, val)\n    }\n}\n\nimpl<'a, K: 'a, V: 'a, Type> NodeRef<marker::Mut<'a>, K, V, Type> {\n    /// Borrows exclusive access to the length of the node.\n    pub fn len_mut(&mut self) -> &mut u16 {\n        &mut self.as_leaf_mut().len\n    }\n}\n\nimpl<'a, K, V> NodeRef<marker::Mut<'a>, K, V, marker::Internal> {\n    /// # Safety\n    /// Every item returned by `range` is a valid edge index for the node.\n    unsafe fn correct_childrens_parent_links<R: Iterator<Item = usize>>(&mut self, range: R) {\n        for i in range {\n            debug_assert!(i <= self.len());\n            unsafe { Handle::new_edge(self.reborrow_mut(), i) }.correct_parent_link();\n        }\n    }\n\n    fn correct_all_childrens_parent_links(&mut self) {\n        let len = self.len();\n        unsafe { self.correct_childrens_parent_links(0..=len) };\n    }\n}\n\nimpl<'a, K: 'a, V: 'a> NodeRef<marker::Mut<'a>, K, V, marker::LeafOrInternal> {\n    /// Sets the node's link to its parent edge,\n    /// without invalidating other references to the node.\n    fn set_parent_link(&mut self, parent: NonNull<InternalNode<K, V>>, parent_idx: usize) {\n        let leaf = Self::as_leaf_ptr(self);\n        unsafe { (*leaf).parent = Some(parent) };\n        unsafe { (*leaf).parent_idx.write(parent_idx as u16) };\n    }\n}\n\nimpl<K, V> NodeRef<marker::Owned, K, V, marker::LeafOrInternal> {\n    /// Clears the root's link to its parent edge.\n    fn clear_parent_link(&mut self) {\n        let mut root_node = self.borrow_mut();\n        let leaf = root_node.as_leaf_mut();\n        leaf.parent = None;\n    }\n}\n\nimpl<K, V> NodeRef<marker::Owned, K, V, marker::LeafOrInternal> {\n    /// Returns a new owned tree, with its own root node that is initially empty.\n    pub fn new() -> Self {\n        NodeRef::new_leaf().forget_type()\n    }\n\n    /// Adds a new internal node with a single edge pointing to the previous root node,\n    /// make that new node the root node, and return it. This increases the height by 1\n    /// and is the opposite of `pop_internal_level`.\n    pub fn push_internal_level(&mut self) -> NodeRef<marker::Mut<'_>, K, V, marker::Internal> {\n        super::mem::take_mut(self, |old_root| NodeRef::new_internal(old_root).forget_type());\n\n        // `self.borrow_mut()`, except that we just forgot we're internal now:\n        NodeRef { height: self.height, node: self.node, _marker: PhantomData }\n    }\n\n    /// Removes the internal root node, using its first child as the new root node.\n    /// As it is intended only to be called when the root node has only one child,\n    /// no cleanup is done on any of the keys, values and other children.\n    /// This decreases the height by 1 and is the opposite of `push_internal_level`.\n    ///\n    /// Requires exclusive access to the `Root` object but not to the root node;\n    /// it will not invalidate other handles or references to the root node.\n    ///\n    /// Panics if there is no internal level, i.e., if the root node is a leaf.\n    pub fn pop_internal_level(&mut self) {\n        assert!(self.height > 0);\n\n        let top = self.node;\n\n        // SAFETY: we asserted to be internal.\n        let internal_self = unsafe { self.borrow_mut().cast_to_internal_unchecked() };\n        // SAFETY: we borrowed `self` exclusively and its borrow type is exclusive.\n        let internal_node = unsafe { &mut *NodeRef::as_internal_ptr(&internal_self) };\n        // SAFETY: the first edge is always initialized.\n        self.node = unsafe { internal_node.edges[0].assume_init_read() };\n        self.height -= 1;\n        self.clear_parent_link();\n\n        unsafe {\n            Global.deallocate(top.cast(), Layout::new::<InternalNode<K, V>>());\n        }\n    }\n}\n\nimpl<K, V, Type> NodeRef<marker::Owned, K, V, Type> {\n    /// Mutably borrows the owned root node. Unlike `reborrow_mut`, this is safe\n    /// because the return value cannot be used to destroy the root, and there\n    /// cannot be other references to the tree.\n    pub fn borrow_mut(&mut self) -> NodeRef<marker::Mut<'_>, K, V, Type> {\n        NodeRef { height: self.height, node: self.node, _marker: PhantomData }\n    }\n\n    /// Slightly mutably borrows the owned root node.\n    pub fn borrow_valmut(&mut self) -> NodeRef<marker::ValMut<'_>, K, V, Type> {\n        NodeRef { height: self.height, node: self.node, _marker: PhantomData }\n    }\n\n    /// Irreversibly transitions to a reference that permits traversal and offers\n    /// destructive methods and little else.\n    pub fn into_dying(self) -> NodeRef<marker::Dying, K, V, Type> {\n        NodeRef { height: self.height, node: self.node, _marker: PhantomData }\n    }\n}\n\nimpl<'a, K: 'a, V: 'a> NodeRef<marker::Mut<'a>, K, V, marker::Leaf> {\n    /// Adds a key-value pair to the end of the node.\n    pub fn push(&mut self, key: K, val: V) {\n        let len = self.len_mut();\n        let idx = usize::from(*len);\n        assert!(idx < CAPACITY);\n        *len += 1;\n        unsafe {\n            self.key_area_mut(idx).write(key);\n            self.val_area_mut(idx).write(val);\n        }\n    }\n}\n\nimpl<'a, K: 'a, V: 'a> NodeRef<marker::Mut<'a>, K, V, marker::Internal> {\n    /// Adds a key-value pair, and an edge to go to the right of that pair,\n    /// to the end of the node.\n    pub fn push(&mut self, key: K, val: V, edge: Root<K, V>) {\n        assert!(edge.height == self.height - 1);\n\n        let len = self.len_mut();\n        let idx = usize::from(*len);\n        assert!(idx < CAPACITY);\n        *len += 1;\n        unsafe {\n            self.key_area_mut(idx).write(key);\n            self.val_area_mut(idx).write(val);\n            self.edge_area_mut(idx + 1).write(edge.node);\n            Handle::new_edge(self.reborrow_mut(), idx + 1).correct_parent_link();\n        }\n    }\n}\n\nimpl<BorrowType, K, V> NodeRef<BorrowType, K, V, marker::Leaf> {\n    /// Removes any static information asserting that this node is a `Leaf` node.\n    pub fn forget_type(self) -> NodeRef<BorrowType, K, V, marker::LeafOrInternal> {\n        NodeRef { height: self.height, node: self.node, _marker: PhantomData }\n    }\n}\n\nimpl<BorrowType, K, V> NodeRef<BorrowType, K, V, marker::Internal> {\n    /// Removes any static information asserting that this node is an `Internal` node.\n    pub fn forget_type(self) -> NodeRef<BorrowType, K, V, marker::LeafOrInternal> {\n        NodeRef { height: self.height, node: self.node, _marker: PhantomData }\n    }\n}\n\nimpl<BorrowType, K, V> NodeRef<BorrowType, K, V, marker::LeafOrInternal> {\n    /// Checks whether a node is an `Internal` node or a `Leaf` node.\n    pub fn force(\n        self,\n    ) -> ForceResult<\n        NodeRef<BorrowType, K, V, marker::Leaf>,\n        NodeRef<BorrowType, K, V, marker::Internal>,\n    > {\n        if self.height == 0 {\n            ForceResult::Leaf(NodeRef {\n                height: self.height,\n                node: self.node,\n                _marker: PhantomData,\n            })\n        } else {\n            ForceResult::Internal(NodeRef {\n                height: self.height,\n                node: self.node,\n                _marker: PhantomData,\n            })\n        }\n    }\n}\n\nimpl<'a, K, V> NodeRef<marker::Mut<'a>, K, V, marker::LeafOrInternal> {\n    /// Unsafely asserts to the compiler the static information that this node is a `Leaf`.\n    unsafe fn cast_to_leaf_unchecked(self) -> NodeRef<marker::Mut<'a>, K, V, marker::Leaf> {\n        debug_assert!(self.height == 0);\n        NodeRef { height: self.height, node: self.node, _marker: PhantomData }\n    }\n\n    /// Unsafely asserts to the compiler the static information that this node is an `Internal`.\n    unsafe fn cast_to_internal_unchecked(self) -> NodeRef<marker::Mut<'a>, K, V, marker::Internal> {\n        debug_assert!(self.height > 0);\n        NodeRef { height: self.height, node: self.node, _marker: PhantomData }\n    }\n}\n\n/// A reference to a specific key-value pair or edge within a node. The `Node` parameter\n/// must be a `NodeRef`, while the `Type` can either be `KV` (signifying a handle on a key-value\n/// pair) or `Edge` (signifying a handle on an edge).\n///\n/// Note that even `Leaf` nodes can have `Edge` handles. Instead of representing a pointer to\n/// a child node, these represent the spaces where child pointers would go between the key-value\n/// pairs. For example, in a node with length 2, there would be 3 possible edge locations - one\n/// to the left of the node, one between the two pairs, and one at the right of the node.\npub struct Handle<Node, Type> {\n    node: Node,\n    idx: usize,\n    _marker: PhantomData<Type>,\n}\n\nimpl<Node: Copy, Type> Copy for Handle<Node, Type> {}\n// We don't need the full generality of `#[derive(Clone)]`, as the only time `Node` will be\n// `Clone`able is when it is an immutable reference and therefore `Copy`.\nimpl<Node: Copy, Type> Clone for Handle<Node, Type> {\n    fn clone(&self) -> Self {\n        *self\n    }\n}\n\nimpl<Node, Type> Handle<Node, Type> {\n    /// Retrieves the node that contains the edge or key-value pair this handle points to.\n    pub fn into_node(self) -> Node {\n        self.node\n    }\n\n    /// Returns the position of this handle in the node.\n    pub fn idx(&self) -> usize {\n        self.idx\n    }\n}\n\nimpl<BorrowType, K, V, NodeType> Handle<NodeRef<BorrowType, K, V, NodeType>, marker::KV> {\n    /// Creates a new handle to a key-value pair in `node`.\n    /// Unsafe because the caller must ensure that `idx < node.len()`.\n    pub unsafe fn new_kv(node: NodeRef<BorrowType, K, V, NodeType>, idx: usize) -> Self {\n        debug_assert!(idx < node.len());\n\n        Handle { node, idx, _marker: PhantomData }\n    }\n\n    pub fn left_edge(self) -> Handle<NodeRef<BorrowType, K, V, NodeType>, marker::Edge> {\n        unsafe { Handle::new_edge(self.node, self.idx) }\n    }\n\n    pub fn right_edge(self) -> Handle<NodeRef<BorrowType, K, V, NodeType>, marker::Edge> {\n        unsafe { Handle::new_edge(self.node, self.idx + 1) }\n    }\n}\n\nimpl<BorrowType, K, V, NodeType, HandleType> PartialEq\n    for Handle<NodeRef<BorrowType, K, V, NodeType>, HandleType>\n{\n    fn eq(&self, other: &Self) -> bool {\n        let Self { node, idx, _marker } = self;\n        node.eq(&other.node) && *idx == other.idx\n    }\n}\n\nimpl<BorrowType, K, V, NodeType, HandleType>\n    Handle<NodeRef<BorrowType, K, V, NodeType>, HandleType>\n{\n    /// Temporarily takes out another immutable handle on the same location.\n    pub fn reborrow(&self) -> Handle<NodeRef<marker::Immut<'_>, K, V, NodeType>, HandleType> {\n        // We can't use Handle::new_kv or Handle::new_edge because we don't know our type\n        Handle { node: self.node.reborrow(), idx: self.idx, _marker: PhantomData }\n    }\n}\n\nimpl<'a, K, V, NodeType, HandleType> Handle<NodeRef<marker::Mut<'a>, K, V, NodeType>, HandleType> {\n    /// Temporarily takes out another mutable handle on the same location. Beware, as\n    /// this method is very dangerous, doubly so since it may not immediately appear\n    /// dangerous.\n    ///\n    /// For details, see `NodeRef::reborrow_mut`.\n    pub unsafe fn reborrow_mut(\n        &mut self,\n    ) -> Handle<NodeRef<marker::Mut<'_>, K, V, NodeType>, HandleType> {\n        // We can't use Handle::new_kv or Handle::new_edge because we don't know our type\n        Handle { node: unsafe { self.node.reborrow_mut() }, idx: self.idx, _marker: PhantomData }\n    }\n}\n\nimpl<BorrowType, K, V, NodeType> Handle<NodeRef<BorrowType, K, V, NodeType>, marker::Edge> {\n    /// Creates a new handle to an edge in `node`.\n    /// Unsafe because the caller must ensure that `idx <= node.len()`.\n    pub unsafe fn new_edge(node: NodeRef<BorrowType, K, V, NodeType>, idx: usize) -> Self {\n        debug_assert!(idx <= node.len());\n\n        Handle { node, idx, _marker: PhantomData }\n    }\n\n    pub fn left_kv(self) -> Result<Handle<NodeRef<BorrowType, K, V, NodeType>, marker::KV>, Self> {\n        if self.idx > 0 {\n            Ok(unsafe { Handle::new_kv(self.node, self.idx - 1) })\n        } else {\n            Err(self)\n        }\n    }\n\n    pub fn right_kv(self) -> Result<Handle<NodeRef<BorrowType, K, V, NodeType>, marker::KV>, Self> {\n        if self.idx < self.node.len() {\n            Ok(unsafe { Handle::new_kv(self.node, self.idx) })\n        } else {\n            Err(self)\n        }\n    }\n}\n\npub enum LeftOrRight<T> {\n    Left(T),\n    Right(T),\n}\n\n/// Given an edge index where we want to insert into a node filled to capacity,\n/// computes a sensible KV index of a split point and where to perform the insertion.\n/// The goal of the split point is for its key and value to end up in a parent node;\n/// the keys, values and edges to the left of the split point become the left child;\n/// the keys, values and edges to the right of the split point become the right child.\nfn splitpoint(edge_idx: usize) -> (usize, LeftOrRight<usize>) {\n    debug_assert!(edge_idx <= CAPACITY);\n    // Rust issue #74834 tries to explain these symmetric rules.\n    match edge_idx {\n        0..EDGE_IDX_LEFT_OF_CENTER => (KV_IDX_CENTER - 1, LeftOrRight::Left(edge_idx)),\n        EDGE_IDX_LEFT_OF_CENTER => (KV_IDX_CENTER, LeftOrRight::Left(edge_idx)),\n        EDGE_IDX_RIGHT_OF_CENTER => (KV_IDX_CENTER, LeftOrRight::Right(0)),\n        _ => (KV_IDX_CENTER + 1, LeftOrRight::Right(edge_idx - (KV_IDX_CENTER + 1 + 1))),\n    }\n}\n\nimpl<'a, K: 'a, V: 'a> Handle<NodeRef<marker::Mut<'a>, K, V, marker::Leaf>, marker::Edge> {\n    /// Inserts a new key-value pair between the key-value pairs to the right and left of\n    /// this edge. This method assumes that there is enough space in the node for the new\n    /// pair to fit.\n    ///\n    /// The returned pointer points to the inserted value.\n    fn insert_fit(&mut self, key: K, val: V) -> *mut V {\n        debug_assert!(self.node.len() < CAPACITY);\n        let new_len = self.node.len() + 1;\n\n        unsafe {\n            slice_insert(self.node.key_area_mut(..new_len), self.idx, key);\n            slice_insert(self.node.val_area_mut(..new_len), self.idx, val);\n            *self.node.len_mut() = new_len as u16;\n\n            self.node.val_area_mut(self.idx).assume_init_mut()\n        }\n    }\n}\n\nimpl<'a, K: 'a, V: 'a> Handle<NodeRef<marker::Mut<'a>, K, V, marker::Leaf>, marker::Edge> {\n    /// Inserts a new key-value pair between the key-value pairs to the right and left of\n    /// this edge. This method splits the node if there isn't enough room.\n    ///\n    /// The returned pointer points to the inserted value.\n    fn insert(mut self, key: K, val: V) -> (InsertResult<'a, K, V, marker::Leaf>, *mut V) {\n        if self.node.len() < CAPACITY {\n            let val_ptr = self.insert_fit(key, val);\n            let kv = unsafe { Handle::new_kv(self.node, self.idx) };\n            (InsertResult::Fit(kv), val_ptr)\n        } else {\n            let (middle_kv_idx, insertion) = splitpoint(self.idx);\n            let middle = unsafe { Handle::new_kv(self.node, middle_kv_idx) };\n            let mut result = middle.split();\n            let mut insertion_edge = match insertion {\n                LeftOrRight::Left(insert_idx) => unsafe {\n                    Handle::new_edge(result.left.reborrow_mut(), insert_idx)\n                },\n                LeftOrRight::Right(insert_idx) => unsafe {\n                    Handle::new_edge(result.right.borrow_mut(), insert_idx)\n                },\n            };\n            let val_ptr = insertion_edge.insert_fit(key, val);\n            (InsertResult::Split(result), val_ptr)\n        }\n    }\n}\n\nimpl<'a, K, V> Handle<NodeRef<marker::Mut<'a>, K, V, marker::Internal>, marker::Edge> {\n    /// Fixes the parent pointer and index in the child node that this edge\n    /// links to. This is useful when the ordering of edges has been changed,\n    fn correct_parent_link(self) {\n        // Create backpointer without invalidating other references to the node.\n        let ptr = unsafe { NonNull::new_unchecked(NodeRef::as_internal_ptr(&self.node)) };\n        let idx = self.idx;\n        let mut child = self.descend();\n        child.set_parent_link(ptr, idx);\n    }\n}\n\nimpl<'a, K: 'a, V: 'a> Handle<NodeRef<marker::Mut<'a>, K, V, marker::Internal>, marker::Edge> {\n    /// Inserts a new key-value pair and an edge that will go to the right of that new pair\n    /// between this edge and the key-value pair to the right of this edge. This method assumes\n    /// that there is enough space in the node for the new pair to fit.\n    fn insert_fit(&mut self, key: K, val: V, edge: Root<K, V>) {\n        debug_assert!(self.node.len() < CAPACITY);\n        debug_assert!(edge.height == self.node.height - 1);\n        let new_len = self.node.len() + 1;\n\n        unsafe {\n            slice_insert(self.node.key_area_mut(..new_len), self.idx, key);\n            slice_insert(self.node.val_area_mut(..new_len), self.idx, val);\n            slice_insert(self.node.edge_area_mut(..new_len + 1), self.idx + 1, edge.node);\n            *self.node.len_mut() = new_len as u16;\n\n            self.node.correct_childrens_parent_links(self.idx + 1..new_len + 1);\n        }\n    }\n\n    /// Inserts a new key-value pair and an edge that will go to the right of that new pair\n    /// between this edge and the key-value pair to the right of this edge. This method splits\n    /// the node if there isn't enough room.\n    fn insert(\n        mut self,\n        key: K,\n        val: V,\n        edge: Root<K, V>,\n    ) -> InsertResult<'a, K, V, marker::Internal> {\n        assert!(edge.height == self.node.height - 1);\n\n        if self.node.len() < CAPACITY {\n            self.insert_fit(key, val, edge);\n            let kv = unsafe { Handle::new_kv(self.node, self.idx) };\n            InsertResult::Fit(kv)\n        } else {\n            let (middle_kv_idx, insertion) = splitpoint(self.idx);\n            let middle = unsafe { Handle::new_kv(self.node, middle_kv_idx) };\n            let mut result = middle.split();\n            let mut insertion_edge = match insertion {\n                LeftOrRight::Left(insert_idx) => unsafe {\n                    Handle::new_edge(result.left.reborrow_mut(), insert_idx)\n                },\n                LeftOrRight::Right(insert_idx) => unsafe {\n                    Handle::new_edge(result.right.borrow_mut(), insert_idx)\n                },\n            };\n            insertion_edge.insert_fit(key, val, edge);\n            InsertResult::Split(result)\n        }\n    }\n}\n\nimpl<'a, K: 'a, V: 'a> Handle<NodeRef<marker::Mut<'a>, K, V, marker::Leaf>, marker::Edge> {\n    /// Inserts a new key-value pair between the key-value pairs to the right and left of\n    /// this edge. This method splits the node if there isn't enough room, and tries to\n    /// insert the split off portion into the parent node recursively, until the root is reached.\n    ///\n    /// If the returned result is a `Fit`, its handle's node can be this edge's node or an ancestor.\n    /// If the returned result is a `Split`, the `left` field will be the root node.\n    /// The returned pointer points to the inserted value.\n    pub fn insert_recursing(\n        self,\n        key: K,\n        value: V,\n    ) -> (InsertResult<'a, K, V, marker::LeafOrInternal>, *mut V) {\n        let (mut split, val_ptr) = match self.insert(key, value) {\n            (InsertResult::Fit(handle), ptr) => {\n                return (InsertResult::Fit(handle.forget_node_type()), ptr);\n            }\n            (InsertResult::Split(split), val_ptr) => (split.forget_node_type(), val_ptr),\n        };\n\n        loop {\n            split = match split.left.ascend() {\n                Ok(parent) => match parent.insert(split.kv.0, split.kv.1, split.right) {\n                    InsertResult::Fit(handle) => {\n                        return (InsertResult::Fit(handle.forget_node_type()), val_ptr);\n                    }\n                    InsertResult::Split(split) => split.forget_node_type(),\n                },\n                Err(root) => {\n                    return (InsertResult::Split(SplitResult { left: root, ..split }), val_ptr);\n                }\n            };\n        }\n    }\n}\n\nimpl<BorrowType: marker::BorrowType, K, V>\n    Handle<NodeRef<BorrowType, K, V, marker::Internal>, marker::Edge>\n{\n    /// Finds the node pointed to by this edge.\n    ///\n    /// The method name assumes you picture trees with the root node on top.\n    ///\n    /// `edge.descend().ascend().unwrap()` and `node.ascend().unwrap().descend()` should\n    /// both, upon success, do nothing.\n    pub fn descend(self) -> NodeRef<BorrowType, K, V, marker::LeafOrInternal> {\n        assert!(BorrowType::PERMITS_TRAVERSAL);\n        // We need to use raw pointers to nodes because, if BorrowType is\n        // marker::ValMut, there might be outstanding mutable references to\n        // values that we must not invalidate. There's no worry accessing the\n        // height field because that value is copied. Beware that, once the\n        // node pointer is dereferenced, we access the edges array with a\n        // reference (Rust issue #73987) and invalidate any other references\n        // to or inside the array, should any be around.\n        let parent_ptr = NodeRef::as_internal_ptr(&self.node);\n        let node = unsafe { (*parent_ptr).edges.get_unchecked(self.idx).assume_init_read() };\n        NodeRef { node, height: self.node.height - 1, _marker: PhantomData }\n    }\n}\n\nimpl<'a, K: 'a, V: 'a, NodeType> Handle<NodeRef<marker::Immut<'a>, K, V, NodeType>, marker::KV> {\n    pub fn into_kv(self) -> (&'a K, &'a V) {\n        debug_assert!(self.idx < self.node.len());\n        let leaf = self.node.into_leaf();\n        let k = unsafe { leaf.keys.get_unchecked(self.idx).assume_init_ref() };\n        let v = unsafe { leaf.vals.get_unchecked(self.idx).assume_init_ref() };\n        (k, v)\n    }\n}\n\nimpl<'a, K: 'a, V: 'a, NodeType> Handle<NodeRef<marker::Mut<'a>, K, V, NodeType>, marker::KV> {\n    pub fn key_mut(&mut self) -> &mut K {\n        unsafe { self.node.key_area_mut(self.idx).assume_init_mut() }\n    }\n\n    pub fn into_val_mut(self) -> &'a mut V {\n        debug_assert!(self.idx < self.node.len());\n        let leaf = self.node.into_leaf_mut();\n        unsafe { leaf.vals.get_unchecked_mut(self.idx).assume_init_mut() }\n    }\n}\n\nimpl<'a, K, V, NodeType> Handle<NodeRef<marker::ValMut<'a>, K, V, NodeType>, marker::KV> {\n    pub fn into_kv_valmut(self) -> (&'a K, &'a mut V) {\n        unsafe { self.node.into_key_val_mut_at(self.idx) }\n    }\n}\n\nimpl<'a, K: 'a, V: 'a, NodeType> Handle<NodeRef<marker::Mut<'a>, K, V, NodeType>, marker::KV> {\n    pub fn kv_mut(&mut self) -> (&mut K, &mut V) {\n        debug_assert!(self.idx < self.node.len());\n        // We cannot call separate key and value methods, because calling the second one\n        // invalidates the reference returned by the first.\n        unsafe {\n            let leaf = self.node.as_leaf_mut();\n            let key = leaf.keys.get_unchecked_mut(self.idx).assume_init_mut();\n            let val = leaf.vals.get_unchecked_mut(self.idx).assume_init_mut();\n            (key, val)\n        }\n    }\n\n    /// Replaces the key and value that the KV handle refers to.\n    pub fn replace_kv(&mut self, k: K, v: V) -> (K, V) {\n        let (key, val) = self.kv_mut();\n        (mem::replace(key, k), mem::replace(val, v))\n    }\n}\n\nimpl<K, V, NodeType> Handle<NodeRef<marker::Dying, K, V, NodeType>, marker::KV> {\n    /// Extracts the key and value that the KV handle refers to.\n    pub fn into_key_val(mut self) -> (K, V) {\n        debug_assert!(self.idx < self.node.len());\n        let leaf = self.node.as_leaf_dying();\n        unsafe {\n            let key = leaf.keys.get_unchecked_mut(self.idx).assume_init_read();\n            let val = leaf.vals.get_unchecked_mut(self.idx).assume_init_read();\n            (key, val)\n        }\n    }\n\n    /// Drops the key and value that the KV handle refers to.\n    #[inline]\n    pub fn drop_key_val(mut self) {\n        debug_assert!(self.idx < self.node.len());\n        let leaf = self.node.as_leaf_dying();\n        unsafe {\n            leaf.keys.get_unchecked_mut(self.idx).assume_init_drop();\n            leaf.vals.get_unchecked_mut(self.idx).assume_init_drop();\n        }\n    }\n}\n\nimpl<'a, K: 'a, V: 'a, NodeType> Handle<NodeRef<marker::Mut<'a>, K, V, NodeType>, marker::KV> {\n    /// Helps implementations of `split` for a particular `NodeType`,\n    /// by taking care of leaf data.\n    fn split_leaf_data(&mut self, new_node: &mut LeafNode<K, V>) -> (K, V) {\n        debug_assert!(self.idx < self.node.len());\n        let old_len = self.node.len();\n        let new_len = old_len - self.idx - 1;\n        new_node.len = new_len as u16;\n        unsafe {\n            let k = self.node.key_area_mut(self.idx).assume_init_read();\n            let v = self.node.val_area_mut(self.idx).assume_init_read();\n\n            move_to_slice(\n                self.node.key_area_mut(self.idx + 1..old_len),\n                &mut new_node.keys[..new_len],\n            );\n            move_to_slice(\n                self.node.val_area_mut(self.idx + 1..old_len),\n                &mut new_node.vals[..new_len],\n            );\n\n            *self.node.len_mut() = self.idx as u16;\n            (k, v)\n        }\n    }\n}\n\nimpl<'a, K: 'a, V: 'a> Handle<NodeRef<marker::Mut<'a>, K, V, marker::Leaf>, marker::KV> {\n    /// Splits the underlying node into three parts:\n    ///\n    /// - The node is truncated to only contain the key-value pairs to the left of\n    ///   this handle.\n    /// - The key and value pointed to by this handle are extracted.\n    /// - All the key-value pairs to the right of this handle are put into a newly\n    ///   allocated node.\n    pub fn split(mut self) -> SplitResult<'a, K, V, marker::Leaf> {\n        let mut new_node = LeafNode::new();\n\n        let kv = self.split_leaf_data(&mut new_node);\n\n        let right = NodeRef::from_new_leaf(new_node);\n        SplitResult { left: self.node, kv, right }\n    }\n\n    /// Removes the key-value pair pointed to by this handle and returns it, along with the edge\n    /// that the key-value pair collapsed into.\n    pub fn remove(\n        mut self,\n    ) -> ((K, V), Handle<NodeRef<marker::Mut<'a>, K, V, marker::Leaf>, marker::Edge>) {\n        let old_len = self.node.len();\n        unsafe {\n            let k = slice_remove(self.node.key_area_mut(..old_len), self.idx);\n            let v = slice_remove(self.node.val_area_mut(..old_len), self.idx);\n            *self.node.len_mut() = (old_len - 1) as u16;\n            ((k, v), self.left_edge())\n        }\n    }\n}\n\nimpl<'a, K: 'a, V: 'a> Handle<NodeRef<marker::Mut<'a>, K, V, marker::Internal>, marker::KV> {\n    /// Splits the underlying node into three parts:\n    ///\n    /// - The node is truncated to only contain the edges and key-value pairs to the\n    ///   left of this handle.\n    /// - The key and value pointed to by this handle are extracted.\n    /// - All the edges and key-value pairs to the right of this handle are put into\n    ///   a newly allocated node.\n    pub fn split(mut self) -> SplitResult<'a, K, V, marker::Internal> {\n        let old_len = self.node.len();\n        unsafe {\n            let mut new_node = InternalNode::new();\n            let kv = self.split_leaf_data(&mut new_node.data);\n            let new_len = usize::from(new_node.data.len);\n            move_to_slice(\n                self.node.edge_area_mut(self.idx + 1..old_len + 1),\n                &mut new_node.edges[..new_len + 1],\n            );\n\n            let height = self.node.height;\n            let right = NodeRef::from_new_internal(new_node, height);\n\n            SplitResult { left: self.node, kv, right }\n        }\n    }\n}\n\n/// Represents a session for evaluating and performing a balancing operation\n/// around an internal key-value pair.\npub struct BalancingContext<'a, K, V> {\n    parent: Handle<NodeRef<marker::Mut<'a>, K, V, marker::Internal>, marker::KV>,\n    left_child: NodeRef<marker::Mut<'a>, K, V, marker::LeafOrInternal>,\n    right_child: NodeRef<marker::Mut<'a>, K, V, marker::LeafOrInternal>,\n}\n\nimpl<'a, K, V> Handle<NodeRef<marker::Mut<'a>, K, V, marker::Internal>, marker::KV> {\n    pub fn consider_for_balancing(self) -> BalancingContext<'a, K, V> {\n        let self1 = unsafe { ptr::read(&self) };\n        let self2 = unsafe { ptr::read(&self) };\n        BalancingContext {\n            parent: self,\n            left_child: self1.left_edge().descend(),\n            right_child: self2.right_edge().descend(),\n        }\n    }\n}\n\nimpl<'a, K, V> NodeRef<marker::Mut<'a>, K, V, marker::LeafOrInternal> {\n    /// Chooses a balancing context involving the node as a child, thus between\n    /// the KV immediately to the left or to the right in the parent node.\n    /// Returns an `Err` if there is no parent.\n    /// Panics if the parent is empty.\n    ///\n    /// Prefers the left side, to be optimal if the given node is somehow\n    /// underfull, meaning here only that it has fewer elements than its left\n    /// sibling and than its right sibling, if they exist. In that case,\n    /// merging with the left sibling is faster, since we only need to move\n    /// the node's N elements, instead of shifting them to the right and moving\n    /// more than N elements in front. Stealing from the left sibling is also\n    /// typically faster, since we only need to shift the node's N elements to\n    /// the right, instead of shifting at least N of the sibling's elements to\n    /// the left.\n    pub fn choose_parent_kv(self) -> Result<LeftOrRight<BalancingContext<'a, K, V>>, Self> {\n        match unsafe { ptr::read(&self) }.ascend() {\n            Ok(parent_edge) => match parent_edge.left_kv() {\n                Ok(left_parent_kv) => Ok(LeftOrRight::Left(BalancingContext {\n                    parent: unsafe { ptr::read(&left_parent_kv) },\n                    left_child: left_parent_kv.left_edge().descend(),\n                    right_child: self,\n                })),\n                Err(parent_edge) => match parent_edge.right_kv() {\n                    Ok(right_parent_kv) => Ok(LeftOrRight::Right(BalancingContext {\n                        parent: unsafe { ptr::read(&right_parent_kv) },\n                        left_child: self,\n                        right_child: right_parent_kv.right_edge().descend(),\n                    })),\n                    Err(_) => unreachable!(\"empty internal node\"),\n                },\n            },\n            Err(root) => Err(root),\n        }\n    }\n}\n\nimpl<'a, K, V> BalancingContext<'a, K, V> {\n    pub fn left_child_len(&self) -> usize {\n        self.left_child.len()\n    }\n\n    pub fn right_child_len(&self) -> usize {\n        self.right_child.len()\n    }\n\n    pub fn into_left_child(self) -> NodeRef<marker::Mut<'a>, K, V, marker::LeafOrInternal> {\n        self.left_child\n    }\n\n    pub fn into_right_child(self) -> NodeRef<marker::Mut<'a>, K, V, marker::LeafOrInternal> {\n        self.right_child\n    }\n\n    /// Returns whether merging is possible, i.e., whether there is enough room\n    /// in a node to combine the central KV with both adjacent child nodes.\n    pub fn can_merge(&self) -> bool {\n        self.left_child.len() + 1 + self.right_child.len() <= CAPACITY\n    }\n}\n\nimpl<'a, K: 'a, V: 'a> BalancingContext<'a, K, V> {\n    /// Performs a merge and lets a closure decide what to return.\n    fn do_merge<\n        F: FnOnce(\n            NodeRef<marker::Mut<'a>, K, V, marker::Internal>,\n            NodeRef<marker::Mut<'a>, K, V, marker::LeafOrInternal>,\n        ) -> R,\n        R,\n    >(\n        self,\n        result: F,\n    ) -> R {\n        let Handle { node: mut parent_node, idx: parent_idx, _marker } = self.parent;\n        let old_parent_len = parent_node.len();\n        let mut left_node = self.left_child;\n        let old_left_len = left_node.len();\n        let mut right_node = self.right_child;\n        let right_len = right_node.len();\n        let new_left_len = old_left_len + 1 + right_len;\n\n        assert!(new_left_len <= CAPACITY);\n\n        unsafe {\n            *left_node.len_mut() = new_left_len as u16;\n\n            let parent_key = slice_remove(parent_node.key_area_mut(..old_parent_len), parent_idx);\n            left_node.key_area_mut(old_left_len).write(parent_key);\n            move_to_slice(\n                right_node.key_area_mut(..right_len),\n                left_node.key_area_mut(old_left_len + 1..new_left_len),\n            );\n\n            let parent_val = slice_remove(parent_node.val_area_mut(..old_parent_len), parent_idx);\n            left_node.val_area_mut(old_left_len).write(parent_val);\n            move_to_slice(\n                right_node.val_area_mut(..right_len),\n                left_node.val_area_mut(old_left_len + 1..new_left_len),\n            );\n\n            slice_remove(&mut parent_node.edge_area_mut(..old_parent_len + 1), parent_idx + 1);\n            parent_node.correct_childrens_parent_links(parent_idx + 1..old_parent_len);\n            *parent_node.len_mut() -= 1;\n\n            if parent_node.height > 1 {\n                // SAFETY: the height of the nodes being merged is one below the height\n                // of the node of this edge, thus above zero, so they are internal.\n                let mut left_node = left_node.reborrow_mut().cast_to_internal_unchecked();\n                let mut right_node = right_node.cast_to_internal_unchecked();\n                move_to_slice(\n                    right_node.edge_area_mut(..right_len + 1),\n                    left_node.edge_area_mut(old_left_len + 1..new_left_len + 1),\n                );\n\n                left_node.correct_childrens_parent_links(old_left_len + 1..new_left_len + 1);\n\n                Global.deallocate(right_node.node.cast(), Layout::new::<InternalNode<K, V>>());\n            } else {\n                Global.deallocate(right_node.node.cast(), Layout::new::<LeafNode<K, V>>());\n            }\n        }\n        result(parent_node, left_node)\n    }\n\n    /// Merges the parent's key-value pair and both adjacent child nodes into\n    /// the left child node and returns the shrunk parent node.\n    ///\n    /// Panics unless we `.can_merge()`.\n    pub fn merge_tracking_parent(self) -> NodeRef<marker::Mut<'a>, K, V, marker::Internal> {\n        self.do_merge(|parent, _child| parent)\n    }\n\n    /// Merges the parent's key-value pair and both adjacent child nodes into\n    /// the left child node and returns that child node.\n    ///\n    /// Panics unless we `.can_merge()`.\n    pub fn merge_tracking_child(self) -> NodeRef<marker::Mut<'a>, K, V, marker::LeafOrInternal> {\n        self.do_merge(|_parent, child| child)\n    }\n\n    /// Merges the parent's key-value pair and both adjacent child nodes into\n    /// the left child node and returns the edge handle in that child node\n    /// where the tracked child edge ended up,\n    ///\n    /// Panics unless we `.can_merge()`.\n    pub fn merge_tracking_child_edge(\n        self,\n        track_edge_idx: LeftOrRight<usize>,\n    ) -> Handle<NodeRef<marker::Mut<'a>, K, V, marker::LeafOrInternal>, marker::Edge> {\n        let old_left_len = self.left_child.len();\n        let right_len = self.right_child.len();\n        assert!(match track_edge_idx {\n            LeftOrRight::Left(idx) => idx <= old_left_len,\n            LeftOrRight::Right(idx) => idx <= right_len,\n        });\n        let child = self.merge_tracking_child();\n        let new_idx = match track_edge_idx {\n            LeftOrRight::Left(idx) => idx,\n            LeftOrRight::Right(idx) => old_left_len + 1 + idx,\n        };\n        unsafe { Handle::new_edge(child, new_idx) }\n    }\n\n    /// Removes a key-value pair from the left child and places it in the key-value storage\n    /// of the parent, while pushing the old parent key-value pair into the right child.\n    /// Returns a handle to the edge in the right child corresponding to where the original\n    /// edge specified by `track_right_edge_idx` ended up.\n    pub fn steal_left(\n        mut self,\n        track_right_edge_idx: usize,\n    ) -> Handle<NodeRef<marker::Mut<'a>, K, V, marker::LeafOrInternal>, marker::Edge> {\n        self.bulk_steal_left(1);\n        unsafe { Handle::new_edge(self.right_child, 1 + track_right_edge_idx) }\n    }\n\n    /// Removes a key-value pair from the right child and places it in the key-value storage\n    /// of the parent, while pushing the old parent key-value pair onto the left child.\n    /// Returns a handle to the edge in the left child specified by `track_left_edge_idx`,\n    /// which didn't move.\n    pub fn steal_right(\n        mut self,\n        track_left_edge_idx: usize,\n    ) -> Handle<NodeRef<marker::Mut<'a>, K, V, marker::LeafOrInternal>, marker::Edge> {\n        self.bulk_steal_right(1);\n        unsafe { Handle::new_edge(self.left_child, track_left_edge_idx) }\n    }\n\n    /// This does stealing similar to `steal_left` but steals multiple elements at once.\n    pub fn bulk_steal_left(&mut self, count: usize) {\n        assert!(count > 0);\n        unsafe {\n            let left_node = &mut self.left_child;\n            let old_left_len = left_node.len();\n            let right_node = &mut self.right_child;\n            let old_right_len = right_node.len();\n\n            // Make sure that we may steal safely.\n            assert!(old_right_len + count <= CAPACITY);\n            assert!(old_left_len >= count);\n\n            let new_left_len = old_left_len - count;\n            let new_right_len = old_right_len + count;\n            *left_node.len_mut() = new_left_len as u16;\n            *right_node.len_mut() = new_right_len as u16;\n\n            // Move leaf data.\n            {\n                // Make room for stolen elements in the right child.\n                slice_shr(right_node.key_area_mut(..new_right_len), count);\n                slice_shr(right_node.val_area_mut(..new_right_len), count);\n\n                // Move elements from the left child to the right one.\n                move_to_slice(\n                    left_node.key_area_mut(new_left_len + 1..old_left_len),\n                    right_node.key_area_mut(..count - 1),\n                );\n                move_to_slice(\n                    left_node.val_area_mut(new_left_len + 1..old_left_len),\n                    right_node.val_area_mut(..count - 1),\n                );\n\n                // Move the left-most stolen pair to the parent.\n                let k = left_node.key_area_mut(new_left_len).assume_init_read();\n                let v = left_node.val_area_mut(new_left_len).assume_init_read();\n                let (k, v) = self.parent.replace_kv(k, v);\n\n                // Move parent's key-value pair to the right child.\n                right_node.key_area_mut(count - 1).write(k);\n                right_node.val_area_mut(count - 1).write(v);\n            }\n\n            match (left_node.reborrow_mut().force(), right_node.reborrow_mut().force()) {\n                (ForceResult::Internal(mut left), ForceResult::Internal(mut right)) => {\n                    // Make room for stolen edges.\n                    slice_shr(right.edge_area_mut(..new_right_len + 1), count);\n\n                    // Steal edges.\n                    move_to_slice(\n                        left.edge_area_mut(new_left_len + 1..old_left_len + 1),\n                        right.edge_area_mut(..count),\n                    );\n\n                    right.correct_childrens_parent_links(0..new_right_len + 1);\n                }\n                (ForceResult::Leaf(_), ForceResult::Leaf(_)) => {}\n                _ => unreachable!(),\n            }\n        }\n    }\n\n    /// The symmetric clone of `bulk_steal_left`.\n    pub fn bulk_steal_right(&mut self, count: usize) {\n        assert!(count > 0);\n        unsafe {\n            let left_node = &mut self.left_child;\n            let old_left_len = left_node.len();\n            let right_node = &mut self.right_child;\n            let old_right_len = right_node.len();\n\n            // Make sure that we may steal safely.\n            assert!(old_left_len + count <= CAPACITY);\n            assert!(old_right_len >= count);\n\n            let new_left_len = old_left_len + count;\n            let new_right_len = old_right_len - count;\n            *left_node.len_mut() = new_left_len as u16;\n            *right_node.len_mut() = new_right_len as u16;\n\n            // Move leaf data.\n            {\n                // Move the right-most stolen pair to the parent.\n                let k = right_node.key_area_mut(count - 1).assume_init_read();\n                let v = right_node.val_area_mut(count - 1).assume_init_read();\n                let (k, v) = self.parent.replace_kv(k, v);\n\n                // Move parent's key-value pair to the left child.\n                left_node.key_area_mut(old_left_len).write(k);\n                left_node.val_area_mut(old_left_len).write(v);\n\n                // Move elements from the right child to the left one.\n                move_to_slice(\n                    right_node.key_area_mut(..count - 1),\n                    left_node.key_area_mut(old_left_len + 1..new_left_len),\n                );\n                move_to_slice(\n                    right_node.val_area_mut(..count - 1),\n                    left_node.val_area_mut(old_left_len + 1..new_left_len),\n                );\n\n                // Fill gap where stolen elements used to be.\n                slice_shl(right_node.key_area_mut(..old_right_len), count);\n                slice_shl(right_node.val_area_mut(..old_right_len), count);\n            }\n\n            match (left_node.reborrow_mut().force(), right_node.reborrow_mut().force()) {\n                (ForceResult::Internal(mut left), ForceResult::Internal(mut right)) => {\n                    // Steal edges.\n                    move_to_slice(\n                        right.edge_area_mut(..count),\n                        left.edge_area_mut(old_left_len + 1..new_left_len + 1),\n                    );\n\n                    // Fill gap where stolen edges used to be.\n                    slice_shl(right.edge_area_mut(..old_right_len + 1), count);\n\n                    left.correct_childrens_parent_links(old_left_len + 1..new_left_len + 1);\n                    right.correct_childrens_parent_links(0..new_right_len + 1);\n                }\n                (ForceResult::Leaf(_), ForceResult::Leaf(_)) => {}\n                _ => unreachable!(),\n            }\n        }\n    }\n}\n\nimpl<BorrowType, K, V> Handle<NodeRef<BorrowType, K, V, marker::Leaf>, marker::Edge> {\n    pub fn forget_node_type(\n        self,\n    ) -> Handle<NodeRef<BorrowType, K, V, marker::LeafOrInternal>, marker::Edge> {\n        unsafe { Handle::new_edge(self.node.forget_type(), self.idx) }\n    }\n}\n\nimpl<BorrowType, K, V> Handle<NodeRef<BorrowType, K, V, marker::Internal>, marker::Edge> {\n    pub fn forget_node_type(\n        self,\n    ) -> Handle<NodeRef<BorrowType, K, V, marker::LeafOrInternal>, marker::Edge> {\n        unsafe { Handle::new_edge(self.node.forget_type(), self.idx) }\n    }\n}\n\nimpl<BorrowType, K, V> Handle<NodeRef<BorrowType, K, V, marker::Leaf>, marker::KV> {\n    pub fn forget_node_type(\n        self,\n    ) -> Handle<NodeRef<BorrowType, K, V, marker::LeafOrInternal>, marker::KV> {\n        unsafe { Handle::new_kv(self.node.forget_type(), self.idx) }\n    }\n}\n\nimpl<BorrowType, K, V> Handle<NodeRef<BorrowType, K, V, marker::Internal>, marker::KV> {\n    pub fn forget_node_type(\n        self,\n    ) -> Handle<NodeRef<BorrowType, K, V, marker::LeafOrInternal>, marker::KV> {\n        unsafe { Handle::new_kv(self.node.forget_type(), self.idx) }\n    }\n}\n\nimpl<BorrowType, K, V, Type> Handle<NodeRef<BorrowType, K, V, marker::LeafOrInternal>, Type> {\n    /// Checks whether the underlying node is an `Internal` node or a `Leaf` node.\n    pub fn force(\n        self,\n    ) -> ForceResult<\n        Handle<NodeRef<BorrowType, K, V, marker::Leaf>, Type>,\n        Handle<NodeRef<BorrowType, K, V, marker::Internal>, Type>,\n    > {\n        match self.node.force() {\n            ForceResult::Leaf(node) => {\n                ForceResult::Leaf(Handle { node, idx: self.idx, _marker: PhantomData })\n            }\n            ForceResult::Internal(node) => {\n                ForceResult::Internal(Handle { node, idx: self.idx, _marker: PhantomData })\n            }\n        }\n    }\n}\n\nimpl<'a, K, V, Type> Handle<NodeRef<marker::Mut<'a>, K, V, marker::LeafOrInternal>, Type> {\n    /// Unsafely asserts to the compiler the static information that the handle's node is a `Leaf`.\n    pub unsafe fn cast_to_leaf_unchecked(\n        self,\n    ) -> Handle<NodeRef<marker::Mut<'a>, K, V, marker::Leaf>, Type> {\n        let node = unsafe { self.node.cast_to_leaf_unchecked() };\n        Handle { node, idx: self.idx, _marker: PhantomData }\n    }\n}\n\nimpl<'a, K, V> Handle<NodeRef<marker::Mut<'a>, K, V, marker::LeafOrInternal>, marker::Edge> {\n    /// Move the suffix after `self` from one node to another one. `right` must be empty.\n    /// The first edge of `right` remains unchanged.\n    pub fn move_suffix(\n        &mut self,\n        right: &mut NodeRef<marker::Mut<'a>, K, V, marker::LeafOrInternal>,\n    ) {\n        unsafe {\n            let new_left_len = self.idx;\n            let mut left_node = self.reborrow_mut().into_node();\n            let old_left_len = left_node.len();\n\n            let new_right_len = old_left_len - new_left_len;\n            let mut right_node = right.reborrow_mut();\n\n            assert!(right_node.len() == 0);\n            assert!(left_node.height == right_node.height);\n\n            if new_right_len > 0 {\n                *left_node.len_mut() = new_left_len as u16;\n                *right_node.len_mut() = new_right_len as u16;\n\n                move_to_slice(\n                    left_node.key_area_mut(new_left_len..old_left_len),\n                    right_node.key_area_mut(..new_right_len),\n                );\n                move_to_slice(\n                    left_node.val_area_mut(new_left_len..old_left_len),\n                    right_node.val_area_mut(..new_right_len),\n                );\n                match (left_node.force(), right_node.force()) {\n                    (ForceResult::Internal(mut left), ForceResult::Internal(mut right)) => {\n                        move_to_slice(\n                            left.edge_area_mut(new_left_len + 1..old_left_len + 1),\n                            right.edge_area_mut(1..new_right_len + 1),\n                        );\n                        right.correct_childrens_parent_links(1..new_right_len + 1);\n                    }\n                    (ForceResult::Leaf(_), ForceResult::Leaf(_)) => {}\n                    _ => unreachable!(),\n                }\n            }\n        }\n    }\n}\n\npub enum ForceResult<Leaf, Internal> {\n    Leaf(Leaf),\n    Internal(Internal),\n}\n\n/// Result of insertion, when a node needed to expand beyond its capacity.\npub struct SplitResult<'a, K, V, NodeType> {\n    // Altered node in existing tree with elements and edges that belong to the left of `kv`.\n    pub left: NodeRef<marker::Mut<'a>, K, V, NodeType>,\n    // Some key and value split off, to be inserted elsewhere.\n    pub kv: (K, V),\n    // Owned, unattached, new node with elements and edges that belong to the right of `kv`.\n    pub right: NodeRef<marker::Owned, K, V, NodeType>,\n}\n\nimpl<'a, K, V> SplitResult<'a, K, V, marker::Leaf> {\n    pub fn forget_node_type(self) -> SplitResult<'a, K, V, marker::LeafOrInternal> {\n        SplitResult { left: self.left.forget_type(), kv: self.kv, right: self.right.forget_type() }\n    }\n}\n\nimpl<'a, K, V> SplitResult<'a, K, V, marker::Internal> {\n    pub fn forget_node_type(self) -> SplitResult<'a, K, V, marker::LeafOrInternal> {\n        SplitResult { left: self.left.forget_type(), kv: self.kv, right: self.right.forget_type() }\n    }\n}\n\npub enum InsertResult<'a, K, V, NodeType> {\n    Fit(Handle<NodeRef<marker::Mut<'a>, K, V, NodeType>, marker::KV>),\n    Split(SplitResult<'a, K, V, NodeType>),\n}\n\npub mod marker {\n    use core::marker::PhantomData;\n\n    pub enum Leaf {}\n    pub enum Internal {}\n    pub enum LeafOrInternal {}\n\n    pub enum Owned {}\n    pub enum Dying {}\n    pub struct Immut<'a>(PhantomData<&'a ()>);\n    pub struct Mut<'a>(PhantomData<&'a mut ()>);\n    pub struct ValMut<'a>(PhantomData<&'a mut ()>);\n\n    pub trait BorrowType {\n        // Whether node references of this borrow type allow traversing\n        // to other nodes in the tree.\n        const PERMITS_TRAVERSAL: bool = true;\n    }\n    impl BorrowType for Owned {\n        // Traversal isn't needede, it happens using the result of `borrow_mut`.\n        // By disabling traversal, and only creating new references to roots,\n        // we know that every reference of the `Owned` type is to a root node.\n        const PERMITS_TRAVERSAL: bool = false;\n    }\n    impl BorrowType for Dying {}\n    impl<'a> BorrowType for Immut<'a> {}\n    impl<'a> BorrowType for Mut<'a> {}\n    impl<'a> BorrowType for ValMut<'a> {}\n\n    pub enum KV {}\n    pub enum Edge {}\n}\n\n/// Inserts a value into a slice of initialized elements followed by one uninitialized element.\n///\n/// # Safety\n/// The slice has more than `idx` elements.\nunsafe fn slice_insert<T>(slice: &mut [MaybeUninit<T>], idx: usize, val: T) {\n    unsafe {\n        let len = slice.len();\n        debug_assert!(len > idx);\n        let slice_ptr = slice.as_mut_ptr();\n        if len > idx + 1 {\n            ptr::copy(slice_ptr.add(idx), slice_ptr.add(idx + 1), len - idx - 1);\n        }\n        (*slice_ptr.add(idx)).write(val);\n    }\n}\n\n/// Removes and returns a value from a slice of all initialized elements, leaving behind one\n/// trailing uninitialized element.\n///\n/// # Safety\n/// The slice has more than `idx` elements.\nunsafe fn slice_remove<T>(slice: &mut [MaybeUninit<T>], idx: usize) -> T {\n    unsafe {\n        let len = slice.len();\n        debug_assert!(idx < len);\n        let slice_ptr = slice.as_mut_ptr();\n        let ret = (*slice_ptr.add(idx)).assume_init_read();\n        ptr::copy(slice_ptr.add(idx + 1), slice_ptr.add(idx), len - idx - 1);\n        ret\n    }\n}\n\n/// Shifts the elements in a slice `distance` positions to the left.\n///\n/// # Safety\n/// The slice has at least `distance` elements.\nunsafe fn slice_shl<T>(slice: &mut [MaybeUninit<T>], distance: usize) {\n    unsafe {\n        let slice_ptr = slice.as_mut_ptr();\n        ptr::copy(slice_ptr.add(distance), slice_ptr, slice.len() - distance);\n    }\n}\n\n/// Shifts the elements in a slice `distance` positions to the right.\n///\n/// # Safety\n/// The slice has at least `distance` elements.\nunsafe fn slice_shr<T>(slice: &mut [MaybeUninit<T>], distance: usize) {\n    unsafe {\n        let slice_ptr = slice.as_mut_ptr();\n        ptr::copy(slice_ptr, slice_ptr.add(distance), slice.len() - distance);\n    }\n}\n\n/// Moves all values from a slice of initialized elements to a slice\n/// of uninitialized elements, leaving behind `src` as all uninitialized.\n/// Works like `dst.copy_from_slice(src)` but does not require `T` to be `Copy`.\nfn move_to_slice<T>(src: &mut [MaybeUninit<T>], dst: &mut [MaybeUninit<T>]) {\n    assert!(src.len() == dst.len());\n    unsafe {\n        ptr::copy_nonoverlapping(src.as_ptr(), dst.as_mut_ptr(), src.len());\n    }\n}\n\n#[cfg(test)]\nmod tests;\n"],[2035,"use super::node::{ForceResult::*, Root};\nuse super::search::SearchResult::*;\nuse core::borrow::Borrow;\n\nimpl<K, V> Root<K, V> {\n    /// Calculates the length of both trees that result from splitting up\n    /// a given number of distinct key-value pairs.\n    pub fn calc_split_length(\n        total_num: usize,\n        root_a: &Root<K, V>,\n        root_b: &Root<K, V>,\n    ) -> (usize, usize) {\n        let (length_a, length_b);\n        if root_a.height() < root_b.height() {\n            length_a = root_a.reborrow().calc_length();\n            length_b = total_num - length_a;\n            debug_assert_eq!(length_b, root_b.reborrow().calc_length());\n        } else {\n            length_b = root_b.reborrow().calc_length();\n            length_a = total_num - length_b;\n            debug_assert_eq!(length_a, root_a.reborrow().calc_length());\n        }\n        (length_a, length_b)\n    }\n\n    /// Split off a tree with key-value pairs at and after the given key.\n    /// The result is meaningful only if the tree is ordered by key,\n    /// and if the ordering of `Q` corresponds to that of `K`.\n    /// If `self` respects all `BTreeMap` tree invariants, then both\n    /// `self` and the returned tree will respect those invariants.\n    pub fn split_off<Q: ?Sized + Ord>(&mut self, key: &Q) -> Self\n    where\n        K: Borrow<Q>,\n    {\n        let left_root = self;\n        let mut right_root = Root::new_pillar(left_root.height());\n        let mut left_node = left_root.borrow_mut();\n        let mut right_node = right_root.borrow_mut();\n\n        loop {\n            let mut split_edge = match left_node.search_node(key) {\n                // key is going to the right tree\n                Found(kv) => kv.left_edge(),\n                GoDown(edge) => edge,\n            };\n\n            split_edge.move_suffix(&mut right_node);\n\n            match (split_edge.force(), right_node.force()) {\n                (Internal(edge), Internal(node)) => {\n                    left_node = edge.descend();\n                    right_node = node.first_edge().descend();\n                }\n                (Leaf(_), Leaf(_)) => break,\n                _ => unreachable!(),\n            }\n        }\n\n        left_root.fix_right_border();\n        right_root.fix_left_border();\n        right_root\n    }\n\n    /// Creates a tree consisting of empty nodes.\n    fn new_pillar(height: usize) -> Self {\n        let mut root = Root::new();\n        for _ in 0..height {\n            root.push_internal_level();\n        }\n        root\n    }\n}\n"],[2036,"use super::super::testing::crash_test::{CrashTestDummy, Panic};\nuse super::super::testing::rng::DeterministicRng;\nuse super::*;\nuse crate::vec::Vec;\nuse std::cmp::Ordering;\nuse std::iter::FromIterator;\nuse std::panic::{catch_unwind, AssertUnwindSafe};\n\n#[test]\nfn test_clone_eq() {\n    let mut m = BTreeSet::new();\n\n    m.insert(1);\n    m.insert(2);\n\n    assert_eq!(m.clone(), m);\n}\n\n#[allow(dead_code)]\nfn test_const() {\n    const SET: &'static BTreeSet<()> = &BTreeSet::new();\n    const LEN: usize = SET.len();\n    const IS_EMPTY: bool = SET.is_empty();\n}\n\n#[test]\nfn test_iter_min_max() {\n    let mut a = BTreeSet::new();\n    assert_eq!(a.iter().min(), None);\n    assert_eq!(a.iter().max(), None);\n    assert_eq!(a.range(..).min(), None);\n    assert_eq!(a.range(..).max(), None);\n    assert_eq!(a.difference(&BTreeSet::new()).min(), None);\n    assert_eq!(a.difference(&BTreeSet::new()).max(), None);\n    assert_eq!(a.intersection(&a).min(), None);\n    assert_eq!(a.intersection(&a).max(), None);\n    assert_eq!(a.symmetric_difference(&BTreeSet::new()).min(), None);\n    assert_eq!(a.symmetric_difference(&BTreeSet::new()).max(), None);\n    assert_eq!(a.union(&a).min(), None);\n    assert_eq!(a.union(&a).max(), None);\n    a.insert(1);\n    a.insert(2);\n    assert_eq!(a.iter().min(), Some(&1));\n    assert_eq!(a.iter().max(), Some(&2));\n    assert_eq!(a.range(..).min(), Some(&1));\n    assert_eq!(a.range(..).max(), Some(&2));\n    assert_eq!(a.difference(&BTreeSet::new()).min(), Some(&1));\n    assert_eq!(a.difference(&BTreeSet::new()).max(), Some(&2));\n    assert_eq!(a.intersection(&a).min(), Some(&1));\n    assert_eq!(a.intersection(&a).max(), Some(&2));\n    assert_eq!(a.symmetric_difference(&BTreeSet::new()).min(), Some(&1));\n    assert_eq!(a.symmetric_difference(&BTreeSet::new()).max(), Some(&2));\n    assert_eq!(a.union(&a).min(), Some(&1));\n    assert_eq!(a.union(&a).max(), Some(&2));\n}\n\nfn check<F>(a: &[i32], b: &[i32], expected: &[i32], f: F)\nwhere\n    F: FnOnce(&BTreeSet<i32>, &BTreeSet<i32>, &mut dyn FnMut(&i32) -> bool) -> bool,\n{\n    let mut set_a = BTreeSet::new();\n    let mut set_b = BTreeSet::new();\n\n    for x in a {\n        assert!(set_a.insert(*x))\n    }\n    for y in b {\n        assert!(set_b.insert(*y))\n    }\n\n    let mut i = 0;\n    f(&set_a, &set_b, &mut |&x| {\n        if i < expected.len() {\n            assert_eq!(x, expected[i]);\n        }\n        i += 1;\n        true\n    });\n    assert_eq!(i, expected.len());\n}\n\n#[test]\nfn test_intersection() {\n    fn check_intersection(a: &[i32], b: &[i32], expected: &[i32]) {\n        check(a, b, expected, |x, y, f| x.intersection(y).all(f))\n    }\n\n    check_intersection(&[], &[], &[]);\n    check_intersection(&[1, 2, 3], &[], &[]);\n    check_intersection(&[], &[1, 2, 3], &[]);\n    check_intersection(&[2], &[1, 2, 3], &[2]);\n    check_intersection(&[1, 2, 3], &[2], &[2]);\n    check_intersection(&[11, 1, 3, 77, 103, 5, -5], &[2, 11, 77, -9, -42, 5, 3], &[3, 5, 11, 77]);\n\n    if cfg!(miri) {\n        // Miri is too slow\n        return;\n    }\n\n    let large = (0..100).collect::<Vec<_>>();\n    check_intersection(&[], &large, &[]);\n    check_intersection(&large, &[], &[]);\n    check_intersection(&[-1], &large, &[]);\n    check_intersection(&large, &[-1], &[]);\n    check_intersection(&[0], &large, &[0]);\n    check_intersection(&large, &[0], &[0]);\n    check_intersection(&[99], &large, &[99]);\n    check_intersection(&large, &[99], &[99]);\n    check_intersection(&[100], &large, &[]);\n    check_intersection(&large, &[100], &[]);\n    check_intersection(&[11, 5000, 1, 3, 77, 8924], &large, &[1, 3, 11, 77]);\n}\n\n#[test]\nfn test_intersection_size_hint() {\n    let x: BTreeSet<i32> = [3, 4].iter().copied().collect();\n    let y: BTreeSet<i32> = [1, 2, 3].iter().copied().collect();\n    let mut iter = x.intersection(&y);\n    assert_eq!(iter.size_hint(), (1, Some(1)));\n    assert_eq!(iter.next(), Some(&3));\n    assert_eq!(iter.size_hint(), (0, Some(0)));\n    assert_eq!(iter.next(), None);\n\n    iter = y.intersection(&y);\n    assert_eq!(iter.size_hint(), (0, Some(3)));\n    assert_eq!(iter.next(), Some(&1));\n    assert_eq!(iter.size_hint(), (0, Some(2)));\n}\n\n#[test]\nfn test_difference() {\n    fn check_difference(a: &[i32], b: &[i32], expected: &[i32]) {\n        check(a, b, expected, |x, y, f| x.difference(y).all(f))\n    }\n\n    check_difference(&[], &[], &[]);\n    check_difference(&[1, 12], &[], &[1, 12]);\n    check_difference(&[], &[1, 2, 3, 9], &[]);\n    check_difference(&[1, 3, 5, 9, 11], &[3, 9], &[1, 5, 11]);\n    check_difference(&[1, 3, 5, 9, 11], &[3, 6, 9], &[1, 5, 11]);\n    check_difference(&[1, 3, 5, 9, 11], &[0, 1], &[3, 5, 9, 11]);\n    check_difference(&[1, 3, 5, 9, 11], &[11, 12], &[1, 3, 5, 9]);\n    check_difference(\n        &[-5, 11, 22, 33, 40, 42],\n        &[-12, -5, 14, 23, 34, 38, 39, 50],\n        &[11, 22, 33, 40, 42],\n    );\n\n    if cfg!(miri) {\n        // Miri is too slow\n        return;\n    }\n\n    let large = (0..100).collect::<Vec<_>>();\n    check_difference(&[], &large, &[]);\n    check_difference(&[-1], &large, &[-1]);\n    check_difference(&[0], &large, &[]);\n    check_difference(&[99], &large, &[]);\n    check_difference(&[100], &large, &[100]);\n    check_difference(&[11, 5000, 1, 3, 77, 8924], &large, &[5000, 8924]);\n    check_difference(&large, &[], &large);\n    check_difference(&large, &[-1], &large);\n    check_difference(&large, &[100], &large);\n}\n\n#[test]\nfn test_difference_size_hint() {\n    let s246: BTreeSet<i32> = [2, 4, 6].iter().copied().collect();\n    let s23456: BTreeSet<i32> = (2..=6).collect();\n    let mut iter = s246.difference(&s23456);\n    assert_eq!(iter.size_hint(), (0, Some(3)));\n    assert_eq!(iter.next(), None);\n\n    let s12345: BTreeSet<i32> = (1..=5).collect();\n    iter = s246.difference(&s12345);\n    assert_eq!(iter.size_hint(), (0, Some(3)));\n    assert_eq!(iter.next(), Some(&6));\n    assert_eq!(iter.size_hint(), (0, Some(0)));\n    assert_eq!(iter.next(), None);\n\n    let s34567: BTreeSet<i32> = (3..=7).collect();\n    iter = s246.difference(&s34567);\n    assert_eq!(iter.size_hint(), (0, Some(3)));\n    assert_eq!(iter.next(), Some(&2));\n    assert_eq!(iter.size_hint(), (0, Some(2)));\n    assert_eq!(iter.next(), None);\n\n    let s1: BTreeSet<i32> = (-9..=1).collect();\n    iter = s246.difference(&s1);\n    assert_eq!(iter.size_hint(), (3, Some(3)));\n\n    let s2: BTreeSet<i32> = (-9..=2).collect();\n    iter = s246.difference(&s2);\n    assert_eq!(iter.size_hint(), (2, Some(2)));\n    assert_eq!(iter.next(), Some(&4));\n    assert_eq!(iter.size_hint(), (1, Some(1)));\n\n    let s23: BTreeSet<i32> = (2..=3).collect();\n    iter = s246.difference(&s23);\n    assert_eq!(iter.size_hint(), (1, Some(3)));\n    assert_eq!(iter.next(), Some(&4));\n    assert_eq!(iter.size_hint(), (1, Some(1)));\n\n    let s4: BTreeSet<i32> = (4..=4).collect();\n    iter = s246.difference(&s4);\n    assert_eq!(iter.size_hint(), (2, Some(3)));\n    assert_eq!(iter.next(), Some(&2));\n    assert_eq!(iter.size_hint(), (1, Some(2)));\n    assert_eq!(iter.next(), Some(&6));\n    assert_eq!(iter.size_hint(), (0, Some(0)));\n    assert_eq!(iter.next(), None);\n\n    let s56: BTreeSet<i32> = (5..=6).collect();\n    iter = s246.difference(&s56);\n    assert_eq!(iter.size_hint(), (1, Some(3)));\n    assert_eq!(iter.next(), Some(&2));\n    assert_eq!(iter.size_hint(), (0, Some(2)));\n\n    let s6: BTreeSet<i32> = (6..=19).collect();\n    iter = s246.difference(&s6);\n    assert_eq!(iter.size_hint(), (2, Some(2)));\n    assert_eq!(iter.next(), Some(&2));\n    assert_eq!(iter.size_hint(), (1, Some(1)));\n\n    let s7: BTreeSet<i32> = (7..=19).collect();\n    iter = s246.difference(&s7);\n    assert_eq!(iter.size_hint(), (3, Some(3)));\n}\n\n#[test]\nfn test_symmetric_difference() {\n    fn check_symmetric_difference(a: &[i32], b: &[i32], expected: &[i32]) {\n        check(a, b, expected, |x, y, f| x.symmetric_difference(y).all(f))\n    }\n\n    check_symmetric_difference(&[], &[], &[]);\n    check_symmetric_difference(&[1, 2, 3], &[2], &[1, 3]);\n    check_symmetric_difference(&[2], &[1, 2, 3], &[1, 3]);\n    check_symmetric_difference(&[1, 3, 5, 9, 11], &[-2, 3, 9, 14, 22], &[-2, 1, 5, 11, 14, 22]);\n}\n\n#[test]\nfn test_symmetric_difference_size_hint() {\n    let x: BTreeSet<i32> = [2, 4].iter().copied().collect();\n    let y: BTreeSet<i32> = [1, 2, 3].iter().copied().collect();\n    let mut iter = x.symmetric_difference(&y);\n    assert_eq!(iter.size_hint(), (0, Some(5)));\n    assert_eq!(iter.next(), Some(&1));\n    assert_eq!(iter.size_hint(), (0, Some(4)));\n    assert_eq!(iter.next(), Some(&3));\n    assert_eq!(iter.size_hint(), (0, Some(1)));\n}\n\n#[test]\nfn test_union() {\n    fn check_union(a: &[i32], b: &[i32], expected: &[i32]) {\n        check(a, b, expected, |x, y, f| x.union(y).all(f))\n    }\n\n    check_union(&[], &[], &[]);\n    check_union(&[1, 2, 3], &[2], &[1, 2, 3]);\n    check_union(&[2], &[1, 2, 3], &[1, 2, 3]);\n    check_union(\n        &[1, 3, 5, 9, 11, 16, 19, 24],\n        &[-2, 1, 5, 9, 13, 19],\n        &[-2, 1, 3, 5, 9, 11, 13, 16, 19, 24],\n    );\n}\n\n#[test]\nfn test_union_size_hint() {\n    let x: BTreeSet<i32> = [2, 4].iter().copied().collect();\n    let y: BTreeSet<i32> = [1, 2, 3].iter().copied().collect();\n    let mut iter = x.union(&y);\n    assert_eq!(iter.size_hint(), (3, Some(5)));\n    assert_eq!(iter.next(), Some(&1));\n    assert_eq!(iter.size_hint(), (2, Some(4)));\n    assert_eq!(iter.next(), Some(&2));\n    assert_eq!(iter.size_hint(), (1, Some(2)));\n}\n\n#[test]\n// Only tests the simple function definition with respect to intersection\nfn test_is_disjoint() {\n    let one = [1].iter().collect::<BTreeSet<_>>();\n    let two = [2].iter().collect::<BTreeSet<_>>();\n    assert!(one.is_disjoint(&two));\n}\n\n#[test]\n// Also implicitly tests the trivial function definition of is_superset\nfn test_is_subset() {\n    fn is_subset(a: &[i32], b: &[i32]) -> bool {\n        let set_a = a.iter().collect::<BTreeSet<_>>();\n        let set_b = b.iter().collect::<BTreeSet<_>>();\n        set_a.is_subset(&set_b)\n    }\n\n    assert_eq!(is_subset(&[], &[]), true);\n    assert_eq!(is_subset(&[], &[1, 2]), true);\n    assert_eq!(is_subset(&[0], &[1, 2]), false);\n    assert_eq!(is_subset(&[1], &[1, 2]), true);\n    assert_eq!(is_subset(&[2], &[1, 2]), true);\n    assert_eq!(is_subset(&[3], &[1, 2]), false);\n    assert_eq!(is_subset(&[1, 2], &[1]), false);\n    assert_eq!(is_subset(&[1, 2], &[1, 2]), true);\n    assert_eq!(is_subset(&[1, 2], &[2, 3]), false);\n    assert_eq!(\n        is_subset(&[-5, 11, 22, 33, 40, 42], &[-12, -5, 11, 14, 22, 23, 33, 34, 38, 39, 40, 42]),\n        true\n    );\n    assert_eq!(is_subset(&[-5, 11, 22, 33, 40, 42], &[-12, -5, 11, 14, 22, 23, 34, 38]), false);\n\n    if cfg!(miri) {\n        // Miri is too slow\n        return;\n    }\n\n    let large = (0..100).collect::<Vec<_>>();\n    assert_eq!(is_subset(&[], &large), true);\n    assert_eq!(is_subset(&large, &[]), false);\n    assert_eq!(is_subset(&[-1], &large), false);\n    assert_eq!(is_subset(&[0], &large), true);\n    assert_eq!(is_subset(&[1, 2], &large), true);\n    assert_eq!(is_subset(&[99, 100], &large), false);\n}\n\n#[test]\nfn test_retain() {\n    let xs = [1, 2, 3, 4, 5, 6];\n    let mut set: BTreeSet<i32> = xs.iter().cloned().collect();\n    set.retain(|&k| k % 2 == 0);\n    assert_eq!(set.len(), 3);\n    assert!(set.contains(&2));\n    assert!(set.contains(&4));\n    assert!(set.contains(&6));\n}\n\n#[test]\nfn test_drain_filter() {\n    let mut x: BTreeSet<_> = [1].iter().copied().collect();\n    let mut y: BTreeSet<_> = [1].iter().copied().collect();\n\n    x.drain_filter(|_| true);\n    y.drain_filter(|_| false);\n    assert_eq!(x.len(), 0);\n    assert_eq!(y.len(), 1);\n}\n\n#[test]\nfn test_drain_filter_drop_panic_leak() {\n    let a = CrashTestDummy::new(0);\n    let b = CrashTestDummy::new(1);\n    let c = CrashTestDummy::new(2);\n    let mut set = BTreeSet::new();\n    set.insert(a.spawn(Panic::Never));\n    set.insert(b.spawn(Panic::InDrop));\n    set.insert(c.spawn(Panic::Never));\n\n    catch_unwind(move || drop(set.drain_filter(|dummy| dummy.query(true)))).ok();\n\n    assert_eq!(a.queried(), 1);\n    assert_eq!(b.queried(), 1);\n    assert_eq!(c.queried(), 0);\n    assert_eq!(a.dropped(), 1);\n    assert_eq!(b.dropped(), 1);\n    assert_eq!(c.dropped(), 1);\n}\n\n#[test]\nfn test_drain_filter_pred_panic_leak() {\n    let a = CrashTestDummy::new(0);\n    let b = CrashTestDummy::new(1);\n    let c = CrashTestDummy::new(2);\n    let mut set = BTreeSet::new();\n    set.insert(a.spawn(Panic::Never));\n    set.insert(b.spawn(Panic::InQuery));\n    set.insert(c.spawn(Panic::InQuery));\n\n    catch_unwind(AssertUnwindSafe(|| drop(set.drain_filter(|dummy| dummy.query(true))))).ok();\n\n    assert_eq!(a.queried(), 1);\n    assert_eq!(b.queried(), 1);\n    assert_eq!(c.queried(), 0);\n    assert_eq!(a.dropped(), 1);\n    assert_eq!(b.dropped(), 0);\n    assert_eq!(c.dropped(), 0);\n    assert_eq!(set.len(), 2);\n    assert_eq!(set.first().unwrap().id(), 1);\n    assert_eq!(set.last().unwrap().id(), 2);\n}\n\n#[test]\nfn test_clear() {\n    let mut x = BTreeSet::new();\n    x.insert(1);\n\n    x.clear();\n    assert!(x.is_empty());\n}\n\n#[test]\nfn test_zip() {\n    let mut x = BTreeSet::new();\n    x.insert(5);\n    x.insert(12);\n    x.insert(11);\n\n    let mut y = BTreeSet::new();\n    y.insert(\"foo\");\n    y.insert(\"bar\");\n\n    let x = x;\n    let y = y;\n    let mut z = x.iter().zip(&y);\n\n    assert_eq!(z.next().unwrap(), (&5, &(\"bar\")));\n    assert_eq!(z.next().unwrap(), (&11, &(\"foo\")));\n    assert!(z.next().is_none());\n}\n\n#[test]\nfn test_from_iter() {\n    let xs = [1, 2, 3, 4, 5, 6, 7, 8, 9];\n\n    let set: BTreeSet<_> = xs.iter().cloned().collect();\n\n    for x in &xs {\n        assert!(set.contains(x));\n    }\n}\n\n#[test]\nfn test_show() {\n    let mut set = BTreeSet::new();\n    let empty = BTreeSet::<i32>::new();\n\n    set.insert(1);\n    set.insert(2);\n\n    let set_str = format!(\"{:?}\", set);\n\n    assert_eq!(set_str, \"{1, 2}\");\n    assert_eq!(format!(\"{:?}\", empty), \"{}\");\n}\n\n#[test]\nfn test_extend_ref() {\n    let mut a = BTreeSet::new();\n    a.insert(1);\n\n    a.extend(&[2, 3, 4]);\n\n    assert_eq!(a.len(), 4);\n    assert!(a.contains(&1));\n    assert!(a.contains(&2));\n    assert!(a.contains(&3));\n    assert!(a.contains(&4));\n\n    let mut b = BTreeSet::new();\n    b.insert(5);\n    b.insert(6);\n\n    a.extend(&b);\n\n    assert_eq!(a.len(), 6);\n    assert!(a.contains(&1));\n    assert!(a.contains(&2));\n    assert!(a.contains(&3));\n    assert!(a.contains(&4));\n    assert!(a.contains(&5));\n    assert!(a.contains(&6));\n}\n\n#[test]\nfn test_recovery() {\n    #[derive(Debug)]\n    struct Foo(&'static str, i32);\n\n    impl PartialEq for Foo {\n        fn eq(&self, other: &Self) -> bool {\n            self.0 == other.0\n        }\n    }\n\n    impl Eq for Foo {}\n\n    impl PartialOrd for Foo {\n        fn partial_cmp(&self, other: &Self) -> Option<Ordering> {\n            self.0.partial_cmp(&other.0)\n        }\n    }\n\n    impl Ord for Foo {\n        fn cmp(&self, other: &Self) -> Ordering {\n            self.0.cmp(&other.0)\n        }\n    }\n\n    let mut s = BTreeSet::new();\n    assert_eq!(s.replace(Foo(\"a\", 1)), None);\n    assert_eq!(s.len(), 1);\n    assert_eq!(s.replace(Foo(\"a\", 2)), Some(Foo(\"a\", 1)));\n    assert_eq!(s.len(), 1);\n\n    {\n        let mut it = s.iter();\n        assert_eq!(it.next(), Some(&Foo(\"a\", 2)));\n        assert_eq!(it.next(), None);\n    }\n\n    assert_eq!(s.get(&Foo(\"a\", 1)), Some(&Foo(\"a\", 2)));\n    assert_eq!(s.take(&Foo(\"a\", 1)), Some(Foo(\"a\", 2)));\n    assert_eq!(s.len(), 0);\n\n    assert_eq!(s.get(&Foo(\"a\", 1)), None);\n    assert_eq!(s.take(&Foo(\"a\", 1)), None);\n\n    assert_eq!(s.iter().next(), None);\n}\n\n#[allow(dead_code)]\nfn test_variance() {\n    fn set<'new>(v: BTreeSet<&'static str>) -> BTreeSet<&'new str> {\n        v\n    }\n    fn iter<'a, 'new>(v: Iter<'a, &'static str>) -> Iter<'a, &'new str> {\n        v\n    }\n    fn into_iter<'new>(v: IntoIter<&'static str>) -> IntoIter<&'new str> {\n        v\n    }\n    fn range<'a, 'new>(v: Range<'a, &'static str>) -> Range<'a, &'new str> {\n        v\n    }\n    // not applied to Difference, Intersection, SymmetricDifference, Union\n}\n\n#[allow(dead_code)]\nfn test_sync() {\n    fn set<T: Sync>(v: &BTreeSet<T>) -> impl Sync + '_ {\n        v\n    }\n\n    fn iter<T: Sync>(v: &BTreeSet<T>) -> impl Sync + '_ {\n        v.iter()\n    }\n\n    fn into_iter<T: Sync>(v: BTreeSet<T>) -> impl Sync {\n        v.into_iter()\n    }\n\n    fn range<T: Sync + Ord>(v: &BTreeSet<T>) -> impl Sync + '_ {\n        v.range(..)\n    }\n\n    fn drain_filter<T: Sync + Ord>(v: &mut BTreeSet<T>) -> impl Sync + '_ {\n        v.drain_filter(|_| false)\n    }\n\n    fn difference<T: Sync + Ord>(v: &BTreeSet<T>) -> impl Sync + '_ {\n        v.difference(&v)\n    }\n\n    fn intersection<T: Sync + Ord>(v: &BTreeSet<T>) -> impl Sync + '_ {\n        v.intersection(&v)\n    }\n\n    fn symmetric_difference<T: Sync + Ord>(v: &BTreeSet<T>) -> impl Sync + '_ {\n        v.symmetric_difference(&v)\n    }\n\n    fn union<T: Sync + Ord>(v: &BTreeSet<T>) -> impl Sync + '_ {\n        v.union(&v)\n    }\n}\n\n#[allow(dead_code)]\nfn test_send() {\n    fn set<T: Send>(v: BTreeSet<T>) -> impl Send {\n        v\n    }\n\n    fn iter<T: Send + Sync>(v: &BTreeSet<T>) -> impl Send + '_ {\n        v.iter()\n    }\n\n    fn into_iter<T: Send>(v: BTreeSet<T>) -> impl Send {\n        v.into_iter()\n    }\n\n    fn range<T: Send + Sync + Ord>(v: &BTreeSet<T>) -> impl Send + '_ {\n        v.range(..)\n    }\n\n    fn drain_filter<T: Send + Ord>(v: &mut BTreeSet<T>) -> impl Send + '_ {\n        v.drain_filter(|_| false)\n    }\n\n    fn difference<T: Send + Sync + Ord>(v: &BTreeSet<T>) -> impl Send + '_ {\n        v.difference(&v)\n    }\n\n    fn intersection<T: Send + Sync + Ord>(v: &BTreeSet<T>) -> impl Send + '_ {\n        v.intersection(&v)\n    }\n\n    fn symmetric_difference<T: Send + Sync + Ord>(v: &BTreeSet<T>) -> impl Send + '_ {\n        v.symmetric_difference(&v)\n    }\n\n    fn union<T: Send + Sync + Ord>(v: &BTreeSet<T>) -> impl Send + '_ {\n        v.union(&v)\n    }\n}\n\n#[allow(dead_code)]\nfn test_ord_absence() {\n    fn set<K>(mut set: BTreeSet<K>) {\n        set.is_empty();\n        set.len();\n        set.clear();\n        set.iter();\n        set.into_iter();\n    }\n\n    fn set_debug<K: Debug>(set: BTreeSet<K>) {\n        format!(\"{:?}\", set);\n        format!(\"{:?}\", set.iter());\n        format!(\"{:?}\", set.into_iter());\n    }\n\n    fn set_clone<K: Clone>(mut set: BTreeSet<K>) {\n        set.clone_from(&set.clone());\n    }\n}\n\n#[test]\nfn test_append() {\n    let mut a = BTreeSet::new();\n    a.insert(1);\n    a.insert(2);\n    a.insert(3);\n\n    let mut b = BTreeSet::new();\n    b.insert(3);\n    b.insert(4);\n    b.insert(5);\n\n    a.append(&mut b);\n\n    assert_eq!(a.len(), 5);\n    assert_eq!(b.len(), 0);\n\n    assert_eq!(a.contains(&1), true);\n    assert_eq!(a.contains(&2), true);\n    assert_eq!(a.contains(&3), true);\n    assert_eq!(a.contains(&4), true);\n    assert_eq!(a.contains(&5), true);\n}\n\n#[test]\nfn test_first_last() {\n    let mut a = BTreeSet::new();\n    assert_eq!(a.first(), None);\n    assert_eq!(a.last(), None);\n    a.insert(1);\n    assert_eq!(a.first(), Some(&1));\n    assert_eq!(a.last(), Some(&1));\n    a.insert(2);\n    assert_eq!(a.first(), Some(&1));\n    assert_eq!(a.last(), Some(&2));\n    for i in 3..=12 {\n        a.insert(i);\n    }\n    assert_eq!(a.first(), Some(&1));\n    assert_eq!(a.last(), Some(&12));\n    assert_eq!(a.pop_first(), Some(1));\n    assert_eq!(a.pop_last(), Some(12));\n    assert_eq!(a.pop_first(), Some(2));\n    assert_eq!(a.pop_last(), Some(11));\n    assert_eq!(a.pop_first(), Some(3));\n    assert_eq!(a.pop_last(), Some(10));\n    assert_eq!(a.pop_first(), Some(4));\n    assert_eq!(a.pop_first(), Some(5));\n    assert_eq!(a.pop_first(), Some(6));\n    assert_eq!(a.pop_first(), Some(7));\n    assert_eq!(a.pop_first(), Some(8));\n    assert_eq!(a.clone().pop_last(), Some(9));\n    assert_eq!(a.pop_first(), Some(9));\n    assert_eq!(a.pop_first(), None);\n    assert_eq!(a.pop_last(), None);\n}\n\n// Unlike the function with the same name in map/tests, returns no values.\n// Which also means it returns different predetermined pseudo-random keys,\n// and the test cases using this function explore slightly different trees.\nfn rand_data(len: usize) -> Vec<u32> {\n    let mut rng = DeterministicRng::new();\n    Vec::from_iter((0..len).map(|_| rng.next()))\n}\n\n#[test]\nfn test_split_off_empty_right() {\n    let mut data = rand_data(173);\n\n    let mut set = BTreeSet::from_iter(data.clone());\n    let right = set.split_off(&(data.iter().max().unwrap() + 1));\n\n    data.sort();\n    assert!(set.into_iter().eq(data));\n    assert!(right.into_iter().eq(None));\n}\n\n#[test]\nfn test_split_off_empty_left() {\n    let mut data = rand_data(314);\n\n    let mut set = BTreeSet::from_iter(data.clone());\n    let right = set.split_off(data.iter().min().unwrap());\n\n    data.sort();\n    assert!(set.into_iter().eq(None));\n    assert!(right.into_iter().eq(data));\n}\n\n#[test]\nfn test_split_off_large_random_sorted() {\n    // Miri is too slow\n    let mut data = if cfg!(miri) { rand_data(529) } else { rand_data(1529) };\n    // special case with maximum height.\n    data.sort();\n\n    let mut set = BTreeSet::from_iter(data.clone());\n    let key = data[data.len() / 2];\n    let right = set.split_off(&key);\n\n    assert!(set.into_iter().eq(data.clone().into_iter().filter(|x| *x < key)));\n    assert!(right.into_iter().eq(data.into_iter().filter(|x| *x >= key)));\n}\n"],[2037,"use super::DormantMutRef;\n\n#[test]\nfn test_borrow() {\n    let mut data = 1;\n    let mut stack = vec![];\n    let mut rr = &mut data;\n    for factor in [2, 3, 7].iter() {\n        let (r, dormant_r) = DormantMutRef::new(rr);\n        rr = r;\n        assert_eq!(*rr, 1);\n        stack.push((factor, dormant_r));\n    }\n    while let Some((factor, dormant_r)) = stack.pop() {\n        let r = unsafe { dormant_r.awaken() };\n        *r *= factor;\n    }\n    assert_eq!(data, 42);\n}\n"],[2038,"use core::marker::PhantomData;\nuse core::ptr::NonNull;\n\n/// Models a reborrow of some unique reference, when you know that the reborrow\n/// and all its descendants (i.e., all pointers and references derived from it)\n/// will not be used any more at some point, after which you want to use the\n/// original unique reference again.\n///\n/// The borrow checker usually handles this stacking of borrows for you, but\n/// some control flows that accomplish this stacking are too complicated for\n/// the compiler to follow. A `DormantMutRef` allows you to check borrowing\n/// yourself, while still expressing its stacked nature, and encapsulating\n/// the raw pointer code needed to do this without undefined behavior.\npub struct DormantMutRef<'a, T> {\n    ptr: NonNull<T>,\n    _marker: PhantomData<&'a mut T>,\n}\n\nunsafe impl<'a, T> Sync for DormantMutRef<'a, T> where &'a mut T: Sync {}\nunsafe impl<'a, T> Send for DormantMutRef<'a, T> where &'a mut T: Send {}\n\nimpl<'a, T> DormantMutRef<'a, T> {\n    /// Capture a unique borrow, and immediately reborrow it. For the compiler,\n    /// the lifetime of the new reference is the same as the lifetime of the\n    /// original reference, but you promise to use it for a shorter period.\n    pub fn new(t: &'a mut T) -> (&'a mut T, Self) {\n        let ptr = NonNull::from(t);\n        // SAFETY: we hold the borrow throughout 'a via `_marker`, and we expose\n        // only this reference, so it is unique.\n        let new_ref = unsafe { &mut *ptr.as_ptr() };\n        (new_ref, Self { ptr, _marker: PhantomData })\n    }\n\n    /// Revert to the unique borrow initially captured.\n    ///\n    /// # Safety\n    ///\n    /// The reborrow must have ended, i.e., the reference returned by `new` and\n    /// all pointers and references derived from it, must not be used anymore.\n    pub unsafe fn awaken(self) -> &'a mut T {\n        // SAFETY: our own safety conditions imply this reference is again unique.\n        unsafe { &mut *self.ptr.as_ptr() }\n    }\n}\n\n#[cfg(test)]\nmod tests;\n"],[2039,"use super::super::navigate;\nuse super::*;\nuse crate::fmt::Debug;\nuse crate::string::String;\n\nimpl<'a, K: 'a, V: 'a> NodeRef<marker::Immut<'a>, K, V, marker::LeafOrInternal> {\n    // Asserts that the back pointer in each reachable node points to its parent.\n    pub fn assert_back_pointers(self) {\n        if let ForceResult::Internal(node) = self.force() {\n            for idx in 0..=node.len() {\n                let edge = unsafe { Handle::new_edge(node, idx) };\n                let child = edge.descend();\n                assert!(child.ascend().ok() == Some(edge));\n                child.assert_back_pointers();\n            }\n        }\n    }\n\n    // Renders a multi-line display of the keys in order and in tree hierarchy,\n    // picturing the tree growing sideways from its root on the left to its\n    // leaves on the right.\n    pub fn dump_keys(self) -> String\n    where\n        K: Debug,\n    {\n        let mut result = String::new();\n        self.visit_nodes_in_order(|pos| match pos {\n            navigate::Position::Leaf(leaf) => {\n                let depth = self.height();\n                let indent = \"  \".repeat(depth);\n                result += &format!(\"\\n{}{:?}\", indent, leaf.keys());\n            }\n            navigate::Position::Internal(_) => {}\n            navigate::Position::InternalKV(kv) => {\n                let depth = self.height() - kv.into_node().height();\n                let indent = \"  \".repeat(depth);\n                result += &format!(\"\\n{}{:?}\", indent, kv.into_kv().0);\n            }\n        });\n        result\n    }\n}\n\n#[test]\nfn test_splitpoint() {\n    for idx in 0..=CAPACITY {\n        let (middle_kv_idx, insertion) = splitpoint(idx);\n\n        // Simulate performing the split:\n        let mut left_len = middle_kv_idx;\n        let mut right_len = CAPACITY - middle_kv_idx - 1;\n        match insertion {\n            LeftOrRight::Left(edge_idx) => {\n                assert!(edge_idx <= left_len);\n                left_len += 1;\n            }\n            LeftOrRight::Right(edge_idx) => {\n                assert!(edge_idx <= right_len);\n                right_len += 1;\n            }\n        }\n        assert!(left_len >= MIN_LEN_AFTER_SPLIT);\n        assert!(right_len >= MIN_LEN_AFTER_SPLIT);\n        assert!(left_len + right_len == CAPACITY);\n    }\n}\n\n#[test]\nfn test_partial_eq() {\n    let mut root1 = NodeRef::new_leaf();\n    root1.borrow_mut().push(1, ());\n    let mut root1 = NodeRef::new_internal(root1.forget_type()).forget_type();\n    let root2 = Root::new();\n    root1.reborrow().assert_back_pointers();\n    root2.reborrow().assert_back_pointers();\n\n    let leaf_edge_1a = root1.reborrow().first_leaf_edge().forget_node_type();\n    let leaf_edge_1b = root1.reborrow().last_leaf_edge().forget_node_type();\n    let top_edge_1 = root1.reborrow().first_edge();\n    let top_edge_2 = root2.reborrow().first_edge();\n\n    assert!(leaf_edge_1a == leaf_edge_1a);\n    assert!(leaf_edge_1a != leaf_edge_1b);\n    assert!(leaf_edge_1a != top_edge_1);\n    assert!(leaf_edge_1a != top_edge_2);\n    assert!(top_edge_1 == top_edge_1);\n    assert!(top_edge_1 != top_edge_2);\n\n    root1.pop_internal_level();\n    unsafe { root1.into_dying().deallocate_and_ascend() };\n    unsafe { root2.into_dying().deallocate_and_ascend() };\n}\n\n#[test]\n#[cfg(target_arch = \"x86_64\")]\nfn test_sizes() {\n    assert_eq!(core::mem::size_of::<LeafNode<(), ()>>(), 16);\n    assert_eq!(core::mem::size_of::<LeafNode<i64, i64>>(), 16 + CAPACITY * 2 * 8);\n    assert_eq!(core::mem::size_of::<InternalNode<(), ()>>(), 16 + (CAPACITY + 1) * 8);\n    assert_eq!(core::mem::size_of::<InternalNode<i64, i64>>(), 16 + (CAPACITY * 3 + 1) * 8);\n}\n"],[2040,"use core::borrow::Borrow;\nuse core::cmp::Ordering;\nuse core::ops::{Bound, RangeBounds};\n\nuse super::node::{marker, ForceResult::*, Handle, NodeRef};\n\nuse SearchBound::*;\nuse SearchResult::*;\n\npub enum SearchBound<T> {\n    /// An inclusive bound to look for, just like `Bound::Included(T)`.\n    Included(T),\n    /// An exclusive bound to look for, just like `Bound::Excluded(T)`.\n    Excluded(T),\n    /// An unconditional inclusive bound, just like `Bound::Unbounded`.\n    AllIncluded,\n    /// An unconditional exclusive bound.\n    AllExcluded,\n}\n\nimpl<T> SearchBound<T> {\n    pub fn from_range(range_bound: Bound<T>) -> Self {\n        match range_bound {\n            Bound::Included(t) => Included(t),\n            Bound::Excluded(t) => Excluded(t),\n            Bound::Unbounded => AllIncluded,\n        }\n    }\n}\n\npub enum SearchResult<BorrowType, K, V, FoundType, GoDownType> {\n    Found(Handle<NodeRef<BorrowType, K, V, FoundType>, marker::KV>),\n    GoDown(Handle<NodeRef<BorrowType, K, V, GoDownType>, marker::Edge>),\n}\n\npub enum IndexResult {\n    KV(usize),\n    Edge(usize),\n}\n\nimpl<BorrowType: marker::BorrowType, K, V> NodeRef<BorrowType, K, V, marker::LeafOrInternal> {\n    /// Looks up a given key in a (sub)tree headed by the node, recursively.\n    /// Returns a `Found` with the handle of the matching KV, if any. Otherwise,\n    /// returns a `GoDown` with the handle of the leaf edge where the key belongs.\n    ///\n    /// The result is meaningful only if the tree is ordered by key, like the tree\n    /// in a `BTreeMap` is.\n    pub fn search_tree<Q: ?Sized>(\n        mut self,\n        key: &Q,\n    ) -> SearchResult<BorrowType, K, V, marker::LeafOrInternal, marker::Leaf>\n    where\n        Q: Ord,\n        K: Borrow<Q>,\n    {\n        loop {\n            self = match self.search_node(key) {\n                Found(handle) => return Found(handle),\n                GoDown(handle) => match handle.force() {\n                    Leaf(leaf) => return GoDown(leaf),\n                    Internal(internal) => internal.descend(),\n                },\n            }\n        }\n    }\n\n    /// Descends to the nearest node where the edge matching the lower bound\n    /// of the range is different from the edge matching the upper bound, i.e.,\n    /// the nearest node that has at least one key contained in the range.\n    ///\n    /// If found, returns an `Ok` with that node, the strictly ascending pair of\n    /// edge indices in the node delimiting the range, and the corresponding\n    /// pair of bounds for continuing the search in the child nodes, in case\n    /// the node is internal.\n    ///\n    /// If not found, returns an `Err` with the leaf edge matching the entire\n    /// range.\n    ///\n    /// As a diagnostic service, panics if the range specifies impossible bounds.\n    ///\n    /// The result is meaningful only if the tree is ordered by key.\n    pub fn search_tree_for_bifurcation<'r, Q: ?Sized, R>(\n        mut self,\n        range: &'r R,\n    ) -> Result<\n        (\n            NodeRef<BorrowType, K, V, marker::LeafOrInternal>,\n            usize,\n            usize,\n            SearchBound<&'r Q>,\n            SearchBound<&'r Q>,\n        ),\n        Handle<NodeRef<BorrowType, K, V, marker::Leaf>, marker::Edge>,\n    >\n    where\n        Q: Ord,\n        K: Borrow<Q>,\n        R: RangeBounds<Q>,\n    {\n        // Inlining these variables should be avoided. We assume the bounds reported by `range`\n        // remain the same, but an adversarial implementation could change between calls (#81138).\n        let (start, end) = (range.start_bound(), range.end_bound());\n        match (start, end) {\n            (Bound::Excluded(s), Bound::Excluded(e)) if s == e => {\n                panic!(\"range start and end are equal and excluded in BTreeMap\")\n            }\n            (Bound::Included(s) | Bound::Excluded(s), Bound::Included(e) | Bound::Excluded(e))\n                if s > e =>\n            {\n                panic!(\"range start is greater than range end in BTreeMap\")\n            }\n            _ => {}\n        }\n        let mut lower_bound = SearchBound::from_range(start);\n        let mut upper_bound = SearchBound::from_range(end);\n        loop {\n            let (lower_edge_idx, lower_child_bound) = self.find_lower_bound_index(lower_bound);\n            let (upper_edge_idx, upper_child_bound) =\n                unsafe { self.find_upper_bound_index(upper_bound, lower_edge_idx) };\n            if lower_edge_idx < upper_edge_idx {\n                return Ok((\n                    self,\n                    lower_edge_idx,\n                    upper_edge_idx,\n                    lower_child_bound,\n                    upper_child_bound,\n                ));\n            }\n            debug_assert_eq!(lower_edge_idx, upper_edge_idx);\n            let common_edge = unsafe { Handle::new_edge(self, lower_edge_idx) };\n            match common_edge.force() {\n                Leaf(common_edge) => return Err(common_edge),\n                Internal(common_edge) => {\n                    self = common_edge.descend();\n                    lower_bound = lower_child_bound;\n                    upper_bound = upper_child_bound;\n                }\n            }\n        }\n    }\n\n    /// Finds an edge in the node delimiting the lower bound of a range.\n    /// Also returns the lower bound to be used for continuing the search in\n    /// the matching child node, if `self` is an internal node.\n    ///\n    /// The result is meaningful only if the tree is ordered by key.\n    pub fn find_lower_bound_edge<'r, Q>(\n        self,\n        bound: SearchBound<&'r Q>,\n    ) -> (Handle<Self, marker::Edge>, SearchBound<&'r Q>)\n    where\n        Q: ?Sized + Ord,\n        K: Borrow<Q>,\n    {\n        let (edge_idx, bound) = self.find_lower_bound_index(bound);\n        let edge = unsafe { Handle::new_edge(self, edge_idx) };\n        (edge, bound)\n    }\n\n    /// Clone of `find_lower_bound_edge` for the upper bound.\n    pub fn find_upper_bound_edge<'r, Q>(\n        self,\n        bound: SearchBound<&'r Q>,\n    ) -> (Handle<Self, marker::Edge>, SearchBound<&'r Q>)\n    where\n        Q: ?Sized + Ord,\n        K: Borrow<Q>,\n    {\n        let (edge_idx, bound) = unsafe { self.find_upper_bound_index(bound, 0) };\n        let edge = unsafe { Handle::new_edge(self, edge_idx) };\n        (edge, bound)\n    }\n}\n\nimpl<BorrowType, K, V, Type> NodeRef<BorrowType, K, V, Type> {\n    /// Looks up a given key in the node, without recursion.\n    /// Returns a `Found` with the handle of the matching KV, if any. Otherwise,\n    /// returns a `GoDown` with the handle of the edge where the key might be found\n    /// (if the node is internal) or where the key can be inserted.\n    ///\n    /// The result is meaningful only if the tree is ordered by key, like the tree\n    /// in a `BTreeMap` is.\n    pub fn search_node<Q: ?Sized>(self, key: &Q) -> SearchResult<BorrowType, K, V, Type, Type>\n    where\n        Q: Ord,\n        K: Borrow<Q>,\n    {\n        match unsafe { self.find_key_index(key, 0) } {\n            IndexResult::KV(idx) => Found(unsafe { Handle::new_kv(self, idx) }),\n            IndexResult::Edge(idx) => GoDown(unsafe { Handle::new_edge(self, idx) }),\n        }\n    }\n\n    /// Returns either the KV index in the node at which the key (or an equivalent)\n    /// exists, or the edge index where the key belongs, starting from a particular index.\n    ///\n    /// The result is meaningful only if the tree is ordered by key, like the tree\n    /// in a `BTreeMap` is.\n    ///\n    /// # Safety\n    /// `start_index` must be a valid edge index for the node.\n    unsafe fn find_key_index<Q: ?Sized>(&self, key: &Q, start_index: usize) -> IndexResult\n    where\n        Q: Ord,\n        K: Borrow<Q>,\n    {\n        let node = self.reborrow();\n        let keys = node.keys();\n        debug_assert!(start_index <= keys.len());\n        for (offset, k) in unsafe { keys.get_unchecked(start_index..) }.iter().enumerate() {\n            match key.cmp(k.borrow()) {\n                Ordering::Greater => {}\n                Ordering::Equal => return IndexResult::KV(start_index + offset),\n                Ordering::Less => return IndexResult::Edge(start_index + offset),\n            }\n        }\n        IndexResult::Edge(keys.len())\n    }\n\n    /// Finds an edge index in the node delimiting the lower bound of a range.\n    /// Also returns the lower bound to be used for continuing the search in\n    /// the matching child node, if `self` is an internal node.\n    ///\n    /// The result is meaningful only if the tree is ordered by key.\n    fn find_lower_bound_index<'r, Q>(\n        &self,\n        bound: SearchBound<&'r Q>,\n    ) -> (usize, SearchBound<&'r Q>)\n    where\n        Q: ?Sized + Ord,\n        K: Borrow<Q>,\n    {\n        match bound {\n            Included(key) => match unsafe { self.find_key_index(key, 0) } {\n                IndexResult::KV(idx) => (idx, AllExcluded),\n                IndexResult::Edge(idx) => (idx, bound),\n            },\n            Excluded(key) => match unsafe { self.find_key_index(key, 0) } {\n                IndexResult::KV(idx) => (idx + 1, AllIncluded),\n                IndexResult::Edge(idx) => (idx, bound),\n            },\n            AllIncluded => (0, AllIncluded),\n            AllExcluded => (self.len(), AllExcluded),\n        }\n    }\n\n    /// Mirror image of `find_lower_bound_index` for the upper bound,\n    /// with an additional parameter to skip part of the key array.\n    ///\n    /// # Safety\n    /// `start_index` must be a valid edge index for the node.\n    unsafe fn find_upper_bound_index<'r, Q>(\n        &self,\n        bound: SearchBound<&'r Q>,\n        start_index: usize,\n    ) -> (usize, SearchBound<&'r Q>)\n    where\n        Q: ?Sized + Ord,\n        K: Borrow<Q>,\n    {\n        match bound {\n            Included(key) => match unsafe { self.find_key_index(key, start_index) } {\n                IndexResult::KV(idx) => (idx + 1, AllExcluded),\n                IndexResult::Edge(idx) => (idx, bound),\n            },\n            Excluded(key) => match unsafe { self.find_key_index(key, start_index) } {\n                IndexResult::KV(idx) => (idx, AllIncluded),\n                IndexResult::Edge(idx) => (idx, bound),\n            },\n            AllIncluded => (self.len(), AllIncluded),\n            AllExcluded => (start_index, AllExcluded),\n        }\n    }\n}\n"],[2041,"use core::borrow::Borrow;\nuse core::cmp::Ordering;\nuse core::fmt::{self, Debug};\nuse core::hash::{Hash, Hasher};\nuse core::iter::{FromIterator, FusedIterator};\nuse core::marker::PhantomData;\nuse core::mem::{self, ManuallyDrop};\nuse core::ops::{Index, RangeBounds};\nuse core::ptr;\n\nuse super::borrow::DormantMutRef;\nuse super::navigate::LeafRange;\nuse super::node::{self, marker, ForceResult::*, Handle, NodeRef, Root};\nuse super::search::SearchResult::*;\n\nmod entry;\npub use entry::{Entry, OccupiedEntry, OccupiedError, VacantEntry};\nuse Entry::*;\n\n/// Minimum number of elements in nodes that are not a root.\n/// We might temporarily have fewer elements during methods.\npub(super) const MIN_LEN: usize = node::MIN_LEN_AFTER_SPLIT;\n\n// A tree in a `BTreeMap` is a tree in the `node` module with additional invariants:\n// - Keys must appear in ascending order (according to the key's type).\n// - If the root node is internal, it must contain at least 1 element.\n// - Every non-root node contains at least MIN_LEN elements.\n//\n// An empty map may be represented both by the absence of a root node or by a\n// root node that is an empty leaf.\n\n/// A map based on a [B-Tree].\n///\n/// B-Trees represent a fundamental compromise between cache-efficiency and actually minimizing\n/// the amount of work performed in a search. In theory, a binary search tree (BST) is the optimal\n/// choice for a sorted map, as a perfectly balanced BST performs the theoretical minimum amount of\n/// comparisons necessary to find an element (log<sub>2</sub>n). However, in practice the way this\n/// is done is *very* inefficient for modern computer architectures. In particular, every element\n/// is stored in its own individually heap-allocated node. This means that every single insertion\n/// triggers a heap-allocation, and every single comparison should be a cache-miss. Since these\n/// are both notably expensive things to do in practice, we are forced to at very least reconsider\n/// the BST strategy.\n///\n/// A B-Tree instead makes each node contain B-1 to 2B-1 elements in a contiguous array. By doing\n/// this, we reduce the number of allocations by a factor of B, and improve cache efficiency in\n/// searches. However, this does mean that searches will have to do *more* comparisons on average.\n/// The precise number of comparisons depends on the node search strategy used. For optimal cache\n/// efficiency, one could search the nodes linearly. For optimal comparisons, one could search\n/// the node using binary search. As a compromise, one could also perform a linear search\n/// that initially only checks every i<sup>th</sup> element for some choice of i.\n///\n/// Currently, our implementation simply performs naive linear search. This provides excellent\n/// performance on *small* nodes of elements which are cheap to compare. However in the future we\n/// would like to further explore choosing the optimal search strategy based on the choice of B,\n/// and possibly other factors. Using linear search, searching for a random element is expected\n/// to take O(B * log(n)) comparisons, which is generally worse than a BST. In practice,\n/// however, performance is excellent.\n///\n/// It is a logic error for a key to be modified in such a way that the key's ordering relative to\n/// any other key, as determined by the [`Ord`] trait, changes while it is in the map. This is\n/// normally only possible through [`Cell`], [`RefCell`], global state, I/O, or unsafe code.\n/// The behavior resulting from such a logic error is not specified, but will not result in\n/// undefined behavior. This could include panics, incorrect results, aborts, memory leaks, and\n/// non-termination.\n///\n/// [B-Tree]: https://en.wikipedia.org/wiki/B-tree\n/// [`Cell`]: core::cell::Cell\n/// [`RefCell`]: core::cell::RefCell\n///\n/// # Examples\n///\n/// ```\n/// use std::collections::BTreeMap;\n///\n/// // type inference lets us omit an explicit type signature (which\n/// // would be `BTreeMap<&str, &str>` in this example).\n/// let mut movie_reviews = BTreeMap::new();\n///\n/// // review some movies.\n/// movie_reviews.insert(\"Office Space\",       \"Deals with real issues in the workplace.\");\n/// movie_reviews.insert(\"Pulp Fiction\",       \"Masterpiece.\");\n/// movie_reviews.insert(\"The Godfather\",      \"Very enjoyable.\");\n/// movie_reviews.insert(\"The Blues Brothers\", \"Eye lyked it a lot.\");\n///\n/// // check for a specific one.\n/// if !movie_reviews.contains_key(\"Les Misérables\") {\n///     println!(\"We've got {} reviews, but Les Misérables ain't one.\",\n///              movie_reviews.len());\n/// }\n///\n/// // oops, this review has a lot of spelling mistakes, let's delete it.\n/// movie_reviews.remove(\"The Blues Brothers\");\n///\n/// // look up the values associated with some keys.\n/// let to_find = [\"Up!\", \"Office Space\"];\n/// for movie in &to_find {\n///     match movie_reviews.get(movie) {\n///        Some(review) => println!(\"{}: {}\", movie, review),\n///        None => println!(\"{} is unreviewed.\", movie)\n///     }\n/// }\n///\n/// // Look up the value for a key (will panic if the key is not found).\n/// println!(\"Movie review: {}\", movie_reviews[\"Office Space\"]);\n///\n/// // iterate over everything.\n/// for (movie, review) in &movie_reviews {\n///     println!(\"{}: \\\"{}\\\"\", movie, review);\n/// }\n/// ```\n///\n/// `BTreeMap` also implements an [`Entry API`], which allows for more complex\n/// methods of getting, setting, updating and removing keys and their values:\n///\n/// [`Entry API`]: BTreeMap::entry\n///\n/// ```\n/// use std::collections::BTreeMap;\n///\n/// // type inference lets us omit an explicit type signature (which\n/// // would be `BTreeMap<&str, u8>` in this example).\n/// let mut player_stats = BTreeMap::new();\n///\n/// fn random_stat_buff() -> u8 {\n///     // could actually return some random value here - let's just return\n///     // some fixed value for now\n///     42\n/// }\n///\n/// // insert a key only if it doesn't already exist\n/// player_stats.entry(\"health\").or_insert(100);\n///\n/// // insert a key using a function that provides a new value only if it\n/// // doesn't already exist\n/// player_stats.entry(\"defence\").or_insert_with(random_stat_buff);\n///\n/// // update a key, guarding against the key possibly not being set\n/// let stat = player_stats.entry(\"attack\").or_insert(100);\n/// *stat += random_stat_buff();\n/// ```\n#[stable(feature = \"rust1\", since = \"1.0.0\")]\n#[cfg_attr(not(test), rustc_diagnostic_item = \"BTreeMap\")]\npub struct BTreeMap<K, V> {\n    root: Option<Root<K, V>>,\n    length: usize,\n}\n\n#[stable(feature = \"btree_drop\", since = \"1.7.0\")]\nunsafe impl<#[may_dangle] K, #[may_dangle] V> Drop for BTreeMap<K, V> {\n    fn drop(&mut self) {\n        if let Some(root) = self.root.take() {\n            Dropper { front: root.into_dying().first_leaf_edge(), remaining_length: self.length };\n        }\n    }\n}\n\n#[stable(feature = \"rust1\", since = \"1.0.0\")]\nimpl<K: Clone, V: Clone> Clone for BTreeMap<K, V> {\n    fn clone(&self) -> BTreeMap<K, V> {\n        fn clone_subtree<'a, K: Clone, V: Clone>(\n            node: NodeRef<marker::Immut<'a>, K, V, marker::LeafOrInternal>,\n        ) -> BTreeMap<K, V>\n        where\n            K: 'a,\n            V: 'a,\n        {\n            match node.force() {\n                Leaf(leaf) => {\n                    let mut out_tree = BTreeMap { root: Some(Root::new()), length: 0 };\n\n                    {\n                        let root = out_tree.root.as_mut().unwrap(); // unwrap succeeds because we just wrapped\n                        let mut out_node = match root.borrow_mut().force() {\n                            Leaf(leaf) => leaf,\n                            Internal(_) => unreachable!(),\n                        };\n\n                        let mut in_edge = leaf.first_edge();\n                        while let Ok(kv) = in_edge.right_kv() {\n                            let (k, v) = kv.into_kv();\n                            in_edge = kv.right_edge();\n\n                            out_node.push(k.clone(), v.clone());\n                            out_tree.length += 1;\n                        }\n                    }\n\n                    out_tree\n                }\n                Internal(internal) => {\n                    let mut out_tree = clone_subtree(internal.first_edge().descend());\n\n                    {\n                        let out_root = BTreeMap::ensure_is_owned(&mut out_tree.root);\n                        let mut out_node = out_root.push_internal_level();\n                        let mut in_edge = internal.first_edge();\n                        while let Ok(kv) = in_edge.right_kv() {\n                            let (k, v) = kv.into_kv();\n                            in_edge = kv.right_edge();\n\n                            let k = (*k).clone();\n                            let v = (*v).clone();\n                            let subtree = clone_subtree(in_edge.descend());\n\n                            // We can't destructure subtree directly\n                            // because BTreeMap implements Drop\n                            let (subroot, sublength) = unsafe {\n                                let subtree = ManuallyDrop::new(subtree);\n                                let root = ptr::read(&subtree.root);\n                                let length = subtree.length;\n                                (root, length)\n                            };\n\n                            out_node.push(k, v, subroot.unwrap_or_else(Root::new));\n                            out_tree.length += 1 + sublength;\n                        }\n                    }\n\n                    out_tree\n                }\n            }\n        }\n\n        if self.is_empty() {\n            // Ideally we'd call `BTreeMap::new` here, but that has the `K:\n            // Ord` constraint, which this method lacks.\n            BTreeMap { root: None, length: 0 }\n        } else {\n            clone_subtree(self.root.as_ref().unwrap().reborrow()) // unwrap succeeds because not empty\n        }\n    }\n}\n\nimpl<K, Q: ?Sized> super::Recover<Q> for BTreeMap<K, ()>\nwhere\n    K: Borrow<Q> + Ord,\n    Q: Ord,\n{\n    type Key = K;\n\n    fn get(&self, key: &Q) -> Option<&K> {\n        let root_node = self.root.as_ref()?.reborrow();\n        match root_node.search_tree(key) {\n            Found(handle) => Some(handle.into_kv().0),\n            GoDown(_) => None,\n        }\n    }\n\n    fn take(&mut self, key: &Q) -> Option<K> {\n        let (map, dormant_map) = DormantMutRef::new(self);\n        let root_node = map.root.as_mut()?.borrow_mut();\n        match root_node.search_tree(key) {\n            Found(handle) => {\n                Some(OccupiedEntry { handle, dormant_map, _marker: PhantomData }.remove_kv().0)\n            }\n            GoDown(_) => None,\n        }\n    }\n\n    fn replace(&mut self, key: K) -> Option<K> {\n        let (map, dormant_map) = DormantMutRef::new(self);\n        let root_node = Self::ensure_is_owned(&mut map.root).borrow_mut();\n        match root_node.search_tree::<K>(&key) {\n            Found(mut kv) => Some(mem::replace(kv.key_mut(), key)),\n            GoDown(handle) => {\n                VacantEntry { key, handle, dormant_map, _marker: PhantomData }.insert(());\n                None\n            }\n        }\n    }\n}\n\n/// An iterator over the entries of a `BTreeMap`.\n///\n/// This `struct` is created by the [`iter`] method on [`BTreeMap`]. See its\n/// documentation for more.\n///\n/// [`iter`]: BTreeMap::iter\n#[stable(feature = \"rust1\", since = \"1.0.0\")]\npub struct Iter<'a, K: 'a, V: 'a> {\n    range: Range<'a, K, V>,\n    length: usize,\n}\n\n#[stable(feature = \"collection_debug\", since = \"1.17.0\")]\nimpl<K: fmt::Debug, V: fmt::Debug> fmt::Debug for Iter<'_, K, V> {\n    fn fmt(&self, f: &mut fmt::Formatter<'_>) -> fmt::Result {\n        f.debug_list().entries(self.clone()).finish()\n    }\n}\n\n/// A mutable iterator over the entries of a `BTreeMap`.\n///\n/// This `struct` is created by the [`iter_mut`] method on [`BTreeMap`]. See its\n/// documentation for more.\n///\n/// [`iter_mut`]: BTreeMap::iter_mut\n#[stable(feature = \"rust1\", since = \"1.0.0\")]\n#[derive(Debug)]\npub struct IterMut<'a, K: 'a, V: 'a> {\n    range: RangeMut<'a, K, V>,\n    length: usize,\n}\n\n/// An owning iterator over the entries of a `BTreeMap`.\n///\n/// This `struct` is created by the [`into_iter`] method on [`BTreeMap`]\n/// (provided by the `IntoIterator` trait). See its documentation for more.\n///\n/// [`into_iter`]: IntoIterator::into_iter\n#[stable(feature = \"rust1\", since = \"1.0.0\")]\npub struct IntoIter<K, V> {\n    range: LeafRange<marker::Dying, K, V>,\n    length: usize,\n}\n\nimpl<K, V> IntoIter<K, V> {\n    /// Returns an iterator of references over the remaining items.\n    #[inline]\n    pub(super) fn iter(&self) -> Iter<'_, K, V> {\n        let range = Range { inner: self.range.reborrow() };\n        Iter { range: range, length: self.length }\n    }\n}\n\n#[stable(feature = \"collection_debug\", since = \"1.17.0\")]\nimpl<K: fmt::Debug, V: fmt::Debug> fmt::Debug for IntoIter<K, V> {\n    fn fmt(&self, f: &mut fmt::Formatter<'_>) -> fmt::Result {\n        f.debug_list().entries(self.iter()).finish()\n    }\n}\n\n/// A simplified version of `IntoIter` that is not double-ended and has only one\n/// purpose: to drop the remainder of an `IntoIter`. Therefore it also serves to\n/// drop an entire tree without the need to first look up a `back` leaf edge.\nstruct Dropper<K, V> {\n    front: Handle<NodeRef<marker::Dying, K, V, marker::Leaf>, marker::Edge>,\n    remaining_length: usize,\n}\n\n/// An iterator over the keys of a `BTreeMap`.\n///\n/// This `struct` is created by the [`keys`] method on [`BTreeMap`]. See its\n/// documentation for more.\n///\n/// [`keys`]: BTreeMap::keys\n#[stable(feature = \"rust1\", since = \"1.0.0\")]\npub struct Keys<'a, K: 'a, V: 'a> {\n    inner: Iter<'a, K, V>,\n}\n\n#[stable(feature = \"collection_debug\", since = \"1.17.0\")]\nimpl<K: fmt::Debug, V> fmt::Debug for Keys<'_, K, V> {\n    fn fmt(&self, f: &mut fmt::Formatter<'_>) -> fmt::Result {\n        f.debug_list().entries(self.clone()).finish()\n    }\n}\n\n/// An iterator over the values of a `BTreeMap`.\n///\n/// This `struct` is created by the [`values`] method on [`BTreeMap`]. See its\n/// documentation for more.\n///\n/// [`values`]: BTreeMap::values\n#[stable(feature = \"rust1\", since = \"1.0.0\")]\npub struct Values<'a, K: 'a, V: 'a> {\n    inner: Iter<'a, K, V>,\n}\n\n#[stable(feature = \"collection_debug\", since = \"1.17.0\")]\nimpl<K, V: fmt::Debug> fmt::Debug for Values<'_, K, V> {\n    fn fmt(&self, f: &mut fmt::Formatter<'_>) -> fmt::Result {\n        f.debug_list().entries(self.clone()).finish()\n    }\n}\n\n/// A mutable iterator over the values of a `BTreeMap`.\n///\n/// This `struct` is created by the [`values_mut`] method on [`BTreeMap`]. See its\n/// documentation for more.\n///\n/// [`values_mut`]: BTreeMap::values_mut\n#[stable(feature = \"map_values_mut\", since = \"1.10.0\")]\npub struct ValuesMut<'a, K: 'a, V: 'a> {\n    inner: IterMut<'a, K, V>,\n}\n\n#[stable(feature = \"map_values_mut\", since = \"1.10.0\")]\nimpl<K, V: fmt::Debug> fmt::Debug for ValuesMut<'_, K, V> {\n    fn fmt(&self, f: &mut fmt::Formatter<'_>) -> fmt::Result {\n        f.debug_list().entries(self.inner.iter().map(|(_, val)| val)).finish()\n    }\n}\n\n/// An owning iterator over the keys of a `BTreeMap`.\n///\n/// This `struct` is created by the [`into_keys`] method on [`BTreeMap`].\n/// See its documentation for more.\n///\n/// [`into_keys`]: BTreeMap::into_keys\n#[stable(feature = \"map_into_keys_values\", since = \"1.54.0\")]\npub struct IntoKeys<K, V> {\n    inner: IntoIter<K, V>,\n}\n\n#[stable(feature = \"map_into_keys_values\", since = \"1.54.0\")]\nimpl<K: fmt::Debug, V> fmt::Debug for IntoKeys<K, V> {\n    fn fmt(&self, f: &mut fmt::Formatter<'_>) -> fmt::Result {\n        f.debug_list().entries(self.inner.iter().map(|(key, _)| key)).finish()\n    }\n}\n\n/// An owning iterator over the values of a `BTreeMap`.\n///\n/// This `struct` is created by the [`into_values`] method on [`BTreeMap`].\n/// See its documentation for more.\n///\n/// [`into_values`]: BTreeMap::into_values\n#[stable(feature = \"map_into_keys_values\", since = \"1.54.0\")]\npub struct IntoValues<K, V> {\n    inner: IntoIter<K, V>,\n}\n\n#[stable(feature = \"map_into_keys_values\", since = \"1.54.0\")]\nimpl<K, V: fmt::Debug> fmt::Debug for IntoValues<K, V> {\n    fn fmt(&self, f: &mut fmt::Formatter<'_>) -> fmt::Result {\n        f.debug_list().entries(self.inner.iter().map(|(_, val)| val)).finish()\n    }\n}\n\n/// An iterator over a sub-range of entries in a `BTreeMap`.\n///\n/// This `struct` is created by the [`range`] method on [`BTreeMap`]. See its\n/// documentation for more.\n///\n/// [`range`]: BTreeMap::range\n#[stable(feature = \"btree_range\", since = \"1.17.0\")]\npub struct Range<'a, K: 'a, V: 'a> {\n    inner: LeafRange<marker::Immut<'a>, K, V>,\n}\n\n#[stable(feature = \"collection_debug\", since = \"1.17.0\")]\nimpl<K: fmt::Debug, V: fmt::Debug> fmt::Debug for Range<'_, K, V> {\n    fn fmt(&self, f: &mut fmt::Formatter<'_>) -> fmt::Result {\n        f.debug_list().entries(self.clone()).finish()\n    }\n}\n\n/// A mutable iterator over a sub-range of entries in a `BTreeMap`.\n///\n/// This `struct` is created by the [`range_mut`] method on [`BTreeMap`]. See its\n/// documentation for more.\n///\n/// [`range_mut`]: BTreeMap::range_mut\n#[stable(feature = \"btree_range\", since = \"1.17.0\")]\npub struct RangeMut<'a, K: 'a, V: 'a> {\n    inner: LeafRange<marker::ValMut<'a>, K, V>,\n\n    // Be invariant in `K` and `V`\n    _marker: PhantomData<&'a mut (K, V)>,\n}\n\n#[stable(feature = \"collection_debug\", since = \"1.17.0\")]\nimpl<K: fmt::Debug, V: fmt::Debug> fmt::Debug for RangeMut<'_, K, V> {\n    fn fmt(&self, f: &mut fmt::Formatter<'_>) -> fmt::Result {\n        let range = Range { inner: self.inner.reborrow() };\n        f.debug_list().entries(range).finish()\n    }\n}\n\nimpl<K, V> BTreeMap<K, V> {\n    /// Makes a new, empty `BTreeMap`.\n    ///\n    /// Does not allocate anything on its own.\n    ///\n    /// # Examples\n    ///\n    /// Basic usage:\n    ///\n    /// ```\n    /// use std::collections::BTreeMap;\n    ///\n    /// let mut map = BTreeMap::new();\n    ///\n    /// // entries can now be inserted into the empty map\n    /// map.insert(1, \"a\");\n    /// ```\n    #[stable(feature = \"rust1\", since = \"1.0.0\")]\n    #[rustc_const_unstable(feature = \"const_btree_new\", issue = \"71835\")]\n    pub const fn new() -> BTreeMap<K, V>\n    where\n        K: Ord,\n    {\n        BTreeMap { root: None, length: 0 }\n    }\n\n    /// Clears the map, removing all elements.\n    ///\n    /// # Examples\n    ///\n    /// Basic usage:\n    ///\n    /// ```\n    /// use std::collections::BTreeMap;\n    ///\n    /// let mut a = BTreeMap::new();\n    /// a.insert(1, \"a\");\n    /// a.clear();\n    /// assert!(a.is_empty());\n    /// ```\n    #[stable(feature = \"rust1\", since = \"1.0.0\")]\n    pub fn clear(&mut self) {\n        *self = BTreeMap { root: None, length: 0 };\n    }\n\n    /// Returns a reference to the value corresponding to the key.\n    ///\n    /// The key may be any borrowed form of the map's key type, but the ordering\n    /// on the borrowed form *must* match the ordering on the key type.\n    ///\n    /// # Examples\n    ///\n    /// Basic usage:\n    ///\n    /// ```\n    /// use std::collections::BTreeMap;\n    ///\n    /// let mut map = BTreeMap::new();\n    /// map.insert(1, \"a\");\n    /// assert_eq!(map.get(&1), Some(&\"a\"));\n    /// assert_eq!(map.get(&2), None);\n    /// ```\n    #[stable(feature = \"rust1\", since = \"1.0.0\")]\n    pub fn get<Q: ?Sized>(&self, key: &Q) -> Option<&V>\n    where\n        K: Borrow<Q> + Ord,\n        Q: Ord,\n    {\n        let root_node = self.root.as_ref()?.reborrow();\n        match root_node.search_tree(key) {\n            Found(handle) => Some(handle.into_kv().1),\n            GoDown(_) => None,\n        }\n    }\n\n    /// Returns the key-value pair corresponding to the supplied key.\n    ///\n    /// The supplied key may be any borrowed form of the map's key type, but the ordering\n    /// on the borrowed form *must* match the ordering on the key type.\n    ///\n    /// # Examples\n    ///\n    /// ```\n    /// use std::collections::BTreeMap;\n    ///\n    /// let mut map = BTreeMap::new();\n    /// map.insert(1, \"a\");\n    /// assert_eq!(map.get_key_value(&1), Some((&1, &\"a\")));\n    /// assert_eq!(map.get_key_value(&2), None);\n    /// ```\n    #[stable(feature = \"map_get_key_value\", since = \"1.40.0\")]\n    pub fn get_key_value<Q: ?Sized>(&self, k: &Q) -> Option<(&K, &V)>\n    where\n        K: Borrow<Q> + Ord,\n        Q: Ord,\n    {\n        let root_node = self.root.as_ref()?.reborrow();\n        match root_node.search_tree(k) {\n            Found(handle) => Some(handle.into_kv()),\n            GoDown(_) => None,\n        }\n    }\n\n    /// Returns the first key-value pair in the map.\n    /// The key in this pair is the minimum key in the map.\n    ///\n    /// # Examples\n    ///\n    /// Basic usage:\n    ///\n    /// ```\n    /// #![feature(map_first_last)]\n    /// use std::collections::BTreeMap;\n    ///\n    /// let mut map = BTreeMap::new();\n    /// assert_eq!(map.first_key_value(), None);\n    /// map.insert(1, \"b\");\n    /// map.insert(2, \"a\");\n    /// assert_eq!(map.first_key_value(), Some((&1, &\"b\")));\n    /// ```\n    #[unstable(feature = \"map_first_last\", issue = \"62924\")]\n    pub fn first_key_value(&self) -> Option<(&K, &V)>\n    where\n        K: Ord,\n    {\n        let root_node = self.root.as_ref()?.reborrow();\n        root_node.first_leaf_edge().right_kv().ok().map(Handle::into_kv)\n    }\n\n    /// Returns the first entry in the map for in-place manipulation.\n    /// The key of this entry is the minimum key in the map.\n    ///\n    /// # Examples\n    ///\n    /// ```\n    /// #![feature(map_first_last)]\n    /// use std::collections::BTreeMap;\n    ///\n    /// let mut map = BTreeMap::new();\n    /// map.insert(1, \"a\");\n    /// map.insert(2, \"b\");\n    /// if let Some(mut entry) = map.first_entry() {\n    ///     if *entry.key() > 0 {\n    ///         entry.insert(\"first\");\n    ///     }\n    /// }\n    /// assert_eq!(*map.get(&1).unwrap(), \"first\");\n    /// assert_eq!(*map.get(&2).unwrap(), \"b\");\n    /// ```\n    #[unstable(feature = \"map_first_last\", issue = \"62924\")]\n    pub fn first_entry(&mut self) -> Option<OccupiedEntry<'_, K, V>>\n    where\n        K: Ord,\n    {\n        let (map, dormant_map) = DormantMutRef::new(self);\n        let root_node = map.root.as_mut()?.borrow_mut();\n        let kv = root_node.first_leaf_edge().right_kv().ok()?;\n        Some(OccupiedEntry { handle: kv.forget_node_type(), dormant_map, _marker: PhantomData })\n    }\n\n    /// Removes and returns the first element in the map.\n    /// The key of this element is the minimum key that was in the map.\n    ///\n    /// # Examples\n    ///\n    /// Draining elements in ascending order, while keeping a usable map each iteration.\n    ///\n    /// ```\n    /// #![feature(map_first_last)]\n    /// use std::collections::BTreeMap;\n    ///\n    /// let mut map = BTreeMap::new();\n    /// map.insert(1, \"a\");\n    /// map.insert(2, \"b\");\n    /// while let Some((key, _val)) = map.pop_first() {\n    ///     assert!(map.iter().all(|(k, _v)| *k > key));\n    /// }\n    /// assert!(map.is_empty());\n    /// ```\n    #[unstable(feature = \"map_first_last\", issue = \"62924\")]\n    pub fn pop_first(&mut self) -> Option<(K, V)>\n    where\n        K: Ord,\n    {\n        self.first_entry().map(|entry| entry.remove_entry())\n    }\n\n    /// Returns the last key-value pair in the map.\n    /// The key in this pair is the maximum key in the map.\n    ///\n    /// # Examples\n    ///\n    /// Basic usage:\n    ///\n    /// ```\n    /// #![feature(map_first_last)]\n    /// use std::collections::BTreeMap;\n    ///\n    /// let mut map = BTreeMap::new();\n    /// map.insert(1, \"b\");\n    /// map.insert(2, \"a\");\n    /// assert_eq!(map.last_key_value(), Some((&2, &\"a\")));\n    /// ```\n    #[unstable(feature = \"map_first_last\", issue = \"62924\")]\n    pub fn last_key_value(&self) -> Option<(&K, &V)>\n    where\n        K: Ord,\n    {\n        let root_node = self.root.as_ref()?.reborrow();\n        root_node.last_leaf_edge().left_kv().ok().map(Handle::into_kv)\n    }\n\n    /// Returns the last entry in the map for in-place manipulation.\n    /// The key of this entry is the maximum key in the map.\n    ///\n    /// # Examples\n    ///\n    /// ```\n    /// #![feature(map_first_last)]\n    /// use std::collections::BTreeMap;\n    ///\n    /// let mut map = BTreeMap::new();\n    /// map.insert(1, \"a\");\n    /// map.insert(2, \"b\");\n    /// if let Some(mut entry) = map.last_entry() {\n    ///     if *entry.key() > 0 {\n    ///         entry.insert(\"last\");\n    ///     }\n    /// }\n    /// assert_eq!(*map.get(&1).unwrap(), \"a\");\n    /// assert_eq!(*map.get(&2).unwrap(), \"last\");\n    /// ```\n    #[unstable(feature = \"map_first_last\", issue = \"62924\")]\n    pub fn last_entry(&mut self) -> Option<OccupiedEntry<'_, K, V>>\n    where\n        K: Ord,\n    {\n        let (map, dormant_map) = DormantMutRef::new(self);\n        let root_node = map.root.as_mut()?.borrow_mut();\n        let kv = root_node.last_leaf_edge().left_kv().ok()?;\n        Some(OccupiedEntry { handle: kv.forget_node_type(), dormant_map, _marker: PhantomData })\n    }\n\n    /// Removes and returns the last element in the map.\n    /// The key of this element is the maximum key that was in the map.\n    ///\n    /// # Examples\n    ///\n    /// Draining elements in descending order, while keeping a usable map each iteration.\n    ///\n    /// ```\n    /// #![feature(map_first_last)]\n    /// use std::collections::BTreeMap;\n    ///\n    /// let mut map = BTreeMap::new();\n    /// map.insert(1, \"a\");\n    /// map.insert(2, \"b\");\n    /// while let Some((key, _val)) = map.pop_last() {\n    ///     assert!(map.iter().all(|(k, _v)| *k < key));\n    /// }\n    /// assert!(map.is_empty());\n    /// ```\n    #[unstable(feature = \"map_first_last\", issue = \"62924\")]\n    pub fn pop_last(&mut self) -> Option<(K, V)>\n    where\n        K: Ord,\n    {\n        self.last_entry().map(|entry| entry.remove_entry())\n    }\n\n    /// Returns `true` if the map contains a value for the specified key.\n    ///\n    /// The key may be any borrowed form of the map's key type, but the ordering\n    /// on the borrowed form *must* match the ordering on the key type.\n    ///\n    /// # Examples\n    ///\n    /// Basic usage:\n    ///\n    /// ```\n    /// use std::collections::BTreeMap;\n    ///\n    /// let mut map = BTreeMap::new();\n    /// map.insert(1, \"a\");\n    /// assert_eq!(map.contains_key(&1), true);\n    /// assert_eq!(map.contains_key(&2), false);\n    /// ```\n    #[stable(feature = \"rust1\", since = \"1.0.0\")]\n    pub fn contains_key<Q: ?Sized>(&self, key: &Q) -> bool\n    where\n        K: Borrow<Q> + Ord,\n        Q: Ord,\n    {\n        self.get(key).is_some()\n    }\n\n    /// Returns a mutable reference to the value corresponding to the key.\n    ///\n    /// The key may be any borrowed form of the map's key type, but the ordering\n    /// on the borrowed form *must* match the ordering on the key type.\n    ///\n    /// # Examples\n    ///\n    /// Basic usage:\n    ///\n    /// ```\n    /// use std::collections::BTreeMap;\n    ///\n    /// let mut map = BTreeMap::new();\n    /// map.insert(1, \"a\");\n    /// if let Some(x) = map.get_mut(&1) {\n    ///     *x = \"b\";\n    /// }\n    /// assert_eq!(map[&1], \"b\");\n    /// ```\n    // See `get` for implementation notes, this is basically a copy-paste with mut's added\n    #[stable(feature = \"rust1\", since = \"1.0.0\")]\n    pub fn get_mut<Q: ?Sized>(&mut self, key: &Q) -> Option<&mut V>\n    where\n        K: Borrow<Q> + Ord,\n        Q: Ord,\n    {\n        let root_node = self.root.as_mut()?.borrow_mut();\n        match root_node.search_tree(key) {\n            Found(handle) => Some(handle.into_val_mut()),\n            GoDown(_) => None,\n        }\n    }\n\n    /// Inserts a key-value pair into the map.\n    ///\n    /// If the map did not have this key present, `None` is returned.\n    ///\n    /// If the map did have this key present, the value is updated, and the old\n    /// value is returned. The key is not updated, though; this matters for\n    /// types that can be `==` without being identical. See the [module-level\n    /// documentation] for more.\n    ///\n    /// [module-level documentation]: index.html#insert-and-complex-keys\n    ///\n    /// # Examples\n    ///\n    /// Basic usage:\n    ///\n    /// ```\n    /// use std::collections::BTreeMap;\n    ///\n    /// let mut map = BTreeMap::new();\n    /// assert_eq!(map.insert(37, \"a\"), None);\n    /// assert_eq!(map.is_empty(), false);\n    ///\n    /// map.insert(37, \"b\");\n    /// assert_eq!(map.insert(37, \"c\"), Some(\"b\"));\n    /// assert_eq!(map[&37], \"c\");\n    /// ```\n    #[stable(feature = \"rust1\", since = \"1.0.0\")]\n    pub fn insert(&mut self, key: K, value: V) -> Option<V>\n    where\n        K: Ord,\n    {\n        match self.entry(key) {\n            Occupied(mut entry) => Some(entry.insert(value)),\n            Vacant(entry) => {\n                entry.insert(value);\n                None\n            }\n        }\n    }\n\n    /// Tries to insert a key-value pair into the map, and returns\n    /// a mutable reference to the value in the entry.\n    ///\n    /// If the map already had this key present, nothing is updated, and\n    /// an error containing the occupied entry and the value is returned.\n    ///\n    /// # Examples\n    ///\n    /// Basic usage:\n    ///\n    /// ```\n    /// #![feature(map_try_insert)]\n    ///\n    /// use std::collections::BTreeMap;\n    ///\n    /// let mut map = BTreeMap::new();\n    /// assert_eq!(map.try_insert(37, \"a\").unwrap(), &\"a\");\n    ///\n    /// let err = map.try_insert(37, \"b\").unwrap_err();\n    /// assert_eq!(err.entry.key(), &37);\n    /// assert_eq!(err.entry.get(), &\"a\");\n    /// assert_eq!(err.value, \"b\");\n    /// ```\n    #[unstable(feature = \"map_try_insert\", issue = \"82766\")]\n    pub fn try_insert(&mut self, key: K, value: V) -> Result<&mut V, OccupiedError<'_, K, V>>\n    where\n        K: Ord,\n    {\n        match self.entry(key) {\n            Occupied(entry) => Err(OccupiedError { entry, value }),\n            Vacant(entry) => Ok(entry.insert(value)),\n        }\n    }\n\n    /// Removes a key from the map, returning the value at the key if the key\n    /// was previously in the map.\n    ///\n    /// The key may be any borrowed form of the map's key type, but the ordering\n    /// on the borrowed form *must* match the ordering on the key type.\n    ///\n    /// # Examples\n    ///\n    /// Basic usage:\n    ///\n    /// ```\n    /// use std::collections::BTreeMap;\n    ///\n    /// let mut map = BTreeMap::new();\n    /// map.insert(1, \"a\");\n    /// assert_eq!(map.remove(&1), Some(\"a\"));\n    /// assert_eq!(map.remove(&1), None);\n    /// ```\n    #[doc(alias = \"delete\")]\n    #[stable(feature = \"rust1\", since = \"1.0.0\")]\n    pub fn remove<Q: ?Sized>(&mut self, key: &Q) -> Option<V>\n    where\n        K: Borrow<Q> + Ord,\n        Q: Ord,\n    {\n        self.remove_entry(key).map(|(_, v)| v)\n    }\n\n    /// Removes a key from the map, returning the stored key and value if the key\n    /// was previously in the map.\n    ///\n    /// The key may be any borrowed form of the map's key type, but the ordering\n    /// on the borrowed form *must* match the ordering on the key type.\n    ///\n    /// # Examples\n    ///\n    /// Basic usage:\n    ///\n    /// ```\n    /// use std::collections::BTreeMap;\n    ///\n    /// let mut map = BTreeMap::new();\n    /// map.insert(1, \"a\");\n    /// assert_eq!(map.remove_entry(&1), Some((1, \"a\")));\n    /// assert_eq!(map.remove_entry(&1), None);\n    /// ```\n    #[stable(feature = \"btreemap_remove_entry\", since = \"1.45.0\")]\n    pub fn remove_entry<Q: ?Sized>(&mut self, key: &Q) -> Option<(K, V)>\n    where\n        K: Borrow<Q> + Ord,\n        Q: Ord,\n    {\n        let (map, dormant_map) = DormantMutRef::new(self);\n        let root_node = map.root.as_mut()?.borrow_mut();\n        match root_node.search_tree(key) {\n            Found(handle) => {\n                Some(OccupiedEntry { handle, dormant_map, _marker: PhantomData }.remove_entry())\n            }\n            GoDown(_) => None,\n        }\n    }\n\n    /// Retains only the elements specified by the predicate.\n    ///\n    /// In other words, remove all pairs `(k, v)` such that `f(&k, &mut v)` returns `false`.\n    ///\n    /// # Examples\n    ///\n    /// ```\n    /// use std::collections::BTreeMap;\n    ///\n    /// let mut map: BTreeMap<i32, i32> = (0..8).map(|x| (x, x*10)).collect();\n    /// // Keep only the elements with even-numbered keys.\n    /// map.retain(|&k, _| k % 2 == 0);\n    /// assert!(map.into_iter().eq(vec![(0, 0), (2, 20), (4, 40), (6, 60)]));\n    /// ```\n    #[inline]\n    #[stable(feature = \"btree_retain\", since = \"1.53.0\")]\n    pub fn retain<F>(&mut self, mut f: F)\n    where\n        K: Ord,\n        F: FnMut(&K, &mut V) -> bool,\n    {\n        self.drain_filter(|k, v| !f(k, v));\n    }\n\n    /// Moves all elements from `other` into `Self`, leaving `other` empty.\n    ///\n    /// # Examples\n    ///\n    /// ```\n    /// use std::collections::BTreeMap;\n    ///\n    /// let mut a = BTreeMap::new();\n    /// a.insert(1, \"a\");\n    /// a.insert(2, \"b\");\n    /// a.insert(3, \"c\");\n    ///\n    /// let mut b = BTreeMap::new();\n    /// b.insert(3, \"d\");\n    /// b.insert(4, \"e\");\n    /// b.insert(5, \"f\");\n    ///\n    /// a.append(&mut b);\n    ///\n    /// assert_eq!(a.len(), 5);\n    /// assert_eq!(b.len(), 0);\n    ///\n    /// assert_eq!(a[&1], \"a\");\n    /// assert_eq!(a[&2], \"b\");\n    /// assert_eq!(a[&3], \"d\");\n    /// assert_eq!(a[&4], \"e\");\n    /// assert_eq!(a[&5], \"f\");\n    /// ```\n    #[stable(feature = \"btree_append\", since = \"1.11.0\")]\n    pub fn append(&mut self, other: &mut Self)\n    where\n        K: Ord,\n    {\n        // Do we have to append anything at all?\n        if other.is_empty() {\n            return;\n        }\n\n        // We can just swap `self` and `other` if `self` is empty.\n        if self.is_empty() {\n            mem::swap(self, other);\n            return;\n        }\n\n        let self_iter = mem::take(self).into_iter();\n        let other_iter = mem::take(other).into_iter();\n        let root = BTreeMap::ensure_is_owned(&mut self.root);\n        root.append_from_sorted_iters(self_iter, other_iter, &mut self.length)\n    }\n\n    /// Constructs a double-ended iterator over a sub-range of elements in the map.\n    /// The simplest way is to use the range syntax `min..max`, thus `range(min..max)` will\n    /// yield elements from min (inclusive) to max (exclusive).\n    /// The range may also be entered as `(Bound<T>, Bound<T>)`, so for example\n    /// `range((Excluded(4), Included(10)))` will yield a left-exclusive, right-inclusive\n    /// range from 4 to 10.\n    ///\n    /// # Panics\n    ///\n    /// Panics if range `start > end`.\n    /// Panics if range `start == end` and both bounds are `Excluded`.\n    ///\n    /// # Examples\n    ///\n    /// Basic usage:\n    ///\n    /// ```\n    /// use std::collections::BTreeMap;\n    /// use std::ops::Bound::Included;\n    ///\n    /// let mut map = BTreeMap::new();\n    /// map.insert(3, \"a\");\n    /// map.insert(5, \"b\");\n    /// map.insert(8, \"c\");\n    /// for (&key, &value) in map.range((Included(&4), Included(&8))) {\n    ///     println!(\"{}: {}\", key, value);\n    /// }\n    /// assert_eq!(Some((&5, &\"b\")), map.range(4..).next());\n    /// ```\n    #[stable(feature = \"btree_range\", since = \"1.17.0\")]\n    pub fn range<T: ?Sized, R>(&self, range: R) -> Range<'_, K, V>\n    where\n        T: Ord,\n        K: Borrow<T> + Ord,\n        R: RangeBounds<T>,\n    {\n        if let Some(root) = &self.root {\n            Range { inner: root.reborrow().range_search(range) }\n        } else {\n            Range { inner: LeafRange::none() }\n        }\n    }\n\n    /// Constructs a mutable double-ended iterator over a sub-range of elements in the map.\n    /// The simplest way is to use the range syntax `min..max`, thus `range(min..max)` will\n    /// yield elements from min (inclusive) to max (exclusive).\n    /// The range may also be entered as `(Bound<T>, Bound<T>)`, so for example\n    /// `range((Excluded(4), Included(10)))` will yield a left-exclusive, right-inclusive\n    /// range from 4 to 10.\n    ///\n    /// # Panics\n    ///\n    /// Panics if range `start > end`.\n    /// Panics if range `start == end` and both bounds are `Excluded`.\n    ///\n    /// # Examples\n    ///\n    /// Basic usage:\n    ///\n    /// ```\n    /// use std::collections::BTreeMap;\n    ///\n    /// let mut map: BTreeMap<&str, i32> = [\"Alice\", \"Bob\", \"Carol\", \"Cheryl\"]\n    ///     .iter()\n    ///     .map(|&s| (s, 0))\n    ///     .collect();\n    /// for (_, balance) in map.range_mut(\"B\"..\"Cheryl\") {\n    ///     *balance += 100;\n    /// }\n    /// for (name, balance) in &map {\n    ///     println!(\"{} => {}\", name, balance);\n    /// }\n    /// ```\n    #[stable(feature = \"btree_range\", since = \"1.17.0\")]\n    pub fn range_mut<T: ?Sized, R>(&mut self, range: R) -> RangeMut<'_, K, V>\n    where\n        T: Ord,\n        K: Borrow<T> + Ord,\n        R: RangeBounds<T>,\n    {\n        if let Some(root) = &mut self.root {\n            RangeMut { inner: root.borrow_valmut().range_search(range), _marker: PhantomData }\n        } else {\n            RangeMut { inner: LeafRange::none(), _marker: PhantomData }\n        }\n    }\n\n    /// Gets the given key's corresponding entry in the map for in-place manipulation.\n    ///\n    /// # Examples\n    ///\n    /// Basic usage:\n    ///\n    /// ```\n    /// use std::collections::BTreeMap;\n    ///\n    /// let mut count: BTreeMap<&str, usize> = BTreeMap::new();\n    ///\n    /// // count the number of occurrences of letters in the vec\n    /// for x in vec![\"a\", \"b\", \"a\", \"c\", \"a\", \"b\"] {\n    ///     *count.entry(x).or_insert(0) += 1;\n    /// }\n    ///\n    /// assert_eq!(count[\"a\"], 3);\n    /// ```\n    #[stable(feature = \"rust1\", since = \"1.0.0\")]\n    pub fn entry(&mut self, key: K) -> Entry<'_, K, V>\n    where\n        K: Ord,\n    {\n        // FIXME(@porglezomp) Avoid allocating if we don't insert\n        let (map, dormant_map) = DormantMutRef::new(self);\n        let root_node = Self::ensure_is_owned(&mut map.root).borrow_mut();\n        match root_node.search_tree(&key) {\n            Found(handle) => Occupied(OccupiedEntry { handle, dormant_map, _marker: PhantomData }),\n            GoDown(handle) => {\n                Vacant(VacantEntry { key, handle, dormant_map, _marker: PhantomData })\n            }\n        }\n    }\n\n    /// Splits the collection into two at the given key. Returns everything after the given key,\n    /// including the key.\n    ///\n    /// # Examples\n    ///\n    /// Basic usage:\n    ///\n    /// ```\n    /// use std::collections::BTreeMap;\n    ///\n    /// let mut a = BTreeMap::new();\n    /// a.insert(1, \"a\");\n    /// a.insert(2, \"b\");\n    /// a.insert(3, \"c\");\n    /// a.insert(17, \"d\");\n    /// a.insert(41, \"e\");\n    ///\n    /// let b = a.split_off(&3);\n    ///\n    /// assert_eq!(a.len(), 2);\n    /// assert_eq!(b.len(), 3);\n    ///\n    /// assert_eq!(a[&1], \"a\");\n    /// assert_eq!(a[&2], \"b\");\n    ///\n    /// assert_eq!(b[&3], \"c\");\n    /// assert_eq!(b[&17], \"d\");\n    /// assert_eq!(b[&41], \"e\");\n    /// ```\n    #[stable(feature = \"btree_split_off\", since = \"1.11.0\")]\n    pub fn split_off<Q: ?Sized + Ord>(&mut self, key: &Q) -> Self\n    where\n        K: Borrow<Q> + Ord,\n    {\n        if self.is_empty() {\n            return Self::new();\n        }\n\n        let total_num = self.len();\n        let left_root = self.root.as_mut().unwrap(); // unwrap succeeds because not empty\n\n        let right_root = left_root.split_off(key);\n\n        let (new_left_len, right_len) = Root::calc_split_length(total_num, &left_root, &right_root);\n        self.length = new_left_len;\n\n        BTreeMap { root: Some(right_root), length: right_len }\n    }\n\n    /// Creates an iterator that visits all elements (key-value pairs) in\n    /// ascending key order and uses a closure to determine if an element should\n    /// be removed. If the closure returns `true`, the element is removed from\n    /// the map and yielded. If the closure returns `false`, or panics, the\n    /// element remains in the map and will not be yielded.\n    ///\n    /// The iterator also lets you mutate the value of each element in the\n    /// closure, regardless of whether you choose to keep or remove it.\n    ///\n    /// If the iterator is only partially consumed or not consumed at all, each\n    /// of the remaining elements is still subjected to the closure, which may\n    /// change its value and, by returning `true`, have the element removed and\n    /// dropped.\n    ///\n    /// It is unspecified how many more elements will be subjected to the\n    /// closure if a panic occurs in the closure, or a panic occurs while\n    /// dropping an element, or if the `DrainFilter` value is leaked.\n    ///\n    /// # Examples\n    ///\n    /// Splitting a map into even and odd keys, reusing the original map:\n    ///\n    /// ```\n    /// #![feature(btree_drain_filter)]\n    /// use std::collections::BTreeMap;\n    ///\n    /// let mut map: BTreeMap<i32, i32> = (0..8).map(|x| (x, x)).collect();\n    /// let evens: BTreeMap<_, _> = map.drain_filter(|k, _v| k % 2 == 0).collect();\n    /// let odds = map;\n    /// assert_eq!(evens.keys().copied().collect::<Vec<_>>(), vec![0, 2, 4, 6]);\n    /// assert_eq!(odds.keys().copied().collect::<Vec<_>>(), vec![1, 3, 5, 7]);\n    /// ```\n    #[unstable(feature = \"btree_drain_filter\", issue = \"70530\")]\n    pub fn drain_filter<F>(&mut self, pred: F) -> DrainFilter<'_, K, V, F>\n    where\n        K: Ord,\n        F: FnMut(&K, &mut V) -> bool,\n    {\n        DrainFilter { pred, inner: self.drain_filter_inner() }\n    }\n\n    pub(super) fn drain_filter_inner(&mut self) -> DrainFilterInner<'_, K, V>\n    where\n        K: Ord,\n    {\n        if let Some(root) = self.root.as_mut() {\n            let (root, dormant_root) = DormantMutRef::new(root);\n            let front = root.borrow_mut().first_leaf_edge();\n            DrainFilterInner {\n                length: &mut self.length,\n                dormant_root: Some(dormant_root),\n                cur_leaf_edge: Some(front),\n            }\n        } else {\n            DrainFilterInner { length: &mut self.length, dormant_root: None, cur_leaf_edge: None }\n        }\n    }\n\n    /// Creates a consuming iterator visiting all the keys, in sorted order.\n    /// The map cannot be used after calling this.\n    /// The iterator element type is `K`.\n    ///\n    /// # Examples\n    ///\n    /// ```\n    /// use std::collections::BTreeMap;\n    ///\n    /// let mut a = BTreeMap::new();\n    /// a.insert(2, \"b\");\n    /// a.insert(1, \"a\");\n    ///\n    /// let keys: Vec<i32> = a.into_keys().collect();\n    /// assert_eq!(keys, [1, 2]);\n    /// ```\n    #[inline]\n    #[stable(feature = \"map_into_keys_values\", since = \"1.54.0\")]\n    pub fn into_keys(self) -> IntoKeys<K, V> {\n        IntoKeys { inner: self.into_iter() }\n    }\n\n    /// Creates a consuming iterator visiting all the values, in order by key.\n    /// The map cannot be used after calling this.\n    /// The iterator element type is `V`.\n    ///\n    /// # Examples\n    ///\n    /// ```\n    /// use std::collections::BTreeMap;\n    ///\n    /// let mut a = BTreeMap::new();\n    /// a.insert(1, \"hello\");\n    /// a.insert(2, \"goodbye\");\n    ///\n    /// let values: Vec<&str> = a.into_values().collect();\n    /// assert_eq!(values, [\"hello\", \"goodbye\"]);\n    /// ```\n    #[inline]\n    #[stable(feature = \"map_into_keys_values\", since = \"1.54.0\")]\n    pub fn into_values(self) -> IntoValues<K, V> {\n        IntoValues { inner: self.into_iter() }\n    }\n}\n\n#[stable(feature = \"rust1\", since = \"1.0.0\")]\nimpl<'a, K, V> IntoIterator for &'a BTreeMap<K, V> {\n    type Item = (&'a K, &'a V);\n    type IntoIter = Iter<'a, K, V>;\n\n    fn into_iter(self) -> Iter<'a, K, V> {\n        self.iter()\n    }\n}\n\n#[stable(feature = \"rust1\", since = \"1.0.0\")]\nimpl<'a, K: 'a, V: 'a> Iterator for Iter<'a, K, V> {\n    type Item = (&'a K, &'a V);\n\n    fn next(&mut self) -> Option<(&'a K, &'a V)> {\n        if self.length == 0 {\n            None\n        } else {\n            self.length -= 1;\n            Some(unsafe { self.range.inner.next_unchecked() })\n        }\n    }\n\n    fn size_hint(&self) -> (usize, Option<usize>) {\n        (self.length, Some(self.length))\n    }\n\n    fn last(mut self) -> Option<(&'a K, &'a V)> {\n        self.next_back()\n    }\n\n    fn min(mut self) -> Option<(&'a K, &'a V)> {\n        self.next()\n    }\n\n    fn max(mut self) -> Option<(&'a K, &'a V)> {\n        self.next_back()\n    }\n}\n\n#[stable(feature = \"fused\", since = \"1.26.0\")]\nimpl<K, V> FusedIterator for Iter<'_, K, V> {}\n\n#[stable(feature = \"rust1\", since = \"1.0.0\")]\nimpl<'a, K: 'a, V: 'a> DoubleEndedIterator for Iter<'a, K, V> {\n    fn next_back(&mut self) -> Option<(&'a K, &'a V)> {\n        if self.length == 0 {\n            None\n        } else {\n            self.length -= 1;\n            Some(unsafe { self.range.inner.next_back_unchecked() })\n        }\n    }\n}\n\n#[stable(feature = \"rust1\", since = \"1.0.0\")]\nimpl<K, V> ExactSizeIterator for Iter<'_, K, V> {\n    fn len(&self) -> usize {\n        self.length\n    }\n}\n\n#[stable(feature = \"rust1\", since = \"1.0.0\")]\nimpl<K, V> Clone for Iter<'_, K, V> {\n    fn clone(&self) -> Self {\n        Iter { range: self.range.clone(), length: self.length }\n    }\n}\n\n#[stable(feature = \"rust1\", since = \"1.0.0\")]\nimpl<'a, K, V> IntoIterator for &'a mut BTreeMap<K, V> {\n    type Item = (&'a K, &'a mut V);\n    type IntoIter = IterMut<'a, K, V>;\n\n    fn into_iter(self) -> IterMut<'a, K, V> {\n        self.iter_mut()\n    }\n}\n\n#[stable(feature = \"rust1\", since = \"1.0.0\")]\nimpl<'a, K: 'a, V: 'a> Iterator for IterMut<'a, K, V> {\n    type Item = (&'a K, &'a mut V);\n\n    fn next(&mut self) -> Option<(&'a K, &'a mut V)> {\n        if self.length == 0 {\n            None\n        } else {\n            self.length -= 1;\n            Some(unsafe { self.range.inner.next_unchecked() })\n        }\n    }\n\n    fn size_hint(&self) -> (usize, Option<usize>) {\n        (self.length, Some(self.length))\n    }\n\n    fn last(mut self) -> Option<(&'a K, &'a mut V)> {\n        self.next_back()\n    }\n\n    fn min(mut self) -> Option<(&'a K, &'a mut V)> {\n        self.next()\n    }\n\n    fn max(mut self) -> Option<(&'a K, &'a mut V)> {\n        self.next_back()\n    }\n}\n\n#[stable(feature = \"rust1\", since = \"1.0.0\")]\nimpl<'a, K: 'a, V: 'a> DoubleEndedIterator for IterMut<'a, K, V> {\n    fn next_back(&mut self) -> Option<(&'a K, &'a mut V)> {\n        if self.length == 0 {\n            None\n        } else {\n            self.length -= 1;\n            Some(unsafe { self.range.inner.next_back_unchecked() })\n        }\n    }\n}\n\n#[stable(feature = \"rust1\", since = \"1.0.0\")]\nimpl<K, V> ExactSizeIterator for IterMut<'_, K, V> {\n    fn len(&self) -> usize {\n        self.length\n    }\n}\n\n#[stable(feature = \"fused\", since = \"1.26.0\")]\nimpl<K, V> FusedIterator for IterMut<'_, K, V> {}\n\nimpl<'a, K, V> IterMut<'a, K, V> {\n    /// Returns an iterator of references over the remaining items.\n    #[inline]\n    pub(super) fn iter(&self) -> Iter<'_, K, V> {\n        Iter { range: self.range.iter(), length: self.length }\n    }\n}\n\n#[stable(feature = \"rust1\", since = \"1.0.0\")]\nimpl<K, V> IntoIterator for BTreeMap<K, V> {\n    type Item = (K, V);\n    type IntoIter = IntoIter<K, V>;\n\n    fn into_iter(self) -> IntoIter<K, V> {\n        let mut me = ManuallyDrop::new(self);\n        if let Some(root) = me.root.take() {\n            let full_range = root.into_dying().full_range();\n\n            IntoIter { range: full_range, length: me.length }\n        } else {\n            IntoIter { range: LeafRange::none(), length: 0 }\n        }\n    }\n}\n\nimpl<K, V> Drop for Dropper<K, V> {\n    fn drop(&mut self) {\n        // Similar to advancing a non-fusing iterator.\n        fn next_or_end<K, V>(\n            this: &mut Dropper<K, V>,\n        ) -> Option<Handle<NodeRef<marker::Dying, K, V, marker::LeafOrInternal>, marker::KV>>\n        {\n            if this.remaining_length == 0 {\n                unsafe { ptr::read(&this.front).deallocating_end() }\n                None\n            } else {\n                this.remaining_length -= 1;\n                Some(unsafe { this.front.deallocating_next_unchecked() })\n            }\n        }\n\n        struct DropGuard<'a, K, V>(&'a mut Dropper<K, V>);\n\n        impl<'a, K, V> Drop for DropGuard<'a, K, V> {\n            fn drop(&mut self) {\n                // Continue the same loop we perform below. This only runs when unwinding, so we\n                // don't have to care about panics this time (they'll abort).\n                while let Some(kv) = next_or_end(&mut self.0) {\n                    kv.drop_key_val();\n                }\n            }\n        }\n\n        while let Some(kv) = next_or_end(self) {\n            let guard = DropGuard(self);\n            kv.drop_key_val();\n            mem::forget(guard);\n        }\n    }\n}\n\n#[stable(feature = \"btree_drop\", since = \"1.7.0\")]\nimpl<K, V> Drop for IntoIter<K, V> {\n    fn drop(&mut self) {\n        if let Some(front) = self.range.take_front() {\n            Dropper { front, remaining_length: self.length };\n        }\n    }\n}\n\n#[stable(feature = \"rust1\", since = \"1.0.0\")]\nimpl<K, V> Iterator for IntoIter<K, V> {\n    type Item = (K, V);\n\n    fn next(&mut self) -> Option<(K, V)> {\n        if self.length == 0 {\n            None\n        } else {\n            self.length -= 1;\n            let kv = unsafe { self.range.deallocating_next_unchecked() };\n            Some(kv.into_key_val())\n        }\n    }\n\n    fn size_hint(&self) -> (usize, Option<usize>) {\n        (self.length, Some(self.length))\n    }\n}\n\n#[stable(feature = \"rust1\", since = \"1.0.0\")]\nimpl<K, V> DoubleEndedIterator for IntoIter<K, V> {\n    fn next_back(&mut self) -> Option<(K, V)> {\n        if self.length == 0 {\n            None\n        } else {\n            self.length -= 1;\n            let kv = unsafe { self.range.deallocating_next_back_unchecked() };\n            Some(kv.into_key_val())\n        }\n    }\n}\n\n#[stable(feature = \"rust1\", since = \"1.0.0\")]\nimpl<K, V> ExactSizeIterator for IntoIter<K, V> {\n    fn len(&self) -> usize {\n        self.length\n    }\n}\n\n#[stable(feature = \"fused\", since = \"1.26.0\")]\nimpl<K, V> FusedIterator for IntoIter<K, V> {}\n\n#[stable(feature = \"rust1\", since = \"1.0.0\")]\nimpl<'a, K, V> Iterator for Keys<'a, K, V> {\n    type Item = &'a K;\n\n    fn next(&mut self) -> Option<&'a K> {\n        self.inner.next().map(|(k, _)| k)\n    }\n\n    fn size_hint(&self) -> (usize, Option<usize>) {\n        self.inner.size_hint()\n    }\n\n    fn last(mut self) -> Option<&'a K> {\n        self.next_back()\n    }\n\n    fn min(mut self) -> Option<&'a K> {\n        self.next()\n    }\n\n    fn max(mut self) -> Option<&'a K> {\n        self.next_back()\n    }\n}\n\n#[stable(feature = \"rust1\", since = \"1.0.0\")]\nimpl<'a, K, V> DoubleEndedIterator for Keys<'a, K, V> {\n    fn next_back(&mut self) -> Option<&'a K> {\n        self.inner.next_back().map(|(k, _)| k)\n    }\n}\n\n#[stable(feature = \"rust1\", since = \"1.0.0\")]\nimpl<K, V> ExactSizeIterator for Keys<'_, K, V> {\n    fn len(&self) -> usize {\n        self.inner.len()\n    }\n}\n\n#[stable(feature = \"fused\", since = \"1.26.0\")]\nimpl<K, V> FusedIterator for Keys<'_, K, V> {}\n\n#[stable(feature = \"rust1\", since = \"1.0.0\")]\nimpl<K, V> Clone for Keys<'_, K, V> {\n    fn clone(&self) -> Self {\n        Keys { inner: self.inner.clone() }\n    }\n}\n\n#[stable(feature = \"rust1\", since = \"1.0.0\")]\nimpl<'a, K, V> Iterator for Values<'a, K, V> {\n    type Item = &'a V;\n\n    fn next(&mut self) -> Option<&'a V> {\n        self.inner.next().map(|(_, v)| v)\n    }\n\n    fn size_hint(&self) -> (usize, Option<usize>) {\n        self.inner.size_hint()\n    }\n\n    fn last(mut self) -> Option<&'a V> {\n        self.next_back()\n    }\n}\n\n#[stable(feature = \"rust1\", since = \"1.0.0\")]\nimpl<'a, K, V> DoubleEndedIterator for Values<'a, K, V> {\n    fn next_back(&mut self) -> Option<&'a V> {\n        self.inner.next_back().map(|(_, v)| v)\n    }\n}\n\n#[stable(feature = \"rust1\", since = \"1.0.0\")]\nimpl<K, V> ExactSizeIterator for Values<'_, K, V> {\n    fn len(&self) -> usize {\n        self.inner.len()\n    }\n}\n\n#[stable(feature = \"fused\", since = \"1.26.0\")]\nimpl<K, V> FusedIterator for Values<'_, K, V> {}\n\n#[stable(feature = \"rust1\", since = \"1.0.0\")]\nimpl<K, V> Clone for Values<'_, K, V> {\n    fn clone(&self) -> Self {\n        Values { inner: self.inner.clone() }\n    }\n}\n\n/// An iterator produced by calling `drain_filter` on BTreeMap.\n#[unstable(feature = \"btree_drain_filter\", issue = \"70530\")]\npub struct DrainFilter<'a, K, V, F>\nwhere\n    K: 'a,\n    V: 'a,\n    F: 'a + FnMut(&K, &mut V) -> bool,\n{\n    pred: F,\n    inner: DrainFilterInner<'a, K, V>,\n}\n/// Most of the implementation of DrainFilter are generic over the type\n/// of the predicate, thus also serving for BTreeSet::DrainFilter.\npub(super) struct DrainFilterInner<'a, K: 'a, V: 'a> {\n    /// Reference to the length field in the borrowed map, updated live.\n    length: &'a mut usize,\n    /// Buried reference to the root field in the borrowed map.\n    /// Wrapped in `Option` to allow drop handler to `take` it.\n    dormant_root: Option<DormantMutRef<'a, Root<K, V>>>,\n    /// Contains a leaf edge preceding the next element to be returned, or the last leaf edge.\n    /// Empty if the map has no root, if iteration went beyond the last leaf edge,\n    /// or if a panic occurred in the predicate.\n    cur_leaf_edge: Option<Handle<NodeRef<marker::Mut<'a>, K, V, marker::Leaf>, marker::Edge>>,\n}\n\n#[unstable(feature = \"btree_drain_filter\", issue = \"70530\")]\nimpl<K, V, F> Drop for DrainFilter<'_, K, V, F>\nwhere\n    F: FnMut(&K, &mut V) -> bool,\n{\n    fn drop(&mut self) {\n        self.for_each(drop);\n    }\n}\n\n#[unstable(feature = \"btree_drain_filter\", issue = \"70530\")]\nimpl<K, V, F> fmt::Debug for DrainFilter<'_, K, V, F>\nwhere\n    K: fmt::Debug,\n    V: fmt::Debug,\n    F: FnMut(&K, &mut V) -> bool,\n{\n    fn fmt(&self, f: &mut fmt::Formatter<'_>) -> fmt::Result {\n        f.debug_tuple(\"DrainFilter\").field(&self.inner.peek()).finish()\n    }\n}\n\n#[unstable(feature = \"btree_drain_filter\", issue = \"70530\")]\nimpl<K, V, F> Iterator for DrainFilter<'_, K, V, F>\nwhere\n    F: FnMut(&K, &mut V) -> bool,\n{\n    type Item = (K, V);\n\n    fn next(&mut self) -> Option<(K, V)> {\n        self.inner.next(&mut self.pred)\n    }\n\n    fn size_hint(&self) -> (usize, Option<usize>) {\n        self.inner.size_hint()\n    }\n}\n\nimpl<'a, K: 'a, V: 'a> DrainFilterInner<'a, K, V> {\n    /// Allow Debug implementations to predict the next element.\n    pub(super) fn peek(&self) -> Option<(&K, &V)> {\n        let edge = self.cur_leaf_edge.as_ref()?;\n        edge.reborrow().next_kv().ok().map(Handle::into_kv)\n    }\n\n    /// Implementation of a typical `DrainFilter::next` method, given the predicate.\n    pub(super) fn next<F>(&mut self, pred: &mut F) -> Option<(K, V)>\n    where\n        F: FnMut(&K, &mut V) -> bool,\n    {\n        while let Ok(mut kv) = self.cur_leaf_edge.take()?.next_kv() {\n            let (k, v) = kv.kv_mut();\n            if pred(k, v) {\n                *self.length -= 1;\n                let (kv, pos) = kv.remove_kv_tracking(|| {\n                    // SAFETY: we will touch the root in a way that will not\n                    // invalidate the position returned.\n                    let root = unsafe { self.dormant_root.take().unwrap().awaken() };\n                    root.pop_internal_level();\n                    self.dormant_root = Some(DormantMutRef::new(root).1);\n                });\n                self.cur_leaf_edge = Some(pos);\n                return Some(kv);\n            }\n            self.cur_leaf_edge = Some(kv.next_leaf_edge());\n        }\n        None\n    }\n\n    /// Implementation of a typical `DrainFilter::size_hint` method.\n    pub(super) fn size_hint(&self) -> (usize, Option<usize>) {\n        // In most of the btree iterators, `self.length` is the number of elements\n        // yet to be visited. Here, it includes elements that were visited and that\n        // the predicate decided not to drain. Making this upper bound more accurate\n        // requires maintaining an extra field and is not worth while.\n        (0, Some(*self.length))\n    }\n}\n\n#[unstable(feature = \"btree_drain_filter\", issue = \"70530\")]\nimpl<K, V, F> FusedIterator for DrainFilter<'_, K, V, F> where F: FnMut(&K, &mut V) -> bool {}\n\n#[stable(feature = \"btree_range\", since = \"1.17.0\")]\nimpl<'a, K, V> Iterator for Range<'a, K, V> {\n    type Item = (&'a K, &'a V);\n\n    fn next(&mut self) -> Option<(&'a K, &'a V)> {\n        self.inner.next_checked()\n    }\n\n    fn last(mut self) -> Option<(&'a K, &'a V)> {\n        self.next_back()\n    }\n\n    fn min(mut self) -> Option<(&'a K, &'a V)> {\n        self.next()\n    }\n\n    fn max(mut self) -> Option<(&'a K, &'a V)> {\n        self.next_back()\n    }\n}\n\n#[stable(feature = \"map_values_mut\", since = \"1.10.0\")]\nimpl<'a, K, V> Iterator for ValuesMut<'a, K, V> {\n    type Item = &'a mut V;\n\n    fn next(&mut self) -> Option<&'a mut V> {\n        self.inner.next().map(|(_, v)| v)\n    }\n\n    fn size_hint(&self) -> (usize, Option<usize>) {\n        self.inner.size_hint()\n    }\n\n    fn last(mut self) -> Option<&'a mut V> {\n        self.next_back()\n    }\n}\n\n#[stable(feature = \"map_values_mut\", since = \"1.10.0\")]\nimpl<'a, K, V> DoubleEndedIterator for ValuesMut<'a, K, V> {\n    fn next_back(&mut self) -> Option<&'a mut V> {\n        self.inner.next_back().map(|(_, v)| v)\n    }\n}\n\n#[stable(feature = \"map_values_mut\", since = \"1.10.0\")]\nimpl<K, V> ExactSizeIterator for ValuesMut<'_, K, V> {\n    fn len(&self) -> usize {\n        self.inner.len()\n    }\n}\n\n#[stable(feature = \"fused\", since = \"1.26.0\")]\nimpl<K, V> FusedIterator for ValuesMut<'_, K, V> {}\n\n#[stable(feature = \"map_into_keys_values\", since = \"1.54.0\")]\nimpl<K, V> Iterator for IntoKeys<K, V> {\n    type Item = K;\n\n    fn next(&mut self) -> Option<K> {\n        self.inner.next().map(|(k, _)| k)\n    }\n\n    fn size_hint(&self) -> (usize, Option<usize>) {\n        self.inner.size_hint()\n    }\n\n    fn last(mut self) -> Option<K> {\n        self.next_back()\n    }\n\n    fn min(mut self) -> Option<K> {\n        self.next()\n    }\n\n    fn max(mut self) -> Option<K> {\n        self.next_back()\n    }\n}\n\n#[stable(feature = \"map_into_keys_values\", since = \"1.54.0\")]\nimpl<K, V> DoubleEndedIterator for IntoKeys<K, V> {\n    fn next_back(&mut self) -> Option<K> {\n        self.inner.next_back().map(|(k, _)| k)\n    }\n}\n\n#[stable(feature = \"map_into_keys_values\", since = \"1.54.0\")]\nimpl<K, V> ExactSizeIterator for IntoKeys<K, V> {\n    fn len(&self) -> usize {\n        self.inner.len()\n    }\n}\n\n#[stable(feature = \"map_into_keys_values\", since = \"1.54.0\")]\nimpl<K, V> FusedIterator for IntoKeys<K, V> {}\n\n#[stable(feature = \"map_into_keys_values\", since = \"1.54.0\")]\nimpl<K, V> Iterator for IntoValues<K, V> {\n    type Item = V;\n\n    fn next(&mut self) -> Option<V> {\n        self.inner.next().map(|(_, v)| v)\n    }\n\n    fn size_hint(&self) -> (usize, Option<usize>) {\n        self.inner.size_hint()\n    }\n\n    fn last(mut self) -> Option<V> {\n        self.next_back()\n    }\n}\n\n#[stable(feature = \"map_into_keys_values\", since = \"1.54.0\")]\nimpl<K, V> DoubleEndedIterator for IntoValues<K, V> {\n    fn next_back(&mut self) -> Option<V> {\n        self.inner.next_back().map(|(_, v)| v)\n    }\n}\n\n#[stable(feature = \"map_into_keys_values\", since = \"1.54.0\")]\nimpl<K, V> ExactSizeIterator for IntoValues<K, V> {\n    fn len(&self) -> usize {\n        self.inner.len()\n    }\n}\n\n#[stable(feature = \"map_into_keys_values\", since = \"1.54.0\")]\nimpl<K, V> FusedIterator for IntoValues<K, V> {}\n\n#[stable(feature = \"btree_range\", since = \"1.17.0\")]\nimpl<'a, K, V> DoubleEndedIterator for Range<'a, K, V> {\n    fn next_back(&mut self) -> Option<(&'a K, &'a V)> {\n        self.inner.next_back_checked()\n    }\n}\n\n#[stable(feature = \"fused\", since = \"1.26.0\")]\nimpl<K, V> FusedIterator for Range<'_, K, V> {}\n\n#[stable(feature = \"btree_range\", since = \"1.17.0\")]\nimpl<K, V> Clone for Range<'_, K, V> {\n    fn clone(&self) -> Self {\n        Range { inner: self.inner.clone() }\n    }\n}\n\n#[stable(feature = \"btree_range\", since = \"1.17.0\")]\nimpl<'a, K, V> Iterator for RangeMut<'a, K, V> {\n    type Item = (&'a K, &'a mut V);\n\n    fn next(&mut self) -> Option<(&'a K, &'a mut V)> {\n        self.inner.next_checked()\n    }\n\n    fn last(mut self) -> Option<(&'a K, &'a mut V)> {\n        self.next_back()\n    }\n\n    fn min(mut self) -> Option<(&'a K, &'a mut V)> {\n        self.next()\n    }\n\n    fn max(mut self) -> Option<(&'a K, &'a mut V)> {\n        self.next_back()\n    }\n}\n\nimpl<'a, K, V> RangeMut<'a, K, V> {\n    /// Returns an iterator of references over the remaining items.\n    #[inline]\n    pub(super) fn iter(&self) -> Range<'_, K, V> {\n        Range { inner: self.inner.reborrow() }\n    }\n}\n\n#[stable(feature = \"btree_range\", since = \"1.17.0\")]\nimpl<'a, K, V> DoubleEndedIterator for RangeMut<'a, K, V> {\n    fn next_back(&mut self) -> Option<(&'a K, &'a mut V)> {\n        self.inner.next_back_checked()\n    }\n}\n\n#[stable(feature = \"fused\", since = \"1.26.0\")]\nimpl<K, V> FusedIterator for RangeMut<'_, K, V> {}\n\n#[stable(feature = \"rust1\", since = \"1.0.0\")]\nimpl<K: Ord, V> FromIterator<(K, V)> for BTreeMap<K, V> {\n    fn from_iter<T: IntoIterator<Item = (K, V)>>(iter: T) -> BTreeMap<K, V> {\n        let mut map = BTreeMap::new();\n        map.extend(iter);\n        map\n    }\n}\n\n#[stable(feature = \"rust1\", since = \"1.0.0\")]\nimpl<K: Ord, V> Extend<(K, V)> for BTreeMap<K, V> {\n    #[inline]\n    fn extend<T: IntoIterator<Item = (K, V)>>(&mut self, iter: T) {\n        iter.into_iter().for_each(move |(k, v)| {\n            self.insert(k, v);\n        });\n    }\n\n    #[inline]\n    fn extend_one(&mut self, (k, v): (K, V)) {\n        self.insert(k, v);\n    }\n}\n\n#[stable(feature = \"extend_ref\", since = \"1.2.0\")]\nimpl<'a, K: Ord + Copy, V: Copy> Extend<(&'a K, &'a V)> for BTreeMap<K, V> {\n    fn extend<I: IntoIterator<Item = (&'a K, &'a V)>>(&mut self, iter: I) {\n        self.extend(iter.into_iter().map(|(&key, &value)| (key, value)));\n    }\n\n    #[inline]\n    fn extend_one(&mut self, (&k, &v): (&'a K, &'a V)) {\n        self.insert(k, v);\n    }\n}\n\n#[stable(feature = \"rust1\", since = \"1.0.0\")]\nimpl<K: Hash, V: Hash> Hash for BTreeMap<K, V> {\n    fn hash<H: Hasher>(&self, state: &mut H) {\n        for elt in self {\n            elt.hash(state);\n        }\n    }\n}\n\n#[stable(feature = \"rust1\", since = \"1.0.0\")]\nimpl<K: Ord, V> Default for BTreeMap<K, V> {\n    /// Creates an empty `BTreeMap`.\n    fn default() -> BTreeMap<K, V> {\n        BTreeMap::new()\n    }\n}\n\n#[stable(feature = \"rust1\", since = \"1.0.0\")]\nimpl<K: PartialEq, V: PartialEq> PartialEq for BTreeMap<K, V> {\n    fn eq(&self, other: &BTreeMap<K, V>) -> bool {\n        self.len() == other.len() && self.iter().zip(other).all(|(a, b)| a == b)\n    }\n}\n\n#[stable(feature = \"rust1\", since = \"1.0.0\")]\nimpl<K: Eq, V: Eq> Eq for BTreeMap<K, V> {}\n\n#[stable(feature = \"rust1\", since = \"1.0.0\")]\nimpl<K: PartialOrd, V: PartialOrd> PartialOrd for BTreeMap<K, V> {\n    #[inline]\n    fn partial_cmp(&self, other: &BTreeMap<K, V>) -> Option<Ordering> {\n        self.iter().partial_cmp(other.iter())\n    }\n}\n\n#[stable(feature = \"rust1\", since = \"1.0.0\")]\nimpl<K: Ord, V: Ord> Ord for BTreeMap<K, V> {\n    #[inline]\n    fn cmp(&self, other: &BTreeMap<K, V>) -> Ordering {\n        self.iter().cmp(other.iter())\n    }\n}\n\n#[stable(feature = \"rust1\", since = \"1.0.0\")]\nimpl<K: Debug, V: Debug> Debug for BTreeMap<K, V> {\n    fn fmt(&self, f: &mut fmt::Formatter<'_>) -> fmt::Result {\n        f.debug_map().entries(self.iter()).finish()\n    }\n}\n\n#[stable(feature = \"rust1\", since = \"1.0.0\")]\nimpl<K, Q: ?Sized, V> Index<&Q> for BTreeMap<K, V>\nwhere\n    K: Borrow<Q> + Ord,\n    Q: Ord,\n{\n    type Output = V;\n\n    /// Returns a reference to the value corresponding to the supplied key.\n    ///\n    /// # Panics\n    ///\n    /// Panics if the key is not present in the `BTreeMap`.\n    #[inline]\n    fn index(&self, key: &Q) -> &V {\n        self.get(key).expect(\"no entry found for key\")\n    }\n}\n\nimpl<K, V> BTreeMap<K, V> {\n    /// Gets an iterator over the entries of the map, sorted by key.\n    ///\n    /// # Examples\n    ///\n    /// Basic usage:\n    ///\n    /// ```\n    /// use std::collections::BTreeMap;\n    ///\n    /// let mut map = BTreeMap::new();\n    /// map.insert(3, \"c\");\n    /// map.insert(2, \"b\");\n    /// map.insert(1, \"a\");\n    ///\n    /// for (key, value) in map.iter() {\n    ///     println!(\"{}: {}\", key, value);\n    /// }\n    ///\n    /// let (first_key, first_value) = map.iter().next().unwrap();\n    /// assert_eq!((*first_key, *first_value), (1, \"a\"));\n    /// ```\n    #[stable(feature = \"rust1\", since = \"1.0.0\")]\n    pub fn iter(&self) -> Iter<'_, K, V> {\n        if let Some(root) = &self.root {\n            let full_range = root.reborrow().full_range();\n\n            Iter { range: Range { inner: full_range }, length: self.length }\n        } else {\n            Iter { range: Range { inner: LeafRange::none() }, length: 0 }\n        }\n    }\n\n    /// Gets a mutable iterator over the entries of the map, sorted by key.\n    ///\n    /// # Examples\n    ///\n    /// Basic usage:\n    ///\n    /// ```\n    /// use std::collections::BTreeMap;\n    ///\n    /// let mut map = BTreeMap::new();\n    /// map.insert(\"a\", 1);\n    /// map.insert(\"b\", 2);\n    /// map.insert(\"c\", 3);\n    ///\n    /// // add 10 to the value if the key isn't \"a\"\n    /// for (key, value) in map.iter_mut() {\n    ///     if key != &\"a\" {\n    ///         *value += 10;\n    ///     }\n    /// }\n    /// ```\n    #[stable(feature = \"rust1\", since = \"1.0.0\")]\n    pub fn iter_mut(&mut self) -> IterMut<'_, K, V> {\n        if let Some(root) = &mut self.root {\n            let full_range = root.borrow_valmut().full_range();\n\n            IterMut {\n                range: RangeMut { inner: full_range, _marker: PhantomData },\n                length: self.length,\n            }\n        } else {\n            IterMut {\n                range: RangeMut { inner: LeafRange::none(), _marker: PhantomData },\n                length: 0,\n            }\n        }\n    }\n\n    /// Gets an iterator over the keys of the map, in sorted order.\n    ///\n    /// # Examples\n    ///\n    /// Basic usage:\n    ///\n    /// ```\n    /// use std::collections::BTreeMap;\n    ///\n    /// let mut a = BTreeMap::new();\n    /// a.insert(2, \"b\");\n    /// a.insert(1, \"a\");\n    ///\n    /// let keys: Vec<_> = a.keys().cloned().collect();\n    /// assert_eq!(keys, [1, 2]);\n    /// ```\n    #[stable(feature = \"rust1\", since = \"1.0.0\")]\n    pub fn keys(&self) -> Keys<'_, K, V> {\n        Keys { inner: self.iter() }\n    }\n\n    /// Gets an iterator over the values of the map, in order by key.\n    ///\n    /// # Examples\n    ///\n    /// Basic usage:\n    ///\n    /// ```\n    /// use std::collections::BTreeMap;\n    ///\n    /// let mut a = BTreeMap::new();\n    /// a.insert(1, \"hello\");\n    /// a.insert(2, \"goodbye\");\n    ///\n    /// let values: Vec<&str> = a.values().cloned().collect();\n    /// assert_eq!(values, [\"hello\", \"goodbye\"]);\n    /// ```\n    #[stable(feature = \"rust1\", since = \"1.0.0\")]\n    pub fn values(&self) -> Values<'_, K, V> {\n        Values { inner: self.iter() }\n    }\n\n    /// Gets a mutable iterator over the values of the map, in order by key.\n    ///\n    /// # Examples\n    ///\n    /// Basic usage:\n    ///\n    /// ```\n    /// use std::collections::BTreeMap;\n    ///\n    /// let mut a = BTreeMap::new();\n    /// a.insert(1, String::from(\"hello\"));\n    /// a.insert(2, String::from(\"goodbye\"));\n    ///\n    /// for value in a.values_mut() {\n    ///     value.push_str(\"!\");\n    /// }\n    ///\n    /// let values: Vec<String> = a.values().cloned().collect();\n    /// assert_eq!(values, [String::from(\"hello!\"),\n    ///                     String::from(\"goodbye!\")]);\n    /// ```\n    #[stable(feature = \"map_values_mut\", since = \"1.10.0\")]\n    pub fn values_mut(&mut self) -> ValuesMut<'_, K, V> {\n        ValuesMut { inner: self.iter_mut() }\n    }\n\n    /// Returns the number of elements in the map.\n    ///\n    /// # Examples\n    ///\n    /// Basic usage:\n    ///\n    /// ```\n    /// use std::collections::BTreeMap;\n    ///\n    /// let mut a = BTreeMap::new();\n    /// assert_eq!(a.len(), 0);\n    /// a.insert(1, \"a\");\n    /// assert_eq!(a.len(), 1);\n    /// ```\n    #[doc(alias = \"length\")]\n    #[stable(feature = \"rust1\", since = \"1.0.0\")]\n    #[rustc_const_unstable(feature = \"const_btree_new\", issue = \"71835\")]\n    pub const fn len(&self) -> usize {\n        self.length\n    }\n\n    /// Returns `true` if the map contains no elements.\n    ///\n    /// # Examples\n    ///\n    /// Basic usage:\n    ///\n    /// ```\n    /// use std::collections::BTreeMap;\n    ///\n    /// let mut a = BTreeMap::new();\n    /// assert!(a.is_empty());\n    /// a.insert(1, \"a\");\n    /// assert!(!a.is_empty());\n    /// ```\n    #[stable(feature = \"rust1\", since = \"1.0.0\")]\n    #[rustc_const_unstable(feature = \"const_btree_new\", issue = \"71835\")]\n    pub const fn is_empty(&self) -> bool {\n        self.len() == 0\n    }\n\n    /// If the root node is the empty (non-allocated) root node, allocate our\n    /// own node. Is an associated function to avoid borrowing the entire BTreeMap.\n    fn ensure_is_owned(root: &mut Option<Root<K, V>>) -> &mut Root<K, V> {\n        root.get_or_insert_with(Root::new)\n    }\n}\n\n#[cfg(test)]\nmod tests;\n"],[2042,"// This is pretty much entirely stolen from TreeSet, since BTreeMap has an identical interface\n// to TreeMap\n\nuse core::borrow::Borrow;\nuse core::cmp::Ordering::{Equal, Greater, Less};\nuse core::cmp::{max, min};\nuse core::fmt::{self, Debug};\nuse core::iter::{FromIterator, FusedIterator, Peekable};\nuse core::ops::{BitAnd, BitOr, BitXor, RangeBounds, Sub};\n\nuse super::map::{BTreeMap, Keys};\nuse super::merge_iter::MergeIterInner;\nuse super::Recover;\n\n// FIXME(conventions): implement bounded iterators\n\n/// A set based on a B-Tree.\n///\n/// See [`BTreeMap`]'s documentation for a detailed discussion of this collection's performance\n/// benefits and drawbacks.\n///\n/// It is a logic error for an item to be modified in such a way that the item's ordering relative\n/// to any other item, as determined by the [`Ord`] trait, changes while it is in the set. This is\n/// normally only possible through [`Cell`], [`RefCell`], global state, I/O, or unsafe code.\n/// The behavior resulting from such a logic error is not specified, but will not result in\n/// undefined behavior. This could include panics, incorrect results, aborts, memory leaks, and\n/// non-termination.\n///\n/// [`Ord`]: core::cmp::Ord\n/// [`Cell`]: core::cell::Cell\n/// [`RefCell`]: core::cell::RefCell\n///\n/// # Examples\n///\n/// ```\n/// use std::collections::BTreeSet;\n///\n/// // Type inference lets us omit an explicit type signature (which\n/// // would be `BTreeSet<&str>` in this example).\n/// let mut books = BTreeSet::new();\n///\n/// // Add some books.\n/// books.insert(\"A Dance With Dragons\");\n/// books.insert(\"To Kill a Mockingbird\");\n/// books.insert(\"The Odyssey\");\n/// books.insert(\"The Great Gatsby\");\n///\n/// // Check for a specific one.\n/// if !books.contains(\"The Winds of Winter\") {\n///     println!(\"We have {} books, but The Winds of Winter ain't one.\",\n///              books.len());\n/// }\n///\n/// // Remove a book.\n/// books.remove(\"The Odyssey\");\n///\n/// // Iterate over everything.\n/// for book in &books {\n///     println!(\"{}\", book);\n/// }\n/// ```\n#[derive(Hash, PartialEq, Eq, Ord, PartialOrd)]\n#[stable(feature = \"rust1\", since = \"1.0.0\")]\n#[cfg_attr(not(test), rustc_diagnostic_item = \"BTreeSet\")]\npub struct BTreeSet<T> {\n    map: BTreeMap<T, ()>,\n}\n\n#[stable(feature = \"rust1\", since = \"1.0.0\")]\nimpl<T: Clone> Clone for BTreeSet<T> {\n    fn clone(&self) -> Self {\n        BTreeSet { map: self.map.clone() }\n    }\n\n    fn clone_from(&mut self, other: &Self) {\n        self.map.clone_from(&other.map);\n    }\n}\n\n/// An iterator over the items of a `BTreeSet`.\n///\n/// This `struct` is created by the [`iter`] method on [`BTreeSet`].\n/// See its documentation for more.\n///\n/// [`iter`]: BTreeSet::iter\n#[stable(feature = \"rust1\", since = \"1.0.0\")]\npub struct Iter<'a, T: 'a> {\n    iter: Keys<'a, T, ()>,\n}\n\n#[stable(feature = \"collection_debug\", since = \"1.17.0\")]\nimpl<T: fmt::Debug> fmt::Debug for Iter<'_, T> {\n    fn fmt(&self, f: &mut fmt::Formatter<'_>) -> fmt::Result {\n        f.debug_tuple(\"Iter\").field(&self.iter.clone()).finish()\n    }\n}\n\n/// An owning iterator over the items of a `BTreeSet`.\n///\n/// This `struct` is created by the [`into_iter`] method on [`BTreeSet`]\n/// (provided by the `IntoIterator` trait). See its documentation for more.\n///\n/// [`into_iter`]: BTreeSet#method.into_iter\n#[stable(feature = \"rust1\", since = \"1.0.0\")]\n#[derive(Debug)]\npub struct IntoIter<T> {\n    iter: super::map::IntoIter<T, ()>,\n}\n\n/// An iterator over a sub-range of items in a `BTreeSet`.\n///\n/// This `struct` is created by the [`range`] method on [`BTreeSet`].\n/// See its documentation for more.\n///\n/// [`range`]: BTreeSet::range\n#[derive(Debug)]\n#[stable(feature = \"btree_range\", since = \"1.17.0\")]\npub struct Range<'a, T: 'a> {\n    iter: super::map::Range<'a, T, ()>,\n}\n\n/// A lazy iterator producing elements in the difference of `BTreeSet`s.\n///\n/// This `struct` is created by the [`difference`] method on [`BTreeSet`].\n/// See its documentation for more.\n///\n/// [`difference`]: BTreeSet::difference\n#[stable(feature = \"rust1\", since = \"1.0.0\")]\npub struct Difference<'a, T: 'a> {\n    inner: DifferenceInner<'a, T>,\n}\n#[derive(Debug)]\nenum DifferenceInner<'a, T: 'a> {\n    Stitch {\n        // iterate all of `self` and some of `other`, spotting matches along the way\n        self_iter: Iter<'a, T>,\n        other_iter: Peekable<Iter<'a, T>>,\n    },\n    Search {\n        // iterate `self`, look up in `other`\n        self_iter: Iter<'a, T>,\n        other_set: &'a BTreeSet<T>,\n    },\n    Iterate(Iter<'a, T>), // simply produce all values in `self`\n}\n\n#[stable(feature = \"collection_debug\", since = \"1.17.0\")]\nimpl<T: fmt::Debug> fmt::Debug for Difference<'_, T> {\n    fn fmt(&self, f: &mut fmt::Formatter<'_>) -> fmt::Result {\n        f.debug_tuple(\"Difference\").field(&self.inner).finish()\n    }\n}\n\n/// A lazy iterator producing elements in the symmetric difference of `BTreeSet`s.\n///\n/// This `struct` is created by the [`symmetric_difference`] method on\n/// [`BTreeSet`]. See its documentation for more.\n///\n/// [`symmetric_difference`]: BTreeSet::symmetric_difference\n#[stable(feature = \"rust1\", since = \"1.0.0\")]\npub struct SymmetricDifference<'a, T: 'a>(MergeIterInner<Iter<'a, T>>);\n\n#[stable(feature = \"collection_debug\", since = \"1.17.0\")]\nimpl<T: fmt::Debug> fmt::Debug for SymmetricDifference<'_, T> {\n    fn fmt(&self, f: &mut fmt::Formatter<'_>) -> fmt::Result {\n        f.debug_tuple(\"SymmetricDifference\").field(&self.0).finish()\n    }\n}\n\n/// A lazy iterator producing elements in the intersection of `BTreeSet`s.\n///\n/// This `struct` is created by the [`intersection`] method on [`BTreeSet`].\n/// See its documentation for more.\n///\n/// [`intersection`]: BTreeSet::intersection\n#[stable(feature = \"rust1\", since = \"1.0.0\")]\npub struct Intersection<'a, T: 'a> {\n    inner: IntersectionInner<'a, T>,\n}\n#[derive(Debug)]\nenum IntersectionInner<'a, T: 'a> {\n    Stitch {\n        // iterate similarly sized sets jointly, spotting matches along the way\n        a: Iter<'a, T>,\n        b: Iter<'a, T>,\n    },\n    Search {\n        // iterate a small set, look up in the large set\n        small_iter: Iter<'a, T>,\n        large_set: &'a BTreeSet<T>,\n    },\n    Answer(Option<&'a T>), // return a specific value or emptiness\n}\n\n#[stable(feature = \"collection_debug\", since = \"1.17.0\")]\nimpl<T: fmt::Debug> fmt::Debug for Intersection<'_, T> {\n    fn fmt(&self, f: &mut fmt::Formatter<'_>) -> fmt::Result {\n        f.debug_tuple(\"Intersection\").field(&self.inner).finish()\n    }\n}\n\n/// A lazy iterator producing elements in the union of `BTreeSet`s.\n///\n/// This `struct` is created by the [`union`] method on [`BTreeSet`].\n/// See its documentation for more.\n///\n/// [`union`]: BTreeSet::union\n#[stable(feature = \"rust1\", since = \"1.0.0\")]\npub struct Union<'a, T: 'a>(MergeIterInner<Iter<'a, T>>);\n\n#[stable(feature = \"collection_debug\", since = \"1.17.0\")]\nimpl<T: fmt::Debug> fmt::Debug for Union<'_, T> {\n    fn fmt(&self, f: &mut fmt::Formatter<'_>) -> fmt::Result {\n        f.debug_tuple(\"Union\").field(&self.0).finish()\n    }\n}\n\n// This constant is used by functions that compare two sets.\n// It estimates the relative size at which searching performs better\n// than iterating, based on the benchmarks in\n// https://github.com/ssomers/rust_bench_btreeset_intersection.\n// It's used to divide rather than multiply sizes, to rule out overflow,\n// and it's a power of two to make that division cheap.\nconst ITER_PERFORMANCE_TIPPING_SIZE_DIFF: usize = 16;\n\nimpl<T> BTreeSet<T> {\n    /// Makes a new, empty `BTreeSet`.\n    ///\n    /// Does not allocate anything on its own.\n    ///\n    /// # Examples\n    ///\n    /// ```\n    /// # #![allow(unused_mut)]\n    /// use std::collections::BTreeSet;\n    ///\n    /// let mut set: BTreeSet<i32> = BTreeSet::new();\n    /// ```\n    #[stable(feature = \"rust1\", since = \"1.0.0\")]\n    #[rustc_const_unstable(feature = \"const_btree_new\", issue = \"71835\")]\n    pub const fn new() -> BTreeSet<T>\n    where\n        T: Ord,\n    {\n        BTreeSet { map: BTreeMap::new() }\n    }\n\n    /// Constructs a double-ended iterator over a sub-range of elements in the set.\n    /// The simplest way is to use the range syntax `min..max`, thus `range(min..max)` will\n    /// yield elements from min (inclusive) to max (exclusive).\n    /// The range may also be entered as `(Bound<T>, Bound<T>)`, so for example\n    /// `range((Excluded(4), Included(10)))` will yield a left-exclusive, right-inclusive\n    /// range from 4 to 10.\n    ///\n    /// # Examples\n    ///\n    /// ```\n    /// use std::collections::BTreeSet;\n    /// use std::ops::Bound::Included;\n    ///\n    /// let mut set = BTreeSet::new();\n    /// set.insert(3);\n    /// set.insert(5);\n    /// set.insert(8);\n    /// for &elem in set.range((Included(&4), Included(&8))) {\n    ///     println!(\"{}\", elem);\n    /// }\n    /// assert_eq!(Some(&5), set.range(4..).next());\n    /// ```\n    #[stable(feature = \"btree_range\", since = \"1.17.0\")]\n    pub fn range<K: ?Sized, R>(&self, range: R) -> Range<'_, T>\n    where\n        K: Ord,\n        T: Borrow<K> + Ord,\n        R: RangeBounds<K>,\n    {\n        Range { iter: self.map.range(range) }\n    }\n\n    /// Visits the values representing the difference,\n    /// i.e., the values that are in `self` but not in `other`,\n    /// in ascending order.\n    ///\n    /// # Examples\n    ///\n    /// ```\n    /// use std::collections::BTreeSet;\n    ///\n    /// let mut a = BTreeSet::new();\n    /// a.insert(1);\n    /// a.insert(2);\n    ///\n    /// let mut b = BTreeSet::new();\n    /// b.insert(2);\n    /// b.insert(3);\n    ///\n    /// let diff: Vec<_> = a.difference(&b).cloned().collect();\n    /// assert_eq!(diff, [1]);\n    /// ```\n    #[stable(feature = \"rust1\", since = \"1.0.0\")]\n    pub fn difference<'a>(&'a self, other: &'a BTreeSet<T>) -> Difference<'a, T>\n    where\n        T: Ord,\n    {\n        let (self_min, self_max) =\n            if let (Some(self_min), Some(self_max)) = (self.first(), self.last()) {\n                (self_min, self_max)\n            } else {\n                return Difference { inner: DifferenceInner::Iterate(self.iter()) };\n            };\n        let (other_min, other_max) =\n            if let (Some(other_min), Some(other_max)) = (other.first(), other.last()) {\n                (other_min, other_max)\n            } else {\n                return Difference { inner: DifferenceInner::Iterate(self.iter()) };\n            };\n        Difference {\n            inner: match (self_min.cmp(other_max), self_max.cmp(other_min)) {\n                (Greater, _) | (_, Less) => DifferenceInner::Iterate(self.iter()),\n                (Equal, _) => {\n                    let mut self_iter = self.iter();\n                    self_iter.next();\n                    DifferenceInner::Iterate(self_iter)\n                }\n                (_, Equal) => {\n                    let mut self_iter = self.iter();\n                    self_iter.next_back();\n                    DifferenceInner::Iterate(self_iter)\n                }\n                _ if self.len() <= other.len() / ITER_PERFORMANCE_TIPPING_SIZE_DIFF => {\n                    DifferenceInner::Search { self_iter: self.iter(), other_set: other }\n                }\n                _ => DifferenceInner::Stitch {\n                    self_iter: self.iter(),\n                    other_iter: other.iter().peekable(),\n                },\n            },\n        }\n    }\n\n    /// Visits the values representing the symmetric difference,\n    /// i.e., the values that are in `self` or in `other` but not in both,\n    /// in ascending order.\n    ///\n    /// # Examples\n    ///\n    /// ```\n    /// use std::collections::BTreeSet;\n    ///\n    /// let mut a = BTreeSet::new();\n    /// a.insert(1);\n    /// a.insert(2);\n    ///\n    /// let mut b = BTreeSet::new();\n    /// b.insert(2);\n    /// b.insert(3);\n    ///\n    /// let sym_diff: Vec<_> = a.symmetric_difference(&b).cloned().collect();\n    /// assert_eq!(sym_diff, [1, 3]);\n    /// ```\n    #[stable(feature = \"rust1\", since = \"1.0.0\")]\n    pub fn symmetric_difference<'a>(&'a self, other: &'a BTreeSet<T>) -> SymmetricDifference<'a, T>\n    where\n        T: Ord,\n    {\n        SymmetricDifference(MergeIterInner::new(self.iter(), other.iter()))\n    }\n\n    /// Visits the values representing the intersection,\n    /// i.e., the values that are both in `self` and `other`,\n    /// in ascending order.\n    ///\n    /// # Examples\n    ///\n    /// ```\n    /// use std::collections::BTreeSet;\n    ///\n    /// let mut a = BTreeSet::new();\n    /// a.insert(1);\n    /// a.insert(2);\n    ///\n    /// let mut b = BTreeSet::new();\n    /// b.insert(2);\n    /// b.insert(3);\n    ///\n    /// let intersection: Vec<_> = a.intersection(&b).cloned().collect();\n    /// assert_eq!(intersection, [2]);\n    /// ```\n    #[stable(feature = \"rust1\", since = \"1.0.0\")]\n    pub fn intersection<'a>(&'a self, other: &'a BTreeSet<T>) -> Intersection<'a, T>\n    where\n        T: Ord,\n    {\n        let (self_min, self_max) =\n            if let (Some(self_min), Some(self_max)) = (self.first(), self.last()) {\n                (self_min, self_max)\n            } else {\n                return Intersection { inner: IntersectionInner::Answer(None) };\n            };\n        let (other_min, other_max) =\n            if let (Some(other_min), Some(other_max)) = (other.first(), other.last()) {\n                (other_min, other_max)\n            } else {\n                return Intersection { inner: IntersectionInner::Answer(None) };\n            };\n        Intersection {\n            inner: match (self_min.cmp(other_max), self_max.cmp(other_min)) {\n                (Greater, _) | (_, Less) => IntersectionInner::Answer(None),\n                (Equal, _) => IntersectionInner::Answer(Some(self_min)),\n                (_, Equal) => IntersectionInner::Answer(Some(self_max)),\n                _ if self.len() <= other.len() / ITER_PERFORMANCE_TIPPING_SIZE_DIFF => {\n                    IntersectionInner::Search { small_iter: self.iter(), large_set: other }\n                }\n                _ if other.len() <= self.len() / ITER_PERFORMANCE_TIPPING_SIZE_DIFF => {\n                    IntersectionInner::Search { small_iter: other.iter(), large_set: self }\n                }\n                _ => IntersectionInner::Stitch { a: self.iter(), b: other.iter() },\n            },\n        }\n    }\n\n    /// Visits the values representing the union,\n    /// i.e., all the values in `self` or `other`, without duplicates,\n    /// in ascending order.\n    ///\n    /// # Examples\n    ///\n    /// ```\n    /// use std::collections::BTreeSet;\n    ///\n    /// let mut a = BTreeSet::new();\n    /// a.insert(1);\n    ///\n    /// let mut b = BTreeSet::new();\n    /// b.insert(2);\n    ///\n    /// let union: Vec<_> = a.union(&b).cloned().collect();\n    /// assert_eq!(union, [1, 2]);\n    /// ```\n    #[stable(feature = \"rust1\", since = \"1.0.0\")]\n    pub fn union<'a>(&'a self, other: &'a BTreeSet<T>) -> Union<'a, T>\n    where\n        T: Ord,\n    {\n        Union(MergeIterInner::new(self.iter(), other.iter()))\n    }\n\n    /// Clears the set, removing all values.\n    ///\n    /// # Examples\n    ///\n    /// ```\n    /// use std::collections::BTreeSet;\n    ///\n    /// let mut v = BTreeSet::new();\n    /// v.insert(1);\n    /// v.clear();\n    /// assert!(v.is_empty());\n    /// ```\n    #[stable(feature = \"rust1\", since = \"1.0.0\")]\n    pub fn clear(&mut self) {\n        self.map.clear()\n    }\n\n    /// Returns `true` if the set contains a value.\n    ///\n    /// The value may be any borrowed form of the set's value type,\n    /// but the ordering on the borrowed form *must* match the\n    /// ordering on the value type.\n    ///\n    /// # Examples\n    ///\n    /// ```\n    /// use std::collections::BTreeSet;\n    ///\n    /// let set: BTreeSet<_> = [1, 2, 3].iter().cloned().collect();\n    /// assert_eq!(set.contains(&1), true);\n    /// assert_eq!(set.contains(&4), false);\n    /// ```\n    #[stable(feature = \"rust1\", since = \"1.0.0\")]\n    pub fn contains<Q: ?Sized>(&self, value: &Q) -> bool\n    where\n        T: Borrow<Q> + Ord,\n        Q: Ord,\n    {\n        self.map.contains_key(value)\n    }\n\n    /// Returns a reference to the value in the set, if any, that is equal to the given value.\n    ///\n    /// The value may be any borrowed form of the set's value type,\n    /// but the ordering on the borrowed form *must* match the\n    /// ordering on the value type.\n    ///\n    /// # Examples\n    ///\n    /// ```\n    /// use std::collections::BTreeSet;\n    ///\n    /// let set: BTreeSet<_> = [1, 2, 3].iter().cloned().collect();\n    /// assert_eq!(set.get(&2), Some(&2));\n    /// assert_eq!(set.get(&4), None);\n    /// ```\n    #[stable(feature = \"set_recovery\", since = \"1.9.0\")]\n    pub fn get<Q: ?Sized>(&self, value: &Q) -> Option<&T>\n    where\n        T: Borrow<Q> + Ord,\n        Q: Ord,\n    {\n        Recover::get(&self.map, value)\n    }\n\n    /// Returns `true` if `self` has no elements in common with `other`.\n    /// This is equivalent to checking for an empty intersection.\n    ///\n    /// # Examples\n    ///\n    /// ```\n    /// use std::collections::BTreeSet;\n    ///\n    /// let a: BTreeSet<_> = [1, 2, 3].iter().cloned().collect();\n    /// let mut b = BTreeSet::new();\n    ///\n    /// assert_eq!(a.is_disjoint(&b), true);\n    /// b.insert(4);\n    /// assert_eq!(a.is_disjoint(&b), true);\n    /// b.insert(1);\n    /// assert_eq!(a.is_disjoint(&b), false);\n    /// ```\n    #[stable(feature = \"rust1\", since = \"1.0.0\")]\n    pub fn is_disjoint(&self, other: &BTreeSet<T>) -> bool\n    where\n        T: Ord,\n    {\n        self.intersection(other).next().is_none()\n    }\n\n    /// Returns `true` if the set is a subset of another,\n    /// i.e., `other` contains at least all the values in `self`.\n    ///\n    /// # Examples\n    ///\n    /// ```\n    /// use std::collections::BTreeSet;\n    ///\n    /// let sup: BTreeSet<_> = [1, 2, 3].iter().cloned().collect();\n    /// let mut set = BTreeSet::new();\n    ///\n    /// assert_eq!(set.is_subset(&sup), true);\n    /// set.insert(2);\n    /// assert_eq!(set.is_subset(&sup), true);\n    /// set.insert(4);\n    /// assert_eq!(set.is_subset(&sup), false);\n    /// ```\n    #[stable(feature = \"rust1\", since = \"1.0.0\")]\n    pub fn is_subset(&self, other: &BTreeSet<T>) -> bool\n    where\n        T: Ord,\n    {\n        // Same result as self.difference(other).next().is_none()\n        // but the code below is faster (hugely in some cases).\n        if self.len() > other.len() {\n            return false;\n        }\n        let (self_min, self_max) =\n            if let (Some(self_min), Some(self_max)) = (self.first(), self.last()) {\n                (self_min, self_max)\n            } else {\n                return true; // self is empty\n            };\n        let (other_min, other_max) =\n            if let (Some(other_min), Some(other_max)) = (other.first(), other.last()) {\n                (other_min, other_max)\n            } else {\n                return false; // other is empty\n            };\n        let mut self_iter = self.iter();\n        match self_min.cmp(other_min) {\n            Less => return false,\n            Equal => {\n                self_iter.next();\n            }\n            Greater => (),\n        }\n        match self_max.cmp(other_max) {\n            Greater => return false,\n            Equal => {\n                self_iter.next_back();\n            }\n            Less => (),\n        }\n        if self_iter.len() <= other.len() / ITER_PERFORMANCE_TIPPING_SIZE_DIFF {\n            for next in self_iter {\n                if !other.contains(next) {\n                    return false;\n                }\n            }\n        } else {\n            let mut other_iter = other.iter();\n            other_iter.next();\n            other_iter.next_back();\n            let mut self_next = self_iter.next();\n            while let Some(self1) = self_next {\n                match other_iter.next().map_or(Less, |other1| self1.cmp(other1)) {\n                    Less => return false,\n                    Equal => self_next = self_iter.next(),\n                    Greater => (),\n                }\n            }\n        }\n        true\n    }\n\n    /// Returns `true` if the set is a superset of another,\n    /// i.e., `self` contains at least all the values in `other`.\n    ///\n    /// # Examples\n    ///\n    /// ```\n    /// use std::collections::BTreeSet;\n    ///\n    /// let sub: BTreeSet<_> = [1, 2].iter().cloned().collect();\n    /// let mut set = BTreeSet::new();\n    ///\n    /// assert_eq!(set.is_superset(&sub), false);\n    ///\n    /// set.insert(0);\n    /// set.insert(1);\n    /// assert_eq!(set.is_superset(&sub), false);\n    ///\n    /// set.insert(2);\n    /// assert_eq!(set.is_superset(&sub), true);\n    /// ```\n    #[stable(feature = \"rust1\", since = \"1.0.0\")]\n    pub fn is_superset(&self, other: &BTreeSet<T>) -> bool\n    where\n        T: Ord,\n    {\n        other.is_subset(self)\n    }\n\n    /// Returns a reference to the first value in the set, if any.\n    /// This value is always the minimum of all values in the set.\n    ///\n    /// # Examples\n    ///\n    /// Basic usage:\n    ///\n    /// ```\n    /// #![feature(map_first_last)]\n    /// use std::collections::BTreeSet;\n    ///\n    /// let mut set = BTreeSet::new();\n    /// assert_eq!(set.first(), None);\n    /// set.insert(1);\n    /// assert_eq!(set.first(), Some(&1));\n    /// set.insert(2);\n    /// assert_eq!(set.first(), Some(&1));\n    /// ```\n    #[unstable(feature = \"map_first_last\", issue = \"62924\")]\n    pub fn first(&self) -> Option<&T>\n    where\n        T: Ord,\n    {\n        self.map.first_key_value().map(|(k, _)| k)\n    }\n\n    /// Returns a reference to the last value in the set, if any.\n    /// This value is always the maximum of all values in the set.\n    ///\n    /// # Examples\n    ///\n    /// Basic usage:\n    ///\n    /// ```\n    /// #![feature(map_first_last)]\n    /// use std::collections::BTreeSet;\n    ///\n    /// let mut set = BTreeSet::new();\n    /// assert_eq!(set.last(), None);\n    /// set.insert(1);\n    /// assert_eq!(set.last(), Some(&1));\n    /// set.insert(2);\n    /// assert_eq!(set.last(), Some(&2));\n    /// ```\n    #[unstable(feature = \"map_first_last\", issue = \"62924\")]\n    pub fn last(&self) -> Option<&T>\n    where\n        T: Ord,\n    {\n        self.map.last_key_value().map(|(k, _)| k)\n    }\n\n    /// Removes the first value from the set and returns it, if any.\n    /// The first value is always the minimum value in the set.\n    ///\n    /// # Examples\n    ///\n    /// ```\n    /// #![feature(map_first_last)]\n    /// use std::collections::BTreeSet;\n    ///\n    /// let mut set = BTreeSet::new();\n    ///\n    /// set.insert(1);\n    /// while let Some(n) = set.pop_first() {\n    ///     assert_eq!(n, 1);\n    /// }\n    /// assert!(set.is_empty());\n    /// ```\n    #[unstable(feature = \"map_first_last\", issue = \"62924\")]\n    pub fn pop_first(&mut self) -> Option<T>\n    where\n        T: Ord,\n    {\n        self.map.pop_first().map(|kv| kv.0)\n    }\n\n    /// Removes the last value from the set and returns it, if any.\n    /// The last value is always the maximum value in the set.\n    ///\n    /// # Examples\n    ///\n    /// ```\n    /// #![feature(map_first_last)]\n    /// use std::collections::BTreeSet;\n    ///\n    /// let mut set = BTreeSet::new();\n    ///\n    /// set.insert(1);\n    /// while let Some(n) = set.pop_last() {\n    ///     assert_eq!(n, 1);\n    /// }\n    /// assert!(set.is_empty());\n    /// ```\n    #[unstable(feature = \"map_first_last\", issue = \"62924\")]\n    pub fn pop_last(&mut self) -> Option<T>\n    where\n        T: Ord,\n    {\n        self.map.pop_last().map(|kv| kv.0)\n    }\n\n    /// Adds a value to the set.\n    ///\n    /// If the set did not have this value present, `true` is returned.\n    ///\n    /// If the set did have this value present, `false` is returned, and the\n    /// entry is not updated. See the [module-level documentation] for more.\n    ///\n    /// [module-level documentation]: index.html#insert-and-complex-keys\n    ///\n    /// # Examples\n    ///\n    /// ```\n    /// use std::collections::BTreeSet;\n    ///\n    /// let mut set = BTreeSet::new();\n    ///\n    /// assert_eq!(set.insert(2), true);\n    /// assert_eq!(set.insert(2), false);\n    /// assert_eq!(set.len(), 1);\n    /// ```\n    #[stable(feature = \"rust1\", since = \"1.0.0\")]\n    pub fn insert(&mut self, value: T) -> bool\n    where\n        T: Ord,\n    {\n        self.map.insert(value, ()).is_none()\n    }\n\n    /// Adds a value to the set, replacing the existing value, if any, that is equal to the given\n    /// one. Returns the replaced value.\n    ///\n    /// # Examples\n    ///\n    /// ```\n    /// use std::collections::BTreeSet;\n    ///\n    /// let mut set = BTreeSet::new();\n    /// set.insert(Vec::<i32>::new());\n    ///\n    /// assert_eq!(set.get(&[][..]).unwrap().capacity(), 0);\n    /// set.replace(Vec::with_capacity(10));\n    /// assert_eq!(set.get(&[][..]).unwrap().capacity(), 10);\n    /// ```\n    #[stable(feature = \"set_recovery\", since = \"1.9.0\")]\n    pub fn replace(&mut self, value: T) -> Option<T>\n    where\n        T: Ord,\n    {\n        Recover::replace(&mut self.map, value)\n    }\n\n    /// Removes a value from the set. Returns whether the value was\n    /// present in the set.\n    ///\n    /// The value may be any borrowed form of the set's value type,\n    /// but the ordering on the borrowed form *must* match the\n    /// ordering on the value type.\n    ///\n    /// # Examples\n    ///\n    /// ```\n    /// use std::collections::BTreeSet;\n    ///\n    /// let mut set = BTreeSet::new();\n    ///\n    /// set.insert(2);\n    /// assert_eq!(set.remove(&2), true);\n    /// assert_eq!(set.remove(&2), false);\n    /// ```\n    #[doc(alias = \"delete\")]\n    #[stable(feature = \"rust1\", since = \"1.0.0\")]\n    pub fn remove<Q: ?Sized>(&mut self, value: &Q) -> bool\n    where\n        T: Borrow<Q> + Ord,\n        Q: Ord,\n    {\n        self.map.remove(value).is_some()\n    }\n\n    /// Removes and returns the value in the set, if any, that is equal to the given one.\n    ///\n    /// The value may be any borrowed form of the set's value type,\n    /// but the ordering on the borrowed form *must* match the\n    /// ordering on the value type.\n    ///\n    /// # Examples\n    ///\n    /// ```\n    /// use std::collections::BTreeSet;\n    ///\n    /// let mut set: BTreeSet<_> = [1, 2, 3].iter().cloned().collect();\n    /// assert_eq!(set.take(&2), Some(2));\n    /// assert_eq!(set.take(&2), None);\n    /// ```\n    #[stable(feature = \"set_recovery\", since = \"1.9.0\")]\n    pub fn take<Q: ?Sized>(&mut self, value: &Q) -> Option<T>\n    where\n        T: Borrow<Q> + Ord,\n        Q: Ord,\n    {\n        Recover::take(&mut self.map, value)\n    }\n\n    /// Retains only the elements specified by the predicate.\n    ///\n    /// In other words, remove all elements `e` such that `f(&e)` returns `false`.\n    ///\n    /// # Examples\n    ///\n    /// ```\n    /// use std::collections::BTreeSet;\n    ///\n    /// let xs = [1, 2, 3, 4, 5, 6];\n    /// let mut set: BTreeSet<i32> = xs.iter().cloned().collect();\n    /// // Keep only the even numbers.\n    /// set.retain(|&k| k % 2 == 0);\n    /// assert!(set.iter().eq([2, 4, 6].iter()));\n    /// ```\n    #[stable(feature = \"btree_retain\", since = \"1.53.0\")]\n    pub fn retain<F>(&mut self, mut f: F)\n    where\n        T: Ord,\n        F: FnMut(&T) -> bool,\n    {\n        self.drain_filter(|v| !f(v));\n    }\n\n    /// Moves all elements from `other` into `Self`, leaving `other` empty.\n    ///\n    /// # Examples\n    ///\n    /// ```\n    /// use std::collections::BTreeSet;\n    ///\n    /// let mut a = BTreeSet::new();\n    /// a.insert(1);\n    /// a.insert(2);\n    /// a.insert(3);\n    ///\n    /// let mut b = BTreeSet::new();\n    /// b.insert(3);\n    /// b.insert(4);\n    /// b.insert(5);\n    ///\n    /// a.append(&mut b);\n    ///\n    /// assert_eq!(a.len(), 5);\n    /// assert_eq!(b.len(), 0);\n    ///\n    /// assert!(a.contains(&1));\n    /// assert!(a.contains(&2));\n    /// assert!(a.contains(&3));\n    /// assert!(a.contains(&4));\n    /// assert!(a.contains(&5));\n    /// ```\n    #[stable(feature = \"btree_append\", since = \"1.11.0\")]\n    pub fn append(&mut self, other: &mut Self)\n    where\n        T: Ord,\n    {\n        self.map.append(&mut other.map);\n    }\n\n    /// Splits the collection into two at the given key. Returns everything after the given key,\n    /// including the key.\n    ///\n    /// # Examples\n    ///\n    /// Basic usage:\n    ///\n    /// ```\n    /// use std::collections::BTreeSet;\n    ///\n    /// let mut a = BTreeSet::new();\n    /// a.insert(1);\n    /// a.insert(2);\n    /// a.insert(3);\n    /// a.insert(17);\n    /// a.insert(41);\n    ///\n    /// let b = a.split_off(&3);\n    ///\n    /// assert_eq!(a.len(), 2);\n    /// assert_eq!(b.len(), 3);\n    ///\n    /// assert!(a.contains(&1));\n    /// assert!(a.contains(&2));\n    ///\n    /// assert!(b.contains(&3));\n    /// assert!(b.contains(&17));\n    /// assert!(b.contains(&41));\n    /// ```\n    #[stable(feature = \"btree_split_off\", since = \"1.11.0\")]\n    pub fn split_off<Q: ?Sized + Ord>(&mut self, key: &Q) -> Self\n    where\n        T: Borrow<Q> + Ord,\n    {\n        BTreeSet { map: self.map.split_off(key) }\n    }\n\n    /// Creates an iterator which uses a closure to determine if a value should be removed.\n    ///\n    /// If the closure returns true, then the value is removed and yielded.\n    /// If the closure returns false, the value will remain in the list and will not be yielded\n    /// by the iterator.\n    ///\n    /// If the iterator is only partially consumed or not consumed at all, each of the remaining\n    /// values will still be subjected to the closure and removed and dropped if it returns true.\n    ///\n    /// It is unspecified how many more values will be subjected to the closure\n    /// if a panic occurs in the closure, or if a panic occurs while dropping a value, or if the\n    /// `DrainFilter` itself is leaked.\n    ///\n    /// # Examples\n    ///\n    /// Splitting a set into even and odd values, reusing the original set:\n    ///\n    /// ```\n    /// #![feature(btree_drain_filter)]\n    /// use std::collections::BTreeSet;\n    ///\n    /// let mut set: BTreeSet<i32> = (0..8).collect();\n    /// let evens: BTreeSet<_> = set.drain_filter(|v| v % 2 == 0).collect();\n    /// let odds = set;\n    /// assert_eq!(evens.into_iter().collect::<Vec<_>>(), vec![0, 2, 4, 6]);\n    /// assert_eq!(odds.into_iter().collect::<Vec<_>>(), vec![1, 3, 5, 7]);\n    /// ```\n    #[unstable(feature = \"btree_drain_filter\", issue = \"70530\")]\n    pub fn drain_filter<'a, F>(&'a mut self, pred: F) -> DrainFilter<'a, T, F>\n    where\n        T: Ord,\n        F: 'a + FnMut(&T) -> bool,\n    {\n        DrainFilter { pred, inner: self.map.drain_filter_inner() }\n    }\n\n    /// Gets an iterator that visits the values in the `BTreeSet` in ascending order.\n    ///\n    /// # Examples\n    ///\n    /// ```\n    /// use std::collections::BTreeSet;\n    ///\n    /// let set: BTreeSet<usize> = [1, 2, 3].iter().cloned().collect();\n    /// let mut set_iter = set.iter();\n    /// assert_eq!(set_iter.next(), Some(&1));\n    /// assert_eq!(set_iter.next(), Some(&2));\n    /// assert_eq!(set_iter.next(), Some(&3));\n    /// assert_eq!(set_iter.next(), None);\n    /// ```\n    ///\n    /// Values returned by the iterator are returned in ascending order:\n    ///\n    /// ```\n    /// use std::collections::BTreeSet;\n    ///\n    /// let set: BTreeSet<usize> = [3, 1, 2].iter().cloned().collect();\n    /// let mut set_iter = set.iter();\n    /// assert_eq!(set_iter.next(), Some(&1));\n    /// assert_eq!(set_iter.next(), Some(&2));\n    /// assert_eq!(set_iter.next(), Some(&3));\n    /// assert_eq!(set_iter.next(), None);\n    /// ```\n    #[stable(feature = \"rust1\", since = \"1.0.0\")]\n    pub fn iter(&self) -> Iter<'_, T> {\n        Iter { iter: self.map.keys() }\n    }\n\n    /// Returns the number of elements in the set.\n    ///\n    /// # Examples\n    ///\n    /// ```\n    /// use std::collections::BTreeSet;\n    ///\n    /// let mut v = BTreeSet::new();\n    /// assert_eq!(v.len(), 0);\n    /// v.insert(1);\n    /// assert_eq!(v.len(), 1);\n    /// ```\n    #[doc(alias = \"length\")]\n    #[stable(feature = \"rust1\", since = \"1.0.0\")]\n    #[rustc_const_unstable(feature = \"const_btree_new\", issue = \"71835\")]\n    pub const fn len(&self) -> usize {\n        self.map.len()\n    }\n\n    /// Returns `true` if the set contains no elements.\n    ///\n    /// # Examples\n    ///\n    /// ```\n    /// use std::collections::BTreeSet;\n    ///\n    /// let mut v = BTreeSet::new();\n    /// assert!(v.is_empty());\n    /// v.insert(1);\n    /// assert!(!v.is_empty());\n    /// ```\n    #[stable(feature = \"rust1\", since = \"1.0.0\")]\n    #[rustc_const_unstable(feature = \"const_btree_new\", issue = \"71835\")]\n    pub const fn is_empty(&self) -> bool {\n        self.len() == 0\n    }\n}\n\n#[stable(feature = \"rust1\", since = \"1.0.0\")]\nimpl<T: Ord> FromIterator<T> for BTreeSet<T> {\n    fn from_iter<I: IntoIterator<Item = T>>(iter: I) -> BTreeSet<T> {\n        let mut set = BTreeSet::new();\n        set.extend(iter);\n        set\n    }\n}\n\n#[stable(feature = \"rust1\", since = \"1.0.0\")]\nimpl<T> IntoIterator for BTreeSet<T> {\n    type Item = T;\n    type IntoIter = IntoIter<T>;\n\n    /// Gets an iterator for moving out the `BTreeSet`'s contents.\n    ///\n    /// # Examples\n    ///\n    /// ```\n    /// use std::collections::BTreeSet;\n    ///\n    /// let set: BTreeSet<usize> = [1, 2, 3, 4].iter().cloned().collect();\n    ///\n    /// let v: Vec<_> = set.into_iter().collect();\n    /// assert_eq!(v, [1, 2, 3, 4]);\n    /// ```\n    fn into_iter(self) -> IntoIter<T> {\n        IntoIter { iter: self.map.into_iter() }\n    }\n}\n\n#[stable(feature = \"rust1\", since = \"1.0.0\")]\nimpl<'a, T> IntoIterator for &'a BTreeSet<T> {\n    type Item = &'a T;\n    type IntoIter = Iter<'a, T>;\n\n    fn into_iter(self) -> Iter<'a, T> {\n        self.iter()\n    }\n}\n\n/// An iterator produced by calling `drain_filter` on BTreeSet.\n#[unstable(feature = \"btree_drain_filter\", issue = \"70530\")]\npub struct DrainFilter<'a, T, F>\nwhere\n    T: 'a,\n    F: 'a + FnMut(&T) -> bool,\n{\n    pred: F,\n    inner: super::map::DrainFilterInner<'a, T, ()>,\n}\n\n#[unstable(feature = \"btree_drain_filter\", issue = \"70530\")]\nimpl<T, F> Drop for DrainFilter<'_, T, F>\nwhere\n    F: FnMut(&T) -> bool,\n{\n    fn drop(&mut self) {\n        self.for_each(drop);\n    }\n}\n\n#[unstable(feature = \"btree_drain_filter\", issue = \"70530\")]\nimpl<T, F> fmt::Debug for DrainFilter<'_, T, F>\nwhere\n    T: fmt::Debug,\n    F: FnMut(&T) -> bool,\n{\n    fn fmt(&self, f: &mut fmt::Formatter<'_>) -> fmt::Result {\n        f.debug_tuple(\"DrainFilter\").field(&self.inner.peek().map(|(k, _)| k)).finish()\n    }\n}\n\n#[unstable(feature = \"btree_drain_filter\", issue = \"70530\")]\nimpl<'a, T, F> Iterator for DrainFilter<'_, T, F>\nwhere\n    F: 'a + FnMut(&T) -> bool,\n{\n    type Item = T;\n\n    fn next(&mut self) -> Option<T> {\n        let pred = &mut self.pred;\n        let mut mapped_pred = |k: &T, _v: &mut ()| pred(k);\n        self.inner.next(&mut mapped_pred).map(|(k, _)| k)\n    }\n\n    fn size_hint(&self) -> (usize, Option<usize>) {\n        self.inner.size_hint()\n    }\n}\n\n#[unstable(feature = \"btree_drain_filter\", issue = \"70530\")]\nimpl<T, F> FusedIterator for DrainFilter<'_, T, F> where F: FnMut(&T) -> bool {}\n\n#[stable(feature = \"rust1\", since = \"1.0.0\")]\nimpl<T: Ord> Extend<T> for BTreeSet<T> {\n    #[inline]\n    fn extend<Iter: IntoIterator<Item = T>>(&mut self, iter: Iter) {\n        iter.into_iter().for_each(move |elem| {\n            self.insert(elem);\n        });\n    }\n\n    #[inline]\n    fn extend_one(&mut self, elem: T) {\n        self.insert(elem);\n    }\n}\n\n#[stable(feature = \"extend_ref\", since = \"1.2.0\")]\nimpl<'a, T: 'a + Ord + Copy> Extend<&'a T> for BTreeSet<T> {\n    fn extend<I: IntoIterator<Item = &'a T>>(&mut self, iter: I) {\n        self.extend(iter.into_iter().cloned());\n    }\n\n    #[inline]\n    fn extend_one(&mut self, &elem: &'a T) {\n        self.insert(elem);\n    }\n}\n\n#[stable(feature = \"rust1\", since = \"1.0.0\")]\nimpl<T: Ord> Default for BTreeSet<T> {\n    /// Creates an empty `BTreeSet`.\n    fn default() -> BTreeSet<T> {\n        BTreeSet::new()\n    }\n}\n\n#[stable(feature = \"rust1\", since = \"1.0.0\")]\nimpl<T: Ord + Clone> Sub<&BTreeSet<T>> for &BTreeSet<T> {\n    type Output = BTreeSet<T>;\n\n    /// Returns the difference of `self` and `rhs` as a new `BTreeSet<T>`.\n    ///\n    /// # Examples\n    ///\n    /// ```\n    /// use std::collections::BTreeSet;\n    ///\n    /// let a: BTreeSet<_> = vec![1, 2, 3].into_iter().collect();\n    /// let b: BTreeSet<_> = vec![3, 4, 5].into_iter().collect();\n    ///\n    /// let result = &a - &b;\n    /// let result_vec: Vec<_> = result.into_iter().collect();\n    /// assert_eq!(result_vec, [1, 2]);\n    /// ```\n    fn sub(self, rhs: &BTreeSet<T>) -> BTreeSet<T> {\n        self.difference(rhs).cloned().collect()\n    }\n}\n\n#[stable(feature = \"rust1\", since = \"1.0.0\")]\nimpl<T: Ord + Clone> BitXor<&BTreeSet<T>> for &BTreeSet<T> {\n    type Output = BTreeSet<T>;\n\n    /// Returns the symmetric difference of `self` and `rhs` as a new `BTreeSet<T>`.\n    ///\n    /// # Examples\n    ///\n    /// ```\n    /// use std::collections::BTreeSet;\n    ///\n    /// let a: BTreeSet<_> = vec![1, 2, 3].into_iter().collect();\n    /// let b: BTreeSet<_> = vec![2, 3, 4].into_iter().collect();\n    ///\n    /// let result = &a ^ &b;\n    /// let result_vec: Vec<_> = result.into_iter().collect();\n    /// assert_eq!(result_vec, [1, 4]);\n    /// ```\n    fn bitxor(self, rhs: &BTreeSet<T>) -> BTreeSet<T> {\n        self.symmetric_difference(rhs).cloned().collect()\n    }\n}\n\n#[stable(feature = \"rust1\", since = \"1.0.0\")]\nimpl<T: Ord + Clone> BitAnd<&BTreeSet<T>> for &BTreeSet<T> {\n    type Output = BTreeSet<T>;\n\n    /// Returns the intersection of `self` and `rhs` as a new `BTreeSet<T>`.\n    ///\n    /// # Examples\n    ///\n    /// ```\n    /// use std::collections::BTreeSet;\n    ///\n    /// let a: BTreeSet<_> = vec![1, 2, 3].into_iter().collect();\n    /// let b: BTreeSet<_> = vec![2, 3, 4].into_iter().collect();\n    ///\n    /// let result = &a & &b;\n    /// let result_vec: Vec<_> = result.into_iter().collect();\n    /// assert_eq!(result_vec, [2, 3]);\n    /// ```\n    fn bitand(self, rhs: &BTreeSet<T>) -> BTreeSet<T> {\n        self.intersection(rhs).cloned().collect()\n    }\n}\n\n#[stable(feature = \"rust1\", since = \"1.0.0\")]\nimpl<T: Ord + Clone> BitOr<&BTreeSet<T>> for &BTreeSet<T> {\n    type Output = BTreeSet<T>;\n\n    /// Returns the union of `self` and `rhs` as a new `BTreeSet<T>`.\n    ///\n    /// # Examples\n    ///\n    /// ```\n    /// use std::collections::BTreeSet;\n    ///\n    /// let a: BTreeSet<_> = vec![1, 2, 3].into_iter().collect();\n    /// let b: BTreeSet<_> = vec![3, 4, 5].into_iter().collect();\n    ///\n    /// let result = &a | &b;\n    /// let result_vec: Vec<_> = result.into_iter().collect();\n    /// assert_eq!(result_vec, [1, 2, 3, 4, 5]);\n    /// ```\n    fn bitor(self, rhs: &BTreeSet<T>) -> BTreeSet<T> {\n        self.union(rhs).cloned().collect()\n    }\n}\n\n#[stable(feature = \"rust1\", since = \"1.0.0\")]\nimpl<T: Debug> Debug for BTreeSet<T> {\n    fn fmt(&self, f: &mut fmt::Formatter<'_>) -> fmt::Result {\n        f.debug_set().entries(self.iter()).finish()\n    }\n}\n\n#[stable(feature = \"rust1\", since = \"1.0.0\")]\nimpl<T> Clone for Iter<'_, T> {\n    fn clone(&self) -> Self {\n        Iter { iter: self.iter.clone() }\n    }\n}\n#[stable(feature = \"rust1\", since = \"1.0.0\")]\nimpl<'a, T> Iterator for Iter<'a, T> {\n    type Item = &'a T;\n\n    fn next(&mut self) -> Option<&'a T> {\n        self.iter.next()\n    }\n\n    fn size_hint(&self) -> (usize, Option<usize>) {\n        self.iter.size_hint()\n    }\n\n    fn last(mut self) -> Option<&'a T> {\n        self.next_back()\n    }\n\n    fn min(mut self) -> Option<&'a T> {\n        self.next()\n    }\n\n    fn max(mut self) -> Option<&'a T> {\n        self.next_back()\n    }\n}\n#[stable(feature = \"rust1\", since = \"1.0.0\")]\nimpl<'a, T> DoubleEndedIterator for Iter<'a, T> {\n    fn next_back(&mut self) -> Option<&'a T> {\n        self.iter.next_back()\n    }\n}\n#[stable(feature = \"rust1\", since = \"1.0.0\")]\nimpl<T> ExactSizeIterator for Iter<'_, T> {\n    fn len(&self) -> usize {\n        self.iter.len()\n    }\n}\n\n#[stable(feature = \"fused\", since = \"1.26.0\")]\nimpl<T> FusedIterator for Iter<'_, T> {}\n\n#[stable(feature = \"rust1\", since = \"1.0.0\")]\nimpl<T> Iterator for IntoIter<T> {\n    type Item = T;\n\n    fn next(&mut self) -> Option<T> {\n        self.iter.next().map(|(k, _)| k)\n    }\n\n    fn size_hint(&self) -> (usize, Option<usize>) {\n        self.iter.size_hint()\n    }\n}\n#[stable(feature = \"rust1\", since = \"1.0.0\")]\nimpl<T> DoubleEndedIterator for IntoIter<T> {\n    fn next_back(&mut self) -> Option<T> {\n        self.iter.next_back().map(|(k, _)| k)\n    }\n}\n#[stable(feature = \"rust1\", since = \"1.0.0\")]\nimpl<T> ExactSizeIterator for IntoIter<T> {\n    fn len(&self) -> usize {\n        self.iter.len()\n    }\n}\n\n#[stable(feature = \"fused\", since = \"1.26.0\")]\nimpl<T> FusedIterator for IntoIter<T> {}\n\n#[stable(feature = \"btree_range\", since = \"1.17.0\")]\nimpl<T> Clone for Range<'_, T> {\n    fn clone(&self) -> Self {\n        Range { iter: self.iter.clone() }\n    }\n}\n\n#[stable(feature = \"btree_range\", since = \"1.17.0\")]\nimpl<'a, T> Iterator for Range<'a, T> {\n    type Item = &'a T;\n\n    fn next(&mut self) -> Option<&'a T> {\n        self.iter.next().map(|(k, _)| k)\n    }\n\n    fn last(mut self) -> Option<&'a T> {\n        self.next_back()\n    }\n\n    fn min(mut self) -> Option<&'a T> {\n        self.next()\n    }\n\n    fn max(mut self) -> Option<&'a T> {\n        self.next_back()\n    }\n}\n\n#[stable(feature = \"btree_range\", since = \"1.17.0\")]\nimpl<'a, T> DoubleEndedIterator for Range<'a, T> {\n    fn next_back(&mut self) -> Option<&'a T> {\n        self.iter.next_back().map(|(k, _)| k)\n    }\n}\n\n#[stable(feature = \"fused\", since = \"1.26.0\")]\nimpl<T> FusedIterator for Range<'_, T> {}\n\n#[stable(feature = \"rust1\", since = \"1.0.0\")]\nimpl<T> Clone for Difference<'_, T> {\n    fn clone(&self) -> Self {\n        Difference {\n            inner: match &self.inner {\n                DifferenceInner::Stitch { self_iter, other_iter } => DifferenceInner::Stitch {\n                    self_iter: self_iter.clone(),\n                    other_iter: other_iter.clone(),\n                },\n                DifferenceInner::Search { self_iter, other_set } => {\n                    DifferenceInner::Search { self_iter: self_iter.clone(), other_set }\n                }\n                DifferenceInner::Iterate(iter) => DifferenceInner::Iterate(iter.clone()),\n            },\n        }\n    }\n}\n#[stable(feature = \"rust1\", since = \"1.0.0\")]\nimpl<'a, T: Ord> Iterator for Difference<'a, T> {\n    type Item = &'a T;\n\n    fn next(&mut self) -> Option<&'a T> {\n        match &mut self.inner {\n            DifferenceInner::Stitch { self_iter, other_iter } => {\n                let mut self_next = self_iter.next()?;\n                loop {\n                    match other_iter.peek().map_or(Less, |other_next| self_next.cmp(other_next)) {\n                        Less => return Some(self_next),\n                        Equal => {\n                            self_next = self_iter.next()?;\n                            other_iter.next();\n                        }\n                        Greater => {\n                            other_iter.next();\n                        }\n                    }\n                }\n            }\n            DifferenceInner::Search { self_iter, other_set } => loop {\n                let self_next = self_iter.next()?;\n                if !other_set.contains(&self_next) {\n                    return Some(self_next);\n                }\n            },\n            DifferenceInner::Iterate(iter) => iter.next(),\n        }\n    }\n\n    fn size_hint(&self) -> (usize, Option<usize>) {\n        let (self_len, other_len) = match &self.inner {\n            DifferenceInner::Stitch { self_iter, other_iter } => {\n                (self_iter.len(), other_iter.len())\n            }\n            DifferenceInner::Search { self_iter, other_set } => (self_iter.len(), other_set.len()),\n            DifferenceInner::Iterate(iter) => (iter.len(), 0),\n        };\n        (self_len.saturating_sub(other_len), Some(self_len))\n    }\n\n    fn min(mut self) -> Option<&'a T> {\n        self.next()\n    }\n}\n\n#[stable(feature = \"fused\", since = \"1.26.0\")]\nimpl<T: Ord> FusedIterator for Difference<'_, T> {}\n\n#[stable(feature = \"rust1\", since = \"1.0.0\")]\nimpl<T> Clone for SymmetricDifference<'_, T> {\n    fn clone(&self) -> Self {\n        SymmetricDifference(self.0.clone())\n    }\n}\n#[stable(feature = \"rust1\", since = \"1.0.0\")]\nimpl<'a, T: Ord> Iterator for SymmetricDifference<'a, T> {\n    type Item = &'a T;\n\n    fn next(&mut self) -> Option<&'a T> {\n        loop {\n            let (a_next, b_next) = self.0.nexts(Self::Item::cmp);\n            if a_next.and(b_next).is_none() {\n                return a_next.or(b_next);\n            }\n        }\n    }\n\n    fn size_hint(&self) -> (usize, Option<usize>) {\n        let (a_len, b_len) = self.0.lens();\n        // No checked_add, because even if a and b refer to the same set,\n        // and T is an empty type, the storage overhead of sets limits\n        // the number of elements to less than half the range of usize.\n        (0, Some(a_len + b_len))\n    }\n\n    fn min(mut self) -> Option<&'a T> {\n        self.next()\n    }\n}\n\n#[stable(feature = \"fused\", since = \"1.26.0\")]\nimpl<T: Ord> FusedIterator for SymmetricDifference<'_, T> {}\n\n#[stable(feature = \"rust1\", since = \"1.0.0\")]\nimpl<T> Clone for Intersection<'_, T> {\n    fn clone(&self) -> Self {\n        Intersection {\n            inner: match &self.inner {\n                IntersectionInner::Stitch { a, b } => {\n                    IntersectionInner::Stitch { a: a.clone(), b: b.clone() }\n                }\n                IntersectionInner::Search { small_iter, large_set } => {\n                    IntersectionInner::Search { small_iter: small_iter.clone(), large_set }\n                }\n                IntersectionInner::Answer(answer) => IntersectionInner::Answer(*answer),\n            },\n        }\n    }\n}\n#[stable(feature = \"rust1\", since = \"1.0.0\")]\nimpl<'a, T: Ord> Iterator for Intersection<'a, T> {\n    type Item = &'a T;\n\n    fn next(&mut self) -> Option<&'a T> {\n        match &mut self.inner {\n            IntersectionInner::Stitch { a, b } => {\n                let mut a_next = a.next()?;\n                let mut b_next = b.next()?;\n                loop {\n                    match a_next.cmp(b_next) {\n                        Less => a_next = a.next()?,\n                        Greater => b_next = b.next()?,\n                        Equal => return Some(a_next),\n                    }\n                }\n            }\n            IntersectionInner::Search { small_iter, large_set } => loop {\n                let small_next = small_iter.next()?;\n                if large_set.contains(&small_next) {\n                    return Some(small_next);\n                }\n            },\n            IntersectionInner::Answer(answer) => answer.take(),\n        }\n    }\n\n    fn size_hint(&self) -> (usize, Option<usize>) {\n        match &self.inner {\n            IntersectionInner::Stitch { a, b } => (0, Some(min(a.len(), b.len()))),\n            IntersectionInner::Search { small_iter, .. } => (0, Some(small_iter.len())),\n            IntersectionInner::Answer(None) => (0, Some(0)),\n            IntersectionInner::Answer(Some(_)) => (1, Some(1)),\n        }\n    }\n\n    fn min(mut self) -> Option<&'a T> {\n        self.next()\n    }\n}\n\n#[stable(feature = \"fused\", since = \"1.26.0\")]\nimpl<T: Ord> FusedIterator for Intersection<'_, T> {}\n\n#[stable(feature = \"rust1\", since = \"1.0.0\")]\nimpl<T> Clone for Union<'_, T> {\n    fn clone(&self) -> Self {\n        Union(self.0.clone())\n    }\n}\n#[stable(feature = \"rust1\", since = \"1.0.0\")]\nimpl<'a, T: Ord> Iterator for Union<'a, T> {\n    type Item = &'a T;\n\n    fn next(&mut self) -> Option<&'a T> {\n        let (a_next, b_next) = self.0.nexts(Self::Item::cmp);\n        a_next.or(b_next)\n    }\n\n    fn size_hint(&self) -> (usize, Option<usize>) {\n        let (a_len, b_len) = self.0.lens();\n        // No checked_add - see SymmetricDifference::size_hint.\n        (max(a_len, b_len), Some(a_len + b_len))\n    }\n\n    fn min(mut self) -> Option<&'a T> {\n        self.next()\n    }\n}\n\n#[stable(feature = \"fused\", since = \"1.26.0\")]\nimpl<T: Ord> FusedIterator for Union<'_, T> {}\n\n#[cfg(test)]\nmod tests;\n"],[2043,"use super::map::MIN_LEN;\nuse super::node::{marker, ForceResult::*, Handle, LeftOrRight::*, NodeRef, Root};\n\nimpl<'a, K: 'a, V: 'a> NodeRef<marker::Mut<'a>, K, V, marker::LeafOrInternal> {\n    /// Stocks up a possibly underfull node by merging with or stealing from a\n    /// sibling. If successful but at the cost of shrinking the parent node,\n    /// returns that shrunk parent node. Returns an `Err` if the node is\n    /// an empty root.\n    fn fix_node_through_parent(\n        self,\n    ) -> Result<Option<NodeRef<marker::Mut<'a>, K, V, marker::Internal>>, Self> {\n        let len = self.len();\n        if len >= MIN_LEN {\n            Ok(None)\n        } else {\n            match self.choose_parent_kv() {\n                Ok(Left(mut left_parent_kv)) => {\n                    if left_parent_kv.can_merge() {\n                        let parent = left_parent_kv.merge_tracking_parent();\n                        Ok(Some(parent))\n                    } else {\n                        left_parent_kv.bulk_steal_left(MIN_LEN - len);\n                        Ok(None)\n                    }\n                }\n                Ok(Right(mut right_parent_kv)) => {\n                    if right_parent_kv.can_merge() {\n                        let parent = right_parent_kv.merge_tracking_parent();\n                        Ok(Some(parent))\n                    } else {\n                        right_parent_kv.bulk_steal_right(MIN_LEN - len);\n                        Ok(None)\n                    }\n                }\n                Err(root) => {\n                    if len > 0 {\n                        Ok(None)\n                    } else {\n                        Err(root)\n                    }\n                }\n            }\n        }\n    }\n}\n\nimpl<'a, K: 'a, V: 'a> NodeRef<marker::Mut<'a>, K, V, marker::LeafOrInternal> {\n    /// Stocks up a possibly underfull node, and if that causes its parent node\n    /// to shrink, stocks up the parent, recursively.\n    /// Returns `true` if it fixed the tree, `false` if it couldn't because the\n    /// root node became empty.\n    ///\n    /// This method does not expect ancestors to already be underfull upon entry\n    /// and panics if it encounters an empty ancestor.\n    pub fn fix_node_and_affected_ancestors(mut self) -> bool {\n        loop {\n            match self.fix_node_through_parent() {\n                Ok(Some(parent)) => self = parent.forget_type(),\n                Ok(None) => return true,\n                Err(_) => return false,\n            }\n        }\n    }\n}\n\nimpl<K, V> Root<K, V> {\n    /// Removes empty levels on the top, but keeps an empty leaf if the entire tree is empty.\n    pub fn fix_top(&mut self) {\n        while self.height() > 0 && self.len() == 0 {\n            self.pop_internal_level();\n        }\n    }\n\n    /// Stocks up or merge away any underfull nodes on the right border of the\n    /// tree. The other nodes, those that are not the root nor a rightmost edge,\n    /// must already have at least MIN_LEN elements.\n    pub fn fix_right_border(&mut self) {\n        self.fix_top();\n        if self.len() > 0 {\n            self.borrow_mut().last_kv().fix_right_border_of_right_edge();\n            self.fix_top();\n        }\n    }\n\n    /// The symmetric clone of `fix_right_border`.\n    pub fn fix_left_border(&mut self) {\n        self.fix_top();\n        if self.len() > 0 {\n            self.borrow_mut().first_kv().fix_left_border_of_left_edge();\n            self.fix_top();\n        }\n    }\n\n    /// Stock up any underfull nodes on the right border of the tree.\n    /// The other nodes, those that are not the root nor a rightmost edge,\n    /// must be prepared to have up to MIN_LEN elements stolen.\n    pub fn fix_right_border_of_plentiful(&mut self) {\n        let mut cur_node = self.borrow_mut();\n        while let Internal(internal) = cur_node.force() {\n            // Check if right-most child is underfull.\n            let mut last_kv = internal.last_kv().consider_for_balancing();\n            debug_assert!(last_kv.left_child_len() >= MIN_LEN * 2);\n            let right_child_len = last_kv.right_child_len();\n            if right_child_len < MIN_LEN {\n                // We need to steal.\n                last_kv.bulk_steal_left(MIN_LEN - right_child_len);\n            }\n\n            // Go further down.\n            cur_node = last_kv.into_right_child();\n        }\n    }\n}\n\nimpl<'a, K: 'a, V: 'a> Handle<NodeRef<marker::Mut<'a>, K, V, marker::LeafOrInternal>, marker::KV> {\n    fn fix_left_border_of_left_edge(mut self) {\n        while let Internal(internal_kv) = self.force() {\n            self = internal_kv.fix_left_child().first_kv();\n            debug_assert!(self.reborrow().into_node().len() > MIN_LEN);\n        }\n    }\n\n    fn fix_right_border_of_right_edge(mut self) {\n        while let Internal(internal_kv) = self.force() {\n            self = internal_kv.fix_right_child().last_kv();\n            debug_assert!(self.reborrow().into_node().len() > MIN_LEN);\n        }\n    }\n}\n\nimpl<'a, K: 'a, V: 'a> Handle<NodeRef<marker::Mut<'a>, K, V, marker::Internal>, marker::KV> {\n    /// Stocks up the left child, assuming the right child isn't underfull, and\n    /// provisions an extra element to allow merging its children in turn\n    /// without becoming underfull.\n    /// Returns the left child.\n    fn fix_left_child(self) -> NodeRef<marker::Mut<'a>, K, V, marker::LeafOrInternal> {\n        let mut internal_kv = self.consider_for_balancing();\n        let left_len = internal_kv.left_child_len();\n        debug_assert!(internal_kv.right_child_len() >= MIN_LEN);\n        if internal_kv.can_merge() {\n            internal_kv.merge_tracking_child()\n        } else {\n            // `MIN_LEN + 1` to avoid readjust if merge happens on the next level.\n            let count = (MIN_LEN + 1).saturating_sub(left_len);\n            if count > 0 {\n                internal_kv.bulk_steal_right(count);\n            }\n            internal_kv.into_left_child()\n        }\n    }\n\n    /// Stocks up the right child, assuming the left child isn't underfull, and\n    /// provisions an extra element to allow merging its children in turn\n    /// without becoming underfull.\n    /// Returns wherever the right child ended up.\n    fn fix_right_child(self) -> NodeRef<marker::Mut<'a>, K, V, marker::LeafOrInternal> {\n        let mut internal_kv = self.consider_for_balancing();\n        let right_len = internal_kv.right_child_len();\n        debug_assert!(internal_kv.left_child_len() >= MIN_LEN);\n        if internal_kv.can_merge() {\n            internal_kv.merge_tracking_child()\n        } else {\n            // `MIN_LEN + 1` to avoid readjust if merge happens on the next level.\n            let count = (MIN_LEN + 1).saturating_sub(right_len);\n            if count > 0 {\n                internal_kv.bulk_steal_left(count);\n            }\n            internal_kv.into_right_child()\n        }\n    }\n}\n"],[2044,"mod append;\nmod borrow;\nmod fix;\npub mod map;\nmod mem;\nmod merge_iter;\nmod navigate;\nmod node;\nmod remove;\nmod search;\npub mod set;\nmod split;\n\n#[doc(hidden)]\ntrait Recover<Q: ?Sized> {\n    type Key;\n\n    fn get(&self, key: &Q) -> Option<&Self::Key>;\n    fn take(&mut self, key: &Q) -> Option<Self::Key>;\n    fn replace(&mut self, key: Self::Key) -> Option<Self::Key>;\n}\n\n#[cfg(test)]\nmod testing;\n"],[2045,"use core::intrinsics;\nuse core::mem;\nuse core::ptr;\n\n/// This replaces the value behind the `v` unique reference by calling the\n/// relevant function.\n///\n/// If a panic occurs in the `change` closure, the entire process will be aborted.\n#[allow(dead_code)] // keep as illustration and for future use\n#[inline]\npub fn take_mut<T>(v: &mut T, change: impl FnOnce(T) -> T) {\n    replace(v, |value| (change(value), ()))\n}\n\n/// This replaces the value behind the `v` unique reference by calling the\n/// relevant function, and returns a result obtained along the way.\n///\n/// If a panic occurs in the `change` closure, the entire process will be aborted.\n#[inline]\npub fn replace<T, R>(v: &mut T, change: impl FnOnce(T) -> (T, R)) -> R {\n    struct PanicGuard;\n    impl Drop for PanicGuard {\n        fn drop(&mut self) {\n            intrinsics::abort()\n        }\n    }\n    let guard = PanicGuard;\n    let value = unsafe { ptr::read(v) };\n    let (new_value, ret) = change(value);\n    unsafe {\n        ptr::write(v, new_value);\n    }\n    mem::forget(guard);\n    ret\n}\n"],[2046,"use core::fmt::{self, Debug};\nuse core::marker::PhantomData;\nuse core::mem;\n\nuse super::super::borrow::DormantMutRef;\nuse super::super::node::{marker, Handle, InsertResult::*, NodeRef};\nuse super::BTreeMap;\n\nuse Entry::*;\n\n/// A view into a single entry in a map, which may either be vacant or occupied.\n///\n/// This `enum` is constructed from the [`entry`] method on [`BTreeMap`].\n///\n/// [`entry`]: BTreeMap::entry\n#[stable(feature = \"rust1\", since = \"1.0.0\")]\npub enum Entry<'a, K: 'a, V: 'a> {\n    /// A vacant entry.\n    #[stable(feature = \"rust1\", since = \"1.0.0\")]\n    Vacant(#[stable(feature = \"rust1\", since = \"1.0.0\")] VacantEntry<'a, K, V>),\n\n    /// An occupied entry.\n    #[stable(feature = \"rust1\", since = \"1.0.0\")]\n    Occupied(#[stable(feature = \"rust1\", since = \"1.0.0\")] OccupiedEntry<'a, K, V>),\n}\n\n#[stable(feature = \"debug_btree_map\", since = \"1.12.0\")]\nimpl<K: Debug + Ord, V: Debug> Debug for Entry<'_, K, V> {\n    fn fmt(&self, f: &mut fmt::Formatter<'_>) -> fmt::Result {\n        match *self {\n            Vacant(ref v) => f.debug_tuple(\"Entry\").field(v).finish(),\n            Occupied(ref o) => f.debug_tuple(\"Entry\").field(o).finish(),\n        }\n    }\n}\n\n/// A view into a vacant entry in a `BTreeMap`.\n/// It is part of the [`Entry`] enum.\n#[stable(feature = \"rust1\", since = \"1.0.0\")]\npub struct VacantEntry<'a, K: 'a, V: 'a> {\n    pub(super) key: K,\n    pub(super) handle: Handle<NodeRef<marker::Mut<'a>, K, V, marker::Leaf>, marker::Edge>,\n    pub(super) dormant_map: DormantMutRef<'a, BTreeMap<K, V>>,\n\n    // Be invariant in `K` and `V`\n    pub(super) _marker: PhantomData<&'a mut (K, V)>,\n}\n\n#[stable(feature = \"debug_btree_map\", since = \"1.12.0\")]\nimpl<K: Debug + Ord, V> Debug for VacantEntry<'_, K, V> {\n    fn fmt(&self, f: &mut fmt::Formatter<'_>) -> fmt::Result {\n        f.debug_tuple(\"VacantEntry\").field(self.key()).finish()\n    }\n}\n\n/// A view into an occupied entry in a `BTreeMap`.\n/// It is part of the [`Entry`] enum.\n#[stable(feature = \"rust1\", since = \"1.0.0\")]\npub struct OccupiedEntry<'a, K: 'a, V: 'a> {\n    pub(super) handle: Handle<NodeRef<marker::Mut<'a>, K, V, marker::LeafOrInternal>, marker::KV>,\n    pub(super) dormant_map: DormantMutRef<'a, BTreeMap<K, V>>,\n\n    // Be invariant in `K` and `V`\n    pub(super) _marker: PhantomData<&'a mut (K, V)>,\n}\n\n#[stable(feature = \"debug_btree_map\", since = \"1.12.0\")]\nimpl<K: Debug + Ord, V: Debug> Debug for OccupiedEntry<'_, K, V> {\n    fn fmt(&self, f: &mut fmt::Formatter<'_>) -> fmt::Result {\n        f.debug_struct(\"OccupiedEntry\").field(\"key\", self.key()).field(\"value\", self.get()).finish()\n    }\n}\n\n/// The error returned by [`try_insert`](BTreeMap::try_insert) when the key already exists.\n///\n/// Contains the occupied entry, and the value that was not inserted.\n#[unstable(feature = \"map_try_insert\", issue = \"82766\")]\npub struct OccupiedError<'a, K: 'a, V: 'a> {\n    /// The entry in the map that was already occupied.\n    pub entry: OccupiedEntry<'a, K, V>,\n    /// The value which was not inserted, because the entry was already occupied.\n    pub value: V,\n}\n\n#[unstable(feature = \"map_try_insert\", issue = \"82766\")]\nimpl<K: Debug + Ord, V: Debug> Debug for OccupiedError<'_, K, V> {\n    fn fmt(&self, f: &mut fmt::Formatter<'_>) -> fmt::Result {\n        f.debug_struct(\"OccupiedError\")\n            .field(\"key\", self.entry.key())\n            .field(\"old_value\", self.entry.get())\n            .field(\"new_value\", &self.value)\n            .finish()\n    }\n}\n\n#[unstable(feature = \"map_try_insert\", issue = \"82766\")]\nimpl<'a, K: Debug + Ord, V: Debug> fmt::Display for OccupiedError<'a, K, V> {\n    fn fmt(&self, f: &mut fmt::Formatter<'_>) -> fmt::Result {\n        write!(\n            f,\n            \"failed to insert {:?}, key {:?} already exists with value {:?}\",\n            self.value,\n            self.entry.key(),\n            self.entry.get(),\n        )\n    }\n}\n\nimpl<'a, K: Ord, V> Entry<'a, K, V> {\n    /// Ensures a value is in the entry by inserting the default if empty, and returns\n    /// a mutable reference to the value in the entry.\n    ///\n    /// # Examples\n    ///\n    /// ```\n    /// use std::collections::BTreeMap;\n    ///\n    /// let mut map: BTreeMap<&str, usize> = BTreeMap::new();\n    /// map.entry(\"poneyland\").or_insert(12);\n    ///\n    /// assert_eq!(map[\"poneyland\"], 12);\n    /// ```\n    #[stable(feature = \"rust1\", since = \"1.0.0\")]\n    pub fn or_insert(self, default: V) -> &'a mut V {\n        match self {\n            Occupied(entry) => entry.into_mut(),\n            Vacant(entry) => entry.insert(default),\n        }\n    }\n\n    /// Ensures a value is in the entry by inserting the result of the default function if empty,\n    /// and returns a mutable reference to the value in the entry.\n    ///\n    /// # Examples\n    ///\n    /// ```\n    /// use std::collections::BTreeMap;\n    ///\n    /// let mut map: BTreeMap<&str, String> = BTreeMap::new();\n    /// let s = \"hoho\".to_string();\n    ///\n    /// map.entry(\"poneyland\").or_insert_with(|| s);\n    ///\n    /// assert_eq!(map[\"poneyland\"], \"hoho\".to_string());\n    /// ```\n    #[stable(feature = \"rust1\", since = \"1.0.0\")]\n    pub fn or_insert_with<F: FnOnce() -> V>(self, default: F) -> &'a mut V {\n        match self {\n            Occupied(entry) => entry.into_mut(),\n            Vacant(entry) => entry.insert(default()),\n        }\n    }\n\n    /// Ensures a value is in the entry by inserting, if empty, the result of the default function.\n    /// This method allows for generating key-derived values for insertion by providing the default\n    /// function a reference to the key that was moved during the `.entry(key)` method call.\n    ///\n    /// The reference to the moved key is provided so that cloning or copying the key is\n    /// unnecessary, unlike with `.or_insert_with(|| ... )`.\n    ///\n    /// # Examples\n    ///\n    /// ```\n    /// use std::collections::BTreeMap;\n    ///\n    /// let mut map: BTreeMap<&str, usize> = BTreeMap::new();\n    ///\n    /// map.entry(\"poneyland\").or_insert_with_key(|key| key.chars().count());\n    ///\n    /// assert_eq!(map[\"poneyland\"], 9);\n    /// ```\n    #[inline]\n    #[stable(feature = \"or_insert_with_key\", since = \"1.50.0\")]\n    pub fn or_insert_with_key<F: FnOnce(&K) -> V>(self, default: F) -> &'a mut V {\n        match self {\n            Occupied(entry) => entry.into_mut(),\n            Vacant(entry) => {\n                let value = default(entry.key());\n                entry.insert(value)\n            }\n        }\n    }\n\n    /// Returns a reference to this entry's key.\n    ///\n    /// # Examples\n    ///\n    /// ```\n    /// use std::collections::BTreeMap;\n    ///\n    /// let mut map: BTreeMap<&str, usize> = BTreeMap::new();\n    /// assert_eq!(map.entry(\"poneyland\").key(), &\"poneyland\");\n    /// ```\n    #[stable(feature = \"map_entry_keys\", since = \"1.10.0\")]\n    pub fn key(&self) -> &K {\n        match *self {\n            Occupied(ref entry) => entry.key(),\n            Vacant(ref entry) => entry.key(),\n        }\n    }\n\n    /// Provides in-place mutable access to an occupied entry before any\n    /// potential inserts into the map.\n    ///\n    /// # Examples\n    ///\n    /// ```\n    /// use std::collections::BTreeMap;\n    ///\n    /// let mut map: BTreeMap<&str, usize> = BTreeMap::new();\n    ///\n    /// map.entry(\"poneyland\")\n    ///    .and_modify(|e| { *e += 1 })\n    ///    .or_insert(42);\n    /// assert_eq!(map[\"poneyland\"], 42);\n    ///\n    /// map.entry(\"poneyland\")\n    ///    .and_modify(|e| { *e += 1 })\n    ///    .or_insert(42);\n    /// assert_eq!(map[\"poneyland\"], 43);\n    /// ```\n    #[stable(feature = \"entry_and_modify\", since = \"1.26.0\")]\n    pub fn and_modify<F>(self, f: F) -> Self\n    where\n        F: FnOnce(&mut V),\n    {\n        match self {\n            Occupied(mut entry) => {\n                f(entry.get_mut());\n                Occupied(entry)\n            }\n            Vacant(entry) => Vacant(entry),\n        }\n    }\n}\n\nimpl<'a, K: Ord, V: Default> Entry<'a, K, V> {\n    #[stable(feature = \"entry_or_default\", since = \"1.28.0\")]\n    /// Ensures a value is in the entry by inserting the default value if empty,\n    /// and returns a mutable reference to the value in the entry.\n    ///\n    /// # Examples\n    ///\n    /// ```\n    /// use std::collections::BTreeMap;\n    ///\n    /// let mut map: BTreeMap<&str, Option<usize>> = BTreeMap::new();\n    /// map.entry(\"poneyland\").or_default();\n    ///\n    /// assert_eq!(map[\"poneyland\"], None);\n    /// ```\n    pub fn or_default(self) -> &'a mut V {\n        match self {\n            Occupied(entry) => entry.into_mut(),\n            Vacant(entry) => entry.insert(Default::default()),\n        }\n    }\n}\n\nimpl<'a, K: Ord, V> VacantEntry<'a, K, V> {\n    /// Gets a reference to the key that would be used when inserting a value\n    /// through the VacantEntry.\n    ///\n    /// # Examples\n    ///\n    /// ```\n    /// use std::collections::BTreeMap;\n    ///\n    /// let mut map: BTreeMap<&str, usize> = BTreeMap::new();\n    /// assert_eq!(map.entry(\"poneyland\").key(), &\"poneyland\");\n    /// ```\n    #[stable(feature = \"map_entry_keys\", since = \"1.10.0\")]\n    pub fn key(&self) -> &K {\n        &self.key\n    }\n\n    /// Take ownership of the key.\n    ///\n    /// # Examples\n    ///\n    /// ```\n    /// use std::collections::BTreeMap;\n    /// use std::collections::btree_map::Entry;\n    ///\n    /// let mut map: BTreeMap<&str, usize> = BTreeMap::new();\n    ///\n    /// if let Entry::Vacant(v) = map.entry(\"poneyland\") {\n    ///     v.into_key();\n    /// }\n    /// ```\n    #[stable(feature = \"map_entry_recover_keys2\", since = \"1.12.0\")]\n    pub fn into_key(self) -> K {\n        self.key\n    }\n\n    /// Sets the value of the entry with the `VacantEntry`'s key,\n    /// and returns a mutable reference to it.\n    ///\n    /// # Examples\n    ///\n    /// ```\n    /// use std::collections::BTreeMap;\n    /// use std::collections::btree_map::Entry;\n    ///\n    /// let mut map: BTreeMap<&str, u32> = BTreeMap::new();\n    ///\n    /// if let Entry::Vacant(o) = map.entry(\"poneyland\") {\n    ///     o.insert(37);\n    /// }\n    /// assert_eq!(map[\"poneyland\"], 37);\n    /// ```\n    #[stable(feature = \"rust1\", since = \"1.0.0\")]\n    pub fn insert(self, value: V) -> &'a mut V {\n        let out_ptr = match self.handle.insert_recursing(self.key, value) {\n            (Fit(_), val_ptr) => {\n                // SAFETY: We have consumed self.handle and the handle returned.\n                let map = unsafe { self.dormant_map.awaken() };\n                map.length += 1;\n                val_ptr\n            }\n            (Split(ins), val_ptr) => {\n                drop(ins.left);\n                // SAFETY: We have consumed self.handle and the reference returned.\n                let map = unsafe { self.dormant_map.awaken() };\n                let root = map.root.as_mut().unwrap();\n                root.push_internal_level().push(ins.kv.0, ins.kv.1, ins.right);\n                map.length += 1;\n                val_ptr\n            }\n        };\n        // Now that we have finished growing the tree using borrowed references,\n        // dereference the pointer to a part of it, that we picked up along the way.\n        unsafe { &mut *out_ptr }\n    }\n}\n\nimpl<'a, K: Ord, V> OccupiedEntry<'a, K, V> {\n    /// Gets a reference to the key in the entry.\n    ///\n    /// # Examples\n    ///\n    /// ```\n    /// use std::collections::BTreeMap;\n    ///\n    /// let mut map: BTreeMap<&str, usize> = BTreeMap::new();\n    /// map.entry(\"poneyland\").or_insert(12);\n    /// assert_eq!(map.entry(\"poneyland\").key(), &\"poneyland\");\n    /// ```\n    #[stable(feature = \"map_entry_keys\", since = \"1.10.0\")]\n    pub fn key(&self) -> &K {\n        self.handle.reborrow().into_kv().0\n    }\n\n    /// Take ownership of the key and value from the map.\n    ///\n    /// # Examples\n    ///\n    /// ```\n    /// use std::collections::BTreeMap;\n    /// use std::collections::btree_map::Entry;\n    ///\n    /// let mut map: BTreeMap<&str, usize> = BTreeMap::new();\n    /// map.entry(\"poneyland\").or_insert(12);\n    ///\n    /// if let Entry::Occupied(o) = map.entry(\"poneyland\") {\n    ///     // We delete the entry from the map.\n    ///     o.remove_entry();\n    /// }\n    ///\n    /// // If now try to get the value, it will panic:\n    /// // println!(\"{}\", map[\"poneyland\"]);\n    /// ```\n    #[stable(feature = \"map_entry_recover_keys2\", since = \"1.12.0\")]\n    pub fn remove_entry(self) -> (K, V) {\n        self.remove_kv()\n    }\n\n    /// Gets a reference to the value in the entry.\n    ///\n    /// # Examples\n    ///\n    /// ```\n    /// use std::collections::BTreeMap;\n    /// use std::collections::btree_map::Entry;\n    ///\n    /// let mut map: BTreeMap<&str, usize> = BTreeMap::new();\n    /// map.entry(\"poneyland\").or_insert(12);\n    ///\n    /// if let Entry::Occupied(o) = map.entry(\"poneyland\") {\n    ///     assert_eq!(o.get(), &12);\n    /// }\n    /// ```\n    #[stable(feature = \"rust1\", since = \"1.0.0\")]\n    pub fn get(&self) -> &V {\n        self.handle.reborrow().into_kv().1\n    }\n\n    /// Gets a mutable reference to the value in the entry.\n    ///\n    /// If you need a reference to the `OccupiedEntry` that may outlive the\n    /// destruction of the `Entry` value, see [`into_mut`].\n    ///\n    /// [`into_mut`]: OccupiedEntry::into_mut\n    ///\n    /// # Examples\n    ///\n    /// ```\n    /// use std::collections::BTreeMap;\n    /// use std::collections::btree_map::Entry;\n    ///\n    /// let mut map: BTreeMap<&str, usize> = BTreeMap::new();\n    /// map.entry(\"poneyland\").or_insert(12);\n    ///\n    /// assert_eq!(map[\"poneyland\"], 12);\n    /// if let Entry::Occupied(mut o) = map.entry(\"poneyland\") {\n    ///     *o.get_mut() += 10;\n    ///     assert_eq!(*o.get(), 22);\n    ///\n    ///     // We can use the same Entry multiple times.\n    ///     *o.get_mut() += 2;\n    /// }\n    /// assert_eq!(map[\"poneyland\"], 24);\n    /// ```\n    #[stable(feature = \"rust1\", since = \"1.0.0\")]\n    pub fn get_mut(&mut self) -> &mut V {\n        self.handle.kv_mut().1\n    }\n\n    /// Converts the entry into a mutable reference to its value.\n    ///\n    /// If you need multiple references to the `OccupiedEntry`, see [`get_mut`].\n    ///\n    /// [`get_mut`]: OccupiedEntry::get_mut\n    ///\n    /// # Examples\n    ///\n    /// ```\n    /// use std::collections::BTreeMap;\n    /// use std::collections::btree_map::Entry;\n    ///\n    /// let mut map: BTreeMap<&str, usize> = BTreeMap::new();\n    /// map.entry(\"poneyland\").or_insert(12);\n    ///\n    /// assert_eq!(map[\"poneyland\"], 12);\n    /// if let Entry::Occupied(o) = map.entry(\"poneyland\") {\n    ///     *o.into_mut() += 10;\n    /// }\n    /// assert_eq!(map[\"poneyland\"], 22);\n    /// ```\n    #[stable(feature = \"rust1\", since = \"1.0.0\")]\n    pub fn into_mut(self) -> &'a mut V {\n        self.handle.into_val_mut()\n    }\n\n    /// Sets the value of the entry with the `OccupiedEntry`'s key,\n    /// and returns the entry's old value.\n    ///\n    /// # Examples\n    ///\n    /// ```\n    /// use std::collections::BTreeMap;\n    /// use std::collections::btree_map::Entry;\n    ///\n    /// let mut map: BTreeMap<&str, usize> = BTreeMap::new();\n    /// map.entry(\"poneyland\").or_insert(12);\n    ///\n    /// if let Entry::Occupied(mut o) = map.entry(\"poneyland\") {\n    ///     assert_eq!(o.insert(15), 12);\n    /// }\n    /// assert_eq!(map[\"poneyland\"], 15);\n    /// ```\n    #[stable(feature = \"rust1\", since = \"1.0.0\")]\n    pub fn insert(&mut self, value: V) -> V {\n        mem::replace(self.get_mut(), value)\n    }\n\n    /// Takes the value of the entry out of the map, and returns it.\n    ///\n    /// # Examples\n    ///\n    /// ```\n    /// use std::collections::BTreeMap;\n    /// use std::collections::btree_map::Entry;\n    ///\n    /// let mut map: BTreeMap<&str, usize> = BTreeMap::new();\n    /// map.entry(\"poneyland\").or_insert(12);\n    ///\n    /// if let Entry::Occupied(o) = map.entry(\"poneyland\") {\n    ///     assert_eq!(o.remove(), 12);\n    /// }\n    /// // If we try to get \"poneyland\"'s value, it'll panic:\n    /// // println!(\"{}\", map[\"poneyland\"]);\n    /// ```\n    #[stable(feature = \"rust1\", since = \"1.0.0\")]\n    pub fn remove(self) -> V {\n        self.remove_kv().1\n    }\n\n    // Body of `remove_entry`, probably separate because the name reflects the returned pair.\n    pub(super) fn remove_kv(self) -> (K, V) {\n        let mut emptied_internal_root = false;\n        let (old_kv, _) = self.handle.remove_kv_tracking(|| emptied_internal_root = true);\n        // SAFETY: we consumed the intermediate root borrow, `self.handle`.\n        let map = unsafe { self.dormant_map.awaken() };\n        map.length -= 1;\n        if emptied_internal_root {\n            let root = map.root.as_mut().unwrap();\n            root.pop_internal_level();\n        }\n        old_kv\n    }\n}\n"],[2047,"use super::super::testing::crash_test::{CrashTestDummy, Panic};\nuse super::super::testing::ord_chaos::{Cyclic3, Governed, Governor};\nuse super::super::testing::rng::DeterministicRng;\nuse super::Entry::{Occupied, Vacant};\nuse super::*;\nuse crate::boxed::Box;\nuse crate::fmt::Debug;\nuse crate::rc::Rc;\nuse crate::string::{String, ToString};\nuse crate::vec::Vec;\nuse std::cmp::Ordering;\nuse std::convert::TryFrom;\nuse std::iter::{self, FromIterator};\nuse std::mem;\nuse std::ops::Bound::{self, Excluded, Included, Unbounded};\nuse std::ops::RangeBounds;\nuse std::panic::{catch_unwind, AssertUnwindSafe};\nuse std::sync::atomic::{AtomicUsize, Ordering::SeqCst};\n\n// Capacity of a tree with a single level,\n// i.e., a tree who's root is a leaf node at height 0.\nconst NODE_CAPACITY: usize = node::CAPACITY;\n\n// Minimum number of elements to insert, to guarantee a tree with 2 levels,\n// i.e., a tree who's root is an internal node at height 1, with edges to leaf nodes.\n// It's not the minimum size: removing an element from such a tree does not always reduce height.\nconst MIN_INSERTS_HEIGHT_1: usize = NODE_CAPACITY + 1;\n\n// Minimum number of elements to insert in ascending order, to guarantee a tree with 3 levels,\n// i.e., a tree who's root is an internal node at height 2, with edges to more internal nodes.\n// It's not the minimum size: removing an element from such a tree does not always reduce height.\nconst MIN_INSERTS_HEIGHT_2: usize = 89;\n\n// Gathers all references from a mutable iterator and makes sure Miri notices if\n// using them is dangerous.\nfn test_all_refs<'a, T: 'a>(dummy: &mut T, iter: impl Iterator<Item = &'a mut T>) {\n    // Gather all those references.\n    let mut refs: Vec<&mut T> = iter.collect();\n    // Use them all. Twice, to be sure we got all interleavings.\n    for r in refs.iter_mut() {\n        mem::swap(dummy, r);\n    }\n    for r in refs {\n        mem::swap(dummy, r);\n    }\n}\n\nimpl<K, V> BTreeMap<K, V> {\n    // Panics if the map (or the code navigating it) is corrupted.\n    fn check_invariants(&self) {\n        if let Some(root) = &self.root {\n            let root_node = root.reborrow();\n\n            // Check the back pointers top-down, before we attempt to rely on\n            // more serious navigation code.\n            assert!(root_node.ascend().is_err());\n            root_node.assert_back_pointers();\n\n            // Check consistency of `length` with what navigation code encounters.\n            assert_eq!(self.length, root_node.calc_length());\n\n            // Lastly, check the invariant causing the least harm.\n            root_node.assert_min_len(if root_node.height() > 0 { 1 } else { 0 });\n        } else {\n            assert_eq!(self.length, 0);\n        }\n\n        // Check that `assert_strictly_ascending` will encounter all keys.\n        assert_eq!(self.length, self.keys().count());\n    }\n\n    // Panics if the map is corrupted or if the keys are not in strictly\n    // ascending order, in the current opinion of the `Ord` implementation.\n    // If the `Ord` implementation violates transitivity, this method does not\n    // guarantee that all keys are unique, just that adjacent keys are unique.\n    fn check(&self)\n    where\n        K: Debug + Ord,\n    {\n        self.check_invariants();\n        self.assert_strictly_ascending();\n    }\n\n    // Returns the height of the root, if any.\n    fn height(&self) -> Option<usize> {\n        self.root.as_ref().map(node::Root::height)\n    }\n\n    fn dump_keys(&self) -> String\n    where\n        K: Debug,\n    {\n        if let Some(root) = self.root.as_ref() {\n            root.reborrow().dump_keys()\n        } else {\n            String::from(\"not yet allocated\")\n        }\n    }\n\n    // Panics if the keys are not in strictly ascending order.\n    fn assert_strictly_ascending(&self)\n    where\n        K: Debug + Ord,\n    {\n        let mut keys = self.keys();\n        if let Some(mut previous) = keys.next() {\n            for next in keys {\n                assert!(previous < next, \"{:?} >= {:?}\", previous, next);\n                previous = next;\n            }\n        }\n    }\n\n    // Transform the tree to minimize wasted space, obtaining fewer nodes that\n    // are mostly filled up to their capacity. The same compact tree could have\n    // been obtained by inserting keys in a shrewd order.\n    fn compact(&mut self)\n    where\n        K: Ord,\n    {\n        let iter = mem::take(self).into_iter();\n        let root = BTreeMap::ensure_is_owned(&mut self.root);\n        root.bulk_push(iter, &mut self.length);\n    }\n}\n\nimpl<'a, K: 'a, V: 'a> NodeRef<marker::Immut<'a>, K, V, marker::LeafOrInternal> {\n    fn assert_min_len(self, min_len: usize) {\n        assert!(self.len() >= min_len, \"node len {} < {}\", self.len(), min_len);\n        if let node::ForceResult::Internal(node) = self.force() {\n            for idx in 0..=node.len() {\n                let edge = unsafe { Handle::new_edge(node, idx) };\n                edge.descend().assert_min_len(MIN_LEN);\n            }\n        }\n    }\n}\n\n// Tests our value of MIN_INSERTS_HEIGHT_2. Failure may mean you just need to\n// adapt that value to match a change in node::CAPACITY or the choices made\n// during insertion, otherwise other test cases may fail or be less useful.\n#[test]\nfn test_levels() {\n    let mut map = BTreeMap::new();\n    map.check();\n    assert_eq!(map.height(), None);\n    assert_eq!(map.len(), 0);\n\n    map.insert(0, ());\n    while map.height() == Some(0) {\n        let last_key = *map.last_key_value().unwrap().0;\n        map.insert(last_key + 1, ());\n    }\n    map.check();\n    // Structure:\n    // - 1 element in internal root node with 2 children\n    // - 6 elements in left leaf child\n    // - 5 elements in right leaf child\n    assert_eq!(map.height(), Some(1));\n    assert_eq!(map.len(), MIN_INSERTS_HEIGHT_1, \"{}\", map.dump_keys());\n\n    while map.height() == Some(1) {\n        let last_key = *map.last_key_value().unwrap().0;\n        map.insert(last_key + 1, ());\n    }\n    map.check();\n    // Structure:\n    // - 1 element in internal root node with 2 children\n    // - 6 elements in left internal child with 7 grandchildren\n    // - 42 elements in left child's 7 grandchildren with 6 elements each\n    // - 5 elements in right internal child with 6 grandchildren\n    // - 30 elements in right child's 5 first grandchildren with 6 elements each\n    // - 5 elements in right child's last grandchild\n    assert_eq!(map.height(), Some(2));\n    assert_eq!(map.len(), MIN_INSERTS_HEIGHT_2, \"{}\", map.dump_keys());\n}\n\n// Ensures the testing infrastructure usually notices order violations.\n#[test]\n#[should_panic]\nfn test_check_ord_chaos() {\n    let gov = Governor::new();\n    let map: BTreeMap<_, _> = (0..2).map(|i| (Governed(i, &gov), ())).collect();\n    gov.flip();\n    map.check();\n}\n\n// Ensures the testing infrastructure doesn't always mind order violations.\n#[test]\nfn test_check_invariants_ord_chaos() {\n    let gov = Governor::new();\n    let map: BTreeMap<_, _> = (0..2).map(|i| (Governed(i, &gov), ())).collect();\n    gov.flip();\n    map.check_invariants();\n}\n\n#[test]\nfn test_basic_large() {\n    let mut map = BTreeMap::new();\n    // Miri is too slow\n    let size = if cfg!(miri) { MIN_INSERTS_HEIGHT_2 } else { 10000 };\n    let size = size + (size % 2); // round up to even number\n    assert_eq!(map.len(), 0);\n\n    for i in 0..size {\n        assert_eq!(map.insert(i, 10 * i), None);\n        assert_eq!(map.len(), i + 1);\n    }\n\n    assert_eq!(map.first_key_value(), Some((&0, &0)));\n    assert_eq!(map.last_key_value(), Some((&(size - 1), &(10 * (size - 1)))));\n    assert_eq!(map.first_entry().unwrap().key(), &0);\n    assert_eq!(map.last_entry().unwrap().key(), &(size - 1));\n\n    for i in 0..size {\n        assert_eq!(map.get(&i).unwrap(), &(i * 10));\n    }\n\n    for i in size..size * 2 {\n        assert_eq!(map.get(&i), None);\n    }\n\n    for i in 0..size {\n        assert_eq!(map.insert(i, 100 * i), Some(10 * i));\n        assert_eq!(map.len(), size);\n    }\n\n    for i in 0..size {\n        assert_eq!(map.get(&i).unwrap(), &(i * 100));\n    }\n\n    for i in 0..size / 2 {\n        assert_eq!(map.remove(&(i * 2)), Some(i * 200));\n        assert_eq!(map.len(), size - i - 1);\n    }\n\n    for i in 0..size / 2 {\n        assert_eq!(map.get(&(2 * i)), None);\n        assert_eq!(map.get(&(2 * i + 1)).unwrap(), &(i * 200 + 100));\n    }\n\n    for i in 0..size / 2 {\n        assert_eq!(map.remove(&(2 * i)), None);\n        assert_eq!(map.remove(&(2 * i + 1)), Some(i * 200 + 100));\n        assert_eq!(map.len(), size / 2 - i - 1);\n    }\n    map.check();\n}\n\n#[test]\nfn test_basic_small() {\n    let mut map = BTreeMap::new();\n    // Empty, root is absent (None):\n    assert_eq!(map.remove(&1), None);\n    assert_eq!(map.len(), 0);\n    assert_eq!(map.get(&1), None);\n    assert_eq!(map.get_mut(&1), None);\n    assert_eq!(map.first_key_value(), None);\n    assert_eq!(map.last_key_value(), None);\n    assert_eq!(map.keys().count(), 0);\n    assert_eq!(map.values().count(), 0);\n    assert_eq!(map.range(..).next(), None);\n    assert_eq!(map.range(..1).next(), None);\n    assert_eq!(map.range(1..).next(), None);\n    assert_eq!(map.range(1..=1).next(), None);\n    assert_eq!(map.range(1..2).next(), None);\n    assert_eq!(map.height(), None);\n    assert_eq!(map.insert(1, 1), None);\n    assert_eq!(map.height(), Some(0));\n    map.check();\n\n    // 1 key-value pair:\n    assert_eq!(map.len(), 1);\n    assert_eq!(map.get(&1), Some(&1));\n    assert_eq!(map.get_mut(&1), Some(&mut 1));\n    assert_eq!(map.first_key_value(), Some((&1, &1)));\n    assert_eq!(map.last_key_value(), Some((&1, &1)));\n    assert_eq!(map.keys().collect::<Vec<_>>(), vec![&1]);\n    assert_eq!(map.values().collect::<Vec<_>>(), vec![&1]);\n    assert_eq!(map.insert(1, 2), Some(1));\n    assert_eq!(map.len(), 1);\n    assert_eq!(map.get(&1), Some(&2));\n    assert_eq!(map.get_mut(&1), Some(&mut 2));\n    assert_eq!(map.first_key_value(), Some((&1, &2)));\n    assert_eq!(map.last_key_value(), Some((&1, &2)));\n    assert_eq!(map.keys().collect::<Vec<_>>(), vec![&1]);\n    assert_eq!(map.values().collect::<Vec<_>>(), vec![&2]);\n    assert_eq!(map.insert(2, 4), None);\n    assert_eq!(map.height(), Some(0));\n    map.check();\n\n    // 2 key-value pairs:\n    assert_eq!(map.len(), 2);\n    assert_eq!(map.get(&2), Some(&4));\n    assert_eq!(map.get_mut(&2), Some(&mut 4));\n    assert_eq!(map.first_key_value(), Some((&1, &2)));\n    assert_eq!(map.last_key_value(), Some((&2, &4)));\n    assert_eq!(map.keys().collect::<Vec<_>>(), vec![&1, &2]);\n    assert_eq!(map.values().collect::<Vec<_>>(), vec![&2, &4]);\n    assert_eq!(map.remove(&1), Some(2));\n    assert_eq!(map.height(), Some(0));\n    map.check();\n\n    // 1 key-value pair:\n    assert_eq!(map.len(), 1);\n    assert_eq!(map.get(&1), None);\n    assert_eq!(map.get_mut(&1), None);\n    assert_eq!(map.get(&2), Some(&4));\n    assert_eq!(map.get_mut(&2), Some(&mut 4));\n    assert_eq!(map.first_key_value(), Some((&2, &4)));\n    assert_eq!(map.last_key_value(), Some((&2, &4)));\n    assert_eq!(map.keys().collect::<Vec<_>>(), vec![&2]);\n    assert_eq!(map.values().collect::<Vec<_>>(), vec![&4]);\n    assert_eq!(map.remove(&2), Some(4));\n    assert_eq!(map.height(), Some(0));\n    map.check();\n\n    // Empty but root is owned (Some(...)):\n    assert_eq!(map.len(), 0);\n    assert_eq!(map.get(&1), None);\n    assert_eq!(map.get_mut(&1), None);\n    assert_eq!(map.first_key_value(), None);\n    assert_eq!(map.last_key_value(), None);\n    assert_eq!(map.keys().count(), 0);\n    assert_eq!(map.values().count(), 0);\n    assert_eq!(map.range(..).next(), None);\n    assert_eq!(map.range(..1).next(), None);\n    assert_eq!(map.range(1..).next(), None);\n    assert_eq!(map.range(1..=1).next(), None);\n    assert_eq!(map.range(1..2).next(), None);\n    assert_eq!(map.remove(&1), None);\n    assert_eq!(map.height(), Some(0));\n    map.check();\n}\n\n#[test]\nfn test_iter() {\n    // Miri is too slow\n    let size = if cfg!(miri) { 200 } else { 10000 };\n\n    let mut map: BTreeMap<_, _> = (0..size).map(|i| (i, i)).collect();\n\n    fn test<T>(size: usize, mut iter: T)\n    where\n        T: Iterator<Item = (usize, usize)>,\n    {\n        for i in 0..size {\n            assert_eq!(iter.size_hint(), (size - i, Some(size - i)));\n            assert_eq!(iter.next().unwrap(), (i, i));\n        }\n        assert_eq!(iter.size_hint(), (0, Some(0)));\n        assert_eq!(iter.next(), None);\n    }\n    test(size, map.iter().map(|(&k, &v)| (k, v)));\n    test(size, map.iter_mut().map(|(&k, &mut v)| (k, v)));\n    test(size, map.into_iter());\n}\n\n#[test]\nfn test_iter_rev() {\n    // Miri is too slow\n    let size = if cfg!(miri) { 200 } else { 10000 };\n\n    let mut map: BTreeMap<_, _> = (0..size).map(|i| (i, i)).collect();\n\n    fn test<T>(size: usize, mut iter: T)\n    where\n        T: Iterator<Item = (usize, usize)>,\n    {\n        for i in 0..size {\n            assert_eq!(iter.size_hint(), (size - i, Some(size - i)));\n            assert_eq!(iter.next().unwrap(), (size - i - 1, size - i - 1));\n        }\n        assert_eq!(iter.size_hint(), (0, Some(0)));\n        assert_eq!(iter.next(), None);\n    }\n    test(size, map.iter().rev().map(|(&k, &v)| (k, v)));\n    test(size, map.iter_mut().rev().map(|(&k, &mut v)| (k, v)));\n    test(size, map.into_iter().rev());\n}\n\n// Specifically tests iter_mut's ability to mutate the value of pairs in-line.\nfn do_test_iter_mut_mutation<T>(size: usize)\nwhere\n    T: Copy + Debug + Ord + TryFrom<usize>,\n    <T as TryFrom<usize>>::Error: Debug,\n{\n    let zero = T::try_from(0).unwrap();\n    let mut map: BTreeMap<T, T> = (0..size).map(|i| (T::try_from(i).unwrap(), zero)).collect();\n\n    // Forward and backward iteration sees enough pairs (also tested elsewhere)\n    assert_eq!(map.iter_mut().count(), size);\n    assert_eq!(map.iter_mut().rev().count(), size);\n\n    // Iterate forwards, trying to mutate to unique values\n    for (i, (k, v)) in map.iter_mut().enumerate() {\n        assert_eq!(*k, T::try_from(i).unwrap());\n        assert_eq!(*v, zero);\n        *v = T::try_from(i + 1).unwrap();\n    }\n\n    // Iterate backwards, checking that mutations succeeded and trying to mutate again\n    for (i, (k, v)) in map.iter_mut().rev().enumerate() {\n        assert_eq!(*k, T::try_from(size - i - 1).unwrap());\n        assert_eq!(*v, T::try_from(size - i).unwrap());\n        *v = T::try_from(2 * size - i).unwrap();\n    }\n\n    // Check that backward mutations succeeded\n    for (i, (k, v)) in map.iter_mut().enumerate() {\n        assert_eq!(*k, T::try_from(i).unwrap());\n        assert_eq!(*v, T::try_from(size + i + 1).unwrap());\n    }\n    map.check();\n}\n\n#[derive(Clone, Copy, Debug, Eq, PartialEq, PartialOrd, Ord)]\n#[repr(align(32))]\nstruct Align32(usize);\n\nimpl TryFrom<usize> for Align32 {\n    type Error = ();\n\n    fn try_from(s: usize) -> Result<Align32, ()> {\n        Ok(Align32(s))\n    }\n}\n\n#[test]\nfn test_iter_mut_mutation() {\n    // Check many alignments and trees with roots at various heights.\n    do_test_iter_mut_mutation::<u8>(0);\n    do_test_iter_mut_mutation::<u8>(1);\n    do_test_iter_mut_mutation::<u8>(MIN_INSERTS_HEIGHT_1);\n    do_test_iter_mut_mutation::<u8>(MIN_INSERTS_HEIGHT_2);\n    do_test_iter_mut_mutation::<u16>(1);\n    do_test_iter_mut_mutation::<u16>(MIN_INSERTS_HEIGHT_1);\n    do_test_iter_mut_mutation::<u16>(MIN_INSERTS_HEIGHT_2);\n    do_test_iter_mut_mutation::<u32>(1);\n    do_test_iter_mut_mutation::<u32>(MIN_INSERTS_HEIGHT_1);\n    do_test_iter_mut_mutation::<u32>(MIN_INSERTS_HEIGHT_2);\n    do_test_iter_mut_mutation::<u64>(1);\n    do_test_iter_mut_mutation::<u64>(MIN_INSERTS_HEIGHT_1);\n    do_test_iter_mut_mutation::<u64>(MIN_INSERTS_HEIGHT_2);\n    do_test_iter_mut_mutation::<u128>(1);\n    do_test_iter_mut_mutation::<u128>(MIN_INSERTS_HEIGHT_1);\n    do_test_iter_mut_mutation::<u128>(MIN_INSERTS_HEIGHT_2);\n    do_test_iter_mut_mutation::<Align32>(1);\n    do_test_iter_mut_mutation::<Align32>(MIN_INSERTS_HEIGHT_1);\n    do_test_iter_mut_mutation::<Align32>(MIN_INSERTS_HEIGHT_2);\n}\n\n#[test]\nfn test_values_mut() {\n    let mut a: BTreeMap<_, _> = (0..MIN_INSERTS_HEIGHT_2).map(|i| (i, i)).collect();\n    test_all_refs(&mut 13, a.values_mut());\n    a.check();\n}\n\n#[test]\nfn test_values_mut_mutation() {\n    let mut a = BTreeMap::new();\n    a.insert(1, String::from(\"hello\"));\n    a.insert(2, String::from(\"goodbye\"));\n\n    for value in a.values_mut() {\n        value.push_str(\"!\");\n    }\n\n    let values: Vec<String> = a.values().cloned().collect();\n    assert_eq!(values, [String::from(\"hello!\"), String::from(\"goodbye!\")]);\n    a.check();\n}\n\n#[test]\nfn test_iter_entering_root_twice() {\n    let mut map: BTreeMap<_, _> = (0..2).map(|i| (i, i)).collect();\n    let mut it = map.iter_mut();\n    let front = it.next().unwrap();\n    let back = it.next_back().unwrap();\n    assert_eq!(front, (&0, &mut 0));\n    assert_eq!(back, (&1, &mut 1));\n    *front.1 = 24;\n    *back.1 = 42;\n    assert_eq!(front, (&0, &mut 24));\n    assert_eq!(back, (&1, &mut 42));\n    assert_eq!(it.next(), None);\n    assert_eq!(it.next_back(), None);\n    map.check();\n}\n\n#[test]\nfn test_iter_descending_to_same_node_twice() {\n    let mut map: BTreeMap<_, _> = (0..MIN_INSERTS_HEIGHT_1).map(|i| (i, i)).collect();\n    let mut it = map.iter_mut();\n    // Descend into first child.\n    let front = it.next().unwrap();\n    // Descend into first child again, after running through second child.\n    while it.next_back().is_some() {}\n    // Check immutable access.\n    assert_eq!(front, (&0, &mut 0));\n    // Perform mutable access.\n    *front.1 = 42;\n    map.check();\n}\n\n#[test]\nfn test_iter_mixed() {\n    // Miri is too slow\n    let size = if cfg!(miri) { 200 } else { 10000 };\n\n    let mut map: BTreeMap<_, _> = (0..size).map(|i| (i, i)).collect();\n\n    fn test<T>(size: usize, mut iter: T)\n    where\n        T: Iterator<Item = (usize, usize)> + DoubleEndedIterator,\n    {\n        for i in 0..size / 4 {\n            assert_eq!(iter.size_hint(), (size - i * 2, Some(size - i * 2)));\n            assert_eq!(iter.next().unwrap(), (i, i));\n            assert_eq!(iter.next_back().unwrap(), (size - i - 1, size - i - 1));\n        }\n        for i in size / 4..size * 3 / 4 {\n            assert_eq!(iter.size_hint(), (size * 3 / 4 - i, Some(size * 3 / 4 - i)));\n            assert_eq!(iter.next().unwrap(), (i, i));\n        }\n        assert_eq!(iter.size_hint(), (0, Some(0)));\n        assert_eq!(iter.next(), None);\n    }\n    test(size, map.iter().map(|(&k, &v)| (k, v)));\n    test(size, map.iter_mut().map(|(&k, &mut v)| (k, v)));\n    test(size, map.into_iter());\n}\n\n#[test]\nfn test_iter_min_max() {\n    let mut a = BTreeMap::new();\n    assert_eq!(a.iter().min(), None);\n    assert_eq!(a.iter().max(), None);\n    assert_eq!(a.iter_mut().min(), None);\n    assert_eq!(a.iter_mut().max(), None);\n    assert_eq!(a.range(..).min(), None);\n    assert_eq!(a.range(..).max(), None);\n    assert_eq!(a.range_mut(..).min(), None);\n    assert_eq!(a.range_mut(..).max(), None);\n    assert_eq!(a.keys().min(), None);\n    assert_eq!(a.keys().max(), None);\n    assert_eq!(a.values().min(), None);\n    assert_eq!(a.values().max(), None);\n    assert_eq!(a.values_mut().min(), None);\n    assert_eq!(a.values_mut().max(), None);\n    a.insert(1, 42);\n    a.insert(2, 24);\n    assert_eq!(a.iter().min(), Some((&1, &42)));\n    assert_eq!(a.iter().max(), Some((&2, &24)));\n    assert_eq!(a.iter_mut().min(), Some((&1, &mut 42)));\n    assert_eq!(a.iter_mut().max(), Some((&2, &mut 24)));\n    assert_eq!(a.range(..).min(), Some((&1, &42)));\n    assert_eq!(a.range(..).max(), Some((&2, &24)));\n    assert_eq!(a.range_mut(..).min(), Some((&1, &mut 42)));\n    assert_eq!(a.range_mut(..).max(), Some((&2, &mut 24)));\n    assert_eq!(a.keys().min(), Some(&1));\n    assert_eq!(a.keys().max(), Some(&2));\n    assert_eq!(a.values().min(), Some(&24));\n    assert_eq!(a.values().max(), Some(&42));\n    assert_eq!(a.values_mut().min(), Some(&mut 24));\n    assert_eq!(a.values_mut().max(), Some(&mut 42));\n    a.check();\n}\n\nfn range_keys(map: &BTreeMap<i32, i32>, range: impl RangeBounds<i32>) -> Vec<i32> {\n    map.range(range)\n        .map(|(&k, &v)| {\n            assert_eq!(k, v);\n            k\n        })\n        .collect()\n}\n\n#[test]\nfn test_range_small() {\n    let size = 4;\n\n    let map: BTreeMap<_, _> = (1..=size).map(|i| (i, i)).collect();\n    let all: Vec<_> = (1..=size).collect();\n    let (first, last) = (vec![all[0]], vec![all[size as usize - 1]]);\n\n    assert_eq!(range_keys(&map, (Excluded(0), Excluded(size + 1))), all);\n    assert_eq!(range_keys(&map, (Excluded(0), Included(size + 1))), all);\n    assert_eq!(range_keys(&map, (Excluded(0), Included(size))), all);\n    assert_eq!(range_keys(&map, (Excluded(0), Unbounded)), all);\n    assert_eq!(range_keys(&map, (Included(0), Excluded(size + 1))), all);\n    assert_eq!(range_keys(&map, (Included(0), Included(size + 1))), all);\n    assert_eq!(range_keys(&map, (Included(0), Included(size))), all);\n    assert_eq!(range_keys(&map, (Included(0), Unbounded)), all);\n    assert_eq!(range_keys(&map, (Included(1), Excluded(size + 1))), all);\n    assert_eq!(range_keys(&map, (Included(1), Included(size + 1))), all);\n    assert_eq!(range_keys(&map, (Included(1), Included(size))), all);\n    assert_eq!(range_keys(&map, (Included(1), Unbounded)), all);\n    assert_eq!(range_keys(&map, (Unbounded, Excluded(size + 1))), all);\n    assert_eq!(range_keys(&map, (Unbounded, Included(size + 1))), all);\n    assert_eq!(range_keys(&map, (Unbounded, Included(size))), all);\n    assert_eq!(range_keys(&map, ..), all);\n\n    assert_eq!(range_keys(&map, (Excluded(0), Excluded(1))), vec![]);\n    assert_eq!(range_keys(&map, (Excluded(0), Included(0))), vec![]);\n    assert_eq!(range_keys(&map, (Included(0), Included(0))), vec![]);\n    assert_eq!(range_keys(&map, (Included(0), Excluded(1))), vec![]);\n    assert_eq!(range_keys(&map, (Unbounded, Excluded(1))), vec![]);\n    assert_eq!(range_keys(&map, (Unbounded, Included(0))), vec![]);\n    assert_eq!(range_keys(&map, (Excluded(0), Excluded(2))), first);\n    assert_eq!(range_keys(&map, (Excluded(0), Included(1))), first);\n    assert_eq!(range_keys(&map, (Included(0), Excluded(2))), first);\n    assert_eq!(range_keys(&map, (Included(0), Included(1))), first);\n    assert_eq!(range_keys(&map, (Included(1), Excluded(2))), first);\n    assert_eq!(range_keys(&map, (Included(1), Included(1))), first);\n    assert_eq!(range_keys(&map, (Unbounded, Excluded(2))), first);\n    assert_eq!(range_keys(&map, (Unbounded, Included(1))), first);\n    assert_eq!(range_keys(&map, (Excluded(size - 1), Excluded(size + 1))), last);\n    assert_eq!(range_keys(&map, (Excluded(size - 1), Included(size + 1))), last);\n    assert_eq!(range_keys(&map, (Excluded(size - 1), Included(size))), last);\n    assert_eq!(range_keys(&map, (Excluded(size - 1), Unbounded)), last);\n    assert_eq!(range_keys(&map, (Included(size), Excluded(size + 1))), last);\n    assert_eq!(range_keys(&map, (Included(size), Included(size + 1))), last);\n    assert_eq!(range_keys(&map, (Included(size), Included(size))), last);\n    assert_eq!(range_keys(&map, (Included(size), Unbounded)), last);\n    assert_eq!(range_keys(&map, (Excluded(size), Excluded(size + 1))), vec![]);\n    assert_eq!(range_keys(&map, (Excluded(size), Included(size))), vec![]);\n    assert_eq!(range_keys(&map, (Excluded(size), Unbounded)), vec![]);\n    assert_eq!(range_keys(&map, (Included(size + 1), Excluded(size + 1))), vec![]);\n    assert_eq!(range_keys(&map, (Included(size + 1), Included(size + 1))), vec![]);\n    assert_eq!(range_keys(&map, (Included(size + 1), Unbounded)), vec![]);\n\n    assert_eq!(range_keys(&map, ..3), vec![1, 2]);\n    assert_eq!(range_keys(&map, 3..), vec![3, 4]);\n    assert_eq!(range_keys(&map, 2..=3), vec![2, 3]);\n}\n\n#[test]\nfn test_range_height_1() {\n    // Tests tree with a root and 2 leaves. The single key in the root node is\n    // close to the middle among the keys.\n\n    let map: BTreeMap<_, _> = (0..MIN_INSERTS_HEIGHT_1 as i32).map(|i| (i, i)).collect();\n    let middle = MIN_INSERTS_HEIGHT_1 as i32 / 2;\n    for root in middle - 2..=middle + 2 {\n        assert_eq!(range_keys(&map, (Excluded(root), Excluded(root + 1))), vec![]);\n        assert_eq!(range_keys(&map, (Excluded(root), Included(root + 1))), vec![root + 1]);\n        assert_eq!(range_keys(&map, (Included(root), Excluded(root + 1))), vec![root]);\n        assert_eq!(range_keys(&map, (Included(root), Included(root + 1))), vec![root, root + 1]);\n\n        assert_eq!(range_keys(&map, (Excluded(root - 1), Excluded(root))), vec![]);\n        assert_eq!(range_keys(&map, (Included(root - 1), Excluded(root))), vec![root - 1]);\n        assert_eq!(range_keys(&map, (Excluded(root - 1), Included(root))), vec![root]);\n        assert_eq!(range_keys(&map, (Included(root - 1), Included(root))), vec![root - 1, root]);\n    }\n}\n\n#[test]\nfn test_range_large() {\n    let size = 200;\n\n    let map: BTreeMap<_, _> = (1..=size).map(|i| (i, i)).collect();\n    let all: Vec<_> = (1..=size).collect();\n    let (first, last) = (vec![all[0]], vec![all[size as usize - 1]]);\n\n    assert_eq!(range_keys(&map, (Excluded(0), Excluded(size + 1))), all);\n    assert_eq!(range_keys(&map, (Excluded(0), Included(size + 1))), all);\n    assert_eq!(range_keys(&map, (Excluded(0), Included(size))), all);\n    assert_eq!(range_keys(&map, (Excluded(0), Unbounded)), all);\n    assert_eq!(range_keys(&map, (Included(0), Excluded(size + 1))), all);\n    assert_eq!(range_keys(&map, (Included(0), Included(size + 1))), all);\n    assert_eq!(range_keys(&map, (Included(0), Included(size))), all);\n    assert_eq!(range_keys(&map, (Included(0), Unbounded)), all);\n    assert_eq!(range_keys(&map, (Included(1), Excluded(size + 1))), all);\n    assert_eq!(range_keys(&map, (Included(1), Included(size + 1))), all);\n    assert_eq!(range_keys(&map, (Included(1), Included(size))), all);\n    assert_eq!(range_keys(&map, (Included(1), Unbounded)), all);\n    assert_eq!(range_keys(&map, (Unbounded, Excluded(size + 1))), all);\n    assert_eq!(range_keys(&map, (Unbounded, Included(size + 1))), all);\n    assert_eq!(range_keys(&map, (Unbounded, Included(size))), all);\n    assert_eq!(range_keys(&map, ..), all);\n\n    assert_eq!(range_keys(&map, (Excluded(0), Excluded(1))), vec![]);\n    assert_eq!(range_keys(&map, (Excluded(0), Included(0))), vec![]);\n    assert_eq!(range_keys(&map, (Included(0), Included(0))), vec![]);\n    assert_eq!(range_keys(&map, (Included(0), Excluded(1))), vec![]);\n    assert_eq!(range_keys(&map, (Unbounded, Excluded(1))), vec![]);\n    assert_eq!(range_keys(&map, (Unbounded, Included(0))), vec![]);\n    assert_eq!(range_keys(&map, (Excluded(0), Excluded(2))), first);\n    assert_eq!(range_keys(&map, (Excluded(0), Included(1))), first);\n    assert_eq!(range_keys(&map, (Included(0), Excluded(2))), first);\n    assert_eq!(range_keys(&map, (Included(0), Included(1))), first);\n    assert_eq!(range_keys(&map, (Included(1), Excluded(2))), first);\n    assert_eq!(range_keys(&map, (Included(1), Included(1))), first);\n    assert_eq!(range_keys(&map, (Unbounded, Excluded(2))), first);\n    assert_eq!(range_keys(&map, (Unbounded, Included(1))), first);\n    assert_eq!(range_keys(&map, (Excluded(size - 1), Excluded(size + 1))), last);\n    assert_eq!(range_keys(&map, (Excluded(size - 1), Included(size + 1))), last);\n    assert_eq!(range_keys(&map, (Excluded(size - 1), Included(size))), last);\n    assert_eq!(range_keys(&map, (Excluded(size - 1), Unbounded)), last);\n    assert_eq!(range_keys(&map, (Included(size), Excluded(size + 1))), last);\n    assert_eq!(range_keys(&map, (Included(size), Included(size + 1))), last);\n    assert_eq!(range_keys(&map, (Included(size), Included(size))), last);\n    assert_eq!(range_keys(&map, (Included(size), Unbounded)), last);\n    assert_eq!(range_keys(&map, (Excluded(size), Excluded(size + 1))), vec![]);\n    assert_eq!(range_keys(&map, (Excluded(size), Included(size))), vec![]);\n    assert_eq!(range_keys(&map, (Excluded(size), Unbounded)), vec![]);\n    assert_eq!(range_keys(&map, (Included(size + 1), Excluded(size + 1))), vec![]);\n    assert_eq!(range_keys(&map, (Included(size + 1), Included(size + 1))), vec![]);\n    assert_eq!(range_keys(&map, (Included(size + 1), Unbounded)), vec![]);\n\n    fn check<'a, L, R>(lhs: L, rhs: R)\n    where\n        L: IntoIterator<Item = (&'a i32, &'a i32)>,\n        R: IntoIterator<Item = (&'a i32, &'a i32)>,\n    {\n        let lhs: Vec<_> = lhs.into_iter().collect();\n        let rhs: Vec<_> = rhs.into_iter().collect();\n        assert_eq!(lhs, rhs);\n    }\n\n    check(map.range(..=100), map.range(..101));\n    check(map.range(5..=8), vec![(&5, &5), (&6, &6), (&7, &7), (&8, &8)]);\n    check(map.range(-1..=2), vec![(&1, &1), (&2, &2)]);\n}\n\n#[test]\nfn test_range_inclusive_max_value() {\n    let max = usize::MAX;\n    let map: BTreeMap<_, _> = vec![(max, 0)].into_iter().collect();\n\n    assert_eq!(map.range(max..=max).collect::<Vec<_>>(), &[(&max, &0)]);\n}\n\n#[test]\nfn test_range_equal_empty_cases() {\n    let map: BTreeMap<_, _> = (0..5).map(|i| (i, i)).collect();\n    assert_eq!(map.range((Included(2), Excluded(2))).next(), None);\n    assert_eq!(map.range((Excluded(2), Included(2))).next(), None);\n}\n\n#[test]\n#[should_panic]\nfn test_range_equal_excluded() {\n    let map: BTreeMap<_, _> = (0..5).map(|i| (i, i)).collect();\n    map.range((Excluded(2), Excluded(2)));\n}\n\n#[test]\n#[should_panic]\nfn test_range_backwards_1() {\n    let map: BTreeMap<_, _> = (0..5).map(|i| (i, i)).collect();\n    map.range((Included(3), Included(2)));\n}\n\n#[test]\n#[should_panic]\nfn test_range_backwards_2() {\n    let map: BTreeMap<_, _> = (0..5).map(|i| (i, i)).collect();\n    map.range((Included(3), Excluded(2)));\n}\n\n#[test]\n#[should_panic]\nfn test_range_backwards_3() {\n    let map: BTreeMap<_, _> = (0..5).map(|i| (i, i)).collect();\n    map.range((Excluded(3), Included(2)));\n}\n\n#[test]\n#[should_panic]\nfn test_range_backwards_4() {\n    let map: BTreeMap<_, _> = (0..5).map(|i| (i, i)).collect();\n    map.range((Excluded(3), Excluded(2)));\n}\n\n#[test]\nfn test_range_finding_ill_order_in_map() {\n    let mut map = BTreeMap::new();\n    map.insert(Cyclic3::B, ());\n    // Lacking static_assert, call `range` conditionally, to emphasise that\n    // we cause a different panic than `test_range_backwards_1` does.\n    // A more refined `should_panic` would be welcome.\n    if Cyclic3::C < Cyclic3::A {\n        map.range(Cyclic3::C..=Cyclic3::A);\n    }\n}\n\n#[test]\nfn test_range_finding_ill_order_in_range_ord() {\n    // Has proper order the first time asked, then flips around.\n    struct EvilTwin(i32);\n\n    impl PartialOrd for EvilTwin {\n        fn partial_cmp(&self, other: &Self) -> Option<Ordering> {\n            Some(self.cmp(other))\n        }\n    }\n\n    static COMPARES: AtomicUsize = AtomicUsize::new(0);\n    impl Ord for EvilTwin {\n        fn cmp(&self, other: &Self) -> Ordering {\n            let ord = self.0.cmp(&other.0);\n            if COMPARES.fetch_add(1, SeqCst) > 0 { ord.reverse() } else { ord }\n        }\n    }\n\n    impl PartialEq for EvilTwin {\n        fn eq(&self, other: &Self) -> bool {\n            self.0.eq(&other.0)\n        }\n    }\n\n    impl Eq for EvilTwin {}\n\n    #[derive(PartialEq, Eq, PartialOrd, Ord)]\n    struct CompositeKey(i32, EvilTwin);\n\n    impl Borrow<EvilTwin> for CompositeKey {\n        fn borrow(&self) -> &EvilTwin {\n            &self.1\n        }\n    }\n\n    let map = (0..12).map(|i| (CompositeKey(i, EvilTwin(i)), ())).collect::<BTreeMap<_, _>>();\n    map.range(EvilTwin(5)..=EvilTwin(7));\n}\n\n#[test]\nfn test_range_1000() {\n    // Miri is too slow\n    let size = if cfg!(miri) { MIN_INSERTS_HEIGHT_2 as u32 } else { 1000 };\n    let map: BTreeMap<_, _> = (0..size).map(|i| (i, i)).collect();\n\n    fn test(map: &BTreeMap<u32, u32>, size: u32, min: Bound<&u32>, max: Bound<&u32>) {\n        let mut kvs = map.range((min, max)).map(|(&k, &v)| (k, v));\n        let mut pairs = (0..size).map(|i| (i, i));\n\n        for (kv, pair) in kvs.by_ref().zip(pairs.by_ref()) {\n            assert_eq!(kv, pair);\n        }\n        assert_eq!(kvs.next(), None);\n        assert_eq!(pairs.next(), None);\n    }\n    test(&map, size, Included(&0), Excluded(&size));\n    test(&map, size, Unbounded, Excluded(&size));\n    test(&map, size, Included(&0), Included(&(size - 1)));\n    test(&map, size, Unbounded, Included(&(size - 1)));\n    test(&map, size, Included(&0), Unbounded);\n    test(&map, size, Unbounded, Unbounded);\n}\n\n#[test]\nfn test_range_borrowed_key() {\n    let mut map = BTreeMap::new();\n    map.insert(\"aardvark\".to_string(), 1);\n    map.insert(\"baboon\".to_string(), 2);\n    map.insert(\"coyote\".to_string(), 3);\n    map.insert(\"dingo\".to_string(), 4);\n    // NOTE: would like to use simply \"b\"..\"d\" here...\n    let mut iter = map.range::<str, _>((Included(\"b\"), Excluded(\"d\")));\n    assert_eq!(iter.next(), Some((&\"baboon\".to_string(), &2)));\n    assert_eq!(iter.next(), Some((&\"coyote\".to_string(), &3)));\n    assert_eq!(iter.next(), None);\n}\n\n#[test]\nfn test_range() {\n    let size = 200;\n    // Miri is too slow\n    let step = if cfg!(miri) { 66 } else { 1 };\n    let map: BTreeMap<_, _> = (0..size).map(|i| (i, i)).collect();\n\n    for i in (0..size).step_by(step) {\n        for j in (i..size).step_by(step) {\n            let mut kvs = map.range((Included(&i), Included(&j))).map(|(&k, &v)| (k, v));\n            let mut pairs = (i..=j).map(|i| (i, i));\n\n            for (kv, pair) in kvs.by_ref().zip(pairs.by_ref()) {\n                assert_eq!(kv, pair);\n            }\n            assert_eq!(kvs.next(), None);\n            assert_eq!(pairs.next(), None);\n        }\n    }\n}\n\n#[test]\nfn test_range_mut() {\n    let size = 200;\n    // Miri is too slow\n    let step = if cfg!(miri) { 66 } else { 1 };\n    let mut map: BTreeMap<_, _> = (0..size).map(|i| (i, i)).collect();\n\n    for i in (0..size).step_by(step) {\n        for j in (i..size).step_by(step) {\n            let mut kvs = map.range_mut((Included(&i), Included(&j))).map(|(&k, &mut v)| (k, v));\n            let mut pairs = (i..=j).map(|i| (i, i));\n\n            for (kv, pair) in kvs.by_ref().zip(pairs.by_ref()) {\n                assert_eq!(kv, pair);\n            }\n            assert_eq!(kvs.next(), None);\n            assert_eq!(pairs.next(), None);\n        }\n    }\n    map.check();\n}\n\n#[test]\nfn test_retain() {\n    let mut map: BTreeMap<i32, i32> = (0..100).map(|x| (x, x * 10)).collect();\n\n    map.retain(|&k, _| k % 2 == 0);\n    assert_eq!(map.len(), 50);\n    assert_eq!(map[&2], 20);\n    assert_eq!(map[&4], 40);\n    assert_eq!(map[&6], 60);\n}\n\nmod test_drain_filter {\n    use super::*;\n\n    #[test]\n    fn empty() {\n        let mut map: BTreeMap<i32, i32> = BTreeMap::new();\n        map.drain_filter(|_, _| unreachable!(\"there's nothing to decide on\"));\n        assert!(map.is_empty());\n        map.check();\n    }\n\n    // Explicitly consumes the iterator, where most test cases drop it instantly.\n    #[test]\n    fn consumed_keeping_all() {\n        let pairs = (0..3).map(|i| (i, i));\n        let mut map: BTreeMap<_, _> = pairs.collect();\n        assert!(map.drain_filter(|_, _| false).eq(iter::empty()));\n        map.check();\n    }\n\n    // Explicitly consumes the iterator, where most test cases drop it instantly.\n    #[test]\n    fn consumed_removing_all() {\n        let pairs = (0..3).map(|i| (i, i));\n        let mut map: BTreeMap<_, _> = pairs.clone().collect();\n        assert!(map.drain_filter(|_, _| true).eq(pairs));\n        assert!(map.is_empty());\n        map.check();\n    }\n\n    // Explicitly consumes the iterator and modifies values through it.\n    #[test]\n    fn mutating_and_keeping() {\n        let pairs = (0..3).map(|i| (i, i));\n        let mut map: BTreeMap<_, _> = pairs.collect();\n        assert!(\n            map.drain_filter(|_, v| {\n                *v += 6;\n                false\n            })\n            .eq(iter::empty())\n        );\n        assert!(map.keys().copied().eq(0..3));\n        assert!(map.values().copied().eq(6..9));\n        map.check();\n    }\n\n    // Explicitly consumes the iterator and modifies values through it.\n    #[test]\n    fn mutating_and_removing() {\n        let pairs = (0..3).map(|i| (i, i));\n        let mut map: BTreeMap<_, _> = pairs.collect();\n        assert!(\n            map.drain_filter(|_, v| {\n                *v += 6;\n                true\n            })\n            .eq((0..3).map(|i| (i, i + 6)))\n        );\n        assert!(map.is_empty());\n        map.check();\n    }\n\n    #[test]\n    fn underfull_keeping_all() {\n        let pairs = (0..3).map(|i| (i, i));\n        let mut map: BTreeMap<_, _> = pairs.collect();\n        map.drain_filter(|_, _| false);\n        assert!(map.keys().copied().eq(0..3));\n        map.check();\n    }\n\n    #[test]\n    fn underfull_removing_one() {\n        let pairs = (0..3).map(|i| (i, i));\n        for doomed in 0..3 {\n            let mut map: BTreeMap<_, _> = pairs.clone().collect();\n            map.drain_filter(|i, _| *i == doomed);\n            assert_eq!(map.len(), 2);\n            map.check();\n        }\n    }\n\n    #[test]\n    fn underfull_keeping_one() {\n        let pairs = (0..3).map(|i| (i, i));\n        for sacred in 0..3 {\n            let mut map: BTreeMap<_, _> = pairs.clone().collect();\n            map.drain_filter(|i, _| *i != sacred);\n            assert!(map.keys().copied().eq(sacred..=sacred));\n            map.check();\n        }\n    }\n\n    #[test]\n    fn underfull_removing_all() {\n        let pairs = (0..3).map(|i| (i, i));\n        let mut map: BTreeMap<_, _> = pairs.collect();\n        map.drain_filter(|_, _| true);\n        assert!(map.is_empty());\n        map.check();\n    }\n\n    #[test]\n    fn height_0_keeping_all() {\n        let pairs = (0..NODE_CAPACITY).map(|i| (i, i));\n        let mut map: BTreeMap<_, _> = pairs.collect();\n        map.drain_filter(|_, _| false);\n        assert!(map.keys().copied().eq(0..NODE_CAPACITY));\n        map.check();\n    }\n\n    #[test]\n    fn height_0_removing_one() {\n        let pairs = (0..NODE_CAPACITY).map(|i| (i, i));\n        for doomed in 0..NODE_CAPACITY {\n            let mut map: BTreeMap<_, _> = pairs.clone().collect();\n            map.drain_filter(|i, _| *i == doomed);\n            assert_eq!(map.len(), NODE_CAPACITY - 1);\n            map.check();\n        }\n    }\n\n    #[test]\n    fn height_0_keeping_one() {\n        let pairs = (0..NODE_CAPACITY).map(|i| (i, i));\n        for sacred in 0..NODE_CAPACITY {\n            let mut map: BTreeMap<_, _> = pairs.clone().collect();\n            map.drain_filter(|i, _| *i != sacred);\n            assert!(map.keys().copied().eq(sacred..=sacred));\n            map.check();\n        }\n    }\n\n    #[test]\n    fn height_0_removing_all() {\n        let pairs = (0..NODE_CAPACITY).map(|i| (i, i));\n        let mut map: BTreeMap<_, _> = pairs.collect();\n        map.drain_filter(|_, _| true);\n        assert!(map.is_empty());\n        map.check();\n    }\n\n    #[test]\n    fn height_0_keeping_half() {\n        let mut map: BTreeMap<_, _> = (0..16).map(|i| (i, i)).collect();\n        assert_eq!(map.drain_filter(|i, _| *i % 2 == 0).count(), 8);\n        assert_eq!(map.len(), 8);\n        map.check();\n    }\n\n    #[test]\n    fn height_1_removing_all() {\n        let pairs = (0..MIN_INSERTS_HEIGHT_1).map(|i| (i, i));\n        let mut map: BTreeMap<_, _> = pairs.collect();\n        map.drain_filter(|_, _| true);\n        assert!(map.is_empty());\n        map.check();\n    }\n\n    #[test]\n    fn height_1_removing_one() {\n        let pairs = (0..MIN_INSERTS_HEIGHT_1).map(|i| (i, i));\n        for doomed in 0..MIN_INSERTS_HEIGHT_1 {\n            let mut map: BTreeMap<_, _> = pairs.clone().collect();\n            map.drain_filter(|i, _| *i == doomed);\n            assert_eq!(map.len(), MIN_INSERTS_HEIGHT_1 - 1);\n            map.check();\n        }\n    }\n\n    #[test]\n    fn height_1_keeping_one() {\n        let pairs = (0..MIN_INSERTS_HEIGHT_1).map(|i| (i, i));\n        for sacred in 0..MIN_INSERTS_HEIGHT_1 {\n            let mut map: BTreeMap<_, _> = pairs.clone().collect();\n            map.drain_filter(|i, _| *i != sacred);\n            assert!(map.keys().copied().eq(sacred..=sacred));\n            map.check();\n        }\n    }\n\n    #[test]\n    fn height_2_removing_one() {\n        let pairs = (0..MIN_INSERTS_HEIGHT_2).map(|i| (i, i));\n        for doomed in (0..MIN_INSERTS_HEIGHT_2).step_by(12) {\n            let mut map: BTreeMap<_, _> = pairs.clone().collect();\n            map.drain_filter(|i, _| *i == doomed);\n            assert_eq!(map.len(), MIN_INSERTS_HEIGHT_2 - 1);\n            map.check();\n        }\n    }\n\n    #[test]\n    fn height_2_keeping_one() {\n        let pairs = (0..MIN_INSERTS_HEIGHT_2).map(|i| (i, i));\n        for sacred in (0..MIN_INSERTS_HEIGHT_2).step_by(12) {\n            let mut map: BTreeMap<_, _> = pairs.clone().collect();\n            map.drain_filter(|i, _| *i != sacred);\n            assert!(map.keys().copied().eq(sacred..=sacred));\n            map.check();\n        }\n    }\n\n    #[test]\n    fn height_2_removing_all() {\n        let pairs = (0..MIN_INSERTS_HEIGHT_2).map(|i| (i, i));\n        let mut map: BTreeMap<_, _> = pairs.collect();\n        map.drain_filter(|_, _| true);\n        assert!(map.is_empty());\n        map.check();\n    }\n\n    #[test]\n    fn drop_panic_leak() {\n        let a = CrashTestDummy::new(0);\n        let b = CrashTestDummy::new(1);\n        let c = CrashTestDummy::new(2);\n        let mut map = BTreeMap::new();\n        map.insert(a.spawn(Panic::Never), ());\n        map.insert(b.spawn(Panic::InDrop), ());\n        map.insert(c.spawn(Panic::Never), ());\n\n        catch_unwind(move || drop(map.drain_filter(|dummy, _| dummy.query(true)))).unwrap_err();\n\n        assert_eq!(a.queried(), 1);\n        assert_eq!(b.queried(), 1);\n        assert_eq!(c.queried(), 0);\n        assert_eq!(a.dropped(), 1);\n        assert_eq!(b.dropped(), 1);\n        assert_eq!(c.dropped(), 1);\n    }\n\n    #[test]\n    fn pred_panic_leak() {\n        let a = CrashTestDummy::new(0);\n        let b = CrashTestDummy::new(1);\n        let c = CrashTestDummy::new(2);\n        let mut map = BTreeMap::new();\n        map.insert(a.spawn(Panic::Never), ());\n        map.insert(b.spawn(Panic::InQuery), ());\n        map.insert(c.spawn(Panic::InQuery), ());\n\n        catch_unwind(AssertUnwindSafe(|| drop(map.drain_filter(|dummy, _| dummy.query(true)))))\n            .unwrap_err();\n\n        assert_eq!(a.queried(), 1);\n        assert_eq!(b.queried(), 1);\n        assert_eq!(c.queried(), 0);\n        assert_eq!(a.dropped(), 1);\n        assert_eq!(b.dropped(), 0);\n        assert_eq!(c.dropped(), 0);\n        assert_eq!(map.len(), 2);\n        assert_eq!(map.first_entry().unwrap().key().id(), 1);\n        assert_eq!(map.last_entry().unwrap().key().id(), 2);\n        map.check();\n    }\n\n    // Same as above, but attempt to use the iterator again after the panic in the predicate\n    #[test]\n    fn pred_panic_reuse() {\n        let a = CrashTestDummy::new(0);\n        let b = CrashTestDummy::new(1);\n        let c = CrashTestDummy::new(2);\n        let mut map = BTreeMap::new();\n        map.insert(a.spawn(Panic::Never), ());\n        map.insert(b.spawn(Panic::InQuery), ());\n        map.insert(c.spawn(Panic::InQuery), ());\n\n        {\n            let mut it = map.drain_filter(|dummy, _| dummy.query(true));\n            catch_unwind(AssertUnwindSafe(|| while it.next().is_some() {})).unwrap_err();\n            // Iterator behaviour after a panic is explicitly unspecified,\n            // so this is just the current implementation:\n            let result = catch_unwind(AssertUnwindSafe(|| it.next()));\n            assert!(matches!(result, Ok(None)));\n        }\n\n        assert_eq!(a.queried(), 1);\n        assert_eq!(b.queried(), 1);\n        assert_eq!(c.queried(), 0);\n        assert_eq!(a.dropped(), 1);\n        assert_eq!(b.dropped(), 0);\n        assert_eq!(c.dropped(), 0);\n        assert_eq!(map.len(), 2);\n        assert_eq!(map.first_entry().unwrap().key().id(), 1);\n        assert_eq!(map.last_entry().unwrap().key().id(), 2);\n        map.check();\n    }\n}\n\n#[test]\nfn test_borrow() {\n    // make sure these compile -- using the Borrow trait\n    {\n        let mut map = BTreeMap::new();\n        map.insert(\"0\".to_string(), 1);\n        assert_eq!(map[\"0\"], 1);\n    }\n\n    {\n        let mut map = BTreeMap::new();\n        map.insert(Box::new(0), 1);\n        assert_eq!(map[&0], 1);\n    }\n\n    {\n        let mut map = BTreeMap::new();\n        map.insert(Box::new([0, 1]) as Box<[i32]>, 1);\n        assert_eq!(map[&[0, 1][..]], 1);\n    }\n\n    {\n        let mut map = BTreeMap::new();\n        map.insert(Rc::new(0), 1);\n        assert_eq!(map[&0], 1);\n    }\n\n    #[allow(dead_code)]\n    fn get<T: Ord>(v: &BTreeMap<Box<T>, ()>, t: &T) {\n        v.get(t);\n    }\n\n    #[allow(dead_code)]\n    fn get_mut<T: Ord>(v: &mut BTreeMap<Box<T>, ()>, t: &T) {\n        v.get_mut(t);\n    }\n\n    #[allow(dead_code)]\n    fn get_key_value<T: Ord>(v: &BTreeMap<Box<T>, ()>, t: &T) {\n        v.get_key_value(t);\n    }\n\n    #[allow(dead_code)]\n    fn contains_key<T: Ord>(v: &BTreeMap<Box<T>, ()>, t: &T) {\n        v.contains_key(t);\n    }\n\n    #[allow(dead_code)]\n    fn range<T: Ord>(v: &BTreeMap<Box<T>, ()>, t: T) {\n        v.range(t..);\n    }\n\n    #[allow(dead_code)]\n    fn range_mut<T: Ord>(v: &mut BTreeMap<Box<T>, ()>, t: T) {\n        v.range_mut(t..);\n    }\n\n    #[allow(dead_code)]\n    fn remove<T: Ord>(v: &mut BTreeMap<Box<T>, ()>, t: &T) {\n        v.remove(t);\n    }\n\n    #[allow(dead_code)]\n    fn remove_entry<T: Ord>(v: &mut BTreeMap<Box<T>, ()>, t: &T) {\n        v.remove_entry(t);\n    }\n\n    #[allow(dead_code)]\n    fn split_off<T: Ord>(v: &mut BTreeMap<Box<T>, ()>, t: &T) {\n        v.split_off(t);\n    }\n}\n\n#[test]\nfn test_entry() {\n    let xs = [(1, 10), (2, 20), (3, 30), (4, 40), (5, 50), (6, 60)];\n\n    let mut map: BTreeMap<_, _> = xs.iter().cloned().collect();\n\n    // Existing key (insert)\n    match map.entry(1) {\n        Vacant(_) => unreachable!(),\n        Occupied(mut view) => {\n            assert_eq!(view.get(), &10);\n            assert_eq!(view.insert(100), 10);\n        }\n    }\n    assert_eq!(map.get(&1).unwrap(), &100);\n    assert_eq!(map.len(), 6);\n\n    // Existing key (update)\n    match map.entry(2) {\n        Vacant(_) => unreachable!(),\n        Occupied(mut view) => {\n            let v = view.get_mut();\n            *v *= 10;\n        }\n    }\n    assert_eq!(map.get(&2).unwrap(), &200);\n    assert_eq!(map.len(), 6);\n    map.check();\n\n    // Existing key (take)\n    match map.entry(3) {\n        Vacant(_) => unreachable!(),\n        Occupied(view) => {\n            assert_eq!(view.remove(), 30);\n        }\n    }\n    assert_eq!(map.get(&3), None);\n    assert_eq!(map.len(), 5);\n    map.check();\n\n    // Inexistent key (insert)\n    match map.entry(10) {\n        Occupied(_) => unreachable!(),\n        Vacant(view) => {\n            assert_eq!(*view.insert(1000), 1000);\n        }\n    }\n    assert_eq!(map.get(&10).unwrap(), &1000);\n    assert_eq!(map.len(), 6);\n    map.check();\n}\n\n#[test]\nfn test_extend_ref() {\n    let mut a = BTreeMap::new();\n    a.insert(1, \"one\");\n    let mut b = BTreeMap::new();\n    b.insert(2, \"two\");\n    b.insert(3, \"three\");\n\n    a.extend(&b);\n\n    assert_eq!(a.len(), 3);\n    assert_eq!(a[&1], \"one\");\n    assert_eq!(a[&2], \"two\");\n    assert_eq!(a[&3], \"three\");\n    a.check();\n}\n\n#[test]\nfn test_zst() {\n    let mut m = BTreeMap::new();\n    assert_eq!(m.len(), 0);\n\n    assert_eq!(m.insert((), ()), None);\n    assert_eq!(m.len(), 1);\n\n    assert_eq!(m.insert((), ()), Some(()));\n    assert_eq!(m.len(), 1);\n    assert_eq!(m.iter().count(), 1);\n\n    m.clear();\n    assert_eq!(m.len(), 0);\n\n    for _ in 0..100 {\n        m.insert((), ());\n    }\n\n    assert_eq!(m.len(), 1);\n    assert_eq!(m.iter().count(), 1);\n    m.check();\n}\n\n// This test's only purpose is to ensure that zero-sized keys with nonsensical orderings\n// do not cause segfaults when used with zero-sized values. All other map behavior is\n// undefined.\n#[test]\nfn test_bad_zst() {\n    #[derive(Clone, Copy, Debug)]\n    struct Bad;\n\n    impl PartialEq for Bad {\n        fn eq(&self, _: &Self) -> bool {\n            false\n        }\n    }\n\n    impl Eq for Bad {}\n\n    impl PartialOrd for Bad {\n        fn partial_cmp(&self, _: &Self) -> Option<Ordering> {\n            Some(Ordering::Less)\n        }\n    }\n\n    impl Ord for Bad {\n        fn cmp(&self, _: &Self) -> Ordering {\n            Ordering::Less\n        }\n    }\n\n    let mut m = BTreeMap::new();\n\n    for _ in 0..100 {\n        m.insert(Bad, Bad);\n    }\n    m.check();\n}\n\n#[test]\nfn test_clear() {\n    let mut map = BTreeMap::new();\n    for &len in &[MIN_INSERTS_HEIGHT_1, MIN_INSERTS_HEIGHT_2, 0, NODE_CAPACITY] {\n        for i in 0..len {\n            map.insert(i, ());\n        }\n        assert_eq!(map.len(), len);\n        map.clear();\n        map.check();\n        assert!(map.is_empty());\n    }\n}\n\n#[test]\nfn test_clear_drop_panic_leak() {\n    let a = CrashTestDummy::new(0);\n    let b = CrashTestDummy::new(1);\n    let c = CrashTestDummy::new(2);\n\n    let mut map = BTreeMap::new();\n    map.insert(a.spawn(Panic::Never), ());\n    map.insert(b.spawn(Panic::InDrop), ());\n    map.insert(c.spawn(Panic::Never), ());\n\n    catch_unwind(AssertUnwindSafe(|| map.clear())).unwrap_err();\n    assert_eq!(a.dropped(), 1);\n    assert_eq!(b.dropped(), 1);\n    assert_eq!(c.dropped(), 1);\n    assert_eq!(map.len(), 0);\n\n    drop(map);\n    assert_eq!(a.dropped(), 1);\n    assert_eq!(b.dropped(), 1);\n    assert_eq!(c.dropped(), 1);\n}\n\n#[test]\nfn test_clone() {\n    let mut map = BTreeMap::new();\n    let size = MIN_INSERTS_HEIGHT_1;\n    assert_eq!(map.len(), 0);\n\n    for i in 0..size {\n        assert_eq!(map.insert(i, 10 * i), None);\n        assert_eq!(map.len(), i + 1);\n        map.check();\n        assert_eq!(map, map.clone());\n    }\n\n    for i in 0..size {\n        assert_eq!(map.insert(i, 100 * i), Some(10 * i));\n        assert_eq!(map.len(), size);\n        map.check();\n        assert_eq!(map, map.clone());\n    }\n\n    for i in 0..size / 2 {\n        assert_eq!(map.remove(&(i * 2)), Some(i * 200));\n        assert_eq!(map.len(), size - i - 1);\n        map.check();\n        assert_eq!(map, map.clone());\n    }\n\n    for i in 0..size / 2 {\n        assert_eq!(map.remove(&(2 * i)), None);\n        assert_eq!(map.remove(&(2 * i + 1)), Some(i * 200 + 100));\n        assert_eq!(map.len(), size / 2 - i - 1);\n        map.check();\n        assert_eq!(map, map.clone());\n    }\n\n    // Test a tree with 2 semi-full levels and a tree with 3 levels.\n    map = (1..MIN_INSERTS_HEIGHT_2).map(|i| (i, i)).collect();\n    assert_eq!(map.len(), MIN_INSERTS_HEIGHT_2 - 1);\n    assert_eq!(map, map.clone());\n    map.insert(0, 0);\n    assert_eq!(map.len(), MIN_INSERTS_HEIGHT_2);\n    assert_eq!(map, map.clone());\n    map.check();\n}\n\n#[test]\nfn test_clone_panic_leak() {\n    let a = CrashTestDummy::new(0);\n    let b = CrashTestDummy::new(1);\n    let c = CrashTestDummy::new(2);\n\n    let mut map = BTreeMap::new();\n    map.insert(a.spawn(Panic::Never), ());\n    map.insert(b.spawn(Panic::InClone), ());\n    map.insert(c.spawn(Panic::Never), ());\n\n    catch_unwind(|| map.clone()).unwrap_err();\n    assert_eq!(a.cloned(), 1);\n    assert_eq!(b.cloned(), 1);\n    assert_eq!(c.cloned(), 0);\n    assert_eq!(a.dropped(), 1);\n    assert_eq!(b.dropped(), 0);\n    assert_eq!(c.dropped(), 0);\n    assert_eq!(map.len(), 3);\n\n    drop(map);\n    assert_eq!(a.cloned(), 1);\n    assert_eq!(b.cloned(), 1);\n    assert_eq!(c.cloned(), 0);\n    assert_eq!(a.dropped(), 2);\n    assert_eq!(b.dropped(), 1);\n    assert_eq!(c.dropped(), 1);\n}\n\n#[test]\nfn test_clone_from() {\n    let mut map1 = BTreeMap::new();\n    let max_size = MIN_INSERTS_HEIGHT_1;\n\n    // Range to max_size inclusive, because i is the size of map1 being tested.\n    for i in 0..=max_size {\n        let mut map2 = BTreeMap::new();\n        for j in 0..i {\n            let mut map1_copy = map2.clone();\n            map1_copy.clone_from(&map1); // small cloned from large\n            assert_eq!(map1_copy, map1);\n            let mut map2_copy = map1.clone();\n            map2_copy.clone_from(&map2); // large cloned from small\n            assert_eq!(map2_copy, map2);\n            map2.insert(100 * j + 1, 2 * j + 1);\n        }\n        map2.clone_from(&map1); // same length\n        map2.check();\n        assert_eq!(map2, map1);\n        map1.insert(i, 10 * i);\n        map1.check();\n    }\n}\n\n#[allow(dead_code)]\nfn test_variance() {\n    fn map_key<'new>(v: BTreeMap<&'static str, ()>) -> BTreeMap<&'new str, ()> {\n        v\n    }\n    fn map_val<'new>(v: BTreeMap<(), &'static str>) -> BTreeMap<(), &'new str> {\n        v\n    }\n\n    fn iter_key<'a, 'new>(v: Iter<'a, &'static str, ()>) -> Iter<'a, &'new str, ()> {\n        v\n    }\n    fn iter_val<'a, 'new>(v: Iter<'a, (), &'static str>) -> Iter<'a, (), &'new str> {\n        v\n    }\n\n    fn into_iter_key<'new>(v: IntoIter<&'static str, ()>) -> IntoIter<&'new str, ()> {\n        v\n    }\n    fn into_iter_val<'new>(v: IntoIter<(), &'static str>) -> IntoIter<(), &'new str> {\n        v\n    }\n\n    fn into_keys_key<'new>(v: IntoKeys<&'static str, ()>) -> IntoKeys<&'new str, ()> {\n        v\n    }\n    fn into_keys_val<'new>(v: IntoKeys<(), &'static str>) -> IntoKeys<(), &'new str> {\n        v\n    }\n\n    fn into_values_key<'new>(v: IntoValues<&'static str, ()>) -> IntoValues<&'new str, ()> {\n        v\n    }\n    fn into_values_val<'new>(v: IntoValues<(), &'static str>) -> IntoValues<(), &'new str> {\n        v\n    }\n\n    fn range_key<'a, 'new>(v: Range<'a, &'static str, ()>) -> Range<'a, &'new str, ()> {\n        v\n    }\n    fn range_val<'a, 'new>(v: Range<'a, (), &'static str>) -> Range<'a, (), &'new str> {\n        v\n    }\n\n    fn keys_key<'a, 'new>(v: Keys<'a, &'static str, ()>) -> Keys<'a, &'new str, ()> {\n        v\n    }\n    fn keys_val<'a, 'new>(v: Keys<'a, (), &'static str>) -> Keys<'a, (), &'new str> {\n        v\n    }\n\n    fn values_key<'a, 'new>(v: Values<'a, &'static str, ()>) -> Values<'a, &'new str, ()> {\n        v\n    }\n    fn values_val<'a, 'new>(v: Values<'a, (), &'static str>) -> Values<'a, (), &'new str> {\n        v\n    }\n}\n\n#[allow(dead_code)]\nfn test_sync() {\n    fn map<T: Sync>(v: &BTreeMap<T, T>) -> impl Sync + '_ {\n        v\n    }\n\n    fn into_iter<T: Sync>(v: BTreeMap<T, T>) -> impl Sync {\n        v.into_iter()\n    }\n\n    fn into_keys<T: Sync + Ord>(v: BTreeMap<T, T>) -> impl Sync {\n        v.into_keys()\n    }\n\n    fn into_values<T: Sync + Ord>(v: BTreeMap<T, T>) -> impl Sync {\n        v.into_values()\n    }\n\n    fn drain_filter<T: Sync + Ord>(v: &mut BTreeMap<T, T>) -> impl Sync + '_ {\n        v.drain_filter(|_, _| false)\n    }\n\n    fn iter<T: Sync>(v: &BTreeMap<T, T>) -> impl Sync + '_ {\n        v.iter()\n    }\n\n    fn iter_mut<T: Sync>(v: &mut BTreeMap<T, T>) -> impl Sync + '_ {\n        v.iter_mut()\n    }\n\n    fn keys<T: Sync>(v: &BTreeMap<T, T>) -> impl Sync + '_ {\n        v.keys()\n    }\n\n    fn values<T: Sync>(v: &BTreeMap<T, T>) -> impl Sync + '_ {\n        v.values()\n    }\n\n    fn values_mut<T: Sync>(v: &mut BTreeMap<T, T>) -> impl Sync + '_ {\n        v.values_mut()\n    }\n\n    fn range<T: Sync + Ord>(v: &BTreeMap<T, T>) -> impl Sync + '_ {\n        v.range(..)\n    }\n\n    fn range_mut<T: Sync + Ord>(v: &mut BTreeMap<T, T>) -> impl Sync + '_ {\n        v.range_mut(..)\n    }\n\n    fn entry<T: Sync + Ord + Default>(v: &mut BTreeMap<T, T>) -> impl Sync + '_ {\n        v.entry(Default::default())\n    }\n\n    fn occupied_entry<T: Sync + Ord + Default>(v: &mut BTreeMap<T, T>) -> impl Sync + '_ {\n        match v.entry(Default::default()) {\n            Occupied(entry) => entry,\n            _ => unreachable!(),\n        }\n    }\n\n    fn vacant_entry<T: Sync + Ord + Default>(v: &mut BTreeMap<T, T>) -> impl Sync + '_ {\n        match v.entry(Default::default()) {\n            Vacant(entry) => entry,\n            _ => unreachable!(),\n        }\n    }\n}\n\n#[allow(dead_code)]\nfn test_send() {\n    fn map<T: Send>(v: BTreeMap<T, T>) -> impl Send {\n        v\n    }\n\n    fn into_iter<T: Send>(v: BTreeMap<T, T>) -> impl Send {\n        v.into_iter()\n    }\n\n    fn into_keys<T: Send + Ord>(v: BTreeMap<T, T>) -> impl Send {\n        v.into_keys()\n    }\n\n    fn into_values<T: Send + Ord>(v: BTreeMap<T, T>) -> impl Send {\n        v.into_values()\n    }\n\n    fn drain_filter<T: Send + Ord>(v: &mut BTreeMap<T, T>) -> impl Send + '_ {\n        v.drain_filter(|_, _| false)\n    }\n\n    fn iter<T: Send + Sync>(v: &BTreeMap<T, T>) -> impl Send + '_ {\n        v.iter()\n    }\n\n    fn iter_mut<T: Send>(v: &mut BTreeMap<T, T>) -> impl Send + '_ {\n        v.iter_mut()\n    }\n\n    fn keys<T: Send + Sync>(v: &BTreeMap<T, T>) -> impl Send + '_ {\n        v.keys()\n    }\n\n    fn values<T: Send + Sync>(v: &BTreeMap<T, T>) -> impl Send + '_ {\n        v.values()\n    }\n\n    fn values_mut<T: Send>(v: &mut BTreeMap<T, T>) -> impl Send + '_ {\n        v.values_mut()\n    }\n\n    fn range<T: Send + Sync + Ord>(v: &BTreeMap<T, T>) -> impl Send + '_ {\n        v.range(..)\n    }\n\n    fn range_mut<T: Send + Ord>(v: &mut BTreeMap<T, T>) -> impl Send + '_ {\n        v.range_mut(..)\n    }\n\n    fn entry<T: Send + Ord + Default>(v: &mut BTreeMap<T, T>) -> impl Send + '_ {\n        v.entry(Default::default())\n    }\n\n    fn occupied_entry<T: Send + Ord + Default>(v: &mut BTreeMap<T, T>) -> impl Send + '_ {\n        match v.entry(Default::default()) {\n            Occupied(entry) => entry,\n            _ => unreachable!(),\n        }\n    }\n\n    fn vacant_entry<T: Send + Ord + Default>(v: &mut BTreeMap<T, T>) -> impl Send + '_ {\n        match v.entry(Default::default()) {\n            Vacant(entry) => entry,\n            _ => unreachable!(),\n        }\n    }\n}\n\n#[allow(dead_code)]\nfn test_ord_absence() {\n    fn map<K>(mut map: BTreeMap<K, ()>) {\n        map.is_empty();\n        map.len();\n        map.clear();\n        map.iter();\n        map.iter_mut();\n        map.keys();\n        map.values();\n        map.values_mut();\n        if true {\n            map.into_values();\n        } else if true {\n            map.into_iter();\n        } else {\n            map.into_keys();\n        }\n    }\n\n    fn map_debug<K: Debug>(mut map: BTreeMap<K, ()>) {\n        format!(\"{:?}\", map);\n        format!(\"{:?}\", map.iter());\n        format!(\"{:?}\", map.iter_mut());\n        format!(\"{:?}\", map.keys());\n        format!(\"{:?}\", map.values());\n        format!(\"{:?}\", map.values_mut());\n        if true {\n            format!(\"{:?}\", map.into_iter());\n        } else if true {\n            format!(\"{:?}\", map.into_keys());\n        } else {\n            format!(\"{:?}\", map.into_values());\n        }\n    }\n\n    fn map_clone<K: Clone>(mut map: BTreeMap<K, ()>) {\n        map.clone_from(&map.clone());\n    }\n}\n\n#[allow(dead_code)]\nfn test_const() {\n    const MAP: &'static BTreeMap<(), ()> = &BTreeMap::new();\n    const LEN: usize = MAP.len();\n    const IS_EMPTY: bool = MAP.is_empty();\n}\n\n#[test]\nfn test_occupied_entry_key() {\n    let mut a = BTreeMap::new();\n    let key = \"hello there\";\n    let value = \"value goes here\";\n    assert!(a.is_empty());\n    a.insert(key, value);\n    assert_eq!(a.len(), 1);\n    assert_eq!(a[key], value);\n\n    match a.entry(key) {\n        Vacant(_) => panic!(),\n        Occupied(e) => assert_eq!(key, *e.key()),\n    }\n    assert_eq!(a.len(), 1);\n    assert_eq!(a[key], value);\n    a.check();\n}\n\n#[test]\nfn test_vacant_entry_key() {\n    let mut a = BTreeMap::new();\n    let key = \"hello there\";\n    let value = \"value goes here\";\n\n    assert!(a.is_empty());\n    match a.entry(key) {\n        Occupied(_) => panic!(),\n        Vacant(e) => {\n            assert_eq!(key, *e.key());\n            e.insert(value);\n        }\n    }\n    assert_eq!(a.len(), 1);\n    assert_eq!(a[key], value);\n    a.check();\n}\n\n#[test]\nfn test_first_last_entry() {\n    let mut a = BTreeMap::new();\n    assert!(a.first_entry().is_none());\n    assert!(a.last_entry().is_none());\n    a.insert(1, 42);\n    assert_eq!(a.first_entry().unwrap().key(), &1);\n    assert_eq!(a.last_entry().unwrap().key(), &1);\n    a.insert(2, 24);\n    assert_eq!(a.first_entry().unwrap().key(), &1);\n    assert_eq!(a.last_entry().unwrap().key(), &2);\n    a.insert(0, 6);\n    assert_eq!(a.first_entry().unwrap().key(), &0);\n    assert_eq!(a.last_entry().unwrap().key(), &2);\n    let (k1, v1) = a.first_entry().unwrap().remove_entry();\n    assert_eq!(k1, 0);\n    assert_eq!(v1, 6);\n    let (k2, v2) = a.last_entry().unwrap().remove_entry();\n    assert_eq!(k2, 2);\n    assert_eq!(v2, 24);\n    assert_eq!(a.first_entry().unwrap().key(), &1);\n    assert_eq!(a.last_entry().unwrap().key(), &1);\n    a.check();\n}\n\n#[test]\nfn test_insert_into_full_height_0() {\n    let size = NODE_CAPACITY;\n    for pos in 0..=size {\n        let mut map: BTreeMap<_, _> = (0..size).map(|i| (i * 2 + 1, ())).collect();\n        assert!(map.insert(pos * 2, ()).is_none());\n        map.check();\n    }\n}\n\n#[test]\nfn test_insert_into_full_height_1() {\n    let size = NODE_CAPACITY + 1 + NODE_CAPACITY;\n    for pos in 0..=size {\n        let mut map: BTreeMap<_, _> = (0..size).map(|i| (i * 2 + 1, ())).collect();\n        map.compact();\n        let root_node = map.root.as_ref().unwrap().reborrow();\n        assert_eq!(root_node.len(), 1);\n        assert_eq!(root_node.first_leaf_edge().into_node().len(), NODE_CAPACITY);\n        assert_eq!(root_node.last_leaf_edge().into_node().len(), NODE_CAPACITY);\n\n        assert!(map.insert(pos * 2, ()).is_none());\n        map.check();\n    }\n}\n\nmacro_rules! create_append_test {\n    ($name:ident, $len:expr) => {\n        #[test]\n        fn $name() {\n            let mut a = BTreeMap::new();\n            for i in 0..8 {\n                a.insert(i, i);\n            }\n\n            let mut b = BTreeMap::new();\n            for i in 5..$len {\n                b.insert(i, 2 * i);\n            }\n\n            a.append(&mut b);\n\n            assert_eq!(a.len(), $len);\n            assert_eq!(b.len(), 0);\n\n            for i in 0..$len {\n                if i < 5 {\n                    assert_eq!(a[&i], i);\n                } else {\n                    assert_eq!(a[&i], 2 * i);\n                }\n            }\n\n            a.check();\n            assert_eq!(a.remove(&($len - 1)), Some(2 * ($len - 1)));\n            assert_eq!(a.insert($len - 1, 20), None);\n            a.check();\n        }\n    };\n}\n\n// These are mostly for testing the algorithm that \"fixes\" the right edge after insertion.\n// Single node.\ncreate_append_test!(test_append_9, 9);\n// Two leafs that don't need fixing.\ncreate_append_test!(test_append_17, 17);\n// Two leafs where the second one ends up underfull and needs stealing at the end.\ncreate_append_test!(test_append_14, 14);\n// Two leafs where the second one ends up empty because the insertion finished at the root.\ncreate_append_test!(test_append_12, 12);\n// Three levels; insertion finished at the root.\ncreate_append_test!(test_append_144, 144);\n// Three levels; insertion finished at leaf while there is an empty node on the second level.\ncreate_append_test!(test_append_145, 145);\n// Tests for several randomly chosen sizes.\ncreate_append_test!(test_append_170, 170);\ncreate_append_test!(test_append_181, 181);\n#[cfg(not(miri))] // Miri is too slow\ncreate_append_test!(test_append_239, 239);\n#[cfg(not(miri))] // Miri is too slow\ncreate_append_test!(test_append_1700, 1700);\n\n#[test]\nfn test_append_drop_leak() {\n    let a = CrashTestDummy::new(0);\n    let b = CrashTestDummy::new(1);\n    let c = CrashTestDummy::new(2);\n    let mut left = BTreeMap::new();\n    let mut right = BTreeMap::new();\n    left.insert(a.spawn(Panic::Never), ());\n    left.insert(b.spawn(Panic::InDrop), ()); // first duplicate key, dropped during append\n    left.insert(c.spawn(Panic::Never), ());\n    right.insert(b.spawn(Panic::Never), ());\n    right.insert(c.spawn(Panic::Never), ());\n\n    catch_unwind(move || left.append(&mut right)).unwrap_err();\n    assert_eq!(a.dropped(), 1);\n    assert_eq!(b.dropped(), 1); // should be 2 were it not for Rust issue #47949\n    assert_eq!(c.dropped(), 2);\n}\n\n#[test]\nfn test_append_ord_chaos() {\n    let mut map1 = BTreeMap::new();\n    map1.insert(Cyclic3::A, ());\n    map1.insert(Cyclic3::B, ());\n    let mut map2 = BTreeMap::new();\n    map2.insert(Cyclic3::A, ());\n    map2.insert(Cyclic3::B, ());\n    map2.insert(Cyclic3::C, ()); // lands first, before A\n    map2.insert(Cyclic3::B, ()); // lands first, before C\n    map1.check();\n    map2.check(); // keys are not unique but still strictly ascending\n    assert_eq!(map1.len(), 2);\n    assert_eq!(map2.len(), 4);\n    map1.append(&mut map2);\n    assert_eq!(map1.len(), 5);\n    assert_eq!(map2.len(), 0);\n    map1.check();\n    map2.check();\n}\n\nfn rand_data(len: usize) -> Vec<(u32, u32)> {\n    let mut rng = DeterministicRng::new();\n    Vec::from_iter((0..len).map(|_| (rng.next(), rng.next())))\n}\n\n#[test]\nfn test_split_off_empty_right() {\n    let mut data = rand_data(173);\n\n    let mut map = BTreeMap::from_iter(data.clone());\n    let right = map.split_off(&(data.iter().max().unwrap().0 + 1));\n    map.check();\n    right.check();\n\n    data.sort();\n    assert!(map.into_iter().eq(data));\n    assert!(right.into_iter().eq(None));\n}\n\n#[test]\nfn test_split_off_empty_left() {\n    let mut data = rand_data(314);\n\n    let mut map = BTreeMap::from_iter(data.clone());\n    let right = map.split_off(&data.iter().min().unwrap().0);\n    map.check();\n    right.check();\n\n    data.sort();\n    assert!(map.into_iter().eq(None));\n    assert!(right.into_iter().eq(data));\n}\n\n// In a tree with 3 levels, if all but a part of the first leaf node is split off,\n// make sure fix_top eliminates both top levels.\n#[test]\nfn test_split_off_tiny_left_height_2() {\n    let pairs = (0..MIN_INSERTS_HEIGHT_2).map(|i| (i, i));\n    let mut left: BTreeMap<_, _> = pairs.clone().collect();\n    let right = left.split_off(&1);\n    left.check();\n    right.check();\n    assert_eq!(left.len(), 1);\n    assert_eq!(right.len(), MIN_INSERTS_HEIGHT_2 - 1);\n    assert_eq!(*left.first_key_value().unwrap().0, 0);\n    assert_eq!(*right.first_key_value().unwrap().0, 1);\n}\n\n// In a tree with 3 levels, if only part of the last leaf node is split off,\n// make sure fix_top eliminates both top levels.\n#[test]\nfn test_split_off_tiny_right_height_2() {\n    let pairs = (0..MIN_INSERTS_HEIGHT_2).map(|i| (i, i));\n    let last = MIN_INSERTS_HEIGHT_2 - 1;\n    let mut left: BTreeMap<_, _> = pairs.clone().collect();\n    assert_eq!(*left.last_key_value().unwrap().0, last);\n    let right = left.split_off(&last);\n    left.check();\n    right.check();\n    assert_eq!(left.len(), MIN_INSERTS_HEIGHT_2 - 1);\n    assert_eq!(right.len(), 1);\n    assert_eq!(*left.last_key_value().unwrap().0, last - 1);\n    assert_eq!(*right.last_key_value().unwrap().0, last);\n}\n\n#[test]\nfn test_split_off_halfway() {\n    let mut rng = DeterministicRng::new();\n    for &len in &[NODE_CAPACITY, 25, 50, 75, 100] {\n        let mut data = Vec::from_iter((0..len).map(|_| (rng.next(), ())));\n        // Insertion in non-ascending order creates some variation in node length.\n        let mut map = BTreeMap::from_iter(data.iter().copied());\n        data.sort();\n        let small_keys = data.iter().take(len / 2).map(|kv| kv.0);\n        let large_keys = data.iter().skip(len / 2).map(|kv| kv.0);\n        let split_key = large_keys.clone().next().unwrap();\n        let right = map.split_off(&split_key);\n        map.check();\n        right.check();\n        assert!(map.keys().copied().eq(small_keys));\n        assert!(right.keys().copied().eq(large_keys));\n    }\n}\n\n#[test]\nfn test_split_off_large_random_sorted() {\n    // Miri is too slow\n    let mut data = if cfg!(miri) { rand_data(529) } else { rand_data(1529) };\n    // special case with maximum height.\n    data.sort();\n\n    let mut map = BTreeMap::from_iter(data.clone());\n    let key = data[data.len() / 2].0;\n    let right = map.split_off(&key);\n    map.check();\n    right.check();\n\n    assert!(map.into_iter().eq(data.clone().into_iter().filter(|x| x.0 < key)));\n    assert!(right.into_iter().eq(data.into_iter().filter(|x| x.0 >= key)));\n}\n\n#[test]\nfn test_into_iter_drop_leak_height_0() {\n    let a = CrashTestDummy::new(0);\n    let b = CrashTestDummy::new(1);\n    let c = CrashTestDummy::new(2);\n    let d = CrashTestDummy::new(3);\n    let e = CrashTestDummy::new(4);\n    let mut map = BTreeMap::new();\n    map.insert(\"a\", a.spawn(Panic::Never));\n    map.insert(\"b\", b.spawn(Panic::Never));\n    map.insert(\"c\", c.spawn(Panic::Never));\n    map.insert(\"d\", d.spawn(Panic::InDrop));\n    map.insert(\"e\", e.spawn(Panic::Never));\n\n    catch_unwind(move || drop(map.into_iter())).unwrap_err();\n\n    assert_eq!(a.dropped(), 1);\n    assert_eq!(b.dropped(), 1);\n    assert_eq!(c.dropped(), 1);\n    assert_eq!(d.dropped(), 1);\n    assert_eq!(e.dropped(), 1);\n}\n\n#[test]\nfn test_into_iter_drop_leak_height_1() {\n    let size = MIN_INSERTS_HEIGHT_1;\n    for panic_point in vec![0, 1, size - 2, size - 1] {\n        let dummies: Vec<_> = (0..size).map(|i| CrashTestDummy::new(i)).collect();\n        let map: BTreeMap<_, _> = (0..size)\n            .map(|i| {\n                let panic = if i == panic_point { Panic::InDrop } else { Panic::Never };\n                (dummies[i].spawn(Panic::Never), dummies[i].spawn(panic))\n            })\n            .collect();\n        catch_unwind(move || drop(map.into_iter())).unwrap_err();\n        for i in 0..size {\n            assert_eq!(dummies[i].dropped(), 2);\n        }\n    }\n}\n\n#[test]\nfn test_into_keys() {\n    let vec = vec![(1, 'a'), (2, 'b'), (3, 'c')];\n    let map: BTreeMap<_, _> = vec.into_iter().collect();\n    let keys: Vec<_> = map.into_keys().collect();\n\n    assert_eq!(keys.len(), 3);\n    assert!(keys.contains(&1));\n    assert!(keys.contains(&2));\n    assert!(keys.contains(&3));\n}\n\n#[test]\nfn test_into_values() {\n    let vec = vec![(1, 'a'), (2, 'b'), (3, 'c')];\n    let map: BTreeMap<_, _> = vec.into_iter().collect();\n    let values: Vec<_> = map.into_values().collect();\n\n    assert_eq!(values.len(), 3);\n    assert!(values.contains(&'a'));\n    assert!(values.contains(&'b'));\n    assert!(values.contains(&'c'));\n}\n\n#[test]\nfn test_insert_remove_intertwined() {\n    let loops = if cfg!(miri) { 100 } else { 1_000_000 };\n    let mut map = BTreeMap::new();\n    let mut i = 1;\n    let offset = 165; // somewhat arbitrarily chosen to cover some code paths\n    for _ in 0..loops {\n        i = (i + offset) & 0xFF;\n        map.insert(i, i);\n        map.remove(&(0xFF - i));\n    }\n    map.check();\n}\n\n#[test]\nfn test_insert_remove_intertwined_ord_chaos() {\n    let loops = if cfg!(miri) { 100 } else { 1_000_000 };\n    let gov = Governor::new();\n    let mut map = BTreeMap::new();\n    let mut i = 1;\n    let offset = 165; // more arbitrarily copied from above\n    for _ in 0..loops {\n        i = (i + offset) & 0xFF;\n        map.insert(Governed(i, &gov), ());\n        map.remove(&Governed(0xFF - i, &gov));\n        gov.flip();\n    }\n    map.check_invariants();\n}\n"],[2048,"//! The alloc Prelude\n//!\n//! The purpose of this module is to alleviate imports of commonly-used\n//! items of the `alloc` crate by adding a glob import to the top of modules:\n//!\n//! ```\n//! # #![allow(unused_imports)]\n//! #![feature(alloc_prelude)]\n//! extern crate alloc;\n//! use alloc::prelude::v1::*;\n//! ```\n\n#![unstable(feature = \"alloc_prelude\", issue = \"58935\")]\n\npub mod v1;\n"],[2049,"//! The first version of the prelude of `alloc` crate.\n//!\n//! See the [module-level documentation](../index.html) for more.\n\n#![unstable(feature = \"alloc_prelude\", issue = \"58935\")]\n\n#[unstable(feature = \"alloc_prelude\", issue = \"58935\")]\npub use crate::borrow::ToOwned;\n#[unstable(feature = \"alloc_prelude\", issue = \"58935\")]\npub use crate::boxed::Box;\n#[unstable(feature = \"alloc_prelude\", issue = \"58935\")]\npub use crate::string::{String, ToString};\n#[unstable(feature = \"alloc_prelude\", issue = \"58935\")]\npub use crate::vec::Vec;\n"],[2050,"/// Creates a [`Vec`] containing the arguments.\n///\n/// `vec!` allows `Vec`s to be defined with the same syntax as array expressions.\n/// There are two forms of this macro:\n///\n/// - Create a [`Vec`] containing a given list of elements:\n///\n/// ```\n/// let v = vec![1, 2, 3];\n/// assert_eq!(v[0], 1);\n/// assert_eq!(v[1], 2);\n/// assert_eq!(v[2], 3);\n/// ```\n///\n/// - Create a [`Vec`] from a given element and size:\n///\n/// ```\n/// let v = vec![1; 3];\n/// assert_eq!(v, [1, 1, 1]);\n/// ```\n///\n/// Note that unlike array expressions this syntax supports all elements\n/// which implement [`Clone`] and the number of elements doesn't have to be\n/// a constant.\n///\n/// This will use `clone` to duplicate an expression, so one should be careful\n/// using this with types having a nonstandard `Clone` implementation. For\n/// example, `vec![Rc::new(1); 5]` will create a vector of five references\n/// to the same boxed integer value, not five references pointing to independently\n/// boxed integers.\n///\n/// Also, note that `vec![expr; 0]` is allowed, and produces an empty vector.\n/// This will still evaluate `expr`, however, and immediately drop the resulting value, so\n/// be mindful of side effects.\n///\n/// [`Vec`]: crate::vec::Vec\n#[cfg(not(test))]\n#[doc(alias = \"alloc\")]\n#[doc(alias = \"malloc\")]\n#[macro_export]\n#[stable(feature = \"rust1\", since = \"1.0.0\")]\n#[allow_internal_unstable(box_syntax, liballoc_internals)]\nmacro_rules! vec {\n    () => (\n        $crate::__rust_force_expr!($crate::vec::Vec::new())\n    );\n    ($elem:expr; $n:expr) => (\n        $crate::__rust_force_expr!($crate::vec::from_elem($elem, $n))\n    );\n    ($($x:expr),+ $(,)?) => (\n        $crate::__rust_force_expr!(<[_]>::into_vec(box [$($x),+]))\n    );\n}\n\n// HACK(japaric): with cfg(test) the inherent `[T]::into_vec` method, which is\n// required for this macro definition, is not available. Instead use the\n// `slice::into_vec`  function which is only available with cfg(test)\n// NB see the slice::hack module in slice.rs for more information\n#[cfg(test)]\nmacro_rules! vec {\n    () => (\n        $crate::vec::Vec::new()\n    );\n    ($elem:expr; $n:expr) => (\n        $crate::vec::from_elem($elem, $n)\n    );\n    ($($x:expr),*) => (\n        $crate::slice::into_vec(box [$($x),*])\n    );\n    ($($x:expr,)*) => (vec![$($x),*])\n}\n\n/// Creates a `String` using interpolation of runtime expressions.\n///\n/// The first argument `format!` receives is a format string. This must be a string\n/// literal. The power of the formatting string is in the `{}`s contained.\n///\n/// Additional parameters passed to `format!` replace the `{}`s within the\n/// formatting string in the order given unless named or positional parameters\n/// are used; see [`std::fmt`] for more information.\n///\n/// A common use for `format!` is concatenation and interpolation of strings.\n/// The same convention is used with [`print!`] and [`write!`] macros,\n/// depending on the intended destination of the string.\n///\n/// To convert a single value to a string, use the [`to_string`] method. This\n/// will use the [`Display`] formatting trait.\n///\n/// [`std::fmt`]: ../std/fmt/index.html\n/// [`print!`]: ../std/macro.print.html\n/// [`write!`]: core::write\n/// [`to_string`]: crate::string::ToString\n/// [`Display`]: core::fmt::Display\n///\n/// # Panics\n///\n/// `format!` panics if a formatting trait implementation returns an error.\n/// This indicates an incorrect implementation\n/// since `fmt::Write for String` never returns an error itself.\n///\n/// # Examples\n///\n/// ```\n/// format!(\"test\");\n/// format!(\"hello {}\", \"world!\");\n/// format!(\"x = {}, y = {y}\", 10, y = 30);\n/// ```\n#[macro_export]\n#[stable(feature = \"rust1\", since = \"1.0.0\")]\n#[cfg_attr(not(test), rustc_diagnostic_item = \"format_macro\")]\nmacro_rules! format {\n    ($($arg:tt)*) => {{\n        let res = $crate::fmt::format($crate::__export::format_args!($($arg)*));\n        res\n    }}\n}\n\n/// Force AST node to an expression to improve diagnostics in pattern position.\n#[doc(hidden)]\n#[macro_export]\n#[unstable(feature = \"liballoc_internals\", issue = \"none\", reason = \"implementation detail\")]\nmacro_rules! __rust_force_expr {\n    ($e:expr) => {\n        $e\n    };\n}\n"],[2051,"#![stable(feature = \"wake_trait\", since = \"1.51.0\")]\n//! Types and Traits for working with asynchronous tasks.\nuse core::mem::ManuallyDrop;\nuse core::task::{RawWaker, RawWakerVTable, Waker};\n\nuse crate::sync::Arc;\n\n/// The implementation of waking a task on an executor.\n///\n/// This trait can be used to create a [`Waker`]. An executor can define an\n/// implementation of this trait, and use that to construct a Waker to pass\n/// to the tasks that are executed on that executor.\n///\n/// This trait is a memory-safe and ergonomic alternative to constructing a\n/// [`RawWaker`]. It supports the common executor design in which the data used\n/// to wake up a task is stored in an [`Arc`]. Some executors (especially\n/// those for embedded systems) cannot use this API, which is why [`RawWaker`]\n/// exists as an alternative for those systems.\n///\n/// [arc]: ../../std/sync/struct.Arc.html\n///\n/// # Examples\n///\n/// A basic `block_on` function that takes a future and runs it to completion on\n/// the current thread.\n///\n/// **Note:** This example trades correctness for simplicity. In order to prevent\n/// deadlocks, production-grade implementations will also need to handle\n/// intermediate calls to `thread::unpark` as well as nested invocations.\n///\n/// ```rust\n/// use std::future::Future;\n/// use std::sync::Arc;\n/// use std::task::{Context, Poll, Wake};\n/// use std::thread::{self, Thread};\n///\n/// /// A waker that wakes up the current thread when called.\n/// struct ThreadWaker(Thread);\n///\n/// impl Wake for ThreadWaker {\n///     fn wake(self: Arc<Self>) {\n///         self.0.unpark();\n///     }\n/// }\n///\n/// /// Run a future to completion on the current thread.\n/// fn block_on<T>(fut: impl Future<Output = T>) -> T {\n///     // Pin the future so it can be polled.\n///     let mut fut = Box::pin(fut);\n///\n///     // Create a new context to be passed to the future.\n///     let t = thread::current();\n///     let waker = Arc::new(ThreadWaker(t)).into();\n///     let mut cx = Context::from_waker(&waker);\n///\n///     // Run the future to completion.\n///     loop {\n///         match fut.as_mut().poll(&mut cx) {\n///             Poll::Ready(res) => return res,\n///             Poll::Pending => thread::park(),\n///         }\n///     }\n/// }\n///\n/// block_on(async {\n///     println!(\"Hi from inside a future!\");\n/// });\n/// ```\n#[stable(feature = \"wake_trait\", since = \"1.51.0\")]\npub trait Wake {\n    /// Wake this task.\n    #[stable(feature = \"wake_trait\", since = \"1.51.0\")]\n    fn wake(self: Arc<Self>);\n\n    /// Wake this task without consuming the waker.\n    ///\n    /// If an executor supports a cheaper way to wake without consuming the\n    /// waker, it should override this method. By default, it clones the\n    /// [`Arc`] and calls [`wake`] on the clone.\n    ///\n    /// [`wake`]: Wake::wake\n    #[stable(feature = \"wake_trait\", since = \"1.51.0\")]\n    fn wake_by_ref(self: &Arc<Self>) {\n        self.clone().wake();\n    }\n}\n\n#[stable(feature = \"wake_trait\", since = \"1.51.0\")]\nimpl<W: Wake + Send + Sync + 'static> From<Arc<W>> for Waker {\n    /// Use a `Wake`-able type as a `Waker`.\n    ///\n    /// No heap allocations or atomic operations are used for this conversion.\n    fn from(waker: Arc<W>) -> Waker {\n        // SAFETY: This is safe because raw_waker safely constructs\n        // a RawWaker from Arc<W>.\n        unsafe { Waker::from_raw(raw_waker(waker)) }\n    }\n}\n\n#[stable(feature = \"wake_trait\", since = \"1.51.0\")]\nimpl<W: Wake + Send + Sync + 'static> From<Arc<W>> for RawWaker {\n    /// Use a `Wake`-able type as a `RawWaker`.\n    ///\n    /// No heap allocations or atomic operations are used for this conversion.\n    fn from(waker: Arc<W>) -> RawWaker {\n        raw_waker(waker)\n    }\n}\n\n// NB: This private function for constructing a RawWaker is used, rather than\n// inlining this into the `From<Arc<W>> for RawWaker` impl, to ensure that\n// the safety of `From<Arc<W>> for Waker` does not depend on the correct\n// trait dispatch - instead both impls call this function directly and\n// explicitly.\n#[inline(always)]\nfn raw_waker<W: Wake + Send + Sync + 'static>(waker: Arc<W>) -> RawWaker {\n    // Increment the reference count of the arc to clone it.\n    unsafe fn clone_waker<W: Wake + Send + Sync + 'static>(waker: *const ()) -> RawWaker {\n        unsafe { Arc::increment_strong_count(waker as *const W) };\n        RawWaker::new(\n            waker as *const (),\n            &RawWakerVTable::new(clone_waker::<W>, wake::<W>, wake_by_ref::<W>, drop_waker::<W>),\n        )\n    }\n\n    // Wake by value, moving the Arc into the Wake::wake function\n    unsafe fn wake<W: Wake + Send + Sync + 'static>(waker: *const ()) {\n        let waker = unsafe { Arc::from_raw(waker as *const W) };\n        <W as Wake>::wake(waker);\n    }\n\n    // Wake by reference, wrap the waker in ManuallyDrop to avoid dropping it\n    unsafe fn wake_by_ref<W: Wake + Send + Sync + 'static>(waker: *const ()) {\n        let waker = unsafe { ManuallyDrop::new(Arc::from_raw(waker as *const W)) };\n        <W as Wake>::wake_by_ref(&waker);\n    }\n\n    // Decrement the reference count of the Arc on drop\n    unsafe fn drop_waker<W: Wake + Send + Sync + 'static>(waker: *const ()) {\n        unsafe { Arc::decrement_strong_count(waker as *const W) };\n    }\n\n    RawWaker::new(\n        Arc::into_raw(waker) as *const (),\n        &RawWakerVTable::new(clone_waker::<W>, wake::<W>, wake_by_ref::<W>, drop_waker::<W>),\n    )\n}\n"],[2052,"use core::mem::ManuallyDrop;\nuse core::ptr::{self};\n\nuse super::{IntoIter, SpecExtend, SpecFromIterNested, Vec};\n\n/// Specialization trait used for Vec::from_iter\n///\n/// ## The delegation graph:\n///\n/// ```text\n/// +-------------+\n/// |FromIterator |\n/// +-+-----------+\n///   |\n///   v\n/// +-+-------------------------------+  +---------------------+\n/// |SpecFromIter                  +---->+SpecFromIterNested   |\n/// |where I:                      |  |  |where I:             |\n/// |  Iterator (default)----------+  |  |  Iterator (default) |\n/// |  vec::IntoIter               |  |  |  TrustedLen         |\n/// |  SourceIterMarker---fallback-+  |  +---------------------+\n/// +---------------------------------+\n/// ```\npub(super) trait SpecFromIter<T, I> {\n    fn from_iter(iter: I) -> Self;\n}\n\nimpl<T, I> SpecFromIter<T, I> for Vec<T>\nwhere\n    I: Iterator<Item = T>,\n{\n    default fn from_iter(iterator: I) -> Self {\n        SpecFromIterNested::from_iter(iterator)\n    }\n}\n\nimpl<T> SpecFromIter<T, IntoIter<T>> for Vec<T> {\n    fn from_iter(iterator: IntoIter<T>) -> Self {\n        // A common case is passing a vector into a function which immediately\n        // re-collects into a vector. We can short circuit this if the IntoIter\n        // has not been advanced at all.\n        // When it has been advanced We can also reuse the memory and move the data to the front.\n        // But we only do so when the resulting Vec wouldn't have more unused capacity\n        // than creating it through the generic FromIterator implementation would. That limitation\n        // is not strictly necessary as Vec's allocation behavior is intentionally unspecified.\n        // But it is a conservative choice.\n        let has_advanced = iterator.buf.as_ptr() as *const _ != iterator.ptr;\n        if !has_advanced || iterator.len() >= iterator.cap / 2 {\n            unsafe {\n                let it = ManuallyDrop::new(iterator);\n                if has_advanced {\n                    ptr::copy(it.ptr, it.buf.as_ptr(), it.len());\n                }\n                return Vec::from_raw_parts(it.buf.as_ptr(), it.len(), it.cap);\n            }\n        }\n\n        let mut vec = Vec::new();\n        // must delegate to spec_extend() since extend() itself delegates\n        // to spec_from for empty Vecs\n        vec.spec_extend(iterator);\n        vec\n    }\n}\n"],[2053,"//! A contiguous growable array type with heap-allocated contents, written\n//! `Vec<T>`.\n//!\n//! Vectors have `O(1)` indexing, amortized `O(1)` push (to the end) and\n//! `O(1)` pop (from the end).\n//!\n//! Vectors ensure they never allocate more than `isize::MAX` bytes.\n//!\n//! # Examples\n//!\n//! You can explicitly create a [`Vec`] with [`Vec::new`]:\n//!\n//! ```\n//! let v: Vec<i32> = Vec::new();\n//! ```\n//!\n//! ...or by using the [`vec!`] macro:\n//!\n//! ```\n//! let v: Vec<i32> = vec![];\n//!\n//! let v = vec![1, 2, 3, 4, 5];\n//!\n//! let v = vec![0; 10]; // ten zeroes\n//! ```\n//!\n//! You can [`push`] values onto the end of a vector (which will grow the vector\n//! as needed):\n//!\n//! ```\n//! let mut v = vec![1, 2];\n//!\n//! v.push(3);\n//! ```\n//!\n//! Popping values works in much the same way:\n//!\n//! ```\n//! let mut v = vec![1, 2];\n//!\n//! let two = v.pop();\n//! ```\n//!\n//! Vectors also support indexing (through the [`Index`] and [`IndexMut`] traits):\n//!\n//! ```\n//! let mut v = vec![1, 2, 3];\n//! let three = v[2];\n//! v[1] = v[1] + 5;\n//! ```\n//!\n//! [`push`]: Vec::push\n\n#![stable(feature = \"rust1\", since = \"1.0.0\")]\n\n#[cfg(not(no_global_oom_handling))]\nuse core::cmp;\nuse core::cmp::Ordering;\nuse core::convert::TryFrom;\nuse core::fmt;\nuse core::hash::{Hash, Hasher};\nuse core::intrinsics::{arith_offset, assume};\nuse core::iter;\n#[cfg(not(no_global_oom_handling))]\nuse core::iter::FromIterator;\nuse core::marker::PhantomData;\nuse core::mem::{self, ManuallyDrop, MaybeUninit};\nuse core::ops::{self, Index, IndexMut, Range, RangeBounds};\nuse core::ptr::{self, NonNull};\nuse core::slice::{self, SliceIndex};\n\nuse crate::alloc::{Allocator, Global};\nuse crate::borrow::{Cow, ToOwned};\nuse crate::boxed::Box;\nuse crate::collections::TryReserveError;\nuse crate::raw_vec::RawVec;\n\n#[unstable(feature = \"drain_filter\", reason = \"recently added\", issue = \"43244\")]\npub use self::drain_filter::DrainFilter;\n\nmod drain_filter;\n\n#[cfg(not(no_global_oom_handling))]\n#[stable(feature = \"vec_splice\", since = \"1.21.0\")]\npub use self::splice::Splice;\n\n#[cfg(not(no_global_oom_handling))]\nmod splice;\n\n#[stable(feature = \"drain\", since = \"1.6.0\")]\npub use self::drain::Drain;\n\nmod drain;\n\n#[cfg(not(no_global_oom_handling))]\nmod cow;\n\n#[cfg(not(no_global_oom_handling))]\npub(crate) use self::into_iter::AsIntoIter;\n#[stable(feature = \"rust1\", since = \"1.0.0\")]\npub use self::into_iter::IntoIter;\n\nmod into_iter;\n\n#[cfg(not(no_global_oom_handling))]\nuse self::is_zero::IsZero;\n\nmod is_zero;\n\n#[cfg(not(no_global_oom_handling))]\nmod source_iter_marker;\n\nmod partial_eq;\n\n#[cfg(not(no_global_oom_handling))]\nuse self::spec_from_elem::SpecFromElem;\n\n#[cfg(not(no_global_oom_handling))]\nmod spec_from_elem;\n\n#[cfg(not(no_global_oom_handling))]\nuse self::set_len_on_drop::SetLenOnDrop;\n\n#[cfg(not(no_global_oom_handling))]\nmod set_len_on_drop;\n\n#[cfg(not(no_global_oom_handling))]\nuse self::in_place_drop::InPlaceDrop;\n\n#[cfg(not(no_global_oom_handling))]\nmod in_place_drop;\n\n#[cfg(not(no_global_oom_handling))]\nuse self::spec_from_iter_nested::SpecFromIterNested;\n\n#[cfg(not(no_global_oom_handling))]\nmod spec_from_iter_nested;\n\n#[cfg(not(no_global_oom_handling))]\nuse self::spec_from_iter::SpecFromIter;\n\n#[cfg(not(no_global_oom_handling))]\nmod spec_from_iter;\n\n#[cfg(not(no_global_oom_handling))]\nuse self::spec_extend::SpecExtend;\n\n#[cfg(not(no_global_oom_handling))]\nmod spec_extend;\n\n/// A contiguous growable array type, written as `Vec<T>` and pronounced 'vector'.\n///\n/// # Examples\n///\n/// ```\n/// let mut vec = Vec::new();\n/// vec.push(1);\n/// vec.push(2);\n///\n/// assert_eq!(vec.len(), 2);\n/// assert_eq!(vec[0], 1);\n///\n/// assert_eq!(vec.pop(), Some(2));\n/// assert_eq!(vec.len(), 1);\n///\n/// vec[0] = 7;\n/// assert_eq!(vec[0], 7);\n///\n/// vec.extend([1, 2, 3].iter().copied());\n///\n/// for x in &vec {\n///     println!(\"{}\", x);\n/// }\n/// assert_eq!(vec, [7, 1, 2, 3]);\n/// ```\n///\n/// The [`vec!`] macro is provided to make initialization more convenient:\n///\n/// ```\n/// let mut vec = vec![1, 2, 3];\n/// vec.push(4);\n/// assert_eq!(vec, [1, 2, 3, 4]);\n/// ```\n///\n/// It can also initialize each element of a `Vec<T>` with a given value.\n/// This may be more efficient than performing allocation and initialization\n/// in separate steps, especially when initializing a vector of zeros:\n///\n/// ```\n/// let vec = vec![0; 5];\n/// assert_eq!(vec, [0, 0, 0, 0, 0]);\n///\n/// // The following is equivalent, but potentially slower:\n/// let mut vec = Vec::with_capacity(5);\n/// vec.resize(5, 0);\n/// assert_eq!(vec, [0, 0, 0, 0, 0]);\n/// ```\n///\n/// For more information, see\n/// [Capacity and Reallocation](#capacity-and-reallocation).\n///\n/// Use a `Vec<T>` as an efficient stack:\n///\n/// ```\n/// let mut stack = Vec::new();\n///\n/// stack.push(1);\n/// stack.push(2);\n/// stack.push(3);\n///\n/// while let Some(top) = stack.pop() {\n///     // Prints 3, 2, 1\n///     println!(\"{}\", top);\n/// }\n/// ```\n///\n/// # Indexing\n///\n/// The `Vec` type allows to access values by index, because it implements the\n/// [`Index`] trait. An example will be more explicit:\n///\n/// ```\n/// let v = vec![0, 2, 4, 6];\n/// println!(\"{}\", v[1]); // it will display '2'\n/// ```\n///\n/// However be careful: if you try to access an index which isn't in the `Vec`,\n/// your software will panic! You cannot do this:\n///\n/// ```should_panic\n/// let v = vec![0, 2, 4, 6];\n/// println!(\"{}\", v[6]); // it will panic!\n/// ```\n///\n/// Use [`get`] and [`get_mut`] if you want to check whether the index is in\n/// the `Vec`.\n///\n/// # Slicing\n///\n/// A `Vec` can be mutable. On the other hand, slices are read-only objects.\n/// To get a [slice][prim@slice], use [`&`]. Example:\n///\n/// ```\n/// fn read_slice(slice: &[usize]) {\n///     // ...\n/// }\n///\n/// let v = vec![0, 1];\n/// read_slice(&v);\n///\n/// // ... and that's all!\n/// // you can also do it like this:\n/// let u: &[usize] = &v;\n/// // or like this:\n/// let u: &[_] = &v;\n/// ```\n///\n/// In Rust, it's more common to pass slices as arguments rather than vectors\n/// when you just want to provide read access. The same goes for [`String`] and\n/// [`&str`].\n///\n/// # Capacity and reallocation\n///\n/// The capacity of a vector is the amount of space allocated for any future\n/// elements that will be added onto the vector. This is not to be confused with\n/// the *length* of a vector, which specifies the number of actual elements\n/// within the vector. If a vector's length exceeds its capacity, its capacity\n/// will automatically be increased, but its elements will have to be\n/// reallocated.\n///\n/// For example, a vector with capacity 10 and length 0 would be an empty vector\n/// with space for 10 more elements. Pushing 10 or fewer elements onto the\n/// vector will not change its capacity or cause reallocation to occur. However,\n/// if the vector's length is increased to 11, it will have to reallocate, which\n/// can be slow. For this reason, it is recommended to use [`Vec::with_capacity`]\n/// whenever possible to specify how big the vector is expected to get.\n///\n/// # Guarantees\n///\n/// Due to its incredibly fundamental nature, `Vec` makes a lot of guarantees\n/// about its design. This ensures that it's as low-overhead as possible in\n/// the general case, and can be correctly manipulated in primitive ways\n/// by unsafe code. Note that these guarantees refer to an unqualified `Vec<T>`.\n/// If additional type parameters are added (e.g., to support custom allocators),\n/// overriding their defaults may change the behavior.\n///\n/// Most fundamentally, `Vec` is and always will be a (pointer, capacity, length)\n/// triplet. No more, no less. The order of these fields is completely\n/// unspecified, and you should use the appropriate methods to modify these.\n/// The pointer will never be null, so this type is null-pointer-optimized.\n///\n/// However, the pointer might not actually point to allocated memory. In particular,\n/// if you construct a `Vec` with capacity 0 via [`Vec::new`], [`vec![]`][`vec!`],\n/// [`Vec::with_capacity(0)`][`Vec::with_capacity`], or by calling [`shrink_to_fit`]\n/// on an empty Vec, it will not allocate memory. Similarly, if you store zero-sized\n/// types inside a `Vec`, it will not allocate space for them. *Note that in this case\n/// the `Vec` might not report a [`capacity`] of 0*. `Vec` will allocate if and only\n/// if [`mem::size_of::<T>`]`() * capacity() > 0`. In general, `Vec`'s allocation\n/// details are very subtle &mdash; if you intend to allocate memory using a `Vec`\n/// and use it for something else (either to pass to unsafe code, or to build your\n/// own memory-backed collection), be sure to deallocate this memory by using\n/// `from_raw_parts` to recover the `Vec` and then dropping it.\n///\n/// If a `Vec` *has* allocated memory, then the memory it points to is on the heap\n/// (as defined by the allocator Rust is configured to use by default), and its\n/// pointer points to [`len`] initialized, contiguous elements in order (what\n/// you would see if you coerced it to a slice), followed by [`capacity`]` -\n/// `[`len`] logically uninitialized, contiguous elements.\n///\n/// A vector containing the elements `'a'` and `'b'` with capacity 4 can be\n/// visualized as below. The top part is the `Vec` struct, it contains a\n/// pointer to the head of the allocation in the heap, length and capacity.\n/// The bottom part is the allocation on the heap, a contiguous memory block.\n///\n/// ```text\n///             ptr      len  capacity\n///        +--------+--------+--------+\n///        | 0x0123 |      2 |      4 |\n///        +--------+--------+--------+\n///             |\n///             v\n/// Heap   +--------+--------+--------+--------+\n///        |    'a' |    'b' | uninit | uninit |\n///        +--------+--------+--------+--------+\n/// ```\n///\n/// - **uninit** represents memory that is not initialized, see [`MaybeUninit`].\n/// - Note: the ABI is not stable and `Vec` makes no guarantees about its memory\n///   layout (including the order of fields).\n///\n/// `Vec` will never perform a \"small optimization\" where elements are actually\n/// stored on the stack for two reasons:\n///\n/// * It would make it more difficult for unsafe code to correctly manipulate\n///   a `Vec`. The contents of a `Vec` wouldn't have a stable address if it were\n///   only moved, and it would be more difficult to determine if a `Vec` had\n///   actually allocated memory.\n///\n/// * It would penalize the general case, incurring an additional branch\n///   on every access.\n///\n/// `Vec` will never automatically shrink itself, even if completely empty. This\n/// ensures no unnecessary allocations or deallocations occur. Emptying a `Vec`\n/// and then filling it back up to the same [`len`] should incur no calls to\n/// the allocator. If you wish to free up unused memory, use\n/// [`shrink_to_fit`] or [`shrink_to`].\n///\n/// [`push`] and [`insert`] will never (re)allocate if the reported capacity is\n/// sufficient. [`push`] and [`insert`] *will* (re)allocate if\n/// [`len`]` == `[`capacity`]. That is, the reported capacity is completely\n/// accurate, and can be relied on. It can even be used to manually free the memory\n/// allocated by a `Vec` if desired. Bulk insertion methods *may* reallocate, even\n/// when not necessary.\n///\n/// `Vec` does not guarantee any particular growth strategy when reallocating\n/// when full, nor when [`reserve`] is called. The current strategy is basic\n/// and it may prove desirable to use a non-constant growth factor. Whatever\n/// strategy is used will of course guarantee *O*(1) amortized [`push`].\n///\n/// `vec![x; n]`, `vec![a, b, c, d]`, and\n/// [`Vec::with_capacity(n)`][`Vec::with_capacity`], will all produce a `Vec`\n/// with exactly the requested capacity. If [`len`]` == `[`capacity`],\n/// (as is the case for the [`vec!`] macro), then a `Vec<T>` can be converted to\n/// and from a [`Box<[T]>`][owned slice] without reallocating or moving the elements.\n///\n/// `Vec` will not specifically overwrite any data that is removed from it,\n/// but also won't specifically preserve it. Its uninitialized memory is\n/// scratch space that it may use however it wants. It will generally just do\n/// whatever is most efficient or otherwise easy to implement. Do not rely on\n/// removed data to be erased for security purposes. Even if you drop a `Vec`, its\n/// buffer may simply be reused by another `Vec`. Even if you zero a `Vec`'s memory\n/// first, that might not actually happen because the optimizer does not consider\n/// this a side-effect that must be preserved. There is one case which we will\n/// not break, however: using `unsafe` code to write to the excess capacity,\n/// and then increasing the length to match, is always valid.\n///\n/// Currently, `Vec` does not guarantee the order in which elements are dropped.\n/// The order has changed in the past and may change again.\n///\n/// [`get`]: ../../std/vec/struct.Vec.html#method.get\n/// [`get_mut`]: ../../std/vec/struct.Vec.html#method.get_mut\n/// [`String`]: crate::string::String\n/// [`&str`]: type@str\n/// [`shrink_to_fit`]: Vec::shrink_to_fit\n/// [`shrink_to`]: Vec::shrink_to\n/// [`capacity`]: Vec::capacity\n/// [`mem::size_of::<T>`]: core::mem::size_of\n/// [`len`]: Vec::len\n/// [`push`]: Vec::push\n/// [`insert`]: Vec::insert\n/// [`reserve`]: Vec::reserve\n/// [`MaybeUninit`]: core::mem::MaybeUninit\n/// [owned slice]: Box\n#[stable(feature = \"rust1\", since = \"1.0.0\")]\n#[cfg_attr(not(test), rustc_diagnostic_item = \"vec_type\")]\npub struct Vec<T, #[unstable(feature = \"allocator_api\", issue = \"32838\")] A: Allocator = Global> {\n    buf: RawVec<T, A>,\n    len: usize,\n}\n\n////////////////////////////////////////////////////////////////////////////////\n// Inherent methods\n////////////////////////////////////////////////////////////////////////////////\n\nimpl<T> Vec<T> {\n    /// Constructs a new, empty `Vec<T>`.\n    ///\n    /// The vector will not allocate until elements are pushed onto it.\n    ///\n    /// # Examples\n    ///\n    /// ```\n    /// # #![allow(unused_mut)]\n    /// let mut vec: Vec<i32> = Vec::new();\n    /// ```\n    #[inline]\n    #[rustc_const_stable(feature = \"const_vec_new\", since = \"1.39.0\")]\n    #[stable(feature = \"rust1\", since = \"1.0.0\")]\n    pub const fn new() -> Self {\n        Vec { buf: RawVec::NEW, len: 0 }\n    }\n\n    /// Constructs a new, empty `Vec<T>` with the specified capacity.\n    ///\n    /// The vector will be able to hold exactly `capacity` elements without\n    /// reallocating. If `capacity` is 0, the vector will not allocate.\n    ///\n    /// It is important to note that although the returned vector has the\n    /// *capacity* specified, the vector will have a zero *length*. For an\n    /// explanation of the difference between length and capacity, see\n    /// *[Capacity and reallocation]*.\n    ///\n    /// [Capacity and reallocation]: #capacity-and-reallocation\n    ///\n    /// # Panics\n    ///\n    /// Panics if the new capacity exceeds `isize::MAX` bytes.\n    ///\n    /// # Examples\n    ///\n    /// ```\n    /// let mut vec = Vec::with_capacity(10);\n    ///\n    /// // The vector contains no items, even though it has capacity for more\n    /// assert_eq!(vec.len(), 0);\n    /// assert_eq!(vec.capacity(), 10);\n    ///\n    /// // These are all done without reallocating...\n    /// for i in 0..10 {\n    ///     vec.push(i);\n    /// }\n    /// assert_eq!(vec.len(), 10);\n    /// assert_eq!(vec.capacity(), 10);\n    ///\n    /// // ...but this may make the vector reallocate\n    /// vec.push(11);\n    /// assert_eq!(vec.len(), 11);\n    /// assert!(vec.capacity() >= 11);\n    /// ```\n    #[cfg(not(no_global_oom_handling))]\n    #[inline]\n    #[doc(alias = \"malloc\")]\n    #[stable(feature = \"rust1\", since = \"1.0.0\")]\n    pub fn with_capacity(capacity: usize) -> Self {\n        Self::with_capacity_in(capacity, Global)\n    }\n\n    /// Creates a `Vec<T>` directly from the raw components of another vector.\n    ///\n    /// # Safety\n    ///\n    /// This is highly unsafe, due to the number of invariants that aren't\n    /// checked:\n    ///\n    /// * `ptr` needs to have been previously allocated via [`String`]/`Vec<T>`\n    ///   (at least, it's highly likely to be incorrect if it wasn't).\n    /// * `T` needs to have the same size and alignment as what `ptr` was allocated with.\n    ///   (`T` having a less strict alignment is not sufficient, the alignment really\n    ///   needs to be equal to satisfy the [`dealloc`] requirement that memory must be\n    ///   allocated and deallocated with the same layout.)\n    /// * `length` needs to be less than or equal to `capacity`.\n    /// * `capacity` needs to be the capacity that the pointer was allocated with.\n    ///\n    /// Violating these may cause problems like corrupting the allocator's\n    /// internal data structures. For example it is **not** safe\n    /// to build a `Vec<u8>` from a pointer to a C `char` array with length `size_t`.\n    /// It's also not safe to build one from a `Vec<u16>` and its length, because\n    /// the allocator cares about the alignment, and these two types have different\n    /// alignments. The buffer was allocated with alignment 2 (for `u16`), but after\n    /// turning it into a `Vec<u8>` it'll be deallocated with alignment 1.\n    ///\n    /// The ownership of `ptr` is effectively transferred to the\n    /// `Vec<T>` which may then deallocate, reallocate or change the\n    /// contents of memory pointed to by the pointer at will. Ensure\n    /// that nothing else uses the pointer after calling this\n    /// function.\n    ///\n    /// [`String`]: crate::string::String\n    /// [`dealloc`]: crate::alloc::GlobalAlloc::dealloc\n    ///\n    /// # Examples\n    ///\n    /// ```\n    /// use std::ptr;\n    /// use std::mem;\n    ///\n    /// let v = vec![1, 2, 3];\n    ///\n    // FIXME Update this when vec_into_raw_parts is stabilized\n    /// // Prevent running `v`'s destructor so we are in complete control\n    /// // of the allocation.\n    /// let mut v = mem::ManuallyDrop::new(v);\n    ///\n    /// // Pull out the various important pieces of information about `v`\n    /// let p = v.as_mut_ptr();\n    /// let len = v.len();\n    /// let cap = v.capacity();\n    ///\n    /// unsafe {\n    ///     // Overwrite memory with 4, 5, 6\n    ///     for i in 0..len as isize {\n    ///         ptr::write(p.offset(i), 4 + i);\n    ///     }\n    ///\n    ///     // Put everything back together into a Vec\n    ///     let rebuilt = Vec::from_raw_parts(p, len, cap);\n    ///     assert_eq!(rebuilt, [4, 5, 6]);\n    /// }\n    /// ```\n    #[inline]\n    #[stable(feature = \"rust1\", since = \"1.0.0\")]\n    pub unsafe fn from_raw_parts(ptr: *mut T, length: usize, capacity: usize) -> Self {\n        unsafe { Self::from_raw_parts_in(ptr, length, capacity, Global) }\n    }\n}\n\nimpl<T, A: Allocator> Vec<T, A> {\n    /// Constructs a new, empty `Vec<T, A>`.\n    ///\n    /// The vector will not allocate until elements are pushed onto it.\n    ///\n    /// # Examples\n    ///\n    /// ```\n    /// #![feature(allocator_api)]\n    ///\n    /// use std::alloc::System;\n    ///\n    /// # #[allow(unused_mut)]\n    /// let mut vec: Vec<i32, _> = Vec::new_in(System);\n    /// ```\n    #[inline]\n    #[unstable(feature = \"allocator_api\", issue = \"32838\")]\n    pub const fn new_in(alloc: A) -> Self {\n        Vec { buf: RawVec::new_in(alloc), len: 0 }\n    }\n\n    /// Constructs a new, empty `Vec<T, A>` with the specified capacity with the provided\n    /// allocator.\n    ///\n    /// The vector will be able to hold exactly `capacity` elements without\n    /// reallocating. If `capacity` is 0, the vector will not allocate.\n    ///\n    /// It is important to note that although the returned vector has the\n    /// *capacity* specified, the vector will have a zero *length*. For an\n    /// explanation of the difference between length and capacity, see\n    /// *[Capacity and reallocation]*.\n    ///\n    /// [Capacity and reallocation]: #capacity-and-reallocation\n    ///\n    /// # Panics\n    ///\n    /// Panics if the new capacity exceeds `isize::MAX` bytes.\n    ///\n    /// # Examples\n    ///\n    /// ```\n    /// #![feature(allocator_api)]\n    ///\n    /// use std::alloc::System;\n    ///\n    /// let mut vec = Vec::with_capacity_in(10, System);\n    ///\n    /// // The vector contains no items, even though it has capacity for more\n    /// assert_eq!(vec.len(), 0);\n    /// assert_eq!(vec.capacity(), 10);\n    ///\n    /// // These are all done without reallocating...\n    /// for i in 0..10 {\n    ///     vec.push(i);\n    /// }\n    /// assert_eq!(vec.len(), 10);\n    /// assert_eq!(vec.capacity(), 10);\n    ///\n    /// // ...but this may make the vector reallocate\n    /// vec.push(11);\n    /// assert_eq!(vec.len(), 11);\n    /// assert!(vec.capacity() >= 11);\n    /// ```\n    #[cfg(not(no_global_oom_handling))]\n    #[inline]\n    #[unstable(feature = \"allocator_api\", issue = \"32838\")]\n    pub fn with_capacity_in(capacity: usize, alloc: A) -> Self {\n        Vec { buf: RawVec::with_capacity_in(capacity, alloc), len: 0 }\n    }\n\n    /// Creates a `Vec<T, A>` directly from the raw components of another vector.\n    ///\n    /// # Safety\n    ///\n    /// This is highly unsafe, due to the number of invariants that aren't\n    /// checked:\n    ///\n    /// * `ptr` needs to have been previously allocated via [`String`]/`Vec<T>`\n    ///   (at least, it's highly likely to be incorrect if it wasn't).\n    /// * `T` needs to have the same size and alignment as what `ptr` was allocated with.\n    ///   (`T` having a less strict alignment is not sufficient, the alignment really\n    ///   needs to be equal to satisfy the [`dealloc`] requirement that memory must be\n    ///   allocated and deallocated with the same layout.)\n    /// * `length` needs to be less than or equal to `capacity`.\n    /// * `capacity` needs to be the capacity that the pointer was allocated with.\n    ///\n    /// Violating these may cause problems like corrupting the allocator's\n    /// internal data structures. For example it is **not** safe\n    /// to build a `Vec<u8>` from a pointer to a C `char` array with length `size_t`.\n    /// It's also not safe to build one from a `Vec<u16>` and its length, because\n    /// the allocator cares about the alignment, and these two types have different\n    /// alignments. The buffer was allocated with alignment 2 (for `u16`), but after\n    /// turning it into a `Vec<u8>` it'll be deallocated with alignment 1.\n    ///\n    /// The ownership of `ptr` is effectively transferred to the\n    /// `Vec<T>` which may then deallocate, reallocate or change the\n    /// contents of memory pointed to by the pointer at will. Ensure\n    /// that nothing else uses the pointer after calling this\n    /// function.\n    ///\n    /// [`String`]: crate::string::String\n    /// [`dealloc`]: crate::alloc::GlobalAlloc::dealloc\n    ///\n    /// # Examples\n    ///\n    /// ```\n    /// #![feature(allocator_api)]\n    ///\n    /// use std::alloc::System;\n    ///\n    /// use std::ptr;\n    /// use std::mem;\n    ///\n    /// let mut v = Vec::with_capacity_in(3, System);\n    /// v.push(1);\n    /// v.push(2);\n    /// v.push(3);\n    ///\n    // FIXME Update this when vec_into_raw_parts is stabilized\n    /// // Prevent running `v`'s destructor so we are in complete control\n    /// // of the allocation.\n    /// let mut v = mem::ManuallyDrop::new(v);\n    ///\n    /// // Pull out the various important pieces of information about `v`\n    /// let p = v.as_mut_ptr();\n    /// let len = v.len();\n    /// let cap = v.capacity();\n    /// let alloc = v.allocator();\n    ///\n    /// unsafe {\n    ///     // Overwrite memory with 4, 5, 6\n    ///     for i in 0..len as isize {\n    ///         ptr::write(p.offset(i), 4 + i);\n    ///     }\n    ///\n    ///     // Put everything back together into a Vec\n    ///     let rebuilt = Vec::from_raw_parts_in(p, len, cap, alloc.clone());\n    ///     assert_eq!(rebuilt, [4, 5, 6]);\n    /// }\n    /// ```\n    #[inline]\n    #[unstable(feature = \"allocator_api\", issue = \"32838\")]\n    pub unsafe fn from_raw_parts_in(ptr: *mut T, length: usize, capacity: usize, alloc: A) -> Self {\n        unsafe { Vec { buf: RawVec::from_raw_parts_in(ptr, capacity, alloc), len: length } }\n    }\n\n    /// Decomposes a `Vec<T>` into its raw components.\n    ///\n    /// Returns the raw pointer to the underlying data, the length of\n    /// the vector (in elements), and the allocated capacity of the\n    /// data (in elements). These are the same arguments in the same\n    /// order as the arguments to [`from_raw_parts`].\n    ///\n    /// After calling this function, the caller is responsible for the\n    /// memory previously managed by the `Vec`. The only way to do\n    /// this is to convert the raw pointer, length, and capacity back\n    /// into a `Vec` with the [`from_raw_parts`] function, allowing\n    /// the destructor to perform the cleanup.\n    ///\n    /// [`from_raw_parts`]: Vec::from_raw_parts\n    ///\n    /// # Examples\n    ///\n    /// ```\n    /// #![feature(vec_into_raw_parts)]\n    /// let v: Vec<i32> = vec![-1, 0, 1];\n    ///\n    /// let (ptr, len, cap) = v.into_raw_parts();\n    ///\n    /// let rebuilt = unsafe {\n    ///     // We can now make changes to the components, such as\n    ///     // transmuting the raw pointer to a compatible type.\n    ///     let ptr = ptr as *mut u32;\n    ///\n    ///     Vec::from_raw_parts(ptr, len, cap)\n    /// };\n    /// assert_eq!(rebuilt, [4294967295, 0, 1]);\n    /// ```\n    #[unstable(feature = \"vec_into_raw_parts\", reason = \"new API\", issue = \"65816\")]\n    pub fn into_raw_parts(self) -> (*mut T, usize, usize) {\n        let mut me = ManuallyDrop::new(self);\n        (me.as_mut_ptr(), me.len(), me.capacity())\n    }\n\n    /// Decomposes a `Vec<T>` into its raw components.\n    ///\n    /// Returns the raw pointer to the underlying data, the length of the vector (in elements),\n    /// the allocated capacity of the data (in elements), and the allocator. These are the same\n    /// arguments in the same order as the arguments to [`from_raw_parts_in`].\n    ///\n    /// After calling this function, the caller is responsible for the\n    /// memory previously managed by the `Vec`. The only way to do\n    /// this is to convert the raw pointer, length, and capacity back\n    /// into a `Vec` with the [`from_raw_parts_in`] function, allowing\n    /// the destructor to perform the cleanup.\n    ///\n    /// [`from_raw_parts_in`]: Vec::from_raw_parts_in\n    ///\n    /// # Examples\n    ///\n    /// ```\n    /// #![feature(allocator_api, vec_into_raw_parts)]\n    ///\n    /// use std::alloc::System;\n    ///\n    /// let mut v: Vec<i32, System> = Vec::new_in(System);\n    /// v.push(-1);\n    /// v.push(0);\n    /// v.push(1);\n    ///\n    /// let (ptr, len, cap, alloc) = v.into_raw_parts_with_alloc();\n    ///\n    /// let rebuilt = unsafe {\n    ///     // We can now make changes to the components, such as\n    ///     // transmuting the raw pointer to a compatible type.\n    ///     let ptr = ptr as *mut u32;\n    ///\n    ///     Vec::from_raw_parts_in(ptr, len, cap, alloc)\n    /// };\n    /// assert_eq!(rebuilt, [4294967295, 0, 1]);\n    /// ```\n    #[unstable(feature = \"allocator_api\", issue = \"32838\")]\n    // #[unstable(feature = \"vec_into_raw_parts\", reason = \"new API\", issue = \"65816\")]\n    pub fn into_raw_parts_with_alloc(self) -> (*mut T, usize, usize, A) {\n        let mut me = ManuallyDrop::new(self);\n        let len = me.len();\n        let capacity = me.capacity();\n        let ptr = me.as_mut_ptr();\n        let alloc = unsafe { ptr::read(me.allocator()) };\n        (ptr, len, capacity, alloc)\n    }\n\n    /// Returns the number of elements the vector can hold without\n    /// reallocating.\n    ///\n    /// # Examples\n    ///\n    /// ```\n    /// let vec: Vec<i32> = Vec::with_capacity(10);\n    /// assert_eq!(vec.capacity(), 10);\n    /// ```\n    #[inline]\n    #[stable(feature = \"rust1\", since = \"1.0.0\")]\n    pub fn capacity(&self) -> usize {\n        self.buf.capacity()\n    }\n\n    /// Reserves capacity for at least `additional` more elements to be inserted\n    /// in the given `Vec<T>`. The collection may reserve more space to avoid\n    /// frequent reallocations. After calling `reserve`, capacity will be\n    /// greater than or equal to `self.len() + additional`. Does nothing if\n    /// capacity is already sufficient.\n    ///\n    /// # Panics\n    ///\n    /// Panics if the new capacity exceeds `isize::MAX` bytes.\n    ///\n    /// # Examples\n    ///\n    /// ```\n    /// let mut vec = vec![1];\n    /// vec.reserve(10);\n    /// assert!(vec.capacity() >= 11);\n    /// ```\n    #[cfg(not(no_global_oom_handling))]\n    #[doc(alias = \"realloc\")]\n    #[stable(feature = \"rust1\", since = \"1.0.0\")]\n    pub fn reserve(&mut self, additional: usize) {\n        self.buf.reserve(self.len, additional);\n    }\n\n    /// Reserves the minimum capacity for exactly `additional` more elements to\n    /// be inserted in the given `Vec<T>`. After calling `reserve_exact`,\n    /// capacity will be greater than or equal to `self.len() + additional`.\n    /// Does nothing if the capacity is already sufficient.\n    ///\n    /// Note that the allocator may give the collection more space than it\n    /// requests. Therefore, capacity can not be relied upon to be precisely\n    /// minimal. Prefer `reserve` if future insertions are expected.\n    ///\n    /// # Panics\n    ///\n    /// Panics if the new capacity overflows `usize`.\n    ///\n    /// # Examples\n    ///\n    /// ```\n    /// let mut vec = vec![1];\n    /// vec.reserve_exact(10);\n    /// assert!(vec.capacity() >= 11);\n    /// ```\n    #[cfg(not(no_global_oom_handling))]\n    #[doc(alias = \"realloc\")]\n    #[stable(feature = \"rust1\", since = \"1.0.0\")]\n    pub fn reserve_exact(&mut self, additional: usize) {\n        self.buf.reserve_exact(self.len, additional);\n    }\n\n    /// Tries to reserve capacity for at least `additional` more elements to be inserted\n    /// in the given `Vec<T>`. The collection may reserve more space to avoid\n    /// frequent reallocations. After calling `try_reserve`, capacity will be\n    /// greater than or equal to `self.len() + additional`. Does nothing if\n    /// capacity is already sufficient.\n    ///\n    /// # Errors\n    ///\n    /// If the capacity overflows, or the allocator reports a failure, then an error\n    /// is returned.\n    ///\n    /// # Examples\n    ///\n    /// ```\n    /// #![feature(try_reserve)]\n    /// use std::collections::TryReserveError;\n    ///\n    /// fn process_data(data: &[u32]) -> Result<Vec<u32>, TryReserveError> {\n    ///     let mut output = Vec::new();\n    ///\n    ///     // Pre-reserve the memory, exiting if we can't\n    ///     output.try_reserve(data.len())?;\n    ///\n    ///     // Now we know this can't OOM in the middle of our complex work\n    ///     output.extend(data.iter().map(|&val| {\n    ///         val * 2 + 5 // very complicated\n    ///     }));\n    ///\n    ///     Ok(output)\n    /// }\n    /// # process_data(&[1, 2, 3]).expect(\"why is the test harness OOMing on 12 bytes?\");\n    /// ```\n    #[doc(alias = \"realloc\")]\n    #[unstable(feature = \"try_reserve\", reason = \"new API\", issue = \"48043\")]\n    pub fn try_reserve(&mut self, additional: usize) -> Result<(), TryReserveError> {\n        self.buf.try_reserve(self.len, additional)\n    }\n\n    /// Tries to reserve the minimum capacity for exactly `additional`\n    /// elements to be inserted in the given `Vec<T>`. After calling\n    /// `try_reserve_exact`, capacity will be greater than or equal to\n    /// `self.len() + additional` if it returns `Ok(())`.\n    /// Does nothing if the capacity is already sufficient.\n    ///\n    /// Note that the allocator may give the collection more space than it\n    /// requests. Therefore, capacity can not be relied upon to be precisely\n    /// minimal. Prefer `reserve` if future insertions are expected.\n    ///\n    /// # Errors\n    ///\n    /// If the capacity overflows, or the allocator reports a failure, then an error\n    /// is returned.\n    ///\n    /// # Examples\n    ///\n    /// ```\n    /// #![feature(try_reserve)]\n    /// use std::collections::TryReserveError;\n    ///\n    /// fn process_data(data: &[u32]) -> Result<Vec<u32>, TryReserveError> {\n    ///     let mut output = Vec::new();\n    ///\n    ///     // Pre-reserve the memory, exiting if we can't\n    ///     output.try_reserve_exact(data.len())?;\n    ///\n    ///     // Now we know this can't OOM in the middle of our complex work\n    ///     output.extend(data.iter().map(|&val| {\n    ///         val * 2 + 5 // very complicated\n    ///     }));\n    ///\n    ///     Ok(output)\n    /// }\n    /// # process_data(&[1, 2, 3]).expect(\"why is the test harness OOMing on 12 bytes?\");\n    /// ```\n    #[doc(alias = \"realloc\")]\n    #[unstable(feature = \"try_reserve\", reason = \"new API\", issue = \"48043\")]\n    pub fn try_reserve_exact(&mut self, additional: usize) -> Result<(), TryReserveError> {\n        self.buf.try_reserve_exact(self.len, additional)\n    }\n\n    /// Shrinks the capacity of the vector as much as possible.\n    ///\n    /// It will drop down as close as possible to the length but the allocator\n    /// may still inform the vector that there is space for a few more elements.\n    ///\n    /// # Examples\n    ///\n    /// ```\n    /// let mut vec = Vec::with_capacity(10);\n    /// vec.extend([1, 2, 3]);\n    /// assert_eq!(vec.capacity(), 10);\n    /// vec.shrink_to_fit();\n    /// assert!(vec.capacity() >= 3);\n    /// ```\n    #[cfg(not(no_global_oom_handling))]\n    #[doc(alias = \"realloc\")]\n    #[stable(feature = \"rust1\", since = \"1.0.0\")]\n    pub fn shrink_to_fit(&mut self) {\n        // The capacity is never less than the length, and there's nothing to do when\n        // they are equal, so we can avoid the panic case in `RawVec::shrink_to_fit`\n        // by only calling it with a greater capacity.\n        if self.capacity() > self.len {\n            self.buf.shrink_to_fit(self.len);\n        }\n    }\n\n    /// Shrinks the capacity of the vector with a lower bound.\n    ///\n    /// The capacity will remain at least as large as both the length\n    /// and the supplied value.\n    ///\n    /// If the current capacity is less than the lower limit, this is a no-op.\n    ///\n    /// # Examples\n    ///\n    /// ```\n    /// #![feature(shrink_to)]\n    /// let mut vec = Vec::with_capacity(10);\n    /// vec.extend([1, 2, 3]);\n    /// assert_eq!(vec.capacity(), 10);\n    /// vec.shrink_to(4);\n    /// assert!(vec.capacity() >= 4);\n    /// vec.shrink_to(0);\n    /// assert!(vec.capacity() >= 3);\n    /// ```\n    #[cfg(not(no_global_oom_handling))]\n    #[doc(alias = \"realloc\")]\n    #[unstable(feature = \"shrink_to\", reason = \"new API\", issue = \"56431\")]\n    pub fn shrink_to(&mut self, min_capacity: usize) {\n        if self.capacity() > min_capacity {\n            self.buf.shrink_to_fit(cmp::max(self.len, min_capacity));\n        }\n    }\n\n    /// Converts the vector into [`Box<[T]>`][owned slice].\n    ///\n    /// Note that this will drop any excess capacity.\n    ///\n    /// [owned slice]: Box\n    ///\n    /// # Examples\n    ///\n    /// ```\n    /// let v = vec![1, 2, 3];\n    ///\n    /// let slice = v.into_boxed_slice();\n    /// ```\n    ///\n    /// Any excess capacity is removed:\n    ///\n    /// ```\n    /// let mut vec = Vec::with_capacity(10);\n    /// vec.extend([1, 2, 3]);\n    ///\n    /// assert_eq!(vec.capacity(), 10);\n    /// let slice = vec.into_boxed_slice();\n    /// assert_eq!(slice.into_vec().capacity(), 3);\n    /// ```\n    #[cfg(not(no_global_oom_handling))]\n    #[stable(feature = \"rust1\", since = \"1.0.0\")]\n    pub fn into_boxed_slice(mut self) -> Box<[T], A> {\n        unsafe {\n            self.shrink_to_fit();\n            let me = ManuallyDrop::new(self);\n            let buf = ptr::read(&me.buf);\n            let len = me.len();\n            buf.into_box(len).assume_init()\n        }\n    }\n\n    /// Shortens the vector, keeping the first `len` elements and dropping\n    /// the rest.\n    ///\n    /// If `len` is greater than the vector's current length, this has no\n    /// effect.\n    ///\n    /// The [`drain`] method can emulate `truncate`, but causes the excess\n    /// elements to be returned instead of dropped.\n    ///\n    /// Note that this method has no effect on the allocated capacity\n    /// of the vector.\n    ///\n    /// # Examples\n    ///\n    /// Truncating a five element vector to two elements:\n    ///\n    /// ```\n    /// let mut vec = vec![1, 2, 3, 4, 5];\n    /// vec.truncate(2);\n    /// assert_eq!(vec, [1, 2]);\n    /// ```\n    ///\n    /// No truncation occurs when `len` is greater than the vector's current\n    /// length:\n    ///\n    /// ```\n    /// let mut vec = vec![1, 2, 3];\n    /// vec.truncate(8);\n    /// assert_eq!(vec, [1, 2, 3]);\n    /// ```\n    ///\n    /// Truncating when `len == 0` is equivalent to calling the [`clear`]\n    /// method.\n    ///\n    /// ```\n    /// let mut vec = vec![1, 2, 3];\n    /// vec.truncate(0);\n    /// assert_eq!(vec, []);\n    /// ```\n    ///\n    /// [`clear`]: Vec::clear\n    /// [`drain`]: Vec::drain\n    #[stable(feature = \"rust1\", since = \"1.0.0\")]\n    pub fn truncate(&mut self, len: usize) {\n        // This is safe because:\n        //\n        // * the slice passed to `drop_in_place` is valid; the `len > self.len`\n        //   case avoids creating an invalid slice, and\n        // * the `len` of the vector is shrunk before calling `drop_in_place`,\n        //   such that no value will be dropped twice in case `drop_in_place`\n        //   were to panic once (if it panics twice, the program aborts).\n        unsafe {\n            // Note: It's intentional that this is `>` and not `>=`.\n            //       Changing it to `>=` has negative performance\n            //       implications in some cases. See #78884 for more.\n            if len > self.len {\n                return;\n            }\n            let remaining_len = self.len - len;\n            let s = ptr::slice_from_raw_parts_mut(self.as_mut_ptr().add(len), remaining_len);\n            self.len = len;\n            ptr::drop_in_place(s);\n        }\n    }\n\n    /// Extracts a slice containing the entire vector.\n    ///\n    /// Equivalent to `&s[..]`.\n    ///\n    /// # Examples\n    ///\n    /// ```\n    /// use std::io::{self, Write};\n    /// let buffer = vec![1, 2, 3, 5, 8];\n    /// io::sink().write(buffer.as_slice()).unwrap();\n    /// ```\n    #[inline]\n    #[stable(feature = \"vec_as_slice\", since = \"1.7.0\")]\n    pub fn as_slice(&self) -> &[T] {\n        self\n    }\n\n    /// Extracts a mutable slice of the entire vector.\n    ///\n    /// Equivalent to `&mut s[..]`.\n    ///\n    /// # Examples\n    ///\n    /// ```\n    /// use std::io::{self, Read};\n    /// let mut buffer = vec![0; 3];\n    /// io::repeat(0b101).read_exact(buffer.as_mut_slice()).unwrap();\n    /// ```\n    #[inline]\n    #[stable(feature = \"vec_as_slice\", since = \"1.7.0\")]\n    pub fn as_mut_slice(&mut self) -> &mut [T] {\n        self\n    }\n\n    /// Returns a raw pointer to the vector's buffer.\n    ///\n    /// The caller must ensure that the vector outlives the pointer this\n    /// function returns, or else it will end up pointing to garbage.\n    /// Modifying the vector may cause its buffer to be reallocated,\n    /// which would also make any pointers to it invalid.\n    ///\n    /// The caller must also ensure that the memory the pointer (non-transitively) points to\n    /// is never written to (except inside an `UnsafeCell`) using this pointer or any pointer\n    /// derived from it. If you need to mutate the contents of the slice, use [`as_mut_ptr`].\n    ///\n    /// # Examples\n    ///\n    /// ```\n    /// let x = vec![1, 2, 4];\n    /// let x_ptr = x.as_ptr();\n    ///\n    /// unsafe {\n    ///     for i in 0..x.len() {\n    ///         assert_eq!(*x_ptr.add(i), 1 << i);\n    ///     }\n    /// }\n    /// ```\n    ///\n    /// [`as_mut_ptr`]: Vec::as_mut_ptr\n    #[stable(feature = \"vec_as_ptr\", since = \"1.37.0\")]\n    #[inline]\n    pub fn as_ptr(&self) -> *const T {\n        // We shadow the slice method of the same name to avoid going through\n        // `deref`, which creates an intermediate reference.\n        let ptr = self.buf.ptr();\n        unsafe {\n            assume(!ptr.is_null());\n        }\n        ptr\n    }\n\n    /// Returns an unsafe mutable pointer to the vector's buffer.\n    ///\n    /// The caller must ensure that the vector outlives the pointer this\n    /// function returns, or else it will end up pointing to garbage.\n    /// Modifying the vector may cause its buffer to be reallocated,\n    /// which would also make any pointers to it invalid.\n    ///\n    /// # Examples\n    ///\n    /// ```\n    /// // Allocate vector big enough for 4 elements.\n    /// let size = 4;\n    /// let mut x: Vec<i32> = Vec::with_capacity(size);\n    /// let x_ptr = x.as_mut_ptr();\n    ///\n    /// // Initialize elements via raw pointer writes, then set length.\n    /// unsafe {\n    ///     for i in 0..size {\n    ///         *x_ptr.add(i) = i as i32;\n    ///     }\n    ///     x.set_len(size);\n    /// }\n    /// assert_eq!(&*x, &[0, 1, 2, 3]);\n    /// ```\n    #[stable(feature = \"vec_as_ptr\", since = \"1.37.0\")]\n    #[inline]\n    pub fn as_mut_ptr(&mut self) -> *mut T {\n        // We shadow the slice method of the same name to avoid going through\n        // `deref_mut`, which creates an intermediate reference.\n        let ptr = self.buf.ptr();\n        unsafe {\n            assume(!ptr.is_null());\n        }\n        ptr\n    }\n\n    /// Returns a reference to the underlying allocator.\n    #[unstable(feature = \"allocator_api\", issue = \"32838\")]\n    #[inline]\n    pub fn allocator(&self) -> &A {\n        self.buf.allocator()\n    }\n\n    /// Forces the length of the vector to `new_len`.\n    ///\n    /// This is a low-level operation that maintains none of the normal\n    /// invariants of the type. Normally changing the length of a vector\n    /// is done using one of the safe operations instead, such as\n    /// [`truncate`], [`resize`], [`extend`], or [`clear`].\n    ///\n    /// [`truncate`]: Vec::truncate\n    /// [`resize`]: Vec::resize\n    /// [`extend`]: Extend::extend\n    /// [`clear`]: Vec::clear\n    ///\n    /// # Safety\n    ///\n    /// - `new_len` must be less than or equal to [`capacity()`].\n    /// - The elements at `old_len..new_len` must be initialized.\n    ///\n    /// [`capacity()`]: Vec::capacity\n    ///\n    /// # Examples\n    ///\n    /// This method can be useful for situations in which the vector\n    /// is serving as a buffer for other code, particularly over FFI:\n    ///\n    /// ```no_run\n    /// # #![allow(dead_code)]\n    /// # // This is just a minimal skeleton for the doc example;\n    /// # // don't use this as a starting point for a real library.\n    /// # pub struct StreamWrapper { strm: *mut std::ffi::c_void }\n    /// # const Z_OK: i32 = 0;\n    /// # extern \"C\" {\n    /// #     fn deflateGetDictionary(\n    /// #         strm: *mut std::ffi::c_void,\n    /// #         dictionary: *mut u8,\n    /// #         dictLength: *mut usize,\n    /// #     ) -> i32;\n    /// # }\n    /// # impl StreamWrapper {\n    /// pub fn get_dictionary(&self) -> Option<Vec<u8>> {\n    ///     // Per the FFI method's docs, \"32768 bytes is always enough\".\n    ///     let mut dict = Vec::with_capacity(32_768);\n    ///     let mut dict_length = 0;\n    ///     // SAFETY: When `deflateGetDictionary` returns `Z_OK`, it holds that:\n    ///     // 1. `dict_length` elements were initialized.\n    ///     // 2. `dict_length` <= the capacity (32_768)\n    ///     // which makes `set_len` safe to call.\n    ///     unsafe {\n    ///         // Make the FFI call...\n    ///         let r = deflateGetDictionary(self.strm, dict.as_mut_ptr(), &mut dict_length);\n    ///         if r == Z_OK {\n    ///             // ...and update the length to what was initialized.\n    ///             dict.set_len(dict_length);\n    ///             Some(dict)\n    ///         } else {\n    ///             None\n    ///         }\n    ///     }\n    /// }\n    /// # }\n    /// ```\n    ///\n    /// While the following example is sound, there is a memory leak since\n    /// the inner vectors were not freed prior to the `set_len` call:\n    ///\n    /// ```\n    /// let mut vec = vec![vec![1, 0, 0],\n    ///                    vec![0, 1, 0],\n    ///                    vec![0, 0, 1]];\n    /// // SAFETY:\n    /// // 1. `old_len..0` is empty so no elements need to be initialized.\n    /// // 2. `0 <= capacity` always holds whatever `capacity` is.\n    /// unsafe {\n    ///     vec.set_len(0);\n    /// }\n    /// ```\n    ///\n    /// Normally, here, one would use [`clear`] instead to correctly drop\n    /// the contents and thus not leak memory.\n    #[inline]\n    #[stable(feature = \"rust1\", since = \"1.0.0\")]\n    pub unsafe fn set_len(&mut self, new_len: usize) {\n        debug_assert!(new_len <= self.capacity());\n\n        self.len = new_len;\n    }\n\n    /// Removes an element from the vector and returns it.\n    ///\n    /// The removed element is replaced by the last element of the vector.\n    ///\n    /// This does not preserve ordering, but is O(1).\n    ///\n    /// # Panics\n    ///\n    /// Panics if `index` is out of bounds.\n    ///\n    /// # Examples\n    ///\n    /// ```\n    /// let mut v = vec![\"foo\", \"bar\", \"baz\", \"qux\"];\n    ///\n    /// assert_eq!(v.swap_remove(1), \"bar\");\n    /// assert_eq!(v, [\"foo\", \"qux\", \"baz\"]);\n    ///\n    /// assert_eq!(v.swap_remove(0), \"foo\");\n    /// assert_eq!(v, [\"baz\", \"qux\"]);\n    /// ```\n    #[inline]\n    #[stable(feature = \"rust1\", since = \"1.0.0\")]\n    pub fn swap_remove(&mut self, index: usize) -> T {\n        #[cold]\n        #[inline(never)]\n        fn assert_failed(index: usize, len: usize) -> ! {\n            panic!(\"swap_remove index (is {}) should be < len (is {})\", index, len);\n        }\n\n        let len = self.len();\n        if index >= len {\n            assert_failed(index, len);\n        }\n        unsafe {\n            // We replace self[index] with the last element. Note that if the\n            // bounds check above succeeds there must be a last element (which\n            // can be self[index] itself).\n            let last = ptr::read(self.as_ptr().add(len - 1));\n            let hole = self.as_mut_ptr().add(index);\n            self.set_len(len - 1);\n            ptr::replace(hole, last)\n        }\n    }\n\n    /// Inserts an element at position `index` within the vector, shifting all\n    /// elements after it to the right.\n    ///\n    /// # Panics\n    ///\n    /// Panics if `index > len`.\n    ///\n    /// # Examples\n    ///\n    /// ```\n    /// let mut vec = vec![1, 2, 3];\n    /// vec.insert(1, 4);\n    /// assert_eq!(vec, [1, 4, 2, 3]);\n    /// vec.insert(4, 5);\n    /// assert_eq!(vec, [1, 4, 2, 3, 5]);\n    /// ```\n    #[cfg(not(no_global_oom_handling))]\n    #[stable(feature = \"rust1\", since = \"1.0.0\")]\n    pub fn insert(&mut self, index: usize, element: T) {\n        #[cold]\n        #[inline(never)]\n        fn assert_failed(index: usize, len: usize) -> ! {\n            panic!(\"insertion index (is {}) should be <= len (is {})\", index, len);\n        }\n\n        let len = self.len();\n        if index > len {\n            assert_failed(index, len);\n        }\n\n        // space for the new element\n        if len == self.buf.capacity() {\n            self.reserve(1);\n        }\n\n        unsafe {\n            // infallible\n            // The spot to put the new value\n            {\n                let p = self.as_mut_ptr().add(index);\n                // Shift everything over to make space. (Duplicating the\n                // `index`th element into two consecutive places.)\n                ptr::copy(p, p.offset(1), len - index);\n                // Write it in, overwriting the first copy of the `index`th\n                // element.\n                ptr::write(p, element);\n            }\n            self.set_len(len + 1);\n        }\n    }\n\n    /// Removes and returns the element at position `index` within the vector,\n    /// shifting all elements after it to the left.\n    ///\n    /// # Panics\n    ///\n    /// Panics if `index` is out of bounds.\n    ///\n    /// # Examples\n    ///\n    /// ```\n    /// let mut v = vec![1, 2, 3];\n    /// assert_eq!(v.remove(1), 2);\n    /// assert_eq!(v, [1, 3]);\n    /// ```\n    #[stable(feature = \"rust1\", since = \"1.0.0\")]\n    pub fn remove(&mut self, index: usize) -> T {\n        #[cold]\n        #[inline(never)]\n        fn assert_failed(index: usize, len: usize) -> ! {\n            panic!(\"removal index (is {}) should be < len (is {})\", index, len);\n        }\n\n        let len = self.len();\n        if index >= len {\n            assert_failed(index, len);\n        }\n        unsafe {\n            // infallible\n            let ret;\n            {\n                // the place we are taking from.\n                let ptr = self.as_mut_ptr().add(index);\n                // copy it out, unsafely having a copy of the value on\n                // the stack and in the vector at the same time.\n                ret = ptr::read(ptr);\n\n                // Shift everything down to fill in that spot.\n                ptr::copy(ptr.offset(1), ptr, len - index - 1);\n            }\n            self.set_len(len - 1);\n            ret\n        }\n    }\n\n    /// Retains only the elements specified by the predicate.\n    ///\n    /// In other words, remove all elements `e` such that `f(&e)` returns `false`.\n    /// This method operates in place, visiting each element exactly once in the\n    /// original order, and preserves the order of the retained elements.\n    ///\n    /// # Examples\n    ///\n    /// ```\n    /// let mut vec = vec![1, 2, 3, 4];\n    /// vec.retain(|&x| x % 2 == 0);\n    /// assert_eq!(vec, [2, 4]);\n    /// ```\n    ///\n    /// Because the elements are visited exactly once in the original order,\n    /// external state may be used to decide which elements to keep.\n    ///\n    /// ```\n    /// let mut vec = vec![1, 2, 3, 4, 5];\n    /// let keep = [false, true, true, false, true];\n    /// let mut iter = keep.iter();\n    /// vec.retain(|_| *iter.next().unwrap());\n    /// assert_eq!(vec, [2, 3, 5]);\n    /// ```\n    #[stable(feature = \"rust1\", since = \"1.0.0\")]\n    pub fn retain<F>(&mut self, mut f: F)\n    where\n        F: FnMut(&T) -> bool,\n    {\n        let original_len = self.len();\n        // Avoid double drop if the drop guard is not executed,\n        // since we may make some holes during the process.\n        unsafe { self.set_len(0) };\n\n        // Vec: [Kept, Kept, Hole, Hole, Hole, Hole, Unchecked, Unchecked]\n        //      |<-              processed len   ->| ^- next to check\n        //                  |<-  deleted cnt     ->|\n        //      |<-              original_len                          ->|\n        // Kept: Elements which predicate returns true on.\n        // Hole: Moved or dropped element slot.\n        // Unchecked: Unchecked valid elements.\n        //\n        // This drop guard will be invoked when predicate or `drop` of element panicked.\n        // It shifts unchecked elements to cover holes and `set_len` to the correct length.\n        // In cases when predicate and `drop` never panick, it will be optimized out.\n        struct BackshiftOnDrop<'a, T, A: Allocator> {\n            v: &'a mut Vec<T, A>,\n            processed_len: usize,\n            deleted_cnt: usize,\n            original_len: usize,\n        }\n\n        impl<T, A: Allocator> Drop for BackshiftOnDrop<'_, T, A> {\n            fn drop(&mut self) {\n                if self.deleted_cnt > 0 {\n                    // SAFETY: Trailing unchecked items must be valid since we never touch them.\n                    unsafe {\n                        ptr::copy(\n                            self.v.as_ptr().add(self.processed_len),\n                            self.v.as_mut_ptr().add(self.processed_len - self.deleted_cnt),\n                            self.original_len - self.processed_len,\n                        );\n                    }\n                }\n                // SAFETY: After filling holes, all items are in contiguous memory.\n                unsafe {\n                    self.v.set_len(self.original_len - self.deleted_cnt);\n                }\n            }\n        }\n\n        let mut g = BackshiftOnDrop { v: self, processed_len: 0, deleted_cnt: 0, original_len };\n\n        while g.processed_len < original_len {\n            // SAFETY: Unchecked element must be valid.\n            let cur = unsafe { &mut *g.v.as_mut_ptr().add(g.processed_len) };\n            if !f(cur) {\n                // Advance early to avoid double drop if `drop_in_place` panicked.\n                g.processed_len += 1;\n                g.deleted_cnt += 1;\n                // SAFETY: We never touch this element again after dropped.\n                unsafe { ptr::drop_in_place(cur) };\n                // We already advanced the counter.\n                continue;\n            }\n            if g.deleted_cnt > 0 {\n                // SAFETY: `deleted_cnt` > 0, so the hole slot must not overlap with current element.\n                // We use copy for move, and never touch this element again.\n                unsafe {\n                    let hole_slot = g.v.as_mut_ptr().add(g.processed_len - g.deleted_cnt);\n                    ptr::copy_nonoverlapping(cur, hole_slot, 1);\n                }\n            }\n            g.processed_len += 1;\n        }\n\n        // All item are processed. This can be optimized to `set_len` by LLVM.\n        drop(g);\n    }\n\n    /// Removes all but the first of consecutive elements in the vector that resolve to the same\n    /// key.\n    ///\n    /// If the vector is sorted, this removes all duplicates.\n    ///\n    /// # Examples\n    ///\n    /// ```\n    /// let mut vec = vec![10, 20, 21, 30, 20];\n    ///\n    /// vec.dedup_by_key(|i| *i / 10);\n    ///\n    /// assert_eq!(vec, [10, 20, 30, 20]);\n    /// ```\n    #[stable(feature = \"dedup_by\", since = \"1.16.0\")]\n    #[inline]\n    pub fn dedup_by_key<F, K>(&mut self, mut key: F)\n    where\n        F: FnMut(&mut T) -> K,\n        K: PartialEq,\n    {\n        self.dedup_by(|a, b| key(a) == key(b))\n    }\n\n    /// Removes all but the first of consecutive elements in the vector satisfying a given equality\n    /// relation.\n    ///\n    /// The `same_bucket` function is passed references to two elements from the vector and\n    /// must determine if the elements compare equal. The elements are passed in opposite order\n    /// from their order in the slice, so if `same_bucket(a, b)` returns `true`, `a` is removed.\n    ///\n    /// If the vector is sorted, this removes all duplicates.\n    ///\n    /// # Examples\n    ///\n    /// ```\n    /// let mut vec = vec![\"foo\", \"bar\", \"Bar\", \"baz\", \"bar\"];\n    ///\n    /// vec.dedup_by(|a, b| a.eq_ignore_ascii_case(b));\n    ///\n    /// assert_eq!(vec, [\"foo\", \"bar\", \"baz\", \"bar\"]);\n    /// ```\n    #[stable(feature = \"dedup_by\", since = \"1.16.0\")]\n    pub fn dedup_by<F>(&mut self, mut same_bucket: F)\n    where\n        F: FnMut(&mut T, &mut T) -> bool,\n    {\n        let len = self.len();\n        if len <= 1 {\n            return;\n        }\n\n        /* INVARIANT: vec.len() > read >= write > write-1 >= 0 */\n        struct FillGapOnDrop<'a, T, A: core::alloc::Allocator> {\n            /* Offset of the element we want to check if it is duplicate */\n            read: usize,\n\n            /* Offset of the place where we want to place the non-duplicate\n             * when we find it. */\n            write: usize,\n\n            /* The Vec that would need correction if `same_bucket` panicked */\n            vec: &'a mut Vec<T, A>,\n        }\n\n        impl<'a, T, A: core::alloc::Allocator> Drop for FillGapOnDrop<'a, T, A> {\n            fn drop(&mut self) {\n                /* This code gets executed when `same_bucket` panics */\n\n                /* SAFETY: invariant guarantees that `read - write`\n                 * and `len - read` never overflow and that the copy is always\n                 * in-bounds. */\n                unsafe {\n                    let ptr = self.vec.as_mut_ptr();\n                    let len = self.vec.len();\n\n                    /* How many items were left when `same_bucket` paniced.\n                     * Basically vec[read..].len() */\n                    let items_left = len.wrapping_sub(self.read);\n\n                    /* Pointer to first item in vec[write..write+items_left] slice */\n                    let dropped_ptr = ptr.add(self.write);\n                    /* Pointer to first item in vec[read..] slice */\n                    let valid_ptr = ptr.add(self.read);\n\n                    /* Copy `vec[read..]` to `vec[write..write+items_left]`.\n                     * The slices can overlap, so `copy_nonoverlapping` cannot be used */\n                    ptr::copy(valid_ptr, dropped_ptr, items_left);\n\n                    /* How many items have been already dropped\n                     * Basically vec[read..write].len() */\n                    let dropped = self.read.wrapping_sub(self.write);\n\n                    self.vec.set_len(len - dropped);\n                }\n            }\n        }\n\n        let mut gap = FillGapOnDrop { read: 1, write: 1, vec: self };\n        let ptr = gap.vec.as_mut_ptr();\n\n        /* Drop items while going through Vec, it should be more efficient than\n         * doing slice partition_dedup + truncate */\n\n        /* SAFETY: Because of the invariant, read_ptr, prev_ptr and write_ptr\n         * are always in-bounds and read_ptr never aliases prev_ptr */\n        unsafe {\n            while gap.read < len {\n                let read_ptr = ptr.add(gap.read);\n                let prev_ptr = ptr.add(gap.write.wrapping_sub(1));\n\n                if same_bucket(&mut *read_ptr, &mut *prev_ptr) {\n                    // Increase `gap.read` now since the drop may panic.\n                    gap.read += 1;\n                    /* We have found duplicate, drop it in-place */\n                    ptr::drop_in_place(read_ptr);\n                } else {\n                    let write_ptr = ptr.add(gap.write);\n\n                    /* Because `read_ptr` can be equal to `write_ptr`, we either\n                     * have to use `copy` or conditional `copy_nonoverlapping`.\n                     * Looks like the first option is faster. */\n                    ptr::copy(read_ptr, write_ptr, 1);\n\n                    /* We have filled that place, so go further */\n                    gap.write += 1;\n                    gap.read += 1;\n                }\n            }\n\n            /* Technically we could let `gap` clean up with its Drop, but\n             * when `same_bucket` is guaranteed to not panic, this bloats a little\n             * the codegen, so we just do it manually */\n            gap.vec.set_len(gap.write);\n            mem::forget(gap);\n        }\n    }\n\n    /// Appends an element to the back of a collection.\n    ///\n    /// # Panics\n    ///\n    /// Panics if the new capacity exceeds `isize::MAX` bytes.\n    ///\n    /// # Examples\n    ///\n    /// ```\n    /// let mut vec = vec![1, 2];\n    /// vec.push(3);\n    /// assert_eq!(vec, [1, 2, 3]);\n    /// ```\n    #[cfg(not(no_global_oom_handling))]\n    #[inline]\n    #[stable(feature = \"rust1\", since = \"1.0.0\")]\n    pub fn push(&mut self, value: T) {\n        // This will panic or abort if we would allocate > isize::MAX bytes\n        // or if the length increment would overflow for zero-sized types.\n        if self.len == self.buf.capacity() {\n            self.reserve(1);\n        }\n        unsafe {\n            let end = self.as_mut_ptr().add(self.len);\n            ptr::write(end, value);\n            self.len += 1;\n        }\n    }\n\n    /// Removes the last element from a vector and returns it, or [`None`] if it\n    /// is empty.\n    ///\n    /// # Examples\n    ///\n    /// ```\n    /// let mut vec = vec![1, 2, 3];\n    /// assert_eq!(vec.pop(), Some(3));\n    /// assert_eq!(vec, [1, 2]);\n    /// ```\n    #[inline]\n    #[stable(feature = \"rust1\", since = \"1.0.0\")]\n    pub fn pop(&mut self) -> Option<T> {\n        if self.len == 0 {\n            None\n        } else {\n            unsafe {\n                self.len -= 1;\n                Some(ptr::read(self.as_ptr().add(self.len())))\n            }\n        }\n    }\n\n    /// Moves all the elements of `other` into `Self`, leaving `other` empty.\n    ///\n    /// # Panics\n    ///\n    /// Panics if the number of elements in the vector overflows a `usize`.\n    ///\n    /// # Examples\n    ///\n    /// ```\n    /// let mut vec = vec![1, 2, 3];\n    /// let mut vec2 = vec![4, 5, 6];\n    /// vec.append(&mut vec2);\n    /// assert_eq!(vec, [1, 2, 3, 4, 5, 6]);\n    /// assert_eq!(vec2, []);\n    /// ```\n    #[cfg(not(no_global_oom_handling))]\n    #[inline]\n    #[stable(feature = \"append\", since = \"1.4.0\")]\n    pub fn append(&mut self, other: &mut Self) {\n        unsafe {\n            self.append_elements(other.as_slice() as _);\n            other.set_len(0);\n        }\n    }\n\n    /// Appends elements to `Self` from other buffer.\n    #[cfg(not(no_global_oom_handling))]\n    #[inline]\n    unsafe fn append_elements(&mut self, other: *const [T]) {\n        let count = unsafe { (*other).len() };\n        self.reserve(count);\n        let len = self.len();\n        unsafe { ptr::copy_nonoverlapping(other as *const T, self.as_mut_ptr().add(len), count) };\n        self.len += count;\n    }\n\n    /// Creates a draining iterator that removes the specified range in the vector\n    /// and yields the removed items.\n    ///\n    /// When the iterator **is** dropped, all elements in the range are removed\n    /// from the vector, even if the iterator was not fully consumed. If the\n    /// iterator **is not** dropped (with [`mem::forget`] for example), it is\n    /// unspecified how many elements are removed.\n    ///\n    /// # Panics\n    ///\n    /// Panics if the starting point is greater than the end point or if\n    /// the end point is greater than the length of the vector.\n    ///\n    /// # Examples\n    ///\n    /// ```\n    /// let mut v = vec![1, 2, 3];\n    /// let u: Vec<_> = v.drain(1..).collect();\n    /// assert_eq!(v, &[1]);\n    /// assert_eq!(u, &[2, 3]);\n    ///\n    /// // A full range clears the vector\n    /// v.drain(..);\n    /// assert_eq!(v, &[]);\n    /// ```\n    #[stable(feature = \"drain\", since = \"1.6.0\")]\n    pub fn drain<R>(&mut self, range: R) -> Drain<'_, T, A>\n    where\n        R: RangeBounds<usize>,\n    {\n        // Memory safety\n        //\n        // When the Drain is first created, it shortens the length of\n        // the source vector to make sure no uninitialized or moved-from elements\n        // are accessible at all if the Drain's destructor never gets to run.\n        //\n        // Drain will ptr::read out the values to remove.\n        // When finished, remaining tail of the vec is copied back to cover\n        // the hole, and the vector length is restored to the new length.\n        //\n        let len = self.len();\n        let Range { start, end } = slice::range(range, ..len);\n\n        unsafe {\n            // set self.vec length's to start, to be safe in case Drain is leaked\n            self.set_len(start);\n            // Use the borrow in the IterMut to indicate borrowing behavior of the\n            // whole Drain iterator (like &mut T).\n            let range_slice = slice::from_raw_parts_mut(self.as_mut_ptr().add(start), end - start);\n            Drain {\n                tail_start: end,\n                tail_len: len - end,\n                iter: range_slice.iter(),\n                vec: NonNull::from(self),\n            }\n        }\n    }\n\n    /// Clears the vector, removing all values.\n    ///\n    /// Note that this method has no effect on the allocated capacity\n    /// of the vector.\n    ///\n    /// # Examples\n    ///\n    /// ```\n    /// let mut v = vec![1, 2, 3];\n    ///\n    /// v.clear();\n    ///\n    /// assert!(v.is_empty());\n    /// ```\n    #[inline]\n    #[stable(feature = \"rust1\", since = \"1.0.0\")]\n    pub fn clear(&mut self) {\n        self.truncate(0)\n    }\n\n    /// Returns the number of elements in the vector, also referred to\n    /// as its 'length'.\n    ///\n    /// # Examples\n    ///\n    /// ```\n    /// let a = vec![1, 2, 3];\n    /// assert_eq!(a.len(), 3);\n    /// ```\n    #[doc(alias = \"length\")]\n    #[inline]\n    #[stable(feature = \"rust1\", since = \"1.0.0\")]\n    pub fn len(&self) -> usize {\n        self.len\n    }\n\n    /// Returns `true` if the vector contains no elements.\n    ///\n    /// # Examples\n    ///\n    /// ```\n    /// let mut v = Vec::new();\n    /// assert!(v.is_empty());\n    ///\n    /// v.push(1);\n    /// assert!(!v.is_empty());\n    /// ```\n    #[stable(feature = \"rust1\", since = \"1.0.0\")]\n    pub fn is_empty(&self) -> bool {\n        self.len() == 0\n    }\n\n    /// Splits the collection into two at the given index.\n    ///\n    /// Returns a newly allocated vector containing the elements in the range\n    /// `[at, len)`. After the call, the original vector will be left containing\n    /// the elements `[0, at)` with its previous capacity unchanged.\n    ///\n    /// # Panics\n    ///\n    /// Panics if `at > len`.\n    ///\n    /// # Examples\n    ///\n    /// ```\n    /// let mut vec = vec![1, 2, 3];\n    /// let vec2 = vec.split_off(1);\n    /// assert_eq!(vec, [1]);\n    /// assert_eq!(vec2, [2, 3]);\n    /// ```\n    #[cfg(not(no_global_oom_handling))]\n    #[inline]\n    #[must_use = \"use `.truncate()` if you don't need the other half\"]\n    #[stable(feature = \"split_off\", since = \"1.4.0\")]\n    pub fn split_off(&mut self, at: usize) -> Self\n    where\n        A: Clone,\n    {\n        #[cold]\n        #[inline(never)]\n        fn assert_failed(at: usize, len: usize) -> ! {\n            panic!(\"`at` split index (is {}) should be <= len (is {})\", at, len);\n        }\n\n        if at > self.len() {\n            assert_failed(at, self.len());\n        }\n\n        if at == 0 {\n            // the new vector can take over the original buffer and avoid the copy\n            return mem::replace(\n                self,\n                Vec::with_capacity_in(self.capacity(), self.allocator().clone()),\n            );\n        }\n\n        let other_len = self.len - at;\n        let mut other = Vec::with_capacity_in(other_len, self.allocator().clone());\n\n        // Unsafely `set_len` and copy items to `other`.\n        unsafe {\n            self.set_len(at);\n            other.set_len(other_len);\n\n            ptr::copy_nonoverlapping(self.as_ptr().add(at), other.as_mut_ptr(), other.len());\n        }\n        other\n    }\n\n    /// Resizes the `Vec` in-place so that `len` is equal to `new_len`.\n    ///\n    /// If `new_len` is greater than `len`, the `Vec` is extended by the\n    /// difference, with each additional slot filled with the result of\n    /// calling the closure `f`. The return values from `f` will end up\n    /// in the `Vec` in the order they have been generated.\n    ///\n    /// If `new_len` is less than `len`, the `Vec` is simply truncated.\n    ///\n    /// This method uses a closure to create new values on every push. If\n    /// you'd rather [`Clone`] a given value, use [`Vec::resize`]. If you\n    /// want to use the [`Default`] trait to generate values, you can\n    /// pass [`Default::default`] as the second argument.\n    ///\n    /// # Examples\n    ///\n    /// ```\n    /// let mut vec = vec![1, 2, 3];\n    /// vec.resize_with(5, Default::default);\n    /// assert_eq!(vec, [1, 2, 3, 0, 0]);\n    ///\n    /// let mut vec = vec![];\n    /// let mut p = 1;\n    /// vec.resize_with(4, || { p *= 2; p });\n    /// assert_eq!(vec, [2, 4, 8, 16]);\n    /// ```\n    #[cfg(not(no_global_oom_handling))]\n    #[stable(feature = \"vec_resize_with\", since = \"1.33.0\")]\n    pub fn resize_with<F>(&mut self, new_len: usize, f: F)\n    where\n        F: FnMut() -> T,\n    {\n        let len = self.len();\n        if new_len > len {\n            self.extend_with(new_len - len, ExtendFunc(f));\n        } else {\n            self.truncate(new_len);\n        }\n    }\n\n    /// Consumes and leaks the `Vec`, returning a mutable reference to the contents,\n    /// `&'a mut [T]`. Note that the type `T` must outlive the chosen lifetime\n    /// `'a`. If the type has only static references, or none at all, then this\n    /// may be chosen to be `'static`.\n    ///\n    /// This function is similar to the [`leak`][Box::leak] function on [`Box`]\n    /// except that there is no way to recover the leaked memory.\n    ///\n    /// This function is mainly useful for data that lives for the remainder of\n    /// the program's life. Dropping the returned reference will cause a memory\n    /// leak.\n    ///\n    /// # Examples\n    ///\n    /// Simple usage:\n    ///\n    /// ```\n    /// let x = vec![1, 2, 3];\n    /// let static_ref: &'static mut [usize] = x.leak();\n    /// static_ref[0] += 1;\n    /// assert_eq!(static_ref, &[2, 2, 3]);\n    /// ```\n    #[cfg(not(no_global_oom_handling))]\n    #[stable(feature = \"vec_leak\", since = \"1.47.0\")]\n    #[inline]\n    pub fn leak<'a>(self) -> &'a mut [T]\n    where\n        A: 'a,\n    {\n        Box::leak(self.into_boxed_slice())\n    }\n\n    /// Returns the remaining spare capacity of the vector as a slice of\n    /// `MaybeUninit<T>`.\n    ///\n    /// The returned slice can be used to fill the vector with data (e.g. by\n    /// reading from a file) before marking the data as initialized using the\n    /// [`set_len`] method.\n    ///\n    /// [`set_len`]: Vec::set_len\n    ///\n    /// # Examples\n    ///\n    /// ```\n    /// #![feature(vec_spare_capacity, maybe_uninit_extra)]\n    ///\n    /// // Allocate vector big enough for 10 elements.\n    /// let mut v = Vec::with_capacity(10);\n    ///\n    /// // Fill in the first 3 elements.\n    /// let uninit = v.spare_capacity_mut();\n    /// uninit[0].write(0);\n    /// uninit[1].write(1);\n    /// uninit[2].write(2);\n    ///\n    /// // Mark the first 3 elements of the vector as being initialized.\n    /// unsafe {\n    ///     v.set_len(3);\n    /// }\n    ///\n    /// assert_eq!(&v, &[0, 1, 2]);\n    /// ```\n    #[unstable(feature = \"vec_spare_capacity\", issue = \"75017\")]\n    #[inline]\n    pub fn spare_capacity_mut(&mut self) -> &mut [MaybeUninit<T>] {\n        // Note:\n        // This method is not implemented in terms of `split_at_spare_mut`,\n        // to prevent invalidation of pointers to the buffer.\n        unsafe {\n            slice::from_raw_parts_mut(\n                self.as_mut_ptr().add(self.len) as *mut MaybeUninit<T>,\n                self.buf.capacity() - self.len,\n            )\n        }\n    }\n\n    /// Returns vector content as a slice of `T`, along with the remaining spare\n    /// capacity of the vector as a slice of `MaybeUninit<T>`.\n    ///\n    /// The returned spare capacity slice can be used to fill the vector with data\n    /// (e.g. by reading from a file) before marking the data as initialized using\n    /// the [`set_len`] method.\n    ///\n    /// [`set_len`]: Vec::set_len\n    ///\n    /// Note that this is a low-level API, which should be used with care for\n    /// optimization purposes. If you need to append data to a `Vec`\n    /// you can use [`push`], [`extend`], [`extend_from_slice`],\n    /// [`extend_from_within`], [`insert`], [`append`], [`resize`] or\n    /// [`resize_with`], depending on your exact needs.\n    ///\n    /// [`push`]: Vec::push\n    /// [`extend`]: Vec::extend\n    /// [`extend_from_slice`]: Vec::extend_from_slice\n    /// [`extend_from_within`]: Vec::extend_from_within\n    /// [`insert`]: Vec::insert\n    /// [`append`]: Vec::append\n    /// [`resize`]: Vec::resize\n    /// [`resize_with`]: Vec::resize_with\n    ///\n    /// # Examples\n    ///\n    /// ```\n    /// #![feature(vec_split_at_spare, maybe_uninit_extra)]\n    ///\n    /// let mut v = vec![1, 1, 2];\n    ///\n    /// // Reserve additional space big enough for 10 elements.\n    /// v.reserve(10);\n    ///\n    /// let (init, uninit) = v.split_at_spare_mut();\n    /// let sum = init.iter().copied().sum::<u32>();\n    ///\n    /// // Fill in the next 4 elements.\n    /// uninit[0].write(sum);\n    /// uninit[1].write(sum * 2);\n    /// uninit[2].write(sum * 3);\n    /// uninit[3].write(sum * 4);\n    ///\n    /// // Mark the 4 elements of the vector as being initialized.\n    /// unsafe {\n    ///     let len = v.len();\n    ///     v.set_len(len + 4);\n    /// }\n    ///\n    /// assert_eq!(&v, &[1, 1, 2, 4, 8, 12, 16]);\n    /// ```\n    #[unstable(feature = \"vec_split_at_spare\", issue = \"81944\")]\n    #[inline]\n    pub fn split_at_spare_mut(&mut self) -> (&mut [T], &mut [MaybeUninit<T>]) {\n        // SAFETY:\n        // - len is ignored and so never changed\n        let (init, spare, _) = unsafe { self.split_at_spare_mut_with_len() };\n        (init, spare)\n    }\n\n    /// Safety: changing returned .2 (&mut usize) is considered the same as calling `.set_len(_)`.\n    ///\n    /// This method provides unique access to all vec parts at once in `extend_from_within`.\n    unsafe fn split_at_spare_mut_with_len(\n        &mut self,\n    ) -> (&mut [T], &mut [MaybeUninit<T>], &mut usize) {\n        let Range { start: ptr, end: spare_ptr } = self.as_mut_ptr_range();\n        let spare_ptr = spare_ptr.cast::<MaybeUninit<T>>();\n        let spare_len = self.buf.capacity() - self.len;\n\n        // SAFETY:\n        // - `ptr` is guaranteed to be valid for `len` elements\n        // - `spare_ptr` is pointing one element past the buffer, so it doesn't overlap with `initialized`\n        unsafe {\n            let initialized = slice::from_raw_parts_mut(ptr, self.len);\n            let spare = slice::from_raw_parts_mut(spare_ptr, spare_len);\n\n            (initialized, spare, &mut self.len)\n        }\n    }\n}\n\nimpl<T: Clone, A: Allocator> Vec<T, A> {\n    /// Resizes the `Vec` in-place so that `len` is equal to `new_len`.\n    ///\n    /// If `new_len` is greater than `len`, the `Vec` is extended by the\n    /// difference, with each additional slot filled with `value`.\n    /// If `new_len` is less than `len`, the `Vec` is simply truncated.\n    ///\n    /// This method requires `T` to implement [`Clone`],\n    /// in order to be able to clone the passed value.\n    /// If you need more flexibility (or want to rely on [`Default`] instead of\n    /// [`Clone`]), use [`Vec::resize_with`].\n    ///\n    /// # Examples\n    ///\n    /// ```\n    /// let mut vec = vec![\"hello\"];\n    /// vec.resize(3, \"world\");\n    /// assert_eq!(vec, [\"hello\", \"world\", \"world\"]);\n    ///\n    /// let mut vec = vec![1, 2, 3, 4];\n    /// vec.resize(2, 0);\n    /// assert_eq!(vec, [1, 2]);\n    /// ```\n    #[cfg(not(no_global_oom_handling))]\n    #[stable(feature = \"vec_resize\", since = \"1.5.0\")]\n    pub fn resize(&mut self, new_len: usize, value: T) {\n        let len = self.len();\n\n        if new_len > len {\n            self.extend_with(new_len - len, ExtendElement(value))\n        } else {\n            self.truncate(new_len);\n        }\n    }\n\n    /// Clones and appends all elements in a slice to the `Vec`.\n    ///\n    /// Iterates over the slice `other`, clones each element, and then appends\n    /// it to this `Vec`. The `other` vector is traversed in-order.\n    ///\n    /// Note that this function is same as [`extend`] except that it is\n    /// specialized to work with slices instead. If and when Rust gets\n    /// specialization this function will likely be deprecated (but still\n    /// available).\n    ///\n    /// # Examples\n    ///\n    /// ```\n    /// let mut vec = vec![1];\n    /// vec.extend_from_slice(&[2, 3, 4]);\n    /// assert_eq!(vec, [1, 2, 3, 4]);\n    /// ```\n    ///\n    /// [`extend`]: Vec::extend\n    #[cfg(not(no_global_oom_handling))]\n    #[stable(feature = \"vec_extend_from_slice\", since = \"1.6.0\")]\n    pub fn extend_from_slice(&mut self, other: &[T]) {\n        self.spec_extend(other.iter())\n    }\n\n    /// Copies elements from `src` range to the end of the vector.\n    ///\n    /// ## Examples\n    ///\n    /// ```\n    /// let mut vec = vec![0, 1, 2, 3, 4];\n    ///\n    /// vec.extend_from_within(2..);\n    /// assert_eq!(vec, [0, 1, 2, 3, 4, 2, 3, 4]);\n    ///\n    /// vec.extend_from_within(..2);\n    /// assert_eq!(vec, [0, 1, 2, 3, 4, 2, 3, 4, 0, 1]);\n    ///\n    /// vec.extend_from_within(4..8);\n    /// assert_eq!(vec, [0, 1, 2, 3, 4, 2, 3, 4, 0, 1, 4, 2, 3, 4]);\n    /// ```\n    #[cfg(not(no_global_oom_handling))]\n    #[stable(feature = \"vec_extend_from_within\", since = \"1.53.0\")]\n    pub fn extend_from_within<R>(&mut self, src: R)\n    where\n        R: RangeBounds<usize>,\n    {\n        let range = slice::range(src, ..self.len());\n        self.reserve(range.len());\n\n        // SAFETY:\n        // - `slice::range` guarantees  that the given range is valid for indexing self\n        unsafe {\n            self.spec_extend_from_within(range);\n        }\n    }\n}\n\n// This code generalizes `extend_with_{element,default}`.\ntrait ExtendWith<T> {\n    fn next(&mut self) -> T;\n    fn last(self) -> T;\n}\n\nstruct ExtendElement<T>(T);\nimpl<T: Clone> ExtendWith<T> for ExtendElement<T> {\n    fn next(&mut self) -> T {\n        self.0.clone()\n    }\n    fn last(self) -> T {\n        self.0\n    }\n}\n\nstruct ExtendDefault;\nimpl<T: Default> ExtendWith<T> for ExtendDefault {\n    fn next(&mut self) -> T {\n        Default::default()\n    }\n    fn last(self) -> T {\n        Default::default()\n    }\n}\n\nstruct ExtendFunc<F>(F);\nimpl<T, F: FnMut() -> T> ExtendWith<T> for ExtendFunc<F> {\n    fn next(&mut self) -> T {\n        (self.0)()\n    }\n    fn last(mut self) -> T {\n        (self.0)()\n    }\n}\n\nimpl<T, A: Allocator> Vec<T, A> {\n    #[cfg(not(no_global_oom_handling))]\n    /// Extend the vector by `n` values, using the given generator.\n    fn extend_with<E: ExtendWith<T>>(&mut self, n: usize, mut value: E) {\n        self.reserve(n);\n\n        unsafe {\n            let mut ptr = self.as_mut_ptr().add(self.len());\n            // Use SetLenOnDrop to work around bug where compiler\n            // may not realize the store through `ptr` through self.set_len()\n            // don't alias.\n            let mut local_len = SetLenOnDrop::new(&mut self.len);\n\n            // Write all elements except the last one\n            for _ in 1..n {\n                ptr::write(ptr, value.next());\n                ptr = ptr.offset(1);\n                // Increment the length in every step in case next() panics\n                local_len.increment_len(1);\n            }\n\n            if n > 0 {\n                // We can write the last element directly without cloning needlessly\n                ptr::write(ptr, value.last());\n                local_len.increment_len(1);\n            }\n\n            // len set by scope guard\n        }\n    }\n}\n\nimpl<T: PartialEq, A: Allocator> Vec<T, A> {\n    /// Removes consecutive repeated elements in the vector according to the\n    /// [`PartialEq`] trait implementation.\n    ///\n    /// If the vector is sorted, this removes all duplicates.\n    ///\n    /// # Examples\n    ///\n    /// ```\n    /// let mut vec = vec![1, 2, 2, 3, 2];\n    ///\n    /// vec.dedup();\n    ///\n    /// assert_eq!(vec, [1, 2, 3, 2]);\n    /// ```\n    #[stable(feature = \"rust1\", since = \"1.0.0\")]\n    #[inline]\n    pub fn dedup(&mut self) {\n        self.dedup_by(|a, b| a == b)\n    }\n}\n\n////////////////////////////////////////////////////////////////////////////////\n// Internal methods and functions\n////////////////////////////////////////////////////////////////////////////////\n\n#[doc(hidden)]\n#[cfg(not(no_global_oom_handling))]\n#[stable(feature = \"rust1\", since = \"1.0.0\")]\npub fn from_elem<T: Clone>(elem: T, n: usize) -> Vec<T> {\n    <T as SpecFromElem>::from_elem(elem, n, Global)\n}\n\n#[doc(hidden)]\n#[cfg(not(no_global_oom_handling))]\n#[unstable(feature = \"allocator_api\", issue = \"32838\")]\npub fn from_elem_in<T: Clone, A: Allocator>(elem: T, n: usize, alloc: A) -> Vec<T, A> {\n    <T as SpecFromElem>::from_elem(elem, n, alloc)\n}\n\ntrait ExtendFromWithinSpec {\n    /// # Safety\n    ///\n    /// - `src` needs to be valid index\n    /// - `self.capacity() - self.len()` must be `>= src.len()`\n    unsafe fn spec_extend_from_within(&mut self, src: Range<usize>);\n}\n\nimpl<T: Clone, A: Allocator> ExtendFromWithinSpec for Vec<T, A> {\n    default unsafe fn spec_extend_from_within(&mut self, src: Range<usize>) {\n        // SAFETY:\n        // - len is increased only after initializing elements\n        let (this, spare, len) = unsafe { self.split_at_spare_mut_with_len() };\n\n        // SAFETY:\n        // - caller guaratees that src is a valid index\n        let to_clone = unsafe { this.get_unchecked(src) };\n\n        iter::zip(to_clone, spare)\n            .map(|(src, dst)| dst.write(src.clone()))\n            // Note:\n            // - Element was just initialized with `MaybeUninit::write`, so it's ok to increase len\n            // - len is increased after each element to prevent leaks (see issue #82533)\n            .for_each(|_| *len += 1);\n    }\n}\n\nimpl<T: Copy, A: Allocator> ExtendFromWithinSpec for Vec<T, A> {\n    unsafe fn spec_extend_from_within(&mut self, src: Range<usize>) {\n        let count = src.len();\n        {\n            let (init, spare) = self.split_at_spare_mut();\n\n            // SAFETY:\n            // - caller guaratees that `src` is a valid index\n            let source = unsafe { init.get_unchecked(src) };\n\n            // SAFETY:\n            // - Both pointers are created from unique slice references (`&mut [_]`)\n            //   so they are valid and do not overlap.\n            // - Elements are :Copy so it's OK to to copy them, without doing\n            //   anything with the original values\n            // - `count` is equal to the len of `source`, so source is valid for\n            //   `count` reads\n            // - `.reserve(count)` guarantees that `spare.len() >= count` so spare\n            //   is valid for `count` writes\n            unsafe { ptr::copy_nonoverlapping(source.as_ptr(), spare.as_mut_ptr() as _, count) };\n        }\n\n        // SAFETY:\n        // - The elements were just initialized by `copy_nonoverlapping`\n        self.len += count;\n    }\n}\n\n////////////////////////////////////////////////////////////////////////////////\n// Common trait implementations for Vec\n////////////////////////////////////////////////////////////////////////////////\n\n#[stable(feature = \"rust1\", since = \"1.0.0\")]\nimpl<T, A: Allocator> ops::Deref for Vec<T, A> {\n    type Target = [T];\n\n    fn deref(&self) -> &[T] {\n        unsafe { slice::from_raw_parts(self.as_ptr(), self.len) }\n    }\n}\n\n#[stable(feature = \"rust1\", since = \"1.0.0\")]\nimpl<T, A: Allocator> ops::DerefMut for Vec<T, A> {\n    fn deref_mut(&mut self) -> &mut [T] {\n        unsafe { slice::from_raw_parts_mut(self.as_mut_ptr(), self.len) }\n    }\n}\n\n#[cfg(not(no_global_oom_handling))]\n#[stable(feature = \"rust1\", since = \"1.0.0\")]\nimpl<T: Clone, A: Allocator + Clone> Clone for Vec<T, A> {\n    #[cfg(not(test))]\n    fn clone(&self) -> Self {\n        let alloc = self.allocator().clone();\n        <[T]>::to_vec_in(&**self, alloc)\n    }\n\n    // HACK(japaric): with cfg(test) the inherent `[T]::to_vec` method, which is\n    // required for this method definition, is not available. Instead use the\n    // `slice::to_vec`  function which is only available with cfg(test)\n    // NB see the slice::hack module in slice.rs for more information\n    #[cfg(test)]\n    fn clone(&self) -> Self {\n        let alloc = self.allocator().clone();\n        crate::slice::to_vec(&**self, alloc)\n    }\n\n    fn clone_from(&mut self, other: &Self) {\n        // drop anything that will not be overwritten\n        self.truncate(other.len());\n\n        // self.len <= other.len due to the truncate above, so the\n        // slices here are always in-bounds.\n        let (init, tail) = other.split_at(self.len());\n\n        // reuse the contained values' allocations/resources.\n        self.clone_from_slice(init);\n        self.extend_from_slice(tail);\n    }\n}\n\n/// The hash of a vector is the same as that of the corresponding slice,\n/// as required by the `core::borrow::Borrow` implementation.\n///\n/// ```\n/// #![feature(build_hasher_simple_hash_one)]\n/// use std::hash::BuildHasher;\n///\n/// let b = std::collections::hash_map::RandomState::new();\n/// let v: Vec<u8> = vec![0xa8, 0x3c, 0x09];\n/// let s: &[u8] = &[0xa8, 0x3c, 0x09];\n/// assert_eq!(b.hash_one(v), b.hash_one(s));\n/// ```\n#[stable(feature = \"rust1\", since = \"1.0.0\")]\nimpl<T: Hash, A: Allocator> Hash for Vec<T, A> {\n    #[inline]\n    fn hash<H: Hasher>(&self, state: &mut H) {\n        Hash::hash(&**self, state)\n    }\n}\n\n#[stable(feature = \"rust1\", since = \"1.0.0\")]\n#[rustc_on_unimplemented(\n    message = \"vector indices are of type `usize` or ranges of `usize`\",\n    label = \"vector indices are of type `usize` or ranges of `usize`\"\n)]\nimpl<T, I: SliceIndex<[T]>, A: Allocator> Index<I> for Vec<T, A> {\n    type Output = I::Output;\n\n    #[inline]\n    fn index(&self, index: I) -> &Self::Output {\n        Index::index(&**self, index)\n    }\n}\n\n#[stable(feature = \"rust1\", since = \"1.0.0\")]\n#[rustc_on_unimplemented(\n    message = \"vector indices are of type `usize` or ranges of `usize`\",\n    label = \"vector indices are of type `usize` or ranges of `usize`\"\n)]\nimpl<T, I: SliceIndex<[T]>, A: Allocator> IndexMut<I> for Vec<T, A> {\n    #[inline]\n    fn index_mut(&mut self, index: I) -> &mut Self::Output {\n        IndexMut::index_mut(&mut **self, index)\n    }\n}\n\n#[cfg(not(no_global_oom_handling))]\n#[stable(feature = \"rust1\", since = \"1.0.0\")]\nimpl<T> FromIterator<T> for Vec<T> {\n    #[inline]\n    fn from_iter<I: IntoIterator<Item = T>>(iter: I) -> Vec<T> {\n        <Self as SpecFromIter<T, I::IntoIter>>::from_iter(iter.into_iter())\n    }\n}\n\n#[stable(feature = \"rust1\", since = \"1.0.0\")]\nimpl<T, A: Allocator> IntoIterator for Vec<T, A> {\n    type Item = T;\n    type IntoIter = IntoIter<T, A>;\n\n    /// Creates a consuming iterator, that is, one that moves each value out of\n    /// the vector (from start to end). The vector cannot be used after calling\n    /// this.\n    ///\n    /// # Examples\n    ///\n    /// ```\n    /// let v = vec![\"a\".to_string(), \"b\".to_string()];\n    /// for s in v.into_iter() {\n    ///     // s has type String, not &String\n    ///     println!(\"{}\", s);\n    /// }\n    /// ```\n    #[inline]\n    fn into_iter(self) -> IntoIter<T, A> {\n        unsafe {\n            let mut me = ManuallyDrop::new(self);\n            let alloc = ptr::read(me.allocator());\n            let begin = me.as_mut_ptr();\n            let end = if mem::size_of::<T>() == 0 {\n                arith_offset(begin as *const i8, me.len() as isize) as *const T\n            } else {\n                begin.add(me.len()) as *const T\n            };\n            let cap = me.buf.capacity();\n            IntoIter {\n                buf: NonNull::new_unchecked(begin),\n                phantom: PhantomData,\n                cap,\n                alloc,\n                ptr: begin,\n                end,\n            }\n        }\n    }\n}\n\n#[stable(feature = \"rust1\", since = \"1.0.0\")]\nimpl<'a, T, A: Allocator> IntoIterator for &'a Vec<T, A> {\n    type Item = &'a T;\n    type IntoIter = slice::Iter<'a, T>;\n\n    fn into_iter(self) -> slice::Iter<'a, T> {\n        self.iter()\n    }\n}\n\n#[stable(feature = \"rust1\", since = \"1.0.0\")]\nimpl<'a, T, A: Allocator> IntoIterator for &'a mut Vec<T, A> {\n    type Item = &'a mut T;\n    type IntoIter = slice::IterMut<'a, T>;\n\n    fn into_iter(self) -> slice::IterMut<'a, T> {\n        self.iter_mut()\n    }\n}\n\n#[cfg(not(no_global_oom_handling))]\n#[stable(feature = \"rust1\", since = \"1.0.0\")]\nimpl<T, A: Allocator> Extend<T> for Vec<T, A> {\n    #[inline]\n    fn extend<I: IntoIterator<Item = T>>(&mut self, iter: I) {\n        <Self as SpecExtend<T, I::IntoIter>>::spec_extend(self, iter.into_iter())\n    }\n\n    #[inline]\n    fn extend_one(&mut self, item: T) {\n        self.push(item);\n    }\n\n    #[inline]\n    fn extend_reserve(&mut self, additional: usize) {\n        self.reserve(additional);\n    }\n}\n\nimpl<T, A: Allocator> Vec<T, A> {\n    // leaf method to which various SpecFrom/SpecExtend implementations delegate when\n    // they have no further optimizations to apply\n    #[cfg(not(no_global_oom_handling))]\n    fn extend_desugared<I: Iterator<Item = T>>(&mut self, mut iterator: I) {\n        // This is the case for a general iterator.\n        //\n        // This function should be the moral equivalent of:\n        //\n        //      for item in iterator {\n        //          self.push(item);\n        //      }\n        while let Some(element) = iterator.next() {\n            let len = self.len();\n            if len == self.capacity() {\n                let (lower, _) = iterator.size_hint();\n                self.reserve(lower.saturating_add(1));\n            }\n            unsafe {\n                ptr::write(self.as_mut_ptr().add(len), element);\n                // Since next() executes user code which can panic we have to bump the length\n                // after each step.\n                // NB can't overflow since we would have had to alloc the address space\n                self.set_len(len + 1);\n            }\n        }\n    }\n\n    /// Creates a splicing iterator that replaces the specified range in the vector\n    /// with the given `replace_with` iterator and yields the removed items.\n    /// `replace_with` does not need to be the same length as `range`.\n    ///\n    /// `range` is removed even if the iterator is not consumed until the end.\n    ///\n    /// It is unspecified how many elements are removed from the vector\n    /// if the `Splice` value is leaked.\n    ///\n    /// The input iterator `replace_with` is only consumed when the `Splice` value is dropped.\n    ///\n    /// This is optimal if:\n    ///\n    /// * The tail (elements in the vector after `range`) is empty,\n    /// * or `replace_with` yields fewer or equal elements than `range`’s length\n    /// * or the lower bound of its `size_hint()` is exact.\n    ///\n    /// Otherwise, a temporary vector is allocated and the tail is moved twice.\n    ///\n    /// # Panics\n    ///\n    /// Panics if the starting point is greater than the end point or if\n    /// the end point is greater than the length of the vector.\n    ///\n    /// # Examples\n    ///\n    /// ```\n    /// let mut v = vec![1, 2, 3];\n    /// let new = [7, 8];\n    /// let u: Vec<_> = v.splice(..2, new).collect();\n    /// assert_eq!(v, &[7, 8, 3]);\n    /// assert_eq!(u, &[1, 2]);\n    /// ```\n    #[cfg(not(no_global_oom_handling))]\n    #[inline]\n    #[stable(feature = \"vec_splice\", since = \"1.21.0\")]\n    pub fn splice<R, I>(&mut self, range: R, replace_with: I) -> Splice<'_, I::IntoIter, A>\n    where\n        R: RangeBounds<usize>,\n        I: IntoIterator<Item = T>,\n    {\n        Splice { drain: self.drain(range), replace_with: replace_with.into_iter() }\n    }\n\n    /// Creates an iterator which uses a closure to determine if an element should be removed.\n    ///\n    /// If the closure returns true, then the element is removed and yielded.\n    /// If the closure returns false, the element will remain in the vector and will not be yielded\n    /// by the iterator.\n    ///\n    /// Using this method is equivalent to the following code:\n    ///\n    /// ```\n    /// # let some_predicate = |x: &mut i32| { *x == 2 || *x == 3 || *x == 6 };\n    /// # let mut vec = vec![1, 2, 3, 4, 5, 6];\n    /// let mut i = 0;\n    /// while i < vec.len() {\n    ///     if some_predicate(&mut vec[i]) {\n    ///         let val = vec.remove(i);\n    ///         // your code here\n    ///     } else {\n    ///         i += 1;\n    ///     }\n    /// }\n    ///\n    /// # assert_eq!(vec, vec![1, 4, 5]);\n    /// ```\n    ///\n    /// But `drain_filter` is easier to use. `drain_filter` is also more efficient,\n    /// because it can backshift the elements of the array in bulk.\n    ///\n    /// Note that `drain_filter` also lets you mutate every element in the filter closure,\n    /// regardless of whether you choose to keep or remove it.\n    ///\n    /// # Examples\n    ///\n    /// Splitting an array into evens and odds, reusing the original allocation:\n    ///\n    /// ```\n    /// #![feature(drain_filter)]\n    /// let mut numbers = vec![1, 2, 3, 4, 5, 6, 8, 9, 11, 13, 14, 15];\n    ///\n    /// let evens = numbers.drain_filter(|x| *x % 2 == 0).collect::<Vec<_>>();\n    /// let odds = numbers;\n    ///\n    /// assert_eq!(evens, vec![2, 4, 6, 8, 14]);\n    /// assert_eq!(odds, vec![1, 3, 5, 9, 11, 13, 15]);\n    /// ```\n    #[unstable(feature = \"drain_filter\", reason = \"recently added\", issue = \"43244\")]\n    pub fn drain_filter<F>(&mut self, filter: F) -> DrainFilter<'_, T, F, A>\n    where\n        F: FnMut(&mut T) -> bool,\n    {\n        let old_len = self.len();\n\n        // Guard against us getting leaked (leak amplification)\n        unsafe {\n            self.set_len(0);\n        }\n\n        DrainFilter { vec: self, idx: 0, del: 0, old_len, pred: filter, panic_flag: false }\n    }\n}\n\n/// Extend implementation that copies elements out of references before pushing them onto the Vec.\n///\n/// This implementation is specialized for slice iterators, where it uses [`copy_from_slice`] to\n/// append the entire slice at once.\n///\n/// [`copy_from_slice`]: slice::copy_from_slice\n#[cfg(not(no_global_oom_handling))]\n#[stable(feature = \"extend_ref\", since = \"1.2.0\")]\nimpl<'a, T: Copy + 'a, A: Allocator + 'a> Extend<&'a T> for Vec<T, A> {\n    fn extend<I: IntoIterator<Item = &'a T>>(&mut self, iter: I) {\n        self.spec_extend(iter.into_iter())\n    }\n\n    #[inline]\n    fn extend_one(&mut self, &item: &'a T) {\n        self.push(item);\n    }\n\n    #[inline]\n    fn extend_reserve(&mut self, additional: usize) {\n        self.reserve(additional);\n    }\n}\n\n/// Implements comparison of vectors, [lexicographically](core::cmp::Ord#lexicographical-comparison).\n#[stable(feature = \"rust1\", since = \"1.0.0\")]\nimpl<T: PartialOrd, A: Allocator> PartialOrd for Vec<T, A> {\n    #[inline]\n    fn partial_cmp(&self, other: &Self) -> Option<Ordering> {\n        PartialOrd::partial_cmp(&**self, &**other)\n    }\n}\n\n#[stable(feature = \"rust1\", since = \"1.0.0\")]\nimpl<T: Eq, A: Allocator> Eq for Vec<T, A> {}\n\n/// Implements ordering of vectors, [lexicographically](core::cmp::Ord#lexicographical-comparison).\n#[stable(feature = \"rust1\", since = \"1.0.0\")]\nimpl<T: Ord, A: Allocator> Ord for Vec<T, A> {\n    #[inline]\n    fn cmp(&self, other: &Self) -> Ordering {\n        Ord::cmp(&**self, &**other)\n    }\n}\n\n#[stable(feature = \"rust1\", since = \"1.0.0\")]\nunsafe impl<#[may_dangle] T, A: Allocator> Drop for Vec<T, A> {\n    fn drop(&mut self) {\n        unsafe {\n            // use drop for [T]\n            // use a raw slice to refer to the elements of the vector as weakest necessary type;\n            // could avoid questions of validity in certain cases\n            ptr::drop_in_place(ptr::slice_from_raw_parts_mut(self.as_mut_ptr(), self.len))\n        }\n        // RawVec handles deallocation\n    }\n}\n\n#[stable(feature = \"rust1\", since = \"1.0.0\")]\nimpl<T> Default for Vec<T> {\n    /// Creates an empty `Vec<T>`.\n    fn default() -> Vec<T> {\n        Vec::new()\n    }\n}\n\n#[stable(feature = \"rust1\", since = \"1.0.0\")]\nimpl<T: fmt::Debug, A: Allocator> fmt::Debug for Vec<T, A> {\n    fn fmt(&self, f: &mut fmt::Formatter<'_>) -> fmt::Result {\n        fmt::Debug::fmt(&**self, f)\n    }\n}\n\n#[stable(feature = \"rust1\", since = \"1.0.0\")]\nimpl<T, A: Allocator> AsRef<Vec<T, A>> for Vec<T, A> {\n    fn as_ref(&self) -> &Vec<T, A> {\n        self\n    }\n}\n\n#[stable(feature = \"vec_as_mut\", since = \"1.5.0\")]\nimpl<T, A: Allocator> AsMut<Vec<T, A>> for Vec<T, A> {\n    fn as_mut(&mut self) -> &mut Vec<T, A> {\n        self\n    }\n}\n\n#[stable(feature = \"rust1\", since = \"1.0.0\")]\nimpl<T, A: Allocator> AsRef<[T]> for Vec<T, A> {\n    fn as_ref(&self) -> &[T] {\n        self\n    }\n}\n\n#[stable(feature = \"vec_as_mut\", since = \"1.5.0\")]\nimpl<T, A: Allocator> AsMut<[T]> for Vec<T, A> {\n    fn as_mut(&mut self) -> &mut [T] {\n        self\n    }\n}\n\n#[cfg(not(no_global_oom_handling))]\n#[stable(feature = \"rust1\", since = \"1.0.0\")]\nimpl<T: Clone> From<&[T]> for Vec<T> {\n    /// Allocate a `Vec<T>` and fill it by cloning `s`'s items.\n    ///\n    /// # Examples\n    ///\n    /// ```\n    /// assert_eq!(Vec::from(&[1, 2, 3][..]), vec![1, 2, 3]);\n    /// ```\n    #[cfg(not(test))]\n    fn from(s: &[T]) -> Vec<T> {\n        s.to_vec()\n    }\n    #[cfg(test)]\n    fn from(s: &[T]) -> Vec<T> {\n        crate::slice::to_vec(s, Global)\n    }\n}\n\n#[cfg(not(no_global_oom_handling))]\n#[stable(feature = \"vec_from_mut\", since = \"1.19.0\")]\nimpl<T: Clone> From<&mut [T]> for Vec<T> {\n    /// Allocate a `Vec<T>` and fill it by cloning `s`'s items.\n    ///\n    /// # Examples\n    ///\n    /// ```\n    /// assert_eq!(Vec::from(&mut [1, 2, 3][..]), vec![1, 2, 3]);\n    /// ```\n    #[cfg(not(test))]\n    fn from(s: &mut [T]) -> Vec<T> {\n        s.to_vec()\n    }\n    #[cfg(test)]\n    fn from(s: &mut [T]) -> Vec<T> {\n        crate::slice::to_vec(s, Global)\n    }\n}\n\n#[stable(feature = \"vec_from_array\", since = \"1.44.0\")]\nimpl<T, const N: usize> From<[T; N]> for Vec<T> {\n    #[cfg(not(test))]\n    fn from(s: [T; N]) -> Vec<T> {\n        <[T]>::into_vec(box s)\n    }\n    /// Allocate a `Vec<T>` and move `s`'s items into it.\n    ///\n    /// # Examples\n    ///\n    /// ```\n    /// assert_eq!(Vec::from([1, 2, 3]), vec![1, 2, 3]);\n    /// ```\n    #[cfg(test)]\n    fn from(s: [T; N]) -> Vec<T> {\n        crate::slice::into_vec(box s)\n    }\n}\n\n#[stable(feature = \"vec_from_cow_slice\", since = \"1.14.0\")]\nimpl<'a, T> From<Cow<'a, [T]>> for Vec<T>\nwhere\n    [T]: ToOwned<Owned = Vec<T>>,\n{\n    /// Convert a clone-on-write slice into a vector.\n    ///\n    /// If `s` already owns a `Vec<T>`, it will be returned directly.\n    /// If `s` is borrowing a slice, a new `Vec<T>` will be allocated and\n    /// filled by cloning `s`'s items into it.\n    ///\n    /// # Examples\n    ///\n    /// ```\n    /// # use std::borrow::Cow;\n    /// let o: Cow<[i32]> = Cow::Owned(vec![1, 2, 3]);\n    /// let b: Cow<[i32]> = Cow::Borrowed(&[1, 2, 3]);\n    /// assert_eq!(Vec::from(o), Vec::from(b));\n    /// ```\n    fn from(s: Cow<'a, [T]>) -> Vec<T> {\n        s.into_owned()\n    }\n}\n\n// note: test pulls in libstd, which causes errors here\n#[cfg(not(test))]\n#[stable(feature = \"vec_from_box\", since = \"1.18.0\")]\nimpl<T, A: Allocator> From<Box<[T], A>> for Vec<T, A> {\n    /// Convert a boxed slice into a vector by transferring ownership of\n    /// the existing heap allocation.\n    ///\n    /// # Examples\n    ///\n    /// ```\n    /// let b: Box<[i32]> = vec![1, 2, 3].into_boxed_slice();\n    /// assert_eq!(Vec::from(b), vec![1, 2, 3]);\n    /// ```\n    fn from(s: Box<[T], A>) -> Self {\n        s.into_vec()\n    }\n}\n\n// note: test pulls in libstd, which causes errors here\n#[cfg(not(no_global_oom_handling))]\n#[cfg(not(test))]\n#[stable(feature = \"box_from_vec\", since = \"1.20.0\")]\nimpl<T, A: Allocator> From<Vec<T, A>> for Box<[T], A> {\n    /// Convert a vector into a boxed slice.\n    ///\n    /// If `v` has excess capacity, its items will be moved into a\n    /// newly-allocated buffer with exactly the right capacity.\n    ///\n    /// # Examples\n    ///\n    /// ```\n    /// assert_eq!(Box::from(vec![1, 2, 3]), vec![1, 2, 3].into_boxed_slice());\n    /// ```\n    fn from(v: Vec<T, A>) -> Self {\n        v.into_boxed_slice()\n    }\n}\n\n#[cfg(not(no_global_oom_handling))]\n#[stable(feature = \"rust1\", since = \"1.0.0\")]\nimpl From<&str> for Vec<u8> {\n    /// Allocate a `Vec<u8>` and fill it with a UTF-8 string.\n    ///\n    /// # Examples\n    ///\n    /// ```\n    /// assert_eq!(Vec::from(\"123\"), vec![b'1', b'2', b'3']);\n    /// ```\n    fn from(s: &str) -> Vec<u8> {\n        From::from(s.as_bytes())\n    }\n}\n\n#[stable(feature = \"array_try_from_vec\", since = \"1.48.0\")]\nimpl<T, A: Allocator, const N: usize> TryFrom<Vec<T, A>> for [T; N] {\n    type Error = Vec<T, A>;\n\n    /// Gets the entire contents of the `Vec<T>` as an array,\n    /// if its size exactly matches that of the requested array.\n    ///\n    /// # Examples\n    ///\n    /// ```\n    /// use std::convert::TryInto;\n    /// assert_eq!(vec![1, 2, 3].try_into(), Ok([1, 2, 3]));\n    /// assert_eq!(<Vec<i32>>::new().try_into(), Ok([]));\n    /// ```\n    ///\n    /// If the length doesn't match, the input comes back in `Err`:\n    /// ```\n    /// use std::convert::TryInto;\n    /// let r: Result<[i32; 4], _> = (0..10).collect::<Vec<_>>().try_into();\n    /// assert_eq!(r, Err(vec![0, 1, 2, 3, 4, 5, 6, 7, 8, 9]));\n    /// ```\n    ///\n    /// If you're fine with just getting a prefix of the `Vec<T>`,\n    /// you can call [`.truncate(N)`](Vec::truncate) first.\n    /// ```\n    /// use std::convert::TryInto;\n    /// let mut v = String::from(\"hello world\").into_bytes();\n    /// v.sort();\n    /// v.truncate(2);\n    /// let [a, b]: [_; 2] = v.try_into().unwrap();\n    /// assert_eq!(a, b' ');\n    /// assert_eq!(b, b'd');\n    /// ```\n    fn try_from(mut vec: Vec<T, A>) -> Result<[T; N], Vec<T, A>> {\n        if vec.len() != N {\n            return Err(vec);\n        }\n\n        // SAFETY: `.set_len(0)` is always sound.\n        unsafe { vec.set_len(0) };\n\n        // SAFETY: A `Vec`'s pointer is always aligned properly, and\n        // the alignment the array needs is the same as the items.\n        // We checked earlier that we have sufficient items.\n        // The items will not double-drop as the `set_len`\n        // tells the `Vec` not to also drop them.\n        let array = unsafe { ptr::read(vec.as_ptr() as *const [T; N]) };\n        Ok(array)\n    }\n}\n"],[2054,"use crate::alloc::{Allocator, Global};\nuse core::ptr::{self};\nuse core::slice::{self};\n\nuse super::{Drain, Vec};\n\n/// A splicing iterator for `Vec`.\n///\n/// This struct is created by [`Vec::splice()`].\n/// See its documentation for more.\n///\n/// # Example\n///\n/// ```\n/// let mut v = vec![0, 1, 2];\n/// let new = [7, 8];\n/// let iter: std::vec::Splice<_> = v.splice(1.., new);\n/// ```\n#[derive(Debug)]\n#[stable(feature = \"vec_splice\", since = \"1.21.0\")]\npub struct Splice<\n    'a,\n    I: Iterator + 'a,\n    #[unstable(feature = \"allocator_api\", issue = \"32838\")] A: Allocator + 'a = Global,\n> {\n    pub(super) drain: Drain<'a, I::Item, A>,\n    pub(super) replace_with: I,\n}\n\n#[stable(feature = \"vec_splice\", since = \"1.21.0\")]\nimpl<I: Iterator, A: Allocator> Iterator for Splice<'_, I, A> {\n    type Item = I::Item;\n\n    fn next(&mut self) -> Option<Self::Item> {\n        self.drain.next()\n    }\n\n    fn size_hint(&self) -> (usize, Option<usize>) {\n        self.drain.size_hint()\n    }\n}\n\n#[stable(feature = \"vec_splice\", since = \"1.21.0\")]\nimpl<I: Iterator, A: Allocator> DoubleEndedIterator for Splice<'_, I, A> {\n    fn next_back(&mut self) -> Option<Self::Item> {\n        self.drain.next_back()\n    }\n}\n\n#[stable(feature = \"vec_splice\", since = \"1.21.0\")]\nimpl<I: Iterator, A: Allocator> ExactSizeIterator for Splice<'_, I, A> {}\n\n#[stable(feature = \"vec_splice\", since = \"1.21.0\")]\nimpl<I: Iterator, A: Allocator> Drop for Splice<'_, I, A> {\n    fn drop(&mut self) {\n        self.drain.by_ref().for_each(drop);\n\n        unsafe {\n            if self.drain.tail_len == 0 {\n                self.drain.vec.as_mut().extend(self.replace_with.by_ref());\n                return;\n            }\n\n            // First fill the range left by drain().\n            if !self.drain.fill(&mut self.replace_with) {\n                return;\n            }\n\n            // There may be more elements. Use the lower bound as an estimate.\n            // FIXME: Is the upper bound a better guess? Or something else?\n            let (lower_bound, _upper_bound) = self.replace_with.size_hint();\n            if lower_bound > 0 {\n                self.drain.move_tail(lower_bound);\n                if !self.drain.fill(&mut self.replace_with) {\n                    return;\n                }\n            }\n\n            // Collect any remaining elements.\n            // This is a zero-length vector which does not allocate if `lower_bound` was exact.\n            let mut collected = self.replace_with.by_ref().collect::<Vec<I::Item>>().into_iter();\n            // Now we have an exact count.\n            if collected.len() > 0 {\n                self.drain.move_tail(collected.len());\n                let filled = self.drain.fill(&mut collected);\n                debug_assert!(filled);\n                debug_assert_eq!(collected.len(), 0);\n            }\n        }\n        // Let `Drain::drop` move the tail back if necessary and restore `vec.len`.\n    }\n}\n\n/// Private helper methods for `Splice::drop`\nimpl<T, A: Allocator> Drain<'_, T, A> {\n    /// The range from `self.vec.len` to `self.tail_start` contains elements\n    /// that have been moved out.\n    /// Fill that range as much as possible with new elements from the `replace_with` iterator.\n    /// Returns `true` if we filled the entire range. (`replace_with.next()` didn’t return `None`.)\n    unsafe fn fill<I: Iterator<Item = T>>(&mut self, replace_with: &mut I) -> bool {\n        let vec = unsafe { self.vec.as_mut() };\n        let range_start = vec.len;\n        let range_end = self.tail_start;\n        let range_slice = unsafe {\n            slice::from_raw_parts_mut(vec.as_mut_ptr().add(range_start), range_end - range_start)\n        };\n\n        for place in range_slice {\n            if let Some(new_item) = replace_with.next() {\n                unsafe { ptr::write(place, new_item) };\n                vec.len += 1;\n            } else {\n                return false;\n            }\n        }\n        true\n    }\n\n    /// Makes room for inserting more elements before the tail.\n    unsafe fn move_tail(&mut self, additional: usize) {\n        let vec = unsafe { self.vec.as_mut() };\n        let len = self.tail_start + self.tail_len;\n        vec.buf.reserve(len, additional);\n\n        let new_tail_start = self.tail_start + additional;\n        unsafe {\n            let src = vec.as_ptr().add(self.tail_start);\n            let dst = vec.as_mut_ptr().add(new_tail_start);\n            ptr::copy(src, dst, self.tail_len);\n        }\n        self.tail_start = new_tail_start;\n    }\n}\n"],[2055,"use crate::alloc::{Allocator, Global};\nuse core::fmt;\nuse core::iter::{FusedIterator, TrustedLen};\nuse core::mem::{self};\nuse core::ptr::{self, NonNull};\nuse core::slice::{self};\n\nuse super::Vec;\n\n/// A draining iterator for `Vec<T>`.\n///\n/// This `struct` is created by [`Vec::drain`].\n/// See its documentation for more.\n///\n/// # Example\n///\n/// ```\n/// let mut v = vec![0, 1, 2];\n/// let iter: std::vec::Drain<_> = v.drain(..);\n/// ```\n#[stable(feature = \"drain\", since = \"1.6.0\")]\npub struct Drain<\n    'a,\n    T: 'a,\n    #[unstable(feature = \"allocator_api\", issue = \"32838\")] A: Allocator + 'a = Global,\n> {\n    /// Index of tail to preserve\n    pub(super) tail_start: usize,\n    /// Length of tail\n    pub(super) tail_len: usize,\n    /// Current remaining range to remove\n    pub(super) iter: slice::Iter<'a, T>,\n    pub(super) vec: NonNull<Vec<T, A>>,\n}\n\n#[stable(feature = \"collection_debug\", since = \"1.17.0\")]\nimpl<T: fmt::Debug, A: Allocator> fmt::Debug for Drain<'_, T, A> {\n    fn fmt(&self, f: &mut fmt::Formatter<'_>) -> fmt::Result {\n        f.debug_tuple(\"Drain\").field(&self.iter.as_slice()).finish()\n    }\n}\n\nimpl<'a, T, A: Allocator> Drain<'a, T, A> {\n    /// Returns the remaining items of this iterator as a slice.\n    ///\n    /// # Examples\n    ///\n    /// ```\n    /// let mut vec = vec!['a', 'b', 'c'];\n    /// let mut drain = vec.drain(..);\n    /// assert_eq!(drain.as_slice(), &['a', 'b', 'c']);\n    /// let _ = drain.next().unwrap();\n    /// assert_eq!(drain.as_slice(), &['b', 'c']);\n    /// ```\n    #[stable(feature = \"vec_drain_as_slice\", since = \"1.46.0\")]\n    pub fn as_slice(&self) -> &[T] {\n        self.iter.as_slice()\n    }\n\n    /// Returns a reference to the underlying allocator.\n    #[unstable(feature = \"allocator_api\", issue = \"32838\")]\n    #[inline]\n    pub fn allocator(&self) -> &A {\n        unsafe { self.vec.as_ref().allocator() }\n    }\n}\n\n#[stable(feature = \"vec_drain_as_slice\", since = \"1.46.0\")]\nimpl<'a, T, A: Allocator> AsRef<[T]> for Drain<'a, T, A> {\n    fn as_ref(&self) -> &[T] {\n        self.as_slice()\n    }\n}\n\n#[stable(feature = \"drain\", since = \"1.6.0\")]\nunsafe impl<T: Sync, A: Sync + Allocator> Sync for Drain<'_, T, A> {}\n#[stable(feature = \"drain\", since = \"1.6.0\")]\nunsafe impl<T: Send, A: Send + Allocator> Send for Drain<'_, T, A> {}\n\n#[stable(feature = \"drain\", since = \"1.6.0\")]\nimpl<T, A: Allocator> Iterator for Drain<'_, T, A> {\n    type Item = T;\n\n    #[inline]\n    fn next(&mut self) -> Option<T> {\n        self.iter.next().map(|elt| unsafe { ptr::read(elt as *const _) })\n    }\n\n    fn size_hint(&self) -> (usize, Option<usize>) {\n        self.iter.size_hint()\n    }\n}\n\n#[stable(feature = \"drain\", since = \"1.6.0\")]\nimpl<T, A: Allocator> DoubleEndedIterator for Drain<'_, T, A> {\n    #[inline]\n    fn next_back(&mut self) -> Option<T> {\n        self.iter.next_back().map(|elt| unsafe { ptr::read(elt as *const _) })\n    }\n}\n\n#[stable(feature = \"drain\", since = \"1.6.0\")]\nimpl<T, A: Allocator> Drop for Drain<'_, T, A> {\n    fn drop(&mut self) {\n        /// Continues dropping the remaining elements in the `Drain`, then moves back the\n        /// un-`Drain`ed elements to restore the original `Vec`.\n        struct DropGuard<'r, 'a, T, A: Allocator>(&'r mut Drain<'a, T, A>);\n\n        impl<'r, 'a, T, A: Allocator> Drop for DropGuard<'r, 'a, T, A> {\n            fn drop(&mut self) {\n                // Continue the same loop we have below. If the loop already finished, this does\n                // nothing.\n                self.0.for_each(drop);\n\n                if self.0.tail_len > 0 {\n                    unsafe {\n                        let source_vec = self.0.vec.as_mut();\n                        // memmove back untouched tail, update to new length\n                        let start = source_vec.len();\n                        let tail = self.0.tail_start;\n                        if tail != start {\n                            let src = source_vec.as_ptr().add(tail);\n                            let dst = source_vec.as_mut_ptr().add(start);\n                            ptr::copy(src, dst, self.0.tail_len);\n                        }\n                        source_vec.set_len(start + self.0.tail_len);\n                    }\n                }\n            }\n        }\n\n        // exhaust self first\n        while let Some(item) = self.next() {\n            let guard = DropGuard(self);\n            drop(item);\n            mem::forget(guard);\n        }\n\n        // Drop a `DropGuard` to move back the non-drained tail of `self`.\n        DropGuard(self);\n    }\n}\n\n#[stable(feature = \"drain\", since = \"1.6.0\")]\nimpl<T, A: Allocator> ExactSizeIterator for Drain<'_, T, A> {\n    fn is_empty(&self) -> bool {\n        self.iter.is_empty()\n    }\n}\n\n#[unstable(feature = \"trusted_len\", issue = \"37572\")]\nunsafe impl<T, A: Allocator> TrustedLen for Drain<'_, T, A> {}\n\n#[stable(feature = \"fused\", since = \"1.26.0\")]\nimpl<T, A: Allocator> FusedIterator for Drain<'_, T, A> {}\n"],[2056,"use crate::alloc::Allocator;\nuse core::iter::TrustedLen;\nuse core::ptr::{self};\nuse core::slice::{self};\n\nuse super::{IntoIter, SetLenOnDrop, Vec};\n\n// Specialization trait used for Vec::extend\npub(super) trait SpecExtend<T, I> {\n    fn spec_extend(&mut self, iter: I);\n}\n\nimpl<T, I, A: Allocator> SpecExtend<T, I> for Vec<T, A>\nwhere\n    I: Iterator<Item = T>,\n{\n    default fn spec_extend(&mut self, iter: I) {\n        self.extend_desugared(iter)\n    }\n}\n\nimpl<T, I, A: Allocator> SpecExtend<T, I> for Vec<T, A>\nwhere\n    I: TrustedLen<Item = T>,\n{\n    default fn spec_extend(&mut self, iterator: I) {\n        // This is the case for a TrustedLen iterator.\n        let (low, high) = iterator.size_hint();\n        if let Some(additional) = high {\n            debug_assert_eq!(\n                low,\n                additional,\n                \"TrustedLen iterator's size hint is not exact: {:?}\",\n                (low, high)\n            );\n            self.reserve(additional);\n            unsafe {\n                let mut ptr = self.as_mut_ptr().add(self.len());\n                let mut local_len = SetLenOnDrop::new(&mut self.len);\n                iterator.for_each(move |element| {\n                    ptr::write(ptr, element);\n                    ptr = ptr.offset(1);\n                    // Since the loop executes user code which can panic we have to bump the pointer\n                    // after each step.\n                    // NB can't overflow since we would have had to alloc the address space\n                    local_len.increment_len(1);\n                });\n            }\n        } else {\n            // Per TrustedLen contract a `None` upper bound means that the iterator length\n            // truly exceeds usize::MAX, which would eventually lead to a capacity overflow anyway.\n            // Since the other branch already panics eagerly (via `reserve()`) we do the same here.\n            // This avoids additional codegen for a fallback code path which would eventually\n            // panic anyway.\n            panic!(\"capacity overflow\");\n        }\n    }\n}\n\nimpl<T, A: Allocator> SpecExtend<T, IntoIter<T>> for Vec<T, A> {\n    fn spec_extend(&mut self, mut iterator: IntoIter<T>) {\n        unsafe {\n            self.append_elements(iterator.as_slice() as _);\n        }\n        iterator.ptr = iterator.end;\n    }\n}\n\nimpl<'a, T: 'a, I, A: Allocator + 'a> SpecExtend<&'a T, I> for Vec<T, A>\nwhere\n    I: Iterator<Item = &'a T>,\n    T: Clone,\n{\n    default fn spec_extend(&mut self, iterator: I) {\n        self.spec_extend(iterator.cloned())\n    }\n}\n\nimpl<'a, T: 'a, A: Allocator + 'a> SpecExtend<&'a T, slice::Iter<'a, T>> for Vec<T, A>\nwhere\n    T: Copy,\n{\n    fn spec_extend(&mut self, iterator: slice::Iter<'a, T>) {\n        let slice = iterator.as_slice();\n        unsafe { self.append_elements(slice) };\n    }\n}\n"],[2057,"// Set the length of the vec when the `SetLenOnDrop` value goes out of scope.\n//\n// The idea is: The length field in SetLenOnDrop is a local variable\n// that the optimizer will see does not alias with any stores through the Vec's data\n// pointer. This is a workaround for alias analysis issue #32155\npub(super) struct SetLenOnDrop<'a> {\n    len: &'a mut usize,\n    local_len: usize,\n}\n\nimpl<'a> SetLenOnDrop<'a> {\n    #[inline]\n    pub(super) fn new(len: &'a mut usize) -> Self {\n        SetLenOnDrop { local_len: *len, len }\n    }\n\n    #[inline]\n    pub(super) fn increment_len(&mut self, increment: usize) {\n        self.local_len += increment;\n    }\n}\n\nimpl Drop for SetLenOnDrop<'_> {\n    #[inline]\n    fn drop(&mut self) {\n        *self.len = self.local_len;\n    }\n}\n"],[2058,"use core::iter::{InPlaceIterable, SourceIter, TrustedRandomAccess};\nuse core::mem::{self, ManuallyDrop};\nuse core::ptr::{self};\n\nuse super::{AsIntoIter, InPlaceDrop, SpecFromIter, SpecFromIterNested, Vec};\n\n/// Specialization marker for collecting an iterator pipeline into a Vec while reusing the\n/// source allocation, i.e. executing the pipeline in place.\n///\n/// The SourceIter parent trait is necessary for the specializing function to access the allocation\n/// which is to be reused. But it is not sufficient for the specialization to be valid. See\n/// additional bounds on the impl.\n#[rustc_unsafe_specialization_marker]\npub(super) trait SourceIterMarker: SourceIter<Source: AsIntoIter> {}\n\n// The std-internal SourceIter/InPlaceIterable traits are only implemented by chains of\n// Adapter<Adapter<Adapter<IntoIter>>> (all owned by core/std). Additional bounds\n// on the adapter implementations (beyond `impl<I: Trait> Trait for Adapter<I>`) only depend on other\n// traits already marked as specialization traits (Copy, TrustedRandomAccess, FusedIterator).\n// I.e. the marker does not depend on lifetimes of user-supplied types. Modulo the Copy hole, which\n// several other specializations already depend on.\nimpl<T> SourceIterMarker for T where T: SourceIter<Source: AsIntoIter> + InPlaceIterable {}\n\nimpl<T, I> SpecFromIter<T, I> for Vec<T>\nwhere\n    I: Iterator<Item = T> + SourceIterMarker,\n{\n    default fn from_iter(mut iterator: I) -> Self {\n        // Additional requirements which cannot expressed via trait bounds. We rely on const eval\n        // instead:\n        // a) no ZSTs as there would be no allocation to reuse and pointer arithmetic would panic\n        // b) size match as required by Alloc contract\n        // c) alignments match as required by Alloc contract\n        if mem::size_of::<T>() == 0\n            || mem::size_of::<T>()\n                != mem::size_of::<<<I as SourceIter>::Source as AsIntoIter>::Item>()\n            || mem::align_of::<T>()\n                != mem::align_of::<<<I as SourceIter>::Source as AsIntoIter>::Item>()\n        {\n            // fallback to more generic implementations\n            return SpecFromIterNested::from_iter(iterator);\n        }\n\n        let (src_buf, src_ptr, dst_buf, dst_end, cap) = unsafe {\n            let inner = iterator.as_inner().as_into_iter();\n            (\n                inner.buf.as_ptr(),\n                inner.ptr,\n                inner.buf.as_ptr() as *mut T,\n                inner.end as *const T,\n                inner.cap,\n            )\n        };\n\n        let len = SpecInPlaceCollect::collect_in_place(&mut iterator, dst_buf, dst_end);\n\n        let src = unsafe { iterator.as_inner().as_into_iter() };\n        // check if SourceIter contract was upheld\n        // caveat: if they weren't we may not even make it to this point\n        debug_assert_eq!(src_buf, src.buf.as_ptr());\n        // check InPlaceIterable contract. This is only possible if the iterator advanced the\n        // source pointer at all. If it uses unchecked access via TrustedRandomAccess\n        // then the source pointer will stay in its initial position and we can't use it as reference\n        if src.ptr != src_ptr {\n            debug_assert!(\n                unsafe { dst_buf.add(len) as *const _ } <= src.ptr,\n                \"InPlaceIterable contract violation, write pointer advanced beyond read pointer\"\n            );\n        }\n\n        // drop any remaining values at the tail of the source\n        // but prevent drop of the allocation itself once IntoIter goes out of scope\n        // if the drop panics then we also leak any elements collected into dst_buf\n        src.forget_allocation_drop_remaining();\n\n        let vec = unsafe { Vec::from_raw_parts(dst_buf, len, cap) };\n\n        vec\n    }\n}\n\nfn write_in_place_with_drop<T>(\n    src_end: *const T,\n) -> impl FnMut(InPlaceDrop<T>, T) -> Result<InPlaceDrop<T>, !> {\n    move |mut sink, item| {\n        unsafe {\n            // the InPlaceIterable contract cannot be verified precisely here since\n            // try_fold has an exclusive reference to the source pointer\n            // all we can do is check if it's still in range\n            debug_assert!(sink.dst as *const _ <= src_end, \"InPlaceIterable contract violation\");\n            ptr::write(sink.dst, item);\n            // Since this executes user code which can panic we have to bump the pointer\n            // after each step.\n            sink.dst = sink.dst.add(1);\n        }\n        Ok(sink)\n    }\n}\n\n/// Helper trait to hold specialized implementations of the in-place iterate-collect loop\ntrait SpecInPlaceCollect<T, I>: Iterator<Item = T> {\n    /// Collects an iterator (`self`) into the destination buffer (`dst`) and returns the number of items\n    /// collected. `end` is the last writable element of the allocation and used for bounds checks.\n    fn collect_in_place(&mut self, dst: *mut T, end: *const T) -> usize;\n}\n\nimpl<T, I> SpecInPlaceCollect<T, I> for I\nwhere\n    I: Iterator<Item = T>,\n{\n    #[inline]\n    default fn collect_in_place(&mut self, dst_buf: *mut T, end: *const T) -> usize {\n        // use try-fold since\n        // - it vectorizes better for some iterator adapters\n        // - unlike most internal iteration methods, it only takes a &mut self\n        // - it lets us thread the write pointer through its innards and get it back in the end\n        let sink = InPlaceDrop { inner: dst_buf, dst: dst_buf };\n        let sink =\n            self.try_fold::<_, _, Result<_, !>>(sink, write_in_place_with_drop(end)).unwrap();\n        // iteration succeeded, don't drop head\n        unsafe { ManuallyDrop::new(sink).dst.offset_from(dst_buf) as usize }\n    }\n}\n\nimpl<T, I> SpecInPlaceCollect<T, I> for I\nwhere\n    I: Iterator<Item = T> + TrustedRandomAccess,\n{\n    #[inline]\n    fn collect_in_place(&mut self, dst_buf: *mut T, end: *const T) -> usize {\n        let len = self.size();\n        let mut drop_guard = InPlaceDrop { inner: dst_buf, dst: dst_buf };\n        for i in 0..len {\n            // Safety: InplaceIterable contract guarantees that for every element we read\n            // one slot in the underlying storage will have been freed up and we can immediately\n            // write back the result.\n            unsafe {\n                let dst = dst_buf.offset(i as isize);\n                debug_assert!(dst as *const _ <= end, \"InPlaceIterable contract violation\");\n                ptr::write(dst, self.__iterator_get_unchecked(i));\n                // Since this executes user code which can panic we have to bump the pointer\n                // after each step.\n                drop_guard.dst = dst.add(1);\n            }\n        }\n        mem::forget(drop_guard);\n        len\n    }\n}\n"],[2059,"use crate::alloc::{Allocator, Global};\nuse crate::raw_vec::RawVec;\nuse core::fmt;\nuse core::intrinsics::arith_offset;\nuse core::iter::{FusedIterator, InPlaceIterable, SourceIter, TrustedLen, TrustedRandomAccess};\nuse core::marker::PhantomData;\nuse core::mem::{self};\nuse core::ptr::{self, NonNull};\nuse core::slice::{self};\n\n/// An iterator that moves out of a vector.\n///\n/// This `struct` is created by the `into_iter` method on [`Vec`](super::Vec)\n/// (provided by the [`IntoIterator`] trait).\n///\n/// # Example\n///\n/// ```\n/// let v = vec![0, 1, 2];\n/// let iter: std::vec::IntoIter<_> = v.into_iter();\n/// ```\n#[stable(feature = \"rust1\", since = \"1.0.0\")]\npub struct IntoIter<\n    T,\n    #[unstable(feature = \"allocator_api\", issue = \"32838\")] A: Allocator = Global,\n> {\n    pub(super) buf: NonNull<T>,\n    pub(super) phantom: PhantomData<T>,\n    pub(super) cap: usize,\n    pub(super) alloc: A,\n    pub(super) ptr: *const T,\n    pub(super) end: *const T,\n}\n\n#[stable(feature = \"vec_intoiter_debug\", since = \"1.13.0\")]\nimpl<T: fmt::Debug, A: Allocator> fmt::Debug for IntoIter<T, A> {\n    fn fmt(&self, f: &mut fmt::Formatter<'_>) -> fmt::Result {\n        f.debug_tuple(\"IntoIter\").field(&self.as_slice()).finish()\n    }\n}\n\nimpl<T, A: Allocator> IntoIter<T, A> {\n    /// Returns the remaining items of this iterator as a slice.\n    ///\n    /// # Examples\n    ///\n    /// ```\n    /// let vec = vec!['a', 'b', 'c'];\n    /// let mut into_iter = vec.into_iter();\n    /// assert_eq!(into_iter.as_slice(), &['a', 'b', 'c']);\n    /// let _ = into_iter.next().unwrap();\n    /// assert_eq!(into_iter.as_slice(), &['b', 'c']);\n    /// ```\n    #[stable(feature = \"vec_into_iter_as_slice\", since = \"1.15.0\")]\n    pub fn as_slice(&self) -> &[T] {\n        unsafe { slice::from_raw_parts(self.ptr, self.len()) }\n    }\n\n    /// Returns the remaining items of this iterator as a mutable slice.\n    ///\n    /// # Examples\n    ///\n    /// ```\n    /// let vec = vec!['a', 'b', 'c'];\n    /// let mut into_iter = vec.into_iter();\n    /// assert_eq!(into_iter.as_slice(), &['a', 'b', 'c']);\n    /// into_iter.as_mut_slice()[2] = 'z';\n    /// assert_eq!(into_iter.next().unwrap(), 'a');\n    /// assert_eq!(into_iter.next().unwrap(), 'b');\n    /// assert_eq!(into_iter.next().unwrap(), 'z');\n    /// ```\n    #[stable(feature = \"vec_into_iter_as_slice\", since = \"1.15.0\")]\n    pub fn as_mut_slice(&mut self) -> &mut [T] {\n        unsafe { &mut *self.as_raw_mut_slice() }\n    }\n\n    /// Returns a reference to the underlying allocator.\n    #[unstable(feature = \"allocator_api\", issue = \"32838\")]\n    #[inline]\n    pub fn allocator(&self) -> &A {\n        &self.alloc\n    }\n\n    fn as_raw_mut_slice(&mut self) -> *mut [T] {\n        ptr::slice_from_raw_parts_mut(self.ptr as *mut T, self.len())\n    }\n\n    /// Drops remaining elements and relinquishes the backing allocation.\n    ///\n    /// This is roughly equivalent to the following, but more efficient\n    ///\n    /// ```\n    /// # let mut into_iter = Vec::<u8>::with_capacity(10).into_iter();\n    /// (&mut into_iter).for_each(core::mem::drop);\n    /// unsafe { core::ptr::write(&mut into_iter, Vec::new().into_iter()); }\n    /// ```\n    #[cfg(not(no_global_oom_handling))]\n    pub(super) fn forget_allocation_drop_remaining(&mut self) {\n        let remaining = self.as_raw_mut_slice();\n\n        // overwrite the individual fields instead of creating a new\n        // struct and then overwriting &mut self.\n        // this creates less assembly\n        self.cap = 0;\n        self.buf = unsafe { NonNull::new_unchecked(RawVec::NEW.ptr()) };\n        self.ptr = self.buf.as_ptr();\n        self.end = self.buf.as_ptr();\n\n        unsafe {\n            ptr::drop_in_place(remaining);\n        }\n    }\n}\n\n#[stable(feature = \"vec_intoiter_as_ref\", since = \"1.46.0\")]\nimpl<T, A: Allocator> AsRef<[T]> for IntoIter<T, A> {\n    fn as_ref(&self) -> &[T] {\n        self.as_slice()\n    }\n}\n\n#[stable(feature = \"rust1\", since = \"1.0.0\")]\nunsafe impl<T: Send, A: Allocator + Send> Send for IntoIter<T, A> {}\n#[stable(feature = \"rust1\", since = \"1.0.0\")]\nunsafe impl<T: Sync, A: Allocator> Sync for IntoIter<T, A> {}\n\n#[stable(feature = \"rust1\", since = \"1.0.0\")]\nimpl<T, A: Allocator> Iterator for IntoIter<T, A> {\n    type Item = T;\n\n    #[inline]\n    fn next(&mut self) -> Option<T> {\n        if self.ptr as *const _ == self.end {\n            None\n        } else if mem::size_of::<T>() == 0 {\n            // purposefully don't use 'ptr.offset' because for\n            // vectors with 0-size elements this would return the\n            // same pointer.\n            self.ptr = unsafe { arith_offset(self.ptr as *const i8, 1) as *mut T };\n\n            // Make up a value of this ZST.\n            Some(unsafe { mem::zeroed() })\n        } else {\n            let old = self.ptr;\n            self.ptr = unsafe { self.ptr.offset(1) };\n\n            Some(unsafe { ptr::read(old) })\n        }\n    }\n\n    #[inline]\n    fn size_hint(&self) -> (usize, Option<usize>) {\n        let exact = if mem::size_of::<T>() == 0 {\n            (self.end as usize).wrapping_sub(self.ptr as usize)\n        } else {\n            unsafe { self.end.offset_from(self.ptr) as usize }\n        };\n        (exact, Some(exact))\n    }\n\n    #[inline]\n    fn count(self) -> usize {\n        self.len()\n    }\n\n    #[doc(hidden)]\n    unsafe fn __iterator_get_unchecked(&mut self, i: usize) -> Self::Item\n    where\n        Self: TrustedRandomAccess,\n    {\n        // SAFETY: the caller must guarantee that `i` is in bounds of the\n        // `Vec<T>`, so `i` cannot overflow an `isize`, and the `self.ptr.add(i)`\n        // is guaranteed to pointer to an element of the `Vec<T>` and\n        // thus guaranteed to be valid to dereference.\n        //\n        // Also note the implementation of `Self: TrustedRandomAccess` requires\n        // that `T: Copy` so reading elements from the buffer doesn't invalidate\n        // them for `Drop`.\n        unsafe {\n            if mem::size_of::<T>() == 0 { mem::zeroed() } else { ptr::read(self.ptr.add(i)) }\n        }\n    }\n}\n\n#[stable(feature = \"rust1\", since = \"1.0.0\")]\nimpl<T, A: Allocator> DoubleEndedIterator for IntoIter<T, A> {\n    #[inline]\n    fn next_back(&mut self) -> Option<T> {\n        if self.end == self.ptr {\n            None\n        } else if mem::size_of::<T>() == 0 {\n            // See above for why 'ptr.offset' isn't used\n            self.end = unsafe { arith_offset(self.end as *const i8, -1) as *mut T };\n\n            // Make up a value of this ZST.\n            Some(unsafe { mem::zeroed() })\n        } else {\n            self.end = unsafe { self.end.offset(-1) };\n\n            Some(unsafe { ptr::read(self.end) })\n        }\n    }\n}\n\n#[stable(feature = \"rust1\", since = \"1.0.0\")]\nimpl<T, A: Allocator> ExactSizeIterator for IntoIter<T, A> {\n    fn is_empty(&self) -> bool {\n        self.ptr == self.end\n    }\n}\n\n#[stable(feature = \"fused\", since = \"1.26.0\")]\nimpl<T, A: Allocator> FusedIterator for IntoIter<T, A> {}\n\n#[unstable(feature = \"trusted_len\", issue = \"37572\")]\nunsafe impl<T, A: Allocator> TrustedLen for IntoIter<T, A> {}\n\n#[doc(hidden)]\n#[unstable(issue = \"none\", feature = \"std_internals\")]\n// T: Copy as approximation for !Drop since get_unchecked does not advance self.ptr\n// and thus we can't implement drop-handling\nunsafe impl<T, A: Allocator> TrustedRandomAccess for IntoIter<T, A>\nwhere\n    T: Copy,\n{\n    const MAY_HAVE_SIDE_EFFECT: bool = false;\n}\n\n#[cfg(not(no_global_oom_handling))]\n#[stable(feature = \"vec_into_iter_clone\", since = \"1.8.0\")]\nimpl<T: Clone, A: Allocator + Clone> Clone for IntoIter<T, A> {\n    #[cfg(not(test))]\n    fn clone(&self) -> Self {\n        self.as_slice().to_vec_in(self.alloc.clone()).into_iter()\n    }\n    #[cfg(test)]\n    fn clone(&self) -> Self {\n        crate::slice::to_vec(self.as_slice(), self.alloc.clone()).into_iter()\n    }\n}\n\n#[stable(feature = \"rust1\", since = \"1.0.0\")]\nunsafe impl<#[may_dangle] T, A: Allocator> Drop for IntoIter<T, A> {\n    fn drop(&mut self) {\n        struct DropGuard<'a, T, A: Allocator>(&'a mut IntoIter<T, A>);\n\n        impl<T, A: Allocator> Drop for DropGuard<'_, T, A> {\n            fn drop(&mut self) {\n                unsafe {\n                    // `IntoIter::alloc` is not used anymore after this\n                    let alloc = ptr::read(&self.0.alloc);\n                    // RawVec handles deallocation\n                    let _ = RawVec::from_raw_parts_in(self.0.buf.as_ptr(), self.0.cap, alloc);\n                }\n            }\n        }\n\n        let guard = DropGuard(self);\n        // destroy the remaining elements\n        unsafe {\n            ptr::drop_in_place(guard.0.as_raw_mut_slice());\n        }\n        // now `guard` will be dropped and do the rest\n    }\n}\n\n#[unstable(issue = \"none\", feature = \"inplace_iteration\")]\n#[doc(hidden)]\nunsafe impl<T, A: Allocator> InPlaceIterable for IntoIter<T, A> {}\n\n#[unstable(issue = \"none\", feature = \"inplace_iteration\")]\n#[doc(hidden)]\nunsafe impl<T, A: Allocator> SourceIter for IntoIter<T, A> {\n    type Source = Self;\n\n    #[inline]\n    unsafe fn as_inner(&mut self) -> &mut Self::Source {\n        self\n    }\n}\n\n// internal helper trait for in-place iteration specialization.\n#[rustc_specialization_trait]\npub(crate) trait AsIntoIter {\n    type Item;\n    fn as_into_iter(&mut self) -> &mut IntoIter<Self::Item>;\n}\n\nimpl<T> AsIntoIter for IntoIter<T> {\n    type Item = T;\n\n    fn as_into_iter(&mut self) -> &mut IntoIter<Self::Item> {\n        self\n    }\n}\n"],[2060,"use crate::boxed::Box;\n\n#[rustc_specialization_trait]\npub(super) unsafe trait IsZero {\n    /// Whether this value is zero\n    fn is_zero(&self) -> bool;\n}\n\nmacro_rules! impl_is_zero {\n    ($t:ty, $is_zero:expr) => {\n        unsafe impl IsZero for $t {\n            #[inline]\n            fn is_zero(&self) -> bool {\n                $is_zero(*self)\n            }\n        }\n    };\n}\n\nimpl_is_zero!(i16, |x| x == 0);\nimpl_is_zero!(i32, |x| x == 0);\nimpl_is_zero!(i64, |x| x == 0);\nimpl_is_zero!(i128, |x| x == 0);\nimpl_is_zero!(isize, |x| x == 0);\n\nimpl_is_zero!(u16, |x| x == 0);\nimpl_is_zero!(u32, |x| x == 0);\nimpl_is_zero!(u64, |x| x == 0);\nimpl_is_zero!(u128, |x| x == 0);\nimpl_is_zero!(usize, |x| x == 0);\n\nimpl_is_zero!(bool, |x| x == false);\nimpl_is_zero!(char, |x| x == '\\0');\n\nimpl_is_zero!(f32, |x: f32| x.to_bits() == 0);\nimpl_is_zero!(f64, |x: f64| x.to_bits() == 0);\n\nunsafe impl<T> IsZero for *const T {\n    #[inline]\n    fn is_zero(&self) -> bool {\n        (*self).is_null()\n    }\n}\n\nunsafe impl<T> IsZero for *mut T {\n    #[inline]\n    fn is_zero(&self) -> bool {\n        (*self).is_null()\n    }\n}\n\n// `Option<&T>` and `Option<Box<T>>` are guaranteed to represent `None` as null.\n// For fat pointers, the bytes that would be the pointer metadata in the `Some`\n// variant are padding in the `None` variant, so ignoring them and\n// zero-initializing instead is ok.\n// `Option<&mut T>` never implements `Clone`, so there's no need for an impl of\n// `SpecFromElem`.\n\nunsafe impl<T: ?Sized> IsZero for Option<&T> {\n    #[inline]\n    fn is_zero(&self) -> bool {\n        self.is_none()\n    }\n}\n\nunsafe impl<T: ?Sized> IsZero for Option<Box<T>> {\n    #[inline]\n    fn is_zero(&self) -> bool {\n        self.is_none()\n    }\n}\n\n// `Option<num::NonZeroU32>` and similar have a representation guarantee that\n// they're the same size as the corresponding `u32` type, as well as a guarantee\n// that transmuting between `NonZeroU32` and `Option<num::NonZeroU32>` works.\n// While the documentation officially makes it UB to transmute from `None`,\n// we're the standard library so we can make extra inferences, and we know that\n// the only niche available to represent `None` is the one that's all zeros.\n\nmacro_rules! impl_is_zero_option_of_nonzero {\n    ($($t:ident,)+) => {$(\n        unsafe impl IsZero for Option<core::num::$t> {\n            #[inline]\n            fn is_zero(&self) -> bool {\n                self.is_none()\n            }\n        }\n    )+};\n}\n\nimpl_is_zero_option_of_nonzero!(\n    NonZeroU8,\n    NonZeroU16,\n    NonZeroU32,\n    NonZeroU64,\n    NonZeroU128,\n    NonZeroI8,\n    NonZeroI16,\n    NonZeroI32,\n    NonZeroI64,\n    NonZeroI128,\n    NonZeroUsize,\n    NonZeroIsize,\n);\n"],[2061,"use crate::borrow::Cow;\nuse core::iter::FromIterator;\n\nuse super::Vec;\n\n#[stable(feature = \"cow_from_vec\", since = \"1.8.0\")]\nimpl<'a, T: Clone> From<&'a [T]> for Cow<'a, [T]> {\n    /// Creates a [`Borrowed`] variant of [`Cow`]\n    /// from a slice.\n    ///\n    /// This conversion does not allocate or clone the data.\n    ///\n    /// [`Borrowed`]: crate::borrow::Cow::Borrowed\n    fn from(s: &'a [T]) -> Cow<'a, [T]> {\n        Cow::Borrowed(s)\n    }\n}\n\n#[stable(feature = \"cow_from_vec\", since = \"1.8.0\")]\nimpl<'a, T: Clone> From<Vec<T>> for Cow<'a, [T]> {\n    /// Creates an [`Owned`] variant of [`Cow`]\n    /// from an owned instance of [`Vec`].\n    ///\n    /// This conversion does not allocate or clone the data.\n    ///\n    /// [`Owned`]: crate::borrow::Cow::Owned\n    fn from(v: Vec<T>) -> Cow<'a, [T]> {\n        Cow::Owned(v)\n    }\n}\n\n#[stable(feature = \"cow_from_vec_ref\", since = \"1.28.0\")]\nimpl<'a, T: Clone> From<&'a Vec<T>> for Cow<'a, [T]> {\n    /// Creates a [`Borrowed`] variant of [`Cow`]\n    /// from a reference to [`Vec`].\n    ///\n    /// This conversion does not allocate or clone the data.\n    ///\n    /// [`Borrowed`]: crate::borrow::Cow::Borrowed\n    fn from(v: &'a Vec<T>) -> Cow<'a, [T]> {\n        Cow::Borrowed(v.as_slice())\n    }\n}\n\n#[stable(feature = \"rust1\", since = \"1.0.0\")]\nimpl<'a, T> FromIterator<T> for Cow<'a, [T]>\nwhere\n    T: Clone,\n{\n    fn from_iter<I: IntoIterator<Item = T>>(it: I) -> Cow<'a, [T]> {\n        Cow::Owned(FromIterator::from_iter(it))\n    }\n}\n"],[2062,"use crate::alloc::Allocator;\n#[cfg(not(no_global_oom_handling))]\nuse crate::borrow::Cow;\n\nuse super::Vec;\n\nmacro_rules! __impl_slice_eq1 {\n    ([$($vars:tt)*] $lhs:ty, $rhs:ty $(where $ty:ty: $bound:ident)?, #[$stability:meta]) => {\n        #[$stability]\n        impl<T, U, $($vars)*> PartialEq<$rhs> for $lhs\n        where\n            T: PartialEq<U>,\n            $($ty: $bound)?\n        {\n            #[inline]\n            fn eq(&self, other: &$rhs) -> bool { self[..] == other[..] }\n            #[inline]\n            fn ne(&self, other: &$rhs) -> bool { self[..] != other[..] }\n        }\n    }\n}\n\n__impl_slice_eq1! { [A: Allocator] Vec<T, A>, Vec<U, A>, #[stable(feature = \"rust1\", since = \"1.0.0\")] }\n__impl_slice_eq1! { [A: Allocator] Vec<T, A>, &[U], #[stable(feature = \"rust1\", since = \"1.0.0\")] }\n__impl_slice_eq1! { [A: Allocator] Vec<T, A>, &mut [U], #[stable(feature = \"rust1\", since = \"1.0.0\")] }\n__impl_slice_eq1! { [A: Allocator] &[T], Vec<U, A>, #[stable(feature = \"partialeq_vec_for_ref_slice\", since = \"1.46.0\")] }\n__impl_slice_eq1! { [A: Allocator] &mut [T], Vec<U, A>, #[stable(feature = \"partialeq_vec_for_ref_slice\", since = \"1.46.0\")] }\n__impl_slice_eq1! { [A: Allocator] Vec<T, A>, [U], #[stable(feature = \"partialeq_vec_for_slice\", since = \"1.48.0\")]  }\n__impl_slice_eq1! { [A: Allocator] [T], Vec<U, A>, #[stable(feature = \"partialeq_vec_for_slice\", since = \"1.48.0\")]  }\n#[cfg(not(no_global_oom_handling))]\n__impl_slice_eq1! { [A: Allocator] Cow<'_, [T]>, Vec<U, A> where T: Clone, #[stable(feature = \"rust1\", since = \"1.0.0\")] }\n#[cfg(not(no_global_oom_handling))]\n__impl_slice_eq1! { [] Cow<'_, [T]>, &[U] where T: Clone, #[stable(feature = \"rust1\", since = \"1.0.0\")] }\n#[cfg(not(no_global_oom_handling))]\n__impl_slice_eq1! { [] Cow<'_, [T]>, &mut [U] where T: Clone, #[stable(feature = \"rust1\", since = \"1.0.0\")] }\n__impl_slice_eq1! { [A: Allocator, const N: usize] Vec<T, A>, [U; N], #[stable(feature = \"rust1\", since = \"1.0.0\")] }\n__impl_slice_eq1! { [A: Allocator, const N: usize] Vec<T, A>, &[U; N], #[stable(feature = \"rust1\", since = \"1.0.0\")] }\n\n// NOTE: some less important impls are omitted to reduce code bloat\n// FIXME(Centril): Reconsider this?\n//__impl_slice_eq1! { [const N: usize] Vec<A>, &mut [B; N], }\n//__impl_slice_eq1! { [const N: usize] [A; N], Vec<B>, }\n//__impl_slice_eq1! { [const N: usize] &[A; N], Vec<B>, }\n//__impl_slice_eq1! { [const N: usize] &mut [A; N], Vec<B>, }\n//__impl_slice_eq1! { [const N: usize] Cow<'a, [A]>, [B; N], }\n//__impl_slice_eq1! { [const N: usize] Cow<'a, [A]>, &[B; N], }\n//__impl_slice_eq1! { [const N: usize] Cow<'a, [A]>, &mut [B; N], }\n"],[2063,"use crate::alloc::Allocator;\nuse crate::raw_vec::RawVec;\nuse core::ptr::{self};\n\nuse super::{ExtendElement, IsZero, Vec};\n\n// Specialization trait used for Vec::from_elem\npub(super) trait SpecFromElem: Sized {\n    fn from_elem<A: Allocator>(elem: Self, n: usize, alloc: A) -> Vec<Self, A>;\n}\n\nimpl<T: Clone> SpecFromElem for T {\n    default fn from_elem<A: Allocator>(elem: Self, n: usize, alloc: A) -> Vec<Self, A> {\n        let mut v = Vec::with_capacity_in(n, alloc);\n        v.extend_with(n, ExtendElement(elem));\n        v\n    }\n}\n\nimpl SpecFromElem for i8 {\n    #[inline]\n    fn from_elem<A: Allocator>(elem: i8, n: usize, alloc: A) -> Vec<i8, A> {\n        if elem == 0 {\n            return Vec { buf: RawVec::with_capacity_zeroed_in(n, alloc), len: n };\n        }\n        unsafe {\n            let mut v = Vec::with_capacity_in(n, alloc);\n            ptr::write_bytes(v.as_mut_ptr(), elem as u8, n);\n            v.set_len(n);\n            v\n        }\n    }\n}\n\nimpl SpecFromElem for u8 {\n    #[inline]\n    fn from_elem<A: Allocator>(elem: u8, n: usize, alloc: A) -> Vec<u8, A> {\n        if elem == 0 {\n            return Vec { buf: RawVec::with_capacity_zeroed_in(n, alloc), len: n };\n        }\n        unsafe {\n            let mut v = Vec::with_capacity_in(n, alloc);\n            ptr::write_bytes(v.as_mut_ptr(), elem, n);\n            v.set_len(n);\n            v\n        }\n    }\n}\n\nimpl<T: Clone + IsZero> SpecFromElem for T {\n    #[inline]\n    fn from_elem<A: Allocator>(elem: T, n: usize, alloc: A) -> Vec<T, A> {\n        if elem.is_zero() {\n            return Vec { buf: RawVec::with_capacity_zeroed_in(n, alloc), len: n };\n        }\n        let mut v = Vec::with_capacity_in(n, alloc);\n        v.extend_with(n, ExtendElement(elem));\n        v\n    }\n}\n"],[2064,"use crate::alloc::{Allocator, Global};\nuse core::ptr::{self};\nuse core::slice::{self};\n\nuse super::Vec;\n\n/// An iterator which uses a closure to determine if an element should be removed.\n///\n/// This struct is created by [`Vec::drain_filter`].\n/// See its documentation for more.\n///\n/// # Example\n///\n/// ```\n/// #![feature(drain_filter)]\n///\n/// let mut v = vec![0, 1, 2];\n/// let iter: std::vec::DrainFilter<_, _> = v.drain_filter(|x| *x % 2 == 0);\n/// ```\n#[unstable(feature = \"drain_filter\", reason = \"recently added\", issue = \"43244\")]\n#[derive(Debug)]\npub struct DrainFilter<\n    'a,\n    T,\n    F,\n    #[unstable(feature = \"allocator_api\", issue = \"32838\")] A: Allocator = Global,\n> where\n    F: FnMut(&mut T) -> bool,\n{\n    pub(super) vec: &'a mut Vec<T, A>,\n    /// The index of the item that will be inspected by the next call to `next`.\n    pub(super) idx: usize,\n    /// The number of items that have been drained (removed) thus far.\n    pub(super) del: usize,\n    /// The original length of `vec` prior to draining.\n    pub(super) old_len: usize,\n    /// The filter test predicate.\n    pub(super) pred: F,\n    /// A flag that indicates a panic has occurred in the filter test predicate.\n    /// This is used as a hint in the drop implementation to prevent consumption\n    /// of the remainder of the `DrainFilter`. Any unprocessed items will be\n    /// backshifted in the `vec`, but no further items will be dropped or\n    /// tested by the filter predicate.\n    pub(super) panic_flag: bool,\n}\n\nimpl<T, F, A: Allocator> DrainFilter<'_, T, F, A>\nwhere\n    F: FnMut(&mut T) -> bool,\n{\n    /// Returns a reference to the underlying allocator.\n    #[unstable(feature = \"allocator_api\", issue = \"32838\")]\n    #[inline]\n    pub fn allocator(&self) -> &A {\n        self.vec.allocator()\n    }\n}\n\n#[unstable(feature = \"drain_filter\", reason = \"recently added\", issue = \"43244\")]\nimpl<T, F, A: Allocator> Iterator for DrainFilter<'_, T, F, A>\nwhere\n    F: FnMut(&mut T) -> bool,\n{\n    type Item = T;\n\n    fn next(&mut self) -> Option<T> {\n        unsafe {\n            while self.idx < self.old_len {\n                let i = self.idx;\n                let v = slice::from_raw_parts_mut(self.vec.as_mut_ptr(), self.old_len);\n                self.panic_flag = true;\n                let drained = (self.pred)(&mut v[i]);\n                self.panic_flag = false;\n                // Update the index *after* the predicate is called. If the index\n                // is updated prior and the predicate panics, the element at this\n                // index would be leaked.\n                self.idx += 1;\n                if drained {\n                    self.del += 1;\n                    return Some(ptr::read(&v[i]));\n                } else if self.del > 0 {\n                    let del = self.del;\n                    let src: *const T = &v[i];\n                    let dst: *mut T = &mut v[i - del];\n                    ptr::copy_nonoverlapping(src, dst, 1);\n                }\n            }\n            None\n        }\n    }\n\n    fn size_hint(&self) -> (usize, Option<usize>) {\n        (0, Some(self.old_len - self.idx))\n    }\n}\n\n#[unstable(feature = \"drain_filter\", reason = \"recently added\", issue = \"43244\")]\nimpl<T, F, A: Allocator> Drop for DrainFilter<'_, T, F, A>\nwhere\n    F: FnMut(&mut T) -> bool,\n{\n    fn drop(&mut self) {\n        struct BackshiftOnDrop<'a, 'b, T, F, A: Allocator>\n        where\n            F: FnMut(&mut T) -> bool,\n        {\n            drain: &'b mut DrainFilter<'a, T, F, A>,\n        }\n\n        impl<'a, 'b, T, F, A: Allocator> Drop for BackshiftOnDrop<'a, 'b, T, F, A>\n        where\n            F: FnMut(&mut T) -> bool,\n        {\n            fn drop(&mut self) {\n                unsafe {\n                    if self.drain.idx < self.drain.old_len && self.drain.del > 0 {\n                        // This is a pretty messed up state, and there isn't really an\n                        // obviously right thing to do. We don't want to keep trying\n                        // to execute `pred`, so we just backshift all the unprocessed\n                        // elements and tell the vec that they still exist. The backshift\n                        // is required to prevent a double-drop of the last successfully\n                        // drained item prior to a panic in the predicate.\n                        let ptr = self.drain.vec.as_mut_ptr();\n                        let src = ptr.add(self.drain.idx);\n                        let dst = src.sub(self.drain.del);\n                        let tail_len = self.drain.old_len - self.drain.idx;\n                        src.copy_to(dst, tail_len);\n                    }\n                    self.drain.vec.set_len(self.drain.old_len - self.drain.del);\n                }\n            }\n        }\n\n        let backshift = BackshiftOnDrop { drain: self };\n\n        // Attempt to consume any remaining elements if the filter predicate\n        // has not yet panicked. We'll backshift any remaining elements\n        // whether we've already panicked or if the consumption here panics.\n        if !backshift.drain.panic_flag {\n            backshift.drain.for_each(drop);\n        }\n    }\n}\n"],[2065,"use core::iter::TrustedLen;\nuse core::ptr::{self};\n\nuse super::{SpecExtend, Vec};\n\n/// Another specialization trait for Vec::from_iter\n/// necessary to manually prioritize overlapping specializations\n/// see [`SpecFromIter`](super::SpecFromIter) for details.\npub(super) trait SpecFromIterNested<T, I> {\n    fn from_iter(iter: I) -> Self;\n}\n\nimpl<T, I> SpecFromIterNested<T, I> for Vec<T>\nwhere\n    I: Iterator<Item = T>,\n{\n    default fn from_iter(mut iterator: I) -> Self {\n        // Unroll the first iteration, as the vector is going to be\n        // expanded on this iteration in every case when the iterable is not\n        // empty, but the loop in extend_desugared() is not going to see the\n        // vector being full in the few subsequent loop iterations.\n        // So we get better branch prediction.\n        let mut vector = match iterator.next() {\n            None => return Vec::new(),\n            Some(element) => {\n                let (lower, _) = iterator.size_hint();\n                let mut vector = Vec::with_capacity(lower.saturating_add(1));\n                unsafe {\n                    ptr::write(vector.as_mut_ptr(), element);\n                    vector.set_len(1);\n                }\n                vector\n            }\n        };\n        // must delegate to spec_extend() since extend() itself delegates\n        // to spec_from for empty Vecs\n        <Vec<T> as SpecExtend<T, I>>::spec_extend(&mut vector, iterator);\n        vector\n    }\n}\n\nimpl<T, I> SpecFromIterNested<T, I> for Vec<T>\nwhere\n    I: TrustedLen<Item = T>,\n{\n    fn from_iter(iterator: I) -> Self {\n        let mut vector = match iterator.size_hint() {\n            (_, Some(upper)) => Vec::with_capacity(upper),\n            // TrustedLen contract guarantees that `size_hint() == (_, None)` means that there\n            // are more than `usize::MAX` elements.\n            // Since the previous branch would eagerly panic if the capacity is too large\n            // (via `with_capacity`) we do the same here.\n            _ => panic!(\"capacity overflow\"),\n        };\n        // reuse extend specialization for TrustedLen\n        vector.spec_extend(iterator);\n        vector\n    }\n}\n"],[2066,"use core::ptr::{self};\nuse core::slice::{self};\n\n// A helper struct for in-place iteration that drops the destination slice of iteration,\n// i.e. the head. The source slice (the tail) is dropped by IntoIter.\npub(super) struct InPlaceDrop<T> {\n    pub(super) inner: *mut T,\n    pub(super) dst: *mut T,\n}\n\nimpl<T> InPlaceDrop<T> {\n    fn len(&self) -> usize {\n        unsafe { self.dst.offset_from(self.inner) as usize }\n    }\n}\n\nimpl<T> Drop for InPlaceDrop<T> {\n    #[inline]\n    fn drop(&mut self) {\n        unsafe {\n            ptr::drop_in_place(slice::from_raw_parts_mut(self.inner, self.len()));\n        }\n    }\n}\n"],[2067,"#![stable(feature = \"rust1\", since = \"1.0.0\")]\n\n//! Thread-safe reference-counting pointers.\n//!\n//! See the [`Arc<T>`][Arc] documentation for more details.\n\nuse core::any::Any;\nuse core::borrow;\nuse core::cmp::Ordering;\nuse core::convert::{From, TryFrom};\nuse core::fmt;\nuse core::hash::{Hash, Hasher};\nuse core::hint;\nuse core::intrinsics::abort;\n#[cfg(not(no_global_oom_handling))]\nuse core::iter;\nuse core::marker::{PhantomData, Unpin, Unsize};\n#[cfg(not(no_global_oom_handling))]\nuse core::mem::size_of_val;\nuse core::mem::{self, align_of_val_raw};\nuse core::ops::{CoerceUnsized, Deref, DispatchFromDyn, Receiver};\nuse core::pin::Pin;\nuse core::ptr::{self, NonNull};\n#[cfg(not(no_global_oom_handling))]\nuse core::slice::from_raw_parts_mut;\nuse core::sync::atomic;\nuse core::sync::atomic::Ordering::{Acquire, Relaxed, Release, SeqCst};\n\n#[cfg(not(no_global_oom_handling))]\nuse crate::alloc::handle_alloc_error;\n#[cfg(not(no_global_oom_handling))]\nuse crate::alloc::{box_free, WriteCloneIntoRaw};\nuse crate::alloc::{AllocError, Allocator, Global, Layout};\nuse crate::borrow::{Cow, ToOwned};\nuse crate::boxed::Box;\nuse crate::rc::is_dangling;\n#[cfg(not(no_global_oom_handling))]\nuse crate::string::String;\n#[cfg(not(no_global_oom_handling))]\nuse crate::vec::Vec;\n\n#[cfg(test)]\nmod tests;\n\n/// A soft limit on the amount of references that may be made to an `Arc`.\n///\n/// Going above this limit will abort your program (although not\n/// necessarily) at _exactly_ `MAX_REFCOUNT + 1` references.\nconst MAX_REFCOUNT: usize = (isize::MAX) as usize;\n\n#[cfg(not(sanitize = \"thread\"))]\nmacro_rules! acquire {\n    ($x:expr) => {\n        atomic::fence(Acquire)\n    };\n}\n\n// ThreadSanitizer does not support memory fences. To avoid false positive\n// reports in Arc / Weak implementation use atomic loads for synchronization\n// instead.\n#[cfg(sanitize = \"thread\")]\nmacro_rules! acquire {\n    ($x:expr) => {\n        $x.load(Acquire)\n    };\n}\n\n/// A thread-safe reference-counting pointer. 'Arc' stands for 'Atomically\n/// Reference Counted'.\n///\n/// The type `Arc<T>` provides shared ownership of a value of type `T`,\n/// allocated in the heap. Invoking [`clone`][clone] on `Arc` produces\n/// a new `Arc` instance, which points to the same allocation on the heap as the\n/// source `Arc`, while increasing a reference count. When the last `Arc`\n/// pointer to a given allocation is destroyed, the value stored in that allocation (often\n/// referred to as \"inner value\") is also dropped.\n///\n/// Shared references in Rust disallow mutation by default, and `Arc` is no\n/// exception: you cannot generally obtain a mutable reference to something\n/// inside an `Arc`. If you need to mutate through an `Arc`, use\n/// [`Mutex`][mutex], [`RwLock`][rwlock], or one of the [`Atomic`][atomic]\n/// types.\n///\n/// ## Thread Safety\n///\n/// Unlike [`Rc<T>`], `Arc<T>` uses atomic operations for its reference\n/// counting. This means that it is thread-safe. The disadvantage is that\n/// atomic operations are more expensive than ordinary memory accesses. If you\n/// are not sharing reference-counted allocations between threads, consider using\n/// [`Rc<T>`] for lower overhead. [`Rc<T>`] is a safe default, because the\n/// compiler will catch any attempt to send an [`Rc<T>`] between threads.\n/// However, a library might choose `Arc<T>` in order to give library consumers\n/// more flexibility.\n///\n/// `Arc<T>` will implement [`Send`] and [`Sync`] as long as the `T` implements\n/// [`Send`] and [`Sync`]. Why can't you put a non-thread-safe type `T` in an\n/// `Arc<T>` to make it thread-safe? This may be a bit counter-intuitive at\n/// first: after all, isn't the point of `Arc<T>` thread safety? The key is\n/// this: `Arc<T>` makes it thread safe to have multiple ownership of the same\n/// data, but it  doesn't add thread safety to its data. Consider\n/// `Arc<`[`RefCell<T>`]`>`. [`RefCell<T>`] isn't [`Sync`], and if `Arc<T>` was always\n/// [`Send`], `Arc<`[`RefCell<T>`]`>` would be as well. But then we'd have a problem:\n/// [`RefCell<T>`] is not thread safe; it keeps track of the borrowing count using\n/// non-atomic operations.\n///\n/// In the end, this means that you may need to pair `Arc<T>` with some sort of\n/// [`std::sync`] type, usually [`Mutex<T>`][mutex].\n///\n/// ## Breaking cycles with `Weak`\n///\n/// The [`downgrade`][downgrade] method can be used to create a non-owning\n/// [`Weak`] pointer. A [`Weak`] pointer can be [`upgrade`][upgrade]d\n/// to an `Arc`, but this will return [`None`] if the value stored in the allocation has\n/// already been dropped. In other words, `Weak` pointers do not keep the value\n/// inside the allocation alive; however, they *do* keep the allocation\n/// (the backing store for the value) alive.\n///\n/// A cycle between `Arc` pointers will never be deallocated. For this reason,\n/// [`Weak`] is used to break cycles. For example, a tree could have\n/// strong `Arc` pointers from parent nodes to children, and [`Weak`]\n/// pointers from children back to their parents.\n///\n/// # Cloning references\n///\n/// Creating a new reference from an existing reference-counted pointer is done using the\n/// `Clone` trait implemented for [`Arc<T>`][Arc] and [`Weak<T>`][Weak].\n///\n/// ```\n/// use std::sync::Arc;\n/// let foo = Arc::new(vec![1.0, 2.0, 3.0]);\n/// // The two syntaxes below are equivalent.\n/// let a = foo.clone();\n/// let b = Arc::clone(&foo);\n/// // a, b, and foo are all Arcs that point to the same memory location\n/// ```\n///\n/// ## `Deref` behavior\n///\n/// `Arc<T>` automatically dereferences to `T` (via the [`Deref`][deref] trait),\n/// so you can call `T`'s methods on a value of type `Arc<T>`. To avoid name\n/// clashes with `T`'s methods, the methods of `Arc<T>` itself are associated\n/// functions, called using [fully qualified syntax]:\n///\n/// ```\n/// use std::sync::Arc;\n///\n/// let my_arc = Arc::new(());\n/// Arc::downgrade(&my_arc);\n/// ```\n///\n/// `Arc<T>`'s implementations of traits like `Clone` may also be called using\n/// fully qualified syntax. Some people prefer to use fully qualified syntax,\n/// while others prefer using method-call syntax.\n///\n/// ```\n/// use std::sync::Arc;\n///\n/// let arc = Arc::new(());\n/// // Method-call syntax\n/// let arc2 = arc.clone();\n/// // Fully qualified syntax\n/// let arc3 = Arc::clone(&arc);\n/// ```\n///\n/// [`Weak<T>`][Weak] does not auto-dereference to `T`, because the inner value may have\n/// already been dropped.\n///\n/// [`Rc<T>`]: crate::rc::Rc\n/// [clone]: Clone::clone\n/// [mutex]: ../../std/sync/struct.Mutex.html\n/// [rwlock]: ../../std/sync/struct.RwLock.html\n/// [atomic]: core::sync::atomic\n/// [`Send`]: core::marker::Send\n/// [`Sync`]: core::marker::Sync\n/// [deref]: core::ops::Deref\n/// [downgrade]: Arc::downgrade\n/// [upgrade]: Weak::upgrade\n/// [`RefCell<T>`]: core::cell::RefCell\n/// [`std::sync`]: ../../std/sync/index.html\n/// [`Arc::clone(&from)`]: Arc::clone\n/// [fully qualified syntax]: https://doc.rust-lang.org/book/ch19-03-advanced-traits.html#fully-qualified-syntax-for-disambiguation-calling-methods-with-the-same-name\n///\n/// # Examples\n///\n/// Sharing some immutable data between threads:\n///\n// Note that we **do not** run these tests here. The windows builders get super\n// unhappy if a thread outlives the main thread and then exits at the same time\n// (something deadlocks) so we just avoid this entirely by not running these\n// tests.\n/// ```no_run\n/// use std::sync::Arc;\n/// use std::thread;\n///\n/// let five = Arc::new(5);\n///\n/// for _ in 0..10 {\n///     let five = Arc::clone(&five);\n///\n///     thread::spawn(move || {\n///         println!(\"{:?}\", five);\n///     });\n/// }\n/// ```\n///\n/// Sharing a mutable [`AtomicUsize`]:\n///\n/// [`AtomicUsize`]: core::sync::atomic::AtomicUsize\n///\n/// ```no_run\n/// use std::sync::Arc;\n/// use std::sync::atomic::{AtomicUsize, Ordering};\n/// use std::thread;\n///\n/// let val = Arc::new(AtomicUsize::new(5));\n///\n/// for _ in 0..10 {\n///     let val = Arc::clone(&val);\n///\n///     thread::spawn(move || {\n///         let v = val.fetch_add(1, Ordering::SeqCst);\n///         println!(\"{:?}\", v);\n///     });\n/// }\n/// ```\n///\n/// See the [`rc` documentation][rc_examples] for more examples of reference\n/// counting in general.\n///\n/// [rc_examples]: crate::rc#examples\n#[cfg_attr(not(test), rustc_diagnostic_item = \"Arc\")]\n#[stable(feature = \"rust1\", since = \"1.0.0\")]\npub struct Arc<T: ?Sized> {\n    ptr: NonNull<ArcInner<T>>,\n    phantom: PhantomData<ArcInner<T>>,\n}\n\n#[stable(feature = \"rust1\", since = \"1.0.0\")]\nunsafe impl<T: ?Sized + Sync + Send> Send for Arc<T> {}\n#[stable(feature = \"rust1\", since = \"1.0.0\")]\nunsafe impl<T: ?Sized + Sync + Send> Sync for Arc<T> {}\n\n#[unstable(feature = \"coerce_unsized\", issue = \"27732\")]\nimpl<T: ?Sized + Unsize<U>, U: ?Sized> CoerceUnsized<Arc<U>> for Arc<T> {}\n\n#[unstable(feature = \"dispatch_from_dyn\", issue = \"none\")]\nimpl<T: ?Sized + Unsize<U>, U: ?Sized> DispatchFromDyn<Arc<U>> for Arc<T> {}\n\nimpl<T: ?Sized> Arc<T> {\n    fn from_inner(ptr: NonNull<ArcInner<T>>) -> Self {\n        Self { ptr, phantom: PhantomData }\n    }\n\n    unsafe fn from_ptr(ptr: *mut ArcInner<T>) -> Self {\n        unsafe { Self::from_inner(NonNull::new_unchecked(ptr)) }\n    }\n}\n\n/// `Weak` is a version of [`Arc`] that holds a non-owning reference to the\n/// managed allocation. The allocation is accessed by calling [`upgrade`] on the `Weak`\n/// pointer, which returns an [`Option`]`<`[`Arc`]`<T>>`.\n///\n/// Since a `Weak` reference does not count towards ownership, it will not\n/// prevent the value stored in the allocation from being dropped, and `Weak` itself makes no\n/// guarantees about the value still being present. Thus it may return [`None`]\n/// when [`upgrade`]d. Note however that a `Weak` reference *does* prevent the allocation\n/// itself (the backing store) from being deallocated.\n///\n/// A `Weak` pointer is useful for keeping a temporary reference to the allocation\n/// managed by [`Arc`] without preventing its inner value from being dropped. It is also used to\n/// prevent circular references between [`Arc`] pointers, since mutual owning references\n/// would never allow either [`Arc`] to be dropped. For example, a tree could\n/// have strong [`Arc`] pointers from parent nodes to children, and `Weak`\n/// pointers from children back to their parents.\n///\n/// The typical way to obtain a `Weak` pointer is to call [`Arc::downgrade`].\n///\n/// [`upgrade`]: Weak::upgrade\n#[stable(feature = \"arc_weak\", since = \"1.4.0\")]\npub struct Weak<T: ?Sized> {\n    // This is a `NonNull` to allow optimizing the size of this type in enums,\n    // but it is not necessarily a valid pointer.\n    // `Weak::new` sets this to `usize::MAX` so that it doesn’t need\n    // to allocate space on the heap.  That's not a value a real pointer\n    // will ever have because RcBox has alignment at least 2.\n    // This is only possible when `T: Sized`; unsized `T` never dangle.\n    ptr: NonNull<ArcInner<T>>,\n}\n\n#[stable(feature = \"arc_weak\", since = \"1.4.0\")]\nunsafe impl<T: ?Sized + Sync + Send> Send for Weak<T> {}\n#[stable(feature = \"arc_weak\", since = \"1.4.0\")]\nunsafe impl<T: ?Sized + Sync + Send> Sync for Weak<T> {}\n\n#[unstable(feature = \"coerce_unsized\", issue = \"27732\")]\nimpl<T: ?Sized + Unsize<U>, U: ?Sized> CoerceUnsized<Weak<U>> for Weak<T> {}\n#[unstable(feature = \"dispatch_from_dyn\", issue = \"none\")]\nimpl<T: ?Sized + Unsize<U>, U: ?Sized> DispatchFromDyn<Weak<U>> for Weak<T> {}\n\n#[stable(feature = \"arc_weak\", since = \"1.4.0\")]\nimpl<T: ?Sized + fmt::Debug> fmt::Debug for Weak<T> {\n    fn fmt(&self, f: &mut fmt::Formatter<'_>) -> fmt::Result {\n        write!(f, \"(Weak)\")\n    }\n}\n\n// This is repr(C) to future-proof against possible field-reordering, which\n// would interfere with otherwise safe [into|from]_raw() of transmutable\n// inner types.\n#[repr(C)]\nstruct ArcInner<T: ?Sized> {\n    strong: atomic::AtomicUsize,\n\n    // the value usize::MAX acts as a sentinel for temporarily \"locking\" the\n    // ability to upgrade weak pointers or downgrade strong ones; this is used\n    // to avoid races in `make_mut` and `get_mut`.\n    weak: atomic::AtomicUsize,\n\n    data: T,\n}\n\nunsafe impl<T: ?Sized + Sync + Send> Send for ArcInner<T> {}\nunsafe impl<T: ?Sized + Sync + Send> Sync for ArcInner<T> {}\n\nimpl<T> Arc<T> {\n    /// Constructs a new `Arc<T>`.\n    ///\n    /// # Examples\n    ///\n    /// ```\n    /// use std::sync::Arc;\n    ///\n    /// let five = Arc::new(5);\n    /// ```\n    #[inline]\n    #[stable(feature = \"rust1\", since = \"1.0.0\")]\n    pub fn new(data: T) -> Arc<T> {\n        // Start the weak pointer count as 1 which is the weak pointer that's\n        // held by all the strong pointers (kinda), see std/rc.rs for more info\n        let x: Box<_> = box ArcInner {\n            strong: atomic::AtomicUsize::new(1),\n            weak: atomic::AtomicUsize::new(1),\n            data,\n        };\n        Self::from_inner(Box::leak(x).into())\n    }\n\n    /// Constructs a new `Arc<T>` using a weak reference to itself. Attempting\n    /// to upgrade the weak reference before this function returns will result\n    /// in a `None` value. However, the weak reference may be cloned freely and\n    /// stored for use at a later time.\n    ///\n    /// # Examples\n    /// ```\n    /// #![feature(arc_new_cyclic)]\n    /// #![allow(dead_code)]\n    ///\n    /// use std::sync::{Arc, Weak};\n    ///\n    /// struct Foo {\n    ///     me: Weak<Foo>,\n    /// }\n    ///\n    /// let foo = Arc::new_cyclic(|me| Foo {\n    ///     me: me.clone(),\n    /// });\n    /// ```\n    #[inline]\n    #[unstable(feature = \"arc_new_cyclic\", issue = \"75861\")]\n    pub fn new_cyclic(data_fn: impl FnOnce(&Weak<T>) -> T) -> Arc<T> {\n        // Construct the inner in the \"uninitialized\" state with a single\n        // weak reference.\n        let uninit_ptr: NonNull<_> = Box::leak(box ArcInner {\n            strong: atomic::AtomicUsize::new(0),\n            weak: atomic::AtomicUsize::new(1),\n            data: mem::MaybeUninit::<T>::uninit(),\n        })\n        .into();\n        let init_ptr: NonNull<ArcInner<T>> = uninit_ptr.cast();\n\n        let weak = Weak { ptr: init_ptr };\n\n        // It's important we don't give up ownership of the weak pointer, or\n        // else the memory might be freed by the time `data_fn` returns. If\n        // we really wanted to pass ownership, we could create an additional\n        // weak pointer for ourselves, but this would result in additional\n        // updates to the weak reference count which might not be necessary\n        // otherwise.\n        let data = data_fn(&weak);\n\n        // Now we can properly initialize the inner value and turn our weak\n        // reference into a strong reference.\n        unsafe {\n            let inner = init_ptr.as_ptr();\n            ptr::write(ptr::addr_of_mut!((*inner).data), data);\n\n            // The above write to the data field must be visible to any threads which\n            // observe a non-zero strong count. Therefore we need at least \"Release\" ordering\n            // in order to synchronize with the `compare_exchange_weak` in `Weak::upgrade`.\n            //\n            // \"Acquire\" ordering is not required. When considering the possible behaviours\n            // of `data_fn` we only need to look at what it could do with a reference to a\n            // non-upgradeable `Weak`:\n            // - It can *clone* the `Weak`, increasing the weak reference count.\n            // - It can drop those clones, decreasing the weak reference count (but never to zero).\n            //\n            // These side effects do not impact us in any way, and no other side effects are\n            // possible with safe code alone.\n            let prev_value = (*inner).strong.fetch_add(1, Release);\n            debug_assert_eq!(prev_value, 0, \"No prior strong references should exist\");\n        }\n\n        let strong = Arc::from_inner(init_ptr);\n\n        // Strong references should collectively own a shared weak reference,\n        // so don't run the destructor for our old weak reference.\n        mem::forget(weak);\n        strong\n    }\n\n    /// Constructs a new `Arc` with uninitialized contents.\n    ///\n    /// # Examples\n    ///\n    /// ```\n    /// #![feature(new_uninit)]\n    /// #![feature(get_mut_unchecked)]\n    ///\n    /// use std::sync::Arc;\n    ///\n    /// let mut five = Arc::<u32>::new_uninit();\n    ///\n    /// let five = unsafe {\n    ///     // Deferred initialization:\n    ///     Arc::get_mut_unchecked(&mut five).as_mut_ptr().write(5);\n    ///\n    ///     five.assume_init()\n    /// };\n    ///\n    /// assert_eq!(*five, 5)\n    /// ```\n    #[cfg(not(no_global_oom_handling))]\n    #[unstable(feature = \"new_uninit\", issue = \"63291\")]\n    pub fn new_uninit() -> Arc<mem::MaybeUninit<T>> {\n        unsafe {\n            Arc::from_ptr(Arc::allocate_for_layout(\n                Layout::new::<T>(),\n                |layout| Global.allocate(layout),\n                |mem| mem as *mut ArcInner<mem::MaybeUninit<T>>,\n            ))\n        }\n    }\n\n    /// Constructs a new `Arc` with uninitialized contents, with the memory\n    /// being filled with `0` bytes.\n    ///\n    /// See [`MaybeUninit::zeroed`][zeroed] for examples of correct and incorrect usage\n    /// of this method.\n    ///\n    /// # Examples\n    ///\n    /// ```\n    /// #![feature(new_uninit)]\n    ///\n    /// use std::sync::Arc;\n    ///\n    /// let zero = Arc::<u32>::new_zeroed();\n    /// let zero = unsafe { zero.assume_init() };\n    ///\n    /// assert_eq!(*zero, 0)\n    /// ```\n    ///\n    /// [zeroed]: ../../std/mem/union.MaybeUninit.html#method.zeroed\n    #[cfg(not(no_global_oom_handling))]\n    #[unstable(feature = \"new_uninit\", issue = \"63291\")]\n    pub fn new_zeroed() -> Arc<mem::MaybeUninit<T>> {\n        unsafe {\n            Arc::from_ptr(Arc::allocate_for_layout(\n                Layout::new::<T>(),\n                |layout| Global.allocate_zeroed(layout),\n                |mem| mem as *mut ArcInner<mem::MaybeUninit<T>>,\n            ))\n        }\n    }\n\n    /// Constructs a new `Pin<Arc<T>>`. If `T` does not implement `Unpin`, then\n    /// `data` will be pinned in memory and unable to be moved.\n    #[stable(feature = \"pin\", since = \"1.33.0\")]\n    pub fn pin(data: T) -> Pin<Arc<T>> {\n        unsafe { Pin::new_unchecked(Arc::new(data)) }\n    }\n\n    /// Constructs a new `Arc<T>`, returning an error if allocation fails.\n    ///\n    /// # Examples\n    ///\n    /// ```\n    /// #![feature(allocator_api)]\n    /// use std::sync::Arc;\n    ///\n    /// let five = Arc::try_new(5)?;\n    /// # Ok::<(), std::alloc::AllocError>(())\n    /// ```\n    #[unstable(feature = \"allocator_api\", issue = \"32838\")]\n    #[inline]\n    pub fn try_new(data: T) -> Result<Arc<T>, AllocError> {\n        // Start the weak pointer count as 1 which is the weak pointer that's\n        // held by all the strong pointers (kinda), see std/rc.rs for more info\n        let x: Box<_> = Box::try_new(ArcInner {\n            strong: atomic::AtomicUsize::new(1),\n            weak: atomic::AtomicUsize::new(1),\n            data,\n        })?;\n        Ok(Self::from_inner(Box::leak(x).into()))\n    }\n\n    /// Constructs a new `Arc` with uninitialized contents, returning an error\n    /// if allocation fails.\n    ///\n    /// # Examples\n    ///\n    /// ```\n    /// #![feature(new_uninit, allocator_api)]\n    /// #![feature(get_mut_unchecked)]\n    ///\n    /// use std::sync::Arc;\n    ///\n    /// let mut five = Arc::<u32>::try_new_uninit()?;\n    ///\n    /// let five = unsafe {\n    ///     // Deferred initialization:\n    ///     Arc::get_mut_unchecked(&mut five).as_mut_ptr().write(5);\n    ///\n    ///     five.assume_init()\n    /// };\n    ///\n    /// assert_eq!(*five, 5);\n    /// # Ok::<(), std::alloc::AllocError>(())\n    /// ```\n    #[unstable(feature = \"allocator_api\", issue = \"32838\")]\n    // #[unstable(feature = \"new_uninit\", issue = \"63291\")]\n    pub fn try_new_uninit() -> Result<Arc<mem::MaybeUninit<T>>, AllocError> {\n        unsafe {\n            Ok(Arc::from_ptr(Arc::try_allocate_for_layout(\n                Layout::new::<T>(),\n                |layout| Global.allocate(layout),\n                |mem| mem as *mut ArcInner<mem::MaybeUninit<T>>,\n            )?))\n        }\n    }\n\n    /// Constructs a new `Arc` with uninitialized contents, with the memory\n    /// being filled with `0` bytes, returning an error if allocation fails.\n    ///\n    /// See [`MaybeUninit::zeroed`][zeroed] for examples of correct and incorrect usage\n    /// of this method.\n    ///\n    /// # Examples\n    ///\n    /// ```\n    /// #![feature(new_uninit, allocator_api)]\n    ///\n    /// use std::sync::Arc;\n    ///\n    /// let zero = Arc::<u32>::try_new_zeroed()?;\n    /// let zero = unsafe { zero.assume_init() };\n    ///\n    /// assert_eq!(*zero, 0);\n    /// # Ok::<(), std::alloc::AllocError>(())\n    /// ```\n    ///\n    /// [zeroed]: mem::MaybeUninit::zeroed\n    #[unstable(feature = \"allocator_api\", issue = \"32838\")]\n    // #[unstable(feature = \"new_uninit\", issue = \"63291\")]\n    pub fn try_new_zeroed() -> Result<Arc<mem::MaybeUninit<T>>, AllocError> {\n        unsafe {\n            Ok(Arc::from_ptr(Arc::try_allocate_for_layout(\n                Layout::new::<T>(),\n                |layout| Global.allocate_zeroed(layout),\n                |mem| mem as *mut ArcInner<mem::MaybeUninit<T>>,\n            )?))\n        }\n    }\n    /// Returns the inner value, if the `Arc` has exactly one strong reference.\n    ///\n    /// Otherwise, an [`Err`] is returned with the same `Arc` that was\n    /// passed in.\n    ///\n    /// This will succeed even if there are outstanding weak references.\n    ///\n    /// # Examples\n    ///\n    /// ```\n    /// use std::sync::Arc;\n    ///\n    /// let x = Arc::new(3);\n    /// assert_eq!(Arc::try_unwrap(x), Ok(3));\n    ///\n    /// let x = Arc::new(4);\n    /// let _y = Arc::clone(&x);\n    /// assert_eq!(*Arc::try_unwrap(x).unwrap_err(), 4);\n    /// ```\n    #[inline]\n    #[stable(feature = \"arc_unique\", since = \"1.4.0\")]\n    pub fn try_unwrap(this: Self) -> Result<T, Self> {\n        if this.inner().strong.compare_exchange(1, 0, Relaxed, Relaxed).is_err() {\n            return Err(this);\n        }\n\n        acquire!(this.inner().strong);\n\n        unsafe {\n            let elem = ptr::read(&this.ptr.as_ref().data);\n\n            // Make a weak pointer to clean up the implicit strong-weak reference\n            let _weak = Weak { ptr: this.ptr };\n            mem::forget(this);\n\n            Ok(elem)\n        }\n    }\n}\n\nimpl<T> Arc<[T]> {\n    /// Constructs a new atomically reference-counted slice with uninitialized contents.\n    ///\n    /// # Examples\n    ///\n    /// ```\n    /// #![feature(new_uninit)]\n    /// #![feature(get_mut_unchecked)]\n    ///\n    /// use std::sync::Arc;\n    ///\n    /// let mut values = Arc::<[u32]>::new_uninit_slice(3);\n    ///\n    /// let values = unsafe {\n    ///     // Deferred initialization:\n    ///     Arc::get_mut_unchecked(&mut values)[0].as_mut_ptr().write(1);\n    ///     Arc::get_mut_unchecked(&mut values)[1].as_mut_ptr().write(2);\n    ///     Arc::get_mut_unchecked(&mut values)[2].as_mut_ptr().write(3);\n    ///\n    ///     values.assume_init()\n    /// };\n    ///\n    /// assert_eq!(*values, [1, 2, 3])\n    /// ```\n    #[cfg(not(no_global_oom_handling))]\n    #[unstable(feature = \"new_uninit\", issue = \"63291\")]\n    pub fn new_uninit_slice(len: usize) -> Arc<[mem::MaybeUninit<T>]> {\n        unsafe { Arc::from_ptr(Arc::allocate_for_slice(len)) }\n    }\n\n    /// Constructs a new atomically reference-counted slice with uninitialized contents, with the memory being\n    /// filled with `0` bytes.\n    ///\n    /// See [`MaybeUninit::zeroed`][zeroed] for examples of correct and\n    /// incorrect usage of this method.\n    ///\n    /// # Examples\n    ///\n    /// ```\n    /// #![feature(new_uninit)]\n    ///\n    /// use std::sync::Arc;\n    ///\n    /// let values = Arc::<[u32]>::new_zeroed_slice(3);\n    /// let values = unsafe { values.assume_init() };\n    ///\n    /// assert_eq!(*values, [0, 0, 0])\n    /// ```\n    ///\n    /// [zeroed]: ../../std/mem/union.MaybeUninit.html#method.zeroed\n    #[cfg(not(no_global_oom_handling))]\n    #[unstable(feature = \"new_uninit\", issue = \"63291\")]\n    pub fn new_zeroed_slice(len: usize) -> Arc<[mem::MaybeUninit<T>]> {\n        unsafe {\n            Arc::from_ptr(Arc::allocate_for_layout(\n                Layout::array::<T>(len).unwrap(),\n                |layout| Global.allocate_zeroed(layout),\n                |mem| {\n                    ptr::slice_from_raw_parts_mut(mem as *mut T, len)\n                        as *mut ArcInner<[mem::MaybeUninit<T>]>\n                },\n            ))\n        }\n    }\n}\n\nimpl<T> Arc<mem::MaybeUninit<T>> {\n    /// Converts to `Arc<T>`.\n    ///\n    /// # Safety\n    ///\n    /// As with [`MaybeUninit::assume_init`],\n    /// it is up to the caller to guarantee that the inner value\n    /// really is in an initialized state.\n    /// Calling this when the content is not yet fully initialized\n    /// causes immediate undefined behavior.\n    ///\n    /// [`MaybeUninit::assume_init`]: ../../std/mem/union.MaybeUninit.html#method.assume_init\n    ///\n    /// # Examples\n    ///\n    /// ```\n    /// #![feature(new_uninit)]\n    /// #![feature(get_mut_unchecked)]\n    ///\n    /// use std::sync::Arc;\n    ///\n    /// let mut five = Arc::<u32>::new_uninit();\n    ///\n    /// let five = unsafe {\n    ///     // Deferred initialization:\n    ///     Arc::get_mut_unchecked(&mut five).as_mut_ptr().write(5);\n    ///\n    ///     five.assume_init()\n    /// };\n    ///\n    /// assert_eq!(*five, 5)\n    /// ```\n    #[unstable(feature = \"new_uninit\", issue = \"63291\")]\n    #[inline]\n    pub unsafe fn assume_init(self) -> Arc<T> {\n        Arc::from_inner(mem::ManuallyDrop::new(self).ptr.cast())\n    }\n}\n\nimpl<T> Arc<[mem::MaybeUninit<T>]> {\n    /// Converts to `Arc<[T]>`.\n    ///\n    /// # Safety\n    ///\n    /// As with [`MaybeUninit::assume_init`],\n    /// it is up to the caller to guarantee that the inner value\n    /// really is in an initialized state.\n    /// Calling this when the content is not yet fully initialized\n    /// causes immediate undefined behavior.\n    ///\n    /// [`MaybeUninit::assume_init`]: ../../std/mem/union.MaybeUninit.html#method.assume_init\n    ///\n    /// # Examples\n    ///\n    /// ```\n    /// #![feature(new_uninit)]\n    /// #![feature(get_mut_unchecked)]\n    ///\n    /// use std::sync::Arc;\n    ///\n    /// let mut values = Arc::<[u32]>::new_uninit_slice(3);\n    ///\n    /// let values = unsafe {\n    ///     // Deferred initialization:\n    ///     Arc::get_mut_unchecked(&mut values)[0].as_mut_ptr().write(1);\n    ///     Arc::get_mut_unchecked(&mut values)[1].as_mut_ptr().write(2);\n    ///     Arc::get_mut_unchecked(&mut values)[2].as_mut_ptr().write(3);\n    ///\n    ///     values.assume_init()\n    /// };\n    ///\n    /// assert_eq!(*values, [1, 2, 3])\n    /// ```\n    #[unstable(feature = \"new_uninit\", issue = \"63291\")]\n    #[inline]\n    pub unsafe fn assume_init(self) -> Arc<[T]> {\n        unsafe { Arc::from_ptr(mem::ManuallyDrop::new(self).ptr.as_ptr() as _) }\n    }\n}\n\nimpl<T: ?Sized> Arc<T> {\n    /// Consumes the `Arc`, returning the wrapped pointer.\n    ///\n    /// To avoid a memory leak the pointer must be converted back to an `Arc` using\n    /// [`Arc::from_raw`].\n    ///\n    /// # Examples\n    ///\n    /// ```\n    /// use std::sync::Arc;\n    ///\n    /// let x = Arc::new(\"hello\".to_owned());\n    /// let x_ptr = Arc::into_raw(x);\n    /// assert_eq!(unsafe { &*x_ptr }, \"hello\");\n    /// ```\n    #[stable(feature = \"rc_raw\", since = \"1.17.0\")]\n    pub fn into_raw(this: Self) -> *const T {\n        let ptr = Self::as_ptr(&this);\n        mem::forget(this);\n        ptr\n    }\n\n    /// Provides a raw pointer to the data.\n    ///\n    /// The counts are not affected in any way and the `Arc` is not consumed. The pointer is valid for\n    /// as long as there are strong counts in the `Arc`.\n    ///\n    /// # Examples\n    ///\n    /// ```\n    /// use std::sync::Arc;\n    ///\n    /// let x = Arc::new(\"hello\".to_owned());\n    /// let y = Arc::clone(&x);\n    /// let x_ptr = Arc::as_ptr(&x);\n    /// assert_eq!(x_ptr, Arc::as_ptr(&y));\n    /// assert_eq!(unsafe { &*x_ptr }, \"hello\");\n    /// ```\n    #[stable(feature = \"rc_as_ptr\", since = \"1.45.0\")]\n    pub fn as_ptr(this: &Self) -> *const T {\n        let ptr: *mut ArcInner<T> = NonNull::as_ptr(this.ptr);\n\n        // SAFETY: This cannot go through Deref::deref or RcBoxPtr::inner because\n        // this is required to retain raw/mut provenance such that e.g. `get_mut` can\n        // write through the pointer after the Rc is recovered through `from_raw`.\n        unsafe { ptr::addr_of_mut!((*ptr).data) }\n    }\n\n    /// Constructs an `Arc<T>` from a raw pointer.\n    ///\n    /// The raw pointer must have been previously returned by a call to\n    /// [`Arc<U>::into_raw`][into_raw] where `U` must have the same size and\n    /// alignment as `T`. This is trivially true if `U` is `T`.\n    /// Note that if `U` is not `T` but has the same size and alignment, this is\n    /// basically like transmuting references of different types. See\n    /// [`mem::transmute`][transmute] for more information on what\n    /// restrictions apply in this case.\n    ///\n    /// The user of `from_raw` has to make sure a specific value of `T` is only\n    /// dropped once.\n    ///\n    /// This function is unsafe because improper use may lead to memory unsafety,\n    /// even if the returned `Arc<T>` is never accessed.\n    ///\n    /// [into_raw]: Arc::into_raw\n    /// [transmute]: core::mem::transmute\n    ///\n    /// # Examples\n    ///\n    /// ```\n    /// use std::sync::Arc;\n    ///\n    /// let x = Arc::new(\"hello\".to_owned());\n    /// let x_ptr = Arc::into_raw(x);\n    ///\n    /// unsafe {\n    ///     // Convert back to an `Arc` to prevent leak.\n    ///     let x = Arc::from_raw(x_ptr);\n    ///     assert_eq!(&*x, \"hello\");\n    ///\n    ///     // Further calls to `Arc::from_raw(x_ptr)` would be memory-unsafe.\n    /// }\n    ///\n    /// // The memory was freed when `x` went out of scope above, so `x_ptr` is now dangling!\n    /// ```\n    #[stable(feature = \"rc_raw\", since = \"1.17.0\")]\n    pub unsafe fn from_raw(ptr: *const T) -> Self {\n        unsafe {\n            let offset = data_offset(ptr);\n\n            // Reverse the offset to find the original ArcInner.\n            let arc_ptr = (ptr as *mut ArcInner<T>).set_ptr_value((ptr as *mut u8).offset(-offset));\n\n            Self::from_ptr(arc_ptr)\n        }\n    }\n\n    /// Creates a new [`Weak`] pointer to this allocation.\n    ///\n    /// # Examples\n    ///\n    /// ```\n    /// use std::sync::Arc;\n    ///\n    /// let five = Arc::new(5);\n    ///\n    /// let weak_five = Arc::downgrade(&five);\n    /// ```\n    #[stable(feature = \"arc_weak\", since = \"1.4.0\")]\n    pub fn downgrade(this: &Self) -> Weak<T> {\n        // This Relaxed is OK because we're checking the value in the CAS\n        // below.\n        let mut cur = this.inner().weak.load(Relaxed);\n\n        loop {\n            // check if the weak counter is currently \"locked\"; if so, spin.\n            if cur == usize::MAX {\n                hint::spin_loop();\n                cur = this.inner().weak.load(Relaxed);\n                continue;\n            }\n\n            // NOTE: this code currently ignores the possibility of overflow\n            // into usize::MAX; in general both Rc and Arc need to be adjusted\n            // to deal with overflow.\n\n            // Unlike with Clone(), we need this to be an Acquire read to\n            // synchronize with the write coming from `is_unique`, so that the\n            // events prior to that write happen before this read.\n            match this.inner().weak.compare_exchange_weak(cur, cur + 1, Acquire, Relaxed) {\n                Ok(_) => {\n                    // Make sure we do not create a dangling Weak\n                    debug_assert!(!is_dangling(this.ptr.as_ptr()));\n                    return Weak { ptr: this.ptr };\n                }\n                Err(old) => cur = old,\n            }\n        }\n    }\n\n    /// Gets the number of [`Weak`] pointers to this allocation.\n    ///\n    /// # Safety\n    ///\n    /// This method by itself is safe, but using it correctly requires extra care.\n    /// Another thread can change the weak count at any time,\n    /// including potentially between calling this method and acting on the result.\n    ///\n    /// # Examples\n    ///\n    /// ```\n    /// use std::sync::Arc;\n    ///\n    /// let five = Arc::new(5);\n    /// let _weak_five = Arc::downgrade(&five);\n    ///\n    /// // This assertion is deterministic because we haven't shared\n    /// // the `Arc` or `Weak` between threads.\n    /// assert_eq!(1, Arc::weak_count(&five));\n    /// ```\n    #[inline]\n    #[stable(feature = \"arc_counts\", since = \"1.15.0\")]\n    pub fn weak_count(this: &Self) -> usize {\n        let cnt = this.inner().weak.load(SeqCst);\n        // If the weak count is currently locked, the value of the\n        // count was 0 just before taking the lock.\n        if cnt == usize::MAX { 0 } else { cnt - 1 }\n    }\n\n    /// Gets the number of strong (`Arc`) pointers to this allocation.\n    ///\n    /// # Safety\n    ///\n    /// This method by itself is safe, but using it correctly requires extra care.\n    /// Another thread can change the strong count at any time,\n    /// including potentially between calling this method and acting on the result.\n    ///\n    /// # Examples\n    ///\n    /// ```\n    /// use std::sync::Arc;\n    ///\n    /// let five = Arc::new(5);\n    /// let _also_five = Arc::clone(&five);\n    ///\n    /// // This assertion is deterministic because we haven't shared\n    /// // the `Arc` between threads.\n    /// assert_eq!(2, Arc::strong_count(&five));\n    /// ```\n    #[inline]\n    #[stable(feature = \"arc_counts\", since = \"1.15.0\")]\n    pub fn strong_count(this: &Self) -> usize {\n        this.inner().strong.load(SeqCst)\n    }\n\n    /// Increments the strong reference count on the `Arc<T>` associated with the\n    /// provided pointer by one.\n    ///\n    /// # Safety\n    ///\n    /// The pointer must have been obtained through `Arc::into_raw`, and the\n    /// associated `Arc` instance must be valid (i.e. the strong count must be at\n    /// least 1) for the duration of this method.\n    ///\n    /// # Examples\n    ///\n    /// ```\n    /// use std::sync::Arc;\n    ///\n    /// let five = Arc::new(5);\n    ///\n    /// unsafe {\n    ///     let ptr = Arc::into_raw(five);\n    ///     Arc::increment_strong_count(ptr);\n    ///\n    ///     // This assertion is deterministic because we haven't shared\n    ///     // the `Arc` between threads.\n    ///     let five = Arc::from_raw(ptr);\n    ///     assert_eq!(2, Arc::strong_count(&five));\n    /// }\n    /// ```\n    #[inline]\n    #[stable(feature = \"arc_mutate_strong_count\", since = \"1.51.0\")]\n    pub unsafe fn increment_strong_count(ptr: *const T) {\n        // Retain Arc, but don't touch refcount by wrapping in ManuallyDrop\n        let arc = unsafe { mem::ManuallyDrop::new(Arc::<T>::from_raw(ptr)) };\n        // Now increase refcount, but don't drop new refcount either\n        let _arc_clone: mem::ManuallyDrop<_> = arc.clone();\n    }\n\n    /// Decrements the strong reference count on the `Arc<T>` associated with the\n    /// provided pointer by one.\n    ///\n    /// # Safety\n    ///\n    /// The pointer must have been obtained through `Arc::into_raw`, and the\n    /// associated `Arc` instance must be valid (i.e. the strong count must be at\n    /// least 1) when invoking this method. This method can be used to release the final\n    /// `Arc` and backing storage, but **should not** be called after the final `Arc` has been\n    /// released.\n    ///\n    /// # Examples\n    ///\n    /// ```\n    /// use std::sync::Arc;\n    ///\n    /// let five = Arc::new(5);\n    ///\n    /// unsafe {\n    ///     let ptr = Arc::into_raw(five);\n    ///     Arc::increment_strong_count(ptr);\n    ///\n    ///     // Those assertions are deterministic because we haven't shared\n    ///     // the `Arc` between threads.\n    ///     let five = Arc::from_raw(ptr);\n    ///     assert_eq!(2, Arc::strong_count(&five));\n    ///     Arc::decrement_strong_count(ptr);\n    ///     assert_eq!(1, Arc::strong_count(&five));\n    /// }\n    /// ```\n    #[inline]\n    #[stable(feature = \"arc_mutate_strong_count\", since = \"1.51.0\")]\n    pub unsafe fn decrement_strong_count(ptr: *const T) {\n        unsafe { mem::drop(Arc::from_raw(ptr)) };\n    }\n\n    #[inline]\n    fn inner(&self) -> &ArcInner<T> {\n        // This unsafety is ok because while this arc is alive we're guaranteed\n        // that the inner pointer is valid. Furthermore, we know that the\n        // `ArcInner` structure itself is `Sync` because the inner data is\n        // `Sync` as well, so we're ok loaning out an immutable pointer to these\n        // contents.\n        unsafe { self.ptr.as_ref() }\n    }\n\n    // Non-inlined part of `drop`.\n    #[inline(never)]\n    unsafe fn drop_slow(&mut self) {\n        // Destroy the data at this time, even though we may not free the box\n        // allocation itself (there may still be weak pointers lying around).\n        unsafe { ptr::drop_in_place(Self::get_mut_unchecked(self)) };\n\n        // Drop the weak ref collectively held by all strong references\n        drop(Weak { ptr: self.ptr });\n    }\n\n    #[inline]\n    #[stable(feature = \"ptr_eq\", since = \"1.17.0\")]\n    /// Returns `true` if the two `Arc`s point to the same allocation\n    /// (in a vein similar to [`ptr::eq`]).\n    ///\n    /// # Examples\n    ///\n    /// ```\n    /// use std::sync::Arc;\n    ///\n    /// let five = Arc::new(5);\n    /// let same_five = Arc::clone(&five);\n    /// let other_five = Arc::new(5);\n    ///\n    /// assert!(Arc::ptr_eq(&five, &same_five));\n    /// assert!(!Arc::ptr_eq(&five, &other_five));\n    /// ```\n    ///\n    /// [`ptr::eq`]: core::ptr::eq\n    pub fn ptr_eq(this: &Self, other: &Self) -> bool {\n        this.ptr.as_ptr() == other.ptr.as_ptr()\n    }\n}\n\nimpl<T: ?Sized> Arc<T> {\n    /// Allocates an `ArcInner<T>` with sufficient space for\n    /// a possibly-unsized inner value where the value has the layout provided.\n    ///\n    /// The function `mem_to_arcinner` is called with the data pointer\n    /// and must return back a (potentially fat)-pointer for the `ArcInner<T>`.\n    #[cfg(not(no_global_oom_handling))]\n    unsafe fn allocate_for_layout(\n        value_layout: Layout,\n        allocate: impl FnOnce(Layout) -> Result<NonNull<[u8]>, AllocError>,\n        mem_to_arcinner: impl FnOnce(*mut u8) -> *mut ArcInner<T>,\n    ) -> *mut ArcInner<T> {\n        // Calculate layout using the given value layout.\n        // Previously, layout was calculated on the expression\n        // `&*(ptr as *const ArcInner<T>)`, but this created a misaligned\n        // reference (see #54908).\n        let layout = Layout::new::<ArcInner<()>>().extend(value_layout).unwrap().0.pad_to_align();\n        unsafe {\n            Arc::try_allocate_for_layout(value_layout, allocate, mem_to_arcinner)\n                .unwrap_or_else(|_| handle_alloc_error(layout))\n        }\n    }\n\n    /// Allocates an `ArcInner<T>` with sufficient space for\n    /// a possibly-unsized inner value where the value has the layout provided,\n    /// returning an error if allocation fails.\n    ///\n    /// The function `mem_to_arcinner` is called with the data pointer\n    /// and must return back a (potentially fat)-pointer for the `ArcInner<T>`.\n    unsafe fn try_allocate_for_layout(\n        value_layout: Layout,\n        allocate: impl FnOnce(Layout) -> Result<NonNull<[u8]>, AllocError>,\n        mem_to_arcinner: impl FnOnce(*mut u8) -> *mut ArcInner<T>,\n    ) -> Result<*mut ArcInner<T>, AllocError> {\n        // Calculate layout using the given value layout.\n        // Previously, layout was calculated on the expression\n        // `&*(ptr as *const ArcInner<T>)`, but this created a misaligned\n        // reference (see #54908).\n        let layout = Layout::new::<ArcInner<()>>().extend(value_layout).unwrap().0.pad_to_align();\n\n        let ptr = allocate(layout)?;\n\n        // Initialize the ArcInner\n        let inner = mem_to_arcinner(ptr.as_non_null_ptr().as_ptr());\n        debug_assert_eq!(unsafe { Layout::for_value(&*inner) }, layout);\n\n        unsafe {\n            ptr::write(&mut (*inner).strong, atomic::AtomicUsize::new(1));\n            ptr::write(&mut (*inner).weak, atomic::AtomicUsize::new(1));\n        }\n\n        Ok(inner)\n    }\n\n    /// Allocates an `ArcInner<T>` with sufficient space for an unsized inner value.\n    #[cfg(not(no_global_oom_handling))]\n    unsafe fn allocate_for_ptr(ptr: *const T) -> *mut ArcInner<T> {\n        // Allocate for the `ArcInner<T>` using the given value.\n        unsafe {\n            Self::allocate_for_layout(\n                Layout::for_value(&*ptr),\n                |layout| Global.allocate(layout),\n                |mem| (ptr as *mut ArcInner<T>).set_ptr_value(mem) as *mut ArcInner<T>,\n            )\n        }\n    }\n\n    #[cfg(not(no_global_oom_handling))]\n    fn from_box(v: Box<T>) -> Arc<T> {\n        unsafe {\n            let (box_unique, alloc) = Box::into_unique(v);\n            let bptr = box_unique.as_ptr();\n\n            let value_size = size_of_val(&*bptr);\n            let ptr = Self::allocate_for_ptr(bptr);\n\n            // Copy value as bytes\n            ptr::copy_nonoverlapping(\n                bptr as *const T as *const u8,\n                &mut (*ptr).data as *mut _ as *mut u8,\n                value_size,\n            );\n\n            // Free the allocation without dropping its contents\n            box_free(box_unique, alloc);\n\n            Self::from_ptr(ptr)\n        }\n    }\n}\n\nimpl<T> Arc<[T]> {\n    /// Allocates an `ArcInner<[T]>` with the given length.\n    #[cfg(not(no_global_oom_handling))]\n    unsafe fn allocate_for_slice(len: usize) -> *mut ArcInner<[T]> {\n        unsafe {\n            Self::allocate_for_layout(\n                Layout::array::<T>(len).unwrap(),\n                |layout| Global.allocate(layout),\n                |mem| ptr::slice_from_raw_parts_mut(mem as *mut T, len) as *mut ArcInner<[T]>,\n            )\n        }\n    }\n\n    /// Copy elements from slice into newly allocated Arc<\\[T\\]>\n    ///\n    /// Unsafe because the caller must either take ownership or bind `T: Copy`.\n    #[cfg(not(no_global_oom_handling))]\n    unsafe fn copy_from_slice(v: &[T]) -> Arc<[T]> {\n        unsafe {\n            let ptr = Self::allocate_for_slice(v.len());\n\n            ptr::copy_nonoverlapping(v.as_ptr(), &mut (*ptr).data as *mut [T] as *mut T, v.len());\n\n            Self::from_ptr(ptr)\n        }\n    }\n\n    /// Constructs an `Arc<[T]>` from an iterator known to be of a certain size.\n    ///\n    /// Behavior is undefined should the size be wrong.\n    #[cfg(not(no_global_oom_handling))]\n    unsafe fn from_iter_exact(iter: impl iter::Iterator<Item = T>, len: usize) -> Arc<[T]> {\n        // Panic guard while cloning T elements.\n        // In the event of a panic, elements that have been written\n        // into the new ArcInner will be dropped, then the memory freed.\n        struct Guard<T> {\n            mem: NonNull<u8>,\n            elems: *mut T,\n            layout: Layout,\n            n_elems: usize,\n        }\n\n        impl<T> Drop for Guard<T> {\n            fn drop(&mut self) {\n                unsafe {\n                    let slice = from_raw_parts_mut(self.elems, self.n_elems);\n                    ptr::drop_in_place(slice);\n\n                    Global.deallocate(self.mem, self.layout);\n                }\n            }\n        }\n\n        unsafe {\n            let ptr = Self::allocate_for_slice(len);\n\n            let mem = ptr as *mut _ as *mut u8;\n            let layout = Layout::for_value(&*ptr);\n\n            // Pointer to first element\n            let elems = &mut (*ptr).data as *mut [T] as *mut T;\n\n            let mut guard = Guard { mem: NonNull::new_unchecked(mem), elems, layout, n_elems: 0 };\n\n            for (i, item) in iter.enumerate() {\n                ptr::write(elems.add(i), item);\n                guard.n_elems += 1;\n            }\n\n            // All clear. Forget the guard so it doesn't free the new ArcInner.\n            mem::forget(guard);\n\n            Self::from_ptr(ptr)\n        }\n    }\n}\n\n/// Specialization trait used for `From<&[T]>`.\n#[cfg(not(no_global_oom_handling))]\ntrait ArcFromSlice<T> {\n    fn from_slice(slice: &[T]) -> Self;\n}\n\n#[cfg(not(no_global_oom_handling))]\nimpl<T: Clone> ArcFromSlice<T> for Arc<[T]> {\n    #[inline]\n    default fn from_slice(v: &[T]) -> Self {\n        unsafe { Self::from_iter_exact(v.iter().cloned(), v.len()) }\n    }\n}\n\n#[cfg(not(no_global_oom_handling))]\nimpl<T: Copy> ArcFromSlice<T> for Arc<[T]> {\n    #[inline]\n    fn from_slice(v: &[T]) -> Self {\n        unsafe { Arc::copy_from_slice(v) }\n    }\n}\n\n#[stable(feature = \"rust1\", since = \"1.0.0\")]\nimpl<T: ?Sized> Clone for Arc<T> {\n    /// Makes a clone of the `Arc` pointer.\n    ///\n    /// This creates another pointer to the same allocation, increasing the\n    /// strong reference count.\n    ///\n    /// # Examples\n    ///\n    /// ```\n    /// use std::sync::Arc;\n    ///\n    /// let five = Arc::new(5);\n    ///\n    /// let _ = Arc::clone(&five);\n    /// ```\n    #[inline]\n    fn clone(&self) -> Arc<T> {\n        // Using a relaxed ordering is alright here, as knowledge of the\n        // original reference prevents other threads from erroneously deleting\n        // the object.\n        //\n        // As explained in the [Boost documentation][1], Increasing the\n        // reference counter can always be done with memory_order_relaxed: New\n        // references to an object can only be formed from an existing\n        // reference, and passing an existing reference from one thread to\n        // another must already provide any required synchronization.\n        //\n        // [1]: (www.boost.org/doc/libs/1_55_0/doc/html/atomic/usage_examples.html)\n        let old_size = self.inner().strong.fetch_add(1, Relaxed);\n\n        // However we need to guard against massive refcounts in case someone\n        // is `mem::forget`ing Arcs. If we don't do this the count can overflow\n        // and users will use-after free. We racily saturate to `isize::MAX` on\n        // the assumption that there aren't ~2 billion threads incrementing\n        // the reference count at once. This branch will never be taken in\n        // any realistic program.\n        //\n        // We abort because such a program is incredibly degenerate, and we\n        // don't care to support it.\n        if old_size > MAX_REFCOUNT {\n            abort();\n        }\n\n        Self::from_inner(self.ptr)\n    }\n}\n\n#[stable(feature = \"rust1\", since = \"1.0.0\")]\nimpl<T: ?Sized> Deref for Arc<T> {\n    type Target = T;\n\n    #[inline]\n    fn deref(&self) -> &T {\n        &self.inner().data\n    }\n}\n\n#[unstable(feature = \"receiver_trait\", issue = \"none\")]\nimpl<T: ?Sized> Receiver for Arc<T> {}\n\nimpl<T: Clone> Arc<T> {\n    /// Makes a mutable reference into the given `Arc`.\n    ///\n    /// If there are other `Arc` or [`Weak`] pointers to the same allocation,\n    /// then `make_mut` will create a new allocation and invoke [`clone`][clone] on the inner value\n    /// to ensure unique ownership. This is also referred to as clone-on-write.\n    ///\n    /// Note that this differs from the behavior of [`Rc::make_mut`] which disassociates\n    /// any remaining `Weak` pointers.\n    ///\n    /// See also [`get_mut`][get_mut], which will fail rather than cloning.\n    ///\n    /// [clone]: Clone::clone\n    /// [get_mut]: Arc::get_mut\n    /// [`Rc::make_mut`]: super::rc::Rc::make_mut\n    ///\n    /// # Examples\n    ///\n    /// ```\n    /// use std::sync::Arc;\n    ///\n    /// let mut data = Arc::new(5);\n    ///\n    /// *Arc::make_mut(&mut data) += 1;         // Won't clone anything\n    /// let mut other_data = Arc::clone(&data); // Won't clone inner data\n    /// *Arc::make_mut(&mut data) += 1;         // Clones inner data\n    /// *Arc::make_mut(&mut data) += 1;         // Won't clone anything\n    /// *Arc::make_mut(&mut other_data) *= 2;   // Won't clone anything\n    ///\n    /// // Now `data` and `other_data` point to different allocations.\n    /// assert_eq!(*data, 8);\n    /// assert_eq!(*other_data, 12);\n    /// ```\n    #[cfg(not(no_global_oom_handling))]\n    #[inline]\n    #[stable(feature = \"arc_unique\", since = \"1.4.0\")]\n    pub fn make_mut(this: &mut Self) -> &mut T {\n        // Note that we hold both a strong reference and a weak reference.\n        // Thus, releasing our strong reference only will not, by itself, cause\n        // the memory to be deallocated.\n        //\n        // Use Acquire to ensure that we see any writes to `weak` that happen\n        // before release writes (i.e., decrements) to `strong`. Since we hold a\n        // weak count, there's no chance the ArcInner itself could be\n        // deallocated.\n        if this.inner().strong.compare_exchange(1, 0, Acquire, Relaxed).is_err() {\n            // Another strong pointer exists, so we must clone.\n            // Pre-allocate memory to allow writing the cloned value directly.\n            let mut arc = Self::new_uninit();\n            unsafe {\n                let data = Arc::get_mut_unchecked(&mut arc);\n                (**this).write_clone_into_raw(data.as_mut_ptr());\n                *this = arc.assume_init();\n            }\n        } else if this.inner().weak.load(Relaxed) != 1 {\n            // Relaxed suffices in the above because this is fundamentally an\n            // optimization: we are always racing with weak pointers being\n            // dropped. Worst case, we end up allocated a new Arc unnecessarily.\n\n            // We removed the last strong ref, but there are additional weak\n            // refs remaining. We'll move the contents to a new Arc, and\n            // invalidate the other weak refs.\n\n            // Note that it is not possible for the read of `weak` to yield\n            // usize::MAX (i.e., locked), since the weak count can only be\n            // locked by a thread with a strong reference.\n\n            // Materialize our own implicit weak pointer, so that it can clean\n            // up the ArcInner as needed.\n            let _weak = Weak { ptr: this.ptr };\n\n            // Can just steal the data, all that's left is Weaks\n            let mut arc = Self::new_uninit();\n            unsafe {\n                let data = Arc::get_mut_unchecked(&mut arc);\n                data.as_mut_ptr().copy_from_nonoverlapping(&**this, 1);\n                ptr::write(this, arc.assume_init());\n            }\n        } else {\n            // We were the sole reference of either kind; bump back up the\n            // strong ref count.\n            this.inner().strong.store(1, Release);\n        }\n\n        // As with `get_mut()`, the unsafety is ok because our reference was\n        // either unique to begin with, or became one upon cloning the contents.\n        unsafe { Self::get_mut_unchecked(this) }\n    }\n}\n\nimpl<T: ?Sized> Arc<T> {\n    /// Returns a mutable reference into the given `Arc`, if there are\n    /// no other `Arc` or [`Weak`] pointers to the same allocation.\n    ///\n    /// Returns [`None`] otherwise, because it is not safe to\n    /// mutate a shared value.\n    ///\n    /// See also [`make_mut`][make_mut], which will [`clone`][clone]\n    /// the inner value when there are other pointers.\n    ///\n    /// [make_mut]: Arc::make_mut\n    /// [clone]: Clone::clone\n    ///\n    /// # Examples\n    ///\n    /// ```\n    /// use std::sync::Arc;\n    ///\n    /// let mut x = Arc::new(3);\n    /// *Arc::get_mut(&mut x).unwrap() = 4;\n    /// assert_eq!(*x, 4);\n    ///\n    /// let _y = Arc::clone(&x);\n    /// assert!(Arc::get_mut(&mut x).is_none());\n    /// ```\n    #[inline]\n    #[stable(feature = \"arc_unique\", since = \"1.4.0\")]\n    pub fn get_mut(this: &mut Self) -> Option<&mut T> {\n        if this.is_unique() {\n            // This unsafety is ok because we're guaranteed that the pointer\n            // returned is the *only* pointer that will ever be returned to T. Our\n            // reference count is guaranteed to be 1 at this point, and we required\n            // the Arc itself to be `mut`, so we're returning the only possible\n            // reference to the inner data.\n            unsafe { Some(Arc::get_mut_unchecked(this)) }\n        } else {\n            None\n        }\n    }\n\n    /// Returns a mutable reference into the given `Arc`,\n    /// without any check.\n    ///\n    /// See also [`get_mut`], which is safe and does appropriate checks.\n    ///\n    /// [`get_mut`]: Arc::get_mut\n    ///\n    /// # Safety\n    ///\n    /// Any other `Arc` or [`Weak`] pointers to the same allocation must not be dereferenced\n    /// for the duration of the returned borrow.\n    /// This is trivially the case if no such pointers exist,\n    /// for example immediately after `Arc::new`.\n    ///\n    /// # Examples\n    ///\n    /// ```\n    /// #![feature(get_mut_unchecked)]\n    ///\n    /// use std::sync::Arc;\n    ///\n    /// let mut x = Arc::new(String::new());\n    /// unsafe {\n    ///     Arc::get_mut_unchecked(&mut x).push_str(\"foo\")\n    /// }\n    /// assert_eq!(*x, \"foo\");\n    /// ```\n    #[inline]\n    #[unstable(feature = \"get_mut_unchecked\", issue = \"63292\")]\n    pub unsafe fn get_mut_unchecked(this: &mut Self) -> &mut T {\n        // We are careful to *not* create a reference covering the \"count\" fields, as\n        // this would alias with concurrent access to the reference counts (e.g. by `Weak`).\n        unsafe { &mut (*this.ptr.as_ptr()).data }\n    }\n\n    /// Determine whether this is the unique reference (including weak refs) to\n    /// the underlying data.\n    ///\n    /// Note that this requires locking the weak ref count.\n    fn is_unique(&mut self) -> bool {\n        // lock the weak pointer count if we appear to be the sole weak pointer\n        // holder.\n        //\n        // The acquire label here ensures a happens-before relationship with any\n        // writes to `strong` (in particular in `Weak::upgrade`) prior to decrements\n        // of the `weak` count (via `Weak::drop`, which uses release).  If the upgraded\n        // weak ref was never dropped, the CAS here will fail so we do not care to synchronize.\n        if self.inner().weak.compare_exchange(1, usize::MAX, Acquire, Relaxed).is_ok() {\n            // This needs to be an `Acquire` to synchronize with the decrement of the `strong`\n            // counter in `drop` -- the only access that happens when any but the last reference\n            // is being dropped.\n            let unique = self.inner().strong.load(Acquire) == 1;\n\n            // The release write here synchronizes with a read in `downgrade`,\n            // effectively preventing the above read of `strong` from happening\n            // after the write.\n            self.inner().weak.store(1, Release); // release the lock\n            unique\n        } else {\n            false\n        }\n    }\n}\n\n#[stable(feature = \"rust1\", since = \"1.0.0\")]\nunsafe impl<#[may_dangle] T: ?Sized> Drop for Arc<T> {\n    /// Drops the `Arc`.\n    ///\n    /// This will decrement the strong reference count. If the strong reference\n    /// count reaches zero then the only other references (if any) are\n    /// [`Weak`], so we `drop` the inner value.\n    ///\n    /// # Examples\n    ///\n    /// ```\n    /// use std::sync::Arc;\n    ///\n    /// struct Foo;\n    ///\n    /// impl Drop for Foo {\n    ///     fn drop(&mut self) {\n    ///         println!(\"dropped!\");\n    ///     }\n    /// }\n    ///\n    /// let foo  = Arc::new(Foo);\n    /// let foo2 = Arc::clone(&foo);\n    ///\n    /// drop(foo);    // Doesn't print anything\n    /// drop(foo2);   // Prints \"dropped!\"\n    /// ```\n    #[inline]\n    fn drop(&mut self) {\n        // Because `fetch_sub` is already atomic, we do not need to synchronize\n        // with other threads unless we are going to delete the object. This\n        // same logic applies to the below `fetch_sub` to the `weak` count.\n        if self.inner().strong.fetch_sub(1, Release) != 1 {\n            return;\n        }\n\n        // This fence is needed to prevent reordering of use of the data and\n        // deletion of the data.  Because it is marked `Release`, the decreasing\n        // of the reference count synchronizes with this `Acquire` fence. This\n        // means that use of the data happens before decreasing the reference\n        // count, which happens before this fence, which happens before the\n        // deletion of the data.\n        //\n        // As explained in the [Boost documentation][1],\n        //\n        // > It is important to enforce any possible access to the object in one\n        // > thread (through an existing reference) to *happen before* deleting\n        // > the object in a different thread. This is achieved by a \"release\"\n        // > operation after dropping a reference (any access to the object\n        // > through this reference must obviously happened before), and an\n        // > \"acquire\" operation before deleting the object.\n        //\n        // In particular, while the contents of an Arc are usually immutable, it's\n        // possible to have interior writes to something like a Mutex<T>. Since a\n        // Mutex is not acquired when it is deleted, we can't rely on its\n        // synchronization logic to make writes in thread A visible to a destructor\n        // running in thread B.\n        //\n        // Also note that the Acquire fence here could probably be replaced with an\n        // Acquire load, which could improve performance in highly-contended\n        // situations. See [2].\n        //\n        // [1]: (www.boost.org/doc/libs/1_55_0/doc/html/atomic/usage_examples.html)\n        // [2]: (https://github.com/rust-lang/rust/pull/41714)\n        acquire!(self.inner().strong);\n\n        unsafe {\n            self.drop_slow();\n        }\n    }\n}\n\nimpl Arc<dyn Any + Send + Sync> {\n    #[inline]\n    #[stable(feature = \"rc_downcast\", since = \"1.29.0\")]\n    /// Attempt to downcast the `Arc<dyn Any + Send + Sync>` to a concrete type.\n    ///\n    /// # Examples\n    ///\n    /// ```\n    /// use std::any::Any;\n    /// use std::sync::Arc;\n    ///\n    /// fn print_if_string(value: Arc<dyn Any + Send + Sync>) {\n    ///     if let Ok(string) = value.downcast::<String>() {\n    ///         println!(\"String ({}): {}\", string.len(), string);\n    ///     }\n    /// }\n    ///\n    /// let my_string = \"Hello World\".to_string();\n    /// print_if_string(Arc::new(my_string));\n    /// print_if_string(Arc::new(0i8));\n    /// ```\n    pub fn downcast<T>(self) -> Result<Arc<T>, Self>\n    where\n        T: Any + Send + Sync + 'static,\n    {\n        if (*self).is::<T>() {\n            let ptr = self.ptr.cast::<ArcInner<T>>();\n            mem::forget(self);\n            Ok(Arc::from_inner(ptr))\n        } else {\n            Err(self)\n        }\n    }\n}\n\nimpl<T> Weak<T> {\n    /// Constructs a new `Weak<T>`, without allocating any memory.\n    /// Calling [`upgrade`] on the return value always gives [`None`].\n    ///\n    /// [`upgrade`]: Weak::upgrade\n    ///\n    /// # Examples\n    ///\n    /// ```\n    /// use std::sync::Weak;\n    ///\n    /// let empty: Weak<i64> = Weak::new();\n    /// assert!(empty.upgrade().is_none());\n    /// ```\n    #[stable(feature = \"downgraded_weak\", since = \"1.10.0\")]\n    pub fn new() -> Weak<T> {\n        Weak { ptr: NonNull::new(usize::MAX as *mut ArcInner<T>).expect(\"MAX is not 0\") }\n    }\n}\n\n/// Helper type to allow accessing the reference counts without\n/// making any assertions about the data field.\nstruct WeakInner<'a> {\n    weak: &'a atomic::AtomicUsize,\n    strong: &'a atomic::AtomicUsize,\n}\n\nimpl<T: ?Sized> Weak<T> {\n    /// Returns a raw pointer to the object `T` pointed to by this `Weak<T>`.\n    ///\n    /// The pointer is valid only if there are some strong references. The pointer may be dangling,\n    /// unaligned or even [`null`] otherwise.\n    ///\n    /// # Examples\n    ///\n    /// ```\n    /// use std::sync::Arc;\n    /// use std::ptr;\n    ///\n    /// let strong = Arc::new(\"hello\".to_owned());\n    /// let weak = Arc::downgrade(&strong);\n    /// // Both point to the same object\n    /// assert!(ptr::eq(&*strong, weak.as_ptr()));\n    /// // The strong here keeps it alive, so we can still access the object.\n    /// assert_eq!(\"hello\", unsafe { &*weak.as_ptr() });\n    ///\n    /// drop(strong);\n    /// // But not any more. We can do weak.as_ptr(), but accessing the pointer would lead to\n    /// // undefined behaviour.\n    /// // assert_eq!(\"hello\", unsafe { &*weak.as_ptr() });\n    /// ```\n    ///\n    /// [`null`]: core::ptr::null\n    #[stable(feature = \"weak_into_raw\", since = \"1.45.0\")]\n    pub fn as_ptr(&self) -> *const T {\n        let ptr: *mut ArcInner<T> = NonNull::as_ptr(self.ptr);\n\n        if is_dangling(ptr) {\n            // If the pointer is dangling, we return the sentinel directly. This cannot be\n            // a valid payload address, as the payload is at least as aligned as ArcInner (usize).\n            ptr as *const T\n        } else {\n            // SAFETY: if is_dangling returns false, then the pointer is dereferencable.\n            // The payload may be dropped at this point, and we have to maintain provenance,\n            // so use raw pointer manipulation.\n            unsafe { ptr::addr_of_mut!((*ptr).data) }\n        }\n    }\n\n    /// Consumes the `Weak<T>` and turns it into a raw pointer.\n    ///\n    /// This converts the weak pointer into a raw pointer, while still preserving the ownership of\n    /// one weak reference (the weak count is not modified by this operation). It can be turned\n    /// back into the `Weak<T>` with [`from_raw`].\n    ///\n    /// The same restrictions of accessing the target of the pointer as with\n    /// [`as_ptr`] apply.\n    ///\n    /// # Examples\n    ///\n    /// ```\n    /// use std::sync::{Arc, Weak};\n    ///\n    /// let strong = Arc::new(\"hello\".to_owned());\n    /// let weak = Arc::downgrade(&strong);\n    /// let raw = weak.into_raw();\n    ///\n    /// assert_eq!(1, Arc::weak_count(&strong));\n    /// assert_eq!(\"hello\", unsafe { &*raw });\n    ///\n    /// drop(unsafe { Weak::from_raw(raw) });\n    /// assert_eq!(0, Arc::weak_count(&strong));\n    /// ```\n    ///\n    /// [`from_raw`]: Weak::from_raw\n    /// [`as_ptr`]: Weak::as_ptr\n    #[stable(feature = \"weak_into_raw\", since = \"1.45.0\")]\n    pub fn into_raw(self) -> *const T {\n        let result = self.as_ptr();\n        mem::forget(self);\n        result\n    }\n\n    /// Converts a raw pointer previously created by [`into_raw`] back into `Weak<T>`.\n    ///\n    /// This can be used to safely get a strong reference (by calling [`upgrade`]\n    /// later) or to deallocate the weak count by dropping the `Weak<T>`.\n    ///\n    /// It takes ownership of one weak reference (with the exception of pointers created by [`new`],\n    /// as these don't own anything; the method still works on them).\n    ///\n    /// # Safety\n    ///\n    /// The pointer must have originated from the [`into_raw`] and must still own its potential\n    /// weak reference.\n    ///\n    /// It is allowed for the strong count to be 0 at the time of calling this. Nevertheless, this\n    /// takes ownership of one weak reference currently represented as a raw pointer (the weak\n    /// count is not modified by this operation) and therefore it must be paired with a previous\n    /// call to [`into_raw`].\n    /// # Examples\n    ///\n    /// ```\n    /// use std::sync::{Arc, Weak};\n    ///\n    /// let strong = Arc::new(\"hello\".to_owned());\n    ///\n    /// let raw_1 = Arc::downgrade(&strong).into_raw();\n    /// let raw_2 = Arc::downgrade(&strong).into_raw();\n    ///\n    /// assert_eq!(2, Arc::weak_count(&strong));\n    ///\n    /// assert_eq!(\"hello\", &*unsafe { Weak::from_raw(raw_1) }.upgrade().unwrap());\n    /// assert_eq!(1, Arc::weak_count(&strong));\n    ///\n    /// drop(strong);\n    ///\n    /// // Decrement the last weak count.\n    /// assert!(unsafe { Weak::from_raw(raw_2) }.upgrade().is_none());\n    /// ```\n    ///\n    /// [`new`]: Weak::new\n    /// [`into_raw`]: Weak::into_raw\n    /// [`upgrade`]: Weak::upgrade\n    /// [`forget`]: std::mem::forget\n    #[stable(feature = \"weak_into_raw\", since = \"1.45.0\")]\n    pub unsafe fn from_raw(ptr: *const T) -> Self {\n        // See Weak::as_ptr for context on how the input pointer is derived.\n\n        let ptr = if is_dangling(ptr as *mut T) {\n            // This is a dangling Weak.\n            ptr as *mut ArcInner<T>\n        } else {\n            // Otherwise, we're guaranteed the pointer came from a nondangling Weak.\n            // SAFETY: data_offset is safe to call, as ptr references a real (potentially dropped) T.\n            let offset = unsafe { data_offset(ptr) };\n            // Thus, we reverse the offset to get the whole RcBox.\n            // SAFETY: the pointer originated from a Weak, so this offset is safe.\n            unsafe { (ptr as *mut ArcInner<T>).set_ptr_value((ptr as *mut u8).offset(-offset)) }\n        };\n\n        // SAFETY: we now have recovered the original Weak pointer, so can create the Weak.\n        Weak { ptr: unsafe { NonNull::new_unchecked(ptr) } }\n    }\n}\n\nimpl<T: ?Sized> Weak<T> {\n    /// Attempts to upgrade the `Weak` pointer to an [`Arc`], delaying\n    /// dropping of the inner value if successful.\n    ///\n    /// Returns [`None`] if the inner value has since been dropped.\n    ///\n    /// # Examples\n    ///\n    /// ```\n    /// use std::sync::Arc;\n    ///\n    /// let five = Arc::new(5);\n    ///\n    /// let weak_five = Arc::downgrade(&five);\n    ///\n    /// let strong_five: Option<Arc<_>> = weak_five.upgrade();\n    /// assert!(strong_five.is_some());\n    ///\n    /// // Destroy all strong pointers.\n    /// drop(strong_five);\n    /// drop(five);\n    ///\n    /// assert!(weak_five.upgrade().is_none());\n    /// ```\n    #[stable(feature = \"arc_weak\", since = \"1.4.0\")]\n    pub fn upgrade(&self) -> Option<Arc<T>> {\n        // We use a CAS loop to increment the strong count instead of a\n        // fetch_add as this function should never take the reference count\n        // from zero to one.\n        let inner = self.inner()?;\n\n        // Relaxed load because any write of 0 that we can observe\n        // leaves the field in a permanently zero state (so a\n        // \"stale\" read of 0 is fine), and any other value is\n        // confirmed via the CAS below.\n        let mut n = inner.strong.load(Relaxed);\n\n        loop {\n            if n == 0 {\n                return None;\n            }\n\n            // See comments in `Arc::clone` for why we do this (for `mem::forget`).\n            if n > MAX_REFCOUNT {\n                abort();\n            }\n\n            // Relaxed is fine for the failure case because we don't have any expectations about the new state.\n            // Acquire is necessary for the success case to synchronise with `Arc::new_cyclic`, when the inner\n            // value can be initialized after `Weak` references have already been created. In that case, we\n            // expect to observe the fully initialized value.\n            match inner.strong.compare_exchange_weak(n, n + 1, Acquire, Relaxed) {\n                Ok(_) => return Some(Arc::from_inner(self.ptr)), // null checked above\n                Err(old) => n = old,\n            }\n        }\n    }\n\n    /// Gets the number of strong (`Arc`) pointers pointing to this allocation.\n    ///\n    /// If `self` was created using [`Weak::new`], this will return 0.\n    #[stable(feature = \"weak_counts\", since = \"1.41.0\")]\n    pub fn strong_count(&self) -> usize {\n        if let Some(inner) = self.inner() { inner.strong.load(SeqCst) } else { 0 }\n    }\n\n    /// Gets an approximation of the number of `Weak` pointers pointing to this\n    /// allocation.\n    ///\n    /// If `self` was created using [`Weak::new`], or if there are no remaining\n    /// strong pointers, this will return 0.\n    ///\n    /// # Accuracy\n    ///\n    /// Due to implementation details, the returned value can be off by 1 in\n    /// either direction when other threads are manipulating any `Arc`s or\n    /// `Weak`s pointing to the same allocation.\n    #[stable(feature = \"weak_counts\", since = \"1.41.0\")]\n    pub fn weak_count(&self) -> usize {\n        self.inner()\n            .map(|inner| {\n                let weak = inner.weak.load(SeqCst);\n                let strong = inner.strong.load(SeqCst);\n                if strong == 0 {\n                    0\n                } else {\n                    // Since we observed that there was at least one strong pointer\n                    // after reading the weak count, we know that the implicit weak\n                    // reference (present whenever any strong references are alive)\n                    // was still around when we observed the weak count, and can\n                    // therefore safely subtract it.\n                    weak - 1\n                }\n            })\n            .unwrap_or(0)\n    }\n\n    /// Returns `None` when the pointer is dangling and there is no allocated `ArcInner`,\n    /// (i.e., when this `Weak` was created by `Weak::new`).\n    #[inline]\n    fn inner(&self) -> Option<WeakInner<'_>> {\n        if is_dangling(self.ptr.as_ptr()) {\n            None\n        } else {\n            // We are careful to *not* create a reference covering the \"data\" field, as\n            // the field may be mutated concurrently (for example, if the last `Arc`\n            // is dropped, the data field will be dropped in-place).\n            Some(unsafe {\n                let ptr = self.ptr.as_ptr();\n                WeakInner { strong: &(*ptr).strong, weak: &(*ptr).weak }\n            })\n        }\n    }\n\n    /// Returns `true` if the two `Weak`s point to the same allocation (similar to\n    /// [`ptr::eq`]), or if both don't point to any allocation\n    /// (because they were created with `Weak::new()`).\n    ///\n    /// # Notes\n    ///\n    /// Since this compares pointers it means that `Weak::new()` will equal each\n    /// other, even though they don't point to any allocation.\n    ///\n    /// # Examples\n    ///\n    /// ```\n    /// use std::sync::Arc;\n    ///\n    /// let first_rc = Arc::new(5);\n    /// let first = Arc::downgrade(&first_rc);\n    /// let second = Arc::downgrade(&first_rc);\n    ///\n    /// assert!(first.ptr_eq(&second));\n    ///\n    /// let third_rc = Arc::new(5);\n    /// let third = Arc::downgrade(&third_rc);\n    ///\n    /// assert!(!first.ptr_eq(&third));\n    /// ```\n    ///\n    /// Comparing `Weak::new`.\n    ///\n    /// ```\n    /// use std::sync::{Arc, Weak};\n    ///\n    /// let first = Weak::new();\n    /// let second = Weak::new();\n    /// assert!(first.ptr_eq(&second));\n    ///\n    /// let third_rc = Arc::new(());\n    /// let third = Arc::downgrade(&third_rc);\n    /// assert!(!first.ptr_eq(&third));\n    /// ```\n    ///\n    /// [`ptr::eq`]: core::ptr::eq\n    #[inline]\n    #[stable(feature = \"weak_ptr_eq\", since = \"1.39.0\")]\n    pub fn ptr_eq(&self, other: &Self) -> bool {\n        self.ptr.as_ptr() == other.ptr.as_ptr()\n    }\n}\n\n#[stable(feature = \"arc_weak\", since = \"1.4.0\")]\nimpl<T: ?Sized> Clone for Weak<T> {\n    /// Makes a clone of the `Weak` pointer that points to the same allocation.\n    ///\n    /// # Examples\n    ///\n    /// ```\n    /// use std::sync::{Arc, Weak};\n    ///\n    /// let weak_five = Arc::downgrade(&Arc::new(5));\n    ///\n    /// let _ = Weak::clone(&weak_five);\n    /// ```\n    #[inline]\n    fn clone(&self) -> Weak<T> {\n        let inner = if let Some(inner) = self.inner() {\n            inner\n        } else {\n            return Weak { ptr: self.ptr };\n        };\n        // See comments in Arc::clone() for why this is relaxed.  This can use a\n        // fetch_add (ignoring the lock) because the weak count is only locked\n        // where are *no other* weak pointers in existence. (So we can't be\n        // running this code in that case).\n        let old_size = inner.weak.fetch_add(1, Relaxed);\n\n        // See comments in Arc::clone() for why we do this (for mem::forget).\n        if old_size > MAX_REFCOUNT {\n            abort();\n        }\n\n        Weak { ptr: self.ptr }\n    }\n}\n\n#[stable(feature = \"downgraded_weak\", since = \"1.10.0\")]\nimpl<T> Default for Weak<T> {\n    /// Constructs a new `Weak<T>`, without allocating memory.\n    /// Calling [`upgrade`] on the return value always\n    /// gives [`None`].\n    ///\n    /// [`upgrade`]: Weak::upgrade\n    ///\n    /// # Examples\n    ///\n    /// ```\n    /// use std::sync::Weak;\n    ///\n    /// let empty: Weak<i64> = Default::default();\n    /// assert!(empty.upgrade().is_none());\n    /// ```\n    fn default() -> Weak<T> {\n        Weak::new()\n    }\n}\n\n#[stable(feature = \"arc_weak\", since = \"1.4.0\")]\nunsafe impl<#[may_dangle] T: ?Sized> Drop for Weak<T> {\n    /// Drops the `Weak` pointer.\n    ///\n    /// # Examples\n    ///\n    /// ```\n    /// use std::sync::{Arc, Weak};\n    ///\n    /// struct Foo;\n    ///\n    /// impl Drop for Foo {\n    ///     fn drop(&mut self) {\n    ///         println!(\"dropped!\");\n    ///     }\n    /// }\n    ///\n    /// let foo = Arc::new(Foo);\n    /// let weak_foo = Arc::downgrade(&foo);\n    /// let other_weak_foo = Weak::clone(&weak_foo);\n    ///\n    /// drop(weak_foo);   // Doesn't print anything\n    /// drop(foo);        // Prints \"dropped!\"\n    ///\n    /// assert!(other_weak_foo.upgrade().is_none());\n    /// ```\n    fn drop(&mut self) {\n        // If we find out that we were the last weak pointer, then its time to\n        // deallocate the data entirely. See the discussion in Arc::drop() about\n        // the memory orderings\n        //\n        // It's not necessary to check for the locked state here, because the\n        // weak count can only be locked if there was precisely one weak ref,\n        // meaning that drop could only subsequently run ON that remaining weak\n        // ref, which can only happen after the lock is released.\n        let inner = if let Some(inner) = self.inner() { inner } else { return };\n\n        if inner.weak.fetch_sub(1, Release) == 1 {\n            acquire!(inner.weak);\n            unsafe { Global.deallocate(self.ptr.cast(), Layout::for_value_raw(self.ptr.as_ptr())) }\n        }\n    }\n}\n\n#[stable(feature = \"rust1\", since = \"1.0.0\")]\ntrait ArcEqIdent<T: ?Sized + PartialEq> {\n    fn eq(&self, other: &Arc<T>) -> bool;\n    fn ne(&self, other: &Arc<T>) -> bool;\n}\n\n#[stable(feature = \"rust1\", since = \"1.0.0\")]\nimpl<T: ?Sized + PartialEq> ArcEqIdent<T> for Arc<T> {\n    #[inline]\n    default fn eq(&self, other: &Arc<T>) -> bool {\n        **self == **other\n    }\n    #[inline]\n    default fn ne(&self, other: &Arc<T>) -> bool {\n        **self != **other\n    }\n}\n\n/// We're doing this specialization here, and not as a more general optimization on `&T`, because it\n/// would otherwise add a cost to all equality checks on refs. We assume that `Arc`s are used to\n/// store large values, that are slow to clone, but also heavy to check for equality, causing this\n/// cost to pay off more easily. It's also more likely to have two `Arc` clones, that point to\n/// the same value, than two `&T`s.\n///\n/// We can only do this when `T: Eq` as a `PartialEq` might be deliberately irreflexive.\n#[stable(feature = \"rust1\", since = \"1.0.0\")]\nimpl<T: ?Sized + crate::rc::MarkerEq> ArcEqIdent<T> for Arc<T> {\n    #[inline]\n    fn eq(&self, other: &Arc<T>) -> bool {\n        Arc::ptr_eq(self, other) || **self == **other\n    }\n\n    #[inline]\n    fn ne(&self, other: &Arc<T>) -> bool {\n        !Arc::ptr_eq(self, other) && **self != **other\n    }\n}\n\n#[stable(feature = \"rust1\", since = \"1.0.0\")]\nimpl<T: ?Sized + PartialEq> PartialEq for Arc<T> {\n    /// Equality for two `Arc`s.\n    ///\n    /// Two `Arc`s are equal if their inner values are equal, even if they are\n    /// stored in different allocation.\n    ///\n    /// If `T` also implements `Eq` (implying reflexivity of equality),\n    /// two `Arc`s that point to the same allocation are always equal.\n    ///\n    /// # Examples\n    ///\n    /// ```\n    /// use std::sync::Arc;\n    ///\n    /// let five = Arc::new(5);\n    ///\n    /// assert!(five == Arc::new(5));\n    /// ```\n    #[inline]\n    fn eq(&self, other: &Arc<T>) -> bool {\n        ArcEqIdent::eq(self, other)\n    }\n\n    /// Inequality for two `Arc`s.\n    ///\n    /// Two `Arc`s are unequal if their inner values are unequal.\n    ///\n    /// If `T` also implements `Eq` (implying reflexivity of equality),\n    /// two `Arc`s that point to the same value are never unequal.\n    ///\n    /// # Examples\n    ///\n    /// ```\n    /// use std::sync::Arc;\n    ///\n    /// let five = Arc::new(5);\n    ///\n    /// assert!(five != Arc::new(6));\n    /// ```\n    #[inline]\n    fn ne(&self, other: &Arc<T>) -> bool {\n        ArcEqIdent::ne(self, other)\n    }\n}\n\n#[stable(feature = \"rust1\", since = \"1.0.0\")]\nimpl<T: ?Sized + PartialOrd> PartialOrd for Arc<T> {\n    /// Partial comparison for two `Arc`s.\n    ///\n    /// The two are compared by calling `partial_cmp()` on their inner values.\n    ///\n    /// # Examples\n    ///\n    /// ```\n    /// use std::sync::Arc;\n    /// use std::cmp::Ordering;\n    ///\n    /// let five = Arc::new(5);\n    ///\n    /// assert_eq!(Some(Ordering::Less), five.partial_cmp(&Arc::new(6)));\n    /// ```\n    fn partial_cmp(&self, other: &Arc<T>) -> Option<Ordering> {\n        (**self).partial_cmp(&**other)\n    }\n\n    /// Less-than comparison for two `Arc`s.\n    ///\n    /// The two are compared by calling `<` on their inner values.\n    ///\n    /// # Examples\n    ///\n    /// ```\n    /// use std::sync::Arc;\n    ///\n    /// let five = Arc::new(5);\n    ///\n    /// assert!(five < Arc::new(6));\n    /// ```\n    fn lt(&self, other: &Arc<T>) -> bool {\n        *(*self) < *(*other)\n    }\n\n    /// 'Less than or equal to' comparison for two `Arc`s.\n    ///\n    /// The two are compared by calling `<=` on their inner values.\n    ///\n    /// # Examples\n    ///\n    /// ```\n    /// use std::sync::Arc;\n    ///\n    /// let five = Arc::new(5);\n    ///\n    /// assert!(five <= Arc::new(5));\n    /// ```\n    fn le(&self, other: &Arc<T>) -> bool {\n        *(*self) <= *(*other)\n    }\n\n    /// Greater-than comparison for two `Arc`s.\n    ///\n    /// The two are compared by calling `>` on their inner values.\n    ///\n    /// # Examples\n    ///\n    /// ```\n    /// use std::sync::Arc;\n    ///\n    /// let five = Arc::new(5);\n    ///\n    /// assert!(five > Arc::new(4));\n    /// ```\n    fn gt(&self, other: &Arc<T>) -> bool {\n        *(*self) > *(*other)\n    }\n\n    /// 'Greater than or equal to' comparison for two `Arc`s.\n    ///\n    /// The two are compared by calling `>=` on their inner values.\n    ///\n    /// # Examples\n    ///\n    /// ```\n    /// use std::sync::Arc;\n    ///\n    /// let five = Arc::new(5);\n    ///\n    /// assert!(five >= Arc::new(5));\n    /// ```\n    fn ge(&self, other: &Arc<T>) -> bool {\n        *(*self) >= *(*other)\n    }\n}\n#[stable(feature = \"rust1\", since = \"1.0.0\")]\nimpl<T: ?Sized + Ord> Ord for Arc<T> {\n    /// Comparison for two `Arc`s.\n    ///\n    /// The two are compared by calling `cmp()` on their inner values.\n    ///\n    /// # Examples\n    ///\n    /// ```\n    /// use std::sync::Arc;\n    /// use std::cmp::Ordering;\n    ///\n    /// let five = Arc::new(5);\n    ///\n    /// assert_eq!(Ordering::Less, five.cmp(&Arc::new(6)));\n    /// ```\n    fn cmp(&self, other: &Arc<T>) -> Ordering {\n        (**self).cmp(&**other)\n    }\n}\n#[stable(feature = \"rust1\", since = \"1.0.0\")]\nimpl<T: ?Sized + Eq> Eq for Arc<T> {}\n\n#[stable(feature = \"rust1\", since = \"1.0.0\")]\nimpl<T: ?Sized + fmt::Display> fmt::Display for Arc<T> {\n    fn fmt(&self, f: &mut fmt::Formatter<'_>) -> fmt::Result {\n        fmt::Display::fmt(&**self, f)\n    }\n}\n\n#[stable(feature = \"rust1\", since = \"1.0.0\")]\nimpl<T: ?Sized + fmt::Debug> fmt::Debug for Arc<T> {\n    fn fmt(&self, f: &mut fmt::Formatter<'_>) -> fmt::Result {\n        fmt::Debug::fmt(&**self, f)\n    }\n}\n\n#[stable(feature = \"rust1\", since = \"1.0.0\")]\nimpl<T: ?Sized> fmt::Pointer for Arc<T> {\n    fn fmt(&self, f: &mut fmt::Formatter<'_>) -> fmt::Result {\n        fmt::Pointer::fmt(&(&**self as *const T), f)\n    }\n}\n\n#[stable(feature = \"rust1\", since = \"1.0.0\")]\nimpl<T: Default> Default for Arc<T> {\n    /// Creates a new `Arc<T>`, with the `Default` value for `T`.\n    ///\n    /// # Examples\n    ///\n    /// ```\n    /// use std::sync::Arc;\n    ///\n    /// let x: Arc<i32> = Default::default();\n    /// assert_eq!(*x, 0);\n    /// ```\n    fn default() -> Arc<T> {\n        Arc::new(Default::default())\n    }\n}\n\n#[stable(feature = \"rust1\", since = \"1.0.0\")]\nimpl<T: ?Sized + Hash> Hash for Arc<T> {\n    fn hash<H: Hasher>(&self, state: &mut H) {\n        (**self).hash(state)\n    }\n}\n\n#[stable(feature = \"from_for_ptrs\", since = \"1.6.0\")]\nimpl<T> From<T> for Arc<T> {\n    /// Converts a `T` into an `Arc<T>`\n    ///\n    /// The conversion moves the value into a\n    /// newly allocated `Arc`. It is equivalent to\n    /// calling `Arc::new(t)`.\n    ///\n    /// # Example\n    /// ```rust\n    /// # use std::sync::Arc;\n    /// let x = 5;\n    /// let arc = Arc::new(5);\n    ///\n    /// assert_eq!(Arc::from(x), arc);\n    /// ```\n    fn from(t: T) -> Self {\n        Arc::new(t)\n    }\n}\n\n#[cfg(not(no_global_oom_handling))]\n#[stable(feature = \"shared_from_slice\", since = \"1.21.0\")]\nimpl<T: Clone> From<&[T]> for Arc<[T]> {\n    /// Allocate a reference-counted slice and fill it by cloning `v`'s items.\n    ///\n    /// # Example\n    ///\n    /// ```\n    /// # use std::sync::Arc;\n    /// let original: &[i32] = &[1, 2, 3];\n    /// let shared: Arc<[i32]> = Arc::from(original);\n    /// assert_eq!(&[1, 2, 3], &shared[..]);\n    /// ```\n    #[inline]\n    fn from(v: &[T]) -> Arc<[T]> {\n        <Self as ArcFromSlice<T>>::from_slice(v)\n    }\n}\n\n#[cfg(not(no_global_oom_handling))]\n#[stable(feature = \"shared_from_slice\", since = \"1.21.0\")]\nimpl From<&str> for Arc<str> {\n    /// Allocate a reference-counted `str` and copy `v` into it.\n    ///\n    /// # Example\n    ///\n    /// ```\n    /// # use std::sync::Arc;\n    /// let shared: Arc<str> = Arc::from(\"eggplant\");\n    /// assert_eq!(\"eggplant\", &shared[..]);\n    /// ```\n    #[inline]\n    fn from(v: &str) -> Arc<str> {\n        let arc = Arc::<[u8]>::from(v.as_bytes());\n        unsafe { Arc::from_raw(Arc::into_raw(arc) as *const str) }\n    }\n}\n\n#[cfg(not(no_global_oom_handling))]\n#[stable(feature = \"shared_from_slice\", since = \"1.21.0\")]\nimpl From<String> for Arc<str> {\n    /// Allocate a reference-counted `str` and copy `v` into it.\n    ///\n    /// # Example\n    ///\n    /// ```\n    /// # use std::sync::Arc;\n    /// let unique: String = \"eggplant\".to_owned();\n    /// let shared: Arc<str> = Arc::from(unique);\n    /// assert_eq!(\"eggplant\", &shared[..]);\n    /// ```\n    #[inline]\n    fn from(v: String) -> Arc<str> {\n        Arc::from(&v[..])\n    }\n}\n\n#[cfg(not(no_global_oom_handling))]\n#[stable(feature = \"shared_from_slice\", since = \"1.21.0\")]\nimpl<T: ?Sized> From<Box<T>> for Arc<T> {\n    /// Move a boxed object to a new, reference-counted allocation.\n    ///\n    /// # Example\n    ///\n    /// ```\n    /// # use std::sync::Arc;\n    /// let unique: Box<str> = Box::from(\"eggplant\");\n    /// let shared: Arc<str> = Arc::from(unique);\n    /// assert_eq!(\"eggplant\", &shared[..]);\n    /// ```\n    #[inline]\n    fn from(v: Box<T>) -> Arc<T> {\n        Arc::from_box(v)\n    }\n}\n\n#[cfg(not(no_global_oom_handling))]\n#[stable(feature = \"shared_from_slice\", since = \"1.21.0\")]\nimpl<T> From<Vec<T>> for Arc<[T]> {\n    /// Allocate a reference-counted slice and move `v`'s items into it.\n    ///\n    /// # Example\n    ///\n    /// ```\n    /// # use std::sync::Arc;\n    /// let unique: Vec<i32> = vec![1, 2, 3];\n    /// let shared: Arc<[i32]> = Arc::from(unique);\n    /// assert_eq!(&[1, 2, 3], &shared[..]);\n    /// ```\n    #[inline]\n    fn from(mut v: Vec<T>) -> Arc<[T]> {\n        unsafe {\n            let arc = Arc::copy_from_slice(&v);\n\n            // Allow the Vec to free its memory, but not destroy its contents\n            v.set_len(0);\n\n            arc\n        }\n    }\n}\n\n#[stable(feature = \"shared_from_cow\", since = \"1.45.0\")]\nimpl<'a, B> From<Cow<'a, B>> for Arc<B>\nwhere\n    B: ToOwned + ?Sized,\n    Arc<B>: From<&'a B> + From<B::Owned>,\n{\n    /// Create an atomically reference-counted pointer from\n    /// a clone-on-write pointer by copying its content.\n    ///\n    /// # Example\n    ///\n    /// ```rust\n    /// # use std::sync::Arc;\n    /// # use std::borrow::Cow;\n    /// let cow: Cow<str> = Cow::Borrowed(\"eggplant\");\n    /// let shared: Arc<str> = Arc::from(cow);\n    /// assert_eq!(\"eggplant\", &shared[..]);\n    /// ```\n    #[inline]\n    fn from(cow: Cow<'a, B>) -> Arc<B> {\n        match cow {\n            Cow::Borrowed(s) => Arc::from(s),\n            Cow::Owned(s) => Arc::from(s),\n        }\n    }\n}\n\n#[stable(feature = \"boxed_slice_try_from\", since = \"1.43.0\")]\nimpl<T, const N: usize> TryFrom<Arc<[T]>> for Arc<[T; N]> {\n    type Error = Arc<[T]>;\n\n    fn try_from(boxed_slice: Arc<[T]>) -> Result<Self, Self::Error> {\n        if boxed_slice.len() == N {\n            Ok(unsafe { Arc::from_raw(Arc::into_raw(boxed_slice) as *mut [T; N]) })\n        } else {\n            Err(boxed_slice)\n        }\n    }\n}\n\n#[cfg(not(no_global_oom_handling))]\n#[stable(feature = \"shared_from_iter\", since = \"1.37.0\")]\nimpl<T> iter::FromIterator<T> for Arc<[T]> {\n    /// Takes each element in the `Iterator` and collects it into an `Arc<[T]>`.\n    ///\n    /// # Performance characteristics\n    ///\n    /// ## The general case\n    ///\n    /// In the general case, collecting into `Arc<[T]>` is done by first\n    /// collecting into a `Vec<T>`. That is, when writing the following:\n    ///\n    /// ```rust\n    /// # use std::sync::Arc;\n    /// let evens: Arc<[u8]> = (0..10).filter(|&x| x % 2 == 0).collect();\n    /// # assert_eq!(&*evens, &[0, 2, 4, 6, 8]);\n    /// ```\n    ///\n    /// this behaves as if we wrote:\n    ///\n    /// ```rust\n    /// # use std::sync::Arc;\n    /// let evens: Arc<[u8]> = (0..10).filter(|&x| x % 2 == 0)\n    ///     .collect::<Vec<_>>() // The first set of allocations happens here.\n    ///     .into(); // A second allocation for `Arc<[T]>` happens here.\n    /// # assert_eq!(&*evens, &[0, 2, 4, 6, 8]);\n    /// ```\n    ///\n    /// This will allocate as many times as needed for constructing the `Vec<T>`\n    /// and then it will allocate once for turning the `Vec<T>` into the `Arc<[T]>`.\n    ///\n    /// ## Iterators of known length\n    ///\n    /// When your `Iterator` implements `TrustedLen` and is of an exact size,\n    /// a single allocation will be made for the `Arc<[T]>`. For example:\n    ///\n    /// ```rust\n    /// # use std::sync::Arc;\n    /// let evens: Arc<[u8]> = (0..10).collect(); // Just a single allocation happens here.\n    /// # assert_eq!(&*evens, &*(0..10).collect::<Vec<_>>());\n    /// ```\n    fn from_iter<I: iter::IntoIterator<Item = T>>(iter: I) -> Self {\n        ToArcSlice::to_arc_slice(iter.into_iter())\n    }\n}\n\n/// Specialization trait used for collecting into `Arc<[T]>`.\ntrait ToArcSlice<T>: Iterator<Item = T> + Sized {\n    fn to_arc_slice(self) -> Arc<[T]>;\n}\n\n#[cfg(not(no_global_oom_handling))]\nimpl<T, I: Iterator<Item = T>> ToArcSlice<T> for I {\n    default fn to_arc_slice(self) -> Arc<[T]> {\n        self.collect::<Vec<T>>().into()\n    }\n}\n\n#[cfg(not(no_global_oom_handling))]\nimpl<T, I: iter::TrustedLen<Item = T>> ToArcSlice<T> for I {\n    fn to_arc_slice(self) -> Arc<[T]> {\n        // This is the case for a `TrustedLen` iterator.\n        let (low, high) = self.size_hint();\n        if let Some(high) = high {\n            debug_assert_eq!(\n                low,\n                high,\n                \"TrustedLen iterator's size hint is not exact: {:?}\",\n                (low, high)\n            );\n\n            unsafe {\n                // SAFETY: We need to ensure that the iterator has an exact length and we have.\n                Arc::from_iter_exact(self, low)\n            }\n        } else {\n            // TrustedLen contract guarantees that `upper_bound == `None` implies an iterator\n            // length exceeding `usize::MAX`.\n            // The default implementation would collect into a vec which would panic.\n            // Thus we panic here immediately without invoking `Vec` code.\n            panic!(\"capacity overflow\");\n        }\n    }\n}\n\n#[stable(feature = \"rust1\", since = \"1.0.0\")]\nimpl<T: ?Sized> borrow::Borrow<T> for Arc<T> {\n    fn borrow(&self) -> &T {\n        &**self\n    }\n}\n\n#[stable(since = \"1.5.0\", feature = \"smart_ptr_as_ref\")]\nimpl<T: ?Sized> AsRef<T> for Arc<T> {\n    fn as_ref(&self) -> &T {\n        &**self\n    }\n}\n\n#[stable(feature = \"pin\", since = \"1.33.0\")]\nimpl<T: ?Sized> Unpin for Arc<T> {}\n\n/// Get the offset within an `ArcInner` for the payload behind a pointer.\n///\n/// # Safety\n///\n/// The pointer must point to (and have valid metadata for) a previously\n/// valid instance of T, but the T is allowed to be dropped.\nunsafe fn data_offset<T: ?Sized>(ptr: *const T) -> isize {\n    // Align the unsized value to the end of the ArcInner.\n    // Because RcBox is repr(C), it will always be the last field in memory.\n    // SAFETY: since the only unsized types possible are slices, trait objects,\n    // and extern types, the input safety requirement is currently enough to\n    // satisfy the requirements of align_of_val_raw; this is an implementation\n    // detail of the language that may not be relied upon outside of std.\n    unsafe { data_offset_align(align_of_val_raw(ptr)) }\n}\n\n#[inline]\nfn data_offset_align(align: usize) -> isize {\n    let layout = Layout::new::<ArcInner<()>>();\n    (layout.size() + layout.padding_needed_for(align)) as isize\n}\n"],[2068,"use super::*;\nuse std::cell::Cell;\n\n#[test]\nfn allocator_param() {\n    use crate::alloc::AllocError;\n\n    // Writing a test of integration between third-party\n    // allocators and `RawVec` is a little tricky because the `RawVec`\n    // API does not expose fallible allocation methods, so we\n    // cannot check what happens when allocator is exhausted\n    // (beyond detecting a panic).\n    //\n    // Instead, this just checks that the `RawVec` methods do at\n    // least go through the Allocator API when it reserves\n    // storage.\n\n    // A dumb allocator that consumes a fixed amount of fuel\n    // before allocation attempts start failing.\n    struct BoundedAlloc {\n        fuel: Cell<usize>,\n    }\n    unsafe impl Allocator for BoundedAlloc {\n        fn allocate(&self, layout: Layout) -> Result<NonNull<[u8]>, AllocError> {\n            let size = layout.size();\n            if size > self.fuel.get() {\n                return Err(AllocError);\n            }\n            match Global.allocate(layout) {\n                ok @ Ok(_) => {\n                    self.fuel.set(self.fuel.get() - size);\n                    ok\n                }\n                err @ Err(_) => err,\n            }\n        }\n        unsafe fn deallocate(&self, ptr: NonNull<u8>, layout: Layout) {\n            unsafe { Global.deallocate(ptr, layout) }\n        }\n    }\n\n    let a = BoundedAlloc { fuel: Cell::new(500) };\n    let mut v: RawVec<u8, _> = RawVec::with_capacity_in(50, a);\n    assert_eq!(v.alloc.fuel.get(), 450);\n    v.reserve(50, 150); // (causes a realloc, thus using 50 + 150 = 200 units of fuel)\n    assert_eq!(v.alloc.fuel.get(), 250);\n}\n\n#[test]\nfn reserve_does_not_overallocate() {\n    {\n        let mut v: RawVec<u32> = RawVec::new();\n        // First, `reserve` allocates like `reserve_exact`.\n        v.reserve(0, 9);\n        assert_eq!(9, v.capacity());\n    }\n\n    {\n        let mut v: RawVec<u32> = RawVec::new();\n        v.reserve(0, 7);\n        assert_eq!(7, v.capacity());\n        // 97 is more than double of 7, so `reserve` should work\n        // like `reserve_exact`.\n        v.reserve(7, 90);\n        assert_eq!(97, v.capacity());\n    }\n\n    {\n        let mut v: RawVec<u32> = RawVec::new();\n        v.reserve(0, 12);\n        assert_eq!(12, v.capacity());\n        v.reserve(12, 3);\n        // 3 is less than half of 12, so `reserve` must grow\n        // exponentially. At the time of writing this test grow\n        // factor is 2, so new capacity is 24, however, grow factor\n        // of 1.5 is OK too. Hence `>= 18` in assert.\n        assert!(v.capacity() >= 12 + 12 / 2);\n    }\n}\n"],[2069,"use super::*;\n\nuse std::boxed::Box;\nuse std::clone::Clone;\nuse std::convert::{From, TryInto};\nuse std::mem::drop;\nuse std::ops::Drop;\nuse std::option::Option::{self, None, Some};\nuse std::sync::atomic::{\n    self,\n    Ordering::{Acquire, SeqCst},\n};\nuse std::sync::mpsc::channel;\nuse std::sync::Mutex;\nuse std::thread;\n\nuse crate::vec::Vec;\n\nstruct Canary(*mut atomic::AtomicUsize);\n\nimpl Drop for Canary {\n    fn drop(&mut self) {\n        unsafe {\n            match *self {\n                Canary(c) => {\n                    (*c).fetch_add(1, SeqCst);\n                }\n            }\n        }\n    }\n}\n\n#[test]\n#[cfg_attr(target_os = \"emscripten\", ignore)]\nfn manually_share_arc() {\n    let v = vec![1, 2, 3, 4, 5, 6, 7, 8, 9, 10];\n    let arc_v = Arc::new(v);\n\n    let (tx, rx) = channel();\n\n    let _t = thread::spawn(move || {\n        let arc_v: Arc<Vec<i32>> = rx.recv().unwrap();\n        assert_eq!((*arc_v)[3], 4);\n    });\n\n    tx.send(arc_v.clone()).unwrap();\n\n    assert_eq!((*arc_v)[2], 3);\n    assert_eq!((*arc_v)[4], 5);\n}\n\n#[test]\nfn test_arc_get_mut() {\n    let mut x = Arc::new(3);\n    *Arc::get_mut(&mut x).unwrap() = 4;\n    assert_eq!(*x, 4);\n    let y = x.clone();\n    assert!(Arc::get_mut(&mut x).is_none());\n    drop(y);\n    assert!(Arc::get_mut(&mut x).is_some());\n    let _w = Arc::downgrade(&x);\n    assert!(Arc::get_mut(&mut x).is_none());\n}\n\n#[test]\nfn weak_counts() {\n    assert_eq!(Weak::weak_count(&Weak::<u64>::new()), 0);\n    assert_eq!(Weak::strong_count(&Weak::<u64>::new()), 0);\n\n    let a = Arc::new(0);\n    let w = Arc::downgrade(&a);\n    assert_eq!(Weak::strong_count(&w), 1);\n    assert_eq!(Weak::weak_count(&w), 1);\n    let w2 = w.clone();\n    assert_eq!(Weak::strong_count(&w), 1);\n    assert_eq!(Weak::weak_count(&w), 2);\n    assert_eq!(Weak::strong_count(&w2), 1);\n    assert_eq!(Weak::weak_count(&w2), 2);\n    drop(w);\n    assert_eq!(Weak::strong_count(&w2), 1);\n    assert_eq!(Weak::weak_count(&w2), 1);\n    let a2 = a.clone();\n    assert_eq!(Weak::strong_count(&w2), 2);\n    assert_eq!(Weak::weak_count(&w2), 1);\n    drop(a2);\n    drop(a);\n    assert_eq!(Weak::strong_count(&w2), 0);\n    assert_eq!(Weak::weak_count(&w2), 0);\n    drop(w2);\n}\n\n#[test]\nfn try_unwrap() {\n    let x = Arc::new(3);\n    assert_eq!(Arc::try_unwrap(x), Ok(3));\n    let x = Arc::new(4);\n    let _y = x.clone();\n    assert_eq!(Arc::try_unwrap(x), Err(Arc::new(4)));\n    let x = Arc::new(5);\n    let _w = Arc::downgrade(&x);\n    assert_eq!(Arc::try_unwrap(x), Ok(5));\n}\n\n#[test]\nfn into_from_raw() {\n    let x = Arc::new(box \"hello\");\n    let y = x.clone();\n\n    let x_ptr = Arc::into_raw(x);\n    drop(y);\n    unsafe {\n        assert_eq!(**x_ptr, \"hello\");\n\n        let x = Arc::from_raw(x_ptr);\n        assert_eq!(**x, \"hello\");\n\n        assert_eq!(Arc::try_unwrap(x).map(|x| *x), Ok(\"hello\"));\n    }\n}\n\n#[test]\nfn test_into_from_raw_unsized() {\n    use std::fmt::Display;\n    use std::string::ToString;\n\n    let arc: Arc<str> = Arc::from(\"foo\");\n\n    let ptr = Arc::into_raw(arc.clone());\n    let arc2 = unsafe { Arc::from_raw(ptr) };\n\n    assert_eq!(unsafe { &*ptr }, \"foo\");\n    assert_eq!(arc, arc2);\n\n    let arc: Arc<dyn Display> = Arc::new(123);\n\n    let ptr = Arc::into_raw(arc.clone());\n    let arc2 = unsafe { Arc::from_raw(ptr) };\n\n    assert_eq!(unsafe { &*ptr }.to_string(), \"123\");\n    assert_eq!(arc2.to_string(), \"123\");\n}\n\n#[test]\nfn into_from_weak_raw() {\n    let x = Arc::new(box \"hello\");\n    let y = Arc::downgrade(&x);\n\n    let y_ptr = Weak::into_raw(y);\n    unsafe {\n        assert_eq!(**y_ptr, \"hello\");\n\n        let y = Weak::from_raw(y_ptr);\n        let y_up = Weak::upgrade(&y).unwrap();\n        assert_eq!(**y_up, \"hello\");\n        drop(y_up);\n\n        assert_eq!(Arc::try_unwrap(x).map(|x| *x), Ok(\"hello\"));\n    }\n}\n\n#[test]\nfn test_into_from_weak_raw_unsized() {\n    use std::fmt::Display;\n    use std::string::ToString;\n\n    let arc: Arc<str> = Arc::from(\"foo\");\n    let weak: Weak<str> = Arc::downgrade(&arc);\n\n    let ptr = Weak::into_raw(weak.clone());\n    let weak2 = unsafe { Weak::from_raw(ptr) };\n\n    assert_eq!(unsafe { &*ptr }, \"foo\");\n    assert!(weak.ptr_eq(&weak2));\n\n    let arc: Arc<dyn Display> = Arc::new(123);\n    let weak: Weak<dyn Display> = Arc::downgrade(&arc);\n\n    let ptr = Weak::into_raw(weak.clone());\n    let weak2 = unsafe { Weak::from_raw(ptr) };\n\n    assert_eq!(unsafe { &*ptr }.to_string(), \"123\");\n    assert!(weak.ptr_eq(&weak2));\n}\n\n#[test]\nfn test_cowarc_clone_make_mut() {\n    let mut cow0 = Arc::new(75);\n    let mut cow1 = cow0.clone();\n    let mut cow2 = cow1.clone();\n\n    assert!(75 == *Arc::make_mut(&mut cow0));\n    assert!(75 == *Arc::make_mut(&mut cow1));\n    assert!(75 == *Arc::make_mut(&mut cow2));\n\n    *Arc::make_mut(&mut cow0) += 1;\n    *Arc::make_mut(&mut cow1) += 2;\n    *Arc::make_mut(&mut cow2) += 3;\n\n    assert!(76 == *cow0);\n    assert!(77 == *cow1);\n    assert!(78 == *cow2);\n\n    // none should point to the same backing memory\n    assert!(*cow0 != *cow1);\n    assert!(*cow0 != *cow2);\n    assert!(*cow1 != *cow2);\n}\n\n#[test]\nfn test_cowarc_clone_unique2() {\n    let mut cow0 = Arc::new(75);\n    let cow1 = cow0.clone();\n    let cow2 = cow1.clone();\n\n    assert!(75 == *cow0);\n    assert!(75 == *cow1);\n    assert!(75 == *cow2);\n\n    *Arc::make_mut(&mut cow0) += 1;\n    assert!(76 == *cow0);\n    assert!(75 == *cow1);\n    assert!(75 == *cow2);\n\n    // cow1 and cow2 should share the same contents\n    // cow0 should have a unique reference\n    assert!(*cow0 != *cow1);\n    assert!(*cow0 != *cow2);\n    assert!(*cow1 == *cow2);\n}\n\n#[test]\nfn test_cowarc_clone_weak() {\n    let mut cow0 = Arc::new(75);\n    let cow1_weak = Arc::downgrade(&cow0);\n\n    assert!(75 == *cow0);\n    assert!(75 == *cow1_weak.upgrade().unwrap());\n\n    *Arc::make_mut(&mut cow0) += 1;\n\n    assert!(76 == *cow0);\n    assert!(cow1_weak.upgrade().is_none());\n}\n\n#[test]\nfn test_live() {\n    let x = Arc::new(5);\n    let y = Arc::downgrade(&x);\n    assert!(y.upgrade().is_some());\n}\n\n#[test]\nfn test_dead() {\n    let x = Arc::new(5);\n    let y = Arc::downgrade(&x);\n    drop(x);\n    assert!(y.upgrade().is_none());\n}\n\n#[test]\nfn weak_self_cyclic() {\n    struct Cycle {\n        x: Mutex<Option<Weak<Cycle>>>,\n    }\n\n    let a = Arc::new(Cycle { x: Mutex::new(None) });\n    let b = Arc::downgrade(&a.clone());\n    *a.x.lock().unwrap() = Some(b);\n\n    // hopefully we don't double-free (or leak)...\n}\n\n#[test]\nfn drop_arc() {\n    let mut canary = atomic::AtomicUsize::new(0);\n    let x = Arc::new(Canary(&mut canary as *mut atomic::AtomicUsize));\n    drop(x);\n    assert!(canary.load(Acquire) == 1);\n}\n\n#[test]\nfn drop_arc_weak() {\n    let mut canary = atomic::AtomicUsize::new(0);\n    let arc = Arc::new(Canary(&mut canary as *mut atomic::AtomicUsize));\n    let arc_weak = Arc::downgrade(&arc);\n    assert!(canary.load(Acquire) == 0);\n    drop(arc);\n    assert!(canary.load(Acquire) == 1);\n    drop(arc_weak);\n}\n\n#[test]\nfn test_strong_count() {\n    let a = Arc::new(0);\n    assert!(Arc::strong_count(&a) == 1);\n    let w = Arc::downgrade(&a);\n    assert!(Arc::strong_count(&a) == 1);\n    let b = w.upgrade().expect(\"\");\n    assert!(Arc::strong_count(&b) == 2);\n    assert!(Arc::strong_count(&a) == 2);\n    drop(w);\n    drop(a);\n    assert!(Arc::strong_count(&b) == 1);\n    let c = b.clone();\n    assert!(Arc::strong_count(&b) == 2);\n    assert!(Arc::strong_count(&c) == 2);\n}\n\n#[test]\nfn test_weak_count() {\n    let a = Arc::new(0);\n    assert!(Arc::strong_count(&a) == 1);\n    assert!(Arc::weak_count(&a) == 0);\n    let w = Arc::downgrade(&a);\n    assert!(Arc::strong_count(&a) == 1);\n    assert!(Arc::weak_count(&a) == 1);\n    let x = w.clone();\n    assert!(Arc::weak_count(&a) == 2);\n    drop(w);\n    drop(x);\n    assert!(Arc::strong_count(&a) == 1);\n    assert!(Arc::weak_count(&a) == 0);\n    let c = a.clone();\n    assert!(Arc::strong_count(&a) == 2);\n    assert!(Arc::weak_count(&a) == 0);\n    let d = Arc::downgrade(&c);\n    assert!(Arc::weak_count(&c) == 1);\n    assert!(Arc::strong_count(&c) == 2);\n\n    drop(a);\n    drop(c);\n    drop(d);\n}\n\n#[test]\nfn show_arc() {\n    let a = Arc::new(5);\n    assert_eq!(format!(\"{:?}\", a), \"5\");\n}\n\n// Make sure deriving works with Arc<T>\n#[derive(Eq, Ord, PartialEq, PartialOrd, Clone, Debug, Default)]\nstruct Foo {\n    inner: Arc<i32>,\n}\n\n#[test]\nfn test_unsized() {\n    let x: Arc<[i32]> = Arc::new([1, 2, 3]);\n    assert_eq!(format!(\"{:?}\", x), \"[1, 2, 3]\");\n    let y = Arc::downgrade(&x.clone());\n    drop(x);\n    assert!(y.upgrade().is_none());\n}\n\n#[test]\nfn test_maybe_thin_unsized() {\n    // If/when custom thin DSTs exist, this test should be updated to use one\n    use std::ffi::{CStr, CString};\n\n    let x: Arc<CStr> = Arc::from(CString::new(\"swordfish\").unwrap().into_boxed_c_str());\n    assert_eq!(format!(\"{:?}\", x), \"\\\"swordfish\\\"\");\n    let y: Weak<CStr> = Arc::downgrade(&x);\n    drop(x);\n\n    // At this point, the weak points to a dropped DST\n    assert!(y.upgrade().is_none());\n    // But we still need to be able to get the alloc layout to drop.\n    // CStr has no drop glue, but custom DSTs might, and need to work.\n    drop(y);\n}\n\n#[test]\nfn test_from_owned() {\n    let foo = 123;\n    let foo_arc = Arc::from(foo);\n    assert!(123 == *foo_arc);\n}\n\n#[test]\nfn test_new_weak() {\n    let foo: Weak<usize> = Weak::new();\n    assert!(foo.upgrade().is_none());\n}\n\n#[test]\nfn test_ptr_eq() {\n    let five = Arc::new(5);\n    let same_five = five.clone();\n    let other_five = Arc::new(5);\n\n    assert!(Arc::ptr_eq(&five, &same_five));\n    assert!(!Arc::ptr_eq(&five, &other_five));\n}\n\n#[test]\n#[cfg_attr(target_os = \"emscripten\", ignore)]\nfn test_weak_count_locked() {\n    let mut a = Arc::new(atomic::AtomicBool::new(false));\n    let a2 = a.clone();\n    let t = thread::spawn(move || {\n        // Miri is too slow\n        let count = if cfg!(miri) { 1000 } else { 1000000 };\n        for _i in 0..count {\n            Arc::get_mut(&mut a);\n        }\n        a.store(true, SeqCst);\n    });\n\n    while !a2.load(SeqCst) {\n        let n = Arc::weak_count(&a2);\n        assert!(n < 2, \"bad weak count: {}\", n);\n        #[cfg(miri)] // Miri's scheduler does not guarantee liveness, and thus needs this hint.\n        std::hint::spin_loop();\n    }\n    t.join().unwrap();\n}\n\n#[test]\nfn test_from_str() {\n    let r: Arc<str> = Arc::from(\"foo\");\n\n    assert_eq!(&r[..], \"foo\");\n}\n\n#[test]\nfn test_copy_from_slice() {\n    let s: &[u32] = &[1, 2, 3];\n    let r: Arc<[u32]> = Arc::from(s);\n\n    assert_eq!(&r[..], [1, 2, 3]);\n}\n\n#[test]\nfn test_clone_from_slice() {\n    #[derive(Clone, Debug, Eq, PartialEq)]\n    struct X(u32);\n\n    let s: &[X] = &[X(1), X(2), X(3)];\n    let r: Arc<[X]> = Arc::from(s);\n\n    assert_eq!(&r[..], s);\n}\n\n#[test]\n#[should_panic]\nfn test_clone_from_slice_panic() {\n    use std::string::{String, ToString};\n\n    struct Fail(u32, String);\n\n    impl Clone for Fail {\n        fn clone(&self) -> Fail {\n            if self.0 == 2 {\n                panic!();\n            }\n            Fail(self.0, self.1.clone())\n        }\n    }\n\n    let s: &[Fail] =\n        &[Fail(0, \"foo\".to_string()), Fail(1, \"bar\".to_string()), Fail(2, \"baz\".to_string())];\n\n    // Should panic, but not cause memory corruption\n    let _r: Arc<[Fail]> = Arc::from(s);\n}\n\n#[test]\nfn test_from_box() {\n    let b: Box<u32> = box 123;\n    let r: Arc<u32> = Arc::from(b);\n\n    assert_eq!(*r, 123);\n}\n\n#[test]\nfn test_from_box_str() {\n    use std::string::String;\n\n    let s = String::from(\"foo\").into_boxed_str();\n    let r: Arc<str> = Arc::from(s);\n\n    assert_eq!(&r[..], \"foo\");\n}\n\n#[test]\nfn test_from_box_slice() {\n    let s = vec![1, 2, 3].into_boxed_slice();\n    let r: Arc<[u32]> = Arc::from(s);\n\n    assert_eq!(&r[..], [1, 2, 3]);\n}\n\n#[test]\nfn test_from_box_trait() {\n    use std::fmt::Display;\n    use std::string::ToString;\n\n    let b: Box<dyn Display> = box 123;\n    let r: Arc<dyn Display> = Arc::from(b);\n\n    assert_eq!(r.to_string(), \"123\");\n}\n\n#[test]\nfn test_from_box_trait_zero_sized() {\n    use std::fmt::Debug;\n\n    let b: Box<dyn Debug> = box ();\n    let r: Arc<dyn Debug> = Arc::from(b);\n\n    assert_eq!(format!(\"{:?}\", r), \"()\");\n}\n\n#[test]\nfn test_from_vec() {\n    let v = vec![1, 2, 3];\n    let r: Arc<[u32]> = Arc::from(v);\n\n    assert_eq!(&r[..], [1, 2, 3]);\n}\n\n#[test]\nfn test_downcast() {\n    use std::any::Any;\n\n    let r1: Arc<dyn Any + Send + Sync> = Arc::new(i32::MAX);\n    let r2: Arc<dyn Any + Send + Sync> = Arc::new(\"abc\");\n\n    assert!(r1.clone().downcast::<u32>().is_err());\n\n    let r1i32 = r1.downcast::<i32>();\n    assert!(r1i32.is_ok());\n    assert_eq!(r1i32.unwrap(), Arc::new(i32::MAX));\n\n    assert!(r2.clone().downcast::<i32>().is_err());\n\n    let r2str = r2.downcast::<&'static str>();\n    assert!(r2str.is_ok());\n    assert_eq!(r2str.unwrap(), Arc::new(\"abc\"));\n}\n\n#[test]\nfn test_array_from_slice() {\n    let v = vec![1, 2, 3];\n    let r: Arc<[u32]> = Arc::from(v);\n\n    let a: Result<Arc<[u32; 3]>, _> = r.clone().try_into();\n    assert!(a.is_ok());\n\n    let a: Result<Arc<[u32; 2]>, _> = r.clone().try_into();\n    assert!(a.is_err());\n}\n\n#[test]\nfn test_arc_cyclic_with_zero_refs() {\n    struct ZeroRefs {\n        inner: Weak<ZeroRefs>,\n    }\n    let zero_refs = Arc::new_cyclic(|inner| {\n        assert_eq!(inner.strong_count(), 0);\n        assert!(inner.upgrade().is_none());\n        ZeroRefs { inner: Weak::new() }\n    });\n\n    assert_eq!(Arc::strong_count(&zero_refs), 1);\n    assert_eq!(Arc::weak_count(&zero_refs), 0);\n    assert_eq!(zero_refs.inner.strong_count(), 0);\n    assert_eq!(zero_refs.inner.weak_count(), 0);\n}\n\n#[test]\nfn test_arc_new_cyclic_one_ref() {\n    struct OneRef {\n        inner: Weak<OneRef>,\n    }\n    let one_ref = Arc::new_cyclic(|inner| {\n        assert_eq!(inner.strong_count(), 0);\n        assert!(inner.upgrade().is_none());\n        OneRef { inner: inner.clone() }\n    });\n\n    assert_eq!(Arc::strong_count(&one_ref), 1);\n    assert_eq!(Arc::weak_count(&one_ref), 1);\n\n    let one_ref2 = Weak::upgrade(&one_ref.inner).unwrap();\n    assert!(Arc::ptr_eq(&one_ref, &one_ref2));\n\n    assert_eq!(Arc::strong_count(&one_ref), 2);\n    assert_eq!(Arc::weak_count(&one_ref), 1);\n}\n\n#[test]\nfn test_arc_cyclic_two_refs() {\n    struct TwoRefs {\n        inner1: Weak<TwoRefs>,\n        inner2: Weak<TwoRefs>,\n    }\n    let two_refs = Arc::new_cyclic(|inner| {\n        assert_eq!(inner.strong_count(), 0);\n        assert!(inner.upgrade().is_none());\n\n        let inner1 = inner.clone();\n        let inner2 = inner1.clone();\n\n        TwoRefs { inner1, inner2 }\n    });\n\n    assert_eq!(Arc::strong_count(&two_refs), 1);\n    assert_eq!(Arc::weak_count(&two_refs), 2);\n\n    let two_refs1 = Weak::upgrade(&two_refs.inner1).unwrap();\n    assert!(Arc::ptr_eq(&two_refs, &two_refs1));\n\n    let two_refs2 = Weak::upgrade(&two_refs.inner2).unwrap();\n    assert!(Arc::ptr_eq(&two_refs, &two_refs2));\n\n    assert_eq!(Arc::strong_count(&two_refs), 3);\n    assert_eq!(Arc::weak_count(&two_refs), 2);\n}\n"],[2070,"//! Unicode string slices.\n//!\n//! *[See also the `str` primitive type](str).*\n//!\n//! The `&str` type is one of the two main string types, the other being `String`.\n//! Unlike its `String` counterpart, its contents are borrowed.\n//!\n//! # Basic Usage\n//!\n//! A basic string declaration of `&str` type:\n//!\n//! ```\n//! let hello_world = \"Hello, World!\";\n//! ```\n//!\n//! Here we have declared a string literal, also known as a string slice.\n//! String literals have a static lifetime, which means the string `hello_world`\n//! is guaranteed to be valid for the duration of the entire program.\n//! We can explicitly specify `hello_world`'s lifetime as well:\n//!\n//! ```\n//! let hello_world: &'static str = \"Hello, world!\";\n//! ```\n\n#![stable(feature = \"rust1\", since = \"1.0.0\")]\n// Many of the usings in this module are only used in the test configuration.\n// It's cleaner to just turn off the unused_imports warning than to fix them.\n#![allow(unused_imports)]\n\nuse core::borrow::{Borrow, BorrowMut};\nuse core::iter::FusedIterator;\nuse core::mem;\nuse core::ptr;\nuse core::str::pattern::{DoubleEndedSearcher, Pattern, ReverseSearcher, Searcher};\nuse core::unicode::conversions;\n\nuse crate::borrow::ToOwned;\nuse crate::boxed::Box;\nuse crate::slice::{Concat, Join, SliceIndex};\nuse crate::string::String;\nuse crate::vec::Vec;\n\n#[stable(feature = \"rust1\", since = \"1.0.0\")]\npub use core::str::pattern;\n#[stable(feature = \"encode_utf16\", since = \"1.8.0\")]\npub use core::str::EncodeUtf16;\n#[stable(feature = \"split_ascii_whitespace\", since = \"1.34.0\")]\npub use core::str::SplitAsciiWhitespace;\n#[stable(feature = \"split_inclusive\", since = \"1.53.0\")]\npub use core::str::SplitInclusive;\n#[stable(feature = \"rust1\", since = \"1.0.0\")]\npub use core::str::SplitWhitespace;\n#[stable(feature = \"rust1\", since = \"1.0.0\")]\npub use core::str::{from_utf8, from_utf8_mut, Bytes, CharIndices, Chars};\n#[stable(feature = \"rust1\", since = \"1.0.0\")]\npub use core::str::{from_utf8_unchecked, from_utf8_unchecked_mut, ParseBoolError};\n#[stable(feature = \"str_escape\", since = \"1.34.0\")]\npub use core::str::{EscapeDebug, EscapeDefault, EscapeUnicode};\n#[stable(feature = \"rust1\", since = \"1.0.0\")]\npub use core::str::{FromStr, Utf8Error};\n#[allow(deprecated)]\n#[stable(feature = \"rust1\", since = \"1.0.0\")]\npub use core::str::{Lines, LinesAny};\n#[stable(feature = \"rust1\", since = \"1.0.0\")]\npub use core::str::{MatchIndices, RMatchIndices};\n#[stable(feature = \"rust1\", since = \"1.0.0\")]\npub use core::str::{Matches, RMatches};\n#[stable(feature = \"rust1\", since = \"1.0.0\")]\npub use core::str::{RSplit, Split};\n#[stable(feature = \"rust1\", since = \"1.0.0\")]\npub use core::str::{RSplitN, SplitN};\n#[stable(feature = \"rust1\", since = \"1.0.0\")]\npub use core::str::{RSplitTerminator, SplitTerminator};\n\n/// Note: `str` in `Concat<str>` is not meaningful here.\n/// This type parameter of the trait only exists to enable another impl.\n#[cfg(not(no_global_oom_handling))]\n#[unstable(feature = \"slice_concat_ext\", issue = \"27747\")]\nimpl<S: Borrow<str>> Concat<str> for [S] {\n    type Output = String;\n\n    fn concat(slice: &Self) -> String {\n        Join::join(slice, \"\")\n    }\n}\n\n#[cfg(not(no_global_oom_handling))]\n#[unstable(feature = \"slice_concat_ext\", issue = \"27747\")]\nimpl<S: Borrow<str>> Join<&str> for [S] {\n    type Output = String;\n\n    fn join(slice: &Self, sep: &str) -> String {\n        unsafe { String::from_utf8_unchecked(join_generic_copy(slice, sep.as_bytes())) }\n    }\n}\n\n#[cfg(not(no_global_oom_handling))]\nmacro_rules! specialize_for_lengths {\n    ($separator:expr, $target:expr, $iter:expr; $($num:expr),*) => {{\n        let mut target = $target;\n        let iter = $iter;\n        let sep_bytes = $separator;\n        match $separator.len() {\n            $(\n                // loops with hardcoded sizes run much faster\n                // specialize the cases with small separator lengths\n                $num => {\n                    for s in iter {\n                        copy_slice_and_advance!(target, sep_bytes);\n                        let content_bytes = s.borrow().as_ref();\n                        copy_slice_and_advance!(target, content_bytes);\n                    }\n                },\n            )*\n            _ => {\n                // arbitrary non-zero size fallback\n                for s in iter {\n                    copy_slice_and_advance!(target, sep_bytes);\n                    let content_bytes = s.borrow().as_ref();\n                    copy_slice_and_advance!(target, content_bytes);\n                }\n            }\n        }\n        target\n    }}\n}\n\n#[cfg(not(no_global_oom_handling))]\nmacro_rules! copy_slice_and_advance {\n    ($target:expr, $bytes:expr) => {\n        let len = $bytes.len();\n        let (head, tail) = { $target }.split_at_mut(len);\n        head.copy_from_slice($bytes);\n        $target = tail;\n    };\n}\n\n// Optimized join implementation that works for both Vec<T> (T: Copy) and String's inner vec\n// Currently (2018-05-13) there is a bug with type inference and specialization (see issue #36262)\n// For this reason SliceConcat<T> is not specialized for T: Copy and SliceConcat<str> is the\n// only user of this function. It is left in place for the time when that is fixed.\n//\n// the bounds for String-join are S: Borrow<str> and for Vec-join Borrow<[T]>\n// [T] and str both impl AsRef<[T]> for some T\n// => s.borrow().as_ref() and we always have slices\n#[cfg(not(no_global_oom_handling))]\nfn join_generic_copy<B, T, S>(slice: &[S], sep: &[T]) -> Vec<T>\nwhere\n    T: Copy,\n    B: AsRef<[T]> + ?Sized,\n    S: Borrow<B>,\n{\n    let sep_len = sep.len();\n    let mut iter = slice.iter();\n\n    // the first slice is the only one without a separator preceding it\n    let first = match iter.next() {\n        Some(first) => first,\n        None => return vec![],\n    };\n\n    // compute the exact total length of the joined Vec\n    // if the `len` calculation overflows, we'll panic\n    // we would have run out of memory anyway and the rest of the function requires\n    // the entire Vec pre-allocated for safety\n    let reserved_len = sep_len\n        .checked_mul(iter.len())\n        .and_then(|n| {\n            slice.iter().map(|s| s.borrow().as_ref().len()).try_fold(n, usize::checked_add)\n        })\n        .expect(\"attempt to join into collection with len > usize::MAX\");\n\n    // prepare an uninitialized buffer\n    let mut result = Vec::with_capacity(reserved_len);\n    debug_assert!(result.capacity() >= reserved_len);\n\n    result.extend_from_slice(first.borrow().as_ref());\n\n    unsafe {\n        let pos = result.len();\n        let target = result.get_unchecked_mut(pos..reserved_len);\n\n        // copy separator and slices over without bounds checks\n        // generate loops with hardcoded offsets for small separators\n        // massive improvements possible (~ x2)\n        let remain = specialize_for_lengths!(sep, target, iter; 0, 1, 2, 3, 4);\n\n        // A weird borrow implementation may return different\n        // slices for the length calculation and the actual copy.\n        // Make sure we don't expose uninitialized bytes to the caller.\n        let result_len = reserved_len - remain.len();\n        result.set_len(result_len);\n    }\n    result\n}\n\n#[stable(feature = \"rust1\", since = \"1.0.0\")]\nimpl Borrow<str> for String {\n    #[inline]\n    fn borrow(&self) -> &str {\n        &self[..]\n    }\n}\n\n#[stable(feature = \"string_borrow_mut\", since = \"1.36.0\")]\nimpl BorrowMut<str> for String {\n    #[inline]\n    fn borrow_mut(&mut self) -> &mut str {\n        &mut self[..]\n    }\n}\n\n#[cfg(not(no_global_oom_handling))]\n#[stable(feature = \"rust1\", since = \"1.0.0\")]\nimpl ToOwned for str {\n    type Owned = String;\n    #[inline]\n    fn to_owned(&self) -> String {\n        unsafe { String::from_utf8_unchecked(self.as_bytes().to_owned()) }\n    }\n\n    fn clone_into(&self, target: &mut String) {\n        let mut b = mem::take(target).into_bytes();\n        self.as_bytes().clone_into(&mut b);\n        *target = unsafe { String::from_utf8_unchecked(b) }\n    }\n}\n\n/// Methods for string slices.\n#[lang = \"str_alloc\"]\n#[cfg(not(test))]\nimpl str {\n    /// Converts a `Box<str>` into a `Box<[u8]>` without copying or allocating.\n    ///\n    /// # Examples\n    ///\n    /// Basic usage:\n    ///\n    /// ```\n    /// let s = \"this is a string\";\n    /// let boxed_str = s.to_owned().into_boxed_str();\n    /// let boxed_bytes = boxed_str.into_boxed_bytes();\n    /// assert_eq!(*boxed_bytes, *s.as_bytes());\n    /// ```\n    #[stable(feature = \"str_box_extras\", since = \"1.20.0\")]\n    #[inline]\n    pub fn into_boxed_bytes(self: Box<str>) -> Box<[u8]> {\n        self.into()\n    }\n\n    /// Replaces all matches of a pattern with another string.\n    ///\n    /// `replace` creates a new [`String`], and copies the data from this string slice into it.\n    /// While doing so, it attempts to find matches of a pattern. If it finds any, it\n    /// replaces them with the replacement string slice.\n    ///\n    /// # Examples\n    ///\n    /// Basic usage:\n    ///\n    /// ```\n    /// let s = \"this is old\";\n    ///\n    /// assert_eq!(\"this is new\", s.replace(\"old\", \"new\"));\n    /// ```\n    ///\n    /// When the pattern doesn't match:\n    ///\n    /// ```\n    /// let s = \"this is old\";\n    /// assert_eq!(s, s.replace(\"cookie monster\", \"little lamb\"));\n    /// ```\n    #[cfg(not(no_global_oom_handling))]\n    #[must_use = \"this returns the replaced string as a new allocation, \\\n                  without modifying the original\"]\n    #[stable(feature = \"rust1\", since = \"1.0.0\")]\n    #[inline]\n    pub fn replace<'a, P: Pattern<'a>>(&'a self, from: P, to: &str) -> String {\n        let mut result = String::new();\n        let mut last_end = 0;\n        for (start, part) in self.match_indices(from) {\n            result.push_str(unsafe { self.get_unchecked(last_end..start) });\n            result.push_str(to);\n            last_end = start + part.len();\n        }\n        result.push_str(unsafe { self.get_unchecked(last_end..self.len()) });\n        result\n    }\n\n    /// Replaces first N matches of a pattern with another string.\n    ///\n    /// `replacen` creates a new [`String`], and copies the data from this string slice into it.\n    /// While doing so, it attempts to find matches of a pattern. If it finds any, it\n    /// replaces them with the replacement string slice at most `count` times.\n    ///\n    /// # Examples\n    ///\n    /// Basic usage:\n    ///\n    /// ```\n    /// let s = \"foo foo 123 foo\";\n    /// assert_eq!(\"new new 123 foo\", s.replacen(\"foo\", \"new\", 2));\n    /// assert_eq!(\"faa fao 123 foo\", s.replacen('o', \"a\", 3));\n    /// assert_eq!(\"foo foo new23 foo\", s.replacen(char::is_numeric, \"new\", 1));\n    /// ```\n    ///\n    /// When the pattern doesn't match:\n    ///\n    /// ```\n    /// let s = \"this is old\";\n    /// assert_eq!(s, s.replacen(\"cookie monster\", \"little lamb\", 10));\n    /// ```\n    #[cfg(not(no_global_oom_handling))]\n    #[must_use = \"this returns the replaced string as a new allocation, \\\n                  without modifying the original\"]\n    #[stable(feature = \"str_replacen\", since = \"1.16.0\")]\n    pub fn replacen<'a, P: Pattern<'a>>(&'a self, pat: P, to: &str, count: usize) -> String {\n        // Hope to reduce the times of re-allocation\n        let mut result = String::with_capacity(32);\n        let mut last_end = 0;\n        for (start, part) in self.match_indices(pat).take(count) {\n            result.push_str(unsafe { self.get_unchecked(last_end..start) });\n            result.push_str(to);\n            last_end = start + part.len();\n        }\n        result.push_str(unsafe { self.get_unchecked(last_end..self.len()) });\n        result\n    }\n\n    /// Returns the lowercase equivalent of this string slice, as a new [`String`].\n    ///\n    /// 'Lowercase' is defined according to the terms of the Unicode Derived Core Property\n    /// `Lowercase`.\n    ///\n    /// Since some characters can expand into multiple characters when changing\n    /// the case, this function returns a [`String`] instead of modifying the\n    /// parameter in-place.\n    ///\n    /// # Examples\n    ///\n    /// Basic usage:\n    ///\n    /// ```\n    /// let s = \"HELLO\";\n    ///\n    /// assert_eq!(\"hello\", s.to_lowercase());\n    /// ```\n    ///\n    /// A tricky example, with sigma:\n    ///\n    /// ```\n    /// let sigma = \"Σ\";\n    ///\n    /// assert_eq!(\"σ\", sigma.to_lowercase());\n    ///\n    /// // but at the end of a word, it's ς, not σ:\n    /// let odysseus = \"ὈΔΥΣΣΕΎΣ\";\n    ///\n    /// assert_eq!(\"ὀδυσσεύς\", odysseus.to_lowercase());\n    /// ```\n    ///\n    /// Languages without case are not changed:\n    ///\n    /// ```\n    /// let new_year = \"农历新年\";\n    ///\n    /// assert_eq!(new_year, new_year.to_lowercase());\n    /// ```\n    #[cfg(not(no_global_oom_handling))]\n    #[stable(feature = \"unicode_case_mapping\", since = \"1.2.0\")]\n    pub fn to_lowercase(&self) -> String {\n        let mut s = String::with_capacity(self.len());\n        for (i, c) in self[..].char_indices() {\n            if c == 'Σ' {\n                // Σ maps to σ, except at the end of a word where it maps to ς.\n                // This is the only conditional (contextual) but language-independent mapping\n                // in `SpecialCasing.txt`,\n                // so hard-code it rather than have a generic \"condition\" mechanism.\n                // See https://github.com/rust-lang/rust/issues/26035\n                map_uppercase_sigma(self, i, &mut s)\n            } else {\n                match conversions::to_lower(c) {\n                    [a, '\\0', _] => s.push(a),\n                    [a, b, '\\0'] => {\n                        s.push(a);\n                        s.push(b);\n                    }\n                    [a, b, c] => {\n                        s.push(a);\n                        s.push(b);\n                        s.push(c);\n                    }\n                }\n            }\n        }\n        return s;\n\n        fn map_uppercase_sigma(from: &str, i: usize, to: &mut String) {\n            // See https://www.unicode.org/versions/Unicode7.0.0/ch03.pdf#G33992\n            // for the definition of `Final_Sigma`.\n            debug_assert!('Σ'.len_utf8() == 2);\n            let is_word_final = case_ignoreable_then_cased(from[..i].chars().rev())\n                && !case_ignoreable_then_cased(from[i + 2..].chars());\n            to.push_str(if is_word_final { \"ς\" } else { \"σ\" });\n        }\n\n        fn case_ignoreable_then_cased<I: Iterator<Item = char>>(iter: I) -> bool {\n            use core::unicode::{Case_Ignorable, Cased};\n            match iter.skip_while(|&c| Case_Ignorable(c)).next() {\n                Some(c) => Cased(c),\n                None => false,\n            }\n        }\n    }\n\n    /// Returns the uppercase equivalent of this string slice, as a new [`String`].\n    ///\n    /// 'Uppercase' is defined according to the terms of the Unicode Derived Core Property\n    /// `Uppercase`.\n    ///\n    /// Since some characters can expand into multiple characters when changing\n    /// the case, this function returns a [`String`] instead of modifying the\n    /// parameter in-place.\n    ///\n    /// # Examples\n    ///\n    /// Basic usage:\n    ///\n    /// ```\n    /// let s = \"hello\";\n    ///\n    /// assert_eq!(\"HELLO\", s.to_uppercase());\n    /// ```\n    ///\n    /// Scripts without case are not changed:\n    ///\n    /// ```\n    /// let new_year = \"农历新年\";\n    ///\n    /// assert_eq!(new_year, new_year.to_uppercase());\n    /// ```\n    ///\n    /// One character can become multiple:\n    /// ```\n    /// let s = \"tschüß\";\n    ///\n    /// assert_eq!(\"TSCHÜSS\", s.to_uppercase());\n    /// ```\n    #[cfg(not(no_global_oom_handling))]\n    #[stable(feature = \"unicode_case_mapping\", since = \"1.2.0\")]\n    pub fn to_uppercase(&self) -> String {\n        let mut s = String::with_capacity(self.len());\n        for c in self[..].chars() {\n            match conversions::to_upper(c) {\n                [a, '\\0', _] => s.push(a),\n                [a, b, '\\0'] => {\n                    s.push(a);\n                    s.push(b);\n                }\n                [a, b, c] => {\n                    s.push(a);\n                    s.push(b);\n                    s.push(c);\n                }\n            }\n        }\n        s\n    }\n\n    /// Converts a [`Box<str>`] into a [`String`] without copying or allocating.\n    ///\n    /// # Examples\n    ///\n    /// Basic usage:\n    ///\n    /// ```\n    /// let string = String::from(\"birthday gift\");\n    /// let boxed_str = string.clone().into_boxed_str();\n    ///\n    /// assert_eq!(boxed_str.into_string(), string);\n    /// ```\n    #[stable(feature = \"box_str\", since = \"1.4.0\")]\n    #[inline]\n    pub fn into_string(self: Box<str>) -> String {\n        let slice = Box::<[u8]>::from(self);\n        unsafe { String::from_utf8_unchecked(slice.into_vec()) }\n    }\n\n    /// Creates a new [`String`] by repeating a string `n` times.\n    ///\n    /// # Panics\n    ///\n    /// This function will panic if the capacity would overflow.\n    ///\n    /// # Examples\n    ///\n    /// Basic usage:\n    ///\n    /// ```\n    /// assert_eq!(\"abc\".repeat(4), String::from(\"abcabcabcabc\"));\n    /// ```\n    ///\n    /// A panic upon overflow:\n    ///\n    /// ```should_panic\n    /// // this will panic at runtime\n    /// \"0123456789abcdef\".repeat(usize::MAX);\n    /// ```\n    #[cfg(not(no_global_oom_handling))]\n    #[stable(feature = \"repeat_str\", since = \"1.16.0\")]\n    pub fn repeat(&self, n: usize) -> String {\n        unsafe { String::from_utf8_unchecked(self.as_bytes().repeat(n)) }\n    }\n\n    /// Returns a copy of this string where each character is mapped to its\n    /// ASCII upper case equivalent.\n    ///\n    /// ASCII letters 'a' to 'z' are mapped to 'A' to 'Z',\n    /// but non-ASCII letters are unchanged.\n    ///\n    /// To uppercase the value in-place, use [`make_ascii_uppercase`].\n    ///\n    /// To uppercase ASCII characters in addition to non-ASCII characters, use\n    /// [`to_uppercase`].\n    ///\n    /// # Examples\n    ///\n    /// ```\n    /// let s = \"Grüße, Jürgen ❤\";\n    ///\n    /// assert_eq!(\"GRüßE, JüRGEN ❤\", s.to_ascii_uppercase());\n    /// ```\n    ///\n    /// [`make_ascii_uppercase`]: str::make_ascii_uppercase\n    /// [`to_uppercase`]: #method.to_uppercase\n    #[cfg(not(no_global_oom_handling))]\n    #[stable(feature = \"ascii_methods_on_intrinsics\", since = \"1.23.0\")]\n    #[inline]\n    pub fn to_ascii_uppercase(&self) -> String {\n        let mut bytes = self.as_bytes().to_vec();\n        bytes.make_ascii_uppercase();\n        // make_ascii_uppercase() preserves the UTF-8 invariant.\n        unsafe { String::from_utf8_unchecked(bytes) }\n    }\n\n    /// Returns a copy of this string where each character is mapped to its\n    /// ASCII lower case equivalent.\n    ///\n    /// ASCII letters 'A' to 'Z' are mapped to 'a' to 'z',\n    /// but non-ASCII letters are unchanged.\n    ///\n    /// To lowercase the value in-place, use [`make_ascii_lowercase`].\n    ///\n    /// To lowercase ASCII characters in addition to non-ASCII characters, use\n    /// [`to_lowercase`].\n    ///\n    /// # Examples\n    ///\n    /// ```\n    /// let s = \"Grüße, Jürgen ❤\";\n    ///\n    /// assert_eq!(\"grüße, jürgen ❤\", s.to_ascii_lowercase());\n    /// ```\n    ///\n    /// [`make_ascii_lowercase`]: str::make_ascii_lowercase\n    /// [`to_lowercase`]: #method.to_lowercase\n    #[cfg(not(no_global_oom_handling))]\n    #[stable(feature = \"ascii_methods_on_intrinsics\", since = \"1.23.0\")]\n    #[inline]\n    pub fn to_ascii_lowercase(&self) -> String {\n        let mut bytes = self.as_bytes().to_vec();\n        bytes.make_ascii_lowercase();\n        // make_ascii_lowercase() preserves the UTF-8 invariant.\n        unsafe { String::from_utf8_unchecked(bytes) }\n    }\n}\n\n/// Converts a boxed slice of bytes to a boxed string slice without checking\n/// that the string contains valid UTF-8.\n///\n/// # Examples\n///\n/// Basic usage:\n///\n/// ```\n/// let smile_utf8 = Box::new([226, 152, 186]);\n/// let smile = unsafe { std::str::from_boxed_utf8_unchecked(smile_utf8) };\n///\n/// assert_eq!(\"☺\", &*smile);\n/// ```\n#[stable(feature = \"str_box_extras\", since = \"1.20.0\")]\n#[inline]\npub unsafe fn from_boxed_utf8_unchecked(v: Box<[u8]>) -> Box<str> {\n    unsafe { Box::from_raw(Box::into_raw(v) as *mut str) }\n}\n"],[2071,"#![unstable(feature = \"raw_vec_internals\", reason = \"implementation detail\", issue = \"none\")]\n#![doc(hidden)]\n\nuse core::alloc::LayoutError;\nuse core::cmp;\nuse core::intrinsics;\nuse core::mem::{self, ManuallyDrop, MaybeUninit};\nuse core::ops::Drop;\nuse core::ptr::{self, NonNull, Unique};\nuse core::slice;\n\n#[cfg(not(no_global_oom_handling))]\nuse crate::alloc::handle_alloc_error;\nuse crate::alloc::{Allocator, Global, Layout};\nuse crate::boxed::Box;\nuse crate::collections::TryReserveError::{self, *};\n\n#[cfg(test)]\nmod tests;\n\n#[cfg(not(no_global_oom_handling))]\nenum AllocInit {\n    /// The contents of the new memory are uninitialized.\n    Uninitialized,\n    /// The new memory is guaranteed to be zeroed.\n    Zeroed,\n}\n\n/// A low-level utility for more ergonomically allocating, reallocating, and deallocating\n/// a buffer of memory on the heap without having to worry about all the corner cases\n/// involved. This type is excellent for building your own data structures like Vec and VecDeque.\n/// In particular:\n///\n/// * Produces `Unique::dangling()` on zero-sized types.\n/// * Produces `Unique::dangling()` on zero-length allocations.\n/// * Avoids freeing `Unique::dangling()`.\n/// * Catches all overflows in capacity computations (promotes them to \"capacity overflow\" panics).\n/// * Guards against 32-bit systems allocating more than isize::MAX bytes.\n/// * Guards against overflowing your length.\n/// * Calls `handle_alloc_error` for fallible allocations.\n/// * Contains a `ptr::Unique` and thus endows the user with all related benefits.\n/// * Uses the excess returned from the allocator to use the largest available capacity.\n///\n/// This type does not in anyway inspect the memory that it manages. When dropped it *will*\n/// free its memory, but it *won't* try to drop its contents. It is up to the user of `RawVec`\n/// to handle the actual things *stored* inside of a `RawVec`.\n///\n/// Note that the excess of a zero-sized types is always infinite, so `capacity()` always returns\n/// `usize::MAX`. This means that you need to be careful when round-tripping this type with a\n/// `Box<[T]>`, since `capacity()` won't yield the length.\n#[allow(missing_debug_implementations)]\npub struct RawVec<T, A: Allocator = Global> {\n    ptr: Unique<T>,\n    cap: usize,\n    alloc: A,\n}\n\nimpl<T> RawVec<T, Global> {\n    /// HACK(Centril): This exists because stable `const fn` can only call stable `const fn`, so\n    /// they cannot call `Self::new()`.\n    ///\n    /// If you change `RawVec<T>::new` or dependencies, please take care to not introduce anything\n    /// that would truly const-call something unstable.\n    pub const NEW: Self = Self::new();\n\n    /// Creates the biggest possible `RawVec` (on the system heap)\n    /// without allocating. If `T` has positive size, then this makes a\n    /// `RawVec` with capacity `0`. If `T` is zero-sized, then it makes a\n    /// `RawVec` with capacity `usize::MAX`. Useful for implementing\n    /// delayed allocation.\n    pub const fn new() -> Self {\n        Self::new_in(Global)\n    }\n\n    /// Creates a `RawVec` (on the system heap) with exactly the\n    /// capacity and alignment requirements for a `[T; capacity]`. This is\n    /// equivalent to calling `RawVec::new` when `capacity` is `0` or `T` is\n    /// zero-sized. Note that if `T` is zero-sized this means you will\n    /// *not* get a `RawVec` with the requested capacity.\n    ///\n    /// # Panics\n    ///\n    /// Panics if the requested capacity exceeds `isize::MAX` bytes.\n    ///\n    /// # Aborts\n    ///\n    /// Aborts on OOM.\n    #[cfg(not(no_global_oom_handling))]\n    #[inline]\n    pub fn with_capacity(capacity: usize) -> Self {\n        Self::with_capacity_in(capacity, Global)\n    }\n\n    /// Like `with_capacity`, but guarantees the buffer is zeroed.\n    #[cfg(not(no_global_oom_handling))]\n    #[inline]\n    pub fn with_capacity_zeroed(capacity: usize) -> Self {\n        Self::with_capacity_zeroed_in(capacity, Global)\n    }\n\n    /// Reconstitutes a `RawVec` from a pointer and capacity.\n    ///\n    /// # Safety\n    ///\n    /// The `ptr` must be allocated (on the system heap), and with the given `capacity`.\n    /// The `capacity` cannot exceed `isize::MAX` for sized types. (only a concern on 32-bit\n    /// systems). ZST vectors may have a capacity up to `usize::MAX`.\n    /// If the `ptr` and `capacity` come from a `RawVec`, then this is guaranteed.\n    #[inline]\n    pub unsafe fn from_raw_parts(ptr: *mut T, capacity: usize) -> Self {\n        unsafe { Self::from_raw_parts_in(ptr, capacity, Global) }\n    }\n}\n\nimpl<T, A: Allocator> RawVec<T, A> {\n    // Tiny Vecs are dumb. Skip to:\n    // - 8 if the element size is 1, because any heap allocators is likely\n    //   to round up a request of less than 8 bytes to at least 8 bytes.\n    // - 4 if elements are moderate-sized (<= 1 KiB).\n    // - 1 otherwise, to avoid wasting too much space for very short Vecs.\n    const MIN_NON_ZERO_CAP: usize = if mem::size_of::<T>() == 1 {\n        8\n    } else if mem::size_of::<T>() <= 1024 {\n        4\n    } else {\n        1\n    };\n\n    /// Like `new`, but parameterized over the choice of allocator for\n    /// the returned `RawVec`.\n    #[rustc_allow_const_fn_unstable(const_fn)]\n    pub const fn new_in(alloc: A) -> Self {\n        // `cap: 0` means \"unallocated\". zero-sized types are ignored.\n        Self { ptr: Unique::dangling(), cap: 0, alloc }\n    }\n\n    /// Like `with_capacity`, but parameterized over the choice of\n    /// allocator for the returned `RawVec`.\n    #[cfg(not(no_global_oom_handling))]\n    #[inline]\n    pub fn with_capacity_in(capacity: usize, alloc: A) -> Self {\n        Self::allocate_in(capacity, AllocInit::Uninitialized, alloc)\n    }\n\n    /// Like `with_capacity_zeroed`, but parameterized over the choice\n    /// of allocator for the returned `RawVec`.\n    #[cfg(not(no_global_oom_handling))]\n    #[inline]\n    pub fn with_capacity_zeroed_in(capacity: usize, alloc: A) -> Self {\n        Self::allocate_in(capacity, AllocInit::Zeroed, alloc)\n    }\n\n    /// Converts a `Box<[T]>` into a `RawVec<T>`.\n    pub fn from_box(slice: Box<[T], A>) -> Self {\n        unsafe {\n            let (slice, alloc) = Box::into_raw_with_allocator(slice);\n            RawVec::from_raw_parts_in(slice.as_mut_ptr(), slice.len(), alloc)\n        }\n    }\n\n    /// Converts the entire buffer into `Box<[MaybeUninit<T>]>` with the specified `len`.\n    ///\n    /// Note that this will correctly reconstitute any `cap` changes\n    /// that may have been performed. (See description of type for details.)\n    ///\n    /// # Safety\n    ///\n    /// * `len` must be greater than or equal to the most recently requested capacity, and\n    /// * `len` must be less than or equal to `self.capacity()`.\n    ///\n    /// Note, that the requested capacity and `self.capacity()` could differ, as\n    /// an allocator could overallocate and return a greater memory block than requested.\n    pub unsafe fn into_box(self, len: usize) -> Box<[MaybeUninit<T>], A> {\n        // Sanity-check one half of the safety requirement (we cannot check the other half).\n        debug_assert!(\n            len <= self.capacity(),\n            \"`len` must be smaller than or equal to `self.capacity()`\"\n        );\n\n        let me = ManuallyDrop::new(self);\n        unsafe {\n            let slice = slice::from_raw_parts_mut(me.ptr() as *mut MaybeUninit<T>, len);\n            Box::from_raw_in(slice, ptr::read(&me.alloc))\n        }\n    }\n\n    #[cfg(not(no_global_oom_handling))]\n    fn allocate_in(capacity: usize, init: AllocInit, alloc: A) -> Self {\n        if mem::size_of::<T>() == 0 {\n            Self::new_in(alloc)\n        } else {\n            // We avoid `unwrap_or_else` here because it bloats the amount of\n            // LLVM IR generated.\n            let layout = match Layout::array::<T>(capacity) {\n                Ok(layout) => layout,\n                Err(_) => capacity_overflow(),\n            };\n            match alloc_guard(layout.size()) {\n                Ok(_) => {}\n                Err(_) => capacity_overflow(),\n            }\n            let result = match init {\n                AllocInit::Uninitialized => alloc.allocate(layout),\n                AllocInit::Zeroed => alloc.allocate_zeroed(layout),\n            };\n            let ptr = match result {\n                Ok(ptr) => ptr,\n                Err(_) => handle_alloc_error(layout),\n            };\n\n            Self {\n                ptr: unsafe { Unique::new_unchecked(ptr.cast().as_ptr()) },\n                cap: Self::capacity_from_bytes(ptr.len()),\n                alloc,\n            }\n        }\n    }\n\n    /// Reconstitutes a `RawVec` from a pointer, capacity, and allocator.\n    ///\n    /// # Safety\n    ///\n    /// The `ptr` must be allocated (via the given allocator `alloc`), and with the given\n    /// `capacity`.\n    /// The `capacity` cannot exceed `isize::MAX` for sized types. (only a concern on 32-bit\n    /// systems). ZST vectors may have a capacity up to `usize::MAX`.\n    /// If the `ptr` and `capacity` come from a `RawVec` created via `alloc`, then this is\n    /// guaranteed.\n    #[inline]\n    pub unsafe fn from_raw_parts_in(ptr: *mut T, capacity: usize, alloc: A) -> Self {\n        Self { ptr: unsafe { Unique::new_unchecked(ptr) }, cap: capacity, alloc }\n    }\n\n    /// Gets a raw pointer to the start of the allocation. Note that this is\n    /// `Unique::dangling()` if `capacity == 0` or `T` is zero-sized. In the former case, you must\n    /// be careful.\n    #[inline]\n    pub fn ptr(&self) -> *mut T {\n        self.ptr.as_ptr()\n    }\n\n    /// Gets the capacity of the allocation.\n    ///\n    /// This will always be `usize::MAX` if `T` is zero-sized.\n    #[inline(always)]\n    pub fn capacity(&self) -> usize {\n        if mem::size_of::<T>() == 0 { usize::MAX } else { self.cap }\n    }\n\n    /// Returns a shared reference to the allocator backing this `RawVec`.\n    pub fn allocator(&self) -> &A {\n        &self.alloc\n    }\n\n    fn current_memory(&self) -> Option<(NonNull<u8>, Layout)> {\n        if mem::size_of::<T>() == 0 || self.cap == 0 {\n            None\n        } else {\n            // We have an allocated chunk of memory, so we can bypass runtime\n            // checks to get our current layout.\n            unsafe {\n                let align = mem::align_of::<T>();\n                let size = mem::size_of::<T>() * self.cap;\n                let layout = Layout::from_size_align_unchecked(size, align);\n                Some((self.ptr.cast().into(), layout))\n            }\n        }\n    }\n\n    /// Ensures that the buffer contains at least enough space to hold `len +\n    /// additional` elements. If it doesn't already have enough capacity, will\n    /// reallocate enough space plus comfortable slack space to get amortized\n    /// *O*(1) behavior. Will limit this behavior if it would needlessly cause\n    /// itself to panic.\n    ///\n    /// If `len` exceeds `self.capacity()`, this may fail to actually allocate\n    /// the requested space. This is not really unsafe, but the unsafe\n    /// code *you* write that relies on the behavior of this function may break.\n    ///\n    /// This is ideal for implementing a bulk-push operation like `extend`.\n    ///\n    /// # Panics\n    ///\n    /// Panics if the new capacity exceeds `isize::MAX` bytes.\n    ///\n    /// # Aborts\n    ///\n    /// Aborts on OOM.\n    ///\n    /// # Examples\n    ///\n    /// ```\n    /// # #![feature(raw_vec_internals)]\n    /// # extern crate alloc;\n    /// # use std::ptr;\n    /// # use alloc::raw_vec::RawVec;\n    /// struct MyVec<T> {\n    ///     buf: RawVec<T>,\n    ///     len: usize,\n    /// }\n    ///\n    /// impl<T: Clone> MyVec<T> {\n    ///     pub fn push_all(&mut self, elems: &[T]) {\n    ///         self.buf.reserve(self.len, elems.len());\n    ///         // reserve would have aborted or panicked if the len exceeded\n    ///         // `isize::MAX` so this is safe to do unchecked now.\n    ///         for x in elems {\n    ///             unsafe {\n    ///                 ptr::write(self.buf.ptr().add(self.len), x.clone());\n    ///             }\n    ///             self.len += 1;\n    ///         }\n    ///     }\n    /// }\n    /// # fn main() {\n    /// #   let mut vector = MyVec { buf: RawVec::new(), len: 0 };\n    /// #   vector.push_all(&[1, 3, 5, 7, 9]);\n    /// # }\n    /// ```\n    #[cfg(not(no_global_oom_handling))]\n    #[inline]\n    pub fn reserve(&mut self, len: usize, additional: usize) {\n        // Callers expect this function to be very cheap when there is already sufficient capacity.\n        // Therefore, we move all the resizing and error-handling logic from grow_amortized and\n        // handle_reserve behind a call, while making sure that the this function is likely to be\n        // inlined as just a comparison and a call if the comparison fails.\n        #[cold]\n        fn do_reserve_and_handle<T, A: Allocator>(\n            slf: &mut RawVec<T, A>,\n            len: usize,\n            additional: usize,\n        ) {\n            handle_reserve(slf.grow_amortized(len, additional));\n        }\n\n        if self.needs_to_grow(len, additional) {\n            do_reserve_and_handle(self, len, additional);\n        }\n    }\n\n    /// The same as `reserve`, but returns on errors instead of panicking or aborting.\n    pub fn try_reserve(&mut self, len: usize, additional: usize) -> Result<(), TryReserveError> {\n        if self.needs_to_grow(len, additional) {\n            self.grow_amortized(len, additional)\n        } else {\n            Ok(())\n        }\n    }\n\n    /// Ensures that the buffer contains at least enough space to hold `len +\n    /// additional` elements. If it doesn't already, will reallocate the\n    /// minimum possible amount of memory necessary. Generally this will be\n    /// exactly the amount of memory necessary, but in principle the allocator\n    /// is free to give back more than we asked for.\n    ///\n    /// If `len` exceeds `self.capacity()`, this may fail to actually allocate\n    /// the requested space. This is not really unsafe, but the unsafe code\n    /// *you* write that relies on the behavior of this function may break.\n    ///\n    /// # Panics\n    ///\n    /// Panics if the new capacity exceeds `isize::MAX` bytes.\n    ///\n    /// # Aborts\n    ///\n    /// Aborts on OOM.\n    #[cfg(not(no_global_oom_handling))]\n    pub fn reserve_exact(&mut self, len: usize, additional: usize) {\n        handle_reserve(self.try_reserve_exact(len, additional));\n    }\n\n    /// The same as `reserve_exact`, but returns on errors instead of panicking or aborting.\n    pub fn try_reserve_exact(\n        &mut self,\n        len: usize,\n        additional: usize,\n    ) -> Result<(), TryReserveError> {\n        if self.needs_to_grow(len, additional) { self.grow_exact(len, additional) } else { Ok(()) }\n    }\n\n    /// Shrinks the allocation down to the specified amount. If the given amount\n    /// is 0, actually completely deallocates.\n    ///\n    /// # Panics\n    ///\n    /// Panics if the given amount is *larger* than the current capacity.\n    ///\n    /// # Aborts\n    ///\n    /// Aborts on OOM.\n    #[cfg(not(no_global_oom_handling))]\n    pub fn shrink_to_fit(&mut self, amount: usize) {\n        handle_reserve(self.shrink(amount));\n    }\n}\n\nimpl<T, A: Allocator> RawVec<T, A> {\n    /// Returns if the buffer needs to grow to fulfill the needed extra capacity.\n    /// Mainly used to make inlining reserve-calls possible without inlining `grow`.\n    fn needs_to_grow(&self, len: usize, additional: usize) -> bool {\n        additional > self.capacity().wrapping_sub(len)\n    }\n\n    fn capacity_from_bytes(excess: usize) -> usize {\n        debug_assert_ne!(mem::size_of::<T>(), 0);\n        excess / mem::size_of::<T>()\n    }\n\n    fn set_ptr(&mut self, ptr: NonNull<[u8]>) {\n        self.ptr = unsafe { Unique::new_unchecked(ptr.cast().as_ptr()) };\n        self.cap = Self::capacity_from_bytes(ptr.len());\n    }\n\n    // This method is usually instantiated many times. So we want it to be as\n    // small as possible, to improve compile times. But we also want as much of\n    // its contents to be statically computable as possible, to make the\n    // generated code run faster. Therefore, this method is carefully written\n    // so that all of the code that depends on `T` is within it, while as much\n    // of the code that doesn't depend on `T` as possible is in functions that\n    // are non-generic over `T`.\n    fn grow_amortized(&mut self, len: usize, additional: usize) -> Result<(), TryReserveError> {\n        // This is ensured by the calling contexts.\n        debug_assert!(additional > 0);\n\n        if mem::size_of::<T>() == 0 {\n            // Since we return a capacity of `usize::MAX` when `elem_size` is\n            // 0, getting to here necessarily means the `RawVec` is overfull.\n            return Err(CapacityOverflow);\n        }\n\n        // Nothing we can really do about these checks, sadly.\n        let required_cap = len.checked_add(additional).ok_or(CapacityOverflow)?;\n\n        // This guarantees exponential growth. The doubling cannot overflow\n        // because `cap <= isize::MAX` and the type of `cap` is `usize`.\n        let cap = cmp::max(self.cap * 2, required_cap);\n        let cap = cmp::max(Self::MIN_NON_ZERO_CAP, cap);\n\n        let new_layout = Layout::array::<T>(cap);\n\n        // `finish_grow` is non-generic over `T`.\n        let ptr = finish_grow(new_layout, self.current_memory(), &mut self.alloc)?;\n        self.set_ptr(ptr);\n        Ok(())\n    }\n\n    // The constraints on this method are much the same as those on\n    // `grow_amortized`, but this method is usually instantiated less often so\n    // it's less critical.\n    fn grow_exact(&mut self, len: usize, additional: usize) -> Result<(), TryReserveError> {\n        if mem::size_of::<T>() == 0 {\n            // Since we return a capacity of `usize::MAX` when the type size is\n            // 0, getting to here necessarily means the `RawVec` is overfull.\n            return Err(CapacityOverflow);\n        }\n\n        let cap = len.checked_add(additional).ok_or(CapacityOverflow)?;\n        let new_layout = Layout::array::<T>(cap);\n\n        // `finish_grow` is non-generic over `T`.\n        let ptr = finish_grow(new_layout, self.current_memory(), &mut self.alloc)?;\n        self.set_ptr(ptr);\n        Ok(())\n    }\n\n    #[cfg(not(no_global_oom_handling))]\n    fn shrink(&mut self, amount: usize) -> Result<(), TryReserveError> {\n        assert!(amount <= self.capacity(), \"Tried to shrink to a larger capacity\");\n\n        let (ptr, layout) = if let Some(mem) = self.current_memory() { mem } else { return Ok(()) };\n        let new_size = amount * mem::size_of::<T>();\n\n        let ptr = unsafe {\n            let new_layout = Layout::from_size_align_unchecked(new_size, layout.align());\n            self.alloc.shrink(ptr, layout, new_layout).map_err(|_| TryReserveError::AllocError {\n                layout: new_layout,\n                non_exhaustive: (),\n            })?\n        };\n        self.set_ptr(ptr);\n        Ok(())\n    }\n}\n\n// This function is outside `RawVec` to minimize compile times. See the comment\n// above `RawVec::grow_amortized` for details. (The `A` parameter isn't\n// significant, because the number of different `A` types seen in practice is\n// much smaller than the number of `T` types.)\n#[inline(never)]\nfn finish_grow<A>(\n    new_layout: Result<Layout, LayoutError>,\n    current_memory: Option<(NonNull<u8>, Layout)>,\n    alloc: &mut A,\n) -> Result<NonNull<[u8]>, TryReserveError>\nwhere\n    A: Allocator,\n{\n    // Check for the error here to minimize the size of `RawVec::grow_*`.\n    let new_layout = new_layout.map_err(|_| CapacityOverflow)?;\n\n    alloc_guard(new_layout.size())?;\n\n    let memory = if let Some((ptr, old_layout)) = current_memory {\n        debug_assert_eq!(old_layout.align(), new_layout.align());\n        unsafe {\n            // The allocator checks for alignment equality\n            intrinsics::assume(old_layout.align() == new_layout.align());\n            alloc.grow(ptr, old_layout, new_layout)\n        }\n    } else {\n        alloc.allocate(new_layout)\n    };\n\n    memory.map_err(|_| AllocError { layout: new_layout, non_exhaustive: () })\n}\n\nunsafe impl<#[may_dangle] T, A: Allocator> Drop for RawVec<T, A> {\n    /// Frees the memory owned by the `RawVec` *without* trying to drop its contents.\n    fn drop(&mut self) {\n        if let Some((ptr, layout)) = self.current_memory() {\n            unsafe { self.alloc.deallocate(ptr, layout) }\n        }\n    }\n}\n\n// Central function for reserve error handling.\n#[cfg(not(no_global_oom_handling))]\n#[inline]\nfn handle_reserve(result: Result<(), TryReserveError>) {\n    match result {\n        Err(CapacityOverflow) => capacity_overflow(),\n        Err(AllocError { layout, .. }) => handle_alloc_error(layout),\n        Ok(()) => { /* yay */ }\n    }\n}\n\n// We need to guarantee the following:\n// * We don't ever allocate `> isize::MAX` byte-size objects.\n// * We don't overflow `usize::MAX` and actually allocate too little.\n//\n// On 64-bit we just need to check for overflow since trying to allocate\n// `> isize::MAX` bytes will surely fail. On 32-bit and 16-bit we need to add\n// an extra guard for this in case we're running on a platform which can use\n// all 4GB in user-space, e.g., PAE or x32.\n\n#[inline]\nfn alloc_guard(alloc_size: usize) -> Result<(), TryReserveError> {\n    if usize::BITS < 64 && alloc_size > isize::MAX as usize {\n        Err(CapacityOverflow)\n    } else {\n        Ok(())\n    }\n}\n\n// One central function responsible for reporting capacity overflows. This'll\n// ensure that the code generation related to these panics is minimal as there's\n// only one location which panics rather than a bunch throughout the module.\n#[cfg(not(no_global_oom_handling))]\nfn capacity_overflow() -> ! {\n    panic!(\"capacity overflow\");\n}\n"],[2072,"use std::{collections::VecDeque, time::Instant};\n\nconst VECDEQUE_LEN: i32 = 100000;\nconst WARMUP_N: usize = 100;\nconst BENCH_N: usize = 1000;\n\nfn main() {\n    let a: VecDeque<i32> = (0..VECDEQUE_LEN).collect();\n    let b: VecDeque<i32> = (0..VECDEQUE_LEN).collect();\n\n    for _ in 0..WARMUP_N {\n        let mut c = a.clone();\n        let mut d = b.clone();\n        c.append(&mut d);\n    }\n\n    let mut durations = Vec::with_capacity(BENCH_N);\n\n    for _ in 0..BENCH_N {\n        let mut c = a.clone();\n        let mut d = b.clone();\n        let before = Instant::now();\n        c.append(&mut d);\n        let after = Instant::now();\n        durations.push(after.duration_since(before));\n    }\n\n    let l = durations.len();\n    durations.sort();\n\n    assert!(BENCH_N % 2 == 0);\n    let median = (durations[(l / 2) - 1] + durations[l / 2]) / 2;\n    println!(\"\\ncustom-bench vec_deque_append {:?} ns/iter\\n\", median.as_nanos());\n}\n"],[2073,"use std::collections::LinkedList;\nuse test::Bencher;\n\n#[bench]\nfn bench_collect_into(b: &mut Bencher) {\n    let v = &[0; 64];\n    b.iter(|| {\n        let _: LinkedList<_> = v.iter().cloned().collect();\n    })\n}\n\n#[bench]\nfn bench_push_front(b: &mut Bencher) {\n    let mut m: LinkedList<_> = LinkedList::new();\n    b.iter(|| {\n        m.push_front(0);\n    })\n}\n\n#[bench]\nfn bench_push_back(b: &mut Bencher) {\n    let mut m: LinkedList<_> = LinkedList::new();\n    b.iter(|| {\n        m.push_back(0);\n    })\n}\n\n#[bench]\nfn bench_push_back_pop_back(b: &mut Bencher) {\n    let mut m: LinkedList<_> = LinkedList::new();\n    b.iter(|| {\n        m.push_back(0);\n        m.pop_back();\n    })\n}\n\n#[bench]\nfn bench_push_front_pop_front(b: &mut Bencher) {\n    let mut m: LinkedList<_> = LinkedList::new();\n    b.iter(|| {\n        m.push_front(0);\n        m.pop_front();\n    })\n}\n\n#[bench]\nfn bench_iter(b: &mut Bencher) {\n    let v = &[0; 128];\n    let m: LinkedList<_> = v.iter().cloned().collect();\n    b.iter(|| {\n        assert!(m.iter().count() == 128);\n    })\n}\n#[bench]\nfn bench_iter_mut(b: &mut Bencher) {\n    let v = &[0; 128];\n    let mut m: LinkedList<_> = v.iter().cloned().collect();\n    b.iter(|| {\n        assert!(m.iter_mut().count() == 128);\n    })\n}\n#[bench]\nfn bench_iter_rev(b: &mut Bencher) {\n    let v = &[0; 128];\n    let m: LinkedList<_> = v.iter().cloned().collect();\n    b.iter(|| {\n        assert!(m.iter().rev().count() == 128);\n    })\n}\n#[bench]\nfn bench_iter_mut_rev(b: &mut Bencher) {\n    let v = &[0; 128];\n    let mut m: LinkedList<_> = v.iter().cloned().collect();\n    b.iter(|| {\n        assert!(m.iter_mut().rev().count() == 128);\n    })\n}\n"],[2074,"use std::{mem, ptr};\n\nuse rand::distributions::{Alphanumeric, Standard};\nuse rand::{thread_rng, Rng, SeedableRng};\nuse rand_xorshift::XorShiftRng;\nuse test::{black_box, Bencher};\n\n#[bench]\nfn iterator(b: &mut Bencher) {\n    // peculiar numbers to stop LLVM from optimising the summation\n    // out.\n    let v: Vec<_> = (0..100).map(|i| i ^ (i << 1) ^ (i >> 1)).collect();\n\n    b.iter(|| {\n        let mut sum = 0;\n        for x in &v {\n            sum += *x;\n        }\n        // sum == 11806, to stop dead code elimination.\n        if sum == 0 {\n            panic!()\n        }\n    })\n}\n\n#[bench]\nfn mut_iterator(b: &mut Bencher) {\n    let mut v = vec![0; 100];\n\n    b.iter(|| {\n        let mut i = 0;\n        for x in &mut v {\n            *x = i;\n            i += 1;\n        }\n    })\n}\n\n#[bench]\nfn concat(b: &mut Bencher) {\n    let xss: Vec<Vec<i32>> = (0..100).map(|i| (0..i).collect()).collect();\n    b.iter(|| {\n        xss.concat();\n    });\n}\n\n#[bench]\nfn join(b: &mut Bencher) {\n    let xss: Vec<Vec<i32>> = (0..100).map(|i| (0..i).collect()).collect();\n    b.iter(|| xss.join(&0));\n}\n\n#[bench]\nfn push(b: &mut Bencher) {\n    let mut vec = Vec::<i32>::new();\n    b.iter(|| {\n        vec.push(0);\n        black_box(&vec);\n    });\n}\n\n#[bench]\nfn starts_with_same_vector(b: &mut Bencher) {\n    let vec: Vec<_> = (0..100).collect();\n    b.iter(|| vec.starts_with(&vec))\n}\n\n#[bench]\nfn starts_with_single_element(b: &mut Bencher) {\n    let vec: Vec<_> = vec![0];\n    b.iter(|| vec.starts_with(&vec))\n}\n\n#[bench]\nfn starts_with_diff_one_element_at_end(b: &mut Bencher) {\n    let vec: Vec<_> = (0..100).collect();\n    let mut match_vec: Vec<_> = (0..99).collect();\n    match_vec.push(0);\n    b.iter(|| vec.starts_with(&match_vec))\n}\n\n#[bench]\nfn ends_with_same_vector(b: &mut Bencher) {\n    let vec: Vec<_> = (0..100).collect();\n    b.iter(|| vec.ends_with(&vec))\n}\n\n#[bench]\nfn ends_with_single_element(b: &mut Bencher) {\n    let vec: Vec<_> = vec![0];\n    b.iter(|| vec.ends_with(&vec))\n}\n\n#[bench]\nfn ends_with_diff_one_element_at_beginning(b: &mut Bencher) {\n    let vec: Vec<_> = (0..100).collect();\n    let mut match_vec: Vec<_> = (0..100).collect();\n    match_vec[0] = 200;\n    b.iter(|| vec.starts_with(&match_vec))\n}\n\n#[bench]\nfn contains_last_element(b: &mut Bencher) {\n    let vec: Vec<_> = (0..100).collect();\n    b.iter(|| vec.contains(&99))\n}\n\n#[bench]\nfn zero_1kb_from_elem(b: &mut Bencher) {\n    b.iter(|| vec![0u8; 1024]);\n}\n\n#[bench]\nfn zero_1kb_set_memory(b: &mut Bencher) {\n    b.iter(|| {\n        let mut v = Vec::<u8>::with_capacity(1024);\n        unsafe {\n            let vp = v.as_mut_ptr();\n            ptr::write_bytes(vp, 0, 1024);\n            v.set_len(1024);\n        }\n        v\n    });\n}\n\n#[bench]\nfn zero_1kb_loop_set(b: &mut Bencher) {\n    b.iter(|| {\n        let mut v = Vec::<u8>::with_capacity(1024);\n        unsafe {\n            v.set_len(1024);\n        }\n        for i in 0..1024 {\n            v[i] = 0;\n        }\n    });\n}\n\n#[bench]\nfn zero_1kb_mut_iter(b: &mut Bencher) {\n    b.iter(|| {\n        let mut v = Vec::<u8>::with_capacity(1024);\n        unsafe {\n            v.set_len(1024);\n        }\n        for x in &mut v {\n            *x = 0;\n        }\n        v\n    });\n}\n\n#[bench]\nfn random_inserts(b: &mut Bencher) {\n    let mut rng = thread_rng();\n    b.iter(|| {\n        let mut v = vec![(0, 0); 30];\n        for _ in 0..100 {\n            let l = v.len();\n            v.insert(rng.gen::<usize>() % (l + 1), (1, 1));\n        }\n    })\n}\n\n#[bench]\nfn random_removes(b: &mut Bencher) {\n    let mut rng = thread_rng();\n    b.iter(|| {\n        let mut v = vec![(0, 0); 130];\n        for _ in 0..100 {\n            let l = v.len();\n            v.remove(rng.gen::<usize>() % l);\n        }\n    })\n}\n\nfn gen_ascending(len: usize) -> Vec<u64> {\n    (0..len as u64).collect()\n}\n\nfn gen_descending(len: usize) -> Vec<u64> {\n    (0..len as u64).rev().collect()\n}\n\nconst SEED: [u8; 16] = [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15];\n\nfn gen_random(len: usize) -> Vec<u64> {\n    let mut rng = XorShiftRng::from_seed(SEED);\n    (&mut rng).sample_iter(&Standard).take(len).collect()\n}\n\nfn gen_random_bytes(len: usize) -> Vec<u8> {\n    let mut rng = XorShiftRng::from_seed(SEED);\n    (&mut rng).sample_iter(&Standard).take(len).collect()\n}\n\nfn gen_mostly_ascending(len: usize) -> Vec<u64> {\n    let mut rng = XorShiftRng::from_seed(SEED);\n    let mut v = gen_ascending(len);\n    for _ in (0usize..).take_while(|x| x * x <= len) {\n        let x = rng.gen::<usize>() % len;\n        let y = rng.gen::<usize>() % len;\n        v.swap(x, y);\n    }\n    v\n}\n\nfn gen_mostly_descending(len: usize) -> Vec<u64> {\n    let mut rng = XorShiftRng::from_seed(SEED);\n    let mut v = gen_descending(len);\n    for _ in (0usize..).take_while(|x| x * x <= len) {\n        let x = rng.gen::<usize>() % len;\n        let y = rng.gen::<usize>() % len;\n        v.swap(x, y);\n    }\n    v\n}\n\nfn gen_strings(len: usize) -> Vec<String> {\n    let mut rng = XorShiftRng::from_seed(SEED);\n    let mut v = vec![];\n    for _ in 0..len {\n        let n = rng.gen::<usize>() % 20 + 1;\n        v.push((&mut rng).sample_iter(&Alphanumeric).take(n).collect());\n    }\n    v\n}\n\nfn gen_big_random(len: usize) -> Vec<[u64; 16]> {\n    let mut rng = XorShiftRng::from_seed(SEED);\n    (&mut rng).sample_iter(&Standard).map(|x| [x; 16]).take(len).collect()\n}\n\nmacro_rules! sort {\n    ($f:ident, $name:ident, $gen:expr, $len:expr) => {\n        #[bench]\n        fn $name(b: &mut Bencher) {\n            let v = $gen($len);\n            b.iter(|| v.clone().$f());\n            b.bytes = $len * mem::size_of_val(&$gen(1)[0]) as u64;\n        }\n    };\n}\n\nmacro_rules! sort_strings {\n    ($f:ident, $name:ident, $gen:expr, $len:expr) => {\n        #[bench]\n        fn $name(b: &mut Bencher) {\n            let v = $gen($len);\n            let v = v.iter().map(|s| &**s).collect::<Vec<&str>>();\n            b.iter(|| v.clone().$f());\n            b.bytes = $len * mem::size_of::<&str>() as u64;\n        }\n    };\n}\n\nmacro_rules! sort_expensive {\n    ($f:ident, $name:ident, $gen:expr, $len:expr) => {\n        #[bench]\n        fn $name(b: &mut Bencher) {\n            let v = $gen($len);\n            b.iter(|| {\n                let mut v = v.clone();\n                let mut count = 0;\n                v.$f(|a: &u64, b: &u64| {\n                    count += 1;\n                    if count % 1_000_000_000 == 0 {\n                        panic!(\"should not happen\");\n                    }\n                    (*a as f64).cos().partial_cmp(&(*b as f64).cos()).unwrap()\n                });\n                black_box(count);\n            });\n            b.bytes = $len * mem::size_of_val(&$gen(1)[0]) as u64;\n        }\n    };\n}\n\nmacro_rules! sort_lexicographic {\n    ($f:ident, $name:ident, $gen:expr, $len:expr) => {\n        #[bench]\n        fn $name(b: &mut Bencher) {\n            let v = $gen($len);\n            b.iter(|| v.clone().$f(|x| x.to_string()));\n            b.bytes = $len * mem::size_of_val(&$gen(1)[0]) as u64;\n        }\n    };\n}\n\nsort!(sort, sort_small_ascending, gen_ascending, 10);\nsort!(sort, sort_small_descending, gen_descending, 10);\nsort!(sort, sort_small_random, gen_random, 10);\nsort!(sort, sort_small_big, gen_big_random, 10);\nsort!(sort, sort_medium_random, gen_random, 100);\nsort!(sort, sort_large_ascending, gen_ascending, 10000);\nsort!(sort, sort_large_descending, gen_descending, 10000);\nsort!(sort, sort_large_mostly_ascending, gen_mostly_ascending, 10000);\nsort!(sort, sort_large_mostly_descending, gen_mostly_descending, 10000);\nsort!(sort, sort_large_random, gen_random, 10000);\nsort!(sort, sort_large_big, gen_big_random, 10000);\nsort_strings!(sort, sort_large_strings, gen_strings, 10000);\nsort_expensive!(sort_by, sort_large_expensive, gen_random, 10000);\n\nsort!(sort_unstable, sort_unstable_small_ascending, gen_ascending, 10);\nsort!(sort_unstable, sort_unstable_small_descending, gen_descending, 10);\nsort!(sort_unstable, sort_unstable_small_random, gen_random, 10);\nsort!(sort_unstable, sort_unstable_small_big, gen_big_random, 10);\nsort!(sort_unstable, sort_unstable_medium_random, gen_random, 100);\nsort!(sort_unstable, sort_unstable_large_ascending, gen_ascending, 10000);\nsort!(sort_unstable, sort_unstable_large_descending, gen_descending, 10000);\nsort!(sort_unstable, sort_unstable_large_mostly_ascending, gen_mostly_ascending, 10000);\nsort!(sort_unstable, sort_unstable_large_mostly_descending, gen_mostly_descending, 10000);\nsort!(sort_unstable, sort_unstable_large_random, gen_random, 10000);\nsort!(sort_unstable, sort_unstable_large_big, gen_big_random, 10000);\nsort_strings!(sort_unstable, sort_unstable_large_strings, gen_strings, 10000);\nsort_expensive!(sort_unstable_by, sort_unstable_large_expensive, gen_random, 10000);\n\nsort_lexicographic!(sort_by_key, sort_by_key_lexicographic, gen_random, 10000);\nsort_lexicographic!(sort_unstable_by_key, sort_unstable_by_key_lexicographic, gen_random, 10000);\nsort_lexicographic!(sort_by_cached_key, sort_by_cached_key_lexicographic, gen_random, 10000);\n\nmacro_rules! reverse {\n    ($name:ident, $ty:ty, $f:expr) => {\n        #[bench]\n        fn $name(b: &mut Bencher) {\n            // odd length and offset by 1 to be as unaligned as possible\n            let n = 0xFFFFF;\n            let mut v: Vec<_> = (0..1 + (n / mem::size_of::<$ty>() as u64)).map($f).collect();\n            b.iter(|| black_box(&mut v[1..]).reverse());\n            b.bytes = n;\n        }\n    };\n}\n\nreverse!(reverse_u8, u8, |x| x as u8);\nreverse!(reverse_u16, u16, |x| x as u16);\nreverse!(reverse_u8x3, [u8; 3], |x| [x as u8, (x >> 8) as u8, (x >> 16) as u8]);\nreverse!(reverse_u32, u32, |x| x as u32);\nreverse!(reverse_u64, u64, |x| x as u64);\nreverse!(reverse_u128, u128, |x| x as u128);\n#[repr(simd)]\nstruct F64x4(f64, f64, f64, f64);\nreverse!(reverse_simd_f64x4, F64x4, |x| {\n    let x = x as f64;\n    F64x4(x, x, x, x)\n});\n\nmacro_rules! rotate {\n    ($name:ident, $gen:expr, $len:expr, $mid:expr) => {\n        #[bench]\n        fn $name(b: &mut Bencher) {\n            let size = mem::size_of_val(&$gen(1)[0]);\n            let mut v = $gen($len * 8 / size);\n            b.iter(|| black_box(&mut v).rotate_left(($mid * 8 + size - 1) / size));\n            b.bytes = (v.len() * size) as u64;\n        }\n    };\n}\n\nrotate!(rotate_tiny_by1, gen_random, 16, 1);\nrotate!(rotate_tiny_half, gen_random, 16, 16 / 2);\nrotate!(rotate_tiny_half_plus_one, gen_random, 16, 16 / 2 + 1);\n\nrotate!(rotate_medium_by1, gen_random, 9158, 1);\nrotate!(rotate_medium_by727_u64, gen_random, 9158, 727);\nrotate!(rotate_medium_by727_bytes, gen_random_bytes, 9158, 727);\nrotate!(rotate_medium_by727_strings, gen_strings, 9158, 727);\nrotate!(rotate_medium_half, gen_random, 9158, 9158 / 2);\nrotate!(rotate_medium_half_plus_one, gen_random, 9158, 9158 / 2 + 1);\n\n// Intended to use more RAM than the machine has cache\nrotate!(rotate_huge_by1, gen_random, 5 * 1024 * 1024, 1);\nrotate!(rotate_huge_by9199_u64, gen_random, 5 * 1024 * 1024, 9199);\nrotate!(rotate_huge_by9199_bytes, gen_random_bytes, 5 * 1024 * 1024, 9199);\nrotate!(rotate_huge_by9199_strings, gen_strings, 5 * 1024 * 1024, 9199);\nrotate!(rotate_huge_by9199_big, gen_big_random, 5 * 1024 * 1024, 9199);\nrotate!(rotate_huge_by1234577_u64, gen_random, 5 * 1024 * 1024, 1234577);\nrotate!(rotate_huge_by1234577_bytes, gen_random_bytes, 5 * 1024 * 1024, 1234577);\nrotate!(rotate_huge_by1234577_strings, gen_strings, 5 * 1024 * 1024, 1234577);\nrotate!(rotate_huge_by1234577_big, gen_big_random, 5 * 1024 * 1024, 1234577);\nrotate!(rotate_huge_half, gen_random, 5 * 1024 * 1024, 5 * 1024 * 1024 / 2);\nrotate!(rotate_huge_half_plus_one, gen_random, 5 * 1024 * 1024, 5 * 1024 * 1024 / 2 + 1);\n"],[2075,"use std::collections::VecDeque;\nuse test::{black_box, Bencher};\n\n#[bench]\nfn bench_new(b: &mut Bencher) {\n    b.iter(|| {\n        let ring: VecDeque<i32> = VecDeque::new();\n        black_box(ring);\n    })\n}\n\n#[bench]\nfn bench_grow_1025(b: &mut Bencher) {\n    b.iter(|| {\n        let mut deq = VecDeque::new();\n        for i in 0..1025 {\n            deq.push_front(i);\n        }\n        black_box(deq);\n    })\n}\n\n#[bench]\nfn bench_iter_1000(b: &mut Bencher) {\n    let ring: VecDeque<_> = (0..1000).collect();\n\n    b.iter(|| {\n        let mut sum = 0;\n        for &i in &ring {\n            sum += i;\n        }\n        black_box(sum);\n    })\n}\n\n#[bench]\nfn bench_mut_iter_1000(b: &mut Bencher) {\n    let mut ring: VecDeque<_> = (0..1000).collect();\n\n    b.iter(|| {\n        let mut sum = 0;\n        for i in &mut ring {\n            sum += *i;\n        }\n        black_box(sum);\n    })\n}\n\n#[bench]\nfn bench_try_fold(b: &mut Bencher) {\n    let ring: VecDeque<_> = (0..1000).collect();\n\n    b.iter(|| black_box(ring.iter().try_fold(0, |a, b| Some(a + b))))\n}\n"],[2076,"use std::iter::repeat;\nuse test::{black_box, Bencher};\n\n#[bench]\nfn bench_with_capacity(b: &mut Bencher) {\n    b.iter(|| String::with_capacity(100));\n}\n\n#[bench]\nfn bench_push_str(b: &mut Bencher) {\n    let s = \"ศไทย中华Việt Nam; Mary had a little lamb, Little lamb\";\n    b.iter(|| {\n        let mut r = String::new();\n        r.push_str(s);\n    });\n}\n\nconst REPETITIONS: u64 = 10_000;\n\n#[bench]\nfn bench_push_str_one_byte(b: &mut Bencher) {\n    b.bytes = REPETITIONS;\n    b.iter(|| {\n        let mut r = String::new();\n        for _ in 0..REPETITIONS {\n            r.push_str(\"a\")\n        }\n    });\n}\n\n#[bench]\nfn bench_push_char_one_byte(b: &mut Bencher) {\n    b.bytes = REPETITIONS;\n    b.iter(|| {\n        let mut r = String::new();\n        for _ in 0..REPETITIONS {\n            r.push('a')\n        }\n    });\n}\n\n#[bench]\nfn bench_push_char_two_bytes(b: &mut Bencher) {\n    b.bytes = REPETITIONS * 2;\n    b.iter(|| {\n        let mut r = String::new();\n        for _ in 0..REPETITIONS {\n            r.push('â')\n        }\n    });\n}\n\n#[bench]\nfn from_utf8_lossy_100_ascii(b: &mut Bencher) {\n    let s = b\"Hello there, the quick brown fox jumped over the lazy dog! \\\n              Lorem ipsum dolor sit amet, consectetur. \";\n\n    assert_eq!(100, s.len());\n    b.iter(|| {\n        let _ = String::from_utf8_lossy(s);\n    });\n}\n\n#[bench]\nfn from_utf8_lossy_100_multibyte(b: &mut Bencher) {\n    let s = \"𐌀𐌖𐌋𐌄𐌑𐌉ปรدولة الكويتทศไทย中华𐍅𐌿𐌻𐍆𐌹𐌻𐌰\".as_bytes();\n    assert_eq!(100, s.len());\n    b.iter(|| {\n        let _ = String::from_utf8_lossy(s);\n    });\n}\n\n#[bench]\nfn from_utf8_lossy_invalid(b: &mut Bencher) {\n    let s = b\"Hello\\xC0\\x80 There\\xE6\\x83 Goodbye\";\n    b.iter(|| {\n        let _ = String::from_utf8_lossy(s);\n    });\n}\n\n#[bench]\nfn from_utf8_lossy_100_invalid(b: &mut Bencher) {\n    let s = repeat(0xf5).take(100).collect::<Vec<_>>();\n    b.iter(|| {\n        let _ = String::from_utf8_lossy(&s);\n    });\n}\n\n#[bench]\nfn bench_exact_size_shrink_to_fit(b: &mut Bencher) {\n    let s = \"Hello there, the quick brown fox jumped over the lazy dog! \\\n             Lorem ipsum dolor sit amet, consectetur. \";\n    // ensure our operation produces an exact-size string before we benchmark it\n    let mut r = String::with_capacity(s.len());\n    r.push_str(s);\n    assert_eq!(r.len(), r.capacity());\n    b.iter(|| {\n        let mut r = String::with_capacity(s.len());\n        r.push_str(s);\n        r.shrink_to_fit();\n        r\n    });\n}\n\n#[bench]\nfn bench_from_str(b: &mut Bencher) {\n    let s = \"Hello there, the quick brown fox jumped over the lazy dog! \\\n             Lorem ipsum dolor sit amet, consectetur. \";\n    b.iter(|| String::from(s))\n}\n\n#[bench]\nfn bench_from(b: &mut Bencher) {\n    let s = \"Hello there, the quick brown fox jumped over the lazy dog! \\\n             Lorem ipsum dolor sit amet, consectetur. \";\n    b.iter(|| String::from(s))\n}\n\n#[bench]\nfn bench_to_string(b: &mut Bencher) {\n    let s = \"Hello there, the quick brown fox jumped over the lazy dog! \\\n             Lorem ipsum dolor sit amet, consectetur. \";\n    b.iter(|| s.to_string())\n}\n\n#[bench]\nfn bench_insert_char_short(b: &mut Bencher) {\n    let s = \"Hello, World!\";\n    b.iter(|| {\n        let mut x = String::from(s);\n        black_box(&mut x).insert(6, black_box(' '));\n        x\n    })\n}\n\n#[bench]\nfn bench_insert_char_long(b: &mut Bencher) {\n    let s = \"Hello, World!\";\n    b.iter(|| {\n        let mut x = String::from(s);\n        black_box(&mut x).insert(6, black_box('❤'));\n        x\n    })\n}\n\n#[bench]\nfn bench_insert_str_short(b: &mut Bencher) {\n    let s = \"Hello, World!\";\n    b.iter(|| {\n        let mut x = String::from(s);\n        black_box(&mut x).insert_str(6, black_box(\" \"));\n        x\n    })\n}\n\n#[bench]\nfn bench_insert_str_long(b: &mut Bencher) {\n    let s = \"Hello, World!\";\n    b.iter(|| {\n        let mut x = String::from(s);\n        black_box(&mut x).insert_str(6, black_box(\" rustic \"));\n        x\n    })\n}\n"],[2077,"use test::{black_box, Bencher};\n\n#[bench]\nfn char_iterator(b: &mut Bencher) {\n    let s = \"ศไทย中华Việt Nam; Mary had a little lamb, Little lamb\";\n\n    b.iter(|| s.chars().count());\n}\n\n#[bench]\nfn char_iterator_for(b: &mut Bencher) {\n    let s = \"ศไทย中华Việt Nam; Mary had a little lamb, Little lamb\";\n\n    b.iter(|| {\n        for ch in s.chars() {\n            black_box(ch);\n        }\n    });\n}\n\n#[bench]\nfn char_iterator_ascii(b: &mut Bencher) {\n    let s = \"Mary had a little lamb, Little lamb\n    Mary had a little lamb, Little lamb\n    Mary had a little lamb, Little lamb\n    Mary had a little lamb, Little lamb\n    Mary had a little lamb, Little lamb\n    Mary had a little lamb, Little lamb\";\n\n    b.iter(|| s.chars().count());\n}\n\n#[bench]\nfn char_iterator_rev(b: &mut Bencher) {\n    let s = \"ศไทย中华Việt Nam; Mary had a little lamb, Little lamb\";\n\n    b.iter(|| s.chars().rev().count());\n}\n\n#[bench]\nfn char_iterator_rev_for(b: &mut Bencher) {\n    let s = \"ศไทย中华Việt Nam; Mary had a little lamb, Little lamb\";\n\n    b.iter(|| {\n        for ch in s.chars().rev() {\n            black_box(ch);\n        }\n    });\n}\n\n#[bench]\nfn char_indicesator(b: &mut Bencher) {\n    let s = \"ศไทย中华Việt Nam; Mary had a little lamb, Little lamb\";\n    let len = s.chars().count();\n\n    b.iter(|| assert_eq!(s.char_indices().count(), len));\n}\n\n#[bench]\nfn char_indicesator_rev(b: &mut Bencher) {\n    let s = \"ศไทย中华Việt Nam; Mary had a little lamb, Little lamb\";\n    let len = s.chars().count();\n\n    b.iter(|| assert_eq!(s.char_indices().rev().count(), len));\n}\n\n#[bench]\nfn split_unicode_ascii(b: &mut Bencher) {\n    let s = \"ประเทศไทย中华Việt Namประเทศไทย中华Việt Nam\";\n\n    b.iter(|| assert_eq!(s.split('V').count(), 3));\n}\n\n#[bench]\nfn split_ascii(b: &mut Bencher) {\n    let s = \"Mary had a little lamb, Little lamb, little-lamb.\";\n    let len = s.split(' ').count();\n\n    b.iter(|| assert_eq!(s.split(' ').count(), len));\n}\n\n#[bench]\nfn split_extern_fn(b: &mut Bencher) {\n    let s = \"Mary had a little lamb, Little lamb, little-lamb.\";\n    let len = s.split(' ').count();\n    fn pred(c: char) -> bool {\n        c == ' '\n    }\n\n    b.iter(|| assert_eq!(s.split(pred).count(), len));\n}\n\n#[bench]\nfn split_closure(b: &mut Bencher) {\n    let s = \"Mary had a little lamb, Little lamb, little-lamb.\";\n    let len = s.split(' ').count();\n\n    b.iter(|| assert_eq!(s.split(|c: char| c == ' ').count(), len));\n}\n\n#[bench]\nfn split_slice(b: &mut Bencher) {\n    let s = \"Mary had a little lamb, Little lamb, little-lamb.\";\n    let len = s.split(' ').count();\n\n    let c: &[char] = &[' '];\n    b.iter(|| assert_eq!(s.split(c).count(), len));\n}\n\n#[bench]\nfn bench_join(b: &mut Bencher) {\n    let s = \"ศไทย中华Việt Nam; Mary had a little lamb, Little lamb\";\n    let sep = \"→\";\n    let v = vec![s, s, s, s, s, s, s, s, s, s];\n    b.iter(|| {\n        assert_eq!(v.join(sep).len(), s.len() * 10 + sep.len() * 9);\n    })\n}\n\n#[bench]\nfn bench_contains_short_short(b: &mut Bencher) {\n    let haystack = \"Lorem ipsum dolor sit amet, consectetur adipiscing elit.\";\n    let needle = \"sit\";\n\n    b.iter(|| {\n        assert!(haystack.contains(needle));\n    })\n}\n\n#[bench]\nfn bench_contains_short_long(b: &mut Bencher) {\n    let haystack = \"\\\nLorem ipsum dolor sit amet, consectetur adipiscing elit. Suspendisse quis lorem sit amet dolor \\\nultricies condimentum. Praesent iaculis purus elit, ac malesuada quam malesuada in. Duis sed orci \\\neros. Suspendisse sit amet magna mollis, mollis nunc luctus, imperdiet mi. Integer fringilla non \\\nsem ut lacinia. Fusce varius tortor a risus porttitor hendrerit. Morbi mauris dui, ultricies nec \\\ntempus vel, gravida nec quam.\n\nIn est dui, tincidunt sed tempus interdum, adipiscing laoreet ante. Etiam tempor, tellus quis \\\nsagittis interdum, nulla purus mattis sem, quis auctor erat odio ac tellus. In nec nunc sit amet \\\ndiam volutpat molestie at sed ipsum. Vestibulum laoreet consequat vulputate. Integer accumsan \\\nlorem ac dignissim placerat. Suspendisse convallis faucibus lorem. Aliquam erat volutpat. In vel \\\neleifend felis. Sed suscipit nulla lorem, sed mollis est sollicitudin et. Nam fermentum egestas \\\ninterdum. Curabitur ut nisi justo.\n\nSed sollicitudin ipsum tellus, ut condimentum leo eleifend nec. Cras ut velit ante. Phasellus nec \\\nmollis odio. Mauris molestie erat in arcu mattis, at aliquet dolor vehicula. Quisque malesuada \\\nlectus sit amet nisi pretium, a condimentum ipsum porta. Morbi at dapibus diam. Praesent egestas \\\nest sed risus elementum, eu rutrum metus ultrices. Etiam fermentum consectetur magna, id rutrum \\\nfelis accumsan a. Aliquam ut pellentesque libero. Sed mi nulla, lobortis eu tortor id, suscipit \\\nultricies neque. Morbi iaculis sit amet risus at iaculis. Praesent eget ligula quis turpis \\\nfeugiat suscipit vel non arcu. Interdum et malesuada fames ac ante ipsum primis in faucibus. \\\nAliquam sit amet placerat lorem.\n\nCras a lacus vel ante posuere elementum. Nunc est leo, bibendum ut facilisis vel, bibendum at \\\nmauris. Nullam adipiscing diam vel odio ornare, luctus adipiscing mi luctus. Nulla facilisi. \\\nMauris adipiscing bibendum neque, quis adipiscing lectus tempus et. Sed feugiat erat et nisl \\\nlobortis pharetra. Donec vitae erat enim. Nullam sit amet felis et quam lacinia tincidunt. Aliquam \\\nsuscipit dapibus urna. Sed volutpat urna in magna pulvinar volutpat. Phasellus nec tellus ac diam \\\ncursus accumsan.\n\nNam lectus enim, dapibus non nisi tempor, consectetur convallis massa. Maecenas eleifend dictum \\\nfeugiat. Etiam quis mauris vel risus luctus mattis a a nunc. Nullam orci quam, imperdiet id \\\nvehicula in, porttitor ut nibh. Duis sagittis adipiscing nisl vitae congue. Donec mollis risus eu \\\nleo suscipit, varius porttitor nulla porta. Pellentesque ut sem nec nisi euismod vehicula. Nulla \\\nmalesuada sollicitudin quam eu fermentum.\";\n    let needle = \"english\";\n\n    b.iter(|| {\n        assert!(!haystack.contains(needle));\n    })\n}\n\n#[bench]\nfn bench_contains_bad_naive(b: &mut Bencher) {\n    let haystack = \"aaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaa\";\n    let needle = \"aaaaaaaab\";\n\n    b.iter(|| {\n        assert!(!haystack.contains(needle));\n    })\n}\n\n#[bench]\nfn bench_contains_equal(b: &mut Bencher) {\n    let haystack = \"Lorem ipsum dolor sit amet, consectetur adipiscing elit.\";\n    let needle = \"Lorem ipsum dolor sit amet, consectetur adipiscing elit.\";\n\n    b.iter(|| {\n        assert!(haystack.contains(needle));\n    })\n}\n\nmacro_rules! make_test_inner {\n    ($s:ident, $code:expr, $name:ident, $str:expr, $iters:expr) => {\n        #[bench]\n        fn $name(bencher: &mut Bencher) {\n            let mut $s = $str;\n            black_box(&mut $s);\n            bencher.iter(|| {\n                for _ in 0..$iters {\n                    black_box($code);\n                }\n            });\n        }\n    };\n}\n\nmacro_rules! make_test {\n    ($name:ident, $s:ident, $code:expr) => {\n        make_test!($name, $s, $code, 1);\n    };\n    ($name:ident, $s:ident, $code:expr, $iters:expr) => {\n        mod $name {\n            use test::Bencher;\n            use test::black_box;\n\n            // Short strings: 65 bytes each\n            make_test_inner!($s, $code, short_ascii,\n                \"Mary had a little lamb, Little lamb Mary had a littl lamb, lamb!\", $iters);\n            make_test_inner!($s, $code, short_mixed,\n                \"ศไทย中华Việt Nam; Mary had a little lamb, Little lam!\", $iters);\n            make_test_inner!($s, $code, short_pile_of_poo,\n                \"💩💩💩💩💩💩💩💩💩💩💩💩💩💩💩💩!\", $iters);\n            make_test_inner!($s, $code, long_lorem_ipsum,\"\\\nLorem ipsum dolor sit amet, consectetur adipiscing elit. Suspendisse quis lorem sit amet dolor \\\nultricies condimentum. Praesent iaculis purus elit, ac malesuada quam malesuada in. Duis sed orci \\\neros. Suspendisse sit amet magna mollis, mollis nunc luctus, imperdiet mi. Integer fringilla non \\\nsem ut lacinia. Fusce varius tortor a risus porttitor hendrerit. Morbi mauris dui, ultricies nec \\\ntempus vel, gravida nec quam.\n\nIn est dui, tincidunt sed tempus interdum, adipiscing laoreet ante. Etiam tempor, tellus quis \\\nsagittis interdum, nulla purus mattis sem, quis auctor erat odio ac tellus. In nec nunc sit amet \\\ndiam volutpat molestie at sed ipsum. Vestibulum laoreet consequat vulputate. Integer accumsan \\\nlorem ac dignissim placerat. Suspendisse convallis faucibus lorem. Aliquam erat volutpat. In vel \\\neleifend felis. Sed suscipit nulla lorem, sed mollis est sollicitudin et. Nam fermentum egestas \\\ninterdum. Curabitur ut nisi justo.\n\nSed sollicitudin ipsum tellus, ut condimentum leo eleifend nec. Cras ut velit ante. Phasellus nec \\\nmollis odio. Mauris molestie erat in arcu mattis, at aliquet dolor vehicula. Quisque malesuada \\\nlectus sit amet nisi pretium, a condimentum ipsum porta. Morbi at dapibus diam. Praesent egestas \\\nest sed risus elementum, eu rutrum metus ultrices. Etiam fermentum consectetur magna, id rutrum \\\nfelis accumsan a. Aliquam ut pellentesque libero. Sed mi nulla, lobortis eu tortor id, suscipit \\\nultricies neque. Morbi iaculis sit amet risus at iaculis. Praesent eget ligula quis turpis \\\nfeugiat suscipit vel non arcu. Interdum et malesuada fames ac ante ipsum primis in faucibus. \\\nAliquam sit amet placerat lorem.\n\nCras a lacus vel ante posuere elementum. Nunc est leo, bibendum ut facilisis vel, bibendum at \\\nmauris. Nullam adipiscing diam vel odio ornare, luctus adipiscing mi luctus. Nulla facilisi. \\\nMauris adipiscing bibendum neque, quis adipiscing lectus tempus et. Sed feugiat erat et nisl \\\nlobortis pharetra. Donec vitae erat enim. Nullam sit amet felis et quam lacinia tincidunt. Aliquam \\\nsuscipit dapibus urna. Sed volutpat urna in magna pulvinar volutpat. Phasellus nec tellus ac diam \\\ncursus accumsan.\n\nNam lectus enim, dapibus non nisi tempor, consectetur convallis massa. Maecenas eleifend dictum \\\nfeugiat. Etiam quis mauris vel risus luctus mattis a a nunc. Nullam orci quam, imperdiet id \\\nvehicula in, porttitor ut nibh. Duis sagittis adipiscing nisl vitae congue. Donec mollis risus eu \\\nleo suscipit, varius porttitor nulla porta. Pellentesque ut sem nec nisi euismod vehicula. Nulla \\\nmalesuada sollicitudin quam eu fermentum!\", $iters);\n        }\n    }\n}\n\nmake_test!(chars_count, s, s.chars().count());\n\nmake_test!(contains_bang_str, s, s.contains(\"!\"));\nmake_test!(contains_bang_char, s, s.contains('!'));\n\nmake_test!(match_indices_a_str, s, s.match_indices(\"a\").count());\n\nmake_test!(split_a_str, s, s.split(\"a\").count());\n\nmake_test!(trim_ascii_char, s, { s.trim_matches(|c: char| c.is_ascii()) });\nmake_test!(trim_start_ascii_char, s, { s.trim_start_matches(|c: char| c.is_ascii()) });\nmake_test!(trim_end_ascii_char, s, { s.trim_end_matches(|c: char| c.is_ascii()) });\n\nmake_test!(find_underscore_char, s, s.find('_'));\nmake_test!(rfind_underscore_char, s, s.rfind('_'));\nmake_test!(find_underscore_str, s, s.find(\"_\"));\n\nmake_test!(find_zzz_char, s, s.find('\\u{1F4A4}'));\nmake_test!(rfind_zzz_char, s, s.rfind('\\u{1F4A4}'));\nmake_test!(find_zzz_str, s, s.find(\"\\u{1F4A4}\"));\n\nmake_test!(starts_with_ascii_char, s, s.starts_with('/'), 1024);\nmake_test!(ends_with_ascii_char, s, s.ends_with('/'), 1024);\nmake_test!(starts_with_unichar, s, s.starts_with('\\u{1F4A4}'), 1024);\nmake_test!(ends_with_unichar, s, s.ends_with('\\u{1F4A4}'), 1024);\nmake_test!(starts_with_str, s, s.starts_with(\"💩💩💩💩💩💩💩💩💩💩💩💩💩💩💩💩\"), 1024);\nmake_test!(ends_with_str, s, s.ends_with(\"💩💩💩💩💩💩💩💩💩💩💩💩💩💩💩💩\"), 1024);\n\nmake_test!(split_space_char, s, s.split(' ').count());\nmake_test!(split_terminator_space_char, s, s.split_terminator(' ').count());\n\nmake_test!(splitn_space_char, s, s.splitn(10, ' ').count());\nmake_test!(rsplitn_space_char, s, s.rsplitn(10, ' ').count());\n\nmake_test!(split_space_str, s, s.split(\" \").count());\nmake_test!(split_ad_str, s, s.split(\"ad\").count());\n"],[2078,"use rand::RngCore;\nuse std::iter::{repeat, FromIterator};\nuse test::{black_box, Bencher};\n\n#[bench]\nfn bench_new(b: &mut Bencher) {\n    b.iter(|| Vec::<u32>::new())\n}\n\nfn do_bench_with_capacity(b: &mut Bencher, src_len: usize) {\n    b.bytes = src_len as u64;\n\n    b.iter(|| Vec::<u32>::with_capacity(src_len))\n}\n\n#[bench]\nfn bench_with_capacity_0000(b: &mut Bencher) {\n    do_bench_with_capacity(b, 0)\n}\n\n#[bench]\nfn bench_with_capacity_0010(b: &mut Bencher) {\n    do_bench_with_capacity(b, 10)\n}\n\n#[bench]\nfn bench_with_capacity_0100(b: &mut Bencher) {\n    do_bench_with_capacity(b, 100)\n}\n\n#[bench]\nfn bench_with_capacity_1000(b: &mut Bencher) {\n    do_bench_with_capacity(b, 1000)\n}\n\nfn do_bench_from_fn(b: &mut Bencher, src_len: usize) {\n    b.bytes = src_len as u64;\n\n    b.iter(|| (0..src_len).collect::<Vec<_>>())\n}\n\n#[bench]\nfn bench_from_fn_0000(b: &mut Bencher) {\n    do_bench_from_fn(b, 0)\n}\n\n#[bench]\nfn bench_from_fn_0010(b: &mut Bencher) {\n    do_bench_from_fn(b, 10)\n}\n\n#[bench]\nfn bench_from_fn_0100(b: &mut Bencher) {\n    do_bench_from_fn(b, 100)\n}\n\n#[bench]\nfn bench_from_fn_1000(b: &mut Bencher) {\n    do_bench_from_fn(b, 1000)\n}\n\nfn do_bench_from_elem(b: &mut Bencher, src_len: usize) {\n    b.bytes = src_len as u64;\n\n    b.iter(|| repeat(5).take(src_len).collect::<Vec<usize>>())\n}\n\n#[bench]\nfn bench_from_elem_0000(b: &mut Bencher) {\n    do_bench_from_elem(b, 0)\n}\n\n#[bench]\nfn bench_from_elem_0010(b: &mut Bencher) {\n    do_bench_from_elem(b, 10)\n}\n\n#[bench]\nfn bench_from_elem_0100(b: &mut Bencher) {\n    do_bench_from_elem(b, 100)\n}\n\n#[bench]\nfn bench_from_elem_1000(b: &mut Bencher) {\n    do_bench_from_elem(b, 1000)\n}\n\nfn do_bench_from_slice(b: &mut Bencher, src_len: usize) {\n    let src: Vec<_> = FromIterator::from_iter(0..src_len);\n\n    b.bytes = src_len as u64;\n\n    b.iter(|| src.as_slice().to_vec());\n}\n\n#[bench]\nfn bench_from_slice_0000(b: &mut Bencher) {\n    do_bench_from_slice(b, 0)\n}\n\n#[bench]\nfn bench_from_slice_0010(b: &mut Bencher) {\n    do_bench_from_slice(b, 10)\n}\n\n#[bench]\nfn bench_from_slice_0100(b: &mut Bencher) {\n    do_bench_from_slice(b, 100)\n}\n\n#[bench]\nfn bench_from_slice_1000(b: &mut Bencher) {\n    do_bench_from_slice(b, 1000)\n}\n\nfn do_bench_from_iter(b: &mut Bencher, src_len: usize) {\n    let src: Vec<_> = FromIterator::from_iter(0..src_len);\n\n    b.bytes = src_len as u64;\n\n    b.iter(|| {\n        let dst: Vec<_> = FromIterator::from_iter(src.iter().cloned());\n        dst\n    });\n}\n\n#[bench]\nfn bench_from_iter_0000(b: &mut Bencher) {\n    do_bench_from_iter(b, 0)\n}\n\n#[bench]\nfn bench_from_iter_0010(b: &mut Bencher) {\n    do_bench_from_iter(b, 10)\n}\n\n#[bench]\nfn bench_from_iter_0100(b: &mut Bencher) {\n    do_bench_from_iter(b, 100)\n}\n\n#[bench]\nfn bench_from_iter_1000(b: &mut Bencher) {\n    do_bench_from_iter(b, 1000)\n}\n\nfn do_bench_extend(b: &mut Bencher, dst_len: usize, src_len: usize) {\n    let dst: Vec<_> = FromIterator::from_iter(0..dst_len);\n    let src: Vec<_> = FromIterator::from_iter(dst_len..dst_len + src_len);\n\n    b.bytes = src_len as u64;\n\n    b.iter(|| {\n        let mut dst = dst.clone();\n        dst.extend(src.clone());\n        dst\n    });\n}\n\n#[bench]\nfn bench_extend_0000_0000(b: &mut Bencher) {\n    do_bench_extend(b, 0, 0)\n}\n\n#[bench]\nfn bench_extend_0000_0010(b: &mut Bencher) {\n    do_bench_extend(b, 0, 10)\n}\n\n#[bench]\nfn bench_extend_0000_0100(b: &mut Bencher) {\n    do_bench_extend(b, 0, 100)\n}\n\n#[bench]\nfn bench_extend_0000_1000(b: &mut Bencher) {\n    do_bench_extend(b, 0, 1000)\n}\n\n#[bench]\nfn bench_extend_0010_0010(b: &mut Bencher) {\n    do_bench_extend(b, 10, 10)\n}\n\n#[bench]\nfn bench_extend_0100_0100(b: &mut Bencher) {\n    do_bench_extend(b, 100, 100)\n}\n\n#[bench]\nfn bench_extend_1000_1000(b: &mut Bencher) {\n    do_bench_extend(b, 1000, 1000)\n}\n\nfn do_bench_extend_from_slice(b: &mut Bencher, dst_len: usize, src_len: usize) {\n    let dst: Vec<_> = FromIterator::from_iter(0..dst_len);\n    let src: Vec<_> = FromIterator::from_iter(dst_len..dst_len + src_len);\n\n    b.bytes = src_len as u64;\n\n    b.iter(|| {\n        let mut dst = dst.clone();\n        dst.extend_from_slice(&src);\n        dst\n    });\n}\n\n#[bench]\nfn bench_extend_recycle(b: &mut Bencher) {\n    let mut data = vec![0; 1000];\n\n    b.iter(|| {\n        let tmp = std::mem::take(&mut data);\n        let mut to_extend = black_box(Vec::new());\n        to_extend.extend(tmp.into_iter());\n        data = black_box(to_extend);\n    });\n\n    black_box(data);\n}\n\n#[bench]\nfn bench_extend_from_slice_0000_0000(b: &mut Bencher) {\n    do_bench_extend_from_slice(b, 0, 0)\n}\n\n#[bench]\nfn bench_extend_from_slice_0000_0010(b: &mut Bencher) {\n    do_bench_extend_from_slice(b, 0, 10)\n}\n\n#[bench]\nfn bench_extend_from_slice_0000_0100(b: &mut Bencher) {\n    do_bench_extend_from_slice(b, 0, 100)\n}\n\n#[bench]\nfn bench_extend_from_slice_0000_1000(b: &mut Bencher) {\n    do_bench_extend_from_slice(b, 0, 1000)\n}\n\n#[bench]\nfn bench_extend_from_slice_0010_0010(b: &mut Bencher) {\n    do_bench_extend_from_slice(b, 10, 10)\n}\n\n#[bench]\nfn bench_extend_from_slice_0100_0100(b: &mut Bencher) {\n    do_bench_extend_from_slice(b, 100, 100)\n}\n\n#[bench]\nfn bench_extend_from_slice_1000_1000(b: &mut Bencher) {\n    do_bench_extend_from_slice(b, 1000, 1000)\n}\n\nfn do_bench_clone(b: &mut Bencher, src_len: usize) {\n    let src: Vec<usize> = FromIterator::from_iter(0..src_len);\n\n    b.bytes = src_len as u64;\n\n    b.iter(|| src.clone());\n}\n\n#[bench]\nfn bench_clone_0000(b: &mut Bencher) {\n    do_bench_clone(b, 0)\n}\n\n#[bench]\nfn bench_clone_0010(b: &mut Bencher) {\n    do_bench_clone(b, 10)\n}\n\n#[bench]\nfn bench_clone_0100(b: &mut Bencher) {\n    do_bench_clone(b, 100)\n}\n\n#[bench]\nfn bench_clone_1000(b: &mut Bencher) {\n    do_bench_clone(b, 1000)\n}\n\nfn do_bench_clone_from(b: &mut Bencher, times: usize, dst_len: usize, src_len: usize) {\n    let dst: Vec<_> = FromIterator::from_iter(0..src_len);\n    let src: Vec<_> = FromIterator::from_iter(dst_len..dst_len + src_len);\n\n    b.bytes = (times * src_len) as u64;\n\n    b.iter(|| {\n        let mut dst = dst.clone();\n\n        for _ in 0..times {\n            dst.clone_from(&src);\n            dst = black_box(dst);\n        }\n        dst\n    });\n}\n\n#[bench]\nfn bench_clone_from_01_0000_0000(b: &mut Bencher) {\n    do_bench_clone_from(b, 1, 0, 0)\n}\n\n#[bench]\nfn bench_clone_from_01_0000_0010(b: &mut Bencher) {\n    do_bench_clone_from(b, 1, 0, 10)\n}\n\n#[bench]\nfn bench_clone_from_01_0000_0100(b: &mut Bencher) {\n    do_bench_clone_from(b, 1, 0, 100)\n}\n\n#[bench]\nfn bench_clone_from_01_0000_1000(b: &mut Bencher) {\n    do_bench_clone_from(b, 1, 0, 1000)\n}\n\n#[bench]\nfn bench_clone_from_01_0010_0010(b: &mut Bencher) {\n    do_bench_clone_from(b, 1, 10, 10)\n}\n\n#[bench]\nfn bench_clone_from_01_0100_0100(b: &mut Bencher) {\n    do_bench_clone_from(b, 1, 100, 100)\n}\n\n#[bench]\nfn bench_clone_from_01_1000_1000(b: &mut Bencher) {\n    do_bench_clone_from(b, 1, 1000, 1000)\n}\n\n#[bench]\nfn bench_clone_from_01_0010_0100(b: &mut Bencher) {\n    do_bench_clone_from(b, 1, 10, 100)\n}\n\n#[bench]\nfn bench_clone_from_01_0100_1000(b: &mut Bencher) {\n    do_bench_clone_from(b, 1, 100, 1000)\n}\n\n#[bench]\nfn bench_clone_from_01_0010_0000(b: &mut Bencher) {\n    do_bench_clone_from(b, 1, 10, 0)\n}\n\n#[bench]\nfn bench_clone_from_01_0100_0010(b: &mut Bencher) {\n    do_bench_clone_from(b, 1, 100, 10)\n}\n\n#[bench]\nfn bench_clone_from_01_1000_0100(b: &mut Bencher) {\n    do_bench_clone_from(b, 1, 1000, 100)\n}\n\n#[bench]\nfn bench_clone_from_10_0000_0000(b: &mut Bencher) {\n    do_bench_clone_from(b, 10, 0, 0)\n}\n\n#[bench]\nfn bench_clone_from_10_0000_0010(b: &mut Bencher) {\n    do_bench_clone_from(b, 10, 0, 10)\n}\n\n#[bench]\nfn bench_clone_from_10_0000_0100(b: &mut Bencher) {\n    do_bench_clone_from(b, 10, 0, 100)\n}\n\n#[bench]\nfn bench_clone_from_10_0000_1000(b: &mut Bencher) {\n    do_bench_clone_from(b, 10, 0, 1000)\n}\n\n#[bench]\nfn bench_clone_from_10_0010_0010(b: &mut Bencher) {\n    do_bench_clone_from(b, 10, 10, 10)\n}\n\n#[bench]\nfn bench_clone_from_10_0100_0100(b: &mut Bencher) {\n    do_bench_clone_from(b, 10, 100, 100)\n}\n\n#[bench]\nfn bench_clone_from_10_1000_1000(b: &mut Bencher) {\n    do_bench_clone_from(b, 10, 1000, 1000)\n}\n\n#[bench]\nfn bench_clone_from_10_0010_0100(b: &mut Bencher) {\n    do_bench_clone_from(b, 10, 10, 100)\n}\n\n#[bench]\nfn bench_clone_from_10_0100_1000(b: &mut Bencher) {\n    do_bench_clone_from(b, 10, 100, 1000)\n}\n\n#[bench]\nfn bench_clone_from_10_0010_0000(b: &mut Bencher) {\n    do_bench_clone_from(b, 10, 10, 0)\n}\n\n#[bench]\nfn bench_clone_from_10_0100_0010(b: &mut Bencher) {\n    do_bench_clone_from(b, 10, 100, 10)\n}\n\n#[bench]\nfn bench_clone_from_10_1000_0100(b: &mut Bencher) {\n    do_bench_clone_from(b, 10, 1000, 100)\n}\n\nmacro_rules! bench_in_place {\n    ($($fname:ident, $type:ty, $count:expr, $init:expr);*) => {\n        $(\n            #[bench]\n            fn $fname(b: &mut Bencher) {\n                b.iter(|| {\n                    let src: Vec<$type> = black_box(vec![$init; $count]);\n                    src.into_iter()\n                        .enumerate()\n                        .map(|(idx, e)| idx as $type ^ e)\n                        .collect::<Vec<$type>>()\n                });\n            }\n        )+\n    };\n}\n\nbench_in_place![\n    bench_in_place_xxu8_0010_i0,   u8,   10, 0;\n    bench_in_place_xxu8_0100_i0,   u8,  100, 0;\n    bench_in_place_xxu8_1000_i0,   u8, 1000, 0;\n    bench_in_place_xxu8_0010_i1,   u8,   10, 1;\n    bench_in_place_xxu8_0100_i1,   u8,  100, 1;\n    bench_in_place_xxu8_1000_i1,   u8, 1000, 1;\n    bench_in_place_xu32_0010_i0,  u32,   10, 0;\n    bench_in_place_xu32_0100_i0,  u32,  100, 0;\n    bench_in_place_xu32_1000_i0,  u32, 1000, 0;\n    bench_in_place_xu32_0010_i1,  u32,   10, 1;\n    bench_in_place_xu32_0100_i1,  u32,  100, 1;\n    bench_in_place_xu32_1000_i1,  u32, 1000, 1;\n    bench_in_place_u128_0010_i0, u128,   10, 0;\n    bench_in_place_u128_0100_i0, u128,  100, 0;\n    bench_in_place_u128_1000_i0, u128, 1000, 0;\n    bench_in_place_u128_0010_i1, u128,   10, 1;\n    bench_in_place_u128_0100_i1, u128,  100, 1;\n    bench_in_place_u128_1000_i1, u128, 1000, 1\n];\n\n#[bench]\nfn bench_in_place_recycle(b: &mut Bencher) {\n    let mut data = vec![0; 1000];\n\n    b.iter(|| {\n        let tmp = std::mem::take(&mut data);\n        data = black_box(\n            tmp.into_iter()\n                .enumerate()\n                .map(|(idx, e)| idx.wrapping_add(e))\n                .fuse()\n                .collect::<Vec<usize>>(),\n        );\n    });\n}\n\n#[bench]\nfn bench_in_place_zip_recycle(b: &mut Bencher) {\n    let mut data = vec![0u8; 1000];\n    let mut rng = rand::thread_rng();\n    let mut subst = vec![0u8; 1000];\n    rng.fill_bytes(&mut subst[..]);\n\n    b.iter(|| {\n        let tmp = std::mem::take(&mut data);\n        let mangled = tmp\n            .into_iter()\n            .zip(subst.iter().copied())\n            .enumerate()\n            .map(|(i, (d, s))| d.wrapping_add(i as u8) ^ s)\n            .collect::<Vec<_>>();\n        data = black_box(mangled);\n    });\n}\n\n#[bench]\nfn bench_in_place_zip_iter_mut(b: &mut Bencher) {\n    let mut data = vec![0u8; 256];\n    let mut rng = rand::thread_rng();\n    let mut subst = vec![0u8; 1000];\n    rng.fill_bytes(&mut subst[..]);\n\n    b.iter(|| {\n        data.iter_mut().enumerate().for_each(|(i, d)| {\n            *d = d.wrapping_add(i as u8) ^ subst[i];\n        });\n    });\n\n    black_box(data);\n}\n\npub fn vec_cast<T, U>(input: Vec<T>) -> Vec<U> {\n    input.into_iter().map(|e| unsafe { std::mem::transmute_copy(&e) }).collect()\n}\n\n#[bench]\nfn bench_transmute(b: &mut Bencher) {\n    let mut vec = vec![10u32; 100];\n    b.bytes = 800; // 2 casts x 4 bytes x 100\n    b.iter(|| {\n        let v = std::mem::take(&mut vec);\n        let v = black_box(vec_cast::<u32, i32>(v));\n        let v = black_box(vec_cast::<i32, u32>(v));\n        vec = v;\n    });\n}\n\n#[derive(Clone)]\nstruct Droppable(usize);\n\nimpl Drop for Droppable {\n    fn drop(&mut self) {\n        black_box(self);\n    }\n}\n\n#[bench]\nfn bench_in_place_collect_droppable(b: &mut Bencher) {\n    let v: Vec<Droppable> = std::iter::repeat_with(|| Droppable(0)).take(1000).collect();\n    b.iter(|| {\n        v.clone()\n            .into_iter()\n            .skip(100)\n            .enumerate()\n            .map(|(i, e)| Droppable(i ^ e.0))\n            .collect::<Vec<_>>()\n    })\n}\n\nconst LEN: usize = 16384;\n\n#[bench]\nfn bench_chain_collect(b: &mut Bencher) {\n    let data = black_box([0; LEN]);\n    b.iter(|| data.iter().cloned().chain([1]).collect::<Vec<_>>());\n}\n\n#[bench]\nfn bench_chain_chain_collect(b: &mut Bencher) {\n    let data = black_box([0; LEN]);\n    b.iter(|| data.iter().cloned().chain([1]).chain([2]).collect::<Vec<_>>());\n}\n\n#[bench]\nfn bench_nest_chain_chain_collect(b: &mut Bencher) {\n    let data = black_box([0; LEN]);\n    b.iter(|| {\n        data.iter().cloned().chain([1].iter().chain([2].iter()).cloned()).collect::<Vec<_>>()\n    });\n}\n\n#[bench]\nfn bench_range_map_collect(b: &mut Bencher) {\n    b.iter(|| (0..LEN).map(|_| u32::default()).collect::<Vec<_>>());\n}\n\n#[bench]\nfn bench_chain_extend_ref(b: &mut Bencher) {\n    let data = black_box([0; LEN]);\n    b.iter(|| {\n        let mut v = Vec::<u32>::with_capacity(data.len() + 1);\n        v.extend(data.iter().chain([1].iter()));\n        v\n    });\n}\n\n#[bench]\nfn bench_chain_extend_value(b: &mut Bencher) {\n    let data = black_box([0; LEN]);\n    b.iter(|| {\n        let mut v = Vec::<u32>::with_capacity(data.len() + 1);\n        v.extend(data.iter().cloned().chain(Some(1)));\n        v\n    });\n}\n\n#[bench]\nfn bench_rev_1(b: &mut Bencher) {\n    let data = black_box([0; LEN]);\n    b.iter(|| {\n        let mut v = Vec::<u32>::new();\n        v.extend(data.iter().rev());\n        v\n    });\n}\n\n#[bench]\nfn bench_rev_2(b: &mut Bencher) {\n    let data = black_box([0; LEN]);\n    b.iter(|| {\n        let mut v = Vec::<u32>::with_capacity(data.len());\n        v.extend(data.iter().rev());\n        v\n    });\n}\n\n#[bench]\nfn bench_map_regular(b: &mut Bencher) {\n    let data = black_box([(0, 0); LEN]);\n    b.iter(|| {\n        let mut v = Vec::<u32>::new();\n        v.extend(data.iter().map(|t| t.1));\n        v\n    });\n}\n\n#[bench]\nfn bench_map_fast(b: &mut Bencher) {\n    let data = black_box([(0, 0); LEN]);\n    b.iter(|| {\n        let mut result = Vec::with_capacity(data.len());\n        for i in 0..data.len() {\n            unsafe {\n                *result.get_unchecked_mut(i) = data[i].0;\n                result.set_len(i);\n            }\n        }\n        result\n    });\n}\n\nfn random_sorted_fill(mut seed: u32, buf: &mut [u32]) {\n    let mask = if buf.len() < 8192 {\n        0xFF\n    } else if buf.len() < 200_000 {\n        0xFFFF\n    } else {\n        0xFFFF_FFFF\n    };\n\n    for item in buf.iter_mut() {\n        seed ^= seed << 13;\n        seed ^= seed >> 17;\n        seed ^= seed << 5;\n\n        *item = seed & mask;\n    }\n\n    buf.sort();\n}\n\nfn bench_vec_dedup_old(b: &mut Bencher, sz: usize) {\n    let mut template = vec![0u32; sz];\n    b.bytes = std::mem::size_of_val(template.as_slice()) as u64;\n    random_sorted_fill(0x43, &mut template);\n\n    let mut vec = template.clone();\n    b.iter(|| {\n        let len = {\n            let (dedup, _) = vec.partition_dedup();\n            dedup.len()\n        };\n        vec.truncate(len);\n\n        black_box(vec.first());\n        vec.clear();\n        vec.extend_from_slice(&template);\n    });\n}\n\nfn bench_vec_dedup_new(b: &mut Bencher, sz: usize) {\n    let mut template = vec![0u32; sz];\n    b.bytes = std::mem::size_of_val(template.as_slice()) as u64;\n    random_sorted_fill(0x43, &mut template);\n\n    let mut vec = template.clone();\n    b.iter(|| {\n        vec.dedup();\n        black_box(vec.first());\n        vec.clear();\n        vec.extend_from_slice(&template);\n    });\n}\n\n#[bench]\nfn bench_dedup_old_100(b: &mut Bencher) {\n    bench_vec_dedup_old(b, 100);\n}\n#[bench]\nfn bench_dedup_new_100(b: &mut Bencher) {\n    bench_vec_dedup_new(b, 100);\n}\n\n#[bench]\nfn bench_dedup_old_1000(b: &mut Bencher) {\n    bench_vec_dedup_old(b, 1000);\n}\n#[bench]\nfn bench_dedup_new_1000(b: &mut Bencher) {\n    bench_vec_dedup_new(b, 1000);\n}\n\n#[bench]\nfn bench_dedup_old_10000(b: &mut Bencher) {\n    bench_vec_dedup_old(b, 10000);\n}\n#[bench]\nfn bench_dedup_new_10000(b: &mut Bencher) {\n    bench_vec_dedup_new(b, 10000);\n}\n\n#[bench]\nfn bench_dedup_old_100000(b: &mut Bencher) {\n    bench_vec_dedup_old(b, 100000);\n}\n#[bench]\nfn bench_dedup_new_100000(b: &mut Bencher) {\n    bench_vec_dedup_new(b, 100000);\n}\n"],[2079,"// Disabling on android for the time being\n// See https://github.com/rust-lang/rust/issues/73535#event-3477699747\n#![cfg(not(target_os = \"android\"))]\n#![feature(btree_drain_filter)]\n#![feature(map_first_last)]\n#![feature(repr_simd)]\n#![feature(slice_partition_dedup)]\n#![feature(test)]\n\nextern crate test;\n\nmod binary_heap;\nmod btree;\nmod linked_list;\nmod slice;\nmod str;\nmod string;\nmod vec;\nmod vec_deque;\n"],[2080,"use std::collections::BinaryHeap;\n\nuse rand::{seq::SliceRandom, thread_rng};\nuse test::{black_box, Bencher};\n\n#[bench]\nfn bench_find_smallest_1000(b: &mut Bencher) {\n    let mut rng = thread_rng();\n    let mut vec: Vec<u32> = (0..100_000).collect();\n    vec.shuffle(&mut rng);\n\n    b.iter(|| {\n        let mut iter = vec.iter().copied();\n        let mut heap: BinaryHeap<_> = iter.by_ref().take(1000).collect();\n\n        for x in iter {\n            let mut max = heap.peek_mut().unwrap();\n            // This comparison should be true only 1% of the time.\n            // Unnecessary `sift_down`s will degrade performance\n            if x < *max {\n                *max = x;\n            }\n        }\n\n        heap\n    })\n}\n\n#[bench]\nfn bench_peek_mut_deref_mut(b: &mut Bencher) {\n    let mut bheap = BinaryHeap::from(vec![42]);\n    let vec: Vec<u32> = (0..1_000_000).collect();\n\n    b.iter(|| {\n        let vec = black_box(&vec);\n        let mut peek_mut = bheap.peek_mut().unwrap();\n        // The compiler shouldn't be able to optimize away the `sift_down`\n        // assignment in `PeekMut`'s `DerefMut` implementation since\n        // the loop may not run.\n        for &i in vec.iter() {\n            *peek_mut = i;\n        }\n        // Remove the already minimal overhead of the sift_down\n        std::mem::forget(peek_mut);\n    })\n}\n\n#[bench]\nfn bench_from_vec(b: &mut Bencher) {\n    let mut rng = thread_rng();\n    let mut vec: Vec<u32> = (0..100_000).collect();\n    vec.shuffle(&mut rng);\n\n    b.iter(|| BinaryHeap::from(vec.clone()))\n}\n\n#[bench]\nfn bench_into_sorted_vec(b: &mut Bencher) {\n    let bheap: BinaryHeap<i32> = (0..10_000).collect();\n\n    b.iter(|| bheap.clone().into_sorted_vec())\n}\n\n#[bench]\nfn bench_push(b: &mut Bencher) {\n    let mut bheap = BinaryHeap::with_capacity(50_000);\n    let mut rng = thread_rng();\n    let mut vec: Vec<u32> = (0..50_000).collect();\n    vec.shuffle(&mut rng);\n\n    b.iter(|| {\n        for &i in vec.iter() {\n            bheap.push(i);\n        }\n        black_box(&mut bheap);\n        bheap.clear();\n    })\n}\n\n#[bench]\nfn bench_pop(b: &mut Bencher) {\n    let mut bheap = BinaryHeap::with_capacity(10_000);\n\n    b.iter(|| {\n        bheap.extend((0..10_000).rev());\n        black_box(&mut bheap);\n        while let Some(elem) = bheap.pop() {\n            black_box(elem);\n        }\n    })\n}\n"],[2081,"mod map;\nmod set;\n"],[2082,"use std::collections::BTreeSet;\n\nuse rand::{thread_rng, Rng};\nuse test::Bencher;\n\nfn random(n: usize) -> BTreeSet<usize> {\n    let mut rng = thread_rng();\n    let mut set = BTreeSet::new();\n    while set.len() < n {\n        set.insert(rng.gen());\n    }\n    assert_eq!(set.len(), n);\n    set\n}\n\nfn neg(n: usize) -> BTreeSet<i32> {\n    let set: BTreeSet<i32> = (-(n as i32)..=-1).collect();\n    assert_eq!(set.len(), n);\n    set\n}\n\nfn pos(n: usize) -> BTreeSet<i32> {\n    let set: BTreeSet<i32> = (1..=(n as i32)).collect();\n    assert_eq!(set.len(), n);\n    set\n}\n\nfn stagger(n1: usize, factor: usize) -> [BTreeSet<u32>; 2] {\n    let n2 = n1 * factor;\n    let mut sets = [BTreeSet::new(), BTreeSet::new()];\n    for i in 0..(n1 + n2) {\n        let b = i % (factor + 1) != 0;\n        sets[b as usize].insert(i as u32);\n    }\n    assert_eq!(sets[0].len(), n1);\n    assert_eq!(sets[1].len(), n2);\n    sets\n}\n\nmacro_rules! set_bench {\n    ($name: ident, $set_func: ident, $result_func: ident, $sets: expr) => {\n        #[bench]\n        pub fn $name(b: &mut Bencher) {\n            // setup\n            let sets = $sets;\n\n            // measure\n            b.iter(|| sets[0].$set_func(&sets[1]).$result_func())\n        }\n    };\n}\n\nfn slim_set(n: usize) -> BTreeSet<usize> {\n    (0..n).collect::<BTreeSet<_>>()\n}\n\n#[bench]\npub fn clone_100(b: &mut Bencher) {\n    let src = slim_set(100);\n    b.iter(|| src.clone())\n}\n\n#[bench]\npub fn clone_100_and_clear(b: &mut Bencher) {\n    let src = slim_set(100);\n    b.iter(|| src.clone().clear())\n}\n\n#[bench]\npub fn clone_100_and_drain_all(b: &mut Bencher) {\n    let src = slim_set(100);\n    b.iter(|| src.clone().drain_filter(|_| true).count())\n}\n\n#[bench]\npub fn clone_100_and_drain_half(b: &mut Bencher) {\n    let src = slim_set(100);\n    b.iter(|| {\n        let mut set = src.clone();\n        assert_eq!(set.drain_filter(|i| i % 2 == 0).count(), 100 / 2);\n        assert_eq!(set.len(), 100 / 2);\n    })\n}\n\n#[bench]\npub fn clone_100_and_into_iter(b: &mut Bencher) {\n    let src = slim_set(100);\n    b.iter(|| src.clone().into_iter().count())\n}\n\n#[bench]\npub fn clone_100_and_pop_all(b: &mut Bencher) {\n    let src = slim_set(100);\n    b.iter(|| {\n        let mut set = src.clone();\n        while set.pop_first().is_some() {}\n        set\n    });\n}\n\n#[bench]\npub fn clone_100_and_remove_all(b: &mut Bencher) {\n    let src = slim_set(100);\n    b.iter(|| {\n        let mut set = src.clone();\n        while let Some(elt) = set.iter().copied().next() {\n            let ok = set.remove(&elt);\n            debug_assert!(ok);\n        }\n        set\n    });\n}\n\n#[bench]\npub fn clone_100_and_remove_half(b: &mut Bencher) {\n    let src = slim_set(100);\n    b.iter(|| {\n        let mut set = src.clone();\n        for i in (0..100).step_by(2) {\n            let ok = set.remove(&i);\n            debug_assert!(ok);\n        }\n        assert_eq!(set.len(), 100 / 2);\n        set\n    })\n}\n\n#[bench]\npub fn clone_10k(b: &mut Bencher) {\n    let src = slim_set(10_000);\n    b.iter(|| src.clone())\n}\n\n#[bench]\npub fn clone_10k_and_clear(b: &mut Bencher) {\n    let src = slim_set(10_000);\n    b.iter(|| src.clone().clear())\n}\n\n#[bench]\npub fn clone_10k_and_drain_all(b: &mut Bencher) {\n    let src = slim_set(10_000);\n    b.iter(|| src.clone().drain_filter(|_| true).count())\n}\n\n#[bench]\npub fn clone_10k_and_drain_half(b: &mut Bencher) {\n    let src = slim_set(10_000);\n    b.iter(|| {\n        let mut set = src.clone();\n        assert_eq!(set.drain_filter(|i| i % 2 == 0).count(), 10_000 / 2);\n        assert_eq!(set.len(), 10_000 / 2);\n    })\n}\n\n#[bench]\npub fn clone_10k_and_into_iter(b: &mut Bencher) {\n    let src = slim_set(10_000);\n    b.iter(|| src.clone().into_iter().count())\n}\n\n#[bench]\npub fn clone_10k_and_pop_all(b: &mut Bencher) {\n    let src = slim_set(10_000);\n    b.iter(|| {\n        let mut set = src.clone();\n        while set.pop_first().is_some() {}\n        set\n    });\n}\n\n#[bench]\npub fn clone_10k_and_remove_all(b: &mut Bencher) {\n    let src = slim_set(10_000);\n    b.iter(|| {\n        let mut set = src.clone();\n        while let Some(elt) = set.iter().copied().next() {\n            let ok = set.remove(&elt);\n            debug_assert!(ok);\n        }\n        set\n    });\n}\n\n#[bench]\npub fn clone_10k_and_remove_half(b: &mut Bencher) {\n    let src = slim_set(10_000);\n    b.iter(|| {\n        let mut set = src.clone();\n        for i in (0..10_000).step_by(2) {\n            let ok = set.remove(&i);\n            debug_assert!(ok);\n        }\n        assert_eq!(set.len(), 10_000 / 2);\n        set\n    })\n}\n\nset_bench! {intersection_100_neg_vs_100_pos, intersection, count, [neg(100), pos(100)]}\nset_bench! {intersection_100_neg_vs_10k_pos, intersection, count, [neg(100), pos(10_000)]}\nset_bench! {intersection_100_pos_vs_100_neg, intersection, count, [pos(100), neg(100)]}\nset_bench! {intersection_100_pos_vs_10k_neg, intersection, count, [pos(100), neg(10_000)]}\nset_bench! {intersection_10k_neg_vs_100_pos, intersection, count, [neg(10_000), pos(100)]}\nset_bench! {intersection_10k_neg_vs_10k_pos, intersection, count, [neg(10_000), pos(10_000)]}\nset_bench! {intersection_10k_pos_vs_100_neg, intersection, count, [pos(10_000), neg(100)]}\nset_bench! {intersection_10k_pos_vs_10k_neg, intersection, count, [pos(10_000), neg(10_000)]}\nset_bench! {intersection_random_100_vs_100, intersection, count, [random(100), random(100)]}\nset_bench! {intersection_random_100_vs_10k, intersection, count, [random(100), random(10_000)]}\nset_bench! {intersection_random_10k_vs_100, intersection, count, [random(10_000), random(100)]}\nset_bench! {intersection_random_10k_vs_10k, intersection, count, [random(10_000), random(10_000)]}\nset_bench! {intersection_staggered_100_vs_100, intersection, count, stagger(100, 1)}\nset_bench! {intersection_staggered_10k_vs_10k, intersection, count, stagger(10_000, 1)}\nset_bench! {intersection_staggered_100_vs_10k, intersection, count, stagger(100, 100)}\nset_bench! {difference_random_100_vs_100, difference, count, [random(100), random(100)]}\nset_bench! {difference_random_100_vs_10k, difference, count, [random(100), random(10_000)]}\nset_bench! {difference_random_10k_vs_100, difference, count, [random(10_000), random(100)]}\nset_bench! {difference_random_10k_vs_10k, difference, count, [random(10_000), random(10_000)]}\nset_bench! {difference_staggered_100_vs_100, difference, count, stagger(100, 1)}\nset_bench! {difference_staggered_10k_vs_10k, difference, count, stagger(10_000, 1)}\nset_bench! {difference_staggered_100_vs_10k, difference, count, stagger(100, 100)}\nset_bench! {is_subset_100_vs_100, is_subset, clone, [pos(100), pos(100)]}\nset_bench! {is_subset_100_vs_10k, is_subset, clone, [pos(100), pos(10_000)]}\nset_bench! {is_subset_10k_vs_100, is_subset, clone, [pos(10_000), pos(100)]}\nset_bench! {is_subset_10k_vs_10k, is_subset, clone, [pos(10_000), pos(10_000)]}\n"],[2083,"use std::collections::BTreeMap;\nuse std::iter::Iterator;\nuse std::ops::RangeBounds;\nuse std::vec::Vec;\n\nuse rand::{seq::SliceRandom, thread_rng, Rng};\nuse test::{black_box, Bencher};\n\nmacro_rules! map_insert_rand_bench {\n    ($name: ident, $n: expr, $map: ident) => {\n        #[bench]\n        pub fn $name(b: &mut Bencher) {\n            let n: usize = $n;\n            let mut map = $map::new();\n            // setup\n            let mut rng = thread_rng();\n\n            for _ in 0..n {\n                let i = rng.gen::<usize>() % n;\n                map.insert(i, i);\n            }\n\n            // measure\n            b.iter(|| {\n                let k = rng.gen::<usize>() % n;\n                map.insert(k, k);\n                map.remove(&k);\n            });\n            black_box(map);\n        }\n    };\n}\n\nmacro_rules! map_insert_seq_bench {\n    ($name: ident, $n: expr, $map: ident) => {\n        #[bench]\n        pub fn $name(b: &mut Bencher) {\n            let mut map = $map::new();\n            let n: usize = $n;\n            // setup\n            for i in 0..n {\n                map.insert(i * 2, i * 2);\n            }\n\n            // measure\n            let mut i = 1;\n            b.iter(|| {\n                map.insert(i, i);\n                map.remove(&i);\n                i = (i + 2) % n;\n            });\n            black_box(map);\n        }\n    };\n}\n\nmacro_rules! map_find_rand_bench {\n    ($name: ident, $n: expr, $map: ident) => {\n        #[bench]\n        pub fn $name(b: &mut Bencher) {\n            let mut map = $map::new();\n            let n: usize = $n;\n\n            // setup\n            let mut rng = thread_rng();\n            let mut keys: Vec<_> = (0..n).map(|_| rng.gen::<usize>() % n).collect();\n\n            for &k in &keys {\n                map.insert(k, k);\n            }\n\n            keys.shuffle(&mut rng);\n\n            // measure\n            let mut i = 0;\n            b.iter(|| {\n                let t = map.get(&keys[i]);\n                i = (i + 1) % n;\n                black_box(t);\n            })\n        }\n    };\n}\n\nmacro_rules! map_find_seq_bench {\n    ($name: ident, $n: expr, $map: ident) => {\n        #[bench]\n        pub fn $name(b: &mut Bencher) {\n            let mut map = $map::new();\n            let n: usize = $n;\n\n            // setup\n            for i in 0..n {\n                map.insert(i, i);\n            }\n\n            // measure\n            let mut i = 0;\n            b.iter(|| {\n                let x = map.get(&i);\n                i = (i + 1) % n;\n                black_box(x);\n            })\n        }\n    };\n}\n\nmap_insert_rand_bench! {insert_rand_100,    100,    BTreeMap}\nmap_insert_rand_bench! {insert_rand_10_000, 10_000, BTreeMap}\n\nmap_insert_seq_bench! {insert_seq_100,    100,    BTreeMap}\nmap_insert_seq_bench! {insert_seq_10_000, 10_000, BTreeMap}\n\nmap_find_rand_bench! {find_rand_100,    100,    BTreeMap}\nmap_find_rand_bench! {find_rand_10_000, 10_000, BTreeMap}\n\nmap_find_seq_bench! {find_seq_100,    100,    BTreeMap}\nmap_find_seq_bench! {find_seq_10_000, 10_000, BTreeMap}\n\nfn bench_iteration(b: &mut Bencher, size: i32) {\n    let mut map = BTreeMap::<i32, i32>::new();\n    let mut rng = thread_rng();\n\n    for _ in 0..size {\n        map.insert(rng.gen(), rng.gen());\n    }\n\n    b.iter(|| {\n        for entry in &map {\n            black_box(entry);\n        }\n    });\n}\n\n#[bench]\npub fn iteration_20(b: &mut Bencher) {\n    bench_iteration(b, 20);\n}\n\n#[bench]\npub fn iteration_1000(b: &mut Bencher) {\n    bench_iteration(b, 1000);\n}\n\n#[bench]\npub fn iteration_100000(b: &mut Bencher) {\n    bench_iteration(b, 100000);\n}\n\nfn bench_iteration_mut(b: &mut Bencher, size: i32) {\n    let mut map = BTreeMap::<i32, i32>::new();\n    let mut rng = thread_rng();\n\n    for _ in 0..size {\n        map.insert(rng.gen(), rng.gen());\n    }\n\n    b.iter(|| {\n        for kv in map.iter_mut() {\n            black_box(kv);\n        }\n    });\n}\n\n#[bench]\npub fn iteration_mut_20(b: &mut Bencher) {\n    bench_iteration_mut(b, 20);\n}\n\n#[bench]\npub fn iteration_mut_1000(b: &mut Bencher) {\n    bench_iteration_mut(b, 1000);\n}\n\n#[bench]\npub fn iteration_mut_100000(b: &mut Bencher) {\n    bench_iteration_mut(b, 100000);\n}\n\nfn bench_first_and_last_nightly(b: &mut Bencher, size: i32) {\n    let map: BTreeMap<_, _> = (0..size).map(|i| (i, i)).collect();\n    b.iter(|| {\n        for _ in 0..10 {\n            black_box(map.first_key_value());\n            black_box(map.last_key_value());\n        }\n    });\n}\n\nfn bench_first_and_last_stable(b: &mut Bencher, size: i32) {\n    let map: BTreeMap<_, _> = (0..size).map(|i| (i, i)).collect();\n    b.iter(|| {\n        for _ in 0..10 {\n            black_box(map.iter().next());\n            black_box(map.iter().next_back());\n        }\n    });\n}\n\n#[bench]\npub fn first_and_last_0_nightly(b: &mut Bencher) {\n    bench_first_and_last_nightly(b, 0);\n}\n\n#[bench]\npub fn first_and_last_0_stable(b: &mut Bencher) {\n    bench_first_and_last_stable(b, 0);\n}\n\n#[bench]\npub fn first_and_last_100_nightly(b: &mut Bencher) {\n    bench_first_and_last_nightly(b, 100);\n}\n\n#[bench]\npub fn first_and_last_100_stable(b: &mut Bencher) {\n    bench_first_and_last_stable(b, 100);\n}\n\n#[bench]\npub fn first_and_last_10k_nightly(b: &mut Bencher) {\n    bench_first_and_last_nightly(b, 10_000);\n}\n\n#[bench]\npub fn first_and_last_10k_stable(b: &mut Bencher) {\n    bench_first_and_last_stable(b, 10_000);\n}\n\nconst BENCH_RANGE_SIZE: i32 = 145;\nconst BENCH_RANGE_COUNT: i32 = BENCH_RANGE_SIZE * (BENCH_RANGE_SIZE - 1) / 2;\n\nfn bench_range<F, R>(b: &mut Bencher, f: F)\nwhere\n    F: Fn(i32, i32) -> R,\n    R: RangeBounds<i32>,\n{\n    let map: BTreeMap<_, _> = (0..BENCH_RANGE_SIZE).map(|i| (i, i)).collect();\n    b.iter(|| {\n        let mut c = 0;\n        for i in 0..BENCH_RANGE_SIZE {\n            for j in i + 1..BENCH_RANGE_SIZE {\n                black_box(map.range(f(i, j)));\n                c += 1;\n            }\n        }\n        debug_assert_eq!(c, BENCH_RANGE_COUNT);\n    });\n}\n\n#[bench]\npub fn range_included_excluded(b: &mut Bencher) {\n    bench_range(b, |i, j| i..j);\n}\n\n#[bench]\npub fn range_included_included(b: &mut Bencher) {\n    bench_range(b, |i, j| i..=j);\n}\n\n#[bench]\npub fn range_included_unbounded(b: &mut Bencher) {\n    bench_range(b, |i, _| i..);\n}\n\n#[bench]\npub fn range_unbounded_unbounded(b: &mut Bencher) {\n    bench_range(b, |_, _| ..);\n}\n\nfn bench_iter(b: &mut Bencher, repeats: i32, size: i32) {\n    let map: BTreeMap<_, _> = (0..size).map(|i| (i, i)).collect();\n    b.iter(|| {\n        for _ in 0..repeats {\n            black_box(map.iter());\n        }\n    });\n}\n\n/// Contrast range_unbounded_unbounded with `iter()`.\n#[bench]\npub fn range_unbounded_vs_iter(b: &mut Bencher) {\n    bench_iter(b, BENCH_RANGE_COUNT, BENCH_RANGE_SIZE);\n}\n\n#[bench]\npub fn iter_0(b: &mut Bencher) {\n    bench_iter(b, 1_000, 0);\n}\n\n#[bench]\npub fn iter_1(b: &mut Bencher) {\n    bench_iter(b, 1_000, 1);\n}\n\n#[bench]\npub fn iter_100(b: &mut Bencher) {\n    bench_iter(b, 1_000, 100);\n}\n\n#[bench]\npub fn iter_10k(b: &mut Bencher) {\n    bench_iter(b, 1_000, 10_000);\n}\n\n#[bench]\npub fn iter_1m(b: &mut Bencher) {\n    bench_iter(b, 1_000, 1_000_000);\n}\n\nconst FAT: usize = 256;\n\n// The returned map has small keys and values.\n// Benchmarks on it have a counterpart in set.rs with the same keys and no values at all.\nfn slim_map(n: usize) -> BTreeMap<usize, usize> {\n    (0..n).map(|i| (i, i)).collect::<BTreeMap<_, _>>()\n}\n\n// The returned map has small keys and large values.\nfn fat_val_map(n: usize) -> BTreeMap<usize, [usize; FAT]> {\n    (0..n).map(|i| (i, [i; FAT])).collect::<BTreeMap<_, _>>()\n}\n\n#[bench]\npub fn clone_slim_100(b: &mut Bencher) {\n    let src = slim_map(100);\n    b.iter(|| src.clone())\n}\n\n#[bench]\npub fn clone_slim_100_and_clear(b: &mut Bencher) {\n    let src = slim_map(100);\n    b.iter(|| src.clone().clear())\n}\n\n#[bench]\npub fn clone_slim_100_and_drain_all(b: &mut Bencher) {\n    let src = slim_map(100);\n    b.iter(|| src.clone().drain_filter(|_, _| true).count())\n}\n\n#[bench]\npub fn clone_slim_100_and_drain_half(b: &mut Bencher) {\n    let src = slim_map(100);\n    b.iter(|| {\n        let mut map = src.clone();\n        assert_eq!(map.drain_filter(|i, _| i % 2 == 0).count(), 100 / 2);\n        assert_eq!(map.len(), 100 / 2);\n    })\n}\n\n#[bench]\npub fn clone_slim_100_and_into_iter(b: &mut Bencher) {\n    let src = slim_map(100);\n    b.iter(|| src.clone().into_iter().count())\n}\n\n#[bench]\npub fn clone_slim_100_and_pop_all(b: &mut Bencher) {\n    let src = slim_map(100);\n    b.iter(|| {\n        let mut map = src.clone();\n        while map.pop_first().is_some() {}\n        map\n    });\n}\n\n#[bench]\npub fn clone_slim_100_and_remove_all(b: &mut Bencher) {\n    let src = slim_map(100);\n    b.iter(|| {\n        let mut map = src.clone();\n        while let Some(elt) = map.iter().map(|(&i, _)| i).next() {\n            let v = map.remove(&elt);\n            debug_assert!(v.is_some());\n        }\n        map\n    });\n}\n\n#[bench]\npub fn clone_slim_100_and_remove_half(b: &mut Bencher) {\n    let src = slim_map(100);\n    b.iter(|| {\n        let mut map = src.clone();\n        for i in (0..100).step_by(2) {\n            let v = map.remove(&i);\n            debug_assert!(v.is_some());\n        }\n        assert_eq!(map.len(), 100 / 2);\n        map\n    })\n}\n\n#[bench]\npub fn clone_slim_10k(b: &mut Bencher) {\n    let src = slim_map(10_000);\n    b.iter(|| src.clone())\n}\n\n#[bench]\npub fn clone_slim_10k_and_clear(b: &mut Bencher) {\n    let src = slim_map(10_000);\n    b.iter(|| src.clone().clear())\n}\n\n#[bench]\npub fn clone_slim_10k_and_drain_all(b: &mut Bencher) {\n    let src = slim_map(10_000);\n    b.iter(|| src.clone().drain_filter(|_, _| true).count())\n}\n\n#[bench]\npub fn clone_slim_10k_and_drain_half(b: &mut Bencher) {\n    let src = slim_map(10_000);\n    b.iter(|| {\n        let mut map = src.clone();\n        assert_eq!(map.drain_filter(|i, _| i % 2 == 0).count(), 10_000 / 2);\n        assert_eq!(map.len(), 10_000 / 2);\n    })\n}\n\n#[bench]\npub fn clone_slim_10k_and_into_iter(b: &mut Bencher) {\n    let src = slim_map(10_000);\n    b.iter(|| src.clone().into_iter().count())\n}\n\n#[bench]\npub fn clone_slim_10k_and_pop_all(b: &mut Bencher) {\n    let src = slim_map(10_000);\n    b.iter(|| {\n        let mut map = src.clone();\n        while map.pop_first().is_some() {}\n        map\n    });\n}\n\n#[bench]\npub fn clone_slim_10k_and_remove_all(b: &mut Bencher) {\n    let src = slim_map(10_000);\n    b.iter(|| {\n        let mut map = src.clone();\n        while let Some(elt) = map.iter().map(|(&i, _)| i).next() {\n            let v = map.remove(&elt);\n            debug_assert!(v.is_some());\n        }\n        map\n    });\n}\n\n#[bench]\npub fn clone_slim_10k_and_remove_half(b: &mut Bencher) {\n    let src = slim_map(10_000);\n    b.iter(|| {\n        let mut map = src.clone();\n        for i in (0..10_000).step_by(2) {\n            let v = map.remove(&i);\n            debug_assert!(v.is_some());\n        }\n        assert_eq!(map.len(), 10_000 / 2);\n        map\n    })\n}\n\n#[bench]\npub fn clone_fat_val_100(b: &mut Bencher) {\n    let src = fat_val_map(100);\n    b.iter(|| src.clone())\n}\n\n#[bench]\npub fn clone_fat_val_100_and_clear(b: &mut Bencher) {\n    let src = fat_val_map(100);\n    b.iter(|| src.clone().clear())\n}\n\n#[bench]\npub fn clone_fat_val_100_and_drain_all(b: &mut Bencher) {\n    let src = fat_val_map(100);\n    b.iter(|| src.clone().drain_filter(|_, _| true).count())\n}\n\n#[bench]\npub fn clone_fat_val_100_and_drain_half(b: &mut Bencher) {\n    let src = fat_val_map(100);\n    b.iter(|| {\n        let mut map = src.clone();\n        assert_eq!(map.drain_filter(|i, _| i % 2 == 0).count(), 100 / 2);\n        assert_eq!(map.len(), 100 / 2);\n    })\n}\n\n#[bench]\npub fn clone_fat_val_100_and_into_iter(b: &mut Bencher) {\n    let src = fat_val_map(100);\n    b.iter(|| src.clone().into_iter().count())\n}\n\n#[bench]\npub fn clone_fat_val_100_and_pop_all(b: &mut Bencher) {\n    let src = fat_val_map(100);\n    b.iter(|| {\n        let mut map = src.clone();\n        while map.pop_first().is_some() {}\n        map\n    });\n}\n\n#[bench]\npub fn clone_fat_val_100_and_remove_all(b: &mut Bencher) {\n    let src = fat_val_map(100);\n    b.iter(|| {\n        let mut map = src.clone();\n        while let Some(elt) = map.iter().map(|(&i, _)| i).next() {\n            let v = map.remove(&elt);\n            debug_assert!(v.is_some());\n        }\n        map\n    });\n}\n\n#[bench]\npub fn clone_fat_val_100_and_remove_half(b: &mut Bencher) {\n    let src = fat_val_map(100);\n    b.iter(|| {\n        let mut map = src.clone();\n        for i in (0..100).step_by(2) {\n            let v = map.remove(&i);\n            debug_assert!(v.is_some());\n        }\n        assert_eq!(map.len(), 100 / 2);\n        map\n    })\n}\n"],[2084,"#![feature(no_core)]\n#![no_core]\n\npub use core::*;\n"],[2085,"//! Internal interface for communicating between a `proc_macro` client\n//! (a proc macro crate) and a `proc_macro` server (a compiler front-end).\n//!\n//! Serialization (with C ABI buffers) and unique integer handles are employed\n//! to allow safely interfacing between two copies of `proc_macro` built\n//! (from the same source) by different compilers with potentially mismatching\n//! Rust ABIs (e.g., stage0/bin/rustc vs stage1/bin/rustc during bootstrap).\n\n#![deny(unsafe_code)]\n\nuse crate::{Delimiter, Level, LineColumn, Spacing};\nuse std::fmt;\nuse std::hash::Hash;\nuse std::marker;\nuse std::mem;\nuse std::ops::Bound;\nuse std::panic;\nuse std::sync::atomic::AtomicUsize;\nuse std::sync::Once;\nuse std::thread;\n\n/// Higher-order macro describing the server RPC API, allowing automatic\n/// generation of type-safe Rust APIs, both client-side and server-side.\n///\n/// `with_api!(MySelf, my_self, my_macro)` expands to:\n/// ```rust,ignore (pseudo-code)\n/// my_macro! {\n///     // ...\n///     Literal {\n///         // ...\n///         fn character(ch: char) -> MySelf::Literal;\n///         // ...\n///         fn span(my_self: &MySelf::Literal) -> MySelf::Span;\n///         fn set_span(my_self: &mut MySelf::Literal, span: MySelf::Span);\n///     },\n///     // ...\n/// }\n/// ```\n///\n/// The first two arguments serve to customize the arguments names\n/// and argument/return types, to enable several different usecases:\n///\n/// If `my_self` is just `self`, then each `fn` signature can be used\n/// as-is for a method. If it's anything else (`self_` in practice),\n/// then the signatures don't have a special `self` argument, and\n/// can, therefore, have a different one introduced.\n///\n/// If `MySelf` is just `Self`, then the types are only valid inside\n/// a trait or a trait impl, where the trait has associated types\n/// for each of the API types. If non-associated types are desired,\n/// a module name (`self` in practice) can be used instead of `Self`.\nmacro_rules! with_api {\n    ($S:ident, $self:ident, $m:ident) => {\n        $m! {\n            FreeFunctions {\n                fn drop($self: $S::FreeFunctions);\n                fn track_env_var(var: &str, value: Option<&str>);\n            },\n            TokenStream {\n                fn drop($self: $S::TokenStream);\n                fn clone($self: &$S::TokenStream) -> $S::TokenStream;\n                fn new() -> $S::TokenStream;\n                fn is_empty($self: &$S::TokenStream) -> bool;\n                fn from_str(src: &str) -> $S::TokenStream;\n                fn to_string($self: &$S::TokenStream) -> String;\n                fn from_token_tree(\n                    tree: TokenTree<$S::Group, $S::Punct, $S::Ident, $S::Literal>,\n                ) -> $S::TokenStream;\n                fn into_iter($self: $S::TokenStream) -> $S::TokenStreamIter;\n            },\n            TokenStreamBuilder {\n                fn drop($self: $S::TokenStreamBuilder);\n                fn new() -> $S::TokenStreamBuilder;\n                fn push($self: &mut $S::TokenStreamBuilder, stream: $S::TokenStream);\n                fn build($self: $S::TokenStreamBuilder) -> $S::TokenStream;\n            },\n            TokenStreamIter {\n                fn drop($self: $S::TokenStreamIter);\n                fn clone($self: &$S::TokenStreamIter) -> $S::TokenStreamIter;\n                fn next(\n                    $self: &mut $S::TokenStreamIter,\n                ) -> Option<TokenTree<$S::Group, $S::Punct, $S::Ident, $S::Literal>>;\n            },\n            Group {\n                fn drop($self: $S::Group);\n                fn clone($self: &$S::Group) -> $S::Group;\n                fn new(delimiter: Delimiter, stream: $S::TokenStream) -> $S::Group;\n                fn delimiter($self: &$S::Group) -> Delimiter;\n                fn stream($self: &$S::Group) -> $S::TokenStream;\n                fn span($self: &$S::Group) -> $S::Span;\n                fn span_open($self: &$S::Group) -> $S::Span;\n                fn span_close($self: &$S::Group) -> $S::Span;\n                fn set_span($self: &mut $S::Group, span: $S::Span);\n            },\n            Punct {\n                fn new(ch: char, spacing: Spacing) -> $S::Punct;\n                fn as_char($self: $S::Punct) -> char;\n                fn spacing($self: $S::Punct) -> Spacing;\n                fn span($self: $S::Punct) -> $S::Span;\n                fn with_span($self: $S::Punct, span: $S::Span) -> $S::Punct;\n            },\n            Ident {\n                fn new(string: &str, span: $S::Span, is_raw: bool) -> $S::Ident;\n                fn span($self: $S::Ident) -> $S::Span;\n                fn with_span($self: $S::Ident, span: $S::Span) -> $S::Ident;\n            },\n            Literal {\n                fn drop($self: $S::Literal);\n                fn clone($self: &$S::Literal) -> $S::Literal;\n                fn from_str(s: &str) -> Result<$S::Literal, ()>;\n                fn debug_kind($self: &$S::Literal) -> String;\n                fn symbol($self: &$S::Literal) -> String;\n                fn suffix($self: &$S::Literal) -> Option<String>;\n                fn integer(n: &str) -> $S::Literal;\n                fn typed_integer(n: &str, kind: &str) -> $S::Literal;\n                fn float(n: &str) -> $S::Literal;\n                fn f32(n: &str) -> $S::Literal;\n                fn f64(n: &str) -> $S::Literal;\n                fn string(string: &str) -> $S::Literal;\n                fn character(ch: char) -> $S::Literal;\n                fn byte_string(bytes: &[u8]) -> $S::Literal;\n                fn span($self: &$S::Literal) -> $S::Span;\n                fn set_span($self: &mut $S::Literal, span: $S::Span);\n                fn subspan(\n                    $self: &$S::Literal,\n                    start: Bound<usize>,\n                    end: Bound<usize>,\n                ) -> Option<$S::Span>;\n            },\n            SourceFile {\n                fn drop($self: $S::SourceFile);\n                fn clone($self: &$S::SourceFile) -> $S::SourceFile;\n                fn eq($self: &$S::SourceFile, other: &$S::SourceFile) -> bool;\n                fn path($self: &$S::SourceFile) -> String;\n                fn is_real($self: &$S::SourceFile) -> bool;\n            },\n            MultiSpan {\n                fn drop($self: $S::MultiSpan);\n                fn new() -> $S::MultiSpan;\n                fn push($self: &mut $S::MultiSpan, span: $S::Span);\n            },\n            Diagnostic {\n                fn drop($self: $S::Diagnostic);\n                fn new(level: Level, msg: &str, span: $S::MultiSpan) -> $S::Diagnostic;\n                fn sub(\n                    $self: &mut $S::Diagnostic,\n                    level: Level,\n                    msg: &str,\n                    span: $S::MultiSpan,\n                );\n                fn emit($self: $S::Diagnostic);\n            },\n            Span {\n                fn debug($self: $S::Span) -> String;\n                fn def_site() -> $S::Span;\n                fn call_site() -> $S::Span;\n                fn mixed_site() -> $S::Span;\n                fn source_file($self: $S::Span) -> $S::SourceFile;\n                fn parent($self: $S::Span) -> Option<$S::Span>;\n                fn source($self: $S::Span) -> $S::Span;\n                fn start($self: $S::Span) -> LineColumn;\n                fn end($self: $S::Span) -> LineColumn;\n                fn join($self: $S::Span, other: $S::Span) -> Option<$S::Span>;\n                fn resolved_at($self: $S::Span, at: $S::Span) -> $S::Span;\n                fn source_text($self: $S::Span) -> Option<String>;\n                fn save_span($self: $S::Span) -> usize;\n                fn recover_proc_macro_span(id: usize) -> $S::Span;\n            },\n        }\n    };\n}\n\n// FIXME(eddyb) this calls `encode` for each argument, but in reverse,\n// to avoid borrow conflicts from borrows started by `&mut` arguments.\nmacro_rules! reverse_encode {\n    ($writer:ident;) => {};\n    ($writer:ident; $first:ident $(, $rest:ident)*) => {\n        reverse_encode!($writer; $($rest),*);\n        $first.encode(&mut $writer, &mut ());\n    }\n}\n\n// FIXME(eddyb) this calls `decode` for each argument, but in reverse,\n// to avoid borrow conflicts from borrows started by `&mut` arguments.\nmacro_rules! reverse_decode {\n    ($reader:ident, $s:ident;) => {};\n    ($reader:ident, $s:ident; $first:ident: $first_ty:ty $(, $rest:ident: $rest_ty:ty)*) => {\n        reverse_decode!($reader, $s; $($rest: $rest_ty),*);\n        let $first = <$first_ty>::decode(&mut $reader, $s);\n    }\n}\n\n#[allow(unsafe_code)]\nmod buffer;\n#[forbid(unsafe_code)]\npub mod client;\n#[allow(unsafe_code)]\nmod closure;\n#[forbid(unsafe_code)]\nmod handle;\n#[macro_use]\n#[forbid(unsafe_code)]\nmod rpc;\n#[allow(unsafe_code)]\nmod scoped_cell;\n#[forbid(unsafe_code)]\npub mod server;\n\nuse buffer::Buffer;\npub use rpc::PanicMessage;\nuse rpc::{Decode, DecodeMut, Encode, Reader, Writer};\n\n/// An active connection between a server and a client.\n/// The server creates the bridge (`Bridge::run_server` in `server.rs`),\n/// then passes it to the client through the function pointer in the `run`\n/// field of `client::Client`. The client holds its copy of the `Bridge`\n/// in TLS during its execution (`Bridge::{enter, with}` in `client.rs`).\n#[repr(C)]\npub struct Bridge<'a> {\n    /// Reusable buffer (only `clear`-ed, never shrunk), primarily\n    /// used for making requests, but also for passing input to client.\n    cached_buffer: Buffer<u8>,\n\n    /// Server-side function that the client uses to make requests.\n    dispatch: closure::Closure<'a, Buffer<u8>, Buffer<u8>>,\n\n    /// If 'true', always invoke the default panic hook\n    force_show_panics: bool,\n}\n\nimpl<'a> !Sync for Bridge<'a> {}\nimpl<'a> !Send for Bridge<'a> {}\n\n#[forbid(unsafe_code)]\n#[allow(non_camel_case_types)]\nmod api_tags {\n    use super::rpc::{DecodeMut, Encode, Reader, Writer};\n\n    macro_rules! declare_tags {\n        ($($name:ident {\n            $(fn $method:ident($($arg:ident: $arg_ty:ty),* $(,)?) $(-> $ret_ty:ty)*;)*\n        }),* $(,)?) => {\n            $(\n                pub(super) enum $name {\n                    $($method),*\n                }\n                rpc_encode_decode!(enum $name { $($method),* });\n            )*\n\n\n            pub(super) enum Method {\n                $($name($name)),*\n            }\n            rpc_encode_decode!(enum Method { $($name(m)),* });\n        }\n    }\n    with_api!(self, self, declare_tags);\n}\n\n/// Helper to wrap associated types to allow trait impl dispatch.\n/// That is, normally a pair of impls for `T::Foo` and `T::Bar`\n/// can overlap, but if the impls are, instead, on types like\n/// `Marked<T::Foo, Foo>` and `Marked<T::Bar, Bar>`, they can't.\ntrait Mark {\n    type Unmarked;\n    fn mark(unmarked: Self::Unmarked) -> Self;\n}\n\n/// Unwrap types wrapped by `Mark::mark` (see `Mark` for details).\ntrait Unmark {\n    type Unmarked;\n    fn unmark(self) -> Self::Unmarked;\n}\n\n#[derive(Copy, Clone, PartialEq, Eq, Hash)]\nstruct Marked<T, M> {\n    value: T,\n    _marker: marker::PhantomData<M>,\n}\n\nimpl<T, M> Mark for Marked<T, M> {\n    type Unmarked = T;\n    fn mark(unmarked: Self::Unmarked) -> Self {\n        Marked { value: unmarked, _marker: marker::PhantomData }\n    }\n}\nimpl<T, M> Unmark for Marked<T, M> {\n    type Unmarked = T;\n    fn unmark(self) -> Self::Unmarked {\n        self.value\n    }\n}\nimpl<T, M> Unmark for &'a Marked<T, M> {\n    type Unmarked = &'a T;\n    fn unmark(self) -> Self::Unmarked {\n        &self.value\n    }\n}\nimpl<T, M> Unmark for &'a mut Marked<T, M> {\n    type Unmarked = &'a mut T;\n    fn unmark(self) -> Self::Unmarked {\n        &mut self.value\n    }\n}\n\nimpl<T: Mark> Mark for Option<T> {\n    type Unmarked = Option<T::Unmarked>;\n    fn mark(unmarked: Self::Unmarked) -> Self {\n        unmarked.map(T::mark)\n    }\n}\nimpl<T: Unmark> Unmark for Option<T> {\n    type Unmarked = Option<T::Unmarked>;\n    fn unmark(self) -> Self::Unmarked {\n        self.map(T::unmark)\n    }\n}\n\nimpl<T: Mark, E: Mark> Mark for Result<T, E> {\n    type Unmarked = Result<T::Unmarked, E::Unmarked>;\n    fn mark(unmarked: Self::Unmarked) -> Self {\n        unmarked.map(T::mark).map_err(E::mark)\n    }\n}\nimpl<T: Unmark, E: Unmark> Unmark for Result<T, E> {\n    type Unmarked = Result<T::Unmarked, E::Unmarked>;\n    fn unmark(self) -> Self::Unmarked {\n        self.map(T::unmark).map_err(E::unmark)\n    }\n}\n\nmacro_rules! mark_noop {\n    ($($ty:ty),* $(,)?) => {\n        $(\n            impl Mark for $ty {\n                type Unmarked = Self;\n                fn mark(unmarked: Self::Unmarked) -> Self {\n                    unmarked\n                }\n            }\n            impl Unmark for $ty {\n                type Unmarked = Self;\n                fn unmark(self) -> Self::Unmarked {\n                    self\n                }\n            }\n        )*\n    }\n}\nmark_noop! {\n    (),\n    bool,\n    char,\n    &'a [u8],\n    &'a str,\n    String,\n    usize,\n    Delimiter,\n    Level,\n    LineColumn,\n    Spacing,\n    Bound<usize>,\n}\n\nrpc_encode_decode!(\n    enum Delimiter {\n        Parenthesis,\n        Brace,\n        Bracket,\n        None,\n    }\n);\nrpc_encode_decode!(\n    enum Level {\n        Error,\n        Warning,\n        Note,\n        Help,\n    }\n);\nrpc_encode_decode!(struct LineColumn { line, column });\nrpc_encode_decode!(\n    enum Spacing {\n        Alone,\n        Joint,\n    }\n);\n\n#[derive(Clone)]\npub enum TokenTree<G, P, I, L> {\n    Group(G),\n    Punct(P),\n    Ident(I),\n    Literal(L),\n}\n\nimpl<G: Mark, P: Mark, I: Mark, L: Mark> Mark for TokenTree<G, P, I, L> {\n    type Unmarked = TokenTree<G::Unmarked, P::Unmarked, I::Unmarked, L::Unmarked>;\n    fn mark(unmarked: Self::Unmarked) -> Self {\n        match unmarked {\n            TokenTree::Group(tt) => TokenTree::Group(G::mark(tt)),\n            TokenTree::Punct(tt) => TokenTree::Punct(P::mark(tt)),\n            TokenTree::Ident(tt) => TokenTree::Ident(I::mark(tt)),\n            TokenTree::Literal(tt) => TokenTree::Literal(L::mark(tt)),\n        }\n    }\n}\nimpl<G: Unmark, P: Unmark, I: Unmark, L: Unmark> Unmark for TokenTree<G, P, I, L> {\n    type Unmarked = TokenTree<G::Unmarked, P::Unmarked, I::Unmarked, L::Unmarked>;\n    fn unmark(self) -> Self::Unmarked {\n        match self {\n            TokenTree::Group(tt) => TokenTree::Group(tt.unmark()),\n            TokenTree::Punct(tt) => TokenTree::Punct(tt.unmark()),\n            TokenTree::Ident(tt) => TokenTree::Ident(tt.unmark()),\n            TokenTree::Literal(tt) => TokenTree::Literal(tt.unmark()),\n        }\n    }\n}\n\nrpc_encode_decode!(\n    enum TokenTree<G, P, I, L> {\n        Group(tt),\n        Punct(tt),\n        Ident(tt),\n        Literal(tt),\n    }\n);\n"],[2086,"//! `Cell` variant for (scoped) existential lifetimes.\n\nuse std::cell::Cell;\nuse std::mem;\nuse std::ops::{Deref, DerefMut};\n\n/// Type lambda application, with a lifetime.\n#[allow(unused_lifetimes)]\npub trait ApplyL<'a> {\n    type Out;\n}\n\n/// Type lambda taking a lifetime, i.e., `Lifetime -> Type`.\npub trait LambdaL: for<'a> ApplyL<'a> {}\n\nimpl<T: for<'a> ApplyL<'a>> LambdaL for T {}\n\n// HACK(eddyb) work around projection limitations with a newtype\n// FIXME(#52812) replace with `&'a mut <T as ApplyL<'b>>::Out`\npub struct RefMutL<'a, 'b, T: LambdaL>(&'a mut <T as ApplyL<'b>>::Out);\n\nimpl<'a, 'b, T: LambdaL> Deref for RefMutL<'a, 'b, T> {\n    type Target = <T as ApplyL<'b>>::Out;\n    fn deref(&self) -> &Self::Target {\n        self.0\n    }\n}\n\nimpl<'a, 'b, T: LambdaL> DerefMut for RefMutL<'a, 'b, T> {\n    fn deref_mut(&mut self) -> &mut Self::Target {\n        self.0\n    }\n}\n\npub struct ScopedCell<T: LambdaL>(Cell<<T as ApplyL<'static>>::Out>);\n\nimpl<T: LambdaL> ScopedCell<T> {\n    #[rustc_allow_const_fn_unstable(const_fn)]\n    pub const fn new(value: <T as ApplyL<'static>>::Out) -> Self {\n        ScopedCell(Cell::new(value))\n    }\n\n    /// Sets the value in `self` to `replacement` while\n    /// running `f`, which gets the old value, mutably.\n    /// The old value will be restored after `f` exits, even\n    /// by panic, including modifications made to it by `f`.\n    pub fn replace<'a, R>(\n        &self,\n        replacement: <T as ApplyL<'a>>::Out,\n        f: impl for<'b, 'c> FnOnce(RefMutL<'b, 'c, T>) -> R,\n    ) -> R {\n        /// Wrapper that ensures that the cell always gets filled\n        /// (with the original state, optionally changed by `f`),\n        /// even if `f` had panicked.\n        struct PutBackOnDrop<'a, T: LambdaL> {\n            cell: &'a ScopedCell<T>,\n            value: Option<<T as ApplyL<'static>>::Out>,\n        }\n\n        impl<'a, T: LambdaL> Drop for PutBackOnDrop<'a, T> {\n            fn drop(&mut self) {\n                self.cell.0.set(self.value.take().unwrap());\n            }\n        }\n\n        let mut put_back_on_drop = PutBackOnDrop {\n            cell: self,\n            value: Some(self.0.replace(unsafe {\n                let erased = mem::transmute_copy(&replacement);\n                mem::forget(replacement);\n                erased\n            })),\n        };\n\n        f(RefMutL(put_back_on_drop.value.as_mut().unwrap()))\n    }\n\n    /// Sets the value in `self` to `value` while running `f`.\n    pub fn set<R>(&self, value: <T as ApplyL<'_>>::Out, f: impl FnOnce() -> R) -> R {\n        self.replace(value, |_| f())\n    }\n}\n"],[2087,"//! Client-side types.\n\nuse super::*;\n\nmacro_rules! define_handles {\n    (\n        'owned: $($oty:ident,)*\n        'interned: $($ity:ident,)*\n    ) => {\n        #[repr(C)]\n        #[allow(non_snake_case)]\n        pub struct HandleCounters {\n            $($oty: AtomicUsize,)*\n            $($ity: AtomicUsize,)*\n        }\n\n        impl HandleCounters {\n            // FIXME(eddyb) use a reference to the `static COUNTERS`, instead of\n            // a wrapper `fn` pointer, once `const fn` can reference `static`s.\n            extern \"C\" fn get() -> &'static Self {\n                static COUNTERS: HandleCounters = HandleCounters {\n                    $($oty: AtomicUsize::new(1),)*\n                    $($ity: AtomicUsize::new(1),)*\n                };\n                &COUNTERS\n            }\n        }\n\n        // FIXME(eddyb) generate the definition of `HandleStore` in `server.rs`.\n        #[repr(C)]\n        #[allow(non_snake_case)]\n        pub(super) struct HandleStore<S: server::Types> {\n            $($oty: handle::OwnedStore<S::$oty>,)*\n            $($ity: handle::InternedStore<S::$ity>,)*\n        }\n\n        impl<S: server::Types> HandleStore<S> {\n            pub(super) fn new(handle_counters: &'static HandleCounters) -> Self {\n                HandleStore {\n                    $($oty: handle::OwnedStore::new(&handle_counters.$oty),)*\n                    $($ity: handle::InternedStore::new(&handle_counters.$ity),)*\n                }\n            }\n        }\n\n        $(\n            #[repr(C)]\n            pub(crate) struct $oty(handle::Handle);\n            impl !Send for $oty {}\n            impl !Sync for $oty {}\n\n            // Forward `Drop::drop` to the inherent `drop` method.\n            impl Drop for $oty {\n                fn drop(&mut self) {\n                    $oty(self.0).drop();\n                }\n            }\n\n            impl<S> Encode<S> for $oty {\n                fn encode(self, w: &mut Writer, s: &mut S) {\n                    let handle = self.0;\n                    mem::forget(self);\n                    handle.encode(w, s);\n                }\n            }\n\n            impl<S: server::Types> DecodeMut<'_, '_, HandleStore<server::MarkedTypes<S>>>\n                for Marked<S::$oty, $oty>\n            {\n                fn decode(r: &mut Reader<'_>, s: &mut HandleStore<server::MarkedTypes<S>>) -> Self {\n                    s.$oty.take(handle::Handle::decode(r, &mut ()))\n                }\n            }\n\n            impl<S> Encode<S> for &$oty {\n                fn encode(self, w: &mut Writer, s: &mut S) {\n                    self.0.encode(w, s);\n                }\n            }\n\n            impl<S: server::Types> Decode<'_, 's, HandleStore<server::MarkedTypes<S>>>\n                for &'s Marked<S::$oty, $oty>\n            {\n                fn decode(r: &mut Reader<'_>, s: &'s HandleStore<server::MarkedTypes<S>>) -> Self {\n                    &s.$oty[handle::Handle::decode(r, &mut ())]\n                }\n            }\n\n            impl<S> Encode<S> for &mut $oty {\n                fn encode(self, w: &mut Writer, s: &mut S) {\n                    self.0.encode(w, s);\n                }\n            }\n\n            impl<S: server::Types> DecodeMut<'_, 's, HandleStore<server::MarkedTypes<S>>>\n                for &'s mut Marked<S::$oty, $oty>\n            {\n                fn decode(\n                    r: &mut Reader<'_>,\n                    s: &'s mut HandleStore<server::MarkedTypes<S>>\n                ) -> Self {\n                    &mut s.$oty[handle::Handle::decode(r, &mut ())]\n                }\n            }\n\n            impl<S: server::Types> Encode<HandleStore<server::MarkedTypes<S>>>\n                for Marked<S::$oty, $oty>\n            {\n                fn encode(self, w: &mut Writer, s: &mut HandleStore<server::MarkedTypes<S>>) {\n                    s.$oty.alloc(self).encode(w, s);\n                }\n            }\n\n            impl<S> DecodeMut<'_, '_, S> for $oty {\n                fn decode(r: &mut Reader<'_>, s: &mut S) -> Self {\n                    $oty(handle::Handle::decode(r, s))\n                }\n            }\n        )*\n\n        $(\n            #[repr(C)]\n            #[derive(Copy, Clone, PartialEq, Eq, Hash)]\n            pub(crate) struct $ity(handle::Handle);\n            impl !Send for $ity {}\n            impl !Sync for $ity {}\n\n            impl<S> Encode<S> for $ity {\n                fn encode(self, w: &mut Writer, s: &mut S) {\n                    self.0.encode(w, s);\n                }\n            }\n\n            impl<S: server::Types> DecodeMut<'_, '_, HandleStore<server::MarkedTypes<S>>>\n                for Marked<S::$ity, $ity>\n            {\n                fn decode(r: &mut Reader<'_>, s: &mut HandleStore<server::MarkedTypes<S>>) -> Self {\n                    s.$ity.copy(handle::Handle::decode(r, &mut ()))\n                }\n            }\n\n            impl<S: server::Types> Encode<HandleStore<server::MarkedTypes<S>>>\n                for Marked<S::$ity, $ity>\n            {\n                fn encode(self, w: &mut Writer, s: &mut HandleStore<server::MarkedTypes<S>>) {\n                    s.$ity.alloc(self).encode(w, s);\n                }\n            }\n\n            impl<S> DecodeMut<'_, '_, S> for $ity {\n                fn decode(r: &mut Reader<'_>, s: &mut S) -> Self {\n                    $ity(handle::Handle::decode(r, s))\n                }\n            }\n        )*\n    }\n}\ndefine_handles! {\n    'owned:\n    FreeFunctions,\n    TokenStream,\n    TokenStreamBuilder,\n    TokenStreamIter,\n    Group,\n    Literal,\n    SourceFile,\n    MultiSpan,\n    Diagnostic,\n\n    'interned:\n    Punct,\n    Ident,\n    Span,\n}\n\n// FIXME(eddyb) generate these impls by pattern-matching on the\n// names of methods - also could use the presence of `fn drop`\n// to distinguish between 'owned and 'interned, above.\n// Alternatively, special 'modes\" could be listed of types in with_api\n// instead of pattern matching on methods, here and in server decl.\n\nimpl Clone for TokenStream {\n    fn clone(&self) -> Self {\n        self.clone()\n    }\n}\n\nimpl Clone for TokenStreamIter {\n    fn clone(&self) -> Self {\n        self.clone()\n    }\n}\n\nimpl Clone for Group {\n    fn clone(&self) -> Self {\n        self.clone()\n    }\n}\n\nimpl Clone for Literal {\n    fn clone(&self) -> Self {\n        self.clone()\n    }\n}\n\nimpl fmt::Debug for Literal {\n    fn fmt(&self, f: &mut fmt::Formatter<'_>) -> fmt::Result {\n        f.debug_struct(\"Literal\")\n            // format the kind without quotes, as in `kind: Float`\n            .field(\"kind\", &format_args!(\"{}\", &self.debug_kind()))\n            .field(\"symbol\", &self.symbol())\n            // format `Some(\"...\")` on one line even in {:#?} mode\n            .field(\"suffix\", &format_args!(\"{:?}\", &self.suffix()))\n            .field(\"span\", &self.span())\n            .finish()\n    }\n}\n\nimpl Clone for SourceFile {\n    fn clone(&self) -> Self {\n        self.clone()\n    }\n}\n\nimpl fmt::Debug for Span {\n    fn fmt(&self, f: &mut fmt::Formatter<'_>) -> fmt::Result {\n        f.write_str(&self.debug())\n    }\n}\n\nmacro_rules! define_client_side {\n    ($($name:ident {\n        $(fn $method:ident($($arg:ident: $arg_ty:ty),* $(,)?) $(-> $ret_ty:ty)*;)*\n    }),* $(,)?) => {\n        $(impl $name {\n            $(pub(crate) fn $method($($arg: $arg_ty),*) $(-> $ret_ty)* {\n                Bridge::with(|bridge| {\n                    let mut b = bridge.cached_buffer.take();\n\n                    b.clear();\n                    api_tags::Method::$name(api_tags::$name::$method).encode(&mut b, &mut ());\n                    reverse_encode!(b; $($arg),*);\n\n                    b = bridge.dispatch.call(b);\n\n                    let r = Result::<_, PanicMessage>::decode(&mut &b[..], &mut ());\n\n                    bridge.cached_buffer = b;\n\n                    r.unwrap_or_else(|e| panic::resume_unwind(e.into()))\n                })\n            })*\n        })*\n    }\n}\nwith_api!(self, self, define_client_side);\n\nenum BridgeState<'a> {\n    /// No server is currently connected to this client.\n    NotConnected,\n\n    /// A server is connected and available for requests.\n    Connected(Bridge<'a>),\n\n    /// Access to the bridge is being exclusively acquired\n    /// (e.g., during `BridgeState::with`).\n    InUse,\n}\n\nenum BridgeStateL {}\n\nimpl<'a> scoped_cell::ApplyL<'a> for BridgeStateL {\n    type Out = BridgeState<'a>;\n}\n\nthread_local! {\n    static BRIDGE_STATE: scoped_cell::ScopedCell<BridgeStateL> =\n        scoped_cell::ScopedCell::new(BridgeState::NotConnected);\n}\n\nimpl BridgeState<'_> {\n    /// Take exclusive control of the thread-local\n    /// `BridgeState`, and pass it to `f`, mutably.\n    /// The state will be restored after `f` exits, even\n    /// by panic, including modifications made to it by `f`.\n    ///\n    /// N.B., while `f` is running, the thread-local state\n    /// is `BridgeState::InUse`.\n    fn with<R>(f: impl FnOnce(&mut BridgeState<'_>) -> R) -> R {\n        BRIDGE_STATE.with(|state| {\n            state.replace(BridgeState::InUse, |mut state| {\n                // FIXME(#52812) pass `f` directly to `replace` when `RefMutL` is gone\n                f(&mut *state)\n            })\n        })\n    }\n}\n\nimpl Bridge<'_> {\n    pub(crate) fn is_available() -> bool {\n        BridgeState::with(|state| match state {\n            BridgeState::Connected(_) | BridgeState::InUse => true,\n            BridgeState::NotConnected => false,\n        })\n    }\n\n    fn enter<R>(self, f: impl FnOnce() -> R) -> R {\n        let force_show_panics = self.force_show_panics;\n        // Hide the default panic output within `proc_macro` expansions.\n        // NB. the server can't do this because it may use a different libstd.\n        static HIDE_PANICS_DURING_EXPANSION: Once = Once::new();\n        HIDE_PANICS_DURING_EXPANSION.call_once(|| {\n            let prev = panic::take_hook();\n            panic::set_hook(Box::new(move |info| {\n                let show = BridgeState::with(|state| match state {\n                    BridgeState::NotConnected => true,\n                    BridgeState::Connected(_) | BridgeState::InUse => force_show_panics,\n                });\n                if show {\n                    prev(info)\n                }\n            }));\n        });\n\n        BRIDGE_STATE.with(|state| state.set(BridgeState::Connected(self), f))\n    }\n\n    fn with<R>(f: impl FnOnce(&mut Bridge<'_>) -> R) -> R {\n        BridgeState::with(|state| match state {\n            BridgeState::NotConnected => {\n                panic!(\"procedural macro API is used outside of a procedural macro\");\n            }\n            BridgeState::InUse => {\n                panic!(\"procedural macro API is used while it's already in use\");\n            }\n            BridgeState::Connected(bridge) => f(bridge),\n        })\n    }\n}\n\n/// A client-side \"global object\" (usually a function pointer),\n/// which may be using a different `proc_macro` from the one\n/// used by the server, but can be interacted with compatibly.\n///\n/// N.B., `F` must have FFI-friendly memory layout (e.g., a pointer).\n/// The call ABI of function pointers used for `F` doesn't\n/// need to match between server and client, since it's only\n/// passed between them and (eventually) called by the client.\n#[repr(C)]\n#[derive(Copy, Clone)]\npub struct Client<F> {\n    // FIXME(eddyb) use a reference to the `static COUNTERS`, instead of\n    // a wrapper `fn` pointer, once `const fn` can reference `static`s.\n    pub(super) get_handle_counters: extern \"C\" fn() -> &'static HandleCounters,\n    pub(super) run: extern \"C\" fn(Bridge<'_>, F) -> Buffer<u8>,\n    pub(super) f: F,\n}\n\n/// Client-side helper for handling client panics, entering the bridge,\n/// deserializing input and serializing output.\n// FIXME(eddyb) maybe replace `Bridge::enter` with this?\nfn run_client<A: for<'a, 's> DecodeMut<'a, 's, ()>, R: Encode<()>>(\n    mut bridge: Bridge<'_>,\n    f: impl FnOnce(A) -> R,\n) -> Buffer<u8> {\n    // The initial `cached_buffer` contains the input.\n    let mut b = bridge.cached_buffer.take();\n\n    panic::catch_unwind(panic::AssertUnwindSafe(|| {\n        bridge.enter(|| {\n            let reader = &mut &b[..];\n            let input = A::decode(reader, &mut ());\n\n            // Put the `cached_buffer` back in the `Bridge`, for requests.\n            Bridge::with(|bridge| bridge.cached_buffer = b.take());\n\n            let output = f(input);\n\n            // Take the `cached_buffer` back out, for the output value.\n            b = Bridge::with(|bridge| bridge.cached_buffer.take());\n\n            // HACK(eddyb) Separate encoding a success value (`Ok(output)`)\n            // from encoding a panic (`Err(e: PanicMessage)`) to avoid\n            // having handles outside the `bridge.enter(|| ...)` scope, and\n            // to catch panics that could happen while encoding the success.\n            //\n            // Note that panics should be impossible beyond this point, but\n            // this is defensively trying to avoid any accidental panicking\n            // reaching the `extern \"C\"` (which should `abort` but may not\n            // at the moment, so this is also potentially preventing UB).\n            b.clear();\n            Ok::<_, ()>(output).encode(&mut b, &mut ());\n        })\n    }))\n    .map_err(PanicMessage::from)\n    .unwrap_or_else(|e| {\n        b.clear();\n        Err::<(), _>(e).encode(&mut b, &mut ());\n    });\n    b\n}\n\nimpl Client<fn(crate::TokenStream) -> crate::TokenStream> {\n    #[rustc_allow_const_fn_unstable(const_fn)]\n    pub const fn expand1(f: fn(crate::TokenStream) -> crate::TokenStream) -> Self {\n        extern \"C\" fn run(\n            bridge: Bridge<'_>,\n            f: impl FnOnce(crate::TokenStream) -> crate::TokenStream,\n        ) -> Buffer<u8> {\n            run_client(bridge, |input| f(crate::TokenStream(input)).0)\n        }\n        Client { get_handle_counters: HandleCounters::get, run, f }\n    }\n}\n\nimpl Client<fn(crate::TokenStream, crate::TokenStream) -> crate::TokenStream> {\n    #[rustc_allow_const_fn_unstable(const_fn)]\n    pub const fn expand2(\n        f: fn(crate::TokenStream, crate::TokenStream) -> crate::TokenStream,\n    ) -> Self {\n        extern \"C\" fn run(\n            bridge: Bridge<'_>,\n            f: impl FnOnce(crate::TokenStream, crate::TokenStream) -> crate::TokenStream,\n        ) -> Buffer<u8> {\n            run_client(bridge, |(input, input2)| {\n                f(crate::TokenStream(input), crate::TokenStream(input2)).0\n            })\n        }\n        Client { get_handle_counters: HandleCounters::get, run, f }\n    }\n}\n\n#[repr(C)]\n#[derive(Copy, Clone)]\npub enum ProcMacro {\n    CustomDerive {\n        trait_name: &'static str,\n        attributes: &'static [&'static str],\n        client: Client<fn(crate::TokenStream) -> crate::TokenStream>,\n    },\n\n    Attr {\n        name: &'static str,\n        client: Client<fn(crate::TokenStream, crate::TokenStream) -> crate::TokenStream>,\n    },\n\n    Bang {\n        name: &'static str,\n        client: Client<fn(crate::TokenStream) -> crate::TokenStream>,\n    },\n}\n\nimpl ProcMacro {\n    pub fn name(&self) -> &'static str {\n        match self {\n            ProcMacro::CustomDerive { trait_name, .. } => trait_name,\n            ProcMacro::Attr { name, .. } => name,\n            ProcMacro::Bang { name, .. } => name,\n        }\n    }\n\n    #[rustc_allow_const_fn_unstable(const_fn)]\n    pub const fn custom_derive(\n        trait_name: &'static str,\n        attributes: &'static [&'static str],\n        expand: fn(crate::TokenStream) -> crate::TokenStream,\n    ) -> Self {\n        ProcMacro::CustomDerive { trait_name, attributes, client: Client::expand1(expand) }\n    }\n\n    #[rustc_allow_const_fn_unstable(const_fn)]\n    pub const fn attr(\n        name: &'static str,\n        expand: fn(crate::TokenStream, crate::TokenStream) -> crate::TokenStream,\n    ) -> Self {\n        ProcMacro::Attr { name, client: Client::expand2(expand) }\n    }\n\n    #[rustc_allow_const_fn_unstable(const_fn)]\n    pub const fn bang(\n        name: &'static str,\n        expand: fn(crate::TokenStream) -> crate::TokenStream,\n    ) -> Self {\n        ProcMacro::Bang { name, client: Client::expand1(expand) }\n    }\n}\n"],[2088,"//! Serialization for client-server communication.\n\nuse std::any::Any;\nuse std::char;\nuse std::io::Write;\nuse std::num::NonZeroU32;\nuse std::ops::Bound;\nuse std::str;\n\npub(super) type Writer = super::buffer::Buffer<u8>;\n\npub(super) trait Encode<S>: Sized {\n    fn encode(self, w: &mut Writer, s: &mut S);\n}\n\npub(super) type Reader<'a> = &'a [u8];\n\npub(super) trait Decode<'a, 's, S>: Sized {\n    fn decode(r: &mut Reader<'a>, s: &'s S) -> Self;\n}\n\npub(super) trait DecodeMut<'a, 's, S>: Sized {\n    fn decode(r: &mut Reader<'a>, s: &'s mut S) -> Self;\n}\n\nmacro_rules! rpc_encode_decode {\n    (le $ty:ty) => {\n        impl<S> Encode<S> for $ty {\n            fn encode(self, w: &mut Writer, _: &mut S) {\n                w.extend_from_array(&self.to_le_bytes());\n            }\n        }\n\n        impl<S> DecodeMut<'_, '_, S> for $ty {\n            fn decode(r: &mut Reader<'_>, _: &mut S) -> Self {\n                const N: usize = ::std::mem::size_of::<$ty>();\n\n                let mut bytes = [0; N];\n                bytes.copy_from_slice(&r[..N]);\n                *r = &r[N..];\n\n                Self::from_le_bytes(bytes)\n            }\n        }\n    };\n    (struct $name:ident { $($field:ident),* $(,)? }) => {\n        impl<S> Encode<S> for $name {\n            fn encode(self, w: &mut Writer, s: &mut S) {\n                $(self.$field.encode(w, s);)*\n            }\n        }\n\n        impl<S> DecodeMut<'_, '_, S> for $name {\n            fn decode(r: &mut Reader<'_>, s: &mut S) -> Self {\n                $name {\n                    $($field: DecodeMut::decode(r, s)),*\n                }\n            }\n        }\n    };\n    (enum $name:ident $(<$($T:ident),+>)? { $($variant:ident $(($field:ident))*),* $(,)? }) => {\n        impl<S, $($($T: Encode<S>),+)?> Encode<S> for $name $(<$($T),+>)? {\n            fn encode(self, w: &mut Writer, s: &mut S) {\n                // HACK(eddyb): `Tag` enum duplicated between the\n                // two impls as there's no other place to stash it.\n                #[allow(non_upper_case_globals)]\n                mod tag {\n                    #[repr(u8)] enum Tag { $($variant),* }\n\n                    $(pub const $variant: u8 = Tag::$variant as u8;)*\n                }\n\n                match self {\n                    $($name::$variant $(($field))* => {\n                        tag::$variant.encode(w, s);\n                        $($field.encode(w, s);)*\n                    })*\n                }\n            }\n        }\n\n        impl<S, $($($T: for<'s> DecodeMut<'a, 's, S>),+)?> DecodeMut<'a, '_, S>\n            for $name $(<$($T),+>)?\n        {\n            fn decode(r: &mut Reader<'a>, s: &mut S) -> Self {\n                // HACK(eddyb): `Tag` enum duplicated between the\n                // two impls as there's no other place to stash it.\n                #[allow(non_upper_case_globals)]\n                mod tag {\n                    #[repr(u8)] enum Tag { $($variant),* }\n\n                    $(pub const $variant: u8 = Tag::$variant as u8;)*\n                }\n\n                match u8::decode(r, s) {\n                    $(tag::$variant => {\n                        $(let $field = DecodeMut::decode(r, s);)*\n                        $name::$variant $(($field))*\n                    })*\n                    _ => unreachable!(),\n                }\n            }\n        }\n    }\n}\n\nimpl<S> Encode<S> for () {\n    fn encode(self, _: &mut Writer, _: &mut S) {}\n}\n\nimpl<S> DecodeMut<'_, '_, S> for () {\n    fn decode(_: &mut Reader<'_>, _: &mut S) -> Self {}\n}\n\nimpl<S> Encode<S> for u8 {\n    fn encode(self, w: &mut Writer, _: &mut S) {\n        w.push(self);\n    }\n}\n\nimpl<S> DecodeMut<'_, '_, S> for u8 {\n    fn decode(r: &mut Reader<'_>, _: &mut S) -> Self {\n        let x = r[0];\n        *r = &r[1..];\n        x\n    }\n}\n\nrpc_encode_decode!(le u32);\nrpc_encode_decode!(le usize);\n\nimpl<S> Encode<S> for bool {\n    fn encode(self, w: &mut Writer, s: &mut S) {\n        (self as u8).encode(w, s);\n    }\n}\n\nimpl<S> DecodeMut<'_, '_, S> for bool {\n    fn decode(r: &mut Reader<'_>, s: &mut S) -> Self {\n        match u8::decode(r, s) {\n            0 => false,\n            1 => true,\n            _ => unreachable!(),\n        }\n    }\n}\n\nimpl<S> Encode<S> for char {\n    fn encode(self, w: &mut Writer, s: &mut S) {\n        (self as u32).encode(w, s);\n    }\n}\n\nimpl<S> DecodeMut<'_, '_, S> for char {\n    fn decode(r: &mut Reader<'_>, s: &mut S) -> Self {\n        char::from_u32(u32::decode(r, s)).unwrap()\n    }\n}\n\nimpl<S> Encode<S> for NonZeroU32 {\n    fn encode(self, w: &mut Writer, s: &mut S) {\n        self.get().encode(w, s);\n    }\n}\n\nimpl<S> DecodeMut<'_, '_, S> for NonZeroU32 {\n    fn decode(r: &mut Reader<'_>, s: &mut S) -> Self {\n        Self::new(u32::decode(r, s)).unwrap()\n    }\n}\n\nimpl<S, A: Encode<S>, B: Encode<S>> Encode<S> for (A, B) {\n    fn encode(self, w: &mut Writer, s: &mut S) {\n        self.0.encode(w, s);\n        self.1.encode(w, s);\n    }\n}\n\nimpl<S, A: for<'s> DecodeMut<'a, 's, S>, B: for<'s> DecodeMut<'a, 's, S>> DecodeMut<'a, '_, S>\n    for (A, B)\n{\n    fn decode(r: &mut Reader<'a>, s: &mut S) -> Self {\n        (DecodeMut::decode(r, s), DecodeMut::decode(r, s))\n    }\n}\n\nrpc_encode_decode!(\n    enum Bound<T> {\n        Included(x),\n        Excluded(x),\n        Unbounded,\n    }\n);\n\nrpc_encode_decode!(\n    enum Option<T> {\n        None,\n        Some(x),\n    }\n);\n\nrpc_encode_decode!(\n    enum Result<T, E> {\n        Ok(x),\n        Err(e),\n    }\n);\n\nimpl<S> Encode<S> for &[u8] {\n    fn encode(self, w: &mut Writer, s: &mut S) {\n        self.len().encode(w, s);\n        w.write_all(self).unwrap();\n    }\n}\n\nimpl<S> DecodeMut<'a, '_, S> for &'a [u8] {\n    fn decode(r: &mut Reader<'a>, s: &mut S) -> Self {\n        let len = usize::decode(r, s);\n        let xs = &r[..len];\n        *r = &r[len..];\n        xs\n    }\n}\n\nimpl<S> Encode<S> for &str {\n    fn encode(self, w: &mut Writer, s: &mut S) {\n        self.as_bytes().encode(w, s);\n    }\n}\n\nimpl<S> DecodeMut<'a, '_, S> for &'a str {\n    fn decode(r: &mut Reader<'a>, s: &mut S) -> Self {\n        str::from_utf8(<&[u8]>::decode(r, s)).unwrap()\n    }\n}\n\nimpl<S> Encode<S> for String {\n    fn encode(self, w: &mut Writer, s: &mut S) {\n        self[..].encode(w, s);\n    }\n}\n\nimpl<S> DecodeMut<'_, '_, S> for String {\n    fn decode(r: &mut Reader<'_>, s: &mut S) -> Self {\n        <&str>::decode(r, s).to_string()\n    }\n}\n\n/// Simplified version of panic payloads, ignoring\n/// types other than `&'static str` and `String`.\npub enum PanicMessage {\n    StaticStr(&'static str),\n    String(String),\n    Unknown,\n}\n\nimpl From<Box<dyn Any + Send>> for PanicMessage {\n    fn from(payload: Box<dyn Any + Send + 'static>) -> Self {\n        if let Some(s) = payload.downcast_ref::<&'static str>() {\n            return PanicMessage::StaticStr(s);\n        }\n        if let Ok(s) = payload.downcast::<String>() {\n            return PanicMessage::String(*s);\n        }\n        PanicMessage::Unknown\n    }\n}\n\nimpl Into<Box<dyn Any + Send>> for PanicMessage {\n    fn into(self) -> Box<dyn Any + Send> {\n        match self {\n            PanicMessage::StaticStr(s) => Box::new(s),\n            PanicMessage::String(s) => Box::new(s),\n            PanicMessage::Unknown => {\n                struct UnknownPanicMessage;\n                Box::new(UnknownPanicMessage)\n            }\n        }\n    }\n}\n\nimpl PanicMessage {\n    pub fn as_str(&self) -> Option<&str> {\n        match self {\n            PanicMessage::StaticStr(s) => Some(s),\n            PanicMessage::String(s) => Some(s),\n            PanicMessage::Unknown => None,\n        }\n    }\n}\n\nimpl<S> Encode<S> for PanicMessage {\n    fn encode(self, w: &mut Writer, s: &mut S) {\n        self.as_str().encode(w, s);\n    }\n}\n\nimpl<S> DecodeMut<'_, '_, S> for PanicMessage {\n    fn decode(r: &mut Reader<'_>, s: &mut S) -> Self {\n        match Option::<String>::decode(r, s) {\n            Some(s) => PanicMessage::String(s),\n            None => PanicMessage::Unknown,\n        }\n    }\n}\n"],[2089,"//! Server-side traits.\n\nuse super::*;\n\n// FIXME(eddyb) generate the definition of `HandleStore` in `server.rs`.\nuse super::client::HandleStore;\n\n/// Declare an associated item of one of the traits below, optionally\n/// adjusting it (i.e., adding bounds to types and default bodies to methods).\nmacro_rules! associated_item {\n    (type FreeFunctions) =>\n        (type FreeFunctions: 'static;);\n    (type TokenStream) =>\n        (type TokenStream: 'static + Clone;);\n    (type TokenStreamBuilder) =>\n        (type TokenStreamBuilder: 'static;);\n    (type TokenStreamIter) =>\n        (type TokenStreamIter: 'static + Clone;);\n    (type Group) =>\n        (type Group: 'static + Clone;);\n    (type Punct) =>\n        (type Punct: 'static + Copy + Eq + Hash;);\n    (type Ident) =>\n        (type Ident: 'static + Copy + Eq + Hash;);\n    (type Literal) =>\n        (type Literal: 'static + Clone;);\n    (type SourceFile) =>\n        (type SourceFile: 'static + Clone;);\n    (type MultiSpan) =>\n        (type MultiSpan: 'static;);\n    (type Diagnostic) =>\n        (type Diagnostic: 'static;);\n    (type Span) =>\n        (type Span: 'static + Copy + Eq + Hash;);\n    (fn drop(&mut self, $arg:ident: $arg_ty:ty)) =>\n        (fn drop(&mut self, $arg: $arg_ty) { mem::drop($arg) });\n    (fn clone(&mut self, $arg:ident: $arg_ty:ty) -> $ret_ty:ty) =>\n        (fn clone(&mut self, $arg: $arg_ty) -> $ret_ty { $arg.clone() });\n    ($($item:tt)*) => ($($item)*;)\n}\n\nmacro_rules! declare_server_traits {\n    ($($name:ident {\n        $(fn $method:ident($($arg:ident: $arg_ty:ty),* $(,)?) $(-> $ret_ty:ty)?;)*\n    }),* $(,)?) => {\n        pub trait Types {\n            $(associated_item!(type $name);)*\n        }\n\n        $(pub trait $name: Types {\n            $(associated_item!(fn $method(&mut self, $($arg: $arg_ty),*) $(-> $ret_ty)?);)*\n        })*\n\n        pub trait Server: Types $(+ $name)* {}\n        impl<S: Types $(+ $name)*> Server for S {}\n    }\n}\nwith_api!(Self, self_, declare_server_traits);\n\npub(super) struct MarkedTypes<S: Types>(S);\n\nmacro_rules! define_mark_types_impls {\n    ($($name:ident {\n        $(fn $method:ident($($arg:ident: $arg_ty:ty),* $(,)?) $(-> $ret_ty:ty)?;)*\n    }),* $(,)?) => {\n        impl<S: Types> Types for MarkedTypes<S> {\n            $(type $name = Marked<S::$name, client::$name>;)*\n        }\n\n        $(impl<S: $name> $name for MarkedTypes<S> {\n            $(fn $method(&mut self, $($arg: $arg_ty),*) $(-> $ret_ty)? {\n                <_>::mark($name::$method(&mut self.0, $($arg.unmark()),*))\n            })*\n        })*\n    }\n}\nwith_api!(Self, self_, define_mark_types_impls);\n\nstruct Dispatcher<S: Types> {\n    handle_store: HandleStore<S>,\n    server: S,\n}\n\nmacro_rules! define_dispatcher_impl {\n    ($($name:ident {\n        $(fn $method:ident($($arg:ident: $arg_ty:ty),* $(,)?) $(-> $ret_ty:ty)?;)*\n    }),* $(,)?) => {\n        // FIXME(eddyb) `pub` only for `ExecutionStrategy` below.\n        pub trait DispatcherTrait {\n            // HACK(eddyb) these are here to allow `Self::$name` to work below.\n            $(type $name;)*\n            fn dispatch(&mut self, b: Buffer<u8>) -> Buffer<u8>;\n        }\n\n        impl<S: Server> DispatcherTrait for Dispatcher<MarkedTypes<S>> {\n            $(type $name = <MarkedTypes<S> as Types>::$name;)*\n            fn dispatch(&mut self, mut b: Buffer<u8>) -> Buffer<u8> {\n                let Dispatcher { handle_store, server } = self;\n\n                let mut reader = &b[..];\n                match api_tags::Method::decode(&mut reader, &mut ()) {\n                    $(api_tags::Method::$name(m) => match m {\n                        $(api_tags::$name::$method => {\n                            let mut call_method = || {\n                                reverse_decode!(reader, handle_store; $($arg: $arg_ty),*);\n                                $name::$method(server, $($arg),*)\n                            };\n                            // HACK(eddyb) don't use `panic::catch_unwind` in a panic.\n                            // If client and server happen to use the same `libstd`,\n                            // `catch_unwind` asserts that the panic counter was 0,\n                            // even when the closure passed to it didn't panic.\n                            let r = if thread::panicking() {\n                                Ok(call_method())\n                            } else {\n                                panic::catch_unwind(panic::AssertUnwindSafe(call_method))\n                                    .map_err(PanicMessage::from)\n                            };\n\n                            b.clear();\n                            r.encode(&mut b, handle_store);\n                        })*\n                    }),*\n                }\n                b\n            }\n        }\n    }\n}\nwith_api!(Self, self_, define_dispatcher_impl);\n\npub trait ExecutionStrategy {\n    fn run_bridge_and_client<D: Copy + Send + 'static>(\n        &self,\n        dispatcher: &mut impl DispatcherTrait,\n        input: Buffer<u8>,\n        run_client: extern \"C\" fn(Bridge<'_>, D) -> Buffer<u8>,\n        client_data: D,\n        force_show_panics: bool,\n    ) -> Buffer<u8>;\n}\n\npub struct SameThread;\n\nimpl ExecutionStrategy for SameThread {\n    fn run_bridge_and_client<D: Copy + Send + 'static>(\n        &self,\n        dispatcher: &mut impl DispatcherTrait,\n        input: Buffer<u8>,\n        run_client: extern \"C\" fn(Bridge<'_>, D) -> Buffer<u8>,\n        client_data: D,\n        force_show_panics: bool,\n    ) -> Buffer<u8> {\n        let mut dispatch = |b| dispatcher.dispatch(b);\n\n        run_client(\n            Bridge { cached_buffer: input, dispatch: (&mut dispatch).into(), force_show_panics },\n            client_data,\n        )\n    }\n}\n\n// NOTE(eddyb) Two implementations are provided, the second one is a bit\n// faster but neither is anywhere near as fast as same-thread execution.\n\npub struct CrossThread1;\n\nimpl ExecutionStrategy for CrossThread1 {\n    fn run_bridge_and_client<D: Copy + Send + 'static>(\n        &self,\n        dispatcher: &mut impl DispatcherTrait,\n        input: Buffer<u8>,\n        run_client: extern \"C\" fn(Bridge<'_>, D) -> Buffer<u8>,\n        client_data: D,\n        force_show_panics: bool,\n    ) -> Buffer<u8> {\n        use std::sync::mpsc::channel;\n\n        let (req_tx, req_rx) = channel();\n        let (res_tx, res_rx) = channel();\n\n        let join_handle = thread::spawn(move || {\n            let mut dispatch = |b| {\n                req_tx.send(b).unwrap();\n                res_rx.recv().unwrap()\n            };\n\n            run_client(\n                Bridge {\n                    cached_buffer: input,\n                    dispatch: (&mut dispatch).into(),\n                    force_show_panics,\n                },\n                client_data,\n            )\n        });\n\n        for b in req_rx {\n            res_tx.send(dispatcher.dispatch(b)).unwrap();\n        }\n\n        join_handle.join().unwrap()\n    }\n}\n\npub struct CrossThread2;\n\nimpl ExecutionStrategy for CrossThread2 {\n    fn run_bridge_and_client<D: Copy + Send + 'static>(\n        &self,\n        dispatcher: &mut impl DispatcherTrait,\n        input: Buffer<u8>,\n        run_client: extern \"C\" fn(Bridge<'_>, D) -> Buffer<u8>,\n        client_data: D,\n        force_show_panics: bool,\n    ) -> Buffer<u8> {\n        use std::sync::{Arc, Mutex};\n\n        enum State<T> {\n            Req(T),\n            Res(T),\n        }\n\n        let mut state = Arc::new(Mutex::new(State::Res(Buffer::new())));\n\n        let server_thread = thread::current();\n        let state2 = state.clone();\n        let join_handle = thread::spawn(move || {\n            let mut dispatch = |b| {\n                *state2.lock().unwrap() = State::Req(b);\n                server_thread.unpark();\n                loop {\n                    thread::park();\n                    if let State::Res(b) = &mut *state2.lock().unwrap() {\n                        break b.take();\n                    }\n                }\n            };\n\n            let r = run_client(\n                Bridge {\n                    cached_buffer: input,\n                    dispatch: (&mut dispatch).into(),\n                    force_show_panics,\n                },\n                client_data,\n            );\n\n            // Wake up the server so it can exit the dispatch loop.\n            drop(state2);\n            server_thread.unpark();\n\n            r\n        });\n\n        // Check whether `state2` was dropped, to know when to stop.\n        while Arc::get_mut(&mut state).is_none() {\n            thread::park();\n            let mut b = match &mut *state.lock().unwrap() {\n                State::Req(b) => b.take(),\n                _ => continue,\n            };\n            b = dispatcher.dispatch(b.take());\n            *state.lock().unwrap() = State::Res(b);\n            join_handle.thread().unpark();\n        }\n\n        join_handle.join().unwrap()\n    }\n}\n\nfn run_server<\n    S: Server,\n    I: Encode<HandleStore<MarkedTypes<S>>>,\n    O: for<'a, 's> DecodeMut<'a, 's, HandleStore<MarkedTypes<S>>>,\n    D: Copy + Send + 'static,\n>(\n    strategy: &impl ExecutionStrategy,\n    handle_counters: &'static client::HandleCounters,\n    server: S,\n    input: I,\n    run_client: extern \"C\" fn(Bridge<'_>, D) -> Buffer<u8>,\n    client_data: D,\n    force_show_panics: bool,\n) -> Result<O, PanicMessage> {\n    let mut dispatcher =\n        Dispatcher { handle_store: HandleStore::new(handle_counters), server: MarkedTypes(server) };\n\n    let mut b = Buffer::new();\n    input.encode(&mut b, &mut dispatcher.handle_store);\n\n    b = strategy.run_bridge_and_client(\n        &mut dispatcher,\n        b,\n        run_client,\n        client_data,\n        force_show_panics,\n    );\n\n    Result::decode(&mut &b[..], &mut dispatcher.handle_store)\n}\n\nimpl client::Client<fn(crate::TokenStream) -> crate::TokenStream> {\n    pub fn run<S: Server>(\n        &self,\n        strategy: &impl ExecutionStrategy,\n        server: S,\n        input: S::TokenStream,\n        force_show_panics: bool,\n    ) -> Result<S::TokenStream, PanicMessage> {\n        let client::Client { get_handle_counters, run, f } = *self;\n        run_server(\n            strategy,\n            get_handle_counters(),\n            server,\n            <MarkedTypes<S> as Types>::TokenStream::mark(input),\n            run,\n            f,\n            force_show_panics,\n        )\n        .map(<MarkedTypes<S> as Types>::TokenStream::unmark)\n    }\n}\n\nimpl client::Client<fn(crate::TokenStream, crate::TokenStream) -> crate::TokenStream> {\n    pub fn run<S: Server>(\n        &self,\n        strategy: &impl ExecutionStrategy,\n        server: S,\n        input: S::TokenStream,\n        input2: S::TokenStream,\n        force_show_panics: bool,\n    ) -> Result<S::TokenStream, PanicMessage> {\n        let client::Client { get_handle_counters, run, f } = *self;\n        run_server(\n            strategy,\n            get_handle_counters(),\n            server,\n            (\n                <MarkedTypes<S> as Types>::TokenStream::mark(input),\n                <MarkedTypes<S> as Types>::TokenStream::mark(input2),\n            ),\n            run,\n            f,\n            force_show_panics,\n        )\n        .map(<MarkedTypes<S> as Types>::TokenStream::unmark)\n    }\n}\n"],[2090,"//! Server-side handles and storage for per-handle data.\n\nuse std::collections::{BTreeMap, HashMap};\nuse std::hash::Hash;\nuse std::num::NonZeroU32;\nuse std::ops::{Index, IndexMut};\nuse std::sync::atomic::{AtomicUsize, Ordering};\n\npub(super) type Handle = NonZeroU32;\n\npub(super) struct OwnedStore<T: 'static> {\n    counter: &'static AtomicUsize,\n    data: BTreeMap<Handle, T>,\n}\n\nimpl<T> OwnedStore<T> {\n    pub(super) fn new(counter: &'static AtomicUsize) -> Self {\n        // Ensure the handle counter isn't 0, which would panic later,\n        // when `NonZeroU32::new` (aka `Handle::new`) is called in `alloc`.\n        assert_ne!(counter.load(Ordering::SeqCst), 0);\n\n        OwnedStore { counter, data: BTreeMap::new() }\n    }\n}\n\nimpl<T> OwnedStore<T> {\n    pub(super) fn alloc(&mut self, x: T) -> Handle {\n        let counter = self.counter.fetch_add(1, Ordering::SeqCst);\n        let handle = Handle::new(counter as u32).expect(\"`proc_macro` handle counter overflowed\");\n        assert!(self.data.insert(handle, x).is_none());\n        handle\n    }\n\n    pub(super) fn take(&mut self, h: Handle) -> T {\n        self.data.remove(&h).expect(\"use-after-free in `proc_macro` handle\")\n    }\n}\n\nimpl<T> Index<Handle> for OwnedStore<T> {\n    type Output = T;\n    fn index(&self, h: Handle) -> &T {\n        self.data.get(&h).expect(\"use-after-free in `proc_macro` handle\")\n    }\n}\n\nimpl<T> IndexMut<Handle> for OwnedStore<T> {\n    fn index_mut(&mut self, h: Handle) -> &mut T {\n        self.data.get_mut(&h).expect(\"use-after-free in `proc_macro` handle\")\n    }\n}\n\npub(super) struct InternedStore<T: 'static> {\n    owned: OwnedStore<T>,\n    interner: HashMap<T, Handle>,\n}\n\nimpl<T: Copy + Eq + Hash> InternedStore<T> {\n    pub(super) fn new(counter: &'static AtomicUsize) -> Self {\n        InternedStore { owned: OwnedStore::new(counter), interner: HashMap::new() }\n    }\n\n    pub(super) fn alloc(&mut self, x: T) -> Handle {\n        let owned = &mut self.owned;\n        *self.interner.entry(x).or_insert_with(|| owned.alloc(x))\n    }\n\n    pub(super) fn copy(&mut self, h: Handle) -> T {\n        self.owned[h]\n    }\n}\n"],[2091,"//! Closure type (equivalent to `&mut dyn FnMut(A) -> R`) that's `repr(C)`.\n\n#[repr(C)]\npub struct Closure<'a, A, R> {\n    call: unsafe extern \"C\" fn(&mut Env, A) -> R,\n    env: &'a mut Env,\n}\n\nextern \"C\" {\n    type Env;\n}\n\nimpl<'a, A, R> !Sync for Closure<'a, A, R> {}\nimpl<'a, A, R> !Send for Closure<'a, A, R> {}\n\nimpl<'a, A, R, F: FnMut(A) -> R> From<&'a mut F> for Closure<'a, A, R> {\n    fn from(f: &'a mut F) -> Self {\n        unsafe extern \"C\" fn call<A, R, F: FnMut(A) -> R>(env: &mut Env, arg: A) -> R {\n            (*(env as *mut _ as *mut F))(arg)\n        }\n        Closure { call: call::<A, R, F>, env: unsafe { &mut *(f as *mut _ as *mut Env) } }\n    }\n}\n\nimpl<'a, A, R> Closure<'a, A, R> {\n    pub fn call(&mut self, arg: A) -> R {\n        unsafe { (self.call)(self.env, arg) }\n    }\n}\n"],[2092,"//! Buffer management for same-process client<->server communication.\n\nuse std::io::{self, Write};\nuse std::mem;\nuse std::ops::{Deref, DerefMut};\nuse std::slice;\n\n#[repr(C)]\nstruct Slice<'a, T> {\n    data: &'a [T; 0],\n    len: usize,\n}\n\nunsafe impl<'a, T: Sync> Sync for Slice<'a, T> {}\nunsafe impl<'a, T: Sync> Send for Slice<'a, T> {}\n\nimpl<T> Copy for Slice<'a, T> {}\nimpl<T> Clone for Slice<'a, T> {\n    fn clone(&self) -> Self {\n        *self\n    }\n}\n\nimpl<T> From<&'a [T]> for Slice<'a, T> {\n    fn from(xs: &'a [T]) -> Self {\n        Slice { data: unsafe { &*(xs.as_ptr() as *const [T; 0]) }, len: xs.len() }\n    }\n}\n\nimpl<T> Deref for Slice<'a, T> {\n    type Target = [T];\n    fn deref(&self) -> &[T] {\n        unsafe { slice::from_raw_parts(self.data.as_ptr(), self.len) }\n    }\n}\n\n#[repr(C)]\npub struct Buffer<T: Copy> {\n    data: *mut T,\n    len: usize,\n    capacity: usize,\n    reserve: extern \"C\" fn(Buffer<T>, usize) -> Buffer<T>,\n    drop: extern \"C\" fn(Buffer<T>),\n}\n\nunsafe impl<T: Copy + Sync> Sync for Buffer<T> {}\nunsafe impl<T: Copy + Send> Send for Buffer<T> {}\n\nimpl<T: Copy> Default for Buffer<T> {\n    fn default() -> Self {\n        Self::from(vec![])\n    }\n}\n\nimpl<T: Copy> Deref for Buffer<T> {\n    type Target = [T];\n    fn deref(&self) -> &[T] {\n        unsafe { slice::from_raw_parts(self.data as *const T, self.len) }\n    }\n}\n\nimpl<T: Copy> DerefMut for Buffer<T> {\n    fn deref_mut(&mut self) -> &mut [T] {\n        unsafe { slice::from_raw_parts_mut(self.data, self.len) }\n    }\n}\n\nimpl<T: Copy> Buffer<T> {\n    pub(super) fn new() -> Self {\n        Self::default()\n    }\n\n    pub(super) fn clear(&mut self) {\n        self.len = 0;\n    }\n\n    pub(super) fn take(&mut self) -> Self {\n        mem::take(self)\n    }\n\n    // We have the array method separate from extending from a slice. This is\n    // because in the case of small arrays, codegen can be more efficient\n    // (avoiding a memmove call). With extend_from_slice, LLVM at least\n    // currently is not able to make that optimization.\n    pub(super) fn extend_from_array<const N: usize>(&mut self, xs: &[T; N]) {\n        if xs.len() > (self.capacity - self.len) {\n            let b = self.take();\n            *self = (b.reserve)(b, xs.len());\n        }\n        unsafe {\n            xs.as_ptr().copy_to_nonoverlapping(self.data.add(self.len), xs.len());\n            self.len += xs.len();\n        }\n    }\n\n    pub(super) fn extend_from_slice(&mut self, xs: &[T]) {\n        if xs.len() > (self.capacity - self.len) {\n            let b = self.take();\n            *self = (b.reserve)(b, xs.len());\n        }\n        unsafe {\n            xs.as_ptr().copy_to_nonoverlapping(self.data.add(self.len), xs.len());\n            self.len += xs.len();\n        }\n    }\n\n    pub(super) fn push(&mut self, v: T) {\n        // The code here is taken from Vec::push, and we know that reserve()\n        // will panic if we're exceeding isize::MAX bytes and so there's no need\n        // to check for overflow.\n        if self.len == self.capacity {\n            let b = self.take();\n            *self = (b.reserve)(b, 1);\n        }\n        unsafe {\n            *self.data.add(self.len) = v;\n            self.len += 1;\n        }\n    }\n}\n\nimpl Write for Buffer<u8> {\n    fn write(&mut self, xs: &[u8]) -> io::Result<usize> {\n        self.extend_from_slice(xs);\n        Ok(xs.len())\n    }\n\n    fn write_all(&mut self, xs: &[u8]) -> io::Result<()> {\n        self.extend_from_slice(xs);\n        Ok(())\n    }\n\n    fn flush(&mut self) -> io::Result<()> {\n        Ok(())\n    }\n}\n\nimpl<T: Copy> Drop for Buffer<T> {\n    fn drop(&mut self) {\n        let b = self.take();\n        (b.drop)(b);\n    }\n}\n\nimpl<T: Copy> From<Vec<T>> for Buffer<T> {\n    fn from(mut v: Vec<T>) -> Self {\n        let (data, len, capacity) = (v.as_mut_ptr(), v.len(), v.capacity());\n        mem::forget(v);\n\n        // This utility function is nested in here because it can *only*\n        // be safely called on `Buffer`s created by *this* `proc_macro`.\n        fn to_vec<T: Copy>(b: Buffer<T>) -> Vec<T> {\n            unsafe {\n                let Buffer { data, len, capacity, .. } = b;\n                mem::forget(b);\n                Vec::from_raw_parts(data, len, capacity)\n            }\n        }\n\n        extern \"C\" fn reserve<T: Copy>(b: Buffer<T>, additional: usize) -> Buffer<T> {\n            let mut v = to_vec(b);\n            v.reserve(additional);\n            Buffer::from(v)\n        }\n\n        extern \"C\" fn drop<T: Copy>(b: Buffer<T>) {\n            mem::drop(to_vec(b));\n        }\n\n        Buffer { data, len, capacity, reserve, drop }\n    }\n}\n"],[2093,"//! # Quasiquoter\n//! This file contains the implementation internals of the quasiquoter provided by `quote!`.\n\n//! This quasiquoter uses macros 2.0 hygiene to reliably access\n//! items from `proc_macro`, to build a `proc_macro::TokenStream`.\n\nuse crate::{Delimiter, Group, Ident, Literal, Punct, Spacing, Span, TokenStream, TokenTree};\n\nmacro_rules! quote_tt {\n    (($($t:tt)*)) => { Group::new(Delimiter::Parenthesis, quote!($($t)*)) };\n    ([$($t:tt)*]) => { Group::new(Delimiter::Bracket, quote!($($t)*)) };\n    ({$($t:tt)*}) => { Group::new(Delimiter::Brace, quote!($($t)*)) };\n    (,) => { Punct::new(',', Spacing::Alone) };\n    (.) => { Punct::new('.', Spacing::Alone) };\n    (:) => { Punct::new(':', Spacing::Alone) };\n    (;) => { Punct::new(';', Spacing::Alone) };\n    (!) => { Punct::new('!', Spacing::Alone) };\n    (<) => { Punct::new('<', Spacing::Alone) };\n    (>) => { Punct::new('>', Spacing::Alone) };\n    (&) => { Punct::new('&', Spacing::Alone) };\n    (=) => { Punct::new('=', Spacing::Alone) };\n    ($i:ident) => { Ident::new(stringify!($i), Span::def_site()) };\n}\n\nmacro_rules! quote_ts {\n    ((@ $($t:tt)*)) => { $($t)* };\n    (::) => {\n        [\n            TokenTree::from(Punct::new(':', Spacing::Joint)),\n            TokenTree::from(Punct::new(':', Spacing::Alone)),\n        ].iter()\n            .cloned()\n            .map(|mut x| {\n                x.set_span(Span::def_site());\n                x\n            })\n            .collect::<TokenStream>()\n    };\n    ($t:tt) => { TokenTree::from(quote_tt!($t)) };\n}\n\n/// Simpler version of the real `quote!` macro, implemented solely\n/// through `macro_rules`, for bootstrapping the real implementation\n/// (see the `quote` function), which does not have access to the\n/// real `quote!` macro due to the `proc_macro` crate not being\n/// able to depend on itself.\n///\n/// Note: supported tokens are a subset of the real `quote!`, but\n/// unquoting is different: instead of `$x`, this uses `(@ expr)`.\nmacro_rules! quote {\n    () => { TokenStream::new() };\n    ($($t:tt)*) => {\n        [\n            $(TokenStream::from(quote_ts!($t)),)*\n        ].iter().cloned().collect::<TokenStream>()\n    };\n}\n\n/// Quote a `TokenStream` into a `TokenStream`.\n/// This is the actual implementation of the `quote!()` proc macro.\n///\n/// It is loaded by the compiler in `register_builtin_macros`.\n#[unstable(feature = \"proc_macro_quote\", issue = \"54722\")]\npub fn quote(stream: TokenStream) -> TokenStream {\n    if stream.is_empty() {\n        return quote!(crate::TokenStream::new());\n    }\n    let proc_macro_crate = quote!(crate);\n    let mut after_dollar = false;\n    let tokens = stream\n        .into_iter()\n        .filter_map(|tree| {\n            if after_dollar {\n                after_dollar = false;\n                match tree {\n                    TokenTree::Ident(_) => {\n                        return Some(quote!(Into::<crate::TokenStream>::into(\n                        Clone::clone(&(@ tree))),));\n                    }\n                    TokenTree::Punct(ref tt) if tt.as_char() == '$' => {}\n                    _ => panic!(\"`$` must be followed by an ident or `$` in `quote!`\"),\n                }\n            } else if let TokenTree::Punct(ref tt) = tree {\n                if tt.as_char() == '$' {\n                    after_dollar = true;\n                    return None;\n                }\n            }\n\n            Some(quote!(crate::TokenStream::from((@ match tree {\n                TokenTree::Punct(tt) => quote!(crate::TokenTree::Punct(crate::Punct::new(\n                    (@ TokenTree::from(Literal::character(tt.as_char()))),\n                    (@ match tt.spacing() {\n                        Spacing::Alone => quote!(crate::Spacing::Alone),\n                        Spacing::Joint => quote!(crate::Spacing::Joint),\n                    }),\n                ))),\n                TokenTree::Group(tt) => quote!(crate::TokenTree::Group(crate::Group::new(\n                    (@ match tt.delimiter() {\n                        Delimiter::Parenthesis => quote!(crate::Delimiter::Parenthesis),\n                        Delimiter::Brace => quote!(crate::Delimiter::Brace),\n                        Delimiter::Bracket => quote!(crate::Delimiter::Bracket),\n                        Delimiter::None => quote!(crate::Delimiter::None),\n                    }),\n                    (@ quote(tt.stream())),\n                ))),\n                TokenTree::Ident(tt) => quote!(crate::TokenTree::Ident(crate::Ident::new(\n                    (@ TokenTree::from(Literal::string(&tt.to_string()))),\n                    (@ quote_span(proc_macro_crate.clone(), tt.span())),\n                ))),\n                TokenTree::Literal(tt) => quote!(crate::TokenTree::Literal({\n                    let mut iter = (@ TokenTree::from(Literal::string(&tt.to_string())))\n                        .parse::<crate::TokenStream>()\n                        .unwrap()\n                        .into_iter();\n                    if let (Some(crate::TokenTree::Literal(mut lit)), None) =\n                        (iter.next(), iter.next())\n                    {\n                        lit.set_span((@ quote_span(proc_macro_crate.clone(), tt.span())));\n                        lit\n                    } else {\n                        unreachable!()\n                    }\n                }))\n            })),))\n        })\n        .collect::<TokenStream>();\n\n    if after_dollar {\n        panic!(\"unexpected trailing `$` in `quote!`\");\n    }\n\n    quote!([(@ tokens)].iter().cloned().collect::<crate::TokenStream>())\n}\n\n/// Quote a `Span` into a `TokenStream`.\n/// This is needed to implement a custom quoter.\n#[unstable(feature = \"proc_macro_quote\", issue = \"54722\")]\npub fn quote_span(proc_macro_crate: TokenStream, span: Span) -> TokenStream {\n    let id = span.save_span();\n    quote!((@ proc_macro_crate ) ::Span::recover_proc_macro_span((@ TokenTree::from(Literal::usize_unsuffixed(id)))))\n}\n"],[2094,"use crate::Span;\n\n/// An enum representing a diagnostic level.\n#[unstable(feature = \"proc_macro_diagnostic\", issue = \"54140\")]\n#[derive(Copy, Clone, Debug)]\n#[non_exhaustive]\npub enum Level {\n    /// An error.\n    Error,\n    /// A warning.\n    Warning,\n    /// A note.\n    Note,\n    /// A help message.\n    Help,\n}\n\n/// Trait implemented by types that can be converted into a set of `Span`s.\n#[unstable(feature = \"proc_macro_diagnostic\", issue = \"54140\")]\npub trait MultiSpan {\n    /// Converts `self` into a `Vec<Span>`.\n    fn into_spans(self) -> Vec<Span>;\n}\n\n#[unstable(feature = \"proc_macro_diagnostic\", issue = \"54140\")]\nimpl MultiSpan for Span {\n    fn into_spans(self) -> Vec<Span> {\n        vec![self]\n    }\n}\n\n#[unstable(feature = \"proc_macro_diagnostic\", issue = \"54140\")]\nimpl MultiSpan for Vec<Span> {\n    fn into_spans(self) -> Vec<Span> {\n        self\n    }\n}\n\n#[unstable(feature = \"proc_macro_diagnostic\", issue = \"54140\")]\nimpl<'a> MultiSpan for &'a [Span] {\n    fn into_spans(self) -> Vec<Span> {\n        self.to_vec()\n    }\n}\n\n/// A structure representing a diagnostic message and associated children\n/// messages.\n#[unstable(feature = \"proc_macro_diagnostic\", issue = \"54140\")]\n#[derive(Clone, Debug)]\npub struct Diagnostic {\n    level: Level,\n    message: String,\n    spans: Vec<Span>,\n    children: Vec<Diagnostic>,\n}\n\nmacro_rules! diagnostic_child_methods {\n    ($spanned:ident, $regular:ident, $level:expr) => {\n        /// Adds a new child diagnostic message to `self` with the level\n        /// identified by this method's name with the given `spans` and\n        /// `message`.\n        #[unstable(feature = \"proc_macro_diagnostic\", issue = \"54140\")]\n        pub fn $spanned<S, T>(mut self, spans: S, message: T) -> Diagnostic\n        where\n            S: MultiSpan,\n            T: Into<String>,\n        {\n            self.children.push(Diagnostic::spanned(spans, $level, message));\n            self\n        }\n\n        /// Adds a new child diagnostic message to `self` with the level\n        /// identified by this method's name with the given `message`.\n        #[unstable(feature = \"proc_macro_diagnostic\", issue = \"54140\")]\n        pub fn $regular<T: Into<String>>(mut self, message: T) -> Diagnostic {\n            self.children.push(Diagnostic::new($level, message));\n            self\n        }\n    };\n}\n\n/// Iterator over the children diagnostics of a `Diagnostic`.\n#[derive(Debug, Clone)]\n#[unstable(feature = \"proc_macro_diagnostic\", issue = \"54140\")]\npub struct Children<'a>(std::slice::Iter<'a, Diagnostic>);\n\n#[unstable(feature = \"proc_macro_diagnostic\", issue = \"54140\")]\nimpl<'a> Iterator for Children<'a> {\n    type Item = &'a Diagnostic;\n\n    fn next(&mut self) -> Option<Self::Item> {\n        self.0.next()\n    }\n}\n\n#[unstable(feature = \"proc_macro_diagnostic\", issue = \"54140\")]\nimpl Diagnostic {\n    /// Creates a new diagnostic with the given `level` and `message`.\n    #[unstable(feature = \"proc_macro_diagnostic\", issue = \"54140\")]\n    pub fn new<T: Into<String>>(level: Level, message: T) -> Diagnostic {\n        Diagnostic { level, message: message.into(), spans: vec![], children: vec![] }\n    }\n\n    /// Creates a new diagnostic with the given `level` and `message` pointing to\n    /// the given set of `spans`.\n    #[unstable(feature = \"proc_macro_diagnostic\", issue = \"54140\")]\n    pub fn spanned<S, T>(spans: S, level: Level, message: T) -> Diagnostic\n    where\n        S: MultiSpan,\n        T: Into<String>,\n    {\n        Diagnostic { level, message: message.into(), spans: spans.into_spans(), children: vec![] }\n    }\n\n    diagnostic_child_methods!(span_error, error, Level::Error);\n    diagnostic_child_methods!(span_warning, warning, Level::Warning);\n    diagnostic_child_methods!(span_note, note, Level::Note);\n    diagnostic_child_methods!(span_help, help, Level::Help);\n\n    /// Returns the diagnostic `level` for `self`.\n    #[unstable(feature = \"proc_macro_diagnostic\", issue = \"54140\")]\n    pub fn level(&self) -> Level {\n        self.level\n    }\n\n    /// Sets the level in `self` to `level`.\n    #[unstable(feature = \"proc_macro_diagnostic\", issue = \"54140\")]\n    pub fn set_level(&mut self, level: Level) {\n        self.level = level;\n    }\n\n    /// Returns the message in `self`.\n    #[unstable(feature = \"proc_macro_diagnostic\", issue = \"54140\")]\n    pub fn message(&self) -> &str {\n        &self.message\n    }\n\n    /// Sets the message in `self` to `message`.\n    #[unstable(feature = \"proc_macro_diagnostic\", issue = \"54140\")]\n    pub fn set_message<T: Into<String>>(&mut self, message: T) {\n        self.message = message.into();\n    }\n\n    /// Returns the `Span`s in `self`.\n    #[unstable(feature = \"proc_macro_diagnostic\", issue = \"54140\")]\n    pub fn spans(&self) -> &[Span] {\n        &self.spans\n    }\n\n    /// Sets the `Span`s in `self` to `spans`.\n    #[unstable(feature = \"proc_macro_diagnostic\", issue = \"54140\")]\n    pub fn set_spans<S: MultiSpan>(&mut self, spans: S) {\n        self.spans = spans.into_spans();\n    }\n\n    /// Returns an iterator over the children diagnostics of `self`.\n    #[unstable(feature = \"proc_macro_diagnostic\", issue = \"54140\")]\n    pub fn children(&self) -> Children<'_> {\n        Children(self.children.iter())\n    }\n\n    /// Emit the diagnostic.\n    #[unstable(feature = \"proc_macro_diagnostic\", issue = \"54140\")]\n    pub fn emit(self) {\n        fn to_internal(spans: Vec<Span>) -> crate::bridge::client::MultiSpan {\n            let mut multi_span = crate::bridge::client::MultiSpan::new();\n            for span in spans {\n                multi_span.push(span.0);\n            }\n            multi_span\n        }\n\n        let mut diag = crate::bridge::client::Diagnostic::new(\n            self.level,\n            &self.message[..],\n            to_internal(self.spans),\n        );\n        for c in self.children {\n            diag.sub(c.level, &c.message[..], to_internal(c.spans));\n        }\n        diag.emit();\n    }\n}\n"],[2095,"use super::*;\n\nextern crate test;\nuse self::test::test::Bencher;\nuse std::io;\nuse std::io::prelude::*;\n\n// Test vectors generated from R, using the script src/etc/stat-test-vectors.r.\n\nmacro_rules! assert_approx_eq {\n    ($a: expr, $b: expr) => {{\n        let (a, b) = (&$a, &$b);\n        assert!((*a - *b).abs() < 1.0e-6, \"{} is not approximately equal to {}\", *a, *b);\n    }};\n}\n\nfn check(samples: &[f64], summ: &Summary) {\n    let summ2 = Summary::new(samples);\n\n    let mut w = io::sink();\n    let w = &mut w;\n    (write!(w, \"\\n\")).unwrap();\n\n    assert_eq!(summ.sum, summ2.sum);\n    assert_eq!(summ.min, summ2.min);\n    assert_eq!(summ.max, summ2.max);\n    assert_eq!(summ.mean, summ2.mean);\n    assert_eq!(summ.median, summ2.median);\n\n    // We needed a few more digits to get exact equality on these\n    // but they're within float epsilon, which is 1.0e-6.\n    assert_approx_eq!(summ.var, summ2.var);\n    assert_approx_eq!(summ.std_dev, summ2.std_dev);\n    assert_approx_eq!(summ.std_dev_pct, summ2.std_dev_pct);\n    assert_approx_eq!(summ.median_abs_dev, summ2.median_abs_dev);\n    assert_approx_eq!(summ.median_abs_dev_pct, summ2.median_abs_dev_pct);\n\n    assert_eq!(summ.quartiles, summ2.quartiles);\n    assert_eq!(summ.iqr, summ2.iqr);\n}\n\n#[test]\nfn test_min_max_nan() {\n    let xs = &[1.0, 2.0, f64::NAN, 3.0, 4.0];\n    let summary = Summary::new(xs);\n    assert_eq!(summary.min, 1.0);\n    assert_eq!(summary.max, 4.0);\n}\n\n#[test]\nfn test_norm2() {\n    let val = &[958.0000000000, 924.0000000000];\n    let summ = &Summary {\n        sum: 1882.0000000000,\n        min: 924.0000000000,\n        max: 958.0000000000,\n        mean: 941.0000000000,\n        median: 941.0000000000,\n        var: 578.0000000000,\n        std_dev: 24.0416305603,\n        std_dev_pct: 2.5549022912,\n        median_abs_dev: 25.2042000000,\n        median_abs_dev_pct: 2.6784484591,\n        quartiles: (932.5000000000, 941.0000000000, 949.5000000000),\n        iqr: 17.0000000000,\n    };\n    check(val, summ);\n}\n#[test]\nfn test_norm10narrow() {\n    let val = &[\n        966.0000000000,\n        985.0000000000,\n        1110.0000000000,\n        848.0000000000,\n        821.0000000000,\n        975.0000000000,\n        962.0000000000,\n        1157.0000000000,\n        1217.0000000000,\n        955.0000000000,\n    ];\n    let summ = &Summary {\n        sum: 9996.0000000000,\n        min: 821.0000000000,\n        max: 1217.0000000000,\n        mean: 999.6000000000,\n        median: 970.5000000000,\n        var: 16050.7111111111,\n        std_dev: 126.6914010938,\n        std_dev_pct: 12.6742097933,\n        median_abs_dev: 102.2994000000,\n        median_abs_dev_pct: 10.5408964451,\n        quartiles: (956.7500000000, 970.5000000000, 1078.7500000000),\n        iqr: 122.0000000000,\n    };\n    check(val, summ);\n}\n#[test]\nfn test_norm10medium() {\n    let val = &[\n        954.0000000000,\n        1064.0000000000,\n        855.0000000000,\n        1000.0000000000,\n        743.0000000000,\n        1084.0000000000,\n        704.0000000000,\n        1023.0000000000,\n        357.0000000000,\n        869.0000000000,\n    ];\n    let summ = &Summary {\n        sum: 8653.0000000000,\n        min: 357.0000000000,\n        max: 1084.0000000000,\n        mean: 865.3000000000,\n        median: 911.5000000000,\n        var: 48628.4555555556,\n        std_dev: 220.5186059170,\n        std_dev_pct: 25.4846418487,\n        median_abs_dev: 195.7032000000,\n        median_abs_dev_pct: 21.4704552935,\n        quartiles: (771.0000000000, 911.5000000000, 1017.2500000000),\n        iqr: 246.2500000000,\n    };\n    check(val, summ);\n}\n#[test]\nfn test_norm10wide() {\n    let val = &[\n        505.0000000000,\n        497.0000000000,\n        1591.0000000000,\n        887.0000000000,\n        1026.0000000000,\n        136.0000000000,\n        1580.0000000000,\n        940.0000000000,\n        754.0000000000,\n        1433.0000000000,\n    ];\n    let summ = &Summary {\n        sum: 9349.0000000000,\n        min: 136.0000000000,\n        max: 1591.0000000000,\n        mean: 934.9000000000,\n        median: 913.5000000000,\n        var: 239208.9888888889,\n        std_dev: 489.0899599142,\n        std_dev_pct: 52.3146817750,\n        median_abs_dev: 611.5725000000,\n        median_abs_dev_pct: 66.9482758621,\n        quartiles: (567.2500000000, 913.5000000000, 1331.2500000000),\n        iqr: 764.0000000000,\n    };\n    check(val, summ);\n}\n#[test]\nfn test_norm25verynarrow() {\n    let val = &[\n        991.0000000000,\n        1018.0000000000,\n        998.0000000000,\n        1013.0000000000,\n        974.0000000000,\n        1007.0000000000,\n        1014.0000000000,\n        999.0000000000,\n        1011.0000000000,\n        978.0000000000,\n        985.0000000000,\n        999.0000000000,\n        983.0000000000,\n        982.0000000000,\n        1015.0000000000,\n        1002.0000000000,\n        977.0000000000,\n        948.0000000000,\n        1040.0000000000,\n        974.0000000000,\n        996.0000000000,\n        989.0000000000,\n        1015.0000000000,\n        994.0000000000,\n        1024.0000000000,\n    ];\n    let summ = &Summary {\n        sum: 24926.0000000000,\n        min: 948.0000000000,\n        max: 1040.0000000000,\n        mean: 997.0400000000,\n        median: 998.0000000000,\n        var: 393.2066666667,\n        std_dev: 19.8294393937,\n        std_dev_pct: 1.9888308788,\n        median_abs_dev: 22.2390000000,\n        median_abs_dev_pct: 2.2283567134,\n        quartiles: (983.0000000000, 998.0000000000, 1013.0000000000),\n        iqr: 30.0000000000,\n    };\n    check(val, summ);\n}\n#[test]\nfn test_exp10a() {\n    let val = &[\n        23.0000000000,\n        11.0000000000,\n        2.0000000000,\n        57.0000000000,\n        4.0000000000,\n        12.0000000000,\n        5.0000000000,\n        29.0000000000,\n        3.0000000000,\n        21.0000000000,\n    ];\n    let summ = &Summary {\n        sum: 167.0000000000,\n        min: 2.0000000000,\n        max: 57.0000000000,\n        mean: 16.7000000000,\n        median: 11.5000000000,\n        var: 287.7888888889,\n        std_dev: 16.9643416875,\n        std_dev_pct: 101.5828843560,\n        median_abs_dev: 13.3434000000,\n        median_abs_dev_pct: 116.0295652174,\n        quartiles: (4.2500000000, 11.5000000000, 22.5000000000),\n        iqr: 18.2500000000,\n    };\n    check(val, summ);\n}\n#[test]\nfn test_exp10b() {\n    let val = &[\n        24.0000000000,\n        17.0000000000,\n        6.0000000000,\n        38.0000000000,\n        25.0000000000,\n        7.0000000000,\n        51.0000000000,\n        2.0000000000,\n        61.0000000000,\n        32.0000000000,\n    ];\n    let summ = &Summary {\n        sum: 263.0000000000,\n        min: 2.0000000000,\n        max: 61.0000000000,\n        mean: 26.3000000000,\n        median: 24.5000000000,\n        var: 383.5666666667,\n        std_dev: 19.5848580967,\n        std_dev_pct: 74.4671410520,\n        median_abs_dev: 22.9803000000,\n        median_abs_dev_pct: 93.7971428571,\n        quartiles: (9.5000000000, 24.5000000000, 36.5000000000),\n        iqr: 27.0000000000,\n    };\n    check(val, summ);\n}\n#[test]\nfn test_exp10c() {\n    let val = &[\n        71.0000000000,\n        2.0000000000,\n        32.0000000000,\n        1.0000000000,\n        6.0000000000,\n        28.0000000000,\n        13.0000000000,\n        37.0000000000,\n        16.0000000000,\n        36.0000000000,\n    ];\n    let summ = &Summary {\n        sum: 242.0000000000,\n        min: 1.0000000000,\n        max: 71.0000000000,\n        mean: 24.2000000000,\n        median: 22.0000000000,\n        var: 458.1777777778,\n        std_dev: 21.4050876611,\n        std_dev_pct: 88.4507754589,\n        median_abs_dev: 21.4977000000,\n        median_abs_dev_pct: 97.7168181818,\n        quartiles: (7.7500000000, 22.0000000000, 35.0000000000),\n        iqr: 27.2500000000,\n    };\n    check(val, summ);\n}\n#[test]\nfn test_exp25() {\n    let val = &[\n        3.0000000000,\n        24.0000000000,\n        1.0000000000,\n        19.0000000000,\n        7.0000000000,\n        5.0000000000,\n        30.0000000000,\n        39.0000000000,\n        31.0000000000,\n        13.0000000000,\n        25.0000000000,\n        48.0000000000,\n        1.0000000000,\n        6.0000000000,\n        42.0000000000,\n        63.0000000000,\n        2.0000000000,\n        12.0000000000,\n        108.0000000000,\n        26.0000000000,\n        1.0000000000,\n        7.0000000000,\n        44.0000000000,\n        25.0000000000,\n        11.0000000000,\n    ];\n    let summ = &Summary {\n        sum: 593.0000000000,\n        min: 1.0000000000,\n        max: 108.0000000000,\n        mean: 23.7200000000,\n        median: 19.0000000000,\n        var: 601.0433333333,\n        std_dev: 24.5161851301,\n        std_dev_pct: 103.3565983562,\n        median_abs_dev: 19.2738000000,\n        median_abs_dev_pct: 101.4410526316,\n        quartiles: (6.0000000000, 19.0000000000, 31.0000000000),\n        iqr: 25.0000000000,\n    };\n    check(val, summ);\n}\n#[test]\nfn test_binom25() {\n    let val = &[\n        18.0000000000,\n        17.0000000000,\n        27.0000000000,\n        15.0000000000,\n        21.0000000000,\n        25.0000000000,\n        17.0000000000,\n        24.0000000000,\n        25.0000000000,\n        24.0000000000,\n        26.0000000000,\n        26.0000000000,\n        23.0000000000,\n        15.0000000000,\n        23.0000000000,\n        17.0000000000,\n        18.0000000000,\n        18.0000000000,\n        21.0000000000,\n        16.0000000000,\n        15.0000000000,\n        31.0000000000,\n        20.0000000000,\n        17.0000000000,\n        15.0000000000,\n    ];\n    let summ = &Summary {\n        sum: 514.0000000000,\n        min: 15.0000000000,\n        max: 31.0000000000,\n        mean: 20.5600000000,\n        median: 20.0000000000,\n        var: 20.8400000000,\n        std_dev: 4.5650848842,\n        std_dev_pct: 22.2037202539,\n        median_abs_dev: 5.9304000000,\n        median_abs_dev_pct: 29.6520000000,\n        quartiles: (17.0000000000, 20.0000000000, 24.0000000000),\n        iqr: 7.0000000000,\n    };\n    check(val, summ);\n}\n#[test]\nfn test_pois25lambda30() {\n    let val = &[\n        27.0000000000,\n        33.0000000000,\n        34.0000000000,\n        34.0000000000,\n        24.0000000000,\n        39.0000000000,\n        28.0000000000,\n        27.0000000000,\n        31.0000000000,\n        28.0000000000,\n        38.0000000000,\n        21.0000000000,\n        33.0000000000,\n        36.0000000000,\n        29.0000000000,\n        37.0000000000,\n        32.0000000000,\n        34.0000000000,\n        31.0000000000,\n        39.0000000000,\n        25.0000000000,\n        31.0000000000,\n        32.0000000000,\n        40.0000000000,\n        24.0000000000,\n    ];\n    let summ = &Summary {\n        sum: 787.0000000000,\n        min: 21.0000000000,\n        max: 40.0000000000,\n        mean: 31.4800000000,\n        median: 32.0000000000,\n        var: 26.5933333333,\n        std_dev: 5.1568724372,\n        std_dev_pct: 16.3814245145,\n        median_abs_dev: 5.9304000000,\n        median_abs_dev_pct: 18.5325000000,\n        quartiles: (28.0000000000, 32.0000000000, 34.0000000000),\n        iqr: 6.0000000000,\n    };\n    check(val, summ);\n}\n#[test]\nfn test_pois25lambda40() {\n    let val = &[\n        42.0000000000,\n        50.0000000000,\n        42.0000000000,\n        46.0000000000,\n        34.0000000000,\n        45.0000000000,\n        34.0000000000,\n        49.0000000000,\n        39.0000000000,\n        28.0000000000,\n        40.0000000000,\n        35.0000000000,\n        37.0000000000,\n        39.0000000000,\n        46.0000000000,\n        44.0000000000,\n        32.0000000000,\n        45.0000000000,\n        42.0000000000,\n        37.0000000000,\n        48.0000000000,\n        42.0000000000,\n        33.0000000000,\n        42.0000000000,\n        48.0000000000,\n    ];\n    let summ = &Summary {\n        sum: 1019.0000000000,\n        min: 28.0000000000,\n        max: 50.0000000000,\n        mean: 40.7600000000,\n        median: 42.0000000000,\n        var: 34.4400000000,\n        std_dev: 5.8685603004,\n        std_dev_pct: 14.3978417577,\n        median_abs_dev: 5.9304000000,\n        median_abs_dev_pct: 14.1200000000,\n        quartiles: (37.0000000000, 42.0000000000, 45.0000000000),\n        iqr: 8.0000000000,\n    };\n    check(val, summ);\n}\n#[test]\nfn test_pois25lambda50() {\n    let val = &[\n        45.0000000000,\n        43.0000000000,\n        44.0000000000,\n        61.0000000000,\n        51.0000000000,\n        53.0000000000,\n        59.0000000000,\n        52.0000000000,\n        49.0000000000,\n        51.0000000000,\n        51.0000000000,\n        50.0000000000,\n        49.0000000000,\n        56.0000000000,\n        42.0000000000,\n        52.0000000000,\n        51.0000000000,\n        43.0000000000,\n        48.0000000000,\n        48.0000000000,\n        50.0000000000,\n        42.0000000000,\n        43.0000000000,\n        42.0000000000,\n        60.0000000000,\n    ];\n    let summ = &Summary {\n        sum: 1235.0000000000,\n        min: 42.0000000000,\n        max: 61.0000000000,\n        mean: 49.4000000000,\n        median: 50.0000000000,\n        var: 31.6666666667,\n        std_dev: 5.6273143387,\n        std_dev_pct: 11.3913245723,\n        median_abs_dev: 4.4478000000,\n        median_abs_dev_pct: 8.8956000000,\n        quartiles: (44.0000000000, 50.0000000000, 52.0000000000),\n        iqr: 8.0000000000,\n    };\n    check(val, summ);\n}\n#[test]\nfn test_unif25() {\n    let val = &[\n        99.0000000000,\n        55.0000000000,\n        92.0000000000,\n        79.0000000000,\n        14.0000000000,\n        2.0000000000,\n        33.0000000000,\n        49.0000000000,\n        3.0000000000,\n        32.0000000000,\n        84.0000000000,\n        59.0000000000,\n        22.0000000000,\n        86.0000000000,\n        76.0000000000,\n        31.0000000000,\n        29.0000000000,\n        11.0000000000,\n        41.0000000000,\n        53.0000000000,\n        45.0000000000,\n        44.0000000000,\n        98.0000000000,\n        98.0000000000,\n        7.0000000000,\n    ];\n    let summ = &Summary {\n        sum: 1242.0000000000,\n        min: 2.0000000000,\n        max: 99.0000000000,\n        mean: 49.6800000000,\n        median: 45.0000000000,\n        var: 1015.6433333333,\n        std_dev: 31.8691595957,\n        std_dev_pct: 64.1488719719,\n        median_abs_dev: 45.9606000000,\n        median_abs_dev_pct: 102.1346666667,\n        quartiles: (29.0000000000, 45.0000000000, 79.0000000000),\n        iqr: 50.0000000000,\n    };\n    check(val, summ);\n}\n\n#[test]\nfn test_sum_f64s() {\n    assert_eq!([0.5f64, 3.2321f64, 1.5678f64].sum(), 5.2999);\n}\n#[test]\nfn test_sum_f64_between_ints_that_sum_to_0() {\n    assert_eq!([1e30f64, 1.2f64, -1e30f64].sum(), 1.2);\n}\n\n#[bench]\npub fn sum_three_items(b: &mut Bencher) {\n    b.iter(|| {\n        [1e20f64, 1.5f64, -1e20f64].sum();\n    })\n}\n#[bench]\npub fn sum_many_f64(b: &mut Bencher) {\n    let nums = [-1e30f64, 1e60, 1e30, 1.0, -1e60];\n    let v = (0..500).map(|i| nums[i % 5]).collect::<Vec<_>>();\n\n    b.iter(|| {\n        v.sum();\n    })\n}\n\n#[bench]\npub fn no_iter(_: &mut Bencher) {}\n"],[2096,"//! Enums denoting options for test execution.\n\n/// Whether to execute tests concurrently or not\n#[derive(Copy, Clone, Debug, PartialEq, Eq)]\npub enum Concurrent {\n    Yes,\n    No,\n}\n\n/// Number of times to run a benchmarked function\n#[derive(Clone, PartialEq, Eq)]\npub enum BenchMode {\n    Auto,\n    Single,\n}\n\n/// Whether test is expected to panic or not\n#[derive(Copy, Clone, Debug, PartialEq, Eq, Hash)]\npub enum ShouldPanic {\n    No,\n    Yes,\n    YesWithMessage(&'static str),\n}\n\n/// Whether should console output be colored or not\n#[derive(Copy, Clone, Debug)]\npub enum ColorConfig {\n    AutoColor,\n    AlwaysColor,\n    NeverColor,\n}\n\n/// Format of the test results output\n#[derive(Copy, Clone, Debug, PartialEq, Eq)]\npub enum OutputFormat {\n    /// Verbose output\n    Pretty,\n    /// Quiet output\n    Terse,\n    /// JSON output\n    Json,\n    /// JUnit output\n    Junit,\n}\n\n/// Whether ignored test should be run or not\n#[derive(Copy, Clone, Debug, PartialEq, Eq)]\npub enum RunIgnored {\n    Yes,\n    No,\n    /// Run only ignored tests\n    Only,\n}\n\n#[derive(Clone, Copy)]\npub enum RunStrategy {\n    /// Runs the test in the current process, and sends the result back over the\n    /// supplied channel.\n    InProcess,\n\n    /// Spawns a subprocess to run the test, and sends the result back over the\n    /// supplied channel. Requires `argv[0]` to exist and point to the binary\n    /// that's currently running.\n    SpawnPrimary,\n}\n\n/// Options for the test run defined by the caller (instead of CLI arguments).\n/// In case we want to add other options as well, just add them in this struct.\n#[derive(Copy, Clone, Debug)]\npub struct Options {\n    pub display_output: bool,\n    pub panic_abort: bool,\n}\n\nimpl Options {\n    pub fn new() -> Options {\n        Options { display_output: false, panic_abort: false }\n    }\n\n    pub fn display_output(mut self, display_output: bool) -> Options {\n        self.display_output = display_output;\n        self\n    }\n\n    pub fn panic_abort(mut self, panic_abort: bool) -> Options {\n        self.panic_abort = panic_abort;\n        self\n    }\n}\n"],[2097,"//! Module `time` contains everything related to the time measurement of unit tests\n//! execution.\n//! The purposes of this module:\n//! - Check whether test is timed out.\n//! - Provide helpers for `report-time` and `measure-time` options.\n//! - Provide newtypes for executions times.\n\nuse std::env;\nuse std::fmt;\nuse std::str::FromStr;\nuse std::time::{Duration, Instant};\n\nuse super::types::{TestDesc, TestType};\n\npub const TEST_WARN_TIMEOUT_S: u64 = 60;\n\n/// This small module contains constants used by `report-time` option.\n/// Those constants values will be used if corresponding environment variables are not set.\n///\n/// To override values for unit-tests, use a constant `RUST_TEST_TIME_UNIT`,\n/// To override values for integration tests, use a constant `RUST_TEST_TIME_INTEGRATION`,\n/// To override values for doctests, use a constant `RUST_TEST_TIME_DOCTEST`.\n///\n/// Example of the expected format is `RUST_TEST_TIME_xxx=100,200`, where 100 means\n/// warn time, and 200 means critical time.\npub mod time_constants {\n    use super::TEST_WARN_TIMEOUT_S;\n    use std::time::Duration;\n\n    /// Environment variable for overriding default threshold for unit-tests.\n    pub const UNIT_ENV_NAME: &str = \"RUST_TEST_TIME_UNIT\";\n\n    // Unit tests are supposed to be really quick.\n    pub const UNIT_WARN: Duration = Duration::from_millis(50);\n    pub const UNIT_CRITICAL: Duration = Duration::from_millis(100);\n\n    /// Environment variable for overriding default threshold for unit-tests.\n    pub const INTEGRATION_ENV_NAME: &str = \"RUST_TEST_TIME_INTEGRATION\";\n\n    // Integration tests may have a lot of work, so they can take longer to execute.\n    pub const INTEGRATION_WARN: Duration = Duration::from_millis(500);\n    pub const INTEGRATION_CRITICAL: Duration = Duration::from_millis(1000);\n\n    /// Environment variable for overriding default threshold for unit-tests.\n    pub const DOCTEST_ENV_NAME: &str = \"RUST_TEST_TIME_DOCTEST\";\n\n    // Doctests are similar to integration tests, because they can include a lot of\n    // initialization code.\n    pub const DOCTEST_WARN: Duration = INTEGRATION_WARN;\n    pub const DOCTEST_CRITICAL: Duration = INTEGRATION_CRITICAL;\n\n    // Do not suppose anything about unknown tests, base limits on the\n    // `TEST_WARN_TIMEOUT_S` constant.\n    pub const UNKNOWN_WARN: Duration = Duration::from_secs(TEST_WARN_TIMEOUT_S);\n    pub const UNKNOWN_CRITICAL: Duration = Duration::from_secs(TEST_WARN_TIMEOUT_S * 2);\n}\n\n/// Returns an `Instance` object denoting when the test should be considered\n/// timed out.\npub fn get_default_test_timeout() -> Instant {\n    Instant::now() + Duration::from_secs(TEST_WARN_TIMEOUT_S)\n}\n\n/// The measured execution time of a unit test.\n#[derive(Debug, Clone, PartialEq)]\npub struct TestExecTime(pub Duration);\n\nimpl fmt::Display for TestExecTime {\n    fn fmt(&self, f: &mut fmt::Formatter<'_>) -> fmt::Result {\n        write!(f, \"{:.3}s\", self.0.as_secs_f64())\n    }\n}\n\n/// The measured execution time of the whole test suite.\n#[derive(Debug, Clone, Default, PartialEq)]\npub struct TestSuiteExecTime(pub Duration);\n\nimpl fmt::Display for TestSuiteExecTime {\n    fn fmt(&self, f: &mut fmt::Formatter<'_>) -> fmt::Result {\n        write!(f, \"{:.2}s\", self.0.as_secs_f64())\n    }\n}\n\n/// Structure denoting time limits for test execution.\n#[derive(Copy, Clone, Debug, Default, PartialEq, Eq)]\npub struct TimeThreshold {\n    pub warn: Duration,\n    pub critical: Duration,\n}\n\nimpl TimeThreshold {\n    /// Creates a new `TimeThreshold` instance with provided durations.\n    pub fn new(warn: Duration, critical: Duration) -> Self {\n        Self { warn, critical }\n    }\n\n    /// Attempts to create a `TimeThreshold` instance with values obtained\n    /// from the environment variable, and returns `None` if the variable\n    /// is not set.\n    /// Environment variable format is expected to match `\\d+,\\d+`.\n    ///\n    /// # Panics\n    ///\n    /// Panics if variable with provided name is set but contains inappropriate\n    /// value.\n    pub fn from_env_var(env_var_name: &str) -> Option<Self> {\n        let durations_str = env::var(env_var_name).ok()?;\n        let (warn_str, critical_str) = durations_str.split_once(',').unwrap_or_else(|| {\n            panic!(\n                \"Duration variable {} expected to have 2 numbers separated by comma, but got {}\",\n                env_var_name, durations_str\n            )\n        });\n\n        let parse_u64 = |v| {\n            u64::from_str(v).unwrap_or_else(|_| {\n                panic!(\n                    \"Duration value in variable {} is expected to be a number, but got {}\",\n                    env_var_name, v\n                )\n            })\n        };\n\n        let warn = parse_u64(warn_str);\n        let critical = parse_u64(critical_str);\n        if warn > critical {\n            panic!(\"Test execution warn time should be less or equal to the critical time\");\n        }\n\n        Some(Self::new(Duration::from_millis(warn), Duration::from_millis(critical)))\n    }\n}\n\n/// Structure with parameters for calculating test execution time.\n#[derive(Copy, Clone, Debug, Default, PartialEq, Eq)]\npub struct TestTimeOptions {\n    /// Denotes if the test critical execution time limit excess should be considered\n    /// a test failure.\n    pub error_on_excess: bool,\n    pub colored: bool,\n    pub unit_threshold: TimeThreshold,\n    pub integration_threshold: TimeThreshold,\n    pub doctest_threshold: TimeThreshold,\n}\n\nimpl TestTimeOptions {\n    pub fn new_from_env(error_on_excess: bool, colored: bool) -> Self {\n        let unit_threshold = TimeThreshold::from_env_var(time_constants::UNIT_ENV_NAME)\n            .unwrap_or_else(Self::default_unit);\n\n        let integration_threshold =\n            TimeThreshold::from_env_var(time_constants::INTEGRATION_ENV_NAME)\n                .unwrap_or_else(Self::default_integration);\n\n        let doctest_threshold = TimeThreshold::from_env_var(time_constants::DOCTEST_ENV_NAME)\n            .unwrap_or_else(Self::default_doctest);\n\n        Self { error_on_excess, colored, unit_threshold, integration_threshold, doctest_threshold }\n    }\n\n    pub fn is_warn(&self, test: &TestDesc, exec_time: &TestExecTime) -> bool {\n        exec_time.0 >= self.warn_time(test)\n    }\n\n    pub fn is_critical(&self, test: &TestDesc, exec_time: &TestExecTime) -> bool {\n        exec_time.0 >= self.critical_time(test)\n    }\n\n    fn warn_time(&self, test: &TestDesc) -> Duration {\n        match test.test_type {\n            TestType::UnitTest => self.unit_threshold.warn,\n            TestType::IntegrationTest => self.integration_threshold.warn,\n            TestType::DocTest => self.doctest_threshold.warn,\n            TestType::Unknown => time_constants::UNKNOWN_WARN,\n        }\n    }\n\n    fn critical_time(&self, test: &TestDesc) -> Duration {\n        match test.test_type {\n            TestType::UnitTest => self.unit_threshold.critical,\n            TestType::IntegrationTest => self.integration_threshold.critical,\n            TestType::DocTest => self.doctest_threshold.critical,\n            TestType::Unknown => time_constants::UNKNOWN_CRITICAL,\n        }\n    }\n\n    fn default_unit() -> TimeThreshold {\n        TimeThreshold::new(time_constants::UNIT_WARN, time_constants::UNIT_CRITICAL)\n    }\n\n    fn default_integration() -> TimeThreshold {\n        TimeThreshold::new(time_constants::INTEGRATION_WARN, time_constants::INTEGRATION_CRITICAL)\n    }\n\n    fn default_doctest() -> TimeThreshold {\n        TimeThreshold::new(time_constants::DOCTEST_WARN, time_constants::DOCTEST_CRITICAL)\n    }\n}\n"],[2098,"#![allow(missing_docs)]\n#![allow(deprecated)] // Float\n\nuse std::mem;\n\n#[cfg(test)]\nmod tests;\n\nfn local_sort(v: &mut [f64]) {\n    v.sort_by(|x: &f64, y: &f64| x.total_cmp(y));\n}\n\n/// Trait that provides simple descriptive statistics on a univariate set of numeric samples.\npub trait Stats {\n    /// Sum of the samples.\n    ///\n    /// Note: this method sacrifices performance at the altar of accuracy\n    /// Depends on IEEE-754 arithmetic guarantees. See proof of correctness at:\n    /// [\"Adaptive Precision Floating-Point Arithmetic and Fast Robust Geometric\n    /// Predicates\"][paper]\n    ///\n    /// [paper]: https://www.cs.cmu.edu/~quake-papers/robust-arithmetic.ps\n    fn sum(&self) -> f64;\n\n    /// Minimum value of the samples.\n    fn min(&self) -> f64;\n\n    /// Maximum value of the samples.\n    fn max(&self) -> f64;\n\n    /// Arithmetic mean (average) of the samples: sum divided by sample-count.\n    ///\n    /// See: <https://en.wikipedia.org/wiki/Arithmetic_mean>\n    fn mean(&self) -> f64;\n\n    /// Median of the samples: value separating the lower half of the samples from the higher half.\n    /// Equal to `self.percentile(50.0)`.\n    ///\n    /// See: <https://en.wikipedia.org/wiki/Median>\n    fn median(&self) -> f64;\n\n    /// Variance of the samples: bias-corrected mean of the squares of the differences of each\n    /// sample from the sample mean. Note that this calculates the _sample variance_ rather than the\n    /// population variance, which is assumed to be unknown. It therefore corrects the `(n-1)/n`\n    /// bias that would appear if we calculated a population variance, by dividing by `(n-1)` rather\n    /// than `n`.\n    ///\n    /// See: <https://en.wikipedia.org/wiki/Variance>\n    fn var(&self) -> f64;\n\n    /// Standard deviation: the square root of the sample variance.\n    ///\n    /// Note: this is not a robust statistic for non-normal distributions. Prefer the\n    /// `median_abs_dev` for unknown distributions.\n    ///\n    /// See: <https://en.wikipedia.org/wiki/Standard_deviation>\n    fn std_dev(&self) -> f64;\n\n    /// Standard deviation as a percent of the mean value. See `std_dev` and `mean`.\n    ///\n    /// Note: this is not a robust statistic for non-normal distributions. Prefer the\n    /// `median_abs_dev_pct` for unknown distributions.\n    fn std_dev_pct(&self) -> f64;\n\n    /// Scaled median of the absolute deviations of each sample from the sample median. This is a\n    /// robust (distribution-agnostic) estimator of sample variability. Use this in preference to\n    /// `std_dev` if you cannot assume your sample is normally distributed. Note that this is scaled\n    /// by the constant `1.4826` to allow its use as a consistent estimator for the standard\n    /// deviation.\n    ///\n    /// See: <https://en.wikipedia.org/wiki/Median_absolute_deviation>\n    fn median_abs_dev(&self) -> f64;\n\n    /// Median absolute deviation as a percent of the median. See `median_abs_dev` and `median`.\n    fn median_abs_dev_pct(&self) -> f64;\n\n    /// Percentile: the value below which `pct` percent of the values in `self` fall. For example,\n    /// percentile(95.0) will return the value `v` such that 95% of the samples `s` in `self`\n    /// satisfy `s <= v`.\n    ///\n    /// Calculated by linear interpolation between closest ranks.\n    ///\n    /// See: <https://en.wikipedia.org/wiki/Percentile>\n    fn percentile(&self, pct: f64) -> f64;\n\n    /// Quartiles of the sample: three values that divide the sample into four equal groups, each\n    /// with 1/4 of the data. The middle value is the median. See `median` and `percentile`. This\n    /// function may calculate the 3 quartiles more efficiently than 3 calls to `percentile`, but\n    /// is otherwise equivalent.\n    ///\n    /// See also: <https://en.wikipedia.org/wiki/Quartile>\n    fn quartiles(&self) -> (f64, f64, f64);\n\n    /// Inter-quartile range: the difference between the 25th percentile (1st quartile) and the 75th\n    /// percentile (3rd quartile). See `quartiles`.\n    ///\n    /// See also: <https://en.wikipedia.org/wiki/Interquartile_range>\n    fn iqr(&self) -> f64;\n}\n\n/// Extracted collection of all the summary statistics of a sample set.\n#[derive(Debug, Clone, PartialEq, Copy)]\n#[allow(missing_docs)]\npub struct Summary {\n    pub sum: f64,\n    pub min: f64,\n    pub max: f64,\n    pub mean: f64,\n    pub median: f64,\n    pub var: f64,\n    pub std_dev: f64,\n    pub std_dev_pct: f64,\n    pub median_abs_dev: f64,\n    pub median_abs_dev_pct: f64,\n    pub quartiles: (f64, f64, f64),\n    pub iqr: f64,\n}\n\nimpl Summary {\n    /// Construct a new summary of a sample set.\n    pub fn new(samples: &[f64]) -> Summary {\n        Summary {\n            sum: samples.sum(),\n            min: samples.min(),\n            max: samples.max(),\n            mean: samples.mean(),\n            median: samples.median(),\n            var: samples.var(),\n            std_dev: samples.std_dev(),\n            std_dev_pct: samples.std_dev_pct(),\n            median_abs_dev: samples.median_abs_dev(),\n            median_abs_dev_pct: samples.median_abs_dev_pct(),\n            quartiles: samples.quartiles(),\n            iqr: samples.iqr(),\n        }\n    }\n}\n\nimpl Stats for [f64] {\n    // FIXME #11059 handle NaN, inf and overflow\n    fn sum(&self) -> f64 {\n        let mut partials = vec![];\n\n        for &x in self {\n            let mut x = x;\n            let mut j = 0;\n            // This inner loop applies `hi`/`lo` summation to each\n            // partial so that the list of partial sums remains exact.\n            for i in 0..partials.len() {\n                let mut y: f64 = partials[i];\n                if x.abs() < y.abs() {\n                    mem::swap(&mut x, &mut y);\n                }\n                // Rounded `x+y` is stored in `hi` with round-off stored in\n                // `lo`. Together `hi+lo` are exactly equal to `x+y`.\n                let hi = x + y;\n                let lo = y - (hi - x);\n                if lo != 0.0 {\n                    partials[j] = lo;\n                    j += 1;\n                }\n                x = hi;\n            }\n            if j >= partials.len() {\n                partials.push(x);\n            } else {\n                partials[j] = x;\n                partials.truncate(j + 1);\n            }\n        }\n        let zero: f64 = 0.0;\n        partials.iter().fold(zero, |p, q| p + *q)\n    }\n\n    fn min(&self) -> f64 {\n        assert!(!self.is_empty());\n        self.iter().fold(self[0], |p, q| p.min(*q))\n    }\n\n    fn max(&self) -> f64 {\n        assert!(!self.is_empty());\n        self.iter().fold(self[0], |p, q| p.max(*q))\n    }\n\n    fn mean(&self) -> f64 {\n        assert!(!self.is_empty());\n        self.sum() / (self.len() as f64)\n    }\n\n    fn median(&self) -> f64 {\n        self.percentile(50_f64)\n    }\n\n    fn var(&self) -> f64 {\n        if self.len() < 2 {\n            0.0\n        } else {\n            let mean = self.mean();\n            let mut v: f64 = 0.0;\n            for s in self {\n                let x = *s - mean;\n                v += x * x;\n            }\n            // N.B., this is _supposed to be_ len-1, not len. If you\n            // change it back to len, you will be calculating a\n            // population variance, not a sample variance.\n            let denom = (self.len() - 1) as f64;\n            v / denom\n        }\n    }\n\n    fn std_dev(&self) -> f64 {\n        self.var().sqrt()\n    }\n\n    fn std_dev_pct(&self) -> f64 {\n        let hundred = 100_f64;\n        (self.std_dev() / self.mean()) * hundred\n    }\n\n    fn median_abs_dev(&self) -> f64 {\n        let med = self.median();\n        let abs_devs: Vec<f64> = self.iter().map(|&v| (med - v).abs()).collect();\n        // This constant is derived by smarter statistics brains than me, but it is\n        // consistent with how R and other packages treat the MAD.\n        let number = 1.4826;\n        abs_devs.median() * number\n    }\n\n    fn median_abs_dev_pct(&self) -> f64 {\n        let hundred = 100_f64;\n        (self.median_abs_dev() / self.median()) * hundred\n    }\n\n    fn percentile(&self, pct: f64) -> f64 {\n        let mut tmp = self.to_vec();\n        local_sort(&mut tmp);\n        percentile_of_sorted(&tmp, pct)\n    }\n\n    fn quartiles(&self) -> (f64, f64, f64) {\n        let mut tmp = self.to_vec();\n        local_sort(&mut tmp);\n        let first = 25_f64;\n        let a = percentile_of_sorted(&tmp, first);\n        let second = 50_f64;\n        let b = percentile_of_sorted(&tmp, second);\n        let third = 75_f64;\n        let c = percentile_of_sorted(&tmp, third);\n        (a, b, c)\n    }\n\n    fn iqr(&self) -> f64 {\n        let (a, _, c) = self.quartiles();\n        c - a\n    }\n}\n\n// Helper function: extract a value representing the `pct` percentile of a sorted sample-set, using\n// linear interpolation. If samples are not sorted, return nonsensical value.\nfn percentile_of_sorted(sorted_samples: &[f64], pct: f64) -> f64 {\n    assert!(!sorted_samples.is_empty());\n    if sorted_samples.len() == 1 {\n        return sorted_samples[0];\n    }\n    let zero: f64 = 0.0;\n    assert!(zero <= pct);\n    let hundred = 100_f64;\n    assert!(pct <= hundred);\n    if pct == hundred {\n        return sorted_samples[sorted_samples.len() - 1];\n    }\n    let length = (sorted_samples.len() - 1) as f64;\n    let rank = (pct / hundred) * length;\n    let lrank = rank.floor();\n    let d = rank - lrank;\n    let n = lrank as usize;\n    let lo = sorted_samples[n];\n    let hi = sorted_samples[n + 1];\n    lo + (hi - lo) * d\n}\n\n/// Winsorize a set of samples, replacing values above the `100-pct` percentile\n/// and below the `pct` percentile with those percentiles themselves. This is a\n/// way of minimizing the effect of outliers, at the cost of biasing the sample.\n/// It differs from trimming in that it does not change the number of samples,\n/// just changes the values of those that are outliers.\n///\n/// See: <https://en.wikipedia.org/wiki/Winsorising>\npub fn winsorize(samples: &mut [f64], pct: f64) {\n    let mut tmp = samples.to_vec();\n    local_sort(&mut tmp);\n    let lo = percentile_of_sorted(&tmp, pct);\n    let hundred = 100_f64;\n    let hi = percentile_of_sorted(&tmp, hundred - pct);\n    for samp in samples {\n        if *samp > hi {\n            *samp = hi\n        } else if *samp < lo {\n            *samp = lo\n        }\n    }\n}\n"],[2099,"//! Benchmarking module.\nuse super::{\n    event::CompletedTest,\n    options::BenchMode,\n    test_result::TestResult,\n    types::{TestDesc, TestId},\n    Sender,\n};\n\nuse crate::stats;\nuse std::cmp;\nuse std::io;\nuse std::panic::{catch_unwind, AssertUnwindSafe};\nuse std::sync::{Arc, Mutex};\nuse std::time::{Duration, Instant};\n\n/// An identity function that *__hints__* to the compiler to be maximally pessimistic about what\n/// `black_box` could do.\n///\n/// See [`std::hint::black_box`] for details.\n#[inline(always)]\npub fn black_box<T>(dummy: T) -> T {\n    std::hint::black_box(dummy)\n}\n\n/// Manager of the benchmarking runs.\n///\n/// This is fed into functions marked with `#[bench]` to allow for\n/// set-up & tear-down before running a piece of code repeatedly via a\n/// call to `iter`.\n#[derive(Clone)]\npub struct Bencher {\n    mode: BenchMode,\n    summary: Option<stats::Summary>,\n    pub bytes: u64,\n}\n\nimpl Bencher {\n    /// Callback for benchmark functions to run in their body.\n    pub fn iter<T, F>(&mut self, mut inner: F)\n    where\n        F: FnMut() -> T,\n    {\n        if self.mode == BenchMode::Single {\n            ns_iter_inner(&mut inner, 1);\n            return;\n        }\n\n        self.summary = Some(iter(&mut inner));\n    }\n\n    pub fn bench<F>(&mut self, mut f: F) -> Option<stats::Summary>\n    where\n        F: FnMut(&mut Bencher),\n    {\n        f(self);\n        self.summary\n    }\n}\n\n#[derive(Debug, Clone, PartialEq)]\npub struct BenchSamples {\n    pub ns_iter_summ: stats::Summary,\n    pub mb_s: usize,\n}\n\npub fn fmt_bench_samples(bs: &BenchSamples) -> String {\n    use std::fmt::Write;\n    let mut output = String::new();\n\n    let median = bs.ns_iter_summ.median as usize;\n    let deviation = (bs.ns_iter_summ.max - bs.ns_iter_summ.min) as usize;\n\n    write!(\n        output,\n        \"{:>11} ns/iter (+/- {})\",\n        fmt_thousands_sep(median, ','),\n        fmt_thousands_sep(deviation, ',')\n    )\n    .unwrap();\n    if bs.mb_s != 0 {\n        write!(output, \" = {} MB/s\", bs.mb_s).unwrap();\n    }\n    output\n}\n\n// Format a number with thousands separators\nfn fmt_thousands_sep(mut n: usize, sep: char) -> String {\n    use std::fmt::Write;\n    let mut output = String::new();\n    let mut trailing = false;\n    for &pow in &[9, 6, 3, 0] {\n        let base = 10_usize.pow(pow);\n        if pow == 0 || trailing || n / base != 0 {\n            if !trailing {\n                write!(output, \"{}\", n / base).unwrap();\n            } else {\n                write!(output, \"{:03}\", n / base).unwrap();\n            }\n            if pow != 0 {\n                output.push(sep);\n            }\n            trailing = true;\n        }\n        n %= base;\n    }\n\n    output\n}\n\nfn ns_iter_inner<T, F>(inner: &mut F, k: u64) -> u64\nwhere\n    F: FnMut() -> T,\n{\n    let start = Instant::now();\n    for _ in 0..k {\n        black_box(inner());\n    }\n    start.elapsed().as_nanos() as u64\n}\n\npub fn iter<T, F>(inner: &mut F) -> stats::Summary\nwhere\n    F: FnMut() -> T,\n{\n    // Initial bench run to get ballpark figure.\n    let ns_single = ns_iter_inner(inner, 1);\n\n    // Try to estimate iter count for 1ms falling back to 1m\n    // iterations if first run took < 1ns.\n    let ns_target_total = 1_000_000; // 1ms\n    let mut n = ns_target_total / cmp::max(1, ns_single);\n\n    // if the first run took more than 1ms we don't want to just\n    // be left doing 0 iterations on every loop. The unfortunate\n    // side effect of not being able to do as many runs is\n    // automatically handled by the statistical analysis below\n    // (i.e., larger error bars).\n    n = cmp::max(1, n);\n\n    let mut total_run = Duration::new(0, 0);\n    let samples: &mut [f64] = &mut [0.0_f64; 50];\n    loop {\n        let loop_start = Instant::now();\n\n        for p in &mut *samples {\n            *p = ns_iter_inner(inner, n) as f64 / n as f64;\n        }\n\n        stats::winsorize(samples, 5.0);\n        let summ = stats::Summary::new(samples);\n\n        for p in &mut *samples {\n            let ns = ns_iter_inner(inner, 5 * n);\n            *p = ns as f64 / (5 * n) as f64;\n        }\n\n        stats::winsorize(samples, 5.0);\n        let summ5 = stats::Summary::new(samples);\n\n        let loop_run = loop_start.elapsed();\n\n        // If we've run for 100ms and seem to have converged to a\n        // stable median.\n        if loop_run > Duration::from_millis(100)\n            && summ.median_abs_dev_pct < 1.0\n            && summ.median - summ5.median < summ5.median_abs_dev\n        {\n            return summ5;\n        }\n\n        total_run += loop_run;\n        // Longest we ever run for is 3s.\n        if total_run > Duration::from_secs(3) {\n            return summ5;\n        }\n\n        // If we overflow here just return the results so far. We check a\n        // multiplier of 10 because we're about to multiply by 2 and the\n        // next iteration of the loop will also multiply by 5 (to calculate\n        // the summ5 result)\n        n = match n.checked_mul(10) {\n            Some(_) => n * 2,\n            None => {\n                return summ5;\n            }\n        };\n    }\n}\n\npub fn benchmark<F>(\n    id: TestId,\n    desc: TestDesc,\n    monitor_ch: Sender<CompletedTest>,\n    nocapture: bool,\n    f: F,\n) where\n    F: FnMut(&mut Bencher),\n{\n    let mut bs = Bencher { mode: BenchMode::Auto, summary: None, bytes: 0 };\n\n    let data = Arc::new(Mutex::new(Vec::new()));\n\n    if !nocapture {\n        io::set_output_capture(Some(data.clone()));\n    }\n\n    let result = catch_unwind(AssertUnwindSafe(|| bs.bench(f)));\n\n    io::set_output_capture(None);\n\n    let test_result = match result {\n        //bs.bench(f) {\n        Ok(Some(ns_iter_summ)) => {\n            let ns_iter = cmp::max(ns_iter_summ.median as u64, 1);\n            let mb_s = bs.bytes * 1000 / ns_iter;\n\n            let bs = BenchSamples { ns_iter_summ, mb_s: mb_s as usize };\n            TestResult::TrBench(bs)\n        }\n        Ok(None) => {\n            // iter not called, so no data.\n            // FIXME: error in this case?\n            let samples: &mut [f64] = &mut [0.0_f64; 1];\n            let bs = BenchSamples { ns_iter_summ: stats::Summary::new(samples), mb_s: 0 };\n            TestResult::TrBench(bs)\n        }\n        Err(_) => TestResult::TrFailed,\n    };\n\n    let stdout = data.lock().unwrap().to_vec();\n    let message = CompletedTest::new(id, desc, test_result, None, stdout);\n    monitor_ch.send(message).unwrap();\n}\n\npub fn run_once<F>(f: F)\nwhere\n    F: FnMut(&mut Bencher),\n{\n    let mut bs = Bencher { mode: BenchMode::Single, summary: None, bytes: 0 };\n    bs.bench(f);\n}\n"],[2100,"//! Common types used by `libtest`.\n\nuse std::borrow::Cow;\nuse std::fmt;\n\nuse super::bench::Bencher;\nuse super::options;\n\npub use NamePadding::*;\npub use TestFn::*;\npub use TestName::*;\n\n/// Type of the test according to the [rust book](https://doc.rust-lang.org/cargo/guide/tests.html)\n/// conventions.\n#[derive(Copy, Clone, Debug, PartialEq, Eq, Hash)]\npub enum TestType {\n    /// Unit-tests are expected to be in the `src` folder of the crate.\n    UnitTest,\n    /// Integration-style tests are expected to be in the `tests` folder of the crate.\n    IntegrationTest,\n    /// Doctests are created by the `librustdoc` manually, so it's a different type of test.\n    DocTest,\n    /// Tests for the sources that don't follow the project layout convention\n    /// (e.g. tests in raw `main.rs` compiled by calling `rustc --test` directly).\n    Unknown,\n}\n\n#[derive(Clone, Copy, PartialEq, Eq, Hash, Debug)]\npub enum NamePadding {\n    PadNone,\n    PadOnRight,\n}\n\n// The name of a test. By convention this follows the rules for rust\n// paths; i.e., it should be a series of identifiers separated by double\n// colons. This way if some test runner wants to arrange the tests\n// hierarchically it may.\n#[derive(Clone, PartialEq, Eq, Hash, Debug)]\npub enum TestName {\n    StaticTestName(&'static str),\n    DynTestName(String),\n    AlignedTestName(Cow<'static, str>, NamePadding),\n}\n\nimpl TestName {\n    pub fn as_slice(&self) -> &str {\n        match *self {\n            StaticTestName(s) => s,\n            DynTestName(ref s) => s,\n            AlignedTestName(ref s, _) => &*s,\n        }\n    }\n\n    pub fn padding(&self) -> NamePadding {\n        match self {\n            &AlignedTestName(_, p) => p,\n            _ => PadNone,\n        }\n    }\n\n    pub fn with_padding(&self, padding: NamePadding) -> TestName {\n        let name = match *self {\n            TestName::StaticTestName(name) => Cow::Borrowed(name),\n            TestName::DynTestName(ref name) => Cow::Owned(name.clone()),\n            TestName::AlignedTestName(ref name, _) => name.clone(),\n        };\n\n        TestName::AlignedTestName(name, padding)\n    }\n}\nimpl fmt::Display for TestName {\n    fn fmt(&self, f: &mut fmt::Formatter<'_>) -> fmt::Result {\n        fmt::Display::fmt(self.as_slice(), f)\n    }\n}\n\n/// Represents a benchmark function.\npub trait TDynBenchFn: Send {\n    fn run(&self, harness: &mut Bencher);\n}\n\n// A function that runs a test. If the function returns successfully,\n// the test succeeds; if the function panics then the test fails. We\n// may need to come up with a more clever definition of test in order\n// to support isolation of tests into threads.\npub enum TestFn {\n    StaticTestFn(fn()),\n    StaticBenchFn(fn(&mut Bencher)),\n    DynTestFn(Box<dyn FnOnce() + Send>),\n    DynBenchFn(Box<dyn TDynBenchFn + 'static>),\n}\n\nimpl TestFn {\n    pub fn padding(&self) -> NamePadding {\n        match *self {\n            StaticTestFn(..) => PadNone,\n            StaticBenchFn(..) => PadOnRight,\n            DynTestFn(..) => PadNone,\n            DynBenchFn(..) => PadOnRight,\n        }\n    }\n}\n\nimpl fmt::Debug for TestFn {\n    fn fmt(&self, f: &mut fmt::Formatter<'_>) -> fmt::Result {\n        f.write_str(match *self {\n            StaticTestFn(..) => \"StaticTestFn(..)\",\n            StaticBenchFn(..) => \"StaticBenchFn(..)\",\n            DynTestFn(..) => \"DynTestFn(..)\",\n            DynBenchFn(..) => \"DynBenchFn(..)\",\n        })\n    }\n}\n\n// A unique integer associated with each test.\n#[derive(Clone, Copy, Debug, Eq, Hash, PartialEq)]\npub struct TestId(pub usize);\n\n// The definition of a single test. A test runner will run a list of\n// these.\n#[derive(Clone, Debug)]\npub struct TestDesc {\n    pub name: TestName,\n    pub ignore: bool,\n    pub should_panic: options::ShouldPanic,\n    pub allow_fail: bool,\n    #[cfg(not(bootstrap))]\n    pub compile_fail: bool,\n    #[cfg(not(bootstrap))]\n    pub no_run: bool,\n    pub test_type: TestType,\n}\n\nimpl TestDesc {\n    pub fn padded_name(&self, column_count: usize, align: NamePadding) -> String {\n        let mut name = String::from(self.name.as_slice());\n        let fill = column_count.saturating_sub(name.len());\n        let pad = \" \".repeat(fill);\n        match align {\n            PadNone => name,\n            PadOnRight => {\n                name.push_str(&pad);\n                name\n            }\n        }\n    }\n\n    /// Returns None for ignored test or that that are just run, otherwise give a description of the type of test.\n    /// Descriptions include \"should panic\", \"compile fail\" and \"compile\".\n    #[cfg(not(bootstrap))]\n    pub fn test_mode(&self) -> Option<&'static str> {\n        if self.ignore {\n            return None;\n        }\n        match self.should_panic {\n            options::ShouldPanic::Yes | options::ShouldPanic::YesWithMessage(_) => {\n                return Some(\"should panic\");\n            }\n            options::ShouldPanic::No => {}\n        }\n        if self.allow_fail {\n            return Some(\"allow fail\");\n        }\n        if self.compile_fail {\n            return Some(\"compile fail\");\n        }\n        if self.no_run {\n            return Some(\"compile\");\n        }\n        None\n    }\n\n    #[cfg(bootstrap)]\n    pub fn test_mode(&self) -> Option<&'static str> {\n        None\n    }\n}\n\n#[derive(Debug)]\npub struct TestDescAndFn {\n    pub desc: TestDesc,\n    pub testfn: TestFn,\n}\n"],[2101,"use std::{io, io::prelude::Write};\n\nuse super::OutputFormatter;\nuse crate::{\n    bench::fmt_bench_samples,\n    console::{ConsoleTestState, OutputLocation},\n    test_result::TestResult,\n    time,\n    types::TestDesc,\n};\n\npub(crate) struct PrettyFormatter<T> {\n    out: OutputLocation<T>,\n    use_color: bool,\n    time_options: Option<time::TestTimeOptions>,\n\n    /// Number of columns to fill when aligning names\n    max_name_len: usize,\n\n    is_multithreaded: bool,\n}\n\nimpl<T: Write> PrettyFormatter<T> {\n    pub fn new(\n        out: OutputLocation<T>,\n        use_color: bool,\n        max_name_len: usize,\n        is_multithreaded: bool,\n        time_options: Option<time::TestTimeOptions>,\n    ) -> Self {\n        PrettyFormatter { out, use_color, max_name_len, is_multithreaded, time_options }\n    }\n\n    #[cfg(test)]\n    pub fn output_location(&self) -> &OutputLocation<T> {\n        &self.out\n    }\n\n    pub fn write_ok(&mut self) -> io::Result<()> {\n        self.write_short_result(\"ok\", term::color::GREEN)\n    }\n\n    pub fn write_failed(&mut self) -> io::Result<()> {\n        self.write_short_result(\"FAILED\", term::color::RED)\n    }\n\n    pub fn write_ignored(&mut self) -> io::Result<()> {\n        self.write_short_result(\"ignored\", term::color::YELLOW)\n    }\n\n    pub fn write_allowed_fail(&mut self) -> io::Result<()> {\n        self.write_short_result(\"FAILED (allowed)\", term::color::YELLOW)\n    }\n\n    pub fn write_time_failed(&mut self) -> io::Result<()> {\n        self.write_short_result(\"FAILED (time limit exceeded)\", term::color::RED)\n    }\n\n    pub fn write_bench(&mut self) -> io::Result<()> {\n        self.write_pretty(\"bench\", term::color::CYAN)\n    }\n\n    pub fn write_short_result(\n        &mut self,\n        result: &str,\n        color: term::color::Color,\n    ) -> io::Result<()> {\n        self.write_pretty(result, color)\n    }\n\n    pub fn write_pretty(&mut self, word: &str, color: term::color::Color) -> io::Result<()> {\n        match self.out {\n            OutputLocation::Pretty(ref mut term) => {\n                if self.use_color {\n                    term.fg(color)?;\n                }\n                term.write_all(word.as_bytes())?;\n                if self.use_color {\n                    term.reset()?;\n                }\n                term.flush()\n            }\n            OutputLocation::Raw(ref mut stdout) => {\n                stdout.write_all(word.as_bytes())?;\n                stdout.flush()\n            }\n        }\n    }\n\n    pub fn write_plain<S: AsRef<str>>(&mut self, s: S) -> io::Result<()> {\n        let s = s.as_ref();\n        self.out.write_all(s.as_bytes())?;\n        self.out.flush()\n    }\n\n    fn write_time(\n        &mut self,\n        desc: &TestDesc,\n        exec_time: Option<&time::TestExecTime>,\n    ) -> io::Result<()> {\n        if let (Some(opts), Some(time)) = (self.time_options, exec_time) {\n            let time_str = format!(\" <{}>\", time);\n\n            let color = if opts.colored {\n                if opts.is_critical(desc, time) {\n                    Some(term::color::RED)\n                } else if opts.is_warn(desc, time) {\n                    Some(term::color::YELLOW)\n                } else {\n                    None\n                }\n            } else {\n                None\n            };\n\n            match color {\n                Some(color) => self.write_pretty(&time_str, color)?,\n                None => self.write_plain(&time_str)?,\n            }\n        }\n\n        Ok(())\n    }\n\n    fn write_results(\n        &mut self,\n        inputs: &Vec<(TestDesc, Vec<u8>)>,\n        results_type: &str,\n    ) -> io::Result<()> {\n        let results_out_str = format!(\"\\n{}:\\n\", results_type);\n\n        self.write_plain(&results_out_str)?;\n\n        let mut results = Vec::new();\n        let mut stdouts = String::new();\n        for &(ref f, ref stdout) in inputs {\n            results.push(f.name.to_string());\n            if !stdout.is_empty() {\n                stdouts.push_str(&format!(\"---- {} stdout ----\\n\", f.name));\n                let output = String::from_utf8_lossy(stdout);\n                stdouts.push_str(&output);\n                stdouts.push('\\n');\n            }\n        }\n        if !stdouts.is_empty() {\n            self.write_plain(\"\\n\")?;\n            self.write_plain(&stdouts)?;\n        }\n\n        self.write_plain(&results_out_str)?;\n        results.sort();\n        for name in &results {\n            self.write_plain(&format!(\"    {}\\n\", name))?;\n        }\n        Ok(())\n    }\n\n    pub fn write_successes(&mut self, state: &ConsoleTestState) -> io::Result<()> {\n        self.write_results(&state.not_failures, \"successes\")\n    }\n\n    pub fn write_failures(&mut self, state: &ConsoleTestState) -> io::Result<()> {\n        self.write_results(&state.failures, \"failures\")\n    }\n\n    pub fn write_time_failures(&mut self, state: &ConsoleTestState) -> io::Result<()> {\n        self.write_results(&state.time_failures, \"failures (time limit exceeded)\")\n    }\n\n    fn write_test_name(&mut self, desc: &TestDesc) -> io::Result<()> {\n        let name = desc.padded_name(self.max_name_len, desc.name.padding());\n        if let Some(test_mode) = desc.test_mode() {\n            self.write_plain(&format!(\"test {} - {} ... \", name, test_mode))?;\n        } else {\n            self.write_plain(&format!(\"test {} ... \", name))?;\n        }\n\n        Ok(())\n    }\n}\n\nimpl<T: Write> OutputFormatter for PrettyFormatter<T> {\n    fn write_run_start(&mut self, test_count: usize) -> io::Result<()> {\n        let noun = if test_count != 1 { \"tests\" } else { \"test\" };\n        self.write_plain(&format!(\"\\nrunning {} {}\\n\", test_count, noun))\n    }\n\n    fn write_test_start(&mut self, desc: &TestDesc) -> io::Result<()> {\n        // When running tests concurrently, we should not print\n        // the test's name as the result will be mis-aligned.\n        // When running the tests serially, we print the name here so\n        // that the user can see which test hangs.\n        if !self.is_multithreaded {\n            self.write_test_name(desc)?;\n        }\n\n        Ok(())\n    }\n\n    fn write_result(\n        &mut self,\n        desc: &TestDesc,\n        result: &TestResult,\n        exec_time: Option<&time::TestExecTime>,\n        _: &[u8],\n        _: &ConsoleTestState,\n    ) -> io::Result<()> {\n        if self.is_multithreaded {\n            self.write_test_name(desc)?;\n        }\n\n        match *result {\n            TestResult::TrOk => self.write_ok()?,\n            TestResult::TrFailed | TestResult::TrFailedMsg(_) => self.write_failed()?,\n            TestResult::TrIgnored => self.write_ignored()?,\n            TestResult::TrAllowedFail => self.write_allowed_fail()?,\n            TestResult::TrBench(ref bs) => {\n                self.write_bench()?;\n                self.write_plain(&format!(\": {}\", fmt_bench_samples(bs)))?;\n            }\n            TestResult::TrTimedFail => self.write_time_failed()?,\n        }\n\n        self.write_time(desc, exec_time)?;\n        self.write_plain(\"\\n\")\n    }\n\n    fn write_timeout(&mut self, desc: &TestDesc) -> io::Result<()> {\n        self.write_plain(&format!(\n            \"test {} has been running for over {} seconds\\n\",\n            desc.name,\n            time::TEST_WARN_TIMEOUT_S\n        ))\n    }\n\n    fn write_run_finish(&mut self, state: &ConsoleTestState) -> io::Result<bool> {\n        if state.options.display_output {\n            self.write_successes(state)?;\n        }\n        let success = state.failed == 0;\n        if !success {\n            if !state.failures.is_empty() {\n                self.write_failures(state)?;\n            }\n\n            if !state.time_failures.is_empty() {\n                self.write_time_failures(state)?;\n            }\n        }\n\n        self.write_plain(\"\\ntest result: \")?;\n\n        if success {\n            // There's no parallelism at this point so it's safe to use color\n            self.write_pretty(\"ok\", term::color::GREEN)?;\n        } else {\n            self.write_pretty(\"FAILED\", term::color::RED)?;\n        }\n\n        let s = if state.allowed_fail > 0 {\n            format!(\n                \". {} passed; {} failed ({} allowed); {} ignored; {} measured; {} filtered out\",\n                state.passed,\n                state.failed + state.allowed_fail,\n                state.allowed_fail,\n                state.ignored,\n                state.measured,\n                state.filtered_out\n            )\n        } else {\n            format!(\n                \". {} passed; {} failed; {} ignored; {} measured; {} filtered out\",\n                state.passed, state.failed, state.ignored, state.measured, state.filtered_out\n            )\n        };\n\n        self.write_plain(&s)?;\n\n        if let Some(ref exec_time) = state.exec_time {\n            let time_str = format!(\"; finished in {}\", exec_time);\n            self.write_plain(&time_str)?;\n        }\n\n        self.write_plain(\"\\n\\n\")?;\n\n        Ok(success)\n    }\n}\n"],[2102,"use std::io::{self, prelude::Write};\nuse std::time::Duration;\n\nuse super::OutputFormatter;\nuse crate::{\n    console::{ConsoleTestState, OutputLocation},\n    test_result::TestResult,\n    time,\n    types::{TestDesc, TestType},\n};\n\npub struct JunitFormatter<T> {\n    out: OutputLocation<T>,\n    results: Vec<(TestDesc, TestResult, Duration)>,\n}\n\nimpl<T: Write> JunitFormatter<T> {\n    pub fn new(out: OutputLocation<T>) -> Self {\n        Self { out, results: Vec::new() }\n    }\n\n    fn write_message(&mut self, s: &str) -> io::Result<()> {\n        assert!(!s.contains('\\n'));\n\n        self.out.write_all(s.as_ref())\n    }\n}\n\nimpl<T: Write> OutputFormatter for JunitFormatter<T> {\n    fn write_run_start(&mut self, _test_count: usize) -> io::Result<()> {\n        // We write xml header on run start\n        self.write_message(&\"<?xml version=\\\"1.0\\\" encoding=\\\"UTF-8\\\"?>\")\n    }\n\n    fn write_test_start(&mut self, _desc: &TestDesc) -> io::Result<()> {\n        // We do not output anything on test start.\n        Ok(())\n    }\n\n    fn write_timeout(&mut self, _desc: &TestDesc) -> io::Result<()> {\n        // We do not output anything on test timeout.\n        Ok(())\n    }\n\n    fn write_result(\n        &mut self,\n        desc: &TestDesc,\n        result: &TestResult,\n        exec_time: Option<&time::TestExecTime>,\n        _stdout: &[u8],\n        _state: &ConsoleTestState,\n    ) -> io::Result<()> {\n        // Because the testsuit node holds some of the information as attributes, we can't write it\n        // until all of the tests has ran. Instead of writting every result as they come in, we add\n        // them to a Vec and write them all at once when run is complete.\n        let duration = exec_time.map(|t| t.0.clone()).unwrap_or_default();\n        self.results.push((desc.clone(), result.clone(), duration));\n        Ok(())\n    }\n    fn write_run_finish(&mut self, state: &ConsoleTestState) -> io::Result<bool> {\n        self.write_message(\"<testsuites>\")?;\n\n        self.write_message(&*format!(\n            \"<testsuite name=\\\"test\\\" package=\\\"test\\\" id=\\\"0\\\" \\\n             errors=\\\"0\\\" \\\n             failures=\\\"{}\\\" \\\n             tests=\\\"{}\\\" \\\n             skipped=\\\"{}\\\" \\\n             >\",\n            state.failed, state.total, state.ignored\n        ))?;\n        for (desc, result, duration) in std::mem::replace(&mut self.results, Vec::new()) {\n            let (class_name, test_name) = parse_class_name(&desc);\n            match result {\n                TestResult::TrIgnored => { /* no-op */ }\n                TestResult::TrFailed => {\n                    self.write_message(&*format!(\n                        \"<testcase classname=\\\"{}\\\" \\\n                         name=\\\"{}\\\" time=\\\"{}\\\">\",\n                        class_name,\n                        test_name,\n                        duration.as_secs_f64()\n                    ))?;\n                    self.write_message(\"<failure type=\\\"assert\\\"/>\")?;\n                    self.write_message(\"</testcase>\")?;\n                }\n\n                TestResult::TrFailedMsg(ref m) => {\n                    self.write_message(&*format!(\n                        \"<testcase classname=\\\"{}\\\" \\\n                         name=\\\"{}\\\" time=\\\"{}\\\">\",\n                        class_name,\n                        test_name,\n                        duration.as_secs_f64()\n                    ))?;\n                    self.write_message(&*format!(\"<failure message=\\\"{}\\\" type=\\\"assert\\\"/>\", m))?;\n                    self.write_message(\"</testcase>\")?;\n                }\n\n                TestResult::TrTimedFail => {\n                    self.write_message(&*format!(\n                        \"<testcase classname=\\\"{}\\\" \\\n                         name=\\\"{}\\\" time=\\\"{}\\\">\",\n                        class_name,\n                        test_name,\n                        duration.as_secs_f64()\n                    ))?;\n                    self.write_message(\"<failure type=\\\"timeout\\\"/>\")?;\n                    self.write_message(\"</testcase>\")?;\n                }\n\n                TestResult::TrBench(ref b) => {\n                    self.write_message(&*format!(\n                        \"<testcase classname=\\\"benchmark::{}\\\" \\\n                         name=\\\"{}\\\" time=\\\"{}\\\" />\",\n                        class_name, test_name, b.ns_iter_summ.sum\n                    ))?;\n                }\n\n                TestResult::TrOk | TestResult::TrAllowedFail => {\n                    self.write_message(&*format!(\n                        \"<testcase classname=\\\"{}\\\" \\\n                         name=\\\"{}\\\" time=\\\"{}\\\"/>\",\n                        class_name,\n                        test_name,\n                        duration.as_secs_f64()\n                    ))?;\n                }\n            }\n        }\n        self.write_message(\"<system-out/>\")?;\n        self.write_message(\"<system-err/>\")?;\n        self.write_message(\"</testsuite>\")?;\n        self.write_message(\"</testsuites>\")?;\n\n        Ok(state.failed == 0)\n    }\n}\n\nfn parse_class_name(desc: &TestDesc) -> (String, String) {\n    match desc.test_type {\n        TestType::UnitTest => parse_class_name_unit(desc),\n        TestType::DocTest => parse_class_name_doc(desc),\n        TestType::IntegrationTest => parse_class_name_integration(desc),\n        TestType::Unknown => (String::from(\"unknown\"), String::from(desc.name.as_slice())),\n    }\n}\n\nfn parse_class_name_unit(desc: &TestDesc) -> (String, String) {\n    // Module path => classname\n    // Function name => name\n    let module_segments: Vec<&str> = desc.name.as_slice().split(\"::\").collect();\n    let (class_name, test_name) = match module_segments[..] {\n        [test] => (String::from(\"crate\"), String::from(test)),\n        [ref path @ .., test] => (path.join(\"::\"), String::from(test)),\n        [..] => unreachable!(),\n    };\n    (class_name, test_name)\n}\n\nfn parse_class_name_doc(desc: &TestDesc) -> (String, String) {\n    // File path => classname\n    // Line # => test name\n    let segments: Vec<&str> = desc.name.as_slice().split(\" - \").collect();\n    let (class_name, test_name) = match segments[..] {\n        [file, line] => (String::from(file.trim()), String::from(line.trim())),\n        [..] => unreachable!(),\n    };\n    (class_name, test_name)\n}\n\nfn parse_class_name_integration(desc: &TestDesc) -> (String, String) {\n    (String::from(\"integration\"), String::from(desc.name.as_slice()))\n}\n"],[2103,"use std::{io, io::prelude::Write};\n\nuse crate::{\n    console::ConsoleTestState,\n    test_result::TestResult,\n    time,\n    types::{TestDesc, TestName},\n};\n\nmod json;\nmod junit;\nmod pretty;\nmod terse;\n\npub(crate) use self::json::JsonFormatter;\npub(crate) use self::junit::JunitFormatter;\npub(crate) use self::pretty::PrettyFormatter;\npub(crate) use self::terse::TerseFormatter;\n\npub(crate) trait OutputFormatter {\n    fn write_run_start(&mut self, test_count: usize) -> io::Result<()>;\n    fn write_test_start(&mut self, desc: &TestDesc) -> io::Result<()>;\n    fn write_timeout(&mut self, desc: &TestDesc) -> io::Result<()>;\n    fn write_result(\n        &mut self,\n        desc: &TestDesc,\n        result: &TestResult,\n        exec_time: Option<&time::TestExecTime>,\n        stdout: &[u8],\n        state: &ConsoleTestState,\n    ) -> io::Result<()>;\n    fn write_run_finish(&mut self, state: &ConsoleTestState) -> io::Result<bool>;\n}\n\npub(crate) fn write_stderr_delimiter(test_output: &mut Vec<u8>, test_name: &TestName) {\n    match test_output.last() {\n        Some(b'\\n') => (),\n        Some(_) => test_output.push(b'\\n'),\n        None => (),\n    }\n    writeln!(test_output, \"---- {} stderr ----\", test_name).unwrap();\n}\n"],[2104,"use std::{io, io::prelude::Write};\n\nuse super::OutputFormatter;\nuse crate::{\n    bench::fmt_bench_samples,\n    console::{ConsoleTestState, OutputLocation},\n    test_result::TestResult,\n    time,\n    types::NamePadding,\n    types::TestDesc,\n};\n\n// insert a '\\n' after 100 tests in quiet mode\nconst QUIET_MODE_MAX_COLUMN: usize = 100;\n\npub(crate) struct TerseFormatter<T> {\n    out: OutputLocation<T>,\n    use_color: bool,\n    is_multithreaded: bool,\n    /// Number of columns to fill when aligning names\n    max_name_len: usize,\n\n    test_count: usize,\n    total_test_count: usize,\n}\n\nimpl<T: Write> TerseFormatter<T> {\n    pub fn new(\n        out: OutputLocation<T>,\n        use_color: bool,\n        max_name_len: usize,\n        is_multithreaded: bool,\n    ) -> Self {\n        TerseFormatter {\n            out,\n            use_color,\n            max_name_len,\n            is_multithreaded,\n            test_count: 0,\n            total_test_count: 0, // initialized later, when write_run_start is called\n        }\n    }\n\n    pub fn write_ok(&mut self) -> io::Result<()> {\n        self.write_short_result(\".\", term::color::GREEN)\n    }\n\n    pub fn write_failed(&mut self) -> io::Result<()> {\n        self.write_short_result(\"F\", term::color::RED)\n    }\n\n    pub fn write_ignored(&mut self) -> io::Result<()> {\n        self.write_short_result(\"i\", term::color::YELLOW)\n    }\n\n    pub fn write_allowed_fail(&mut self) -> io::Result<()> {\n        self.write_short_result(\"a\", term::color::YELLOW)\n    }\n\n    pub fn write_bench(&mut self) -> io::Result<()> {\n        self.write_pretty(\"bench\", term::color::CYAN)\n    }\n\n    pub fn write_short_result(\n        &mut self,\n        result: &str,\n        color: term::color::Color,\n    ) -> io::Result<()> {\n        self.write_pretty(result, color)?;\n        if self.test_count % QUIET_MODE_MAX_COLUMN == QUIET_MODE_MAX_COLUMN - 1 {\n            // we insert a new line every 100 dots in order to flush the\n            // screen when dealing with line-buffered output (e.g., piping to\n            // `stamp` in the rust CI).\n            let out = format!(\" {}/{}\\n\", self.test_count + 1, self.total_test_count);\n            self.write_plain(&out)?;\n        }\n\n        self.test_count += 1;\n        Ok(())\n    }\n\n    pub fn write_pretty(&mut self, word: &str, color: term::color::Color) -> io::Result<()> {\n        match self.out {\n            OutputLocation::Pretty(ref mut term) => {\n                if self.use_color {\n                    term.fg(color)?;\n                }\n                term.write_all(word.as_bytes())?;\n                if self.use_color {\n                    term.reset()?;\n                }\n                term.flush()\n            }\n            OutputLocation::Raw(ref mut stdout) => {\n                stdout.write_all(word.as_bytes())?;\n                stdout.flush()\n            }\n        }\n    }\n\n    pub fn write_plain<S: AsRef<str>>(&mut self, s: S) -> io::Result<()> {\n        let s = s.as_ref();\n        self.out.write_all(s.as_bytes())?;\n        self.out.flush()\n    }\n\n    pub fn write_outputs(&mut self, state: &ConsoleTestState) -> io::Result<()> {\n        self.write_plain(\"\\nsuccesses:\\n\")?;\n        let mut successes = Vec::new();\n        let mut stdouts = String::new();\n        for &(ref f, ref stdout) in &state.not_failures {\n            successes.push(f.name.to_string());\n            if !stdout.is_empty() {\n                stdouts.push_str(&format!(\"---- {} stdout ----\\n\", f.name));\n                let output = String::from_utf8_lossy(stdout);\n                stdouts.push_str(&output);\n                stdouts.push('\\n');\n            }\n        }\n        if !stdouts.is_empty() {\n            self.write_plain(\"\\n\")?;\n            self.write_plain(&stdouts)?;\n        }\n\n        self.write_plain(\"\\nsuccesses:\\n\")?;\n        successes.sort();\n        for name in &successes {\n            self.write_plain(&format!(\"    {}\\n\", name))?;\n        }\n        Ok(())\n    }\n\n    pub fn write_failures(&mut self, state: &ConsoleTestState) -> io::Result<()> {\n        self.write_plain(\"\\nfailures:\\n\")?;\n        let mut failures = Vec::new();\n        let mut fail_out = String::new();\n        for &(ref f, ref stdout) in &state.failures {\n            failures.push(f.name.to_string());\n            if !stdout.is_empty() {\n                fail_out.push_str(&format!(\"---- {} stdout ----\\n\", f.name));\n                let output = String::from_utf8_lossy(stdout);\n                fail_out.push_str(&output);\n                fail_out.push('\\n');\n            }\n        }\n        if !fail_out.is_empty() {\n            self.write_plain(\"\\n\")?;\n            self.write_plain(&fail_out)?;\n        }\n\n        self.write_plain(\"\\nfailures:\\n\")?;\n        failures.sort();\n        for name in &failures {\n            self.write_plain(&format!(\"    {}\\n\", name))?;\n        }\n        Ok(())\n    }\n\n    fn write_test_name(&mut self, desc: &TestDesc) -> io::Result<()> {\n        let name = desc.padded_name(self.max_name_len, desc.name.padding());\n        if let Some(test_mode) = desc.test_mode() {\n            self.write_plain(&format!(\"test {} - {} ... \", name, test_mode))?;\n        } else {\n            self.write_plain(&format!(\"test {} ... \", name))?;\n        }\n\n        Ok(())\n    }\n}\n\nimpl<T: Write> OutputFormatter for TerseFormatter<T> {\n    fn write_run_start(&mut self, test_count: usize) -> io::Result<()> {\n        self.total_test_count = test_count;\n        let noun = if test_count != 1 { \"tests\" } else { \"test\" };\n        self.write_plain(&format!(\"\\nrunning {} {}\\n\", test_count, noun))\n    }\n\n    fn write_test_start(&mut self, desc: &TestDesc) -> io::Result<()> {\n        // Remnants from old libtest code that used the padding value\n        // in order to indicate benchmarks.\n        // When running benchmarks, terse-mode should still print their name as if\n        // it is the Pretty formatter.\n        if !self.is_multithreaded && desc.name.padding() == NamePadding::PadOnRight {\n            self.write_test_name(desc)?;\n        }\n\n        Ok(())\n    }\n\n    fn write_result(\n        &mut self,\n        desc: &TestDesc,\n        result: &TestResult,\n        _: Option<&time::TestExecTime>,\n        _: &[u8],\n        _: &ConsoleTestState,\n    ) -> io::Result<()> {\n        match *result {\n            TestResult::TrOk => self.write_ok(),\n            TestResult::TrFailed | TestResult::TrFailedMsg(_) | TestResult::TrTimedFail => {\n                self.write_failed()\n            }\n            TestResult::TrIgnored => self.write_ignored(),\n            TestResult::TrAllowedFail => self.write_allowed_fail(),\n            TestResult::TrBench(ref bs) => {\n                if self.is_multithreaded {\n                    self.write_test_name(desc)?;\n                }\n                self.write_bench()?;\n                self.write_plain(&format!(\": {}\\n\", fmt_bench_samples(bs)))\n            }\n        }\n    }\n\n    fn write_timeout(&mut self, desc: &TestDesc) -> io::Result<()> {\n        self.write_plain(&format!(\n            \"test {} has been running for over {} seconds\\n\",\n            desc.name,\n            time::TEST_WARN_TIMEOUT_S\n        ))\n    }\n\n    fn write_run_finish(&mut self, state: &ConsoleTestState) -> io::Result<bool> {\n        if state.options.display_output {\n            self.write_outputs(state)?;\n        }\n        let success = state.failed == 0;\n        if !success {\n            self.write_failures(state)?;\n        }\n\n        self.write_plain(\"\\ntest result: \")?;\n\n        if success {\n            // There's no parallelism at this point so it's safe to use color\n            self.write_pretty(\"ok\", term::color::GREEN)?;\n        } else {\n            self.write_pretty(\"FAILED\", term::color::RED)?;\n        }\n\n        let s = if state.allowed_fail > 0 {\n            format!(\n                \". {} passed; {} failed ({} allowed); {} ignored; {} measured; {} filtered out\",\n                state.passed,\n                state.failed + state.allowed_fail,\n                state.allowed_fail,\n                state.ignored,\n                state.measured,\n                state.filtered_out\n            )\n        } else {\n            format!(\n                \". {} passed; {} failed; {} ignored; {} measured; {} filtered out\",\n                state.passed, state.failed, state.ignored, state.measured, state.filtered_out\n            )\n        };\n\n        self.write_plain(&s)?;\n\n        if let Some(ref exec_time) = state.exec_time {\n            let time_str = format!(\"; finished in {}\", exec_time);\n            self.write_plain(&time_str)?;\n        }\n\n        self.write_plain(\"\\n\\n\")?;\n\n        Ok(success)\n    }\n}\n"],[2105,"use std::{borrow::Cow, io, io::prelude::Write};\n\nuse super::OutputFormatter;\nuse crate::{\n    console::{ConsoleTestState, OutputLocation},\n    test_result::TestResult,\n    time,\n    types::TestDesc,\n};\n\npub(crate) struct JsonFormatter<T> {\n    out: OutputLocation<T>,\n}\n\nimpl<T: Write> JsonFormatter<T> {\n    pub fn new(out: OutputLocation<T>) -> Self {\n        Self { out }\n    }\n\n    fn writeln_message(&mut self, s: &str) -> io::Result<()> {\n        assert!(!s.contains('\\n'));\n\n        self.out.write_all(s.as_ref())?;\n        self.out.write_all(b\"\\n\")\n    }\n\n    fn write_message(&mut self, s: &str) -> io::Result<()> {\n        assert!(!s.contains('\\n'));\n\n        self.out.write_all(s.as_ref())\n    }\n\n    fn write_event(\n        &mut self,\n        ty: &str,\n        name: &str,\n        evt: &str,\n        exec_time: Option<&time::TestExecTime>,\n        stdout: Option<Cow<'_, str>>,\n        extra: Option<&str>,\n    ) -> io::Result<()> {\n        // A doc test's name includes a filename which must be escaped for correct json.\n        self.write_message(&*format!(\n            r#\"{{ \"type\": \"{}\", \"name\": \"{}\", \"event\": \"{}\"\"#,\n            ty,\n            EscapedString(name),\n            evt\n        ))?;\n        if let Some(exec_time) = exec_time {\n            self.write_message(&*format!(r#\", \"exec_time\": {}\"#, exec_time.0.as_secs_f64()))?;\n        }\n        if let Some(stdout) = stdout {\n            self.write_message(&*format!(r#\", \"stdout\": \"{}\"\"#, EscapedString(stdout)))?;\n        }\n        if let Some(extra) = extra {\n            self.write_message(&*format!(r#\", {}\"#, extra))?;\n        }\n        self.writeln_message(\" }\")\n    }\n}\n\nimpl<T: Write> OutputFormatter for JsonFormatter<T> {\n    fn write_run_start(&mut self, test_count: usize) -> io::Result<()> {\n        self.writeln_message(&*format!(\n            r#\"{{ \"type\": \"suite\", \"event\": \"started\", \"test_count\": {} }}\"#,\n            test_count\n        ))\n    }\n\n    fn write_test_start(&mut self, desc: &TestDesc) -> io::Result<()> {\n        self.writeln_message(&*format!(\n            r#\"{{ \"type\": \"test\", \"event\": \"started\", \"name\": \"{}\" }}\"#,\n            EscapedString(desc.name.as_slice())\n        ))\n    }\n\n    fn write_result(\n        &mut self,\n        desc: &TestDesc,\n        result: &TestResult,\n        exec_time: Option<&time::TestExecTime>,\n        stdout: &[u8],\n        state: &ConsoleTestState,\n    ) -> io::Result<()> {\n        let display_stdout = state.options.display_output || *result != TestResult::TrOk;\n        let stdout = if display_stdout && !stdout.is_empty() {\n            Some(String::from_utf8_lossy(stdout))\n        } else {\n            None\n        };\n        match *result {\n            TestResult::TrOk => {\n                self.write_event(\"test\", desc.name.as_slice(), \"ok\", exec_time, stdout, None)\n            }\n\n            TestResult::TrFailed => {\n                self.write_event(\"test\", desc.name.as_slice(), \"failed\", exec_time, stdout, None)\n            }\n\n            TestResult::TrTimedFail => self.write_event(\n                \"test\",\n                desc.name.as_slice(),\n                \"failed\",\n                exec_time,\n                stdout,\n                Some(r#\"\"reason\": \"time limit exceeded\"\"#),\n            ),\n\n            TestResult::TrFailedMsg(ref m) => self.write_event(\n                \"test\",\n                desc.name.as_slice(),\n                \"failed\",\n                exec_time,\n                stdout,\n                Some(&*format!(r#\"\"message\": \"{}\"\"#, EscapedString(m))),\n            ),\n\n            TestResult::TrIgnored => {\n                self.write_event(\"test\", desc.name.as_slice(), \"ignored\", exec_time, stdout, None)\n            }\n\n            TestResult::TrAllowedFail => self.write_event(\n                \"test\",\n                desc.name.as_slice(),\n                \"allowed_failure\",\n                exec_time,\n                stdout,\n                None,\n            ),\n\n            TestResult::TrBench(ref bs) => {\n                let median = bs.ns_iter_summ.median as usize;\n                let deviation = (bs.ns_iter_summ.max - bs.ns_iter_summ.min) as usize;\n\n                let mbps = if bs.mb_s == 0 {\n                    String::new()\n                } else {\n                    format!(r#\", \"mib_per_second\": {}\"#, bs.mb_s)\n                };\n\n                let line = format!(\n                    \"{{ \\\"type\\\": \\\"bench\\\", \\\n                     \\\"name\\\": \\\"{}\\\", \\\n                     \\\"median\\\": {}, \\\n                     \\\"deviation\\\": {}{} }}\",\n                    EscapedString(desc.name.as_slice()),\n                    median,\n                    deviation,\n                    mbps\n                );\n\n                self.writeln_message(&*line)\n            }\n        }\n    }\n\n    fn write_timeout(&mut self, desc: &TestDesc) -> io::Result<()> {\n        self.writeln_message(&*format!(\n            r#\"{{ \"type\": \"test\", \"event\": \"timeout\", \"name\": \"{}\" }}\"#,\n            EscapedString(desc.name.as_slice())\n        ))\n    }\n\n    fn write_run_finish(&mut self, state: &ConsoleTestState) -> io::Result<bool> {\n        self.write_message(&*format!(\n            \"{{ \\\"type\\\": \\\"suite\\\", \\\n             \\\"event\\\": \\\"{}\\\", \\\n             \\\"passed\\\": {}, \\\n             \\\"failed\\\": {}, \\\n             \\\"allowed_fail\\\": {}, \\\n             \\\"ignored\\\": {}, \\\n             \\\"measured\\\": {}, \\\n             \\\"filtered_out\\\": {}\",\n            if state.failed == 0 { \"ok\" } else { \"failed\" },\n            state.passed,\n            state.failed + state.allowed_fail,\n            state.allowed_fail,\n            state.ignored,\n            state.measured,\n            state.filtered_out,\n        ))?;\n\n        if let Some(ref exec_time) = state.exec_time {\n            let time_str = format!(\", \\\"exec_time\\\": {}\", exec_time.0.as_secs_f64());\n            self.write_message(&time_str)?;\n        }\n\n        self.writeln_message(\" }\")?;\n\n        Ok(state.failed == 0)\n    }\n}\n\n/// A formatting utility used to print strings with characters in need of escaping.\n/// Base code taken form `libserialize::json::escape_str`\nstruct EscapedString<S: AsRef<str>>(S);\n\nimpl<S: AsRef<str>> std::fmt::Display for EscapedString<S> {\n    fn fmt(&self, f: &mut std::fmt::Formatter<'_>) -> ::std::fmt::Result {\n        let mut start = 0;\n\n        for (i, byte) in self.0.as_ref().bytes().enumerate() {\n            let escaped = match byte {\n                b'\"' => \"\\\\\\\"\",\n                b'\\\\' => \"\\\\\\\\\",\n                b'\\x00' => \"\\\\u0000\",\n                b'\\x01' => \"\\\\u0001\",\n                b'\\x02' => \"\\\\u0002\",\n                b'\\x03' => \"\\\\u0003\",\n                b'\\x04' => \"\\\\u0004\",\n                b'\\x05' => \"\\\\u0005\",\n                b'\\x06' => \"\\\\u0006\",\n                b'\\x07' => \"\\\\u0007\",\n                b'\\x08' => \"\\\\b\",\n                b'\\t' => \"\\\\t\",\n                b'\\n' => \"\\\\n\",\n                b'\\x0b' => \"\\\\u000b\",\n                b'\\x0c' => \"\\\\f\",\n                b'\\r' => \"\\\\r\",\n                b'\\x0e' => \"\\\\u000e\",\n                b'\\x0f' => \"\\\\u000f\",\n                b'\\x10' => \"\\\\u0010\",\n                b'\\x11' => \"\\\\u0011\",\n                b'\\x12' => \"\\\\u0012\",\n                b'\\x13' => \"\\\\u0013\",\n                b'\\x14' => \"\\\\u0014\",\n                b'\\x15' => \"\\\\u0015\",\n                b'\\x16' => \"\\\\u0016\",\n                b'\\x17' => \"\\\\u0017\",\n                b'\\x18' => \"\\\\u0018\",\n                b'\\x19' => \"\\\\u0019\",\n                b'\\x1a' => \"\\\\u001a\",\n                b'\\x1b' => \"\\\\u001b\",\n                b'\\x1c' => \"\\\\u001c\",\n                b'\\x1d' => \"\\\\u001d\",\n                b'\\x1e' => \"\\\\u001e\",\n                b'\\x1f' => \"\\\\u001f\",\n                b'\\x7f' => \"\\\\u007f\",\n                _ => {\n                    continue;\n                }\n            };\n\n            if start < i {\n                f.write_str(&self.0.as_ref()[start..i])?;\n            }\n\n            f.write_str(escaped)?;\n\n            start = i + 1;\n        }\n\n        if start != self.0.as_ref().len() {\n            f.write_str(&self.0.as_ref()[start..])?;\n        }\n\n        Ok(())\n    }\n}\n"],[2106,"//! Helper module which helps to determine amount of threads to be used\n//! during tests execution.\nuse std::{env, num::NonZeroUsize, thread};\n\npub fn get_concurrency() -> usize {\n    if let Ok(value) = env::var(\"RUST_TEST_THREADS\") {\n        match value.parse::<NonZeroUsize>().ok() {\n            Some(n) => n.get(),\n            _ => panic!(\"RUST_TEST_THREADS is `{}`, should be a positive integer.\", value),\n        }\n    } else {\n        thread::available_concurrency().map(|n| n.get()).unwrap_or(1)\n    }\n}\n"],[2107,"//! Helper module which provides a function to test\n//! if stdout is a tty.\n\ncfg_if::cfg_if! {\n    if #[cfg(unix)] {\n        pub fn stdout_isatty() -> bool {\n            unsafe { libc::isatty(libc::STDOUT_FILENO) != 0 }\n        }\n    } else if #[cfg(windows)] {\n        pub fn stdout_isatty() -> bool {\n            type DWORD = u32;\n            type BOOL = i32;\n            type HANDLE = *mut u8;\n            type LPDWORD = *mut u32;\n            const STD_OUTPUT_HANDLE: DWORD = -11i32 as DWORD;\n            extern \"system\" {\n                fn GetStdHandle(which: DWORD) -> HANDLE;\n                fn GetConsoleMode(hConsoleHandle: HANDLE, lpMode: LPDWORD) -> BOOL;\n            }\n            unsafe {\n                let handle = GetStdHandle(STD_OUTPUT_HANDLE);\n                let mut out = 0;\n                GetConsoleMode(handle, &mut out) != 0\n            }\n        }\n    } else {\n        // FIXME: Implement isatty on SGX\n        pub fn stdout_isatty() -> bool {\n            false\n        }\n    }\n}\n"],[2108,"//! Module with common helpers not directly related to tests\n//! but used in `libtest`.\n\npub mod concurrency;\npub mod exit_code;\npub mod isatty;\npub mod metrics;\n"],[2109,"//! Helper module to detect subprocess exit code.\n\nuse std::process::ExitStatus;\n\n#[cfg(not(unix))]\npub fn get_exit_code(status: ExitStatus) -> Result<i32, String> {\n    status.code().ok_or_else(|| \"received no exit code from child process\".into())\n}\n\n#[cfg(unix)]\npub fn get_exit_code(status: ExitStatus) -> Result<i32, String> {\n    use std::os::unix::process::ExitStatusExt;\n    match status.code() {\n        Some(code) => Ok(code),\n        None => match status.signal() {\n            Some(signal) => Err(format!(\"child process exited with signal {}\", signal)),\n            None => Err(\"child process exited with unknown signal\".into()),\n        },\n    }\n}\n"],[2110,"//! Benchmark metrics.\nuse std::collections::BTreeMap;\n\n#[derive(Clone, PartialEq, Debug, Copy)]\npub struct Metric {\n    value: f64,\n    noise: f64,\n}\n\nimpl Metric {\n    pub fn new(value: f64, noise: f64) -> Metric {\n        Metric { value, noise }\n    }\n}\n\n#[derive(Clone, PartialEq)]\npub struct MetricMap(BTreeMap<String, Metric>);\n\nimpl MetricMap {\n    pub fn new() -> MetricMap {\n        MetricMap(BTreeMap::new())\n    }\n\n    /// Insert a named `value` (+/- `noise`) metric into the map. The value\n    /// must be non-negative. The `noise` indicates the uncertainty of the\n    /// metric, which doubles as the \"noise range\" of acceptable\n    /// pairwise-regressions on this named value, when comparing from one\n    /// metric to the next using `compare_to_old`.\n    ///\n    /// If `noise` is positive, then it means this metric is of a value\n    /// you want to see grow smaller, so a change larger than `noise` in the\n    /// positive direction represents a regression.\n    ///\n    /// If `noise` is negative, then it means this metric is of a value\n    /// you want to see grow larger, so a change larger than `noise` in the\n    /// negative direction represents a regression.\n    pub fn insert_metric(&mut self, name: &str, value: f64, noise: f64) {\n        let m = Metric { value, noise };\n        self.0.insert(name.to_owned(), m);\n    }\n\n    pub fn fmt_metrics(&self) -> String {\n        let v = self\n            .0\n            .iter()\n            .map(|(k, v)| format!(\"{}: {} (+/- {})\", *k, v.value, v.noise))\n            .collect::<Vec<_>>();\n        v.join(\", \")\n    }\n}\n"],[2111,"use super::*;\n\nuse crate::{\n    bench::Bencher,\n    console::OutputLocation,\n    formatters::PrettyFormatter,\n    options::OutputFormat,\n    test::{\n        filter_tests,\n        parse_opts,\n        run_test,\n        DynTestFn,\n        DynTestName,\n        MetricMap,\n        RunIgnored,\n        RunStrategy,\n        ShouldPanic,\n        StaticTestName,\n        TestDesc,\n        TestDescAndFn,\n        TestOpts,\n        TrIgnored,\n        TrOk,\n        // FIXME (introduced by #65251)\n        // ShouldPanic, StaticTestName, TestDesc, TestDescAndFn, TestOpts, TestTimeOptions,\n        // TestType, TrFailedMsg, TrIgnored, TrOk,\n    },\n    time::{TestTimeOptions, TimeThreshold},\n};\nuse std::sync::mpsc::channel;\nuse std::time::Duration;\n\nimpl TestOpts {\n    fn new() -> TestOpts {\n        TestOpts {\n            list: false,\n            filters: vec![],\n            filter_exact: false,\n            force_run_in_process: false,\n            exclude_should_panic: false,\n            run_ignored: RunIgnored::No,\n            run_tests: false,\n            bench_benchmarks: false,\n            logfile: None,\n            nocapture: false,\n            color: AutoColor,\n            format: OutputFormat::Pretty,\n            test_threads: None,\n            skip: vec![],\n            time_options: None,\n            options: Options::new(),\n        }\n    }\n}\n\nfn one_ignored_one_unignored_test() -> Vec<TestDescAndFn> {\n    vec![\n        TestDescAndFn {\n            desc: TestDesc {\n                name: StaticTestName(\"1\"),\n                ignore: true,\n                should_panic: ShouldPanic::No,\n                allow_fail: false,\n                #[cfg(not(bootstrap))]\n                compile_fail: false,\n                #[cfg(not(bootstrap))]\n                no_run: false,\n                test_type: TestType::Unknown,\n            },\n            testfn: DynTestFn(Box::new(move || {})),\n        },\n        TestDescAndFn {\n            desc: TestDesc {\n                name: StaticTestName(\"2\"),\n                ignore: false,\n                should_panic: ShouldPanic::No,\n                allow_fail: false,\n                #[cfg(not(bootstrap))]\n                compile_fail: false,\n                #[cfg(not(bootstrap))]\n                no_run: false,\n                test_type: TestType::Unknown,\n            },\n            testfn: DynTestFn(Box::new(move || {})),\n        },\n    ]\n}\n\n#[test]\npub fn do_not_run_ignored_tests() {\n    fn f() {\n        panic!();\n    }\n    let desc = TestDescAndFn {\n        desc: TestDesc {\n            name: StaticTestName(\"whatever\"),\n            ignore: true,\n            should_panic: ShouldPanic::No,\n            allow_fail: false,\n            #[cfg(not(bootstrap))]\n            compile_fail: false,\n            #[cfg(not(bootstrap))]\n            no_run: false,\n            test_type: TestType::Unknown,\n        },\n        testfn: DynTestFn(Box::new(f)),\n    };\n    let (tx, rx) = channel();\n    run_test(&TestOpts::new(), false, TestId(0), desc, RunStrategy::InProcess, tx, Concurrent::No);\n    let result = rx.recv().unwrap().result;\n    assert_ne!(result, TrOk);\n}\n\n#[test]\npub fn ignored_tests_result_in_ignored() {\n    fn f() {}\n    let desc = TestDescAndFn {\n        desc: TestDesc {\n            name: StaticTestName(\"whatever\"),\n            ignore: true,\n            should_panic: ShouldPanic::No,\n            allow_fail: false,\n            #[cfg(not(bootstrap))]\n            compile_fail: false,\n            #[cfg(not(bootstrap))]\n            no_run: false,\n            test_type: TestType::Unknown,\n        },\n        testfn: DynTestFn(Box::new(f)),\n    };\n    let (tx, rx) = channel();\n    run_test(&TestOpts::new(), false, TestId(0), desc, RunStrategy::InProcess, tx, Concurrent::No);\n    let result = rx.recv().unwrap().result;\n    assert_eq!(result, TrIgnored);\n}\n\n// FIXME: Re-enable emscripten once it can catch panics again (introduced by #65251)\n#[test]\n#[cfg(not(target_os = \"emscripten\"))]\nfn test_should_panic() {\n    fn f() {\n        panic!();\n    }\n    let desc = TestDescAndFn {\n        desc: TestDesc {\n            name: StaticTestName(\"whatever\"),\n            ignore: false,\n            should_panic: ShouldPanic::Yes,\n            allow_fail: false,\n            #[cfg(not(bootstrap))]\n            compile_fail: false,\n            #[cfg(not(bootstrap))]\n            no_run: false,\n            test_type: TestType::Unknown,\n        },\n        testfn: DynTestFn(Box::new(f)),\n    };\n    let (tx, rx) = channel();\n    run_test(&TestOpts::new(), false, TestId(0), desc, RunStrategy::InProcess, tx, Concurrent::No);\n    let result = rx.recv().unwrap().result;\n    assert_eq!(result, TrOk);\n}\n\n// FIXME: Re-enable emscripten once it can catch panics again (introduced by #65251)\n#[test]\n#[cfg(not(target_os = \"emscripten\"))]\nfn test_should_panic_good_message() {\n    fn f() {\n        panic!(\"an error message\");\n    }\n    let desc = TestDescAndFn {\n        desc: TestDesc {\n            name: StaticTestName(\"whatever\"),\n            ignore: false,\n            should_panic: ShouldPanic::YesWithMessage(\"error message\"),\n            allow_fail: false,\n            #[cfg(not(bootstrap))]\n            compile_fail: false,\n            #[cfg(not(bootstrap))]\n            no_run: false,\n            test_type: TestType::Unknown,\n        },\n        testfn: DynTestFn(Box::new(f)),\n    };\n    let (tx, rx) = channel();\n    run_test(&TestOpts::new(), false, TestId(0), desc, RunStrategy::InProcess, tx, Concurrent::No);\n    let result = rx.recv().unwrap().result;\n    assert_eq!(result, TrOk);\n}\n\n// FIXME: Re-enable emscripten once it can catch panics again (introduced by #65251)\n#[test]\n#[cfg(not(target_os = \"emscripten\"))]\nfn test_should_panic_bad_message() {\n    use crate::tests::TrFailedMsg;\n    fn f() {\n        panic!(\"an error message\");\n    }\n    let expected = \"foobar\";\n    let failed_msg = r#\"panic did not contain expected string\n      panic message: `\"an error message\"`,\n expected substring: `\"foobar\"`\"#;\n    let desc = TestDescAndFn {\n        desc: TestDesc {\n            name: StaticTestName(\"whatever\"),\n            ignore: false,\n            should_panic: ShouldPanic::YesWithMessage(expected),\n            allow_fail: false,\n            #[cfg(not(bootstrap))]\n            compile_fail: false,\n            #[cfg(not(bootstrap))]\n            no_run: false,\n            test_type: TestType::Unknown,\n        },\n        testfn: DynTestFn(Box::new(f)),\n    };\n    let (tx, rx) = channel();\n    run_test(&TestOpts::new(), false, TestId(0), desc, RunStrategy::InProcess, tx, Concurrent::No);\n    let result = rx.recv().unwrap().result;\n    assert_eq!(result, TrFailedMsg(failed_msg.to_string()));\n}\n\n// FIXME: Re-enable emscripten once it can catch panics again (introduced by #65251)\n#[test]\n#[cfg(not(target_os = \"emscripten\"))]\nfn test_should_panic_non_string_message_type() {\n    use crate::tests::TrFailedMsg;\n    use std::any::TypeId;\n    fn f() {\n        std::panic::panic_any(1i32);\n    }\n    let expected = \"foobar\";\n    let failed_msg = format!(\n        r#\"expected panic with string value,\n found non-string value: `{:?}`\n     expected substring: `\"foobar\"`\"#,\n        TypeId::of::<i32>()\n    );\n    let desc = TestDescAndFn {\n        desc: TestDesc {\n            name: StaticTestName(\"whatever\"),\n            ignore: false,\n            should_panic: ShouldPanic::YesWithMessage(expected),\n            allow_fail: false,\n            #[cfg(not(bootstrap))]\n            compile_fail: false,\n            #[cfg(not(bootstrap))]\n            no_run: false,\n            test_type: TestType::Unknown,\n        },\n        testfn: DynTestFn(Box::new(f)),\n    };\n    let (tx, rx) = channel();\n    run_test(&TestOpts::new(), false, TestId(0), desc, RunStrategy::InProcess, tx, Concurrent::No);\n    let result = rx.recv().unwrap().result;\n    assert_eq!(result, TrFailedMsg(failed_msg));\n}\n\n// FIXME: Re-enable emscripten once it can catch panics again (introduced by #65251)\n#[test]\n#[cfg(not(target_os = \"emscripten\"))]\nfn test_should_panic_but_succeeds() {\n    let should_panic_variants = [ShouldPanic::Yes, ShouldPanic::YesWithMessage(\"error message\")];\n\n    for &should_panic in should_panic_variants.iter() {\n        fn f() {}\n        let desc = TestDescAndFn {\n            desc: TestDesc {\n                name: StaticTestName(\"whatever\"),\n                ignore: false,\n                should_panic,\n                allow_fail: false,\n                #[cfg(not(bootstrap))]\n                compile_fail: false,\n                #[cfg(not(bootstrap))]\n                no_run: false,\n                test_type: TestType::Unknown,\n            },\n            testfn: DynTestFn(Box::new(f)),\n        };\n        let (tx, rx) = channel();\n        run_test(\n            &TestOpts::new(),\n            false,\n            TestId(0),\n            desc,\n            RunStrategy::InProcess,\n            tx,\n            Concurrent::No,\n        );\n        let result = rx.recv().unwrap().result;\n        assert_eq!(\n            result,\n            TrFailedMsg(\"test did not panic as expected\".to_string()),\n            \"should_panic == {:?}\",\n            should_panic\n        );\n    }\n}\n\nfn report_time_test_template(report_time: bool) -> Option<TestExecTime> {\n    fn f() {}\n    let desc = TestDescAndFn {\n        desc: TestDesc {\n            name: StaticTestName(\"whatever\"),\n            ignore: false,\n            should_panic: ShouldPanic::No,\n            allow_fail: false,\n            #[cfg(not(bootstrap))]\n            compile_fail: false,\n            #[cfg(not(bootstrap))]\n            no_run: false,\n            test_type: TestType::Unknown,\n        },\n        testfn: DynTestFn(Box::new(f)),\n    };\n    let time_options = if report_time { Some(TestTimeOptions::default()) } else { None };\n\n    let test_opts = TestOpts { time_options, ..TestOpts::new() };\n    let (tx, rx) = channel();\n    run_test(&test_opts, false, TestId(0), desc, RunStrategy::InProcess, tx, Concurrent::No);\n    let exec_time = rx.recv().unwrap().exec_time;\n    exec_time\n}\n\n#[test]\nfn test_should_not_report_time() {\n    let exec_time = report_time_test_template(false);\n    assert!(exec_time.is_none());\n}\n\n#[test]\nfn test_should_report_time() {\n    let exec_time = report_time_test_template(true);\n    assert!(exec_time.is_some());\n}\n\nfn time_test_failure_template(test_type: TestType) -> TestResult {\n    fn f() {}\n    let desc = TestDescAndFn {\n        desc: TestDesc {\n            name: StaticTestName(\"whatever\"),\n            ignore: false,\n            should_panic: ShouldPanic::No,\n            allow_fail: false,\n            #[cfg(not(bootstrap))]\n            compile_fail: false,\n            #[cfg(not(bootstrap))]\n            no_run: false,\n            test_type,\n        },\n        testfn: DynTestFn(Box::new(f)),\n    };\n    // `Default` will initialize all the thresholds to 0 milliseconds.\n    let mut time_options = TestTimeOptions::default();\n    time_options.error_on_excess = true;\n\n    let test_opts = TestOpts { time_options: Some(time_options), ..TestOpts::new() };\n    let (tx, rx) = channel();\n    run_test(&test_opts, false, TestId(0), desc, RunStrategy::InProcess, tx, Concurrent::No);\n    let result = rx.recv().unwrap().result;\n\n    result\n}\n\n#[test]\nfn test_error_on_exceed() {\n    let types = [TestType::UnitTest, TestType::IntegrationTest, TestType::DocTest];\n\n    for test_type in types.iter() {\n        let result = time_test_failure_template(*test_type);\n\n        assert_eq!(result, TestResult::TrTimedFail);\n    }\n\n    // Check that for unknown tests thresholds aren't applied.\n    let result = time_test_failure_template(TestType::Unknown);\n    assert_eq!(result, TestResult::TrOk);\n}\n\nfn typed_test_desc(test_type: TestType) -> TestDesc {\n    TestDesc {\n        name: StaticTestName(\"whatever\"),\n        ignore: false,\n        should_panic: ShouldPanic::No,\n        allow_fail: false,\n        #[cfg(not(bootstrap))]\n        compile_fail: false,\n        #[cfg(not(bootstrap))]\n        no_run: false,\n        test_type,\n    }\n}\n\nfn test_exec_time(millis: u64) -> TestExecTime {\n    TestExecTime(Duration::from_millis(millis))\n}\n\n#[test]\nfn test_time_options_threshold() {\n    let unit = TimeThreshold::new(Duration::from_millis(50), Duration::from_millis(100));\n    let integration = TimeThreshold::new(Duration::from_millis(500), Duration::from_millis(1000));\n    let doc = TimeThreshold::new(Duration::from_millis(5000), Duration::from_millis(10000));\n\n    let options = TestTimeOptions {\n        error_on_excess: false,\n        colored: false,\n        unit_threshold: unit.clone(),\n        integration_threshold: integration.clone(),\n        doctest_threshold: doc.clone(),\n    };\n\n    let test_vector = [\n        (TestType::UnitTest, unit.warn.as_millis() - 1, false, false),\n        (TestType::UnitTest, unit.warn.as_millis(), true, false),\n        (TestType::UnitTest, unit.critical.as_millis(), true, true),\n        (TestType::IntegrationTest, integration.warn.as_millis() - 1, false, false),\n        (TestType::IntegrationTest, integration.warn.as_millis(), true, false),\n        (TestType::IntegrationTest, integration.critical.as_millis(), true, true),\n        (TestType::DocTest, doc.warn.as_millis() - 1, false, false),\n        (TestType::DocTest, doc.warn.as_millis(), true, false),\n        (TestType::DocTest, doc.critical.as_millis(), true, true),\n    ];\n\n    for (test_type, time, expected_warn, expected_critical) in test_vector.iter() {\n        let test_desc = typed_test_desc(*test_type);\n        let exec_time = test_exec_time(*time as u64);\n\n        assert_eq!(options.is_warn(&test_desc, &exec_time), *expected_warn);\n        assert_eq!(options.is_critical(&test_desc, &exec_time), *expected_critical);\n    }\n}\n\n#[test]\nfn parse_ignored_flag() {\n    let args = vec![\"progname\".to_string(), \"filter\".to_string(), \"--ignored\".to_string()];\n    let opts = parse_opts(&args).unwrap().unwrap();\n    assert_eq!(opts.run_ignored, RunIgnored::Only);\n}\n\n#[test]\nfn parse_show_output_flag() {\n    let args = vec![\"progname\".to_string(), \"filter\".to_string(), \"--show-output\".to_string()];\n    let opts = parse_opts(&args).unwrap().unwrap();\n    assert!(opts.options.display_output);\n}\n\n#[test]\nfn parse_include_ignored_flag() {\n    let args = vec![\"progname\".to_string(), \"filter\".to_string(), \"--include-ignored\".to_string()];\n    let opts = parse_opts(&args).unwrap().unwrap();\n    assert_eq!(opts.run_ignored, RunIgnored::Yes);\n}\n\n#[test]\npub fn filter_for_ignored_option() {\n    // When we run ignored tests the test filter should filter out all the\n    // unignored tests and flip the ignore flag on the rest to false\n\n    let mut opts = TestOpts::new();\n    opts.run_tests = true;\n    opts.run_ignored = RunIgnored::Only;\n\n    let tests = one_ignored_one_unignored_test();\n    let filtered = filter_tests(&opts, tests);\n\n    assert_eq!(filtered.len(), 1);\n    assert_eq!(filtered[0].desc.name.to_string(), \"1\");\n    assert!(!filtered[0].desc.ignore);\n}\n\n#[test]\npub fn run_include_ignored_option() {\n    // When we \"--include-ignored\" tests, the ignore flag should be set to false on\n    // all tests and no test filtered out\n\n    let mut opts = TestOpts::new();\n    opts.run_tests = true;\n    opts.run_ignored = RunIgnored::Yes;\n\n    let tests = one_ignored_one_unignored_test();\n    let filtered = filter_tests(&opts, tests);\n\n    assert_eq!(filtered.len(), 2);\n    assert!(!filtered[0].desc.ignore);\n    assert!(!filtered[1].desc.ignore);\n}\n\n#[test]\npub fn exclude_should_panic_option() {\n    let mut opts = TestOpts::new();\n    opts.run_tests = true;\n    opts.exclude_should_panic = true;\n\n    let mut tests = one_ignored_one_unignored_test();\n    tests.push(TestDescAndFn {\n        desc: TestDesc {\n            name: StaticTestName(\"3\"),\n            ignore: false,\n            should_panic: ShouldPanic::Yes,\n            allow_fail: false,\n            #[cfg(not(bootstrap))]\n            compile_fail: false,\n            #[cfg(not(bootstrap))]\n            no_run: false,\n            test_type: TestType::Unknown,\n        },\n        testfn: DynTestFn(Box::new(move || {})),\n    });\n\n    let filtered = filter_tests(&opts, tests);\n\n    assert_eq!(filtered.len(), 2);\n    assert!(filtered.iter().all(|test| test.desc.should_panic == ShouldPanic::No));\n}\n\n#[test]\npub fn exact_filter_match() {\n    fn tests() -> Vec<TestDescAndFn> {\n        vec![\"base\", \"base::test\", \"base::test1\", \"base::test2\"]\n            .into_iter()\n            .map(|name| TestDescAndFn {\n                desc: TestDesc {\n                    name: StaticTestName(name),\n                    ignore: false,\n                    should_panic: ShouldPanic::No,\n                    allow_fail: false,\n                    #[cfg(not(bootstrap))]\n                    compile_fail: false,\n                    #[cfg(not(bootstrap))]\n                    no_run: false,\n                    test_type: TestType::Unknown,\n                },\n                testfn: DynTestFn(Box::new(move || {})),\n            })\n            .collect()\n    }\n\n    let substr =\n        filter_tests(&TestOpts { filters: vec![\"base\".into()], ..TestOpts::new() }, tests());\n    assert_eq!(substr.len(), 4);\n\n    let substr =\n        filter_tests(&TestOpts { filters: vec![\"bas\".into()], ..TestOpts::new() }, tests());\n    assert_eq!(substr.len(), 4);\n\n    let substr =\n        filter_tests(&TestOpts { filters: vec![\"::test\".into()], ..TestOpts::new() }, tests());\n    assert_eq!(substr.len(), 3);\n\n    let substr =\n        filter_tests(&TestOpts { filters: vec![\"base::test\".into()], ..TestOpts::new() }, tests());\n    assert_eq!(substr.len(), 3);\n\n    let substr = filter_tests(\n        &TestOpts { filters: vec![\"test1\".into(), \"test2\".into()], ..TestOpts::new() },\n        tests(),\n    );\n    assert_eq!(substr.len(), 2);\n\n    let exact = filter_tests(\n        &TestOpts { filters: vec![\"base\".into()], filter_exact: true, ..TestOpts::new() },\n        tests(),\n    );\n    assert_eq!(exact.len(), 1);\n\n    let exact = filter_tests(\n        &TestOpts { filters: vec![\"bas\".into()], filter_exact: true, ..TestOpts::new() },\n        tests(),\n    );\n    assert_eq!(exact.len(), 0);\n\n    let exact = filter_tests(\n        &TestOpts { filters: vec![\"::test\".into()], filter_exact: true, ..TestOpts::new() },\n        tests(),\n    );\n    assert_eq!(exact.len(), 0);\n\n    let exact = filter_tests(\n        &TestOpts { filters: vec![\"base::test\".into()], filter_exact: true, ..TestOpts::new() },\n        tests(),\n    );\n    assert_eq!(exact.len(), 1);\n\n    let exact = filter_tests(\n        &TestOpts {\n            filters: vec![\"base\".into(), \"base::test\".into()],\n            filter_exact: true,\n            ..TestOpts::new()\n        },\n        tests(),\n    );\n    assert_eq!(exact.len(), 2);\n}\n\n#[test]\npub fn sort_tests() {\n    let mut opts = TestOpts::new();\n    opts.run_tests = true;\n\n    let names = vec![\n        \"sha1::test\".to_string(),\n        \"isize::test_to_str\".to_string(),\n        \"isize::test_pow\".to_string(),\n        \"test::do_not_run_ignored_tests\".to_string(),\n        \"test::ignored_tests_result_in_ignored\".to_string(),\n        \"test::first_free_arg_should_be_a_filter\".to_string(),\n        \"test::parse_ignored_flag\".to_string(),\n        \"test::parse_include_ignored_flag\".to_string(),\n        \"test::filter_for_ignored_option\".to_string(),\n        \"test::run_include_ignored_option\".to_string(),\n        \"test::sort_tests\".to_string(),\n    ];\n    let tests = {\n        fn testfn() {}\n        let mut tests = Vec::new();\n        for name in &names {\n            let test = TestDescAndFn {\n                desc: TestDesc {\n                    name: DynTestName((*name).clone()),\n                    ignore: false,\n                    should_panic: ShouldPanic::No,\n                    allow_fail: false,\n                    #[cfg(not(bootstrap))]\n                    compile_fail: false,\n                    #[cfg(not(bootstrap))]\n                    no_run: false,\n                    test_type: TestType::Unknown,\n                },\n                testfn: DynTestFn(Box::new(testfn)),\n            };\n            tests.push(test);\n        }\n        tests\n    };\n    let filtered = filter_tests(&opts, tests);\n\n    let expected = vec![\n        \"isize::test_pow\".to_string(),\n        \"isize::test_to_str\".to_string(),\n        \"sha1::test\".to_string(),\n        \"test::do_not_run_ignored_tests\".to_string(),\n        \"test::filter_for_ignored_option\".to_string(),\n        \"test::first_free_arg_should_be_a_filter\".to_string(),\n        \"test::ignored_tests_result_in_ignored\".to_string(),\n        \"test::parse_ignored_flag\".to_string(),\n        \"test::parse_include_ignored_flag\".to_string(),\n        \"test::run_include_ignored_option\".to_string(),\n        \"test::sort_tests\".to_string(),\n    ];\n\n    for (a, b) in expected.iter().zip(filtered) {\n        assert_eq!(*a, b.desc.name.to_string());\n    }\n}\n\n#[test]\npub fn test_metricmap_compare() {\n    let mut m1 = MetricMap::new();\n    let mut m2 = MetricMap::new();\n    m1.insert_metric(\"in-both-noise\", 1000.0, 200.0);\n    m2.insert_metric(\"in-both-noise\", 1100.0, 200.0);\n\n    m1.insert_metric(\"in-first-noise\", 1000.0, 2.0);\n    m2.insert_metric(\"in-second-noise\", 1000.0, 2.0);\n\n    m1.insert_metric(\"in-both-want-downwards-but-regressed\", 1000.0, 10.0);\n    m2.insert_metric(\"in-both-want-downwards-but-regressed\", 2000.0, 10.0);\n\n    m1.insert_metric(\"in-both-want-downwards-and-improved\", 2000.0, 10.0);\n    m2.insert_metric(\"in-both-want-downwards-and-improved\", 1000.0, 10.0);\n\n    m1.insert_metric(\"in-both-want-upwards-but-regressed\", 2000.0, -10.0);\n    m2.insert_metric(\"in-both-want-upwards-but-regressed\", 1000.0, -10.0);\n\n    m1.insert_metric(\"in-both-want-upwards-and-improved\", 1000.0, -10.0);\n    m2.insert_metric(\"in-both-want-upwards-and-improved\", 2000.0, -10.0);\n}\n\n#[test]\npub fn test_bench_once_no_iter() {\n    fn f(_: &mut Bencher) {}\n    bench::run_once(f);\n}\n\n#[test]\npub fn test_bench_once_iter() {\n    fn f(b: &mut Bencher) {\n        b.iter(|| {})\n    }\n    bench::run_once(f);\n}\n\n#[test]\npub fn test_bench_no_iter() {\n    fn f(_: &mut Bencher) {}\n\n    let (tx, rx) = channel();\n\n    let desc = TestDesc {\n        name: StaticTestName(\"f\"),\n        ignore: false,\n        should_panic: ShouldPanic::No,\n        allow_fail: false,\n        #[cfg(not(bootstrap))]\n        compile_fail: false,\n        #[cfg(not(bootstrap))]\n        no_run: false,\n        test_type: TestType::Unknown,\n    };\n\n    crate::bench::benchmark(TestId(0), desc, tx, true, f);\n    rx.recv().unwrap();\n}\n\n#[test]\npub fn test_bench_iter() {\n    fn f(b: &mut Bencher) {\n        b.iter(|| {})\n    }\n\n    let (tx, rx) = channel();\n\n    let desc = TestDesc {\n        name: StaticTestName(\"f\"),\n        ignore: false,\n        should_panic: ShouldPanic::No,\n        allow_fail: false,\n        #[cfg(not(bootstrap))]\n        compile_fail: false,\n        #[cfg(not(bootstrap))]\n        no_run: false,\n        test_type: TestType::Unknown,\n    };\n\n    crate::bench::benchmark(TestId(0), desc, tx, true, f);\n    rx.recv().unwrap();\n}\n\n#[test]\nfn should_sort_failures_before_printing_them() {\n    let test_a = TestDesc {\n        name: StaticTestName(\"a\"),\n        ignore: false,\n        should_panic: ShouldPanic::No,\n        allow_fail: false,\n        #[cfg(not(bootstrap))]\n        compile_fail: false,\n        #[cfg(not(bootstrap))]\n        no_run: false,\n        test_type: TestType::Unknown,\n    };\n\n    let test_b = TestDesc {\n        name: StaticTestName(\"b\"),\n        ignore: false,\n        should_panic: ShouldPanic::No,\n        allow_fail: false,\n        #[cfg(not(bootstrap))]\n        compile_fail: false,\n        #[cfg(not(bootstrap))]\n        no_run: false,\n        test_type: TestType::Unknown,\n    };\n\n    let mut out = PrettyFormatter::new(OutputLocation::Raw(Vec::new()), false, 10, false, None);\n\n    let st = console::ConsoleTestState {\n        log_out: None,\n        total: 0,\n        passed: 0,\n        failed: 0,\n        ignored: 0,\n        allowed_fail: 0,\n        filtered_out: 0,\n        measured: 0,\n        exec_time: None,\n        metrics: MetricMap::new(),\n        failures: vec![(test_b, Vec::new()), (test_a, Vec::new())],\n        options: Options::new(),\n        not_failures: Vec::new(),\n        time_failures: Vec::new(),\n    };\n\n    out.write_failures(&st).unwrap();\n    let s = match out.output_location() {\n        &OutputLocation::Raw(ref m) => String::from_utf8_lossy(&m[..]),\n        &OutputLocation::Pretty(_) => unreachable!(),\n    };\n\n    let apos = s.find(\"a\").unwrap();\n    let bpos = s.find(\"b\").unwrap();\n    assert!(apos < bpos);\n}\n"],[2112,"//! Module providing interface for running tests in the console.\n\nuse std::fs::File;\nuse std::io;\nuse std::io::prelude::Write;\nuse std::time::Instant;\n\nuse super::{\n    bench::fmt_bench_samples,\n    cli::TestOpts,\n    event::{CompletedTest, TestEvent},\n    filter_tests,\n    formatters::{JsonFormatter, JunitFormatter, OutputFormatter, PrettyFormatter, TerseFormatter},\n    helpers::{concurrency::get_concurrency, metrics::MetricMap},\n    options::{Options, OutputFormat},\n    run_tests,\n    test_result::TestResult,\n    time::{TestExecTime, TestSuiteExecTime},\n    types::{NamePadding, TestDesc, TestDescAndFn},\n};\n\n/// Generic wrapper over stdout.\npub enum OutputLocation<T> {\n    Pretty(Box<term::StdoutTerminal>),\n    Raw(T),\n}\n\nimpl<T: Write> Write for OutputLocation<T> {\n    fn write(&mut self, buf: &[u8]) -> io::Result<usize> {\n        match *self {\n            OutputLocation::Pretty(ref mut term) => term.write(buf),\n            OutputLocation::Raw(ref mut stdout) => stdout.write(buf),\n        }\n    }\n\n    fn flush(&mut self) -> io::Result<()> {\n        match *self {\n            OutputLocation::Pretty(ref mut term) => term.flush(),\n            OutputLocation::Raw(ref mut stdout) => stdout.flush(),\n        }\n    }\n}\n\npub struct ConsoleTestState {\n    pub log_out: Option<File>,\n    pub total: usize,\n    pub passed: usize,\n    pub failed: usize,\n    pub ignored: usize,\n    pub allowed_fail: usize,\n    pub filtered_out: usize,\n    pub measured: usize,\n    pub exec_time: Option<TestSuiteExecTime>,\n    pub metrics: MetricMap,\n    pub failures: Vec<(TestDesc, Vec<u8>)>,\n    pub not_failures: Vec<(TestDesc, Vec<u8>)>,\n    pub time_failures: Vec<(TestDesc, Vec<u8>)>,\n    pub options: Options,\n}\n\nimpl ConsoleTestState {\n    pub fn new(opts: &TestOpts) -> io::Result<ConsoleTestState> {\n        let log_out = match opts.logfile {\n            Some(ref path) => Some(File::create(path)?),\n            None => None,\n        };\n\n        Ok(ConsoleTestState {\n            log_out,\n            total: 0,\n            passed: 0,\n            failed: 0,\n            ignored: 0,\n            allowed_fail: 0,\n            filtered_out: 0,\n            measured: 0,\n            exec_time: None,\n            metrics: MetricMap::new(),\n            failures: Vec::new(),\n            not_failures: Vec::new(),\n            time_failures: Vec::new(),\n            options: opts.options,\n        })\n    }\n\n    pub fn write_log<F, S>(&mut self, msg: F) -> io::Result<()>\n    where\n        S: AsRef<str>,\n        F: FnOnce() -> S,\n    {\n        match self.log_out {\n            None => Ok(()),\n            Some(ref mut o) => {\n                let msg = msg();\n                let msg = msg.as_ref();\n                o.write_all(msg.as_bytes())\n            }\n        }\n    }\n\n    pub fn write_log_result(\n        &mut self,\n        test: &TestDesc,\n        result: &TestResult,\n        exec_time: Option<&TestExecTime>,\n    ) -> io::Result<()> {\n        self.write_log(|| {\n            format!(\n                \"{} {}\",\n                match *result {\n                    TestResult::TrOk => \"ok\".to_owned(),\n                    TestResult::TrFailed => \"failed\".to_owned(),\n                    TestResult::TrFailedMsg(ref msg) => format!(\"failed: {}\", msg),\n                    TestResult::TrIgnored => \"ignored\".to_owned(),\n                    TestResult::TrAllowedFail => \"failed (allowed)\".to_owned(),\n                    TestResult::TrBench(ref bs) => fmt_bench_samples(bs),\n                    TestResult::TrTimedFail => \"failed (time limit exceeded)\".to_owned(),\n                },\n                test.name,\n            )\n        })?;\n        if let Some(exec_time) = exec_time {\n            self.write_log(|| format!(\" <{}>\", exec_time))?;\n        }\n        self.write_log(|| \"\\n\")\n    }\n\n    fn current_test_count(&self) -> usize {\n        self.passed + self.failed + self.ignored + self.measured + self.allowed_fail\n    }\n}\n\n// List the tests to console, and optionally to logfile. Filters are honored.\npub fn list_tests_console(opts: &TestOpts, tests: Vec<TestDescAndFn>) -> io::Result<()> {\n    let mut output = match term::stdout() {\n        None => OutputLocation::Raw(io::stdout()),\n        Some(t) => OutputLocation::Pretty(t),\n    };\n\n    let quiet = opts.format == OutputFormat::Terse;\n    let mut st = ConsoleTestState::new(opts)?;\n\n    let mut ntest = 0;\n    let mut nbench = 0;\n\n    for test in filter_tests(&opts, tests) {\n        use crate::TestFn::*;\n\n        let TestDescAndFn { desc: TestDesc { name, .. }, testfn } = test;\n\n        let fntype = match testfn {\n            StaticTestFn(..) | DynTestFn(..) => {\n                ntest += 1;\n                \"test\"\n            }\n            StaticBenchFn(..) | DynBenchFn(..) => {\n                nbench += 1;\n                \"benchmark\"\n            }\n        };\n\n        writeln!(output, \"{}: {}\", name, fntype)?;\n        st.write_log(|| format!(\"{} {}\\n\", fntype, name))?;\n    }\n\n    fn plural(count: u32, s: &str) -> String {\n        match count {\n            1 => format!(\"{} {}\", 1, s),\n            n => format!(\"{} {}s\", n, s),\n        }\n    }\n\n    if !quiet {\n        if ntest != 0 || nbench != 0 {\n            writeln!(output)?;\n        }\n\n        writeln!(output, \"{}, {}\", plural(ntest, \"test\"), plural(nbench, \"benchmark\"))?;\n    }\n\n    Ok(())\n}\n\n// Updates `ConsoleTestState` depending on result of the test execution.\nfn handle_test_result(st: &mut ConsoleTestState, completed_test: CompletedTest) {\n    let test = completed_test.desc;\n    let stdout = completed_test.stdout;\n    match completed_test.result {\n        TestResult::TrOk => {\n            st.passed += 1;\n            st.not_failures.push((test, stdout));\n        }\n        TestResult::TrIgnored => st.ignored += 1,\n        TestResult::TrAllowedFail => st.allowed_fail += 1,\n        TestResult::TrBench(bs) => {\n            st.metrics.insert_metric(\n                test.name.as_slice(),\n                bs.ns_iter_summ.median,\n                bs.ns_iter_summ.max - bs.ns_iter_summ.min,\n            );\n            st.measured += 1\n        }\n        TestResult::TrFailed => {\n            st.failed += 1;\n            st.failures.push((test, stdout));\n        }\n        TestResult::TrFailedMsg(msg) => {\n            st.failed += 1;\n            let mut stdout = stdout;\n            stdout.extend_from_slice(format!(\"note: {}\", msg).as_bytes());\n            st.failures.push((test, stdout));\n        }\n        TestResult::TrTimedFail => {\n            st.failed += 1;\n            st.time_failures.push((test, stdout));\n        }\n    }\n}\n\n// Handler for events that occur during test execution.\n// It is provided as a callback to the `run_tests` function.\nfn on_test_event(\n    event: &TestEvent,\n    st: &mut ConsoleTestState,\n    out: &mut dyn OutputFormatter,\n) -> io::Result<()> {\n    match (*event).clone() {\n        TestEvent::TeFiltered(ref filtered_tests) => {\n            st.total = filtered_tests.len();\n            out.write_run_start(filtered_tests.len())?;\n        }\n        TestEvent::TeFilteredOut(filtered_out) => {\n            st.filtered_out = filtered_out;\n        }\n        TestEvent::TeWait(ref test) => out.write_test_start(test)?,\n        TestEvent::TeTimeout(ref test) => out.write_timeout(test)?,\n        TestEvent::TeResult(completed_test) => {\n            let test = &completed_test.desc;\n            let result = &completed_test.result;\n            let exec_time = &completed_test.exec_time;\n            let stdout = &completed_test.stdout;\n\n            st.write_log_result(test, result, exec_time.as_ref())?;\n            out.write_result(test, result, exec_time.as_ref(), &*stdout, st)?;\n            handle_test_result(st, completed_test);\n        }\n    }\n\n    Ok(())\n}\n\n/// A simple console test runner.\n/// Runs provided tests reporting process and results to the stdout.\npub fn run_tests_console(opts: &TestOpts, tests: Vec<TestDescAndFn>) -> io::Result<bool> {\n    let output = match term::stdout() {\n        None => OutputLocation::Raw(io::stdout()),\n        Some(t) => OutputLocation::Pretty(t),\n    };\n\n    let max_name_len = tests\n        .iter()\n        .max_by_key(|t| len_if_padded(*t))\n        .map(|t| t.desc.name.as_slice().len())\n        .unwrap_or(0);\n\n    let is_multithreaded = opts.test_threads.unwrap_or_else(get_concurrency) > 1;\n\n    let mut out: Box<dyn OutputFormatter> = match opts.format {\n        OutputFormat::Pretty => Box::new(PrettyFormatter::new(\n            output,\n            opts.use_color(),\n            max_name_len,\n            is_multithreaded,\n            opts.time_options,\n        )),\n        OutputFormat::Terse => {\n            Box::new(TerseFormatter::new(output, opts.use_color(), max_name_len, is_multithreaded))\n        }\n        OutputFormat::Json => Box::new(JsonFormatter::new(output)),\n        OutputFormat::Junit => Box::new(JunitFormatter::new(output)),\n    };\n    let mut st = ConsoleTestState::new(opts)?;\n\n    // Prevent the usage of `Instant` in some cases:\n    // - It's currently not supported for wasm targets.\n    // - We disable it for miri because it's not available when isolation is enabled.\n    let is_instant_supported = !cfg!(target_arch = \"wasm32\") && !cfg!(miri);\n\n    let start_time = is_instant_supported.then(Instant::now);\n    run_tests(opts, tests, |x| on_test_event(&x, &mut st, &mut *out))?;\n    st.exec_time = start_time.map(|t| TestSuiteExecTime(t.elapsed()));\n\n    assert!(st.current_test_count() == st.total);\n\n    out.write_run_finish(&st)\n}\n\n// Calculates padding for given test description.\nfn len_if_padded(t: &TestDescAndFn) -> usize {\n    match t.testfn.padding() {\n        NamePadding::PadNone => 0,\n        NamePadding::PadOnRight => t.desc.name.as_slice().len(),\n    }\n}\n"],[2113,"//! Module containing different events that can occur\n//! during tests execution process.\n\nuse super::test_result::TestResult;\nuse super::time::TestExecTime;\nuse super::types::{TestDesc, TestId};\n\n#[derive(Debug, Clone)]\npub struct CompletedTest {\n    pub id: TestId,\n    pub desc: TestDesc,\n    pub result: TestResult,\n    pub exec_time: Option<TestExecTime>,\n    pub stdout: Vec<u8>,\n}\n\nimpl CompletedTest {\n    pub fn new(\n        id: TestId,\n        desc: TestDesc,\n        result: TestResult,\n        exec_time: Option<TestExecTime>,\n        stdout: Vec<u8>,\n    ) -> Self {\n        Self { id, desc, result, exec_time, stdout }\n    }\n}\n\n#[derive(Debug, Clone)]\npub enum TestEvent {\n    TeFiltered(Vec<TestDesc>),\n    TeWait(TestDesc),\n    TeResult(CompletedTest),\n    TeTimeout(TestDesc),\n    TeFilteredOut(usize),\n}\n"],[2114,"//! Module converting command-line arguments into test configuration.\n\nuse std::env;\nuse std::path::PathBuf;\n\nuse super::helpers::isatty;\nuse super::options::{ColorConfig, Options, OutputFormat, RunIgnored};\nuse super::time::TestTimeOptions;\n\n#[derive(Debug)]\npub struct TestOpts {\n    pub list: bool,\n    pub filters: Vec<String>,\n    pub filter_exact: bool,\n    pub force_run_in_process: bool,\n    pub exclude_should_panic: bool,\n    pub run_ignored: RunIgnored,\n    pub run_tests: bool,\n    pub bench_benchmarks: bool,\n    pub logfile: Option<PathBuf>,\n    pub nocapture: bool,\n    pub color: ColorConfig,\n    pub format: OutputFormat,\n    pub test_threads: Option<usize>,\n    pub skip: Vec<String>,\n    pub time_options: Option<TestTimeOptions>,\n    pub options: Options,\n}\n\nimpl TestOpts {\n    pub fn use_color(&self) -> bool {\n        match self.color {\n            ColorConfig::AutoColor => !self.nocapture && isatty::stdout_isatty(),\n            ColorConfig::AlwaysColor => true,\n            ColorConfig::NeverColor => false,\n        }\n    }\n}\n\n/// Result of parsing the options.\npub type OptRes = Result<TestOpts, String>;\n/// Result of parsing the option part.\ntype OptPartRes<T> = Result<T, String>;\n\nfn optgroups() -> getopts::Options {\n    let mut opts = getopts::Options::new();\n    opts.optflag(\"\", \"include-ignored\", \"Run ignored and not ignored tests\")\n        .optflag(\"\", \"ignored\", \"Run only ignored tests\")\n        .optflag(\"\", \"force-run-in-process\", \"Forces tests to run in-process when panic=abort\")\n        .optflag(\"\", \"exclude-should-panic\", \"Excludes tests marked as should_panic\")\n        .optflag(\"\", \"test\", \"Run tests and not benchmarks\")\n        .optflag(\"\", \"bench\", \"Run benchmarks instead of tests\")\n        .optflag(\"\", \"list\", \"List all tests and benchmarks\")\n        .optflag(\"h\", \"help\", \"Display this message\")\n        .optopt(\"\", \"logfile\", \"Write logs to the specified file\", \"PATH\")\n        .optflag(\n            \"\",\n            \"nocapture\",\n            \"don't capture stdout/stderr of each \\\n             task, allow printing directly\",\n        )\n        .optopt(\n            \"\",\n            \"test-threads\",\n            \"Number of threads used for running tests \\\n             in parallel\",\n            \"n_threads\",\n        )\n        .optmulti(\n            \"\",\n            \"skip\",\n            \"Skip tests whose names contain FILTER (this flag can \\\n             be used multiple times)\",\n            \"FILTER\",\n        )\n        .optflag(\n            \"q\",\n            \"quiet\",\n            \"Display one character per test instead of one line. \\\n             Alias to --format=terse\",\n        )\n        .optflag(\"\", \"exact\", \"Exactly match filters rather than by substring\")\n        .optopt(\n            \"\",\n            \"color\",\n            \"Configure coloring of output:\n            auto   = colorize if stdout is a tty and tests are run on serially (default);\n            always = always colorize output;\n            never  = never colorize output;\",\n            \"auto|always|never\",\n        )\n        .optopt(\n            \"\",\n            \"format\",\n            \"Configure formatting of output:\n            pretty = Print verbose output;\n            terse  = Display one character per test;\n            json   = Output a json document;\n            junit  = Output a JUnit document\",\n            \"pretty|terse|json|junit\",\n        )\n        .optflag(\"\", \"show-output\", \"Show captured stdout of successful tests\")\n        .optopt(\n            \"Z\",\n            \"\",\n            \"Enable nightly-only flags:\n            unstable-options = Allow use of experimental features\",\n            \"unstable-options\",\n        )\n        .optflagopt(\n            \"\",\n            \"report-time\",\n            \"Show execution time of each test. Available values:\n            plain   = do not colorize the execution time (default);\n            colored = colorize output according to the `color` parameter value;\n\n            Threshold values for colorized output can be configured via\n            `RUST_TEST_TIME_UNIT`, `RUST_TEST_TIME_INTEGRATION` and\n            `RUST_TEST_TIME_DOCTEST` environment variables.\n\n            Expected format of environment variable is `VARIABLE=WARN_TIME,CRITICAL_TIME`.\n            Durations must be specified in milliseconds, e.g. `500,2000` means that the warn time\n            is 0.5 seconds, and the critical time is 2 seconds.\n\n            Not available for --format=terse\",\n            \"plain|colored\",\n        )\n        .optflag(\n            \"\",\n            \"ensure-time\",\n            \"Treat excess of the test execution time limit as error.\n\n            Threshold values for this option can be configured via\n            `RUST_TEST_TIME_UNIT`, `RUST_TEST_TIME_INTEGRATION` and\n            `RUST_TEST_TIME_DOCTEST` environment variables.\n\n            Expected format of environment variable is `VARIABLE=WARN_TIME,CRITICAL_TIME`.\n\n            `CRITICAL_TIME` here means the limit that should not be exceeded by test.\n            \",\n        );\n    opts\n}\n\nfn usage(binary: &str, options: &getopts::Options) {\n    let message = format!(\"Usage: {} [OPTIONS] [FILTERS...]\", binary);\n    println!(\n        r#\"{usage}\n\nThe FILTER string is tested against the name of all tests, and only those\ntests whose names contain the filter are run. Multiple filter strings may\nbe passed, which will run all tests matching any of the filters.\n\nBy default, all tests are run in parallel. This can be altered with the\n--test-threads flag or the RUST_TEST_THREADS environment variable when running\ntests (set it to 1).\n\nAll tests have their standard output and standard error captured by default.\nThis can be overridden with the --nocapture flag or setting RUST_TEST_NOCAPTURE\nenvironment variable to a value other than \"0\". Logging is not captured by default.\n\nTest Attributes:\n\n    `#[test]`        - Indicates a function is a test to be run. This function\n                       takes no arguments.\n    `#[bench]`       - Indicates a function is a benchmark to be run. This\n                       function takes one argument (test::Bencher).\n    `#[should_panic]` - This function (also labeled with `#[test]`) will only pass if\n                        the code causes a panic (an assertion failure or panic!)\n                        A message may be provided, which the failure string must\n                        contain: #[should_panic(expected = \"foo\")].\n    `#[ignore]`       - When applied to a function which is already attributed as a\n                        test, then the test runner will ignore these tests during\n                        normal test runs. Running with --ignored or --include-ignored will run\n                        these tests.\"#,\n        usage = options.usage(&message)\n    );\n}\n\n/// Parses command line arguments into test options.\n/// Returns `None` if help was requested (since we only show help message and don't run tests),\n/// returns `Some(Err(..))` if provided arguments are incorrect,\n/// otherwise creates a `TestOpts` object and returns it.\npub fn parse_opts(args: &[String]) -> Option<OptRes> {\n    // Parse matches.\n    let opts = optgroups();\n    let args = args.get(1..).unwrap_or(args);\n    let matches = match opts.parse(args) {\n        Ok(m) => m,\n        Err(f) => return Some(Err(f.to_string())),\n    };\n\n    // Check if help was requested.\n    if matches.opt_present(\"h\") {\n        // Show help and do nothing more.\n        usage(&args[0], &opts);\n        return None;\n    }\n\n    // Actually parse the opts.\n    let opts_result = parse_opts_impl(matches);\n\n    Some(opts_result)\n}\n\n// Gets the option value and checks if unstable features are enabled.\nmacro_rules! unstable_optflag {\n    ($matches:ident, $allow_unstable:ident, $option_name:literal) => {{\n        let opt = $matches.opt_present($option_name);\n        if !$allow_unstable && opt {\n            return Err(format!(\n                \"The \\\"{}\\\" flag is only accepted on the nightly compiler with -Z unstable-options\",\n                $option_name\n            ));\n        }\n\n        opt\n    }};\n}\n\n// Implementation of `parse_opts` that doesn't care about help message\n// and returns a `Result`.\nfn parse_opts_impl(matches: getopts::Matches) -> OptRes {\n    let allow_unstable = get_allow_unstable(&matches)?;\n\n    // Unstable flags\n    let force_run_in_process = unstable_optflag!(matches, allow_unstable, \"force-run-in-process\");\n    let exclude_should_panic = unstable_optflag!(matches, allow_unstable, \"exclude-should-panic\");\n    let time_options = get_time_options(&matches, allow_unstable)?;\n\n    let include_ignored = matches.opt_present(\"include-ignored\");\n    let quiet = matches.opt_present(\"quiet\");\n    let exact = matches.opt_present(\"exact\");\n    let list = matches.opt_present(\"list\");\n    let skip = matches.opt_strs(\"skip\");\n\n    let bench_benchmarks = matches.opt_present(\"bench\");\n    let run_tests = !bench_benchmarks || matches.opt_present(\"test\");\n\n    let logfile = get_log_file(&matches)?;\n    let run_ignored = get_run_ignored(&matches, include_ignored)?;\n    let filters = matches.free.clone();\n    let nocapture = get_nocapture(&matches)?;\n    let test_threads = get_test_threads(&matches)?;\n    let color = get_color_config(&matches)?;\n    let format = get_format(&matches, quiet, allow_unstable)?;\n\n    let options = Options::new().display_output(matches.opt_present(\"show-output\"));\n\n    let test_opts = TestOpts {\n        list,\n        filters,\n        filter_exact: exact,\n        force_run_in_process,\n        exclude_should_panic,\n        run_ignored,\n        run_tests,\n        bench_benchmarks,\n        logfile,\n        nocapture,\n        color,\n        format,\n        test_threads,\n        skip,\n        time_options,\n        options,\n    };\n\n    Ok(test_opts)\n}\n\n// FIXME: Copied from librustc_ast until linkage errors are resolved. Issue #47566\nfn is_nightly() -> bool {\n    // Whether this is a feature-staged build, i.e., on the beta or stable channel\n    let disable_unstable_features = option_env!(\"CFG_DISABLE_UNSTABLE_FEATURES\").is_some();\n    // Whether we should enable unstable features for bootstrapping\n    let bootstrap = env::var(\"RUSTC_BOOTSTRAP\").is_ok();\n\n    bootstrap || !disable_unstable_features\n}\n\n// Gets the CLI options associated with `report-time` feature.\nfn get_time_options(\n    matches: &getopts::Matches,\n    allow_unstable: bool,\n) -> OptPartRes<Option<TestTimeOptions>> {\n    let report_time = unstable_optflag!(matches, allow_unstable, \"report-time\");\n    let colored_opt_str = matches.opt_str(\"report-time\");\n    let mut report_time_colored = report_time && colored_opt_str == Some(\"colored\".into());\n    let ensure_test_time = unstable_optflag!(matches, allow_unstable, \"ensure-time\");\n\n    // If `ensure-test-time` option is provided, time output is enforced,\n    // so user won't be confused if any of tests will silently fail.\n    let options = if report_time || ensure_test_time {\n        if ensure_test_time && !report_time {\n            report_time_colored = true;\n        }\n        Some(TestTimeOptions::new_from_env(ensure_test_time, report_time_colored))\n    } else {\n        None\n    };\n\n    Ok(options)\n}\n\nfn get_test_threads(matches: &getopts::Matches) -> OptPartRes<Option<usize>> {\n    let test_threads = match matches.opt_str(\"test-threads\") {\n        Some(n_str) => match n_str.parse::<usize>() {\n            Ok(0) => return Err(\"argument for --test-threads must not be 0\".to_string()),\n            Ok(n) => Some(n),\n            Err(e) => {\n                return Err(format!(\n                    \"argument for --test-threads must be a number > 0 \\\n                     (error: {})\",\n                    e\n                ));\n            }\n        },\n        None => None,\n    };\n\n    Ok(test_threads)\n}\n\nfn get_format(\n    matches: &getopts::Matches,\n    quiet: bool,\n    allow_unstable: bool,\n) -> OptPartRes<OutputFormat> {\n    let format = match matches.opt_str(\"format\").as_deref() {\n        None if quiet => OutputFormat::Terse,\n        Some(\"pretty\") | None => OutputFormat::Pretty,\n        Some(\"terse\") => OutputFormat::Terse,\n        Some(\"json\") => {\n            if !allow_unstable {\n                return Err(\"The \\\"json\\\" format is only accepted on the nightly compiler\".into());\n            }\n            OutputFormat::Json\n        }\n        Some(\"junit\") => {\n            if !allow_unstable {\n                return Err(\"The \\\"junit\\\" format is only accepted on the nightly compiler\".into());\n            }\n            OutputFormat::Junit\n        }\n        Some(v) => {\n            return Err(format!(\n                \"argument for --format must be pretty, terse, json or junit (was \\\n                 {})\",\n                v\n            ));\n        }\n    };\n\n    Ok(format)\n}\n\nfn get_color_config(matches: &getopts::Matches) -> OptPartRes<ColorConfig> {\n    let color = match matches.opt_str(\"color\").as_deref() {\n        Some(\"auto\") | None => ColorConfig::AutoColor,\n        Some(\"always\") => ColorConfig::AlwaysColor,\n        Some(\"never\") => ColorConfig::NeverColor,\n\n        Some(v) => {\n            return Err(format!(\n                \"argument for --color must be auto, always, or never (was \\\n                 {})\",\n                v\n            ));\n        }\n    };\n\n    Ok(color)\n}\n\nfn get_nocapture(matches: &getopts::Matches) -> OptPartRes<bool> {\n    let mut nocapture = matches.opt_present(\"nocapture\");\n    if !nocapture {\n        nocapture = match env::var(\"RUST_TEST_NOCAPTURE\") {\n            Ok(val) => &val != \"0\",\n            Err(_) => false,\n        };\n    }\n\n    Ok(nocapture)\n}\n\nfn get_run_ignored(matches: &getopts::Matches, include_ignored: bool) -> OptPartRes<RunIgnored> {\n    let run_ignored = match (include_ignored, matches.opt_present(\"ignored\")) {\n        (true, true) => {\n            return Err(\"the options --include-ignored and --ignored are mutually exclusive\".into());\n        }\n        (true, false) => RunIgnored::Yes,\n        (false, true) => RunIgnored::Only,\n        (false, false) => RunIgnored::No,\n    };\n\n    Ok(run_ignored)\n}\n\nfn get_allow_unstable(matches: &getopts::Matches) -> OptPartRes<bool> {\n    let mut allow_unstable = false;\n\n    if let Some(opt) = matches.opt_str(\"Z\") {\n        if !is_nightly() {\n            return Err(\"the option `Z` is only accepted on the nightly compiler\".into());\n        }\n\n        match &*opt {\n            \"unstable-options\" => {\n                allow_unstable = true;\n            }\n            _ => {\n                return Err(\"Unrecognized option to `Z`\".into());\n            }\n        }\n    };\n\n    Ok(allow_unstable)\n}\n\nfn get_log_file(matches: &getopts::Matches) -> OptPartRes<Option<PathBuf>> {\n    let logfile = matches.opt_str(\"logfile\").map(|s| PathBuf::from(&s));\n\n    Ok(logfile)\n}\n"],[2115,"use std::any::Any;\n\nuse super::bench::BenchSamples;\nuse super::options::ShouldPanic;\nuse super::time;\nuse super::types::TestDesc;\n\npub use self::TestResult::*;\n\n// Return codes for secondary process.\n// Start somewhere other than 0 so we know the return code means what we think\n// it means.\npub const TR_OK: i32 = 50;\npub const TR_FAILED: i32 = 51;\n\n#[derive(Debug, Clone, PartialEq)]\npub enum TestResult {\n    TrOk,\n    TrFailed,\n    TrFailedMsg(String),\n    TrIgnored,\n    TrAllowedFail,\n    TrBench(BenchSamples),\n    TrTimedFail,\n}\n\n/// Creates a `TestResult` depending on the raw result of test execution\n/// and associated data.\npub fn calc_result<'a>(\n    desc: &TestDesc,\n    task_result: Result<(), &'a (dyn Any + 'static + Send)>,\n    time_opts: &Option<time::TestTimeOptions>,\n    exec_time: &Option<time::TestExecTime>,\n) -> TestResult {\n    let result = match (&desc.should_panic, task_result) {\n        (&ShouldPanic::No, Ok(())) | (&ShouldPanic::Yes, Err(_)) => TestResult::TrOk,\n        (&ShouldPanic::YesWithMessage(msg), Err(ref err)) => {\n            let maybe_panic_str = err\n                .downcast_ref::<String>()\n                .map(|e| &**e)\n                .or_else(|| err.downcast_ref::<&'static str>().copied());\n\n            if maybe_panic_str.map(|e| e.contains(msg)).unwrap_or(false) {\n                TestResult::TrOk\n            } else if desc.allow_fail {\n                TestResult::TrAllowedFail\n            } else if let Some(panic_str) = maybe_panic_str {\n                TestResult::TrFailedMsg(format!(\n                    r#\"panic did not contain expected string\n      panic message: `{:?}`,\n expected substring: `{:?}`\"#,\n                    panic_str, msg\n                ))\n            } else {\n                TestResult::TrFailedMsg(format!(\n                    r#\"expected panic with string value,\n found non-string value: `{:?}`\n     expected substring: `{:?}`\"#,\n                    (**err).type_id(),\n                    msg\n                ))\n            }\n        }\n        (&ShouldPanic::Yes, Ok(())) | (&ShouldPanic::YesWithMessage(_), Ok(())) => {\n            TestResult::TrFailedMsg(\"test did not panic as expected\".to_string())\n        }\n        _ if desc.allow_fail => TestResult::TrAllowedFail,\n        _ => TestResult::TrFailed,\n    };\n\n    // If test is already failed (or allowed to fail), do not change the result.\n    if result != TestResult::TrOk {\n        return result;\n    }\n\n    // Check if test is failed due to timeout.\n    if let (Some(opts), Some(time)) = (time_opts, exec_time) {\n        if opts.error_on_excess && opts.is_critical(desc, time) {\n            return TestResult::TrTimedFail;\n        }\n    }\n\n    result\n}\n\n/// Creates a `TestResult` depending on the exit code of test subprocess.\npub fn get_result_from_exit_code(\n    desc: &TestDesc,\n    code: i32,\n    time_opts: &Option<time::TestTimeOptions>,\n    exec_time: &Option<time::TestExecTime>,\n) -> TestResult {\n    let result = match (desc.allow_fail, code) {\n        (_, TR_OK) => TestResult::TrOk,\n        (true, TR_FAILED) => TestResult::TrAllowedFail,\n        (false, TR_FAILED) => TestResult::TrFailed,\n        (_, _) => TestResult::TrFailedMsg(format!(\"got unexpected return code {}\", code)),\n    };\n\n    // If test is already failed (or allowed to fail), do not change the result.\n    if result != TestResult::TrOk {\n        return result;\n    }\n\n    // Check if test is failed due to timeout.\n    if let (Some(opts), Some(time)) = (time_opts, exec_time) {\n        if opts.error_on_excess && opts.is_critical(desc, time) {\n            return TestResult::TrTimedFail;\n        }\n    }\n\n    result\n}\n"],[2116,"//! Utilities for parsing DWARF-encoded data streams.\n//! See <http://www.dwarfstd.org>,\n//! DWARF-4 standard, Section 7 - \"Data Representation\"\n\n// This module is used only by x86_64-pc-windows-gnu for now, but we\n// are compiling it everywhere to avoid regressions.\n#![allow(unused)]\n\n#[cfg(test)]\nmod tests;\n\npub mod eh;\n\nuse core::mem;\n\npub struct DwarfReader {\n    pub ptr: *const u8,\n}\n\n#[repr(C, packed)]\nstruct Unaligned<T>(T);\n\nimpl DwarfReader {\n    pub fn new(ptr: *const u8) -> DwarfReader {\n        DwarfReader { ptr }\n    }\n\n    // DWARF streams are packed, so e.g., a u32 would not necessarily be aligned\n    // on a 4-byte boundary. This may cause problems on platforms with strict\n    // alignment requirements. By wrapping data in a \"packed\" struct, we are\n    // telling the backend to generate \"misalignment-safe\" code.\n    pub unsafe fn read<T: Copy>(&mut self) -> T {\n        let Unaligned(result) = *(self.ptr as *const Unaligned<T>);\n        self.ptr = self.ptr.add(mem::size_of::<T>());\n        result\n    }\n\n    // ULEB128 and SLEB128 encodings are defined in Section 7.6 - \"Variable\n    // Length Data\".\n    pub unsafe fn read_uleb128(&mut self) -> u64 {\n        let mut shift: usize = 0;\n        let mut result: u64 = 0;\n        let mut byte: u8;\n        loop {\n            byte = self.read::<u8>();\n            result |= ((byte & 0x7F) as u64) << shift;\n            shift += 7;\n            if byte & 0x80 == 0 {\n                break;\n            }\n        }\n        result\n    }\n\n    pub unsafe fn read_sleb128(&mut self) -> i64 {\n        let mut shift: u32 = 0;\n        let mut result: u64 = 0;\n        let mut byte: u8;\n        loop {\n            byte = self.read::<u8>();\n            result |= ((byte & 0x7F) as u64) << shift;\n            shift += 7;\n            if byte & 0x80 == 0 {\n                break;\n            }\n        }\n        // sign-extend\n        if shift < u64::BITS && (byte & 0x40) != 0 {\n            result |= (!0 as u64) << shift;\n        }\n        result as i64\n    }\n}\n"],[2117,"//! Parsing of GCC-style Language-Specific Data Area (LSDA)\n//! For details see:\n//!  * <https://refspecs.linuxfoundation.org/LSB_3.0.0/LSB-PDA/LSB-PDA/ehframechpt.html>\n//!  * <https://itanium-cxx-abi.github.io/cxx-abi/exceptions.pdf>\n//!  * <https://www.airs.com/blog/archives/460>\n//!  * <https://www.airs.com/blog/archives/464>\n//!\n//! A reference implementation may be found in the GCC source tree\n//! (`<root>/libgcc/unwind-c.c` as of this writing).\n\n#![allow(non_upper_case_globals)]\n#![allow(unused)]\n\nuse crate::dwarf::DwarfReader;\nuse core::mem;\n\npub const DW_EH_PE_omit: u8 = 0xFF;\npub const DW_EH_PE_absptr: u8 = 0x00;\n\npub const DW_EH_PE_uleb128: u8 = 0x01;\npub const DW_EH_PE_udata2: u8 = 0x02;\npub const DW_EH_PE_udata4: u8 = 0x03;\npub const DW_EH_PE_udata8: u8 = 0x04;\npub const DW_EH_PE_sleb128: u8 = 0x09;\npub const DW_EH_PE_sdata2: u8 = 0x0A;\npub const DW_EH_PE_sdata4: u8 = 0x0B;\npub const DW_EH_PE_sdata8: u8 = 0x0C;\n\npub const DW_EH_PE_pcrel: u8 = 0x10;\npub const DW_EH_PE_textrel: u8 = 0x20;\npub const DW_EH_PE_datarel: u8 = 0x30;\npub const DW_EH_PE_funcrel: u8 = 0x40;\npub const DW_EH_PE_aligned: u8 = 0x50;\n\npub const DW_EH_PE_indirect: u8 = 0x80;\n\n#[derive(Copy, Clone)]\npub struct EHContext<'a> {\n    pub ip: usize,                             // Current instruction pointer\n    pub func_start: usize,                     // Address of the current function\n    pub get_text_start: &'a dyn Fn() -> usize, // Get address of the code section\n    pub get_data_start: &'a dyn Fn() -> usize, // Get address of the data section\n}\n\npub enum EHAction {\n    None,\n    Cleanup(usize),\n    Catch(usize),\n    Terminate,\n}\n\npub const USING_SJLJ_EXCEPTIONS: bool = cfg!(all(target_os = \"ios\", target_arch = \"arm\"));\n\npub unsafe fn find_eh_action(lsda: *const u8, context: &EHContext<'_>) -> Result<EHAction, ()> {\n    if lsda.is_null() {\n        return Ok(EHAction::None);\n    }\n\n    let func_start = context.func_start;\n    let mut reader = DwarfReader::new(lsda);\n\n    let start_encoding = reader.read::<u8>();\n    // base address for landing pad offsets\n    let lpad_base = if start_encoding != DW_EH_PE_omit {\n        read_encoded_pointer(&mut reader, context, start_encoding)?\n    } else {\n        func_start\n    };\n\n    let ttype_encoding = reader.read::<u8>();\n    if ttype_encoding != DW_EH_PE_omit {\n        // Rust doesn't analyze exception types, so we don't care about the type table\n        reader.read_uleb128();\n    }\n\n    let call_site_encoding = reader.read::<u8>();\n    let call_site_table_length = reader.read_uleb128();\n    let action_table = reader.ptr.offset(call_site_table_length as isize);\n    let ip = context.ip;\n\n    if !USING_SJLJ_EXCEPTIONS {\n        while reader.ptr < action_table {\n            let cs_start = read_encoded_pointer(&mut reader, context, call_site_encoding)?;\n            let cs_len = read_encoded_pointer(&mut reader, context, call_site_encoding)?;\n            let cs_lpad = read_encoded_pointer(&mut reader, context, call_site_encoding)?;\n            let cs_action = reader.read_uleb128();\n            // Callsite table is sorted by cs_start, so if we've passed the ip, we\n            // may stop searching.\n            if ip < func_start + cs_start {\n                break;\n            }\n            if ip < func_start + cs_start + cs_len {\n                if cs_lpad == 0 {\n                    return Ok(EHAction::None);\n                } else {\n                    let lpad = lpad_base + cs_lpad;\n                    return Ok(interpret_cs_action(cs_action, lpad));\n                }\n            }\n        }\n        // Ip is not present in the table.  This should not happen... but it does: issue #35011.\n        // So rather than returning EHAction::Terminate, we do this.\n        Ok(EHAction::None)\n    } else {\n        // SjLj version:\n        // The \"IP\" is an index into the call-site table, with two exceptions:\n        // -1 means 'no-action', and 0 means 'terminate'.\n        match ip as isize {\n            -1 => return Ok(EHAction::None),\n            0 => return Ok(EHAction::Terminate),\n            _ => (),\n        }\n        let mut idx = ip;\n        loop {\n            let cs_lpad = reader.read_uleb128();\n            let cs_action = reader.read_uleb128();\n            idx -= 1;\n            if idx == 0 {\n                // Can never have null landing pad for sjlj -- that would have\n                // been indicated by a -1 call site index.\n                let lpad = (cs_lpad + 1) as usize;\n                return Ok(interpret_cs_action(cs_action, lpad));\n            }\n        }\n    }\n}\n\nfn interpret_cs_action(cs_action: u64, lpad: usize) -> EHAction {\n    if cs_action == 0 {\n        // If cs_action is 0 then this is a cleanup (Drop::drop). We run these\n        // for both Rust panics and foreign exceptions.\n        EHAction::Cleanup(lpad)\n    } else {\n        // Stop unwinding Rust panics at catch_unwind.\n        EHAction::Catch(lpad)\n    }\n}\n\n#[inline]\nfn round_up(unrounded: usize, align: usize) -> Result<usize, ()> {\n    if align.is_power_of_two() { Ok((unrounded + align - 1) & !(align - 1)) } else { Err(()) }\n}\n\nunsafe fn read_encoded_pointer(\n    reader: &mut DwarfReader,\n    context: &EHContext<'_>,\n    encoding: u8,\n) -> Result<usize, ()> {\n    if encoding == DW_EH_PE_omit {\n        return Err(());\n    }\n\n    // DW_EH_PE_aligned implies it's an absolute pointer value\n    if encoding == DW_EH_PE_aligned {\n        reader.ptr = round_up(reader.ptr as usize, mem::size_of::<usize>())? as *const u8;\n        return Ok(reader.read::<usize>());\n    }\n\n    let mut result = match encoding & 0x0F {\n        DW_EH_PE_absptr => reader.read::<usize>(),\n        DW_EH_PE_uleb128 => reader.read_uleb128() as usize,\n        DW_EH_PE_udata2 => reader.read::<u16>() as usize,\n        DW_EH_PE_udata4 => reader.read::<u32>() as usize,\n        DW_EH_PE_udata8 => reader.read::<u64>() as usize,\n        DW_EH_PE_sleb128 => reader.read_sleb128() as usize,\n        DW_EH_PE_sdata2 => reader.read::<i16>() as usize,\n        DW_EH_PE_sdata4 => reader.read::<i32>() as usize,\n        DW_EH_PE_sdata8 => reader.read::<i64>() as usize,\n        _ => return Err(()),\n    };\n\n    result += match encoding & 0x70 {\n        DW_EH_PE_absptr => 0,\n        // relative to address of the encoded value, despite the name\n        DW_EH_PE_pcrel => reader.ptr as usize,\n        DW_EH_PE_funcrel => {\n            if context.func_start == 0 {\n                return Err(());\n            }\n            context.func_start\n        }\n        DW_EH_PE_textrel => (*context.get_text_start)(),\n        DW_EH_PE_datarel => (*context.get_data_start)(),\n        _ => return Err(()),\n    };\n\n    if encoding & DW_EH_PE_indirect != 0 {\n        result = *(result as *const usize);\n    }\n\n    Ok(result)\n}\n"],[2118,"use super::*;\n\n#[test]\nfn dwarf_reader() {\n    let encoded: &[u8] = &[1, 2, 3, 4, 5, 6, 7, 0xE5, 0x8E, 0x26, 0x9B, 0xF1, 0x59, 0xFF, 0xFF];\n\n    let mut reader = DwarfReader::new(encoded.as_ptr());\n\n    unsafe {\n        assert!(reader.read::<u8>() == u8::to_be(1u8));\n        assert!(reader.read::<u16>() == u16::to_be(0x0203));\n        assert!(reader.read::<u32>() == u32::to_be(0x04050607));\n\n        assert!(reader.read_uleb128() == 624485);\n        assert!(reader.read_sleb128() == -624485);\n\n        assert!(reader.read::<i8>() == i8::to_be(-1));\n    }\n}\n"],[2119,"//! Unwinding panics for Miri.\nuse alloc::boxed::Box;\nuse core::any::Any;\n\n// The type of the payload that the Miri engine propagates through unwinding for us.\n// Must be pointer-sized.\ntype Payload = Box<Box<dyn Any + Send>>;\n\nextern \"Rust\" {\n    /// Miri-provided extern function to begin unwinding.\n    fn miri_start_panic(payload: *mut u8) -> !;\n}\n\npub unsafe fn panic(payload: Box<dyn Any + Send>) -> u32 {\n    // The payload we pass to `miri_start_panic` will be exactly the argument we get\n    // in `cleanup` below. So we just box it up once, to get something pointer-sized.\n    let payload_box: Payload = Box::new(payload);\n    miri_start_panic(Box::into_raw(payload_box) as *mut u8)\n}\n\npub unsafe fn cleanup(payload_box: *mut u8) -> Box<dyn Any + Send> {\n    // Recover the underlying `Box`.\n    let payload_box: Payload = Box::from_raw(payload_box as *mut _);\n    *payload_box\n}\n"],[2120,"//! Windows SEH\n//!\n//! On Windows (currently only on MSVC), the default exception handling\n//! mechanism is Structured Exception Handling (SEH). This is quite different\n//! than Dwarf-based exception handling (e.g., what other unix platforms use) in\n//! terms of compiler internals, so LLVM is required to have a good deal of\n//! extra support for SEH.\n//!\n//! In a nutshell, what happens here is:\n//!\n//! 1. The `panic` function calls the standard Windows function\n//!    `_CxxThrowException` to throw a C++-like exception, triggering the\n//!    unwinding process.\n//! 2. All landing pads generated by the compiler use the personality function\n//!    `__CxxFrameHandler3`, a function in the CRT, and the unwinding code in\n//!    Windows will use this personality function to execute all cleanup code on\n//!    the stack.\n//! 3. All compiler-generated calls to `invoke` have a landing pad set as a\n//!    `cleanuppad` LLVM instruction, which indicates the start of the cleanup\n//!    routine. The personality (in step 2, defined in the CRT) is responsible\n//!    for running the cleanup routines.\n//! 4. Eventually the \"catch\" code in the `try` intrinsic (generated by the\n//!    compiler) is executed and indicates that control should come back to\n//!    Rust. This is done via a `catchswitch` plus a `catchpad` instruction in\n//!    LLVM IR terms, finally returning normal control to the program with a\n//!    `catchret` instruction.\n//!\n//! Some specific differences from the gcc-based exception handling are:\n//!\n//! * Rust has no custom personality function, it is instead *always*\n//!   `__CxxFrameHandler3`. Additionally, no extra filtering is performed, so we\n//!   end up catching any C++ exceptions that happen to look like the kind we're\n//!   throwing. Note that throwing an exception into Rust is undefined behavior\n//!   anyway, so this should be fine.\n//! * We've got some data to transmit across the unwinding boundary,\n//!   specifically a `Box<dyn Any + Send>`. Like with Dwarf exceptions\n//!   these two pointers are stored as a payload in the exception itself. On\n//!   MSVC, however, there's no need for an extra heap allocation because the\n//!   call stack is preserved while filter functions are being executed. This\n//!   means that the pointers are passed directly to `_CxxThrowException` which\n//!   are then recovered in the filter function to be written to the stack frame\n//!   of the `try` intrinsic.\n//!\n//! [win64]: https://docs.microsoft.com/en-us/cpp/build/exception-handling-x64\n//! [llvm]: https://llvm.org/docs/ExceptionHandling.html#background-on-windows-exceptions\n\n#![allow(nonstandard_style)]\n\nuse alloc::boxed::Box;\nuse core::any::Any;\nuse core::mem::{self, ManuallyDrop};\nuse libc::{c_int, c_uint, c_void};\n\nstruct Exception {\n    // This needs to be an Option because we catch the exception by reference\n    // and its destructor is executed by the C++ runtime. When we take the Box\n    // out of the exception, we need to leave the exception in a valid state\n    // for its destructor to run without double-dropping the Box.\n    data: Option<Box<dyn Any + Send>>,\n}\n\n// First up, a whole bunch of type definitions. There's a few platform-specific\n// oddities here, and a lot that's just blatantly copied from LLVM. The purpose\n// of all this is to implement the `panic` function below through a call to\n// `_CxxThrowException`.\n//\n// This function takes two arguments. The first is a pointer to the data we're\n// passing in, which in this case is our trait object. Pretty easy to find! The\n// next, however, is more complicated. This is a pointer to a `_ThrowInfo`\n// structure, and it generally is just intended to just describe the exception\n// being thrown.\n//\n// Currently the definition of this type [1] is a little hairy, and the main\n// oddity (and difference from the online article) is that on 32-bit the\n// pointers are pointers but on 64-bit the pointers are expressed as 32-bit\n// offsets from the `__ImageBase` symbol. The `ptr_t` and `ptr!` macro in the\n// modules below are used to express this.\n//\n// The maze of type definitions also closely follows what LLVM emits for this\n// sort of operation. For example, if you compile this C++ code on MSVC and emit\n// the LLVM IR:\n//\n//      #include <stdint.h>\n//\n//      struct rust_panic {\n//          rust_panic(const rust_panic&);\n//          ~rust_panic();\n//\n//          uint64_t x[2];\n//      };\n//\n//      void foo() {\n//          rust_panic a = {0, 1};\n//          throw a;\n//      }\n//\n// That's essentially what we're trying to emulate. Most of the constant values\n// below were just copied from LLVM,\n//\n// In any case, these structures are all constructed in a similar manner, and\n// it's just somewhat verbose for us.\n//\n// [1]: https://www.geoffchappell.com/studies/msvc/language/predefined/\n\n#[cfg(target_arch = \"x86\")]\n#[macro_use]\nmod imp {\n    pub type ptr_t = *mut u8;\n\n    macro_rules! ptr {\n        (0) => {\n            core::ptr::null_mut()\n        };\n        ($e:expr) => {\n            $e as *mut u8\n        };\n    }\n}\n\n#[cfg(not(target_arch = \"x86\"))]\n#[macro_use]\nmod imp {\n    pub type ptr_t = u32;\n\n    extern \"C\" {\n        pub static __ImageBase: u8;\n    }\n\n    macro_rules! ptr {\n        (0) => (0);\n        ($e:expr) => {\n            (($e as usize) - (&imp::__ImageBase as *const _ as usize)) as u32\n        }\n    }\n}\n\n#[repr(C)]\npub struct _ThrowInfo {\n    pub attributes: c_uint,\n    pub pmfnUnwind: imp::ptr_t,\n    pub pForwardCompat: imp::ptr_t,\n    pub pCatchableTypeArray: imp::ptr_t,\n}\n\n#[repr(C)]\npub struct _CatchableTypeArray {\n    pub nCatchableTypes: c_int,\n    pub arrayOfCatchableTypes: [imp::ptr_t; 1],\n}\n\n#[repr(C)]\npub struct _CatchableType {\n    pub properties: c_uint,\n    pub pType: imp::ptr_t,\n    pub thisDisplacement: _PMD,\n    pub sizeOrOffset: c_int,\n    pub copyFunction: imp::ptr_t,\n}\n\n#[repr(C)]\npub struct _PMD {\n    pub mdisp: c_int,\n    pub pdisp: c_int,\n    pub vdisp: c_int,\n}\n\n#[repr(C)]\npub struct _TypeDescriptor {\n    pub pVFTable: *const u8,\n    pub spare: *mut u8,\n    pub name: [u8; 11],\n}\n\n// Note that we intentionally ignore name mangling rules here: we don't want C++\n// to be able to catch Rust panics by simply declaring a `struct rust_panic`.\n//\n// When modifying, make sure that the type name string exactly matches\n// the one used in `compiler/rustc_codegen_llvm/src/intrinsic.rs`.\nconst TYPE_NAME: [u8; 11] = *b\"rust_panic\\0\";\n\nstatic mut THROW_INFO: _ThrowInfo = _ThrowInfo {\n    attributes: 0,\n    pmfnUnwind: ptr!(0),\n    pForwardCompat: ptr!(0),\n    pCatchableTypeArray: ptr!(0),\n};\n\nstatic mut CATCHABLE_TYPE_ARRAY: _CatchableTypeArray =\n    _CatchableTypeArray { nCatchableTypes: 1, arrayOfCatchableTypes: [ptr!(0)] };\n\nstatic mut CATCHABLE_TYPE: _CatchableType = _CatchableType {\n    properties: 0,\n    pType: ptr!(0),\n    thisDisplacement: _PMD { mdisp: 0, pdisp: -1, vdisp: 0 },\n    sizeOrOffset: mem::size_of::<Exception>() as c_int,\n    copyFunction: ptr!(0),\n};\n\nextern \"C\" {\n    // The leading `\\x01` byte here is actually a magical signal to LLVM to\n    // *not* apply any other mangling like prefixing with a `_` character.\n    //\n    // This symbol is the vtable used by C++'s `std::type_info`. Objects of type\n    // `std::type_info`, type descriptors, have a pointer to this table. Type\n    // descriptors are referenced by the C++ EH structures defined above and\n    // that we construct below.\n    #[link_name = \"\\x01??_7type_info@@6B@\"]\n    static TYPE_INFO_VTABLE: *const u8;\n}\n\n// This type descriptor is only used when throwing an exception. The catch part\n// is handled by the try intrinsic, which generates its own TypeDescriptor.\n//\n// This is fine since the MSVC runtime uses string comparison on the type name\n// to match TypeDescriptors rather than pointer equality.\nstatic mut TYPE_DESCRIPTOR: _TypeDescriptor = _TypeDescriptor {\n    pVFTable: unsafe { &TYPE_INFO_VTABLE } as *const _ as *const _,\n    spare: core::ptr::null_mut(),\n    name: TYPE_NAME,\n};\n\n// Destructor used if the C++ code decides to capture the exception and drop it\n// without propagating it. The catch part of the try intrinsic will set the\n// first word of the exception object to 0 so that it is skipped by the\n// destructor.\n//\n// Note that x86 Windows uses the \"thiscall\" calling convention for C++ member\n// functions instead of the default \"C\" calling convention.\n//\n// The exception_copy function is a bit special here: it is invoked by the MSVC\n// runtime under a try/catch block and the panic that we generate here will be\n// used as the result of the exception copy. This is used by the C++ runtime to\n// support capturing exceptions with std::exception_ptr, which we can't support\n// because Box<dyn Any> isn't clonable.\nmacro_rules! define_cleanup {\n    ($abi:tt) => {\n        unsafe extern $abi fn exception_cleanup(e: *mut Exception) {\n            if let Exception { data: Some(b) } = e.read() {\n                drop(b);\n                super::__rust_drop_panic();\n            }\n        }\n        #[unwind(allowed)]\n        unsafe extern $abi fn exception_copy(_dest: *mut Exception,\n                                             _src: *mut Exception)\n                                             -> *mut Exception {\n            panic!(\"Rust panics cannot be copied\");\n        }\n    }\n}\ncfg_if::cfg_if! {\n   if #[cfg(target_arch = \"x86\")] {\n       define_cleanup!(\"thiscall\");\n   } else {\n       define_cleanup!(\"C\");\n   }\n}\n\npub unsafe fn panic(data: Box<dyn Any + Send>) -> u32 {\n    use core::intrinsics::atomic_store;\n\n    // _CxxThrowException executes entirely on this stack frame, so there's no\n    // need to otherwise transfer `data` to the heap. We just pass a stack\n    // pointer to this function.\n    //\n    // The ManuallyDrop is needed here since we don't want Exception to be\n    // dropped when unwinding. Instead it will be dropped by exception_cleanup\n    // which is invoked by the C++ runtime.\n    let mut exception = ManuallyDrop::new(Exception { data: Some(data) });\n    let throw_ptr = &mut exception as *mut _ as *mut _;\n\n    // This... may seems surprising, and justifiably so. On 32-bit MSVC the\n    // pointers between these structure are just that, pointers. On 64-bit MSVC,\n    // however, the pointers between structures are rather expressed as 32-bit\n    // offsets from `__ImageBase`.\n    //\n    // Consequently, on 32-bit MSVC we can declare all these pointers in the\n    // `static`s above. On 64-bit MSVC, we would have to express subtraction of\n    // pointers in statics, which Rust does not currently allow, so we can't\n    // actually do that.\n    //\n    // The next best thing, then is to fill in these structures at runtime\n    // (panicking is already the \"slow path\" anyway). So here we reinterpret all\n    // of these pointer fields as 32-bit integers and then store the\n    // relevant value into it (atomically, as concurrent panics may be\n    // happening). Technically the runtime will probably do a nonatomic read of\n    // these fields, but in theory they never read the *wrong* value so it\n    // shouldn't be too bad...\n    //\n    // In any case, we basically need to do something like this until we can\n    // express more operations in statics (and we may never be able to).\n    atomic_store(&mut THROW_INFO.pmfnUnwind as *mut _ as *mut u32, ptr!(exception_cleanup) as u32);\n    atomic_store(\n        &mut THROW_INFO.pCatchableTypeArray as *mut _ as *mut u32,\n        ptr!(&CATCHABLE_TYPE_ARRAY as *const _) as u32,\n    );\n    atomic_store(\n        &mut CATCHABLE_TYPE_ARRAY.arrayOfCatchableTypes[0] as *mut _ as *mut u32,\n        ptr!(&CATCHABLE_TYPE as *const _) as u32,\n    );\n    atomic_store(\n        &mut CATCHABLE_TYPE.pType as *mut _ as *mut u32,\n        ptr!(&TYPE_DESCRIPTOR as *const _) as u32,\n    );\n    atomic_store(\n        &mut CATCHABLE_TYPE.copyFunction as *mut _ as *mut u32,\n        ptr!(exception_copy) as u32,\n    );\n\n    extern \"system\" {\n        #[unwind(allowed)]\n        fn _CxxThrowException(pExceptionObject: *mut c_void, pThrowInfo: *mut u8) -> !;\n    }\n\n    _CxxThrowException(throw_ptr, &mut THROW_INFO as *mut _ as *mut _);\n}\n\npub unsafe fn cleanup(payload: *mut u8) -> Box<dyn Any + Send> {\n    // A null payload here means that we got here from the catch (...) of\n    // __rust_try. This happens when a non-Rust foreign exception is caught.\n    if payload.is_null() {\n        super::__rust_foreign_exception();\n    } else {\n        let exception = &mut *(payload as *mut Exception);\n        exception.data.take().unwrap()\n    }\n}\n\n// This is required by the compiler to exist (e.g., it's a lang item), but\n// it's never actually called by the compiler because __C_specific_handler\n// or _except_handler3 is the personality function that is always used.\n// Hence this is just an aborting stub.\n#[lang = \"eh_personality\"]\n#[cfg(not(test))]\nfn rust_eh_personality() {\n    core::intrinsics::abort()\n}\n"],[2121,"//! Implementation of panics backed by libgcc/libunwind (in some form).\n//!\n//! For background on exception handling and stack unwinding please see\n//! \"Exception Handling in LLVM\" (llvm.org/docs/ExceptionHandling.html) and\n//! documents linked from it.\n//! These are also good reads:\n//!  * <https://itanium-cxx-abi.github.io/cxx-abi/abi-eh.html>\n//!  * <https://monoinfinito.wordpress.com/series/exception-handling-in-c/>\n//!  * <https://www.airs.com/blog/index.php?s=exception+frames>\n//!\n//! ## A brief summary\n//!\n//! Exception handling happens in two phases: a search phase and a cleanup\n//! phase.\n//!\n//! In both phases the unwinder walks stack frames from top to bottom using\n//! information from the stack frame unwind sections of the current process's\n//! modules (\"module\" here refers to an OS module, i.e., an executable or a\n//! dynamic library).\n//!\n//! For each stack frame, it invokes the associated \"personality routine\", whose\n//! address is also stored in the unwind info section.\n//!\n//! In the search phase, the job of a personality routine is to examine\n//! exception object being thrown, and to decide whether it should be caught at\n//! that stack frame. Once the handler frame has been identified, cleanup phase\n//! begins.\n//!\n//! In the cleanup phase, the unwinder invokes each personality routine again.\n//! This time it decides which (if any) cleanup code needs to be run for\n//! the current stack frame. If so, the control is transferred to a special\n//! branch in the function body, the \"landing pad\", which invokes destructors,\n//! frees memory, etc. At the end of the landing pad, control is transferred\n//! back to the unwinder and unwinding resumes.\n//!\n//! Once stack has been unwound down to the handler frame level, unwinding stops\n//! and the last personality routine transfers control to the catch block.\n\nuse alloc::boxed::Box;\nuse core::any::Any;\n\nuse crate::dwarf::eh::{self, EHAction, EHContext};\nuse libc::{c_int, uintptr_t};\nuse unwind as uw;\n\n#[repr(C)]\nstruct Exception {\n    _uwe: uw::_Unwind_Exception,\n    cause: Box<dyn Any + Send>,\n}\n\npub unsafe fn panic(data: Box<dyn Any + Send>) -> u32 {\n    let exception = Box::new(Exception {\n        _uwe: uw::_Unwind_Exception {\n            exception_class: rust_exception_class(),\n            exception_cleanup,\n            private: [0; uw::unwinder_private_data_size],\n        },\n        cause: data,\n    });\n    let exception_param = Box::into_raw(exception) as *mut uw::_Unwind_Exception;\n    return uw::_Unwind_RaiseException(exception_param) as u32;\n\n    extern \"C\" fn exception_cleanup(\n        _unwind_code: uw::_Unwind_Reason_Code,\n        exception: *mut uw::_Unwind_Exception,\n    ) {\n        unsafe {\n            let _: Box<Exception> = Box::from_raw(exception as *mut Exception);\n            super::__rust_drop_panic();\n        }\n    }\n}\n\npub unsafe fn cleanup(ptr: *mut u8) -> Box<dyn Any + Send> {\n    let exception = ptr as *mut uw::_Unwind_Exception;\n    if (*exception).exception_class != rust_exception_class() {\n        uw::_Unwind_DeleteException(exception);\n        super::__rust_foreign_exception();\n    } else {\n        let exception = Box::from_raw(exception as *mut Exception);\n        exception.cause\n    }\n}\n\n// Rust's exception class identifier.  This is used by personality routines to\n// determine whether the exception was thrown by their own runtime.\nfn rust_exception_class() -> uw::_Unwind_Exception_Class {\n    // M O Z \\0  R U S T -- vendor, language\n    0x4d4f5a_00_52555354\n}\n\n// Register ids were lifted from LLVM's TargetLowering::getExceptionPointerRegister()\n// and TargetLowering::getExceptionSelectorRegister() for each architecture,\n// then mapped to DWARF register numbers via register definition tables\n// (typically <arch>RegisterInfo.td, search for \"DwarfRegNum\").\n// See also https://llvm.org/docs/WritingAnLLVMBackend.html#defining-a-register.\n\n#[cfg(target_arch = \"x86\")]\nconst UNWIND_DATA_REG: (i32, i32) = (0, 2); // EAX, EDX\n\n#[cfg(target_arch = \"x86_64\")]\nconst UNWIND_DATA_REG: (i32, i32) = (0, 1); // RAX, RDX\n\n#[cfg(any(target_arch = \"arm\", target_arch = \"aarch64\"))]\nconst UNWIND_DATA_REG: (i32, i32) = (0, 1); // R0, R1 / X0, X1\n\n#[cfg(any(target_arch = \"mips\", target_arch = \"mips64\"))]\nconst UNWIND_DATA_REG: (i32, i32) = (4, 5); // A0, A1\n\n#[cfg(any(target_arch = \"powerpc\", target_arch = \"powerpc64\"))]\nconst UNWIND_DATA_REG: (i32, i32) = (3, 4); // R3, R4 / X3, X4\n\n#[cfg(target_arch = \"s390x\")]\nconst UNWIND_DATA_REG: (i32, i32) = (6, 7); // R6, R7\n\n#[cfg(any(target_arch = \"sparc\", target_arch = \"sparc64\"))]\nconst UNWIND_DATA_REG: (i32, i32) = (24, 25); // I0, I1\n\n#[cfg(target_arch = \"hexagon\")]\nconst UNWIND_DATA_REG: (i32, i32) = (0, 1); // R0, R1\n\n#[cfg(any(target_arch = \"riscv64\", target_arch = \"riscv32\"))]\nconst UNWIND_DATA_REG: (i32, i32) = (10, 11); // x10, x11\n\n// The following code is based on GCC's C and C++ personality routines.  For reference, see:\n// https://github.com/gcc-mirror/gcc/blob/master/libstdc++-v3/libsupc++/eh_personality.cc\n// https://github.com/gcc-mirror/gcc/blob/trunk/libgcc/unwind-c.c\n\ncfg_if::cfg_if! {\n    if #[cfg(all(target_arch = \"arm\", not(target_os = \"ios\"), not(target_os = \"netbsd\")))] {\n        // ARM EHABI personality routine.\n        // https://infocenter.arm.com/help/topic/com.arm.doc.ihi0038b/IHI0038B_ehabi.pdf\n        //\n        // iOS uses the default routine instead since it uses SjLj unwinding.\n        #[lang = \"eh_personality\"]\n        unsafe extern \"C\" fn rust_eh_personality(state: uw::_Unwind_State,\n                                                 exception_object: *mut uw::_Unwind_Exception,\n                                                 context: *mut uw::_Unwind_Context)\n                                                 -> uw::_Unwind_Reason_Code {\n            let state = state as c_int;\n            let action = state & uw::_US_ACTION_MASK as c_int;\n            let search_phase = if action == uw::_US_VIRTUAL_UNWIND_FRAME as c_int {\n                // Backtraces on ARM will call the personality routine with\n                // state == _US_VIRTUAL_UNWIND_FRAME | _US_FORCE_UNWIND. In those cases\n                // we want to continue unwinding the stack, otherwise all our backtraces\n                // would end at __rust_try\n                if state & uw::_US_FORCE_UNWIND as c_int != 0 {\n                    return continue_unwind(exception_object, context);\n                }\n                true\n            } else if action == uw::_US_UNWIND_FRAME_STARTING as c_int {\n                false\n            } else if action == uw::_US_UNWIND_FRAME_RESUME as c_int {\n                return continue_unwind(exception_object, context);\n            } else {\n                return uw::_URC_FAILURE;\n            };\n\n            // The DWARF unwinder assumes that _Unwind_Context holds things like the function\n            // and LSDA pointers, however ARM EHABI places them into the exception object.\n            // To preserve signatures of functions like _Unwind_GetLanguageSpecificData(), which\n            // take only the context pointer, GCC personality routines stash a pointer to\n            // exception_object in the context, using location reserved for ARM's\n            // \"scratch register\" (r12).\n            uw::_Unwind_SetGR(context,\n                              uw::UNWIND_POINTER_REG,\n                              exception_object as uw::_Unwind_Ptr);\n            // ...A more principled approach would be to provide the full definition of ARM's\n            // _Unwind_Context in our libunwind bindings and fetch the required data from there\n            // directly, bypassing DWARF compatibility functions.\n\n            let eh_action = match find_eh_action(context) {\n                Ok(action) => action,\n                Err(_) => return uw::_URC_FAILURE,\n            };\n            if search_phase {\n                match eh_action {\n                    EHAction::None |\n                    EHAction::Cleanup(_) => return continue_unwind(exception_object, context),\n                    EHAction::Catch(_) => {\n                        // EHABI requires the personality routine to update the\n                        // SP value in the barrier cache of the exception object.\n                        (*exception_object).private[5] =\n                            uw::_Unwind_GetGR(context, uw::UNWIND_SP_REG);\n                        return uw::_URC_HANDLER_FOUND;\n                    }\n                    EHAction::Terminate => return uw::_URC_FAILURE,\n                }\n            } else {\n                match eh_action {\n                    EHAction::None => return continue_unwind(exception_object, context),\n                    EHAction::Cleanup(lpad) |\n                    EHAction::Catch(lpad) => {\n                        uw::_Unwind_SetGR(context, UNWIND_DATA_REG.0,\n                                          exception_object as uintptr_t);\n                        uw::_Unwind_SetGR(context, UNWIND_DATA_REG.1, 0);\n                        uw::_Unwind_SetIP(context, lpad);\n                        return uw::_URC_INSTALL_CONTEXT;\n                    }\n                    EHAction::Terminate => return uw::_URC_FAILURE,\n                }\n            }\n\n            // On ARM EHABI the personality routine is responsible for actually\n            // unwinding a single stack frame before returning (ARM EHABI Sec. 6.1).\n            unsafe fn continue_unwind(exception_object: *mut uw::_Unwind_Exception,\n                                      context: *mut uw::_Unwind_Context)\n                                      -> uw::_Unwind_Reason_Code {\n                if __gnu_unwind_frame(exception_object, context) == uw::_URC_NO_REASON {\n                    uw::_URC_CONTINUE_UNWIND\n                } else {\n                    uw::_URC_FAILURE\n                }\n            }\n            // defined in libgcc\n            extern \"C\" {\n                fn __gnu_unwind_frame(exception_object: *mut uw::_Unwind_Exception,\n                                      context: *mut uw::_Unwind_Context)\n                                      -> uw::_Unwind_Reason_Code;\n            }\n        }\n    } else {\n        // Default personality routine, which is used directly on most targets\n        // and indirectly on Windows x86_64 via SEH.\n        unsafe extern \"C\" fn rust_eh_personality_impl(version: c_int,\n                                                      actions: uw::_Unwind_Action,\n                                                      _exception_class: uw::_Unwind_Exception_Class,\n                                                      exception_object: *mut uw::_Unwind_Exception,\n                                                      context: *mut uw::_Unwind_Context)\n                                                      -> uw::_Unwind_Reason_Code {\n            if version != 1 {\n                return uw::_URC_FATAL_PHASE1_ERROR;\n            }\n            let eh_action = match find_eh_action(context) {\n                Ok(action) => action,\n                Err(_) => return uw::_URC_FATAL_PHASE1_ERROR,\n            };\n            if actions as i32 & uw::_UA_SEARCH_PHASE as i32 != 0 {\n                match eh_action {\n                    EHAction::None |\n                    EHAction::Cleanup(_) => uw::_URC_CONTINUE_UNWIND,\n                    EHAction::Catch(_) => uw::_URC_HANDLER_FOUND,\n                    EHAction::Terminate => uw::_URC_FATAL_PHASE1_ERROR,\n                }\n            } else {\n                match eh_action {\n                    EHAction::None => uw::_URC_CONTINUE_UNWIND,\n                    EHAction::Cleanup(lpad) |\n                    EHAction::Catch(lpad) => {\n                        uw::_Unwind_SetGR(context, UNWIND_DATA_REG.0,\n                            exception_object as uintptr_t);\n                        uw::_Unwind_SetGR(context, UNWIND_DATA_REG.1, 0);\n                        uw::_Unwind_SetIP(context, lpad);\n                        uw::_URC_INSTALL_CONTEXT\n                    }\n                    EHAction::Terminate => uw::_URC_FATAL_PHASE2_ERROR,\n                }\n            }\n        }\n\n        cfg_if::cfg_if! {\n            if #[cfg(all(windows, target_arch = \"x86_64\", target_env = \"gnu\"))] {\n                // On x86_64 MinGW targets, the unwinding mechanism is SEH however the unwind\n                // handler data (aka LSDA) uses GCC-compatible encoding.\n                #[lang = \"eh_personality\"]\n                #[allow(nonstandard_style)]\n                unsafe extern \"C\" fn rust_eh_personality(exceptionRecord: *mut uw::EXCEPTION_RECORD,\n                        establisherFrame: uw::LPVOID,\n                        contextRecord: *mut uw::CONTEXT,\n                        dispatcherContext: *mut uw::DISPATCHER_CONTEXT)\n                        -> uw::EXCEPTION_DISPOSITION {\n                    uw::_GCC_specific_handler(exceptionRecord,\n                                             establisherFrame,\n                                             contextRecord,\n                                             dispatcherContext,\n                                             rust_eh_personality_impl)\n                }\n            } else {\n                // The personality routine for most of our targets.\n                #[lang = \"eh_personality\"]\n                unsafe extern \"C\" fn rust_eh_personality(version: c_int,\n                        actions: uw::_Unwind_Action,\n                        exception_class: uw::_Unwind_Exception_Class,\n                        exception_object: *mut uw::_Unwind_Exception,\n                        context: *mut uw::_Unwind_Context)\n                        -> uw::_Unwind_Reason_Code {\n                    rust_eh_personality_impl(version,\n                                             actions,\n                                             exception_class,\n                                             exception_object,\n                                             context)\n                }\n            }\n        }\n    }\n}\n\nunsafe fn find_eh_action(context: *mut uw::_Unwind_Context) -> Result<EHAction, ()> {\n    let lsda = uw::_Unwind_GetLanguageSpecificData(context) as *const u8;\n    let mut ip_before_instr: c_int = 0;\n    let ip = uw::_Unwind_GetIPInfo(context, &mut ip_before_instr);\n    let eh_context = EHContext {\n        // The return address points 1 byte past the call instruction,\n        // which could be in the next IP range in LSDA range table.\n        ip: if ip_before_instr != 0 { ip } else { ip - 1 },\n        func_start: uw::_Unwind_GetRegionStart(context),\n        get_text_start: &|| uw::_Unwind_GetTextRelBase(context),\n        get_data_start: &|| uw::_Unwind_GetDataRelBase(context),\n    };\n    eh::find_eh_action(lsda, &eh_context)\n}\n\n// Frame unwind info registration\n//\n// Each module's image contains a frame unwind info section (usually\n// \".eh_frame\").  When a module is loaded/unloaded into the process, the\n// unwinder must be informed about the location of this section in memory. The\n// methods of achieving that vary by the platform.  On some (e.g., Linux), the\n// unwinder can discover unwind info sections on its own (by dynamically\n// enumerating currently loaded modules via the dl_iterate_phdr() API and\n// finding their \".eh_frame\" sections); Others, like Windows, require modules\n// to actively register their unwind info sections via unwinder API.\n//\n// This module defines two symbols which are referenced and called from\n// rsbegin.rs to register our information with the GCC runtime. The\n// implementation of stack unwinding is (for now) deferred to libgcc_eh, however\n// Rust crates use these Rust-specific entry points to avoid potential clashes\n// with any GCC runtime.\n#[cfg(all(target_os = \"windows\", target_arch = \"x86\", target_env = \"gnu\"))]\npub mod eh_frame_registry {\n    extern \"C\" {\n        fn __register_frame_info(eh_frame_begin: *const u8, object: *mut u8);\n        fn __deregister_frame_info(eh_frame_begin: *const u8, object: *mut u8);\n    }\n\n    #[rustc_std_internal_symbol]\n    pub unsafe extern \"C\" fn rust_eh_register_frames(eh_frame_begin: *const u8, object: *mut u8) {\n        __register_frame_info(eh_frame_begin, object);\n    }\n\n    #[rustc_std_internal_symbol]\n    pub unsafe extern \"C\" fn rust_eh_unregister_frames(eh_frame_begin: *const u8, object: *mut u8) {\n        __deregister_frame_info(eh_frame_begin, object);\n    }\n}\n"],[2122,"//! Unwinding for *wasm32* target.\n//!\n//! Right now we don't support this, so this is just stubs.\n\nuse alloc::boxed::Box;\nuse core::any::Any;\nuse core::intrinsics;\n\npub unsafe fn cleanup(_ptr: *mut u8) -> Box<dyn Any + Send> {\n    intrinsics::abort()\n}\n\npub unsafe fn panic(_data: Box<dyn Any + Send>) -> u32 {\n    intrinsics::abort()\n}\n"],[2123,"//! Unwinding for *emscripten* target.\n//!\n//! Whereas Rust's usual unwinding implementation for Unix platforms\n//! calls into the libunwind APIs directly, on Emscripten we instead\n//! call into the C++ unwinding APIs. This is just an expedience since\n//! Emscripten's runtime always implements those APIs and does not\n//! implement libunwind.\n\nuse alloc::boxed::Box;\nuse core::any::Any;\nuse core::intrinsics;\nuse core::mem;\nuse core::ptr;\nuse core::sync::atomic::{AtomicBool, Ordering};\nuse libc::{self, c_int};\nuse unwind as uw;\n\n// This matches the layout of std::type_info in C++\n#[repr(C)]\nstruct TypeInfo {\n    vtable: *const usize,\n    name: *const u8,\n}\nunsafe impl Sync for TypeInfo {}\n\nextern \"C\" {\n    // The leading `\\x01` byte here is actually a magical signal to LLVM to\n    // *not* apply any other mangling like prefixing with a `_` character.\n    //\n    // This symbol is the vtable used by C++'s `std::type_info`. Objects of type\n    // `std::type_info`, type descriptors, have a pointer to this table. Type\n    // descriptors are referenced by the C++ EH structures defined above and\n    // that we construct below.\n    //\n    // Note that the real size is larger than 3 usize, but we only need our\n    // vtable to point to the third element.\n    #[link_name = \"\\x01_ZTVN10__cxxabiv117__class_type_infoE\"]\n    static CLASS_TYPE_INFO_VTABLE: [usize; 3];\n}\n\n// std::type_info for a rust_panic class\n#[lang = \"eh_catch_typeinfo\"]\nstatic EXCEPTION_TYPE_INFO: TypeInfo = TypeInfo {\n    // Normally we would use .as_ptr().add(2) but this doesn't work in a const context.\n    vtable: unsafe { &CLASS_TYPE_INFO_VTABLE[2] },\n    // This intentionally doesn't use the normal name mangling scheme because\n    // we don't want C++ to be able to produce or catch Rust panics.\n    name: b\"rust_panic\\0\".as_ptr(),\n};\n\nstruct Exception {\n    // This is necessary because C++ code can capture our execption with\n    // std::exception_ptr and rethrow it multiple times, possibly even in\n    // another thread.\n    caught: AtomicBool,\n\n    // This needs to be an Option because the object's lifetime follows C++\n    // semantics: when catch_unwind moves the Box out of the exception it must\n    // still leave the exception object in a valid state because its destructor\n    // is still going to be called by __cxa_end_catch.\n    data: Option<Box<dyn Any + Send>>,\n}\n\npub unsafe fn cleanup(ptr: *mut u8) -> Box<dyn Any + Send> {\n    // intrinsics::try actually gives us a pointer to this structure.\n    #[repr(C)]\n    struct CatchData {\n        ptr: *mut u8,\n        is_rust_panic: bool,\n    }\n    let catch_data = &*(ptr as *mut CatchData);\n\n    let adjusted_ptr = __cxa_begin_catch(catch_data.ptr as *mut libc::c_void) as *mut Exception;\n    let out = if catch_data.is_rust_panic {\n        let was_caught = (*adjusted_ptr).caught.swap(true, Ordering::SeqCst);\n        if was_caught {\n            // Since cleanup() isn't allowed to panic, we just abort instead.\n            intrinsics::abort();\n        }\n        (*adjusted_ptr).data.take().unwrap()\n    } else {\n        super::__rust_foreign_exception();\n    };\n    __cxa_end_catch();\n    out\n}\n\npub unsafe fn panic(data: Box<dyn Any + Send>) -> u32 {\n    let sz = mem::size_of_val(&data);\n    let exception = __cxa_allocate_exception(sz) as *mut Exception;\n    if exception.is_null() {\n        return uw::_URC_FATAL_PHASE1_ERROR as u32;\n    }\n    ptr::write(exception, Exception { caught: AtomicBool::new(false), data: Some(data) });\n    __cxa_throw(exception as *mut _, &EXCEPTION_TYPE_INFO, exception_cleanup);\n}\n\nextern \"C\" fn exception_cleanup(ptr: *mut libc::c_void) -> *mut libc::c_void {\n    unsafe {\n        if let Some(b) = (ptr as *mut Exception).read().data {\n            drop(b);\n            super::__rust_drop_panic();\n        }\n        ptr\n    }\n}\n\n#[lang = \"eh_personality\"]\nunsafe extern \"C\" fn rust_eh_personality(\n    version: c_int,\n    actions: uw::_Unwind_Action,\n    exception_class: uw::_Unwind_Exception_Class,\n    exception_object: *mut uw::_Unwind_Exception,\n    context: *mut uw::_Unwind_Context,\n) -> uw::_Unwind_Reason_Code {\n    __gxx_personality_v0(version, actions, exception_class, exception_object, context)\n}\n\nextern \"C\" {\n    fn __cxa_allocate_exception(thrown_size: libc::size_t) -> *mut libc::c_void;\n    fn __cxa_begin_catch(thrown_exception: *mut libc::c_void) -> *mut libc::c_void;\n    fn __cxa_end_catch();\n    fn __cxa_throw(\n        thrown_exception: *mut libc::c_void,\n        tinfo: *const TypeInfo,\n        dest: extern \"C\" fn(*mut libc::c_void) -> *mut libc::c_void,\n    ) -> !;\n    fn __gxx_personality_v0(\n        version: c_int,\n        actions: uw::_Unwind_Action,\n        exception_class: uw::_Unwind_Exception_Class,\n        exception_object: *mut uw::_Unwind_Exception,\n        context: *mut uw::_Unwind_Context,\n    ) -> uw::_Unwind_Reason_Code;\n}\n"],[2124,"//! Unwinding for *hermit* target.\n//!\n//! Right now we don't support this, so this is just stubs.\n\nuse alloc::boxed::Box;\nuse core::any::Any;\n\npub unsafe fn cleanup(_ptr: *mut u8) -> Box<dyn Any + Send> {\n    extern \"C\" {\n        pub fn __rust_abort() -> !;\n    }\n    __rust_abort();\n}\n\npub unsafe fn panic(_data: Box<dyn Any + Send>) -> u32 {\n    extern \"C\" {\n        pub fn __rust_abort() -> !;\n    }\n    __rust_abort();\n}\n"],[2125,"//! Temporal quantification.\n//!\n//! Example:\n//!\n//! ```\n//! use std::time::Duration;\n//!\n//! let five_seconds = Duration::new(5, 0);\n//! // both declarations are equivalent\n//! assert_eq!(Duration::new(5, 0), Duration::from_secs(5));\n//! ```\n\n#![stable(feature = \"time\", since = \"1.3.0\")]\n\n#[cfg(test)]\nmod tests;\n\nuse crate::cmp;\nuse crate::error::Error;\nuse crate::fmt;\nuse crate::ops::{Add, AddAssign, Sub, SubAssign};\nuse crate::sys::time;\nuse crate::sys_common::mutex::StaticMutex;\nuse crate::sys_common::FromInner;\n\n#[stable(feature = \"time\", since = \"1.3.0\")]\npub use core::time::Duration;\n\n/// A measurement of a monotonically nondecreasing clock.\n/// Opaque and useful only with `Duration`.\n///\n/// Instants are always guaranteed to be no less than any previously measured\n/// instant when created, and are often useful for tasks such as measuring\n/// benchmarks or timing how long an operation takes.\n///\n/// Note, however, that instants are not guaranteed to be **steady**. In other\n/// words, each tick of the underlying clock may not be the same length (e.g.\n/// some seconds may be longer than others). An instant may jump forwards or\n/// experience time dilation (slow down or speed up), but it will never go\n/// backwards.\n///\n/// Instants are opaque types that can only be compared to one another. There is\n/// no method to get \"the number of seconds\" from an instant. Instead, it only\n/// allows measuring the duration between two instants (or comparing two\n/// instants).\n///\n/// The size of an `Instant` struct may vary depending on the target operating\n/// system.\n///\n/// Example:\n///\n/// ```no_run\n/// use std::time::{Duration, Instant};\n/// use std::thread::sleep;\n///\n/// fn main() {\n///    let now = Instant::now();\n///\n///    // we sleep for 2 seconds\n///    sleep(Duration::new(2, 0));\n///    // it prints '2'\n///    println!(\"{}\", now.elapsed().as_secs());\n/// }\n/// ```\n///\n/// # OS-specific behaviors\n///\n/// An `Instant` is a wrapper around system-specific types and it may behave\n/// differently depending on the underlying operating system. For example,\n/// the following snippet is fine on Linux but panics on macOS:\n///\n/// ```no_run\n/// use std::time::{Instant, Duration};\n///\n/// let now = Instant::now();\n/// let max_nanoseconds = u64::MAX / 1_000_000_000;\n/// let duration = Duration::new(max_nanoseconds, 0);\n/// println!(\"{:?}\", now + duration);\n/// ```\n///\n/// # Underlying System calls\n/// Currently, the following system calls are being used to get the current time using `now()`:\n///\n/// |  Platform |               System call                                            |\n/// |-----------|----------------------------------------------------------------------|\n/// | SGX       | [`insecure_time` usercall]. More information on [timekeeping in SGX] |\n/// | UNIX      | [clock_gettime (Monotonic Clock)]                                    |\n/// | Darwin    | [mach_absolute_time]                                                 |\n/// | VXWorks   | [clock_gettime (Monotonic Clock)]                                    |\n/// | WASI      | [__wasi_clock_time_get (Monotonic Clock)]                            |\n/// | Windows   | [QueryPerformanceCounter]                                            |\n///\n/// [QueryPerformanceCounter]: https://docs.microsoft.com/en-us/windows/win32/api/profileapi/nf-profileapi-queryperformancecounter\n/// [`insecure_time` usercall]: https://edp.fortanix.com/docs/api/fortanix_sgx_abi/struct.Usercalls.html#method.insecure_time\n/// [timekeeping in SGX]: https://edp.fortanix.com/docs/concepts/rust-std/#codestdtimecode\n/// [__wasi_clock_time_get (Monotonic Clock)]: https://github.com/WebAssembly/WASI/blob/master/phases/snapshot/docs.md#clock_time_get\n/// [clock_gettime (Monotonic Clock)]: https://linux.die.net/man/3/clock_gettime\n/// [mach_absolute_time]: https://developer.apple.com/library/archive/documentation/Darwin/Conceptual/KernelProgramming/services/services.html\n///\n/// **Disclaimer:** These system calls might change over time.\n///\n/// > Note: mathematical operations like [`add`] may panic if the underlying\n/// > structure cannot represent the new point in time.\n///\n/// [`add`]: Instant::add\n#[derive(Copy, Clone, PartialEq, Eq, PartialOrd, Ord, Hash)]\n#[stable(feature = \"time2\", since = \"1.8.0\")]\npub struct Instant(time::Instant);\n\n/// A measurement of the system clock, useful for talking to\n/// external entities like the file system or other processes.\n///\n/// Distinct from the [`Instant`] type, this time measurement **is not\n/// monotonic**. This means that you can save a file to the file system, then\n/// save another file to the file system, **and the second file has a\n/// `SystemTime` measurement earlier than the first**. In other words, an\n/// operation that happens after another operation in real time may have an\n/// earlier `SystemTime`!\n///\n/// Consequently, comparing two `SystemTime` instances to learn about the\n/// duration between them returns a [`Result`] instead of an infallible [`Duration`]\n/// to indicate that this sort of time drift may happen and needs to be handled.\n///\n/// Although a `SystemTime` cannot be directly inspected, the [`UNIX_EPOCH`]\n/// constant is provided in this module as an anchor in time to learn\n/// information about a `SystemTime`. By calculating the duration from this\n/// fixed point in time, a `SystemTime` can be converted to a human-readable time,\n/// or perhaps some other string representation.\n///\n/// The size of a `SystemTime` struct may vary depending on the target operating\n/// system.\n///\n/// Example:\n///\n/// ```no_run\n/// use std::time::{Duration, SystemTime};\n/// use std::thread::sleep;\n///\n/// fn main() {\n///    let now = SystemTime::now();\n///\n///    // we sleep for 2 seconds\n///    sleep(Duration::new(2, 0));\n///    match now.elapsed() {\n///        Ok(elapsed) => {\n///            // it prints '2'\n///            println!(\"{}\", elapsed.as_secs());\n///        }\n///        Err(e) => {\n///            // an error occurred!\n///            println!(\"Error: {:?}\", e);\n///        }\n///    }\n/// }\n/// ```\n///\n/// # Underlying System calls\n/// Currently, the following system calls are being used to get the current time using `now()`:\n///\n/// |  Platform |               System call                                            |\n/// |-----------|----------------------------------------------------------------------|\n/// | SGX       | [`insecure_time` usercall]. More information on [timekeeping in SGX] |\n/// | UNIX      | [clock_gettime (Realtime Clock)]                                     |\n/// | Darwin    | [gettimeofday]                                                       |\n/// | VXWorks   | [clock_gettime (Realtime Clock)]                                     |\n/// | WASI      | [__wasi_clock_time_get (Realtime Clock)]                             |\n/// | Windows   | [GetSystemTimePreciseAsFileTime] / [GetSystemTimeAsFileTime]         |\n///\n/// [`insecure_time` usercall]: https://edp.fortanix.com/docs/api/fortanix_sgx_abi/struct.Usercalls.html#method.insecure_time\n/// [timekeeping in SGX]: https://edp.fortanix.com/docs/concepts/rust-std/#codestdtimecode\n/// [gettimeofday]: https://man7.org/linux/man-pages/man2/gettimeofday.2.html\n/// [clock_gettime (Realtime Clock)]: https://linux.die.net/man/3/clock_gettime\n/// [__wasi_clock_time_get (Realtime Clock)]: https://github.com/WebAssembly/WASI/blob/master/phases/snapshot/docs.md#clock_time_get\n/// [GetSystemTimePreciseAsFileTime]: https://docs.microsoft.com/en-us/windows/win32/api/sysinfoapi/nf-sysinfoapi-getsystemtimepreciseasfiletime\n/// [GetSystemTimeAsFileTime]: https://docs.microsoft.com/en-us/windows/win32/api/sysinfoapi/nf-sysinfoapi-getsystemtimeasfiletime\n///\n/// **Disclaimer:** These system calls might change over time.\n///\n/// > Note: mathematical operations like [`add`] may panic if the underlying\n/// > structure cannot represent the new point in time.\n///\n/// [`add`]: SystemTime::add\n#[derive(Copy, Clone, PartialEq, Eq, PartialOrd, Ord, Hash)]\n#[stable(feature = \"time2\", since = \"1.8.0\")]\npub struct SystemTime(time::SystemTime);\n\n/// An error returned from the `duration_since` and `elapsed` methods on\n/// `SystemTime`, used to learn how far in the opposite direction a system time\n/// lies.\n///\n/// # Examples\n///\n/// ```no_run\n/// use std::thread::sleep;\n/// use std::time::{Duration, SystemTime};\n///\n/// let sys_time = SystemTime::now();\n/// sleep(Duration::from_secs(1));\n/// let new_sys_time = SystemTime::now();\n/// match sys_time.duration_since(new_sys_time) {\n///     Ok(_) => {}\n///     Err(e) => println!(\"SystemTimeError difference: {:?}\", e.duration()),\n/// }\n/// ```\n#[derive(Clone, Debug)]\n#[stable(feature = \"time2\", since = \"1.8.0\")]\npub struct SystemTimeError(Duration);\n\nimpl Instant {\n    /// Returns an instant corresponding to \"now\".\n    ///\n    /// # Examples\n    ///\n    /// ```\n    /// use std::time::Instant;\n    ///\n    /// let now = Instant::now();\n    /// ```\n    #[stable(feature = \"time2\", since = \"1.8.0\")]\n    pub fn now() -> Instant {\n        let os_now = time::Instant::now();\n\n        // And here we come upon a sad state of affairs. The whole point of\n        // `Instant` is that it's monotonically increasing. We've found in the\n        // wild, however, that it's not actually monotonically increasing for\n        // one reason or another. These appear to be OS and hardware level bugs,\n        // and there's not really a whole lot we can do about them. Here's a\n        // taste of what we've found:\n        //\n        // * #48514 - OpenBSD, x86_64\n        // * #49281 - linux arm64 and s390x\n        // * #51648 - windows, x86\n        // * #56560 - windows, x86_64, AWS\n        // * #56612 - windows, x86, vm (?)\n        // * #56940 - linux, arm64\n        // * https://bugzilla.mozilla.org/show_bug.cgi?id=1487778 - a similar\n        //   Firefox bug\n        //\n        // It seems that this just happens a lot in the wild.\n        // We're seeing panics across various platforms where consecutive calls\n        // to `Instant::now`, such as via the `elapsed` function, are panicking\n        // as they're going backwards. Placed here is a last-ditch effort to try\n        // to fix things up. We keep a global \"latest now\" instance which is\n        // returned instead of what the OS says if the OS goes backwards.\n        //\n        // To hopefully mitigate the impact of this, a few platforms are\n        // excluded as \"these at least haven't gone backwards yet\".\n        if time::Instant::actually_monotonic() {\n            return Instant(os_now);\n        }\n\n        static LOCK: StaticMutex = StaticMutex::new();\n        static mut LAST_NOW: time::Instant = time::Instant::zero();\n        unsafe {\n            let _lock = LOCK.lock();\n            let now = cmp::max(LAST_NOW, os_now);\n            LAST_NOW = now;\n            Instant(now)\n        }\n    }\n\n    /// Returns the amount of time elapsed from another instant to this one.\n    ///\n    /// # Panics\n    ///\n    /// This function will panic if `earlier` is later than `self`.\n    ///\n    /// # Examples\n    ///\n    /// ```no_run\n    /// use std::time::{Duration, Instant};\n    /// use std::thread::sleep;\n    ///\n    /// let now = Instant::now();\n    /// sleep(Duration::new(1, 0));\n    /// let new_now = Instant::now();\n    /// println!(\"{:?}\", new_now.duration_since(now));\n    /// ```\n    #[stable(feature = \"time2\", since = \"1.8.0\")]\n    pub fn duration_since(&self, earlier: Instant) -> Duration {\n        self.0.checked_sub_instant(&earlier.0).expect(\"supplied instant is later than self\")\n    }\n\n    /// Returns the amount of time elapsed from another instant to this one,\n    /// or None if that instant is later than this one.\n    ///\n    /// # Examples\n    ///\n    /// ```no_run\n    /// use std::time::{Duration, Instant};\n    /// use std::thread::sleep;\n    ///\n    /// let now = Instant::now();\n    /// sleep(Duration::new(1, 0));\n    /// let new_now = Instant::now();\n    /// println!(\"{:?}\", new_now.checked_duration_since(now));\n    /// println!(\"{:?}\", now.checked_duration_since(new_now)); // None\n    /// ```\n    #[stable(feature = \"checked_duration_since\", since = \"1.39.0\")]\n    pub fn checked_duration_since(&self, earlier: Instant) -> Option<Duration> {\n        self.0.checked_sub_instant(&earlier.0)\n    }\n\n    /// Returns the amount of time elapsed from another instant to this one,\n    /// or zero duration if that instant is later than this one.\n    ///\n    /// # Examples\n    ///\n    /// ```no_run\n    /// use std::time::{Duration, Instant};\n    /// use std::thread::sleep;\n    ///\n    /// let now = Instant::now();\n    /// sleep(Duration::new(1, 0));\n    /// let new_now = Instant::now();\n    /// println!(\"{:?}\", new_now.saturating_duration_since(now));\n    /// println!(\"{:?}\", now.saturating_duration_since(new_now)); // 0ns\n    /// ```\n    #[stable(feature = \"checked_duration_since\", since = \"1.39.0\")]\n    pub fn saturating_duration_since(&self, earlier: Instant) -> Duration {\n        self.checked_duration_since(earlier).unwrap_or_default()\n    }\n\n    /// Returns the amount of time elapsed since this instant was created.\n    ///\n    /// # Panics\n    ///\n    /// This function may panic if the current time is earlier than this\n    /// instant, which is something that can happen if an `Instant` is\n    /// produced synthetically.\n    ///\n    /// # Examples\n    ///\n    /// ```no_run\n    /// use std::thread::sleep;\n    /// use std::time::{Duration, Instant};\n    ///\n    /// let instant = Instant::now();\n    /// let three_secs = Duration::from_secs(3);\n    /// sleep(three_secs);\n    /// assert!(instant.elapsed() >= three_secs);\n    /// ```\n    #[stable(feature = \"time2\", since = \"1.8.0\")]\n    pub fn elapsed(&self) -> Duration {\n        Instant::now() - *self\n    }\n\n    /// Returns `Some(t)` where `t` is the time `self + duration` if `t` can be represented as\n    /// `Instant` (which means it's inside the bounds of the underlying data structure), `None`\n    /// otherwise.\n    #[stable(feature = \"time_checked_add\", since = \"1.34.0\")]\n    pub fn checked_add(&self, duration: Duration) -> Option<Instant> {\n        self.0.checked_add_duration(&duration).map(Instant)\n    }\n\n    /// Returns `Some(t)` where `t` is the time `self - duration` if `t` can be represented as\n    /// `Instant` (which means it's inside the bounds of the underlying data structure), `None`\n    /// otherwise.\n    #[stable(feature = \"time_checked_add\", since = \"1.34.0\")]\n    pub fn checked_sub(&self, duration: Duration) -> Option<Instant> {\n        self.0.checked_sub_duration(&duration).map(Instant)\n    }\n}\n\n#[stable(feature = \"time2\", since = \"1.8.0\")]\nimpl Add<Duration> for Instant {\n    type Output = Instant;\n\n    /// # Panics\n    ///\n    /// This function may panic if the resulting point in time cannot be represented by the\n    /// underlying data structure. See [`Instant::checked_add`] for a version without panic.\n    fn add(self, other: Duration) -> Instant {\n        self.checked_add(other).expect(\"overflow when adding duration to instant\")\n    }\n}\n\n#[stable(feature = \"time_augmented_assignment\", since = \"1.9.0\")]\nimpl AddAssign<Duration> for Instant {\n    fn add_assign(&mut self, other: Duration) {\n        *self = *self + other;\n    }\n}\n\n#[stable(feature = \"time2\", since = \"1.8.0\")]\nimpl Sub<Duration> for Instant {\n    type Output = Instant;\n\n    fn sub(self, other: Duration) -> Instant {\n        self.checked_sub(other).expect(\"overflow when subtracting duration from instant\")\n    }\n}\n\n#[stable(feature = \"time_augmented_assignment\", since = \"1.9.0\")]\nimpl SubAssign<Duration> for Instant {\n    fn sub_assign(&mut self, other: Duration) {\n        *self = *self - other;\n    }\n}\n\n#[stable(feature = \"time2\", since = \"1.8.0\")]\nimpl Sub<Instant> for Instant {\n    type Output = Duration;\n\n    fn sub(self, other: Instant) -> Duration {\n        self.duration_since(other)\n    }\n}\n\n#[stable(feature = \"time2\", since = \"1.8.0\")]\nimpl fmt::Debug for Instant {\n    fn fmt(&self, f: &mut fmt::Formatter<'_>) -> fmt::Result {\n        self.0.fmt(f)\n    }\n}\n\nimpl SystemTime {\n    /// An anchor in time which can be used to create new `SystemTime` instances or\n    /// learn about where in time a `SystemTime` lies.\n    ///\n    /// This constant is defined to be \"1970-01-01 00:00:00 UTC\" on all systems with\n    /// respect to the system clock. Using `duration_since` on an existing\n    /// `SystemTime` instance can tell how far away from this point in time a\n    /// measurement lies, and using `UNIX_EPOCH + duration` can be used to create a\n    /// `SystemTime` instance to represent another fixed point in time.\n    ///\n    /// # Examples\n    ///\n    /// ```no_run\n    /// use std::time::SystemTime;\n    ///\n    /// match SystemTime::now().duration_since(SystemTime::UNIX_EPOCH) {\n    ///     Ok(n) => println!(\"1970-01-01 00:00:00 UTC was {} seconds ago!\", n.as_secs()),\n    ///     Err(_) => panic!(\"SystemTime before UNIX EPOCH!\"),\n    /// }\n    /// ```\n    #[stable(feature = \"assoc_unix_epoch\", since = \"1.28.0\")]\n    pub const UNIX_EPOCH: SystemTime = UNIX_EPOCH;\n\n    /// Returns the system time corresponding to \"now\".\n    ///\n    /// # Examples\n    ///\n    /// ```\n    /// use std::time::SystemTime;\n    ///\n    /// let sys_time = SystemTime::now();\n    /// ```\n    #[stable(feature = \"time2\", since = \"1.8.0\")]\n    pub fn now() -> SystemTime {\n        SystemTime(time::SystemTime::now())\n    }\n\n    /// Returns the amount of time elapsed from an earlier point in time.\n    ///\n    /// This function may fail because measurements taken earlier are not\n    /// guaranteed to always be before later measurements (due to anomalies such\n    /// as the system clock being adjusted either forwards or backwards).\n    /// [`Instant`] can be used to measure elapsed time without this risk of failure.\n    ///\n    /// If successful, [`Ok`]`(`[`Duration`]`)` is returned where the duration represents\n    /// the amount of time elapsed from the specified measurement to this one.\n    ///\n    /// Returns an [`Err`] if `earlier` is later than `self`, and the error\n    /// contains how far from `self` the time is.\n    ///\n    /// # Examples\n    ///\n    /// ```no_run\n    /// use std::time::SystemTime;\n    ///\n    /// let sys_time = SystemTime::now();\n    /// let new_sys_time = SystemTime::now();\n    /// let difference = new_sys_time.duration_since(sys_time)\n    ///     .expect(\"Clock may have gone backwards\");\n    /// println!(\"{:?}\", difference);\n    /// ```\n    #[stable(feature = \"time2\", since = \"1.8.0\")]\n    pub fn duration_since(&self, earlier: SystemTime) -> Result<Duration, SystemTimeError> {\n        self.0.sub_time(&earlier.0).map_err(SystemTimeError)\n    }\n\n    /// Returns the difference between the clock time when this\n    /// system time was created, and the current clock time.\n    ///\n    /// This function may fail as the underlying system clock is susceptible to\n    /// drift and updates (e.g., the system clock could go backwards), so this\n    /// function may not always succeed. If successful, [`Ok`]`(`[`Duration`]`)` is\n    /// returned where the duration represents the amount of time elapsed from\n    /// this time measurement to the current time.\n    ///\n    /// To measure elapsed time reliably, use [`Instant`] instead.\n    ///\n    /// Returns an [`Err`] if `self` is later than the current system time, and\n    /// the error contains how far from the current system time `self` is.\n    ///\n    /// # Examples\n    ///\n    /// ```no_run\n    /// use std::thread::sleep;\n    /// use std::time::{Duration, SystemTime};\n    ///\n    /// let sys_time = SystemTime::now();\n    /// let one_sec = Duration::from_secs(1);\n    /// sleep(one_sec);\n    /// assert!(sys_time.elapsed().unwrap() >= one_sec);\n    /// ```\n    #[stable(feature = \"time2\", since = \"1.8.0\")]\n    pub fn elapsed(&self) -> Result<Duration, SystemTimeError> {\n        SystemTime::now().duration_since(*self)\n    }\n\n    /// Returns `Some(t)` where `t` is the time `self + duration` if `t` can be represented as\n    /// `SystemTime` (which means it's inside the bounds of the underlying data structure), `None`\n    /// otherwise.\n    #[stable(feature = \"time_checked_add\", since = \"1.34.0\")]\n    pub fn checked_add(&self, duration: Duration) -> Option<SystemTime> {\n        self.0.checked_add_duration(&duration).map(SystemTime)\n    }\n\n    /// Returns `Some(t)` where `t` is the time `self - duration` if `t` can be represented as\n    /// `SystemTime` (which means it's inside the bounds of the underlying data structure), `None`\n    /// otherwise.\n    #[stable(feature = \"time_checked_add\", since = \"1.34.0\")]\n    pub fn checked_sub(&self, duration: Duration) -> Option<SystemTime> {\n        self.0.checked_sub_duration(&duration).map(SystemTime)\n    }\n}\n\n#[stable(feature = \"time2\", since = \"1.8.0\")]\nimpl Add<Duration> for SystemTime {\n    type Output = SystemTime;\n\n    /// # Panics\n    ///\n    /// This function may panic if the resulting point in time cannot be represented by the\n    /// underlying data structure. See [`SystemTime::checked_add`] for a version without panic.\n    fn add(self, dur: Duration) -> SystemTime {\n        self.checked_add(dur).expect(\"overflow when adding duration to instant\")\n    }\n}\n\n#[stable(feature = \"time_augmented_assignment\", since = \"1.9.0\")]\nimpl AddAssign<Duration> for SystemTime {\n    fn add_assign(&mut self, other: Duration) {\n        *self = *self + other;\n    }\n}\n\n#[stable(feature = \"time2\", since = \"1.8.0\")]\nimpl Sub<Duration> for SystemTime {\n    type Output = SystemTime;\n\n    fn sub(self, dur: Duration) -> SystemTime {\n        self.checked_sub(dur).expect(\"overflow when subtracting duration from instant\")\n    }\n}\n\n#[stable(feature = \"time_augmented_assignment\", since = \"1.9.0\")]\nimpl SubAssign<Duration> for SystemTime {\n    fn sub_assign(&mut self, other: Duration) {\n        *self = *self - other;\n    }\n}\n\n#[stable(feature = \"time2\", since = \"1.8.0\")]\nimpl fmt::Debug for SystemTime {\n    fn fmt(&self, f: &mut fmt::Formatter<'_>) -> fmt::Result {\n        self.0.fmt(f)\n    }\n}\n\n/// An anchor in time which can be used to create new `SystemTime` instances or\n/// learn about where in time a `SystemTime` lies.\n///\n/// This constant is defined to be \"1970-01-01 00:00:00 UTC\" on all systems with\n/// respect to the system clock. Using `duration_since` on an existing\n/// [`SystemTime`] instance can tell how far away from this point in time a\n/// measurement lies, and using `UNIX_EPOCH + duration` can be used to create a\n/// [`SystemTime`] instance to represent another fixed point in time.\n///\n/// # Examples\n///\n/// ```no_run\n/// use std::time::{SystemTime, UNIX_EPOCH};\n///\n/// match SystemTime::now().duration_since(UNIX_EPOCH) {\n///     Ok(n) => println!(\"1970-01-01 00:00:00 UTC was {} seconds ago!\", n.as_secs()),\n///     Err(_) => panic!(\"SystemTime before UNIX EPOCH!\"),\n/// }\n/// ```\n#[stable(feature = \"time2\", since = \"1.8.0\")]\npub const UNIX_EPOCH: SystemTime = SystemTime(time::UNIX_EPOCH);\n\nimpl SystemTimeError {\n    /// Returns the positive duration which represents how far forward the\n    /// second system time was from the first.\n    ///\n    /// A `SystemTimeError` is returned from the [`SystemTime::duration_since`]\n    /// and [`SystemTime::elapsed`] methods whenever the second system time\n    /// represents a point later in time than the `self` of the method call.\n    ///\n    /// # Examples\n    ///\n    /// ```no_run\n    /// use std::thread::sleep;\n    /// use std::time::{Duration, SystemTime};\n    ///\n    /// let sys_time = SystemTime::now();\n    /// sleep(Duration::from_secs(1));\n    /// let new_sys_time = SystemTime::now();\n    /// match sys_time.duration_since(new_sys_time) {\n    ///     Ok(_) => {}\n    ///     Err(e) => println!(\"SystemTimeError difference: {:?}\", e.duration()),\n    /// }\n    /// ```\n    #[stable(feature = \"time2\", since = \"1.8.0\")]\n    pub fn duration(&self) -> Duration {\n        self.0\n    }\n}\n\n#[stable(feature = \"time2\", since = \"1.8.0\")]\nimpl Error for SystemTimeError {\n    #[allow(deprecated)]\n    fn description(&self) -> &str {\n        \"other time was not earlier than self\"\n    }\n}\n\n#[stable(feature = \"time2\", since = \"1.8.0\")]\nimpl fmt::Display for SystemTimeError {\n    fn fmt(&self, f: &mut fmt::Formatter<'_>) -> fmt::Result {\n        write!(f, \"second time provided was later than self\")\n    }\n}\n\nimpl FromInner<time::SystemTime> for SystemTime {\n    fn from_inner(time: time::SystemTime) -> SystemTime {\n        SystemTime(time)\n    }\n}\n"],[2126,"//! Inspection and manipulation of the process's environment.\n//!\n//! This module contains functions to inspect various aspects such as\n//! environment variables, process arguments, the current directory, and various\n//! other important directories.\n//!\n//! There are several functions and structs in this module that have a\n//! counterpart ending in `os`. Those ending in `os` will return an [`OsString`]\n//! and those without will return a [`String`].\n\n#![stable(feature = \"env\", since = \"1.0.0\")]\n\n#[cfg(test)]\nmod tests;\n\nuse crate::error::Error;\nuse crate::ffi::{OsStr, OsString};\nuse crate::fmt;\nuse crate::io;\nuse crate::path::{Path, PathBuf};\nuse crate::sys;\nuse crate::sys::os as os_imp;\n\n/// Returns the current working directory as a [`PathBuf`].\n///\n/// # Errors\n///\n/// Returns an [`Err`] if the current working directory value is invalid.\n/// Possible cases:\n///\n/// * Current directory does not exist.\n/// * There are insufficient permissions to access the current directory.\n///\n/// # Examples\n///\n/// ```\n/// use std::env;\n///\n/// fn main() -> std::io::Result<()> {\n///     let path = env::current_dir()?;\n///     println!(\"The current directory is {}\", path.display());\n///     Ok(())\n/// }\n/// ```\n#[stable(feature = \"env\", since = \"1.0.0\")]\npub fn current_dir() -> io::Result<PathBuf> {\n    os_imp::getcwd()\n}\n\n/// Changes the current working directory to the specified path.\n///\n/// Returns an [`Err`] if the operation fails.\n///\n/// # Examples\n///\n/// ```\n/// use std::env;\n/// use std::path::Path;\n///\n/// let root = Path::new(\"/\");\n/// assert!(env::set_current_dir(&root).is_ok());\n/// println!(\"Successfully changed working directory to {}!\", root.display());\n/// ```\n#[doc(alias = \"chdir\")]\n#[stable(feature = \"env\", since = \"1.0.0\")]\npub fn set_current_dir<P: AsRef<Path>>(path: P) -> io::Result<()> {\n    os_imp::chdir(path.as_ref())\n}\n\n/// An iterator over a snapshot of the environment variables of this process.\n///\n/// This structure is created by [`env::vars()`]. See its documentation for more.\n///\n/// [`env::vars()`]: vars\n#[stable(feature = \"env\", since = \"1.0.0\")]\npub struct Vars {\n    inner: VarsOs,\n}\n\n/// An iterator over a snapshot of the environment variables of this process.\n///\n/// This structure is created by [`env::vars_os()`]. See its documentation for more.\n///\n/// [`env::vars_os()`]: vars_os\n#[stable(feature = \"env\", since = \"1.0.0\")]\npub struct VarsOs {\n    inner: os_imp::Env,\n}\n\n/// Returns an iterator of (variable, value) pairs of strings, for all the\n/// environment variables of the current process.\n///\n/// The returned iterator contains a snapshot of the process's environment\n/// variables at the time of this invocation. Modifications to environment\n/// variables afterwards will not be reflected in the returned iterator.\n///\n/// # Panics\n///\n/// While iterating, the returned iterator will panic if any key or value in the\n/// environment is not valid unicode. If this is not desired, consider using\n/// [`env::vars_os()`].\n///\n/// # Examples\n///\n/// ```\n/// use std::env;\n///\n/// // We will iterate through the references to the element returned by\n/// // env::vars();\n/// for (key, value) in env::vars() {\n///     println!(\"{}: {}\", key, value);\n/// }\n/// ```\n///\n/// [`env::vars_os()`]: vars_os\n#[stable(feature = \"env\", since = \"1.0.0\")]\npub fn vars() -> Vars {\n    Vars { inner: vars_os() }\n}\n\n/// Returns an iterator of (variable, value) pairs of OS strings, for all the\n/// environment variables of the current process.\n///\n/// The returned iterator contains a snapshot of the process's environment\n/// variables at the time of this invocation. Modifications to environment\n/// variables afterwards will not be reflected in the returned iterator.\n///\n/// Note that the returned iterator will not check if the environment variables\n/// are valid Unicode. If you want to panic on invalid UTF-8,\n/// use the [`vars`] function instead.\n///\n/// # Examples\n///\n/// ```\n/// use std::env;\n///\n/// // We will iterate through the references to the element returned by\n/// // env::vars_os();\n/// for (key, value) in env::vars_os() {\n///     println!(\"{:?}: {:?}\", key, value);\n/// }\n/// ```\n#[stable(feature = \"env\", since = \"1.0.0\")]\npub fn vars_os() -> VarsOs {\n    VarsOs { inner: os_imp::env() }\n}\n\n#[stable(feature = \"env\", since = \"1.0.0\")]\nimpl Iterator for Vars {\n    type Item = (String, String);\n    fn next(&mut self) -> Option<(String, String)> {\n        self.inner.next().map(|(a, b)| (a.into_string().unwrap(), b.into_string().unwrap()))\n    }\n    fn size_hint(&self) -> (usize, Option<usize>) {\n        self.inner.size_hint()\n    }\n}\n\n#[stable(feature = \"std_debug\", since = \"1.16.0\")]\nimpl fmt::Debug for Vars {\n    fn fmt(&self, f: &mut fmt::Formatter<'_>) -> fmt::Result {\n        f.debug_struct(\"Vars\").finish_non_exhaustive()\n    }\n}\n\n#[stable(feature = \"env\", since = \"1.0.0\")]\nimpl Iterator for VarsOs {\n    type Item = (OsString, OsString);\n    fn next(&mut self) -> Option<(OsString, OsString)> {\n        self.inner.next()\n    }\n    fn size_hint(&self) -> (usize, Option<usize>) {\n        self.inner.size_hint()\n    }\n}\n\n#[stable(feature = \"std_debug\", since = \"1.16.0\")]\nimpl fmt::Debug for VarsOs {\n    fn fmt(&self, f: &mut fmt::Formatter<'_>) -> fmt::Result {\n        f.debug_struct(\"VarOs\").finish_non_exhaustive()\n    }\n}\n\n/// Fetches the environment variable `key` from the current process.\n///\n/// # Errors\n///\n/// Errors if the environment variable is not present.\n/// Errors if the environment variable is not valid Unicode. If this is not desired, consider using\n/// [`var_os`].\n///\n/// # Panics\n///\n/// This function may panic if `key` is empty, contains an ASCII equals sign\n/// `'='` or the NUL character `'\\0'`, or when the value contains the NUL\n/// character.\n///\n/// # Examples\n///\n/// ```\n/// use std::env;\n///\n/// let key = \"HOME\";\n/// match env::var(key) {\n///     Ok(val) => println!(\"{}: {:?}\", key, val),\n///     Err(e) => println!(\"couldn't interpret {}: {}\", key, e),\n/// }\n/// ```\n#[stable(feature = \"env\", since = \"1.0.0\")]\npub fn var<K: AsRef<OsStr>>(key: K) -> Result<String, VarError> {\n    _var(key.as_ref())\n}\n\nfn _var(key: &OsStr) -> Result<String, VarError> {\n    match var_os(key) {\n        Some(s) => s.into_string().map_err(VarError::NotUnicode),\n        None => Err(VarError::NotPresent),\n    }\n}\n\n/// Fetches the environment variable `key` from the current process, returning\n/// [`None`] if the variable isn't set.\n///\n/// # Panics\n///\n/// This function may panic if `key` is empty, contains an ASCII equals sign\n/// `'='` or the NUL character `'\\0'`, or when the value contains the NUL\n/// character.\n///\n/// Note that the method will not check if the environment variable\n/// is valid Unicode. If you want to have an error on invalid UTF-8,\n/// use the [`var`] function instead.\n///\n/// # Examples\n///\n/// ```\n/// use std::env;\n///\n/// let key = \"HOME\";\n/// match env::var_os(key) {\n///     Some(val) => println!(\"{}: {:?}\", key, val),\n///     None => println!(\"{} is not defined in the environment.\", key)\n/// }\n/// ```\n#[stable(feature = \"env\", since = \"1.0.0\")]\npub fn var_os<K: AsRef<OsStr>>(key: K) -> Option<OsString> {\n    _var_os(key.as_ref())\n}\n\nfn _var_os(key: &OsStr) -> Option<OsString> {\n    os_imp::getenv(key)\n        .unwrap_or_else(|e| panic!(\"failed to get environment variable `{:?}`: {}\", key, e))\n}\n\n/// The error type for operations interacting with environment variables.\n/// Possibly returned from [`env::var()`].\n///\n/// [`env::var()`]: var\n#[derive(Debug, PartialEq, Eq, Clone)]\n#[stable(feature = \"env\", since = \"1.0.0\")]\npub enum VarError {\n    /// The specified environment variable was not present in the current\n    /// process's environment.\n    #[stable(feature = \"env\", since = \"1.0.0\")]\n    NotPresent,\n\n    /// The specified environment variable was found, but it did not contain\n    /// valid unicode data. The found data is returned as a payload of this\n    /// variant.\n    #[stable(feature = \"env\", since = \"1.0.0\")]\n    NotUnicode(#[stable(feature = \"env\", since = \"1.0.0\")] OsString),\n}\n\n#[stable(feature = \"env\", since = \"1.0.0\")]\nimpl fmt::Display for VarError {\n    fn fmt(&self, f: &mut fmt::Formatter<'_>) -> fmt::Result {\n        match *self {\n            VarError::NotPresent => write!(f, \"environment variable not found\"),\n            VarError::NotUnicode(ref s) => {\n                write!(f, \"environment variable was not valid unicode: {:?}\", s)\n            }\n        }\n    }\n}\n\n#[stable(feature = \"env\", since = \"1.0.0\")]\nimpl Error for VarError {\n    #[allow(deprecated)]\n    fn description(&self) -> &str {\n        match *self {\n            VarError::NotPresent => \"environment variable not found\",\n            VarError::NotUnicode(..) => \"environment variable was not valid unicode\",\n        }\n    }\n}\n\n/// Sets the environment variable `k` to the value `v` for the currently running\n/// process.\n///\n/// Note that while concurrent access to environment variables is safe in Rust,\n/// some platforms only expose inherently unsafe non-threadsafe APIs for\n/// inspecting the environment. As a result, extra care needs to be taken when\n/// auditing calls to unsafe external FFI functions to ensure that any external\n/// environment accesses are properly synchronized with accesses in Rust.\n///\n/// Discussion of this unsafety on Unix may be found in:\n///\n///  - [Austin Group Bugzilla](https://austingroupbugs.net/view.php?id=188)\n///  - [GNU C library Bugzilla](https://sourceware.org/bugzilla/show_bug.cgi?id=15607#c2)\n///\n/// # Panics\n///\n/// This function may panic if `key` is empty, contains an ASCII equals sign\n/// `'='` or the NUL character `'\\0'`, or when the value contains the NUL\n/// character.\n///\n/// # Examples\n///\n/// ```\n/// use std::env;\n///\n/// let key = \"KEY\";\n/// env::set_var(key, \"VALUE\");\n/// assert_eq!(env::var(key), Ok(\"VALUE\".to_string()));\n/// ```\n#[stable(feature = \"env\", since = \"1.0.0\")]\npub fn set_var<K: AsRef<OsStr>, V: AsRef<OsStr>>(key: K, value: V) {\n    _set_var(key.as_ref(), value.as_ref())\n}\n\nfn _set_var(key: &OsStr, value: &OsStr) {\n    os_imp::setenv(key, value).unwrap_or_else(|e| {\n        panic!(\"failed to set environment variable `{:?}` to `{:?}`: {}\", key, value, e)\n    })\n}\n\n/// Removes an environment variable from the environment of the currently running process.\n///\n/// Note that while concurrent access to environment variables is safe in Rust,\n/// some platforms only expose inherently unsafe non-threadsafe APIs for\n/// inspecting the environment. As a result extra care needs to be taken when\n/// auditing calls to unsafe external FFI functions to ensure that any external\n/// environment accesses are properly synchronized with accesses in Rust.\n///\n/// Discussion of this unsafety on Unix may be found in:\n///\n///  - [Austin Group Bugzilla](https://austingroupbugs.net/view.php?id=188)\n///  - [GNU C library Bugzilla](https://sourceware.org/bugzilla/show_bug.cgi?id=15607#c2)\n///\n/// # Panics\n///\n/// This function may panic if `key` is empty, contains an ASCII equals sign\n/// `'='` or the NUL character `'\\0'`, or when the value contains the NUL\n/// character.\n///\n/// # Examples\n///\n/// ```\n/// use std::env;\n///\n/// let key = \"KEY\";\n/// env::set_var(key, \"VALUE\");\n/// assert_eq!(env::var(key), Ok(\"VALUE\".to_string()));\n///\n/// env::remove_var(key);\n/// assert!(env::var(key).is_err());\n/// ```\n#[stable(feature = \"env\", since = \"1.0.0\")]\npub fn remove_var<K: AsRef<OsStr>>(key: K) {\n    _remove_var(key.as_ref())\n}\n\nfn _remove_var(key: &OsStr) {\n    os_imp::unsetenv(key)\n        .unwrap_or_else(|e| panic!(\"failed to remove environment variable `{:?}`: {}\", key, e))\n}\n\n/// An iterator that splits an environment variable into paths according to\n/// platform-specific conventions.\n///\n/// The iterator element type is [`PathBuf`].\n///\n/// This structure is created by [`env::split_paths()`]. See its\n/// documentation for more.\n///\n/// [`env::split_paths()`]: split_paths\n#[stable(feature = \"env\", since = \"1.0.0\")]\npub struct SplitPaths<'a> {\n    inner: os_imp::SplitPaths<'a>,\n}\n\n/// Parses input according to platform conventions for the `PATH`\n/// environment variable.\n///\n/// Returns an iterator over the paths contained in `unparsed`. The iterator\n/// element type is [`PathBuf`].\n///\n/// # Examples\n///\n/// ```\n/// use std::env;\n///\n/// let key = \"PATH\";\n/// match env::var_os(key) {\n///     Some(paths) => {\n///         for path in env::split_paths(&paths) {\n///             println!(\"'{}'\", path.display());\n///         }\n///     }\n///     None => println!(\"{} is not defined in the environment.\", key)\n/// }\n/// ```\n#[stable(feature = \"env\", since = \"1.0.0\")]\npub fn split_paths<T: AsRef<OsStr> + ?Sized>(unparsed: &T) -> SplitPaths<'_> {\n    SplitPaths { inner: os_imp::split_paths(unparsed.as_ref()) }\n}\n\n#[stable(feature = \"env\", since = \"1.0.0\")]\nimpl<'a> Iterator for SplitPaths<'a> {\n    type Item = PathBuf;\n    fn next(&mut self) -> Option<PathBuf> {\n        self.inner.next()\n    }\n    fn size_hint(&self) -> (usize, Option<usize>) {\n        self.inner.size_hint()\n    }\n}\n\n#[stable(feature = \"std_debug\", since = \"1.16.0\")]\nimpl fmt::Debug for SplitPaths<'_> {\n    fn fmt(&self, f: &mut fmt::Formatter<'_>) -> fmt::Result {\n        f.debug_struct(\"SplitPaths\").finish_non_exhaustive()\n    }\n}\n\n/// The error type for operations on the `PATH` variable. Possibly returned from\n/// [`env::join_paths()`].\n///\n/// [`env::join_paths()`]: join_paths\n#[derive(Debug)]\n#[stable(feature = \"env\", since = \"1.0.0\")]\npub struct JoinPathsError {\n    inner: os_imp::JoinPathsError,\n}\n\n/// Joins a collection of [`Path`]s appropriately for the `PATH`\n/// environment variable.\n///\n/// # Errors\n///\n/// Returns an [`Err`] (containing an error message) if one of the input\n/// [`Path`]s contains an invalid character for constructing the `PATH`\n/// variable (a double quote on Windows or a colon on Unix).\n///\n/// # Examples\n///\n/// Joining paths on a Unix-like platform:\n///\n/// ```\n/// use std::env;\n/// use std::ffi::OsString;\n/// use std::path::Path;\n///\n/// fn main() -> Result<(), env::JoinPathsError> {\n/// # if cfg!(unix) {\n///     let paths = [Path::new(\"/bin\"), Path::new(\"/usr/bin\")];\n///     let path_os_string = env::join_paths(paths.iter())?;\n///     assert_eq!(path_os_string, OsString::from(\"/bin:/usr/bin\"));\n/// # }\n///     Ok(())\n/// }\n/// ```\n///\n/// Joining a path containing a colon on a Unix-like platform results in an\n/// error:\n///\n/// ```\n/// # if cfg!(unix) {\n/// use std::env;\n/// use std::path::Path;\n///\n/// let paths = [Path::new(\"/bin\"), Path::new(\"/usr/bi:n\")];\n/// assert!(env::join_paths(paths.iter()).is_err());\n/// # }\n/// ```\n///\n/// Using `env::join_paths()` with [`env::split_paths()`] to append an item to\n/// the `PATH` environment variable:\n///\n/// ```\n/// use std::env;\n/// use std::path::PathBuf;\n///\n/// fn main() -> Result<(), env::JoinPathsError> {\n///     if let Some(path) = env::var_os(\"PATH\") {\n///         let mut paths = env::split_paths(&path).collect::<Vec<_>>();\n///         paths.push(PathBuf::from(\"/home/xyz/bin\"));\n///         let new_path = env::join_paths(paths)?;\n///         env::set_var(\"PATH\", &new_path);\n///     }\n///\n///     Ok(())\n/// }\n/// ```\n///\n/// [`env::split_paths()`]: split_paths\n#[stable(feature = \"env\", since = \"1.0.0\")]\npub fn join_paths<I, T>(paths: I) -> Result<OsString, JoinPathsError>\nwhere\n    I: IntoIterator<Item = T>,\n    T: AsRef<OsStr>,\n{\n    os_imp::join_paths(paths.into_iter()).map_err(|e| JoinPathsError { inner: e })\n}\n\n#[stable(feature = \"env\", since = \"1.0.0\")]\nimpl fmt::Display for JoinPathsError {\n    fn fmt(&self, f: &mut fmt::Formatter<'_>) -> fmt::Result {\n        self.inner.fmt(f)\n    }\n}\n\n#[stable(feature = \"env\", since = \"1.0.0\")]\nimpl Error for JoinPathsError {\n    #[allow(deprecated, deprecated_in_future)]\n    fn description(&self) -> &str {\n        self.inner.description()\n    }\n}\n\n/// Returns the path of the current user's home directory if known.\n///\n/// # Unix\n///\n/// - Returns the value of the 'HOME' environment variable if it is set\n///   (including to an empty string).\n/// - Otherwise, it tries to determine the home directory by invoking the `getpwuid_r` function\n///   using the UID of the current user. An empty home directory field returned from the\n///   `getpwuid_r` function is considered to be a valid value.\n/// - Returns `None` if the current user has no entry in the /etc/passwd file.\n///\n/// # Windows\n///\n/// - Returns the value of the 'HOME' environment variable if it is set\n///   (including to an empty string).\n/// - Otherwise, returns the value of the 'USERPROFILE' environment variable if it is set\n///   (including to an empty string).\n/// - If both do not exist, [`GetUserProfileDirectory`][msdn] is used to return the path.\n///\n/// [msdn]: https://docs.microsoft.com/en-us/windows/win32/api/userenv/nf-userenv-getuserprofiledirectorya\n///\n/// # Examples\n///\n/// ```\n/// use std::env;\n///\n/// match env::home_dir() {\n///     Some(path) => println!(\"Your home directory, probably: {}\", path.display()),\n///     None => println!(\"Impossible to get your home dir!\"),\n/// }\n/// ```\n#[rustc_deprecated(\n    since = \"1.29.0\",\n    reason = \"This function's behavior is unexpected and probably not what you want. \\\n              Consider using a crate from crates.io instead.\"\n)]\n#[stable(feature = \"env\", since = \"1.0.0\")]\npub fn home_dir() -> Option<PathBuf> {\n    os_imp::home_dir()\n}\n\n/// Returns the path of a temporary directory.\n///\n/// The temporary directory may be shared among users, or between processes\n/// with different privileges; thus, the creation of any files or directories\n/// in the temporary directory must use a secure method to create a uniquely\n/// named file. Creating a file or directory with a fixed or predictable name\n/// may result in \"insecure temporary file\" security vulnerabilities. Consider\n/// using a crate that securely creates temporary files or directories.\n///\n/// # Unix\n///\n/// Returns the value of the `TMPDIR` environment variable if it is\n/// set, otherwise for non-Android it returns `/tmp`. If Android, since there\n/// is no global temporary folder (it is usually allocated per-app), it returns\n/// `/data/local/tmp`.\n///\n/// # Windows\n///\n/// Returns the value of, in order, the `TMP`, `TEMP`,\n/// `USERPROFILE` environment variable if any are set and not the empty\n/// string. Otherwise, `temp_dir` returns the path of the Windows directory.\n/// This behavior is identical to that of [`GetTempPath`][msdn], which this\n/// function uses internally.\n///\n/// [msdn]: https://docs.microsoft.com/en-us/windows/win32/api/fileapi/nf-fileapi-gettemppatha\n///\n/// ```no_run\n/// use std::env;\n///\n/// fn main() {\n///     let mut dir = env::temp_dir();\n///     println!(\"Temporary directory: {}\", dir.display());\n/// }\n/// ```\n#[stable(feature = \"env\", since = \"1.0.0\")]\npub fn temp_dir() -> PathBuf {\n    os_imp::temp_dir()\n}\n\n/// Returns the full filesystem path of the current running executable.\n///\n/// # Platform-specific behavior\n///\n/// If the executable was invoked through a symbolic link, some platforms will\n/// return the path of the symbolic link and other platforms will return the\n/// path of the symbolic link’s target.\n///\n/// # Errors\n///\n/// Acquiring the path of the current executable is a platform-specific operation\n/// that can fail for a good number of reasons. Some errors can include, but not\n/// be limited to, filesystem operations failing or general syscall failures.\n///\n/// # Security\n///\n/// The output of this function should not be used in anything that might have\n/// security implications. For example:\n///\n/// ```\n/// fn main() {\n///     println!(\"{:?}\", std::env::current_exe());\n/// }\n/// ```\n///\n/// On Linux systems, if this is compiled as `foo`:\n///\n/// ```bash\n/// $ rustc foo.rs\n/// $ ./foo\n/// Ok(\"/home/alex/foo\")\n/// ```\n///\n/// And you make a hard link of the program:\n///\n/// ```bash\n/// $ ln foo bar\n/// ```\n///\n/// When you run it, you won’t get the path of the original executable, you’ll\n/// get the path of the hard link:\n///\n/// ```bash\n/// $ ./bar\n/// Ok(\"/home/alex/bar\")\n/// ```\n///\n/// This sort of behavior has been known to [lead to privilege escalation] when\n/// used incorrectly.\n///\n/// [lead to privilege escalation]: https://securityvulns.com/Wdocument183.html\n///\n/// # Examples\n///\n/// ```\n/// use std::env;\n///\n/// match env::current_exe() {\n///     Ok(exe_path) => println!(\"Path of this executable is: {}\",\n///                              exe_path.display()),\n///     Err(e) => println!(\"failed to get current exe path: {}\", e),\n/// };\n/// ```\n#[stable(feature = \"env\", since = \"1.0.0\")]\npub fn current_exe() -> io::Result<PathBuf> {\n    os_imp::current_exe()\n}\n\n/// An iterator over the arguments of a process, yielding a [`String`] value for\n/// each argument.\n///\n/// This struct is created by [`env::args()`]. See its documentation\n/// for more.\n///\n/// The first element is traditionally the path of the executable, but it can be\n/// set to arbitrary text, and may not even exist. This means this property\n/// should not be relied upon for security purposes.\n///\n/// [`env::args()`]: args\n#[stable(feature = \"env\", since = \"1.0.0\")]\npub struct Args {\n    inner: ArgsOs,\n}\n\n/// An iterator over the arguments of a process, yielding an [`OsString`] value\n/// for each argument.\n///\n/// This struct is created by [`env::args_os()`]. See its documentation\n/// for more.\n///\n/// The first element is traditionally the path of the executable, but it can be\n/// set to arbitrary text, and may not even exist. This means this property\n/// should not be relied upon for security purposes.\n///\n/// [`env::args_os()`]: args_os\n#[stable(feature = \"env\", since = \"1.0.0\")]\npub struct ArgsOs {\n    inner: sys::args::Args,\n}\n\n/// Returns the arguments that this program was started with (normally passed\n/// via the command line).\n///\n/// The first element is traditionally the path of the executable, but it can be\n/// set to arbitrary text, and may not even exist. This means this property should\n/// not be relied upon for security purposes.\n///\n/// On Unix systems the shell usually expands unquoted arguments with glob patterns\n/// (such as `*` and `?`). On Windows this is not done, and such arguments are\n/// passed as-is.\n///\n/// On glibc Linux systems, arguments are retrieved by placing a function in `.init_array`.\n/// glibc passes `argc`, `argv`, and `envp` to functions in `.init_array`, as a non-standard\n/// extension. This allows `std::env::args` to work even in a `cdylib` or `staticlib`, as it\n/// does on macOS and Windows.\n///\n/// # Panics\n///\n/// The returned iterator will panic during iteration if any argument to the\n/// process is not valid Unicode. If this is not desired,\n/// use the [`args_os`] function instead.\n///\n/// # Examples\n///\n/// ```\n/// use std::env;\n///\n/// // Prints each argument on a separate line\n/// for argument in env::args() {\n///     println!(\"{}\", argument);\n/// }\n/// ```\n#[stable(feature = \"env\", since = \"1.0.0\")]\npub fn args() -> Args {\n    Args { inner: args_os() }\n}\n\n/// Returns the arguments that this program was started with (normally passed\n/// via the command line).\n///\n/// The first element is traditionally the path of the executable, but it can be\n/// set to arbitrary text, and may not even exist. This means this property should\n/// not be relied upon for security purposes.\n///\n/// On Unix systems the shell usually expands unquoted arguments with glob patterns\n/// (such as `*` and `?`). On Windows this is not done, and such arguments are\n/// passed as-is.\n///\n/// On glibc Linux systems, arguments are retrieved by placing a function in `.init_array`.\n/// glibc passes `argc`, `argv`, and `envp` to functions in `.init_array`, as a non-standard\n/// extension. This allows `std::env::args_os` to work even in a `cdylib` or `staticlib`, as it\n/// does on macOS and Windows.\n///\n/// Note that the returned iterator will not check if the arguments to the\n/// process are valid Unicode. If you want to panic on invalid UTF-8,\n/// use the [`args`] function instead.\n///\n/// # Examples\n///\n/// ```\n/// use std::env;\n///\n/// // Prints each argument on a separate line\n/// for argument in env::args_os() {\n///     println!(\"{:?}\", argument);\n/// }\n/// ```\n#[stable(feature = \"env\", since = \"1.0.0\")]\npub fn args_os() -> ArgsOs {\n    ArgsOs { inner: sys::args::args() }\n}\n\n#[stable(feature = \"env_unimpl_send_sync\", since = \"1.26.0\")]\nimpl !Send for Args {}\n\n#[stable(feature = \"env_unimpl_send_sync\", since = \"1.26.0\")]\nimpl !Sync for Args {}\n\n#[stable(feature = \"env\", since = \"1.0.0\")]\nimpl Iterator for Args {\n    type Item = String;\n    fn next(&mut self) -> Option<String> {\n        self.inner.next().map(|s| s.into_string().unwrap())\n    }\n    fn size_hint(&self) -> (usize, Option<usize>) {\n        self.inner.size_hint()\n    }\n}\n\n#[stable(feature = \"env\", since = \"1.0.0\")]\nimpl ExactSizeIterator for Args {\n    fn len(&self) -> usize {\n        self.inner.len()\n    }\n    fn is_empty(&self) -> bool {\n        self.inner.is_empty()\n    }\n}\n\n#[stable(feature = \"env_iterators\", since = \"1.12.0\")]\nimpl DoubleEndedIterator for Args {\n    fn next_back(&mut self) -> Option<String> {\n        self.inner.next_back().map(|s| s.into_string().unwrap())\n    }\n}\n\n#[stable(feature = \"std_debug\", since = \"1.16.0\")]\nimpl fmt::Debug for Args {\n    fn fmt(&self, f: &mut fmt::Formatter<'_>) -> fmt::Result {\n        f.debug_struct(\"Args\").field(\"inner\", &self.inner.inner).finish()\n    }\n}\n\n#[stable(feature = \"env_unimpl_send_sync\", since = \"1.26.0\")]\nimpl !Send for ArgsOs {}\n\n#[stable(feature = \"env_unimpl_send_sync\", since = \"1.26.0\")]\nimpl !Sync for ArgsOs {}\n\n#[stable(feature = \"env\", since = \"1.0.0\")]\nimpl Iterator for ArgsOs {\n    type Item = OsString;\n    fn next(&mut self) -> Option<OsString> {\n        self.inner.next()\n    }\n    fn size_hint(&self) -> (usize, Option<usize>) {\n        self.inner.size_hint()\n    }\n}\n\n#[stable(feature = \"env\", since = \"1.0.0\")]\nimpl ExactSizeIterator for ArgsOs {\n    fn len(&self) -> usize {\n        self.inner.len()\n    }\n    fn is_empty(&self) -> bool {\n        self.inner.is_empty()\n    }\n}\n\n#[stable(feature = \"env_iterators\", since = \"1.12.0\")]\nimpl DoubleEndedIterator for ArgsOs {\n    fn next_back(&mut self) -> Option<OsString> {\n        self.inner.next_back()\n    }\n}\n\n#[stable(feature = \"std_debug\", since = \"1.16.0\")]\nimpl fmt::Debug for ArgsOs {\n    fn fmt(&self, f: &mut fmt::Formatter<'_>) -> fmt::Result {\n        f.debug_struct(\"ArgsOs\").field(\"inner\", &self.inner).finish()\n    }\n}\n\n/// Constants associated with the current target\n#[stable(feature = \"env\", since = \"1.0.0\")]\npub mod consts {\n    use crate::sys::env::os;\n\n    /// A string describing the architecture of the CPU that is currently\n    /// in use.\n    ///\n    /// Some possible values:\n    ///\n    /// - x86\n    /// - x86_64\n    /// - arm\n    /// - aarch64\n    /// - mips\n    /// - mips64\n    /// - powerpc\n    /// - powerpc64\n    /// - riscv64\n    /// - s390x\n    /// - sparc64\n    #[stable(feature = \"env\", since = \"1.0.0\")]\n    pub const ARCH: &str = env!(\"STD_ENV_ARCH\");\n\n    /// The family of the operating system. Example value is `unix`.\n    ///\n    /// Some possible values:\n    ///\n    /// - unix\n    /// - windows\n    #[stable(feature = \"env\", since = \"1.0.0\")]\n    pub const FAMILY: &str = os::FAMILY;\n\n    /// A string describing the specific operating system in use.\n    /// Example value is `linux`.\n    ///\n    /// Some possible values:\n    ///\n    /// - linux\n    /// - macos\n    /// - ios\n    /// - freebsd\n    /// - dragonfly\n    /// - netbsd\n    /// - openbsd\n    /// - solaris\n    /// - android\n    /// - windows\n    #[stable(feature = \"env\", since = \"1.0.0\")]\n    pub const OS: &str = os::OS;\n\n    /// Specifies the filename prefix used for shared libraries on this\n    /// platform. Example value is `lib`.\n    ///\n    /// Some possible values:\n    ///\n    /// - lib\n    /// - `\"\"` (an empty string)\n    #[stable(feature = \"env\", since = \"1.0.0\")]\n    pub const DLL_PREFIX: &str = os::DLL_PREFIX;\n\n    /// Specifies the filename suffix used for shared libraries on this\n    /// platform. Example value is `.so`.\n    ///\n    /// Some possible values:\n    ///\n    /// - .so\n    /// - .dylib\n    /// - .dll\n    #[stable(feature = \"env\", since = \"1.0.0\")]\n    pub const DLL_SUFFIX: &str = os::DLL_SUFFIX;\n\n    /// Specifies the file extension used for shared libraries on this\n    /// platform that goes after the dot. Example value is `so`.\n    ///\n    /// Some possible values:\n    ///\n    /// - so\n    /// - dylib\n    /// - dll\n    #[stable(feature = \"env\", since = \"1.0.0\")]\n    pub const DLL_EXTENSION: &str = os::DLL_EXTENSION;\n\n    /// Specifies the filename suffix used for executable binaries on this\n    /// platform. Example value is `.exe`.\n    ///\n    /// Some possible values:\n    ///\n    /// - .exe\n    /// - .nexe\n    /// - .pexe\n    /// - `\"\"` (an empty string)\n    #[stable(feature = \"env\", since = \"1.0.0\")]\n    pub const EXE_SUFFIX: &str = os::EXE_SUFFIX;\n\n    /// Specifies the file extension, if any, used for executable binaries\n    /// on this platform. Example value is `exe`.\n    ///\n    /// Some possible values:\n    ///\n    /// - exe\n    /// - `\"\"` (an empty string)\n    #[stable(feature = \"env\", since = \"1.0.0\")]\n    pub const EXE_EXTENSION: &str = os::EXE_EXTENSION;\n}\n"],[2127,"//! Standard library macros\n//!\n//! This module contains a set of macros which are exported from the standard\n//! library. Each macro is available for use when linking against the standard\n//! library.\n\n#[doc = include_str!(\"../../core/src/macros/panic.md\")]\n#[macro_export]\n#[rustc_builtin_macro = \"std_panic\"]\n#[stable(feature = \"rust1\", since = \"1.0.0\")]\n#[allow_internal_unstable(edition_panic)]\n#[cfg_attr(not(test), rustc_diagnostic_item = \"std_panic_macro\")]\nmacro_rules! panic {\n    // Expands to either `$crate::panic::panic_2015` or `$crate::panic::panic_2021`\n    // depending on the edition of the caller.\n    ($($arg:tt)*) => {\n        /* compiler built-in */\n    };\n}\n\n/// Prints to the standard output.\n///\n/// Equivalent to the [`println!`] macro except that a newline is not printed at\n/// the end of the message.\n///\n/// Note that stdout is frequently line-buffered by default so it may be\n/// necessary to use [`io::stdout().flush()`][flush] to ensure the output is emitted\n/// immediately.\n///\n/// Use `print!` only for the primary output of your program. Use\n/// [`eprint!`] instead to print error and progress messages.\n///\n/// [flush]: crate::io::Write::flush\n///\n/// # Panics\n///\n/// Panics if writing to `io::stdout()` fails.\n///\n/// # Examples\n///\n/// ```\n/// use std::io::{self, Write};\n///\n/// print!(\"this \");\n/// print!(\"will \");\n/// print!(\"be \");\n/// print!(\"on \");\n/// print!(\"the \");\n/// print!(\"same \");\n/// print!(\"line \");\n///\n/// io::stdout().flush().unwrap();\n///\n/// print!(\"this string has a newline, why not choose println! instead?\\n\");\n///\n/// io::stdout().flush().unwrap();\n/// ```\n#[macro_export]\n#[stable(feature = \"rust1\", since = \"1.0.0\")]\n#[allow_internal_unstable(print_internals)]\nmacro_rules! print {\n    ($($arg:tt)*) => ($crate::io::_print($crate::format_args!($($arg)*)));\n}\n\n/// Prints to the standard output, with a newline.\n///\n/// On all platforms, the newline is the LINE FEED character (`\\n`/`U+000A`) alone\n/// (no additional CARRIAGE RETURN (`\\r`/`U+000D`)).\n///\n/// Use the [`format!`] syntax to write data to the standard output.\n/// See [`std::fmt`] for more information.\n///\n/// Use `println!` only for the primary output of your program. Use\n/// [`eprintln!`] instead to print error and progress messages.\n///\n/// [`std::fmt`]: crate::fmt\n///\n/// # Panics\n///\n/// Panics if writing to [`io::stdout`] fails.\n///\n/// [`io::stdout`]: crate::io::stdout\n///\n/// # Examples\n///\n/// ```\n/// println!(); // prints just a newline\n/// println!(\"hello there!\");\n/// println!(\"format {} arguments\", \"some\");\n/// ```\n#[macro_export]\n#[stable(feature = \"rust1\", since = \"1.0.0\")]\n#[allow_internal_unstable(print_internals, format_args_nl)]\nmacro_rules! println {\n    () => ($crate::print!(\"\\n\"));\n    ($($arg:tt)*) => ({\n        $crate::io::_print($crate::format_args_nl!($($arg)*));\n    })\n}\n\n/// Prints to the standard error.\n///\n/// Equivalent to the [`print!`] macro, except that output goes to\n/// [`io::stderr`] instead of [`io::stdout`]. See [`print!`] for\n/// example usage.\n///\n/// Use `eprint!` only for error and progress messages. Use `print!`\n/// instead for the primary output of your program.\n///\n/// [`io::stderr`]: crate::io::stderr\n/// [`io::stdout`]: crate::io::stdout\n///\n/// # Panics\n///\n/// Panics if writing to `io::stderr` fails.\n///\n/// # Examples\n///\n/// ```\n/// eprint!(\"Error: Could not complete task\");\n/// ```\n#[macro_export]\n#[stable(feature = \"eprint\", since = \"1.19.0\")]\n#[allow_internal_unstable(print_internals)]\nmacro_rules! eprint {\n    ($($arg:tt)*) => ($crate::io::_eprint($crate::format_args!($($arg)*)));\n}\n\n/// Prints to the standard error, with a newline.\n///\n/// Equivalent to the [`println!`] macro, except that output goes to\n/// [`io::stderr`] instead of [`io::stdout`]. See [`println!`] for\n/// example usage.\n///\n/// Use `eprintln!` only for error and progress messages. Use `println!`\n/// instead for the primary output of your program.\n///\n/// [`io::stderr`]: crate::io::stderr\n/// [`io::stdout`]: crate::io::stdout\n///\n/// # Panics\n///\n/// Panics if writing to `io::stderr` fails.\n///\n/// # Examples\n///\n/// ```\n/// eprintln!(\"Error: Could not complete task\");\n/// ```\n#[macro_export]\n#[stable(feature = \"eprint\", since = \"1.19.0\")]\n#[allow_internal_unstable(print_internals, format_args_nl)]\nmacro_rules! eprintln {\n    () => ($crate::eprint!(\"\\n\"));\n    ($($arg:tt)*) => ({\n        $crate::io::_eprint($crate::format_args_nl!($($arg)*));\n    })\n}\n\n/// Prints and returns the value of a given expression for quick and dirty\n/// debugging.\n///\n/// An example:\n///\n/// ```rust\n/// let a = 2;\n/// let b = dbg!(a * 2) + 1;\n/// //      ^-- prints: [src/main.rs:2] a * 2 = 4\n/// assert_eq!(b, 5);\n/// ```\n///\n/// The macro works by using the `Debug` implementation of the type of\n/// the given expression to print the value to [stderr] along with the\n/// source location of the macro invocation as well as the source code\n/// of the expression.\n///\n/// Invoking the macro on an expression moves and takes ownership of it\n/// before returning the evaluated expression unchanged. If the type\n/// of the expression does not implement `Copy` and you don't want\n/// to give up ownership, you can instead borrow with `dbg!(&expr)`\n/// for some expression `expr`.\n///\n/// The `dbg!` macro works exactly the same in release builds.\n/// This is useful when debugging issues that only occur in release\n/// builds or when debugging in release mode is significantly faster.\n///\n/// Note that the macro is intended as a debugging tool and therefore you\n/// should avoid having uses of it in version control for long periods\n/// (other than in tests and similar).\n/// Debug output from production code is better done with other facilities\n/// such as the [`debug!`] macro from the [`log`] crate.\n///\n/// # Stability\n///\n/// The exact output printed by this macro should not be relied upon\n/// and is subject to future changes.\n///\n/// # Panics\n///\n/// Panics if writing to `io::stderr` fails.\n///\n/// # Further examples\n///\n/// With a method call:\n///\n/// ```rust\n/// fn foo(n: usize) {\n///     if let Some(_) = dbg!(n.checked_sub(4)) {\n///         // ...\n///     }\n/// }\n///\n/// foo(3)\n/// ```\n///\n/// This prints to [stderr]:\n///\n/// ```text,ignore\n/// [src/main.rs:4] n.checked_sub(4) = None\n/// ```\n///\n/// Naive factorial implementation:\n///\n/// ```rust\n/// fn factorial(n: u32) -> u32 {\n///     if dbg!(n <= 1) {\n///         dbg!(1)\n///     } else {\n///         dbg!(n * factorial(n - 1))\n///     }\n/// }\n///\n/// dbg!(factorial(4));\n/// ```\n///\n/// This prints to [stderr]:\n///\n/// ```text,ignore\n/// [src/main.rs:3] n <= 1 = false\n/// [src/main.rs:3] n <= 1 = false\n/// [src/main.rs:3] n <= 1 = false\n/// [src/main.rs:3] n <= 1 = true\n/// [src/main.rs:4] 1 = 1\n/// [src/main.rs:5] n * factorial(n - 1) = 2\n/// [src/main.rs:5] n * factorial(n - 1) = 6\n/// [src/main.rs:5] n * factorial(n - 1) = 24\n/// [src/main.rs:11] factorial(4) = 24\n/// ```\n///\n/// The `dbg!(..)` macro moves the input:\n///\n/// ```compile_fail\n/// /// A wrapper around `usize` which importantly is not Copyable.\n/// #[derive(Debug)]\n/// struct NoCopy(usize);\n///\n/// let a = NoCopy(42);\n/// let _ = dbg!(a); // <-- `a` is moved here.\n/// let _ = dbg!(a); // <-- `a` is moved again; error!\n/// ```\n///\n/// You can also use `dbg!()` without a value to just print the\n/// file and line whenever it's reached.\n///\n/// Finally, if you want to `dbg!(..)` multiple values, it will treat them as\n/// a tuple (and return it, too):\n///\n/// ```\n/// assert_eq!(dbg!(1usize, 2u32), (1, 2));\n/// ```\n///\n/// However, a single argument with a trailing comma will still not be treated\n/// as a tuple, following the convention of ignoring trailing commas in macro\n/// invocations. You can use a 1-tuple directly if you need one:\n///\n/// ```\n/// assert_eq!(1, dbg!(1u32,)); // trailing comma ignored\n/// assert_eq!((1,), dbg!((1u32,))); // 1-tuple\n/// ```\n///\n/// [stderr]: https://en.wikipedia.org/wiki/Standard_streams#Standard_error_(stderr)\n/// [`debug!`]: https://docs.rs/log/*/log/macro.debug.html\n/// [`log`]: https://crates.io/crates/log\n#[macro_export]\n#[stable(feature = \"dbg_macro\", since = \"1.32.0\")]\nmacro_rules! dbg {\n    // NOTE: We cannot use `concat!` to make a static string as a format argument\n    // of `eprintln!` because `file!` could contain a `{` or\n    // `$val` expression could be a block (`{ .. }`), in which case the `eprintln!`\n    // will be malformed.\n    () => {\n        $crate::eprintln!(\"[{}:{}]\", $crate::file!(), $crate::line!());\n    };\n    ($val:expr $(,)?) => {\n        // Use of `match` here is intentional because it affects the lifetimes\n        // of temporaries - https://stackoverflow.com/a/48732525/1063961\n        match $val {\n            tmp => {\n                $crate::eprintln!(\"[{}:{}] {} = {:#?}\",\n                    $crate::file!(), $crate::line!(), $crate::stringify!($val), &tmp);\n                tmp\n            }\n        }\n    };\n    ($($val:expr),+ $(,)?) => {\n        ($($crate::dbg!($val)),+,)\n    };\n}\n\n#[cfg(test)]\nmacro_rules! assert_approx_eq {\n    ($a:expr, $b:expr) => {{\n        let (a, b) = (&$a, &$b);\n        assert!((*a - *b).abs() < 1.0e-6, \"{} is not approximately equal to {}\", *a, *b);\n    }};\n}\n"],[2128,"#[doc(primitive = \"bool\")]\n#[doc(alias = \"true\")]\n#[doc(alias = \"false\")]\n/// The boolean type.\n///\n/// The `bool` represents a value, which could only be either `true` or `false`. If you cast\n/// a `bool` into an integer, `true` will be 1 and `false` will be 0.\n///\n/// # Basic usage\n///\n/// `bool` implements various traits, such as [`BitAnd`], [`BitOr`], [`Not`], etc.,\n/// which allow us to perform boolean operations using `&`, `|` and `!`.\n///\n/// `if` requires a `bool` value as its conditional. [`assert!`], which is an\n/// important macro in testing, checks whether an expression is `true` and panics\n/// if it isn't.\n///\n/// ```\n/// let bool_val = true & false | false;\n/// assert!(!bool_val);\n/// ```\n///\n/// [`BitAnd`]: ops::BitAnd\n/// [`BitOr`]: ops::BitOr\n/// [`Not`]: ops::Not\n///\n/// # Examples\n///\n/// A trivial example of the usage of `bool`:\n///\n/// ```\n/// let praise_the_borrow_checker = true;\n///\n/// // using the `if` conditional\n/// if praise_the_borrow_checker {\n///     println!(\"oh, yeah!\");\n/// } else {\n///     println!(\"what?!!\");\n/// }\n///\n/// // ... or, a match pattern\n/// match praise_the_borrow_checker {\n///     true => println!(\"keep praising!\"),\n///     false => println!(\"you should praise!\"),\n/// }\n/// ```\n///\n/// Also, since `bool` implements the [`Copy`] trait, we don't\n/// have to worry about the move semantics (just like the integer and float primitives).\n///\n/// Now an example of `bool` cast to integer type:\n///\n/// ```\n/// assert_eq!(true as i32, 1);\n/// assert_eq!(false as i32, 0);\n/// ```\n#[stable(feature = \"rust1\", since = \"1.0.0\")]\nmod prim_bool {}\n\n#[doc(primitive = \"never\")]\n#[doc(alias = \"!\")]\n//\n/// The `!` type, also called \"never\".\n///\n/// `!` represents the type of computations which never resolve to any value at all. For example,\n/// the [`exit`] function `fn exit(code: i32) -> !` exits the process without ever returning, and\n/// so returns `!`.\n///\n/// `break`, `continue` and `return` expressions also have type `!`. For example we are allowed to\n/// write:\n///\n/// ```\n/// #![feature(never_type)]\n/// # fn foo() -> u32 {\n/// let x: ! = {\n///     return 123\n/// };\n/// # }\n/// ```\n///\n/// Although the `let` is pointless here, it illustrates the meaning of `!`. Since `x` is never\n/// assigned a value (because `return` returns from the entire function), `x` can be given type\n/// `!`. We could also replace `return 123` with a `panic!` or a never-ending `loop` and this code\n/// would still be valid.\n///\n/// A more realistic usage of `!` is in this code:\n///\n/// ```\n/// # fn get_a_number() -> Option<u32> { None }\n/// # loop {\n/// let num: u32 = match get_a_number() {\n///     Some(num) => num,\n///     None => break,\n/// };\n/// # }\n/// ```\n///\n/// Both match arms must produce values of type [`u32`], but since `break` never produces a value\n/// at all we know it can never produce a value which isn't a [`u32`]. This illustrates another\n/// behaviour of the `!` type - expressions with type `!` will coerce into any other type.\n///\n/// [`u32`]: prim@u32\n/// [`exit`]: process::exit\n///\n/// # `!` and generics\n///\n/// ## Infallible errors\n///\n/// The main place you'll see `!` used explicitly is in generic code. Consider the [`FromStr`]\n/// trait:\n///\n/// ```\n/// trait FromStr: Sized {\n///     type Err;\n///     fn from_str(s: &str) -> Result<Self, Self::Err>;\n/// }\n/// ```\n///\n/// When implementing this trait for [`String`] we need to pick a type for [`Err`]. And since\n/// converting a string into a string will never result in an error, the appropriate type is `!`.\n/// (Currently the type actually used is an enum with no variants, though this is only because `!`\n/// was added to Rust at a later date and it may change in the future.) With an [`Err`] type of\n/// `!`, if we have to call [`String::from_str`] for some reason the result will be a\n/// [`Result<String, !>`] which we can unpack like this:\n///\n/// ```\n/// #![feature(exhaustive_patterns)]\n/// use std::str::FromStr;\n/// let Ok(s) = String::from_str(\"hello\");\n/// ```\n///\n/// Since the [`Err`] variant contains a `!`, it can never occur. If the `exhaustive_patterns`\n/// feature is present this means we can exhaustively match on [`Result<T, !>`] by just taking the\n/// [`Ok`] variant. This illustrates another behaviour of `!` - it can be used to \"delete\" certain\n/// enum variants from generic types like `Result`.\n///\n/// ## Infinite loops\n///\n/// While [`Result<T, !>`] is very useful for removing errors, `!` can also be used to remove\n/// successes as well. If we think of [`Result<T, !>`] as \"if this function returns, it has not\n/// errored,\" we get a very intuitive idea of [`Result<!, E>`] as well: if the function returns, it\n/// *has* errored.\n///\n/// For example, consider the case of a simple web server, which can be simplified to:\n///\n/// ```ignore (hypothetical-example)\n/// loop {\n///     let (client, request) = get_request().expect(\"disconnected\");\n///     let response = request.process();\n///     response.send(client);\n/// }\n/// ```\n///\n/// Currently, this isn't ideal, because we simply panic whenever we fail to get a new connection.\n/// Instead, we'd like to keep track of this error, like this:\n///\n/// ```ignore (hypothetical-example)\n/// loop {\n///     match get_request() {\n///         Err(err) => break err,\n///         Ok((client, request)) => {\n///             let response = request.process();\n///             response.send(client);\n///         },\n///     }\n/// }\n/// ```\n///\n/// Now, when the server disconnects, we exit the loop with an error instead of panicking. While it\n/// might be intuitive to simply return the error, we might want to wrap it in a [`Result<!, E>`]\n/// instead:\n///\n/// ```ignore (hypothetical-example)\n/// fn server_loop() -> Result<!, ConnectionError> {\n///     loop {\n///         let (client, request) = get_request()?;\n///         let response = request.process();\n///         response.send(client);\n///     }\n/// }\n/// ```\n///\n/// Now, we can use `?` instead of `match`, and the return type makes a lot more sense: if the loop\n/// ever stops, it means that an error occurred. We don't even have to wrap the loop in an `Ok`\n/// because `!` coerces to `Result<!, ConnectionError>` automatically.\n///\n/// [`String::from_str`]: str::FromStr::from_str\n/// [`String`]: string::String\n/// [`FromStr`]: str::FromStr\n///\n/// # `!` and traits\n///\n/// When writing your own traits, `!` should have an `impl` whenever there is an obvious `impl`\n/// which doesn't `panic!`. The reason is that functions returning an `impl Trait` where `!`\n/// does not have an `impl` of `Trait` cannot diverge as their only possible code path. In other\n/// words, they can't return `!` from every code path. As an example, this code doesn't compile:\n///\n/// ```compile_fail\n/// use std::ops::Add;\n///\n/// fn foo() -> impl Add<u32> {\n///     unimplemented!()\n/// }\n/// ```\n///\n/// But this code does:\n///\n/// ```\n/// use std::ops::Add;\n///\n/// fn foo() -> impl Add<u32> {\n///     if true {\n///         unimplemented!()\n///     } else {\n///         0\n///     }\n/// }\n/// ```\n///\n/// The reason is that, in the first example, there are many possible types that `!` could coerce\n/// to, because many types implement `Add<u32>`. However, in the second example,\n/// the `else` branch returns a `0`, which the compiler infers from the return type to be of type\n/// `u32`. Since `u32` is a concrete type, `!` can and will be coerced to it. See issue [#36375]\n/// for more information on this quirk of `!`.\n///\n/// [#36375]: https://github.com/rust-lang/rust/issues/36375\n///\n/// As it turns out, though, most traits can have an `impl` for `!`. Take [`Debug`]\n/// for example:\n///\n/// ```\n/// #![feature(never_type)]\n/// # use std::fmt;\n/// # trait Debug {\n/// #     fn fmt(&self, formatter: &mut fmt::Formatter<'_>) -> fmt::Result;\n/// # }\n/// impl Debug for ! {\n///     fn fmt(&self, formatter: &mut fmt::Formatter<'_>) -> fmt::Result {\n///         *self\n///     }\n/// }\n/// ```\n///\n/// Once again we're using `!`'s ability to coerce into any other type, in this case\n/// [`fmt::Result`]. Since this method takes a `&!` as an argument we know that it can never be\n/// called (because there is no value of type `!` for it to be called with). Writing `*self`\n/// essentially tells the compiler \"We know that this code can never be run, so just treat the\n/// entire function body as having type [`fmt::Result`]\". This pattern can be used a lot when\n/// implementing traits for `!`. Generally, any trait which only has methods which take a `self`\n/// parameter should have such an impl.\n///\n/// On the other hand, one trait which would not be appropriate to implement is [`Default`]:\n///\n/// ```\n/// trait Default {\n///     fn default() -> Self;\n/// }\n/// ```\n///\n/// Since `!` has no values, it has no default value either. It's true that we could write an\n/// `impl` for this which simply panics, but the same is true for any type (we could `impl\n/// Default` for (eg.) [`File`] by just making [`default()`] panic.)\n///\n/// [`File`]: fs::File\n/// [`Debug`]: fmt::Debug\n/// [`default()`]: Default::default\n///\n#[unstable(feature = \"never_type\", issue = \"35121\")]\nmod prim_never {}\n\n#[doc(primitive = \"char\")]\n//\n/// A character type.\n///\n/// The `char` type represents a single character. More specifically, since\n/// 'character' isn't a well-defined concept in Unicode, `char` is a '[Unicode\n/// scalar value]', which is similar to, but not the same as, a '[Unicode code\n/// point]'.\n///\n/// [Unicode scalar value]: https://www.unicode.org/glossary/#unicode_scalar_value\n/// [Unicode code point]: https://www.unicode.org/glossary/#code_point\n///\n/// This documentation describes a number of methods and trait implementations on the\n/// `char` type. For technical reasons, there is additional, separate\n/// documentation in [the `std::char` module](char/index.html) as well.\n///\n/// # Representation\n///\n/// `char` is always four bytes in size. This is a different representation than\n/// a given character would have as part of a [`String`]. For example:\n///\n/// ```\n/// let v = vec!['h', 'e', 'l', 'l', 'o'];\n///\n/// // five elements times four bytes for each element\n/// assert_eq!(20, v.len() * std::mem::size_of::<char>());\n///\n/// let s = String::from(\"hello\");\n///\n/// // five elements times one byte per element\n/// assert_eq!(5, s.len() * std::mem::size_of::<u8>());\n/// ```\n///\n/// [`String`]: string/struct.String.html\n///\n/// As always, remember that a human intuition for 'character' may not map to\n/// Unicode's definitions. For example, despite looking similar, the 'é'\n/// character is one Unicode code point while 'é' is two Unicode code points:\n///\n/// ```\n/// let mut chars = \"é\".chars();\n/// // U+00e9: 'latin small letter e with acute'\n/// assert_eq!(Some('\\u{00e9}'), chars.next());\n/// assert_eq!(None, chars.next());\n///\n/// let mut chars = \"é\".chars();\n/// // U+0065: 'latin small letter e'\n/// assert_eq!(Some('\\u{0065}'), chars.next());\n/// // U+0301: 'combining acute accent'\n/// assert_eq!(Some('\\u{0301}'), chars.next());\n/// assert_eq!(None, chars.next());\n/// ```\n///\n/// This means that the contents of the first string above _will_ fit into a\n/// `char` while the contents of the second string _will not_. Trying to create\n/// a `char` literal with the contents of the second string gives an error:\n///\n/// ```text\n/// error: character literal may only contain one codepoint: 'é'\n/// let c = 'é';\n///         ^^^\n/// ```\n///\n/// Another implication of the 4-byte fixed size of a `char` is that\n/// per-`char` processing can end up using a lot more memory:\n///\n/// ```\n/// let s = String::from(\"love: ❤️\");\n/// let v: Vec<char> = s.chars().collect();\n///\n/// assert_eq!(12, std::mem::size_of_val(&s[..]));\n/// assert_eq!(32, std::mem::size_of_val(&v[..]));\n/// ```\n#[stable(feature = \"rust1\", since = \"1.0.0\")]\nmod prim_char {}\n\n#[doc(primitive = \"unit\")]\n#[doc(alias = \"(\")]\n#[doc(alias = \")\")]\n#[doc(alias = \"()\")]\n//\n/// The `()` type, also called \"unit\".\n///\n/// The `()` type has exactly one value `()`, and is used when there\n/// is no other meaningful value that could be returned. `()` is most\n/// commonly seen implicitly: functions without a `-> ...` implicitly\n/// have return type `()`, that is, these are equivalent:\n///\n/// ```rust\n/// fn long() -> () {}\n///\n/// fn short() {}\n/// ```\n///\n/// The semicolon `;` can be used to discard the result of an\n/// expression at the end of a block, making the expression (and thus\n/// the block) evaluate to `()`. For example,\n///\n/// ```rust\n/// fn returns_i64() -> i64 {\n///     1i64\n/// }\n/// fn returns_unit() {\n///     1i64;\n/// }\n///\n/// let is_i64 = {\n///     returns_i64()\n/// };\n/// let is_unit = {\n///     returns_i64();\n/// };\n/// ```\n///\n#[stable(feature = \"rust1\", since = \"1.0.0\")]\nmod prim_unit {}\n\n#[doc(alias = \"ptr\")]\n#[doc(primitive = \"pointer\")]\n//\n/// Raw, unsafe pointers, `*const T`, and `*mut T`.\n///\n/// *[See also the `std::ptr` module](ptr).*\n///\n/// Working with raw pointers in Rust is uncommon, typically limited to a few patterns.\n/// Raw pointers can be unaligned or [`null`]. However, when a raw pointer is\n/// dereferenced (using the `*` operator), it must be non-null and aligned.\n///\n/// Storing through a raw pointer using `*ptr = data` calls `drop` on the old value, so\n/// [`write`] must be used if the type has drop glue and memory is not already\n/// initialized - otherwise `drop` would be called on the uninitialized memory.\n///\n/// Use the [`null`] and [`null_mut`] functions to create null pointers, and the\n/// [`is_null`] method of the `*const T` and `*mut T` types to check for null.\n/// The `*const T` and `*mut T` types also define the [`offset`] method, for\n/// pointer math.\n///\n/// # Common ways to create raw pointers\n///\n/// ## 1. Coerce a reference (`&T`) or mutable reference (`&mut T`).\n///\n/// ```\n/// let my_num: i32 = 10;\n/// let my_num_ptr: *const i32 = &my_num;\n/// let mut my_speed: i32 = 88;\n/// let my_speed_ptr: *mut i32 = &mut my_speed;\n/// ```\n///\n/// To get a pointer to a boxed value, dereference the box:\n///\n/// ```\n/// let my_num: Box<i32> = Box::new(10);\n/// let my_num_ptr: *const i32 = &*my_num;\n/// let mut my_speed: Box<i32> = Box::new(88);\n/// let my_speed_ptr: *mut i32 = &mut *my_speed;\n/// ```\n///\n/// This does not take ownership of the original allocation\n/// and requires no resource management later,\n/// but you must not use the pointer after its lifetime.\n///\n/// ## 2. Consume a box (`Box<T>`).\n///\n/// The [`into_raw`] function consumes a box and returns\n/// the raw pointer. It doesn't destroy `T` or deallocate any memory.\n///\n/// ```\n/// let my_speed: Box<i32> = Box::new(88);\n/// let my_speed: *mut i32 = Box::into_raw(my_speed);\n///\n/// // By taking ownership of the original `Box<T>` though\n/// // we are obligated to put it together later to be destroyed.\n/// unsafe {\n///     drop(Box::from_raw(my_speed));\n/// }\n/// ```\n///\n/// Note that here the call to [`drop`] is for clarity - it indicates\n/// that we are done with the given value and it should be destroyed.\n///\n/// ## 3. Create it using `ptr::addr_of!`\n///\n/// Instead of coercing a reference to a raw pointer, you can use the macros\n/// [`ptr::addr_of!`] (for `*const T`) and [`ptr::addr_of_mut!`] (for `*mut T`).\n/// These macros allow you to create raw pointers to fields to which you cannot\n/// create a reference (without causing undefined behaviour), such as an\n/// unaligned field. This might be necessary if packed structs or uninitialized\n/// memory is involved.\n///\n/// ```\n/// #[derive(Debug, Default, Copy, Clone)]\n/// #[repr(C, packed)]\n/// struct S {\n///     aligned: u8,\n///     unaligned: u32,\n/// }\n/// let s = S::default();\n/// let p = std::ptr::addr_of!(s.unaligned); // not allowed with coercion\n/// ```\n///\n/// ## 4. Get it from C.\n///\n/// ```\n/// # #![feature(rustc_private)]\n/// extern crate libc;\n///\n/// use std::mem;\n///\n/// unsafe {\n///     let my_num: *mut i32 = libc::malloc(mem::size_of::<i32>()) as *mut i32;\n///     if my_num.is_null() {\n///         panic!(\"failed to allocate memory\");\n///     }\n///     libc::free(my_num as *mut libc::c_void);\n/// }\n/// ```\n///\n/// Usually you wouldn't literally use `malloc` and `free` from Rust,\n/// but C APIs hand out a lot of pointers generally, so are a common source\n/// of raw pointers in Rust.\n///\n/// [`null`]: ptr::null\n/// [`null_mut`]: ptr::null_mut\n/// [`is_null`]: pointer::is_null\n/// [`offset`]: pointer::offset\n/// [`into_raw`]: Box::into_raw\n/// [`drop`]: mem::drop\n/// [`write`]: ptr::write\n#[stable(feature = \"rust1\", since = \"1.0.0\")]\nmod prim_pointer {}\n\n#[doc(alias = \"[]\")]\n#[doc(alias = \"[T;N]\")] // unfortunately, rustdoc doesn't have fuzzy search for aliases\n#[doc(alias = \"[T; N]\")]\n#[doc(primitive = \"array\")]\n/// A fixed-size array, denoted `[T; N]`, for the element type, `T`, and the\n/// non-negative compile-time constant size, `N`.\n///\n/// There are two syntactic forms for creating an array:\n///\n/// * A list with each element, i.e., `[x, y, z]`.\n/// * A repeat expression `[x; N]`, which produces an array with `N` copies of `x`.\n///   The type of `x` must be [`Copy`].\n///\n/// Note that `[expr; 0]` is allowed, and produces an empty array.\n/// This will still evaluate `expr`, however, and immediately drop the resulting value, so\n/// be mindful of side effects.\n///\n/// Arrays of *any* size implement the following traits if the element type allows it:\n///\n/// - [`Copy`]\n/// - [`Clone`]\n/// - [`Debug`]\n/// - [`IntoIterator`] (implemented for `[T; N]`, `&[T; N]` and `&mut [T; N]`)\n/// - [`PartialEq`], [`PartialOrd`], [`Eq`], [`Ord`]\n/// - [`Hash`]\n/// - [`AsRef`], [`AsMut`]\n/// - [`Borrow`], [`BorrowMut`]\n///\n/// Arrays of sizes from 0 to 32 (inclusive) implement the [`Default`] trait\n/// if the element type allows it. As a stopgap, trait implementations are\n/// statically generated up to size 32.\n///\n/// Arrays coerce to [slices (`[T]`)][slice], so a slice method may be called on\n/// an array. Indeed, this provides most of the API for working with arrays.\n/// Slices have a dynamic size and do not coerce to arrays.\n///\n/// You can move elements out of an array with a [slice pattern]. If you want\n/// one element, see [`mem::replace`].\n///\n/// # Examples\n///\n/// ```\n/// let mut array: [i32; 3] = [0; 3];\n///\n/// array[1] = 1;\n/// array[2] = 2;\n///\n/// assert_eq!([1, 2], &array[1..]);\n///\n/// // This loop prints: 0 1 2\n/// for x in array {\n///     print!(\"{} \", x);\n/// }\n/// ```\n///\n/// You can also iterate over reference to the array's elements:\n///\n/// ```\n/// let array: [i32; 3] = [0; 3];\n///\n/// for x in &array { }\n/// ```\n///\n/// You can use a [slice pattern] to move elements out of an array:\n///\n/// ```\n/// fn move_away(_: String) { /* Do interesting things. */ }\n///\n/// let [john, roa] = [\"John\".to_string(), \"Roa\".to_string()];\n/// move_away(john);\n/// move_away(roa);\n/// ```\n///\n/// # Editions\n///\n/// Prior to Rust 1.53, arrays did not implement `IntoIterator` by value, so the method call\n/// `array.into_iter()` auto-referenced into a slice iterator. Right now, the old behavior\n/// is preserved in the 2015 and 2018 editions of Rust for compatibility, ignoring\n/// `IntoIterator` by value. In the future, the behavior on the 2015 and 2018 edition\n/// might be made consistent to the behavior of later editions.\n///\n/// ```rust,edition2018\n/// # #![allow(array_into_iter)] // override our `deny(warnings)`\n/// let array: [i32; 3] = [0; 3];\n///\n/// // This creates a slice iterator, producing references to each value.\n/// for item in array.into_iter().enumerate() {\n///     let (i, x): (usize, &i32) = item;\n///     println!(\"array[{}] = {}\", i, x);\n/// }\n///\n/// // The `array_into_iter` lint suggests this change for future compatibility:\n/// for item in array.iter().enumerate() {\n///     let (i, x): (usize, &i32) = item;\n///     println!(\"array[{}] = {}\", i, x);\n/// }\n///\n/// // You can explicitly iterate an array by value using\n/// // `IntoIterator::into_iter` or `std::array::IntoIter::new`:\n/// for item in IntoIterator::into_iter(array).enumerate() {\n///     let (i, x): (usize, i32) = item;\n///     println!(\"array[{}] = {}\", i, x);\n/// }\n/// ```\n///\n/// Starting in the 2021 edition, `array.into_iter()` will use `IntoIterator` normally to iterate\n/// by value, and `iter()` should be used to iterate by reference like previous editions.\n///\n/// ```rust,edition2021,ignore\n/// # // FIXME: ignored because 2021 testing is still unstable\n/// let array: [i32; 3] = [0; 3];\n///\n/// // This iterates by reference:\n/// for item in array.iter().enumerate() {\n///     let (i, x): (usize, &i32) = item;\n///     println!(\"array[{}] = {}\", i, x);\n/// }\n///\n/// // This iterates by value:\n/// for item in array.into_iter().enumerate() {\n///     let (i, x): (usize, i32) = item;\n///     println!(\"array[{}] = {}\", i, x);\n/// }\n/// ```\n///\n/// Future language versions might start treating the `array.into_iter()`\n/// syntax on editions 2015 and 2018 the same as on edition 2021. So code using\n/// those older editions should still be written with this change in mind, to\n/// prevent breakage in the future. The safest way to accomplish this is to\n/// avoid the `into_iter` syntax on those editions. If an edition update is not\n/// viable/desired, there are multiple alternatives:\n/// * use `iter`, equivalent to the old behavior, creating references\n/// * use [`array::IntoIter`], equivalent to the post-2021 behavior (Rust 1.51+)\n/// * replace `for ... in array.into_iter() {` with `for ... in array {`,\n///   equivalent to the post-2021 behavior (Rust 1.53+)\n///\n/// ```rust,edition2018\n/// use std::array::IntoIter;\n///\n/// let array: [i32; 3] = [0; 3];\n///\n/// // This iterates by reference:\n/// for item in array.iter() {\n///     let x: &i32 = item;\n///     println!(\"{}\", x);\n/// }\n///\n/// // This iterates by value:\n/// for item in IntoIter::new(array) {\n///     let x: i32 = item;\n///     println!(\"{}\", x);\n/// }\n///\n/// // This iterates by value:\n/// for item in array {\n///     let x: i32 = item;\n///     println!(\"{}\", x);\n/// }\n///\n/// // IntoIter can also start a chain.\n/// // This iterates by value:\n/// for item in IntoIter::new(array).enumerate() {\n///     let (i, x): (usize, i32) = item;\n///     println!(\"array[{}] = {}\", i, x);\n/// }\n/// ```\n///\n/// [slice]: prim@slice\n/// [`Debug`]: fmt::Debug\n/// [`Hash`]: hash::Hash\n/// [`Borrow`]: borrow::Borrow\n/// [`BorrowMut`]: borrow::BorrowMut\n/// [slice pattern]: ../reference/patterns.html#slice-patterns\n#[stable(feature = \"rust1\", since = \"1.0.0\")]\nmod prim_array {}\n\n#[doc(primitive = \"slice\")]\n#[doc(alias = \"[\")]\n#[doc(alias = \"]\")]\n#[doc(alias = \"[]\")]\n/// A dynamically-sized view into a contiguous sequence, `[T]`. Contiguous here\n/// means that elements are laid out so that every element is the same\n/// distance from its neighbors.\n///\n/// *[See also the `std::slice` module](crate::slice).*\n///\n/// Slices are a view into a block of memory represented as a pointer and a\n/// length.\n///\n/// ```\n/// // slicing a Vec\n/// let vec = vec![1, 2, 3];\n/// let int_slice = &vec[..];\n/// // coercing an array to a slice\n/// let str_slice: &[&str] = &[\"one\", \"two\", \"three\"];\n/// ```\n///\n/// Slices are either mutable or shared. The shared slice type is `&[T]`,\n/// while the mutable slice type is `&mut [T]`, where `T` represents the element\n/// type. For example, you can mutate the block of memory that a mutable slice\n/// points to:\n///\n/// ```\n/// let mut x = [1, 2, 3];\n/// let x = &mut x[..]; // Take a full slice of `x`.\n/// x[1] = 7;\n/// assert_eq!(x, &[1, 7, 3]);\n/// ```\n///\n/// As slices store the length of the sequence they refer to, they have twice\n/// the size of pointers to [`Sized`](marker/trait.Sized.html) types.\n/// Also see the reference on\n/// [dynamically sized types](../reference/dynamically-sized-types.html).\n///\n/// ```\n/// # use std::rc::Rc;\n/// let pointer_size = std::mem::size_of::<&u8>();\n/// assert_eq!(2 * pointer_size, std::mem::size_of::<&[u8]>());\n/// assert_eq!(2 * pointer_size, std::mem::size_of::<*const [u8]>());\n/// assert_eq!(2 * pointer_size, std::mem::size_of::<Box<[u8]>>());\n/// assert_eq!(2 * pointer_size, std::mem::size_of::<Rc<[u8]>>());\n/// ```\n#[stable(feature = \"rust1\", since = \"1.0.0\")]\nmod prim_slice {}\n\n#[doc(primitive = \"str\")]\n//\n/// String slices.\n///\n/// *[See also the `std::str` module](crate::str).*\n///\n/// The `str` type, also called a 'string slice', is the most primitive string\n/// type. It is usually seen in its borrowed form, `&str`. It is also the type\n/// of string literals, `&'static str`.\n///\n/// String slices are always valid UTF-8.\n///\n/// # Examples\n///\n/// String literals are string slices:\n///\n/// ```\n/// let hello = \"Hello, world!\";\n///\n/// // with an explicit type annotation\n/// let hello: &'static str = \"Hello, world!\";\n/// ```\n///\n/// They are `'static` because they're stored directly in the final binary, and\n/// so will be valid for the `'static` duration.\n///\n/// # Representation\n///\n/// A `&str` is made up of two components: a pointer to some bytes, and a\n/// length. You can look at these with the [`as_ptr`] and [`len`] methods:\n///\n/// ```\n/// use std::slice;\n/// use std::str;\n///\n/// let story = \"Once upon a time...\";\n///\n/// let ptr = story.as_ptr();\n/// let len = story.len();\n///\n/// // story has nineteen bytes\n/// assert_eq!(19, len);\n///\n/// // We can re-build a str out of ptr and len. This is all unsafe because\n/// // we are responsible for making sure the two components are valid:\n/// let s = unsafe {\n///     // First, we build a &[u8]...\n///     let slice = slice::from_raw_parts(ptr, len);\n///\n///     // ... and then convert that slice into a string slice\n///     str::from_utf8(slice)\n/// };\n///\n/// assert_eq!(s, Ok(story));\n/// ```\n///\n/// [`as_ptr`]: str::as_ptr\n/// [`len`]: str::len\n///\n/// Note: This example shows the internals of `&str`. `unsafe` should not be\n/// used to get a string slice under normal circumstances. Use `as_str`\n/// instead.\n#[stable(feature = \"rust1\", since = \"1.0.0\")]\nmod prim_str {}\n\n#[doc(primitive = \"tuple\")]\n#[doc(alias = \"(\")]\n#[doc(alias = \")\")]\n#[doc(alias = \"()\")]\n//\n/// A finite heterogeneous sequence, `(T, U, ..)`.\n///\n/// Let's cover each of those in turn:\n///\n/// Tuples are *finite*. In other words, a tuple has a length. Here's a tuple\n/// of length `3`:\n///\n/// ```\n/// (\"hello\", 5, 'c');\n/// ```\n///\n/// 'Length' is also sometimes called 'arity' here; each tuple of a different\n/// length is a different, distinct type.\n///\n/// Tuples are *heterogeneous*. This means that each element of the tuple can\n/// have a different type. In that tuple above, it has the type:\n///\n/// ```\n/// # let _:\n/// (&'static str, i32, char)\n/// # = (\"hello\", 5, 'c');\n/// ```\n///\n/// Tuples are a *sequence*. This means that they can be accessed by position;\n/// this is called 'tuple indexing', and it looks like this:\n///\n/// ```rust\n/// let tuple = (\"hello\", 5, 'c');\n///\n/// assert_eq!(tuple.0, \"hello\");\n/// assert_eq!(tuple.1, 5);\n/// assert_eq!(tuple.2, 'c');\n/// ```\n///\n/// The sequential nature of the tuple applies to its implementations of various\n/// traits.  For example, in `PartialOrd` and `Ord`, the elements are compared\n/// sequentially until the first non-equal set is found.\n///\n/// For more about tuples, see [the book](../book/ch03-02-data-types.html#the-tuple-type).\n///\n/// # Trait implementations\n///\n/// If every type inside a tuple implements one of the following traits, then a\n/// tuple itself also implements it.\n///\n/// * [`Clone`]\n/// * [`Copy`]\n/// * [`PartialEq`]\n/// * [`Eq`]\n/// * [`PartialOrd`]\n/// * [`Ord`]\n/// * [`Debug`]\n/// * [`Default`]\n/// * [`Hash`]\n///\n/// [`Debug`]: fmt::Debug\n/// [`Hash`]: hash::Hash\n///\n/// Due to a temporary restriction in Rust's type system, these traits are only\n/// implemented on tuples of arity 12 or less. In the future, this may change.\n///\n/// # Examples\n///\n/// Basic usage:\n///\n/// ```\n/// let tuple = (\"hello\", 5, 'c');\n///\n/// assert_eq!(tuple.0, \"hello\");\n/// ```\n///\n/// Tuples are often used as a return type when you want to return more than\n/// one value:\n///\n/// ```\n/// fn calculate_point() -> (i32, i32) {\n///     // Don't do a calculation, that's not the point of the example\n///     (4, 5)\n/// }\n///\n/// let point = calculate_point();\n///\n/// assert_eq!(point.0, 4);\n/// assert_eq!(point.1, 5);\n///\n/// // Combining this with patterns can be nicer.\n///\n/// let (x, y) = calculate_point();\n///\n/// assert_eq!(x, 4);\n/// assert_eq!(y, 5);\n/// ```\n///\n#[stable(feature = \"rust1\", since = \"1.0.0\")]\nmod prim_tuple {}\n\n#[doc(primitive = \"f32\")]\n/// A 32-bit floating point type (specifically, the \"binary32\" type defined in IEEE 754-2008).\n///\n/// This type can represent a wide range of decimal numbers, like `3.5`, `27`,\n/// `-113.75`, `0.0078125`, `34359738368`, `0`, `-1`. So unlike integer types\n/// (such as `i32`), floating point types can represent non-integer numbers,\n/// too.\n///\n/// However, being able to represent this wide range of numbers comes at the\n/// cost of precision: floats can only represent some of the real numbers and\n/// calculation with floats round to a nearby representable number. For example,\n/// `5.0` and `1.0` can be exactly represented as `f32`, but `1.0 / 5.0` results\n/// in `0.20000000298023223876953125` since `0.2` cannot be exactly represented\n/// as `f32`. Note, however, that printing floats with `println` and friends will\n/// often discard insignificant digits: `println!(\"{}\", 1.0f32 / 5.0f32)` will\n/// print `0.2`.\n///\n/// Additionally, `f32` can represent some special values:\n///\n/// - −0.0: IEEE 754 floating point numbers have a bit that indicates their sign, so −0.0 is a\n///   possible value. For comparison −0.0 = +0.0, but floating point operations can carry\n///   the sign bit through arithmetic operations. This means −0.0 × +0.0 produces −0.0 and\n///   a negative number rounded to a value smaller than a float can represent also produces −0.0.\n/// - [∞](#associatedconstant.INFINITY) and\n///   [−∞](#associatedconstant.NEG_INFINITY): these result from calculations\n///   like `1.0 / 0.0`.\n/// - [NaN (not a number)](#associatedconstant.NAN): this value results from\n///   calculations like `(-1.0).sqrt()`. NaN has some potentially unexpected\n///   behavior: it is unequal to any float, including itself! It is also neither\n///   smaller nor greater than any float, making it impossible to sort. Lastly,\n///   it is considered infectious as almost all calculations where one of the\n///   operands is NaN will also result in NaN.\n///\n/// For more information on floating point numbers, see [Wikipedia][wikipedia].\n///\n/// *[See also the `std::f32::consts` module](crate::f32::consts).*\n///\n/// [wikipedia]: https://en.wikipedia.org/wiki/Single-precision_floating-point_format\n#[stable(feature = \"rust1\", since = \"1.0.0\")]\nmod prim_f32 {}\n\n#[doc(primitive = \"f64\")]\n/// A 64-bit floating point type (specifically, the \"binary64\" type defined in IEEE 754-2008).\n///\n/// This type is very similar to [`f32`], but has increased\n/// precision by using twice as many bits. Please see [the documentation for\n/// `f32`][`f32`] or [Wikipedia on double precision\n/// values][wikipedia] for more information.\n///\n/// *[See also the `std::f64::consts` module](crate::f64::consts).*\n///\n/// [`f32`]: prim@f32\n/// [wikipedia]: https://en.wikipedia.org/wiki/Double-precision_floating-point_format\n#[stable(feature = \"rust1\", since = \"1.0.0\")]\nmod prim_f64 {}\n\n#[doc(primitive = \"i8\")]\n//\n/// The 8-bit signed integer type.\n#[stable(feature = \"rust1\", since = \"1.0.0\")]\nmod prim_i8 {}\n\n#[doc(primitive = \"i16\")]\n//\n/// The 16-bit signed integer type.\n#[stable(feature = \"rust1\", since = \"1.0.0\")]\nmod prim_i16 {}\n\n#[doc(primitive = \"i32\")]\n//\n/// The 32-bit signed integer type.\n#[stable(feature = \"rust1\", since = \"1.0.0\")]\nmod prim_i32 {}\n\n#[doc(primitive = \"i64\")]\n//\n/// The 64-bit signed integer type.\n#[stable(feature = \"rust1\", since = \"1.0.0\")]\nmod prim_i64 {}\n\n#[doc(primitive = \"i128\")]\n//\n/// The 128-bit signed integer type.\n#[stable(feature = \"i128\", since = \"1.26.0\")]\nmod prim_i128 {}\n\n#[doc(primitive = \"u8\")]\n//\n/// The 8-bit unsigned integer type.\n#[stable(feature = \"rust1\", since = \"1.0.0\")]\nmod prim_u8 {}\n\n#[doc(primitive = \"u16\")]\n//\n/// The 16-bit unsigned integer type.\n#[stable(feature = \"rust1\", since = \"1.0.0\")]\nmod prim_u16 {}\n\n#[doc(primitive = \"u32\")]\n//\n/// The 32-bit unsigned integer type.\n#[stable(feature = \"rust1\", since = \"1.0.0\")]\nmod prim_u32 {}\n\n#[doc(primitive = \"u64\")]\n//\n/// The 64-bit unsigned integer type.\n#[stable(feature = \"rust1\", since = \"1.0.0\")]\nmod prim_u64 {}\n\n#[doc(primitive = \"u128\")]\n//\n/// The 128-bit unsigned integer type.\n#[stable(feature = \"i128\", since = \"1.26.0\")]\nmod prim_u128 {}\n\n#[doc(primitive = \"isize\")]\n//\n/// The pointer-sized signed integer type.\n///\n/// The size of this primitive is how many bytes it takes to reference any\n/// location in memory. For example, on a 32 bit target, this is 4 bytes\n/// and on a 64 bit target, this is 8 bytes.\n#[stable(feature = \"rust1\", since = \"1.0.0\")]\nmod prim_isize {}\n\n#[doc(primitive = \"usize\")]\n//\n/// The pointer-sized unsigned integer type.\n///\n/// The size of this primitive is how many bytes it takes to reference any\n/// location in memory. For example, on a 32 bit target, this is 4 bytes\n/// and on a 64 bit target, this is 8 bytes.\n#[stable(feature = \"rust1\", since = \"1.0.0\")]\nmod prim_usize {}\n\n#[doc(primitive = \"reference\")]\n#[doc(alias = \"&\")]\n#[doc(alias = \"&mut\")]\n//\n/// References, both shared and mutable.\n///\n/// A reference represents a borrow of some owned value. You can get one by using the `&` or `&mut`\n/// operators on a value, or by using a `ref` or `ref mut` pattern.\n///\n/// For those familiar with pointers, a reference is just a pointer that is assumed to be\n/// aligned, not null, and pointing to memory containing a valid value of `T` - for example,\n/// `&bool` can only point to an allocation containing the integer values `1` (`true`) or `0`\n/// (`false`), but creating a `&bool` that points to an allocation containing\n/// the value `3` causes undefined behaviour.\n/// In fact, `Option<&T>` has the same memory representation as a\n/// nullable but aligned pointer, and can be passed across FFI boundaries as such.\n///\n/// In most cases, references can be used much like the original value. Field access, method\n/// calling, and indexing work the same (save for mutability rules, of course). In addition, the\n/// comparison operators transparently defer to the referent's implementation, allowing references\n/// to be compared the same as owned values.\n///\n/// References have a lifetime attached to them, which represents the scope for which the borrow is\n/// valid. A lifetime is said to \"outlive\" another one if its representative scope is as long or\n/// longer than the other. The `'static` lifetime is the longest lifetime, which represents the\n/// total life of the program. For example, string literals have a `'static` lifetime because the\n/// text data is embedded into the binary of the program, rather than in an allocation that needs\n/// to be dynamically managed.\n///\n/// `&mut T` references can be freely coerced into `&T` references with the same referent type, and\n/// references with longer lifetimes can be freely coerced into references with shorter ones.\n///\n/// Reference equality by address, instead of comparing the values pointed to, is accomplished via\n/// implicit reference-pointer coercion and raw pointer equality via [`ptr::eq`], while\n/// [`PartialEq`] compares values.\n///\n/// ```\n/// use std::ptr;\n///\n/// let five = 5;\n/// let other_five = 5;\n/// let five_ref = &five;\n/// let same_five_ref = &five;\n/// let other_five_ref = &other_five;\n///\n/// assert!(five_ref == same_five_ref);\n/// assert!(five_ref == other_five_ref);\n///\n/// assert!(ptr::eq(five_ref, same_five_ref));\n/// assert!(!ptr::eq(five_ref, other_five_ref));\n/// ```\n///\n/// For more information on how to use references, see [the book's section on \"References and\n/// Borrowing\"][book-refs].\n///\n/// [book-refs]: ../book/ch04-02-references-and-borrowing.html\n///\n/// # Trait implementations\n///\n/// The following traits are implemented for all `&T`, regardless of the type of its referent:\n///\n/// * [`Copy`]\n/// * [`Clone`] \\(Note that this will not defer to `T`'s `Clone` implementation if it exists!)\n/// * [`Deref`]\n/// * [`Borrow`]\n/// * [`Pointer`]\n///\n/// [`Deref`]: ops::Deref\n/// [`Borrow`]: borrow::Borrow\n/// [`Pointer`]: fmt::Pointer\n///\n/// `&mut T` references get all of the above except `Copy` and `Clone` (to prevent creating\n/// multiple simultaneous mutable borrows), plus the following, regardless of the type of its\n/// referent:\n///\n/// * [`DerefMut`]\n/// * [`BorrowMut`]\n///\n/// [`DerefMut`]: ops::DerefMut\n/// [`BorrowMut`]: borrow::BorrowMut\n///\n/// The following traits are implemented on `&T` references if the underlying `T` also implements\n/// that trait:\n///\n/// * All the traits in [`std::fmt`] except [`Pointer`] and [`fmt::Write`]\n/// * [`PartialOrd`]\n/// * [`Ord`]\n/// * [`PartialEq`]\n/// * [`Eq`]\n/// * [`AsRef`]\n/// * [`Fn`] \\(in addition, `&T` references get [`FnMut`] and [`FnOnce`] if `T: Fn`)\n/// * [`Hash`]\n/// * [`ToSocketAddrs`]\n///\n/// [`std::fmt`]: fmt\n/// ['Pointer`]: fmt::Pointer\n/// [`Hash`]: hash::Hash\n/// [`ToSocketAddrs`]: net::ToSocketAddrs\n///\n/// `&mut T` references get all of the above except `ToSocketAddrs`, plus the following, if `T`\n/// implements that trait:\n///\n/// * [`AsMut`]\n/// * [`FnMut`] \\(in addition, `&mut T` references get [`FnOnce`] if `T: FnMut`)\n/// * [`fmt::Write`]\n/// * [`Iterator`]\n/// * [`DoubleEndedIterator`]\n/// * [`ExactSizeIterator`]\n/// * [`FusedIterator`]\n/// * [`TrustedLen`]\n/// * [`Send`] \\(note that `&T` references only get `Send` if `T: Sync`)\n/// * [`io::Write`]\n/// * [`Read`]\n/// * [`Seek`]\n/// * [`BufRead`]\n///\n/// [`FusedIterator`]: iter::FusedIterator\n/// [`TrustedLen`]: iter::TrustedLen\n/// [`Seek`]: io::Seek\n/// [`BufRead`]: io::BufRead\n/// [`Read`]: io::Read\n///\n/// Note that due to method call deref coercion, simply calling a trait method will act like they\n/// work on references as well as they do on owned values! The implementations described here are\n/// meant for generic contexts, where the final type `T` is a type parameter or otherwise not\n/// locally known.\n#[stable(feature = \"rust1\", since = \"1.0.0\")]\nmod prim_ref {}\n\n#[doc(primitive = \"fn\")]\n//\n/// Function pointers, like `fn(usize) -> bool`.\n///\n/// *See also the traits [`Fn`], [`FnMut`], and [`FnOnce`].*\n///\n/// [`Fn`]: ops::Fn\n/// [`FnMut`]: ops::FnMut\n/// [`FnOnce`]: ops::FnOnce\n///\n/// Function pointers are pointers that point to *code*, not data. They can be called\n/// just like functions. Like references, function pointers are, among other things, assumed to\n/// not be null, so if you want to pass a function pointer over FFI and be able to accommodate null\n/// pointers, make your type `Option<fn()>` with your required signature.\n///\n/// ### Safety\n///\n/// Plain function pointers are obtained by casting either plain functions, or closures that don't\n/// capture an environment:\n///\n/// ```\n/// fn add_one(x: usize) -> usize {\n///     x + 1\n/// }\n///\n/// let ptr: fn(usize) -> usize = add_one;\n/// assert_eq!(ptr(5), 6);\n///\n/// let clos: fn(usize) -> usize = |x| x + 5;\n/// assert_eq!(clos(5), 10);\n/// ```\n///\n/// In addition to varying based on their signature, function pointers come in two flavors: safe\n/// and unsafe. Plain `fn()` function pointers can only point to safe functions,\n/// while `unsafe fn()` function pointers can point to safe or unsafe functions.\n///\n/// ```\n/// fn add_one(x: usize) -> usize {\n///     x + 1\n/// }\n///\n/// unsafe fn add_one_unsafely(x: usize) -> usize {\n///     x + 1\n/// }\n///\n/// let safe_ptr: fn(usize) -> usize = add_one;\n///\n/// //ERROR: mismatched types: expected normal fn, found unsafe fn\n/// //let bad_ptr: fn(usize) -> usize = add_one_unsafely;\n///\n/// let unsafe_ptr: unsafe fn(usize) -> usize = add_one_unsafely;\n/// let really_safe_ptr: unsafe fn(usize) -> usize = add_one;\n/// ```\n///\n/// ### ABI\n///\n/// On top of that, function pointers can vary based on what ABI they use. This\n/// is achieved by adding the `extern` keyword before the type, followed by the\n/// ABI in question. The default ABI is \"Rust\", i.e., `fn()` is the exact same\n/// type as `extern \"Rust\" fn()`. A pointer to a function with C ABI would have\n/// type `extern \"C\" fn()`.\n///\n/// `extern \"ABI\" { ... }` blocks declare functions with ABI \"ABI\". The default\n/// here is \"C\", i.e., functions declared in an `extern {...}` block have \"C\"\n/// ABI.\n///\n/// For more information and a list of supported ABIs, see [the nomicon's\n/// section on foreign calling conventions][nomicon-abi].\n///\n/// [nomicon-abi]: ../nomicon/ffi.html#foreign-calling-conventions\n///\n/// ### Variadic functions\n///\n/// Extern function declarations with the \"C\" or \"cdecl\" ABIs can also be *variadic*, allowing them\n/// to be called with a variable number of arguments. Normal Rust functions, even those with an\n/// `extern \"ABI\"`, cannot be variadic. For more information, see [the nomicon's section on\n/// variadic functions][nomicon-variadic].\n///\n/// [nomicon-variadic]: ../nomicon/ffi.html#variadic-functions\n///\n/// ### Creating function pointers\n///\n/// When `bar` is the name of a function, then the expression `bar` is *not* a\n/// function pointer. Rather, it denotes a value of an unnameable type that\n/// uniquely identifies the function `bar`. The value is zero-sized because the\n/// type already identifies the function. This has the advantage that \"calling\"\n/// the value (it implements the `Fn*` traits) does not require dynamic\n/// dispatch.\n///\n/// This zero-sized type *coerces* to a regular function pointer. For example:\n///\n/// ```rust\n/// use std::mem;\n///\n/// fn bar(x: i32) {}\n///\n/// let not_bar_ptr = bar; // `not_bar_ptr` is zero-sized, uniquely identifying `bar`\n/// assert_eq!(mem::size_of_val(&not_bar_ptr), 0);\n///\n/// let bar_ptr: fn(i32) = not_bar_ptr; // force coercion to function pointer\n/// assert_eq!(mem::size_of_val(&bar_ptr), mem::size_of::<usize>());\n///\n/// let footgun = &bar; // this is a shared reference to the zero-sized type identifying `bar`\n/// ```\n///\n/// The last line shows that `&bar` is not a function pointer either. Rather, it\n/// is a reference to the function-specific ZST. `&bar` is basically never what you\n/// want when `bar` is a function.\n///\n/// ### Traits\n///\n/// Function pointers implement the following traits:\n///\n/// * [`Clone`]\n/// * [`PartialEq`]\n/// * [`Eq`]\n/// * [`PartialOrd`]\n/// * [`Ord`]\n/// * [`Hash`]\n/// * [`Pointer`]\n/// * [`Debug`]\n///\n/// [`Hash`]: hash::Hash\n/// [`Pointer`]: fmt::Pointer\n///\n/// Due to a temporary restriction in Rust's type system, these traits are only implemented on\n/// functions that take 12 arguments or less, with the `\"Rust\"` and `\"C\"` ABIs. In the future, this\n/// may change.\n///\n/// In addition, function pointers of *any* signature, ABI, or safety are [`Copy`], and all *safe*\n/// function pointers implement [`Fn`], [`FnMut`], and [`FnOnce`]. This works because these traits\n/// are specially known to the compiler.\n#[stable(feature = \"rust1\", since = \"1.0.0\")]\nmod prim_fn {}\n"],[2129,"//! Additional functionality for numerics.\n//!\n//! This module provides some extra types that are useful when doing numerical\n//! work. See the individual documentation for each piece for more information.\n\n#![stable(feature = \"rust1\", since = \"1.0.0\")]\n#![allow(missing_docs)]\n\n#[cfg(test)]\nmod tests;\n\n#[cfg(test)]\nmod benches;\n\n#[stable(feature = \"rust1\", since = \"1.0.0\")]\npub use core::num::Wrapping;\n#[stable(feature = \"rust1\", since = \"1.0.0\")]\npub use core::num::{FpCategory, ParseFloatError, ParseIntError, TryFromIntError};\n\n#[stable(feature = \"signed_nonzero\", since = \"1.34.0\")]\npub use core::num::{NonZeroI128, NonZeroI16, NonZeroI32, NonZeroI64, NonZeroI8, NonZeroIsize};\n#[stable(feature = \"nonzero\", since = \"1.28.0\")]\npub use core::num::{NonZeroU128, NonZeroU16, NonZeroU32, NonZeroU64, NonZeroU8, NonZeroUsize};\n\n#[stable(feature = \"int_error_matching\", since = \"1.55.0\")]\npub use core::num::IntErrorKind;\n\n#[cfg(test)]\nuse crate::fmt;\n#[cfg(test)]\nuse crate::ops::{Add, Div, Mul, Rem, Sub};\n\n/// Helper function for testing numeric operations\n#[cfg(test)]\npub fn test_num<T>(ten: T, two: T)\nwhere\n    T: PartialEq\n        + Add<Output = T>\n        + Sub<Output = T>\n        + Mul<Output = T>\n        + Div<Output = T>\n        + Rem<Output = T>\n        + fmt::Debug\n        + Copy,\n{\n    assert_eq!(ten.add(two), ten + two);\n    assert_eq!(ten.sub(two), ten - two);\n    assert_eq!(ten.mul(two), ten * two);\n    assert_eq!(ten.div(two), ten / two);\n    assert_eq!(ten.rem(two), ten % two);\n}\n"],[2130,"#![allow(dead_code)]\n\nuse crate::cell::RefCell;\nuse crate::panic::{AssertUnwindSafe, UnwindSafe};\nuse crate::rc::Rc;\nuse crate::sync::{Arc, Mutex, RwLock};\n\nstruct Foo {\n    a: i32,\n}\n\nfn assert<T: UnwindSafe + ?Sized>() {}\n\n#[test]\nfn panic_safety_traits() {\n    assert::<i32>();\n    assert::<&i32>();\n    assert::<*mut i32>();\n    assert::<*const i32>();\n    assert::<usize>();\n    assert::<str>();\n    assert::<&str>();\n    assert::<Foo>();\n    assert::<&Foo>();\n    assert::<Vec<i32>>();\n    assert::<String>();\n    assert::<RefCell<i32>>();\n    assert::<Box<i32>>();\n    assert::<Mutex<i32>>();\n    assert::<RwLock<i32>>();\n    assert::<&Mutex<i32>>();\n    assert::<&RwLock<i32>>();\n    assert::<Rc<i32>>();\n    assert::<Arc<i32>>();\n    assert::<Box<[u8]>>();\n\n    {\n        trait Trait: UnwindSafe {}\n        assert::<Box<dyn Trait>>();\n    }\n\n    fn bar<T>() {\n        assert::<Mutex<T>>();\n        assert::<RwLock<T>>();\n    }\n\n    fn baz<T: UnwindSafe>() {\n        assert::<Box<T>>();\n        assert::<Vec<T>>();\n        assert::<RefCell<T>>();\n        assert::<AssertUnwindSafe<T>>();\n        assert::<&AssertUnwindSafe<T>>();\n        assert::<Rc<AssertUnwindSafe<T>>>();\n        assert::<Arc<AssertUnwindSafe<T>>>();\n    }\n}\n"],[2131,"//! Memory allocation APIs.\n//!\n//! In a given program, the standard library has one “global” memory allocator\n//! that is used for example by `Box<T>` and `Vec<T>`.\n//!\n//! Currently the default global allocator is unspecified. Libraries, however,\n//! like `cdylib`s and `staticlib`s are guaranteed to use the [`System`] by\n//! default.\n//!\n//! # The `#[global_allocator]` attribute\n//!\n//! This attribute allows configuring the choice of global allocator.\n//! You can use this to implement a completely custom global allocator\n//! to route all default allocation requests to a custom object.\n//!\n//! ```rust\n//! use std::alloc::{GlobalAlloc, System, Layout};\n//!\n//! struct MyAllocator;\n//!\n//! unsafe impl GlobalAlloc for MyAllocator {\n//!     unsafe fn alloc(&self, layout: Layout) -> *mut u8 {\n//!         System.alloc(layout)\n//!     }\n//!\n//!     unsafe fn dealloc(&self, ptr: *mut u8, layout: Layout) {\n//!         System.dealloc(ptr, layout)\n//!     }\n//! }\n//!\n//! #[global_allocator]\n//! static GLOBAL: MyAllocator = MyAllocator;\n//!\n//! fn main() {\n//!     // This `Vec` will allocate memory through `GLOBAL` above\n//!     let mut v = Vec::new();\n//!     v.push(1);\n//! }\n//! ```\n//!\n//! The attribute is used on a `static` item whose type implements the\n//! [`GlobalAlloc`] trait. This type can be provided by an external library:\n//!\n//! ```rust,ignore (demonstrates crates.io usage)\n//! extern crate jemallocator;\n//!\n//! use jemallocator::Jemalloc;\n//!\n//! #[global_allocator]\n//! static GLOBAL: Jemalloc = Jemalloc;\n//!\n//! fn main() {}\n//! ```\n//!\n//! The `#[global_allocator]` can only be used once in a crate\n//! or its recursive dependencies.\n\n#![deny(unsafe_op_in_unsafe_fn)]\n#![stable(feature = \"alloc_module\", since = \"1.28.0\")]\n\nuse core::intrinsics;\nuse core::ptr::NonNull;\nuse core::sync::atomic::{AtomicPtr, Ordering};\nuse core::{mem, ptr};\n\n#[stable(feature = \"alloc_module\", since = \"1.28.0\")]\n#[doc(inline)]\npub use alloc_crate::alloc::*;\n\n/// The default memory allocator provided by the operating system.\n///\n/// This is based on `malloc` on Unix platforms and `HeapAlloc` on Windows,\n/// plus related functions.\n///\n/// This type implements the `GlobalAlloc` trait and Rust programs by default\n/// work as if they had this definition:\n///\n/// ```rust\n/// use std::alloc::System;\n///\n/// #[global_allocator]\n/// static A: System = System;\n///\n/// fn main() {\n///     let a = Box::new(4); // Allocates from the system allocator.\n///     println!(\"{}\", a);\n/// }\n/// ```\n///\n/// You can also define your own wrapper around `System` if you'd like, such as\n/// keeping track of the number of all bytes allocated:\n///\n/// ```rust\n/// use std::alloc::{System, GlobalAlloc, Layout};\n/// use std::sync::atomic::{AtomicUsize, Ordering::SeqCst};\n///\n/// struct Counter;\n///\n/// static ALLOCATED: AtomicUsize = AtomicUsize::new(0);\n///\n/// unsafe impl GlobalAlloc for Counter {\n///     unsafe fn alloc(&self, layout: Layout) -> *mut u8 {\n///         let ret = System.alloc(layout);\n///         if !ret.is_null() {\n///             ALLOCATED.fetch_add(layout.size(), SeqCst);\n///         }\n///         return ret\n///     }\n///\n///     unsafe fn dealloc(&self, ptr: *mut u8, layout: Layout) {\n///         System.dealloc(ptr, layout);\n///         ALLOCATED.fetch_sub(layout.size(), SeqCst);\n///     }\n/// }\n///\n/// #[global_allocator]\n/// static A: Counter = Counter;\n///\n/// fn main() {\n///     println!(\"allocated bytes before main: {}\", ALLOCATED.load(SeqCst));\n/// }\n/// ```\n///\n/// It can also be used directly to allocate memory independently of whatever\n/// global allocator has been selected for a Rust program. For example if a Rust\n/// program opts in to using jemalloc as the global allocator, `System` will\n/// still allocate memory using `malloc` and `HeapAlloc`.\n#[stable(feature = \"alloc_system_type\", since = \"1.28.0\")]\n#[derive(Debug, Default, Copy, Clone)]\npub struct System;\n\nimpl System {\n    #[inline]\n    fn alloc_impl(&self, layout: Layout, zeroed: bool) -> Result<NonNull<[u8]>, AllocError> {\n        match layout.size() {\n            0 => Ok(NonNull::slice_from_raw_parts(layout.dangling(), 0)),\n            // SAFETY: `layout` is non-zero in size,\n            size => unsafe {\n                let raw_ptr = if zeroed {\n                    GlobalAlloc::alloc_zeroed(self, layout)\n                } else {\n                    GlobalAlloc::alloc(self, layout)\n                };\n                let ptr = NonNull::new(raw_ptr).ok_or(AllocError)?;\n                Ok(NonNull::slice_from_raw_parts(ptr, size))\n            },\n        }\n    }\n\n    // SAFETY: Same as `Allocator::grow`\n    #[inline]\n    unsafe fn grow_impl(\n        &self,\n        ptr: NonNull<u8>,\n        old_layout: Layout,\n        new_layout: Layout,\n        zeroed: bool,\n    ) -> Result<NonNull<[u8]>, AllocError> {\n        debug_assert!(\n            new_layout.size() >= old_layout.size(),\n            \"`new_layout.size()` must be greater than or equal to `old_layout.size()`\"\n        );\n\n        match old_layout.size() {\n            0 => self.alloc_impl(new_layout, zeroed),\n\n            // SAFETY: `new_size` is non-zero as `new_size` is greater than or equal to `old_size`\n            // as required by safety conditions and the `old_size == 0` case was handled in the\n            // previous match arm. Other conditions must be upheld by the caller\n            old_size if old_layout.align() == new_layout.align() => unsafe {\n                let new_size = new_layout.size();\n\n                // `realloc` probably checks for `new_size >= old_layout.size()` or something similar.\n                intrinsics::assume(new_size >= old_layout.size());\n\n                let raw_ptr = GlobalAlloc::realloc(self, ptr.as_ptr(), old_layout, new_size);\n                let ptr = NonNull::new(raw_ptr).ok_or(AllocError)?;\n                if zeroed {\n                    raw_ptr.add(old_size).write_bytes(0, new_size - old_size);\n                }\n                Ok(NonNull::slice_from_raw_parts(ptr, new_size))\n            },\n\n            // SAFETY: because `new_layout.size()` must be greater than or equal to `old_size`,\n            // both the old and new memory allocation are valid for reads and writes for `old_size`\n            // bytes. Also, because the old allocation wasn't yet deallocated, it cannot overlap\n            // `new_ptr`. Thus, the call to `copy_nonoverlapping` is safe. The safety contract\n            // for `dealloc` must be upheld by the caller.\n            old_size => unsafe {\n                let new_ptr = self.alloc_impl(new_layout, zeroed)?;\n                ptr::copy_nonoverlapping(ptr.as_ptr(), new_ptr.as_mut_ptr(), old_size);\n                Allocator::deallocate(&self, ptr, old_layout);\n                Ok(new_ptr)\n            },\n        }\n    }\n}\n\n// The Allocator impl checks the layout size to be non-zero and forwards to the GlobalAlloc impl,\n// which is in `std::sys::*::alloc`.\n#[unstable(feature = \"allocator_api\", issue = \"32838\")]\nunsafe impl Allocator for System {\n    #[inline]\n    fn allocate(&self, layout: Layout) -> Result<NonNull<[u8]>, AllocError> {\n        self.alloc_impl(layout, false)\n    }\n\n    #[inline]\n    fn allocate_zeroed(&self, layout: Layout) -> Result<NonNull<[u8]>, AllocError> {\n        self.alloc_impl(layout, true)\n    }\n\n    #[inline]\n    unsafe fn deallocate(&self, ptr: NonNull<u8>, layout: Layout) {\n        if layout.size() != 0 {\n            // SAFETY: `layout` is non-zero in size,\n            // other conditions must be upheld by the caller\n            unsafe { GlobalAlloc::dealloc(self, ptr.as_ptr(), layout) }\n        }\n    }\n\n    #[inline]\n    unsafe fn grow(\n        &self,\n        ptr: NonNull<u8>,\n        old_layout: Layout,\n        new_layout: Layout,\n    ) -> Result<NonNull<[u8]>, AllocError> {\n        // SAFETY: all conditions must be upheld by the caller\n        unsafe { self.grow_impl(ptr, old_layout, new_layout, false) }\n    }\n\n    #[inline]\n    unsafe fn grow_zeroed(\n        &self,\n        ptr: NonNull<u8>,\n        old_layout: Layout,\n        new_layout: Layout,\n    ) -> Result<NonNull<[u8]>, AllocError> {\n        // SAFETY: all conditions must be upheld by the caller\n        unsafe { self.grow_impl(ptr, old_layout, new_layout, true) }\n    }\n\n    #[inline]\n    unsafe fn shrink(\n        &self,\n        ptr: NonNull<u8>,\n        old_layout: Layout,\n        new_layout: Layout,\n    ) -> Result<NonNull<[u8]>, AllocError> {\n        debug_assert!(\n            new_layout.size() <= old_layout.size(),\n            \"`new_layout.size()` must be smaller than or equal to `old_layout.size()`\"\n        );\n\n        match new_layout.size() {\n            // SAFETY: conditions must be upheld by the caller\n            0 => unsafe {\n                Allocator::deallocate(&self, ptr, old_layout);\n                Ok(NonNull::slice_from_raw_parts(new_layout.dangling(), 0))\n            },\n\n            // SAFETY: `new_size` is non-zero. Other conditions must be upheld by the caller\n            new_size if old_layout.align() == new_layout.align() => unsafe {\n                // `realloc` probably checks for `new_size <= old_layout.size()` or something similar.\n                intrinsics::assume(new_size <= old_layout.size());\n\n                let raw_ptr = GlobalAlloc::realloc(self, ptr.as_ptr(), old_layout, new_size);\n                let ptr = NonNull::new(raw_ptr).ok_or(AllocError)?;\n                Ok(NonNull::slice_from_raw_parts(ptr, new_size))\n            },\n\n            // SAFETY: because `new_size` must be smaller than or equal to `old_layout.size()`,\n            // both the old and new memory allocation are valid for reads and writes for `new_size`\n            // bytes. Also, because the old allocation wasn't yet deallocated, it cannot overlap\n            // `new_ptr`. Thus, the call to `copy_nonoverlapping` is safe. The safety contract\n            // for `dealloc` must be upheld by the caller.\n            new_size => unsafe {\n                let new_ptr = Allocator::allocate(&self, new_layout)?;\n                ptr::copy_nonoverlapping(ptr.as_ptr(), new_ptr.as_mut_ptr(), new_size);\n                Allocator::deallocate(&self, ptr, old_layout);\n                Ok(new_ptr)\n            },\n        }\n    }\n}\n\nstatic HOOK: AtomicPtr<()> = AtomicPtr::new(ptr::null_mut());\n\n/// Registers a custom allocation error hook, replacing any that was previously registered.\n///\n/// The allocation error hook is invoked when an infallible memory allocation fails, before\n/// the runtime aborts. The default hook prints a message to standard error,\n/// but this behavior can be customized with the [`set_alloc_error_hook`] and\n/// [`take_alloc_error_hook`] functions.\n///\n/// The hook is provided with a `Layout` struct which contains information\n/// about the allocation that failed.\n///\n/// The allocation error hook is a global resource.\n#[unstable(feature = \"alloc_error_hook\", issue = \"51245\")]\npub fn set_alloc_error_hook(hook: fn(Layout)) {\n    HOOK.store(hook as *mut (), Ordering::SeqCst);\n}\n\n/// Unregisters the current allocation error hook, returning it.\n///\n/// *See also the function [`set_alloc_error_hook`].*\n///\n/// If no custom hook is registered, the default hook will be returned.\n#[unstable(feature = \"alloc_error_hook\", issue = \"51245\")]\npub fn take_alloc_error_hook() -> fn(Layout) {\n    let hook = HOOK.swap(ptr::null_mut(), Ordering::SeqCst);\n    if hook.is_null() { default_alloc_error_hook } else { unsafe { mem::transmute(hook) } }\n}\n\nfn default_alloc_error_hook(layout: Layout) {\n    rtprintpanic!(\"memory allocation of {} bytes failed\\n\", layout.size());\n}\n\n#[cfg(not(test))]\n#[doc(hidden)]\n#[alloc_error_handler]\n#[unstable(feature = \"alloc_internals\", issue = \"none\")]\npub fn rust_oom(layout: Layout) -> ! {\n    let hook = HOOK.load(Ordering::SeqCst);\n    let hook: fn(Layout) =\n        if hook.is_null() { default_alloc_error_hook } else { unsafe { mem::transmute(hook) } };\n    hook(layout);\n    crate::process::abort()\n}\n\n#[cfg(not(test))]\n#[doc(hidden)]\n#[allow(unused_attributes)]\n#[unstable(feature = \"alloc_internals\", issue = \"none\")]\npub mod __default_lib_allocator {\n    use super::{GlobalAlloc, Layout, System};\n    // These magic symbol names are used as a fallback for implementing the\n    // `__rust_alloc` etc symbols (see `src/liballoc/alloc.rs`) when there is\n    // no `#[global_allocator]` attribute.\n\n    // for symbol names src/librustc_ast/expand/allocator.rs\n    // for signatures src/librustc_allocator/lib.rs\n\n    // linkage directives are provided as part of the current compiler allocator\n    // ABI\n\n    #[rustc_std_internal_symbol]\n    pub unsafe extern \"C\" fn __rdl_alloc(size: usize, align: usize) -> *mut u8 {\n        // SAFETY: see the guarantees expected by `Layout::from_size_align` and\n        // `GlobalAlloc::alloc`.\n        unsafe {\n            let layout = Layout::from_size_align_unchecked(size, align);\n            System.alloc(layout)\n        }\n    }\n\n    #[rustc_std_internal_symbol]\n    pub unsafe extern \"C\" fn __rdl_dealloc(ptr: *mut u8, size: usize, align: usize) {\n        // SAFETY: see the guarantees expected by `Layout::from_size_align` and\n        // `GlobalAlloc::dealloc`.\n        unsafe { System.dealloc(ptr, Layout::from_size_align_unchecked(size, align)) }\n    }\n\n    #[rustc_std_internal_symbol]\n    pub unsafe extern \"C\" fn __rdl_realloc(\n        ptr: *mut u8,\n        old_size: usize,\n        align: usize,\n        new_size: usize,\n    ) -> *mut u8 {\n        // SAFETY: see the guarantees expected by `Layout::from_size_align` and\n        // `GlobalAlloc::realloc`.\n        unsafe {\n            let old_layout = Layout::from_size_align_unchecked(old_size, align);\n            System.realloc(ptr, old_layout, new_size)\n        }\n    }\n\n    #[rustc_std_internal_symbol]\n    pub unsafe extern \"C\" fn __rdl_alloc_zeroed(size: usize, align: usize) -> *mut u8 {\n        // SAFETY: see the guarantees expected by `Layout::from_size_align` and\n        // `GlobalAlloc::alloc_zeroed`.\n        unsafe {\n            let layout = Layout::from_size_align_unchecked(size, align);\n            System.alloc_zeroed(layout)\n        }\n    }\n}\n"],[2132,"//! Constants specific to the `f32` single-precision floating point type.\n//!\n//! *[See also the `f32` primitive type](primitive@f32).*\n//!\n//! Mathematically significant numbers are provided in the `consts` sub-module.\n//!\n//! For the constants defined directly in this module\n//! (as distinct from those defined in the `consts` sub-module),\n//! new code should instead use the associated constants\n//! defined directly on the `f32` type.\n\n#![stable(feature = \"rust1\", since = \"1.0.0\")]\n#![allow(missing_docs)]\n\n#[cfg(test)]\nmod tests;\n\n#[cfg(not(test))]\nuse crate::intrinsics;\n#[cfg(not(test))]\nuse crate::sys::cmath;\n\n#[stable(feature = \"rust1\", since = \"1.0.0\")]\n#[allow(deprecated, deprecated_in_future)]\npub use core::f32::{\n    consts, DIGITS, EPSILON, INFINITY, MANTISSA_DIGITS, MAX, MAX_10_EXP, MAX_EXP, MIN, MIN_10_EXP,\n    MIN_EXP, MIN_POSITIVE, NAN, NEG_INFINITY, RADIX,\n};\n\n#[cfg(not(test))]\n#[lang = \"f32_runtime\"]\nimpl f32 {\n    /// Returns the largest integer less than or equal to a number.\n    ///\n    /// # Examples\n    ///\n    /// ```\n    /// let f = 3.7_f32;\n    /// let g = 3.0_f32;\n    /// let h = -3.7_f32;\n    ///\n    /// assert_eq!(f.floor(), 3.0);\n    /// assert_eq!(g.floor(), 3.0);\n    /// assert_eq!(h.floor(), -4.0);\n    /// ```\n    #[must_use = \"method returns a new number and does not mutate the original value\"]\n    #[stable(feature = \"rust1\", since = \"1.0.0\")]\n    #[inline]\n    pub fn floor(self) -> f32 {\n        unsafe { intrinsics::floorf32(self) }\n    }\n\n    /// Returns the smallest integer greater than or equal to a number.\n    ///\n    /// # Examples\n    ///\n    /// ```\n    /// let f = 3.01_f32;\n    /// let g = 4.0_f32;\n    ///\n    /// assert_eq!(f.ceil(), 4.0);\n    /// assert_eq!(g.ceil(), 4.0);\n    /// ```\n    #[must_use = \"method returns a new number and does not mutate the original value\"]\n    #[stable(feature = \"rust1\", since = \"1.0.0\")]\n    #[inline]\n    pub fn ceil(self) -> f32 {\n        unsafe { intrinsics::ceilf32(self) }\n    }\n\n    /// Returns the nearest integer to a number. Round half-way cases away from\n    /// `0.0`.\n    ///\n    /// # Examples\n    ///\n    /// ```\n    /// let f = 3.3_f32;\n    /// let g = -3.3_f32;\n    ///\n    /// assert_eq!(f.round(), 3.0);\n    /// assert_eq!(g.round(), -3.0);\n    /// ```\n    #[must_use = \"method returns a new number and does not mutate the original value\"]\n    #[stable(feature = \"rust1\", since = \"1.0.0\")]\n    #[inline]\n    pub fn round(self) -> f32 {\n        unsafe { intrinsics::roundf32(self) }\n    }\n\n    /// Returns the integer part of a number.\n    ///\n    /// # Examples\n    ///\n    /// ```\n    /// let f = 3.7_f32;\n    /// let g = 3.0_f32;\n    /// let h = -3.7_f32;\n    ///\n    /// assert_eq!(f.trunc(), 3.0);\n    /// assert_eq!(g.trunc(), 3.0);\n    /// assert_eq!(h.trunc(), -3.0);\n    /// ```\n    #[must_use = \"method returns a new number and does not mutate the original value\"]\n    #[stable(feature = \"rust1\", since = \"1.0.0\")]\n    #[inline]\n    pub fn trunc(self) -> f32 {\n        unsafe { intrinsics::truncf32(self) }\n    }\n\n    /// Returns the fractional part of a number.\n    ///\n    /// # Examples\n    ///\n    /// ```\n    /// let x = 3.6_f32;\n    /// let y = -3.6_f32;\n    /// let abs_difference_x = (x.fract() - 0.6).abs();\n    /// let abs_difference_y = (y.fract() - (-0.6)).abs();\n    ///\n    /// assert!(abs_difference_x <= f32::EPSILON);\n    /// assert!(abs_difference_y <= f32::EPSILON);\n    /// ```\n    #[must_use = \"method returns a new number and does not mutate the original value\"]\n    #[stable(feature = \"rust1\", since = \"1.0.0\")]\n    #[inline]\n    pub fn fract(self) -> f32 {\n        self - self.trunc()\n    }\n\n    /// Computes the absolute value of `self`. Returns `NAN` if the\n    /// number is `NAN`.\n    ///\n    /// # Examples\n    ///\n    /// ```\n    /// let x = 3.5_f32;\n    /// let y = -3.5_f32;\n    ///\n    /// let abs_difference_x = (x.abs() - x).abs();\n    /// let abs_difference_y = (y.abs() - (-y)).abs();\n    ///\n    /// assert!(abs_difference_x <= f32::EPSILON);\n    /// assert!(abs_difference_y <= f32::EPSILON);\n    ///\n    /// assert!(f32::NAN.abs().is_nan());\n    /// ```\n    #[must_use = \"method returns a new number and does not mutate the original value\"]\n    #[stable(feature = \"rust1\", since = \"1.0.0\")]\n    #[inline]\n    pub fn abs(self) -> f32 {\n        unsafe { intrinsics::fabsf32(self) }\n    }\n\n    /// Returns a number that represents the sign of `self`.\n    ///\n    /// - `1.0` if the number is positive, `+0.0` or `INFINITY`\n    /// - `-1.0` if the number is negative, `-0.0` or `NEG_INFINITY`\n    /// - `NAN` if the number is `NAN`\n    ///\n    /// # Examples\n    ///\n    /// ```\n    /// let f = 3.5_f32;\n    ///\n    /// assert_eq!(f.signum(), 1.0);\n    /// assert_eq!(f32::NEG_INFINITY.signum(), -1.0);\n    ///\n    /// assert!(f32::NAN.signum().is_nan());\n    /// ```\n    #[must_use = \"method returns a new number and does not mutate the original value\"]\n    #[stable(feature = \"rust1\", since = \"1.0.0\")]\n    #[inline]\n    pub fn signum(self) -> f32 {\n        if self.is_nan() { Self::NAN } else { 1.0_f32.copysign(self) }\n    }\n\n    /// Returns a number composed of the magnitude of `self` and the sign of\n    /// `sign`.\n    ///\n    /// Equal to `self` if the sign of `self` and `sign` are the same, otherwise\n    /// equal to `-self`. If `self` is a `NAN`, then a `NAN` with the sign of\n    /// `sign` is returned.\n    ///\n    /// # Examples\n    ///\n    /// ```\n    /// let f = 3.5_f32;\n    ///\n    /// assert_eq!(f.copysign(0.42), 3.5_f32);\n    /// assert_eq!(f.copysign(-0.42), -3.5_f32);\n    /// assert_eq!((-f).copysign(0.42), 3.5_f32);\n    /// assert_eq!((-f).copysign(-0.42), -3.5_f32);\n    ///\n    /// assert!(f32::NAN.copysign(1.0).is_nan());\n    /// ```\n    #[must_use = \"method returns a new number and does not mutate the original value\"]\n    #[inline]\n    #[stable(feature = \"copysign\", since = \"1.35.0\")]\n    pub fn copysign(self, sign: f32) -> f32 {\n        unsafe { intrinsics::copysignf32(self, sign) }\n    }\n\n    /// Fused multiply-add. Computes `(self * a) + b` with only one rounding\n    /// error, yielding a more accurate result than an unfused multiply-add.\n    ///\n    /// Using `mul_add` *may* be more performant than an unfused multiply-add if\n    /// the target architecture has a dedicated `fma` CPU instruction. However,\n    /// this is not always true, and will be heavily dependant on designing\n    /// algorithms with specific target hardware in mind.\n    ///\n    /// # Examples\n    ///\n    /// ```\n    /// let m = 10.0_f32;\n    /// let x = 4.0_f32;\n    /// let b = 60.0_f32;\n    ///\n    /// // 100.0\n    /// let abs_difference = (m.mul_add(x, b) - ((m * x) + b)).abs();\n    ///\n    /// assert!(abs_difference <= f32::EPSILON);\n    /// ```\n    #[must_use = \"method returns a new number and does not mutate the original value\"]\n    #[stable(feature = \"rust1\", since = \"1.0.0\")]\n    #[inline]\n    pub fn mul_add(self, a: f32, b: f32) -> f32 {\n        unsafe { intrinsics::fmaf32(self, a, b) }\n    }\n\n    /// Calculates Euclidean division, the matching method for `rem_euclid`.\n    ///\n    /// This computes the integer `n` such that\n    /// `self = n * rhs + self.rem_euclid(rhs)`.\n    /// In other words, the result is `self / rhs` rounded to the integer `n`\n    /// such that `self >= n * rhs`.\n    ///\n    /// # Examples\n    ///\n    /// ```\n    /// let a: f32 = 7.0;\n    /// let b = 4.0;\n    /// assert_eq!(a.div_euclid(b), 1.0); // 7.0 > 4.0 * 1.0\n    /// assert_eq!((-a).div_euclid(b), -2.0); // -7.0 >= 4.0 * -2.0\n    /// assert_eq!(a.div_euclid(-b), -1.0); // 7.0 >= -4.0 * -1.0\n    /// assert_eq!((-a).div_euclid(-b), 2.0); // -7.0 >= -4.0 * 2.0\n    /// ```\n    #[must_use = \"method returns a new number and does not mutate the original value\"]\n    #[inline]\n    #[stable(feature = \"euclidean_division\", since = \"1.38.0\")]\n    pub fn div_euclid(self, rhs: f32) -> f32 {\n        let q = (self / rhs).trunc();\n        if self % rhs < 0.0 {\n            return if rhs > 0.0 { q - 1.0 } else { q + 1.0 };\n        }\n        q\n    }\n\n    /// Calculates the least nonnegative remainder of `self (mod rhs)`.\n    ///\n    /// In particular, the return value `r` satisfies `0.0 <= r < rhs.abs()` in\n    /// most cases. However, due to a floating point round-off error it can\n    /// result in `r == rhs.abs()`, violating the mathematical definition, if\n    /// `self` is much smaller than `rhs.abs()` in magnitude and `self < 0.0`.\n    /// This result is not an element of the function's codomain, but it is the\n    /// closest floating point number in the real numbers and thus fulfills the\n    /// property `self == self.div_euclid(rhs) * rhs + self.rem_euclid(rhs)`\n    /// approximatively.\n    ///\n    /// # Examples\n    ///\n    /// ```\n    /// let a: f32 = 7.0;\n    /// let b = 4.0;\n    /// assert_eq!(a.rem_euclid(b), 3.0);\n    /// assert_eq!((-a).rem_euclid(b), 1.0);\n    /// assert_eq!(a.rem_euclid(-b), 3.0);\n    /// assert_eq!((-a).rem_euclid(-b), 1.0);\n    /// // limitation due to round-off error\n    /// assert!((-f32::EPSILON).rem_euclid(3.0) != 0.0);\n    /// ```\n    #[must_use = \"method returns a new number and does not mutate the original value\"]\n    #[inline]\n    #[stable(feature = \"euclidean_division\", since = \"1.38.0\")]\n    pub fn rem_euclid(self, rhs: f32) -> f32 {\n        let r = self % rhs;\n        if r < 0.0 { r + rhs.abs() } else { r }\n    }\n\n    /// Raises a number to an integer power.\n    ///\n    /// Using this function is generally faster than using `powf`\n    ///\n    /// # Examples\n    ///\n    /// ```\n    /// let x = 2.0_f32;\n    /// let abs_difference = (x.powi(2) - (x * x)).abs();\n    ///\n    /// assert!(abs_difference <= f32::EPSILON);\n    /// ```\n    #[must_use = \"method returns a new number and does not mutate the original value\"]\n    #[stable(feature = \"rust1\", since = \"1.0.0\")]\n    #[inline]\n    pub fn powi(self, n: i32) -> f32 {\n        unsafe { intrinsics::powif32(self, n) }\n    }\n\n    /// Raises a number to a floating point power.\n    ///\n    /// # Examples\n    ///\n    /// ```\n    /// let x = 2.0_f32;\n    /// let abs_difference = (x.powf(2.0) - (x * x)).abs();\n    ///\n    /// assert!(abs_difference <= f32::EPSILON);\n    /// ```\n    #[must_use = \"method returns a new number and does not mutate the original value\"]\n    #[stable(feature = \"rust1\", since = \"1.0.0\")]\n    #[inline]\n    pub fn powf(self, n: f32) -> f32 {\n        unsafe { intrinsics::powf32(self, n) }\n    }\n\n    /// Returns the square root of a number.\n    ///\n    /// Returns NaN if `self` is a negative number.\n    ///\n    /// # Examples\n    ///\n    /// ```\n    /// let positive = 4.0_f32;\n    /// let negative = -4.0_f32;\n    ///\n    /// let abs_difference = (positive.sqrt() - 2.0).abs();\n    ///\n    /// assert!(abs_difference <= f32::EPSILON);\n    /// assert!(negative.sqrt().is_nan());\n    /// ```\n    #[must_use = \"method returns a new number and does not mutate the original value\"]\n    #[stable(feature = \"rust1\", since = \"1.0.0\")]\n    #[inline]\n    pub fn sqrt(self) -> f32 {\n        unsafe { intrinsics::sqrtf32(self) }\n    }\n\n    /// Returns `e^(self)`, (the exponential function).\n    ///\n    /// # Examples\n    ///\n    /// ```\n    /// let one = 1.0f32;\n    /// // e^1\n    /// let e = one.exp();\n    ///\n    /// // ln(e) - 1 == 0\n    /// let abs_difference = (e.ln() - 1.0).abs();\n    ///\n    /// assert!(abs_difference <= f32::EPSILON);\n    /// ```\n    #[must_use = \"method returns a new number and does not mutate the original value\"]\n    #[stable(feature = \"rust1\", since = \"1.0.0\")]\n    #[inline]\n    pub fn exp(self) -> f32 {\n        unsafe { intrinsics::expf32(self) }\n    }\n\n    /// Returns `2^(self)`.\n    ///\n    /// # Examples\n    ///\n    /// ```\n    /// let f = 2.0f32;\n    ///\n    /// // 2^2 - 4 == 0\n    /// let abs_difference = (f.exp2() - 4.0).abs();\n    ///\n    /// assert!(abs_difference <= f32::EPSILON);\n    /// ```\n    #[must_use = \"method returns a new number and does not mutate the original value\"]\n    #[stable(feature = \"rust1\", since = \"1.0.0\")]\n    #[inline]\n    pub fn exp2(self) -> f32 {\n        unsafe { intrinsics::exp2f32(self) }\n    }\n\n    /// Returns the natural logarithm of the number.\n    ///\n    /// # Examples\n    ///\n    /// ```\n    /// let one = 1.0f32;\n    /// // e^1\n    /// let e = one.exp();\n    ///\n    /// // ln(e) - 1 == 0\n    /// let abs_difference = (e.ln() - 1.0).abs();\n    ///\n    /// assert!(abs_difference <= f32::EPSILON);\n    /// ```\n    #[must_use = \"method returns a new number and does not mutate the original value\"]\n    #[stable(feature = \"rust1\", since = \"1.0.0\")]\n    #[inline]\n    pub fn ln(self) -> f32 {\n        unsafe { intrinsics::logf32(self) }\n    }\n\n    /// Returns the logarithm of the number with respect to an arbitrary base.\n    ///\n    /// The result may not be correctly rounded owing to implementation details;\n    /// `self.log2()` can produce more accurate results for base 2, and\n    /// `self.log10()` can produce more accurate results for base 10.\n    ///\n    /// # Examples\n    ///\n    /// ```\n    /// let five = 5.0f32;\n    ///\n    /// // log5(5) - 1 == 0\n    /// let abs_difference = (five.log(5.0) - 1.0).abs();\n    ///\n    /// assert!(abs_difference <= f32::EPSILON);\n    /// ```\n    #[must_use = \"method returns a new number and does not mutate the original value\"]\n    #[stable(feature = \"rust1\", since = \"1.0.0\")]\n    #[inline]\n    pub fn log(self, base: f32) -> f32 {\n        self.ln() / base.ln()\n    }\n\n    /// Returns the base 2 logarithm of the number.\n    ///\n    /// # Examples\n    ///\n    /// ```\n    /// let two = 2.0f32;\n    ///\n    /// // log2(2) - 1 == 0\n    /// let abs_difference = (two.log2() - 1.0).abs();\n    ///\n    /// assert!(abs_difference <= f32::EPSILON);\n    /// ```\n    #[must_use = \"method returns a new number and does not mutate the original value\"]\n    #[stable(feature = \"rust1\", since = \"1.0.0\")]\n    #[inline]\n    pub fn log2(self) -> f32 {\n        #[cfg(target_os = \"android\")]\n        return crate::sys::android::log2f32(self);\n        #[cfg(not(target_os = \"android\"))]\n        return unsafe { intrinsics::log2f32(self) };\n    }\n\n    /// Returns the base 10 logarithm of the number.\n    ///\n    /// # Examples\n    ///\n    /// ```\n    /// let ten = 10.0f32;\n    ///\n    /// // log10(10) - 1 == 0\n    /// let abs_difference = (ten.log10() - 1.0).abs();\n    ///\n    /// assert!(abs_difference <= f32::EPSILON);\n    /// ```\n    #[must_use = \"method returns a new number and does not mutate the original value\"]\n    #[stable(feature = \"rust1\", since = \"1.0.0\")]\n    #[inline]\n    pub fn log10(self) -> f32 {\n        unsafe { intrinsics::log10f32(self) }\n    }\n\n    /// The positive difference of two numbers.\n    ///\n    /// * If `self <= other`: `0:0`\n    /// * Else: `self - other`\n    ///\n    /// # Examples\n    ///\n    /// ```\n    /// let x = 3.0f32;\n    /// let y = -3.0f32;\n    ///\n    /// let abs_difference_x = (x.abs_sub(1.0) - 2.0).abs();\n    /// let abs_difference_y = (y.abs_sub(1.0) - 0.0).abs();\n    ///\n    /// assert!(abs_difference_x <= f32::EPSILON);\n    /// assert!(abs_difference_y <= f32::EPSILON);\n    /// ```\n    #[must_use = \"method returns a new number and does not mutate the original value\"]\n    #[stable(feature = \"rust1\", since = \"1.0.0\")]\n    #[inline]\n    #[rustc_deprecated(\n        since = \"1.10.0\",\n        reason = \"you probably meant `(self - other).abs()`: \\\n                  this operation is `(self - other).max(0.0)` \\\n                  except that `abs_sub` also propagates NaNs (also \\\n                  known as `fdimf` in C). If you truly need the positive \\\n                  difference, consider using that expression or the C function \\\n                  `fdimf`, depending on how you wish to handle NaN (please consider \\\n                  filing an issue describing your use-case too).\"\n    )]\n    pub fn abs_sub(self, other: f32) -> f32 {\n        unsafe { cmath::fdimf(self, other) }\n    }\n\n    /// Returns the cube root of a number.\n    ///\n    /// # Examples\n    ///\n    /// ```\n    /// let x = 8.0f32;\n    ///\n    /// // x^(1/3) - 2 == 0\n    /// let abs_difference = (x.cbrt() - 2.0).abs();\n    ///\n    /// assert!(abs_difference <= f32::EPSILON);\n    /// ```\n    #[must_use = \"method returns a new number and does not mutate the original value\"]\n    #[stable(feature = \"rust1\", since = \"1.0.0\")]\n    #[inline]\n    pub fn cbrt(self) -> f32 {\n        unsafe { cmath::cbrtf(self) }\n    }\n\n    /// Calculates the length of the hypotenuse of a right-angle triangle given\n    /// legs of length `x` and `y`.\n    ///\n    /// # Examples\n    ///\n    /// ```\n    /// let x = 2.0f32;\n    /// let y = 3.0f32;\n    ///\n    /// // sqrt(x^2 + y^2)\n    /// let abs_difference = (x.hypot(y) - (x.powi(2) + y.powi(2)).sqrt()).abs();\n    ///\n    /// assert!(abs_difference <= f32::EPSILON);\n    /// ```\n    #[must_use = \"method returns a new number and does not mutate the original value\"]\n    #[stable(feature = \"rust1\", since = \"1.0.0\")]\n    #[inline]\n    pub fn hypot(self, other: f32) -> f32 {\n        unsafe { cmath::hypotf(self, other) }\n    }\n\n    /// Computes the sine of a number (in radians).\n    ///\n    /// # Examples\n    ///\n    /// ```\n    /// let x = std::f32::consts::FRAC_PI_2;\n    ///\n    /// let abs_difference = (x.sin() - 1.0).abs();\n    ///\n    /// assert!(abs_difference <= f32::EPSILON);\n    /// ```\n    #[must_use = \"method returns a new number and does not mutate the original value\"]\n    #[stable(feature = \"rust1\", since = \"1.0.0\")]\n    #[inline]\n    pub fn sin(self) -> f32 {\n        unsafe { intrinsics::sinf32(self) }\n    }\n\n    /// Computes the cosine of a number (in radians).\n    ///\n    /// # Examples\n    ///\n    /// ```\n    /// let x = 2.0 * std::f32::consts::PI;\n    ///\n    /// let abs_difference = (x.cos() - 1.0).abs();\n    ///\n    /// assert!(abs_difference <= f32::EPSILON);\n    /// ```\n    #[must_use = \"method returns a new number and does not mutate the original value\"]\n    #[stable(feature = \"rust1\", since = \"1.0.0\")]\n    #[inline]\n    pub fn cos(self) -> f32 {\n        unsafe { intrinsics::cosf32(self) }\n    }\n\n    /// Computes the tangent of a number (in radians).\n    ///\n    /// # Examples\n    ///\n    /// ```\n    /// let x = std::f32::consts::FRAC_PI_4;\n    /// let abs_difference = (x.tan() - 1.0).abs();\n    ///\n    /// assert!(abs_difference <= f32::EPSILON);\n    /// ```\n    #[must_use = \"method returns a new number and does not mutate the original value\"]\n    #[stable(feature = \"rust1\", since = \"1.0.0\")]\n    #[inline]\n    pub fn tan(self) -> f32 {\n        unsafe { cmath::tanf(self) }\n    }\n\n    /// Computes the arcsine of a number. Return value is in radians in\n    /// the range [-pi/2, pi/2] or NaN if the number is outside the range\n    /// [-1, 1].\n    ///\n    /// # Examples\n    ///\n    /// ```\n    /// let f = std::f32::consts::FRAC_PI_2;\n    ///\n    /// // asin(sin(pi/2))\n    /// let abs_difference = (f.sin().asin() - std::f32::consts::FRAC_PI_2).abs();\n    ///\n    /// assert!(abs_difference <= f32::EPSILON);\n    /// ```\n    #[must_use = \"method returns a new number and does not mutate the original value\"]\n    #[stable(feature = \"rust1\", since = \"1.0.0\")]\n    #[inline]\n    pub fn asin(self) -> f32 {\n        unsafe { cmath::asinf(self) }\n    }\n\n    /// Computes the arccosine of a number. Return value is in radians in\n    /// the range [0, pi] or NaN if the number is outside the range\n    /// [-1, 1].\n    ///\n    /// # Examples\n    ///\n    /// ```\n    /// let f = std::f32::consts::FRAC_PI_4;\n    ///\n    /// // acos(cos(pi/4))\n    /// let abs_difference = (f.cos().acos() - std::f32::consts::FRAC_PI_4).abs();\n    ///\n    /// assert!(abs_difference <= f32::EPSILON);\n    /// ```\n    #[must_use = \"method returns a new number and does not mutate the original value\"]\n    #[stable(feature = \"rust1\", since = \"1.0.0\")]\n    #[inline]\n    pub fn acos(self) -> f32 {\n        unsafe { cmath::acosf(self) }\n    }\n\n    /// Computes the arctangent of a number. Return value is in radians in the\n    /// range [-pi/2, pi/2];\n    ///\n    /// # Examples\n    ///\n    /// ```\n    /// let f = 1.0f32;\n    ///\n    /// // atan(tan(1))\n    /// let abs_difference = (f.tan().atan() - 1.0).abs();\n    ///\n    /// assert!(abs_difference <= f32::EPSILON);\n    /// ```\n    #[must_use = \"method returns a new number and does not mutate the original value\"]\n    #[stable(feature = \"rust1\", since = \"1.0.0\")]\n    #[inline]\n    pub fn atan(self) -> f32 {\n        unsafe { cmath::atanf(self) }\n    }\n\n    /// Computes the four quadrant arctangent of `self` (`y`) and `other` (`x`) in radians.\n    ///\n    /// * `x = 0`, `y = 0`: `0`\n    /// * `x >= 0`: `arctan(y/x)` -> `[-pi/2, pi/2]`\n    /// * `y >= 0`: `arctan(y/x) + pi` -> `(pi/2, pi]`\n    /// * `y < 0`: `arctan(y/x) - pi` -> `(-pi, -pi/2)`\n    ///\n    /// # Examples\n    ///\n    /// ```\n    /// // Positive angles measured counter-clockwise\n    /// // from positive x axis\n    /// // -pi/4 radians (45 deg clockwise)\n    /// let x1 = 3.0f32;\n    /// let y1 = -3.0f32;\n    ///\n    /// // 3pi/4 radians (135 deg counter-clockwise)\n    /// let x2 = -3.0f32;\n    /// let y2 = 3.0f32;\n    ///\n    /// let abs_difference_1 = (y1.atan2(x1) - (-std::f32::consts::FRAC_PI_4)).abs();\n    /// let abs_difference_2 = (y2.atan2(x2) - (3.0 * std::f32::consts::FRAC_PI_4)).abs();\n    ///\n    /// assert!(abs_difference_1 <= f32::EPSILON);\n    /// assert!(abs_difference_2 <= f32::EPSILON);\n    /// ```\n    #[must_use = \"method returns a new number and does not mutate the original value\"]\n    #[stable(feature = \"rust1\", since = \"1.0.0\")]\n    #[inline]\n    pub fn atan2(self, other: f32) -> f32 {\n        unsafe { cmath::atan2f(self, other) }\n    }\n\n    /// Simultaneously computes the sine and cosine of the number, `x`. Returns\n    /// `(sin(x), cos(x))`.\n    ///\n    /// # Examples\n    ///\n    /// ```\n    /// let x = std::f32::consts::FRAC_PI_4;\n    /// let f = x.sin_cos();\n    ///\n    /// let abs_difference_0 = (f.0 - x.sin()).abs();\n    /// let abs_difference_1 = (f.1 - x.cos()).abs();\n    ///\n    /// assert!(abs_difference_0 <= f32::EPSILON);\n    /// assert!(abs_difference_1 <= f32::EPSILON);\n    /// ```\n    #[stable(feature = \"rust1\", since = \"1.0.0\")]\n    #[inline]\n    pub fn sin_cos(self) -> (f32, f32) {\n        (self.sin(), self.cos())\n    }\n\n    /// Returns `e^(self) - 1` in a way that is accurate even if the\n    /// number is close to zero.\n    ///\n    /// # Examples\n    ///\n    /// ```\n    /// let x = 1e-8_f32;\n    ///\n    /// // for very small x, e^x is approximately 1 + x + x^2 / 2\n    /// let approx = x + x * x / 2.0;\n    /// let abs_difference = (x.exp_m1() - approx).abs();\n    ///\n    /// assert!(abs_difference < 1e-10);\n    /// ```\n    #[must_use = \"method returns a new number and does not mutate the original value\"]\n    #[stable(feature = \"rust1\", since = \"1.0.0\")]\n    #[inline]\n    pub fn exp_m1(self) -> f32 {\n        unsafe { cmath::expm1f(self) }\n    }\n\n    /// Returns `ln(1+n)` (natural logarithm) more accurately than if\n    /// the operations were performed separately.\n    ///\n    /// # Examples\n    ///\n    /// ```\n    /// let x = 1e-8_f32;\n    ///\n    /// // for very small x, ln(1 + x) is approximately x - x^2 / 2\n    /// let approx = x - x * x / 2.0;\n    /// let abs_difference = (x.ln_1p() - approx).abs();\n    ///\n    /// assert!(abs_difference < 1e-10);\n    /// ```\n    #[must_use = \"method returns a new number and does not mutate the original value\"]\n    #[stable(feature = \"rust1\", since = \"1.0.0\")]\n    #[inline]\n    pub fn ln_1p(self) -> f32 {\n        unsafe { cmath::log1pf(self) }\n    }\n\n    /// Hyperbolic sine function.\n    ///\n    /// # Examples\n    ///\n    /// ```\n    /// let e = std::f32::consts::E;\n    /// let x = 1.0f32;\n    ///\n    /// let f = x.sinh();\n    /// // Solving sinh() at 1 gives `(e^2-1)/(2e)`\n    /// let g = ((e * e) - 1.0) / (2.0 * e);\n    /// let abs_difference = (f - g).abs();\n    ///\n    /// assert!(abs_difference <= f32::EPSILON);\n    /// ```\n    #[must_use = \"method returns a new number and does not mutate the original value\"]\n    #[stable(feature = \"rust1\", since = \"1.0.0\")]\n    #[inline]\n    pub fn sinh(self) -> f32 {\n        unsafe { cmath::sinhf(self) }\n    }\n\n    /// Hyperbolic cosine function.\n    ///\n    /// # Examples\n    ///\n    /// ```\n    /// let e = std::f32::consts::E;\n    /// let x = 1.0f32;\n    /// let f = x.cosh();\n    /// // Solving cosh() at 1 gives this result\n    /// let g = ((e * e) + 1.0) / (2.0 * e);\n    /// let abs_difference = (f - g).abs();\n    ///\n    /// // Same result\n    /// assert!(abs_difference <= f32::EPSILON);\n    /// ```\n    #[must_use = \"method returns a new number and does not mutate the original value\"]\n    #[stable(feature = \"rust1\", since = \"1.0.0\")]\n    #[inline]\n    pub fn cosh(self) -> f32 {\n        unsafe { cmath::coshf(self) }\n    }\n\n    /// Hyperbolic tangent function.\n    ///\n    /// # Examples\n    ///\n    /// ```\n    /// let e = std::f32::consts::E;\n    /// let x = 1.0f32;\n    ///\n    /// let f = x.tanh();\n    /// // Solving tanh() at 1 gives `(1 - e^(-2))/(1 + e^(-2))`\n    /// let g = (1.0 - e.powi(-2)) / (1.0 + e.powi(-2));\n    /// let abs_difference = (f - g).abs();\n    ///\n    /// assert!(abs_difference <= f32::EPSILON);\n    /// ```\n    #[must_use = \"method returns a new number and does not mutate the original value\"]\n    #[stable(feature = \"rust1\", since = \"1.0.0\")]\n    #[inline]\n    pub fn tanh(self) -> f32 {\n        unsafe { cmath::tanhf(self) }\n    }\n\n    /// Inverse hyperbolic sine function.\n    ///\n    /// # Examples\n    ///\n    /// ```\n    /// let x = 1.0f32;\n    /// let f = x.sinh().asinh();\n    ///\n    /// let abs_difference = (f - x).abs();\n    ///\n    /// assert!(abs_difference <= f32::EPSILON);\n    /// ```\n    #[must_use = \"method returns a new number and does not mutate the original value\"]\n    #[stable(feature = \"rust1\", since = \"1.0.0\")]\n    #[inline]\n    pub fn asinh(self) -> f32 {\n        (self.abs() + ((self * self) + 1.0).sqrt()).ln().copysign(self)\n    }\n\n    /// Inverse hyperbolic cosine function.\n    ///\n    /// # Examples\n    ///\n    /// ```\n    /// let x = 1.0f32;\n    /// let f = x.cosh().acosh();\n    ///\n    /// let abs_difference = (f - x).abs();\n    ///\n    /// assert!(abs_difference <= f32::EPSILON);\n    /// ```\n    #[must_use = \"method returns a new number and does not mutate the original value\"]\n    #[stable(feature = \"rust1\", since = \"1.0.0\")]\n    #[inline]\n    pub fn acosh(self) -> f32 {\n        if self < 1.0 { Self::NAN } else { (self + ((self * self) - 1.0).sqrt()).ln() }\n    }\n\n    /// Inverse hyperbolic tangent function.\n    ///\n    /// # Examples\n    ///\n    /// ```\n    /// let e = std::f32::consts::E;\n    /// let f = e.tanh().atanh();\n    ///\n    /// let abs_difference = (f - e).abs();\n    ///\n    /// assert!(abs_difference <= 1e-5);\n    /// ```\n    #[must_use = \"method returns a new number and does not mutate the original value\"]\n    #[stable(feature = \"rust1\", since = \"1.0.0\")]\n    #[inline]\n    pub fn atanh(self) -> f32 {\n        0.5 * ((2.0 * self) / (1.0 - self)).ln_1p()\n    }\n\n    /// Linear interpolation between `start` and `end`.\n    ///\n    /// This enables linear interpolation between `start` and `end`, where start is represented by\n    /// `self == 0.0` and `end` is represented by `self == 1.0`. This is the basis of all\n    /// \"transition\", \"easing\", or \"step\" functions; if you change `self` from 0.0 to 1.0\n    /// at a given rate, the result will change from `start` to `end` at a similar rate.\n    ///\n    /// Values below 0.0 or above 1.0 are allowed, allowing you to extrapolate values outside the\n    /// range from `start` to `end`. This also is useful for transition functions which might\n    /// move slightly past the end or start for a desired effect. Mathematically, the values\n    /// returned are equivalent to `start + self * (end - start)`, although we make a few specific\n    /// guarantees that are useful specifically to linear interpolation.\n    ///\n    /// These guarantees are:\n    ///\n    /// * If `start` and `end` are [finite], the value at 0.0 is always `start` and the\n    ///   value at 1.0 is always `end`. (exactness)\n    /// * If `start` and `end` are [finite], the values will always move in the direction from\n    ///   `start` to `end` (monotonicity)\n    /// * If `self` is [finite] and `start == end`, the value at any point will always be\n    ///   `start == end`. (consistency)\n    ///\n    /// [finite]: #method.is_finite\n    #[must_use = \"method returns a new number and does not mutate the original value\"]\n    #[unstable(feature = \"float_interpolation\", issue = \"86269\")]\n    pub fn lerp(self, start: f32, end: f32) -> f32 {\n        // consistent\n        if start == end {\n            start\n\n        // exact/monotonic\n        } else {\n            self.mul_add(end, (-self).mul_add(start, start))\n        }\n    }\n}\n"],[2133,"//! macOS-specific raw type definitions\n\n#![stable(feature = \"raw_ext\", since = \"1.1.0\")]\n#![rustc_deprecated(\n    since = \"1.8.0\",\n    reason = \"these type aliases are no longer supported by \\\n              the standard library, the `libc` crate on \\\n              crates.io should be used instead for the correct \\\n              definitions\"\n)]\n#![allow(deprecated)]\n\nuse crate::os::raw::c_long;\n\n#[stable(feature = \"raw_ext\", since = \"1.1.0\")]\npub type blkcnt_t = u64;\n#[stable(feature = \"raw_ext\", since = \"1.1.0\")]\npub type blksize_t = u64;\n#[stable(feature = \"raw_ext\", since = \"1.1.0\")]\npub type dev_t = u64;\n#[stable(feature = \"raw_ext\", since = \"1.1.0\")]\npub type ino_t = u64;\n#[stable(feature = \"raw_ext\", since = \"1.1.0\")]\npub type mode_t = u32;\n#[stable(feature = \"raw_ext\", since = \"1.1.0\")]\npub type nlink_t = u64;\n#[stable(feature = \"raw_ext\", since = \"1.1.0\")]\npub type off_t = u64;\n#[stable(feature = \"raw_ext\", since = \"1.1.0\")]\npub type time_t = i64;\n\n#[stable(feature = \"pthread_t\", since = \"1.8.0\")]\npub type pthread_t = usize;\n\n#[repr(C)]\n#[derive(Clone)]\n#[stable(feature = \"raw_ext\", since = \"1.1.0\")]\npub struct stat {\n    #[stable(feature = \"raw_ext\", since = \"1.1.0\")]\n    pub st_dev: i32,\n    #[stable(feature = \"raw_ext\", since = \"1.1.0\")]\n    pub st_mode: u16,\n    #[stable(feature = \"raw_ext\", since = \"1.1.0\")]\n    pub st_nlink: u16,\n    #[stable(feature = \"raw_ext\", since = \"1.1.0\")]\n    pub st_ino: u64,\n    #[stable(feature = \"raw_ext\", since = \"1.1.0\")]\n    pub st_uid: u32,\n    #[stable(feature = \"raw_ext\", since = \"1.1.0\")]\n    pub st_gid: u32,\n    #[stable(feature = \"raw_ext\", since = \"1.1.0\")]\n    pub st_rdev: i32,\n    #[stable(feature = \"raw_ext\", since = \"1.1.0\")]\n    pub st_atime: c_long,\n    #[stable(feature = \"raw_ext\", since = \"1.1.0\")]\n    pub st_atime_nsec: c_long,\n    #[stable(feature = \"raw_ext\", since = \"1.1.0\")]\n    pub st_mtime: c_long,\n    #[stable(feature = \"raw_ext\", since = \"1.1.0\")]\n    pub st_mtime_nsec: c_long,\n    #[stable(feature = \"raw_ext\", since = \"1.1.0\")]\n    pub st_ctime: c_long,\n    #[stable(feature = \"raw_ext\", since = \"1.1.0\")]\n    pub st_ctime_nsec: c_long,\n    #[stable(feature = \"raw_ext\", since = \"1.1.0\")]\n    pub st_birthtime: c_long,\n    #[stable(feature = \"raw_ext\", since = \"1.1.0\")]\n    pub st_birthtime_nsec: c_long,\n    #[stable(feature = \"raw_ext\", since = \"1.1.0\")]\n    pub st_size: i64,\n    #[stable(feature = \"raw_ext\", since = \"1.1.0\")]\n    pub st_blocks: i64,\n    #[stable(feature = \"raw_ext\", since = \"1.1.0\")]\n    pub st_blksize: i32,\n    #[stable(feature = \"raw_ext\", since = \"1.1.0\")]\n    pub st_flags: u32,\n    #[stable(feature = \"raw_ext\", since = \"1.1.0\")]\n    pub st_gen: u32,\n    #[stable(feature = \"raw_ext\", since = \"1.1.0\")]\n    pub st_lspare: i32,\n    #[stable(feature = \"raw_ext\", since = \"1.1.0\")]\n    pub st_qspare: [i64; 2],\n}\n"],[2134,"#![stable(feature = \"metadata_ext\", since = \"1.1.0\")]\n\nuse crate::fs::Metadata;\nuse crate::sys_common::AsInner;\n\n#[allow(deprecated)]\nuse crate::os::macos::raw;\n\n/// OS-specific extensions to [`fs::Metadata`].\n///\n/// [`fs::Metadata`]: crate::fs::Metadata\n#[stable(feature = \"metadata_ext\", since = \"1.1.0\")]\npub trait MetadataExt {\n    /// Gain a reference to the underlying `stat` structure which contains\n    /// the raw information returned by the OS.\n    ///\n    /// The contents of the returned `stat` are **not** consistent across\n    /// Unix platforms. The `os::unix::fs::MetadataExt` trait contains the\n    /// cross-Unix abstractions contained within the raw stat.\n    #[stable(feature = \"metadata_ext\", since = \"1.1.0\")]\n    #[rustc_deprecated(\n        since = \"1.8.0\",\n        reason = \"deprecated in favor of the accessor \\\n                  methods of this trait\"\n    )]\n    #[allow(deprecated)]\n    fn as_raw_stat(&self) -> &raw::stat;\n\n    #[stable(feature = \"metadata_ext2\", since = \"1.8.0\")]\n    fn st_dev(&self) -> u64;\n    #[stable(feature = \"metadata_ext2\", since = \"1.8.0\")]\n    fn st_ino(&self) -> u64;\n    #[stable(feature = \"metadata_ext2\", since = \"1.8.0\")]\n    fn st_mode(&self) -> u32;\n    #[stable(feature = \"metadata_ext2\", since = \"1.8.0\")]\n    fn st_nlink(&self) -> u64;\n    #[stable(feature = \"metadata_ext2\", since = \"1.8.0\")]\n    fn st_uid(&self) -> u32;\n    #[stable(feature = \"metadata_ext2\", since = \"1.8.0\")]\n    fn st_gid(&self) -> u32;\n    #[stable(feature = \"metadata_ext2\", since = \"1.8.0\")]\n    fn st_rdev(&self) -> u64;\n    #[stable(feature = \"metadata_ext2\", since = \"1.8.0\")]\n    fn st_size(&self) -> u64;\n    #[stable(feature = \"metadata_ext2\", since = \"1.8.0\")]\n    fn st_atime(&self) -> i64;\n    #[stable(feature = \"metadata_ext2\", since = \"1.8.0\")]\n    fn st_atime_nsec(&self) -> i64;\n    #[stable(feature = \"metadata_ext2\", since = \"1.8.0\")]\n    fn st_mtime(&self) -> i64;\n    #[stable(feature = \"metadata_ext2\", since = \"1.8.0\")]\n    fn st_mtime_nsec(&self) -> i64;\n    #[stable(feature = \"metadata_ext2\", since = \"1.8.0\")]\n    fn st_ctime(&self) -> i64;\n    #[stable(feature = \"metadata_ext2\", since = \"1.8.0\")]\n    fn st_ctime_nsec(&self) -> i64;\n    #[stable(feature = \"metadata_ext2\", since = \"1.8.0\")]\n    fn st_birthtime(&self) -> i64;\n    #[stable(feature = \"metadata_ext2\", since = \"1.8.0\")]\n    fn st_birthtime_nsec(&self) -> i64;\n    #[stable(feature = \"metadata_ext2\", since = \"1.8.0\")]\n    fn st_blksize(&self) -> u64;\n    #[stable(feature = \"metadata_ext2\", since = \"1.8.0\")]\n    fn st_blocks(&self) -> u64;\n    #[stable(feature = \"metadata_ext2\", since = \"1.8.0\")]\n    fn st_flags(&self) -> u32;\n    #[stable(feature = \"metadata_ext2\", since = \"1.8.0\")]\n    fn st_gen(&self) -> u32;\n    #[stable(feature = \"metadata_ext2\", since = \"1.8.0\")]\n    fn st_lspare(&self) -> u32;\n    #[stable(feature = \"metadata_ext2\", since = \"1.8.0\")]\n    fn st_qspare(&self) -> [u64; 2];\n}\n\n#[stable(feature = \"metadata_ext\", since = \"1.1.0\")]\nimpl MetadataExt for Metadata {\n    #[allow(deprecated)]\n    fn as_raw_stat(&self) -> &raw::stat {\n        unsafe { &*(self.as_inner().as_inner() as *const libc::stat as *const raw::stat) }\n    }\n    fn st_dev(&self) -> u64 {\n        self.as_inner().as_inner().st_dev as u64\n    }\n    fn st_ino(&self) -> u64 {\n        self.as_inner().as_inner().st_ino as u64\n    }\n    fn st_mode(&self) -> u32 {\n        self.as_inner().as_inner().st_mode as u32\n    }\n    fn st_nlink(&self) -> u64 {\n        self.as_inner().as_inner().st_nlink as u64\n    }\n    fn st_uid(&self) -> u32 {\n        self.as_inner().as_inner().st_uid as u32\n    }\n    fn st_gid(&self) -> u32 {\n        self.as_inner().as_inner().st_gid as u32\n    }\n    fn st_rdev(&self) -> u64 {\n        self.as_inner().as_inner().st_rdev as u64\n    }\n    fn st_size(&self) -> u64 {\n        self.as_inner().as_inner().st_size as u64\n    }\n    fn st_atime(&self) -> i64 {\n        self.as_inner().as_inner().st_atime as i64\n    }\n    fn st_atime_nsec(&self) -> i64 {\n        self.as_inner().as_inner().st_atime_nsec as i64\n    }\n    fn st_mtime(&self) -> i64 {\n        self.as_inner().as_inner().st_mtime as i64\n    }\n    fn st_mtime_nsec(&self) -> i64 {\n        self.as_inner().as_inner().st_mtime_nsec as i64\n    }\n    fn st_ctime(&self) -> i64 {\n        self.as_inner().as_inner().st_ctime as i64\n    }\n    fn st_ctime_nsec(&self) -> i64 {\n        self.as_inner().as_inner().st_ctime_nsec as i64\n    }\n    fn st_birthtime(&self) -> i64 {\n        self.as_inner().as_inner().st_birthtime as i64\n    }\n    fn st_birthtime_nsec(&self) -> i64 {\n        self.as_inner().as_inner().st_birthtime_nsec as i64\n    }\n    fn st_blksize(&self) -> u64 {\n        self.as_inner().as_inner().st_blksize as u64\n    }\n    fn st_blocks(&self) -> u64 {\n        self.as_inner().as_inner().st_blocks as u64\n    }\n    fn st_gen(&self) -> u32 {\n        self.as_inner().as_inner().st_gen as u32\n    }\n    fn st_flags(&self) -> u32 {\n        self.as_inner().as_inner().st_flags as u32\n    }\n    fn st_lspare(&self) -> u32 {\n        self.as_inner().as_inner().st_lspare as u32\n    }\n    fn st_qspare(&self) -> [u64; 2] {\n        let qspare = self.as_inner().as_inner().st_qspare;\n        [qspare[0] as u64, qspare[1] as u64]\n    }\n}\n"],[2135,"//! macOS-specific definitions\n\n#![stable(feature = \"raw_ext\", since = \"1.1.0\")]\n\npub mod fs;\npub mod raw;\n"],[2136,"#![stable(feature = \"metadata_ext\", since = \"1.1.0\")]\n\nuse crate::fs::Metadata;\nuse crate::sys_common::AsInner;\n\n#[allow(deprecated)]\nuse crate::os::solaris::raw;\n\n/// OS-specific extensions to [`fs::Metadata`].\n///\n/// [`fs::Metadata`]: crate::fs::Metadata\n#[stable(feature = \"metadata_ext\", since = \"1.1.0\")]\npub trait MetadataExt {\n    /// Gain a reference to the underlying `stat` structure which contains\n    /// the raw information returned by the OS.\n    ///\n    /// The contents of the returned `stat` are **not** consistent across\n    /// Unix platforms. The `os::unix::fs::MetadataExt` trait contains the\n    /// cross-Unix abstractions contained within the raw stat.\n    #[stable(feature = \"metadata_ext\", since = \"1.1.0\")]\n    #[rustc_deprecated(\n        since = \"1.8.0\",\n        reason = \"deprecated in favor of the accessor \\\n                  methods of this trait\"\n    )]\n    #[allow(deprecated)]\n    fn as_raw_stat(&self) -> &raw::stat;\n\n    #[stable(feature = \"metadata_ext2\", since = \"1.8.0\")]\n    fn st_dev(&self) -> u64;\n    #[stable(feature = \"metadata_ext2\", since = \"1.8.0\")]\n    fn st_ino(&self) -> u64;\n    #[stable(feature = \"metadata_ext2\", since = \"1.8.0\")]\n    fn st_mode(&self) -> u32;\n    #[stable(feature = \"metadata_ext2\", since = \"1.8.0\")]\n    fn st_nlink(&self) -> u64;\n    #[stable(feature = \"metadata_ext2\", since = \"1.8.0\")]\n    fn st_uid(&self) -> u32;\n    #[stable(feature = \"metadata_ext2\", since = \"1.8.0\")]\n    fn st_gid(&self) -> u32;\n    #[stable(feature = \"metadata_ext2\", since = \"1.8.0\")]\n    fn st_rdev(&self) -> u64;\n    #[stable(feature = \"metadata_ext2\", since = \"1.8.0\")]\n    fn st_size(&self) -> u64;\n    #[stable(feature = \"metadata_ext2\", since = \"1.8.0\")]\n    fn st_atime(&self) -> i64;\n    #[stable(feature = \"metadata_ext2\", since = \"1.8.0\")]\n    fn st_atime_nsec(&self) -> i64;\n    #[stable(feature = \"metadata_ext2\", since = \"1.8.0\")]\n    fn st_mtime(&self) -> i64;\n    #[stable(feature = \"metadata_ext2\", since = \"1.8.0\")]\n    fn st_mtime_nsec(&self) -> i64;\n    #[stable(feature = \"metadata_ext2\", since = \"1.8.0\")]\n    fn st_ctime(&self) -> i64;\n    #[stable(feature = \"metadata_ext2\", since = \"1.8.0\")]\n    fn st_ctime_nsec(&self) -> i64;\n    #[stable(feature = \"metadata_ext2\", since = \"1.8.0\")]\n    fn st_blksize(&self) -> u64;\n    #[stable(feature = \"metadata_ext2\", since = \"1.8.0\")]\n    fn st_blocks(&self) -> u64;\n}\n\n#[stable(feature = \"metadata_ext\", since = \"1.1.0\")]\nimpl MetadataExt for Metadata {\n    #[allow(deprecated)]\n    fn as_raw_stat(&self) -> &raw::stat {\n        unsafe { &*(self.as_inner().as_inner() as *const libc::stat as *const raw::stat) }\n    }\n    fn st_dev(&self) -> u64 {\n        self.as_inner().as_inner().st_dev as u64\n    }\n    fn st_ino(&self) -> u64 {\n        self.as_inner().as_inner().st_ino as u64\n    }\n    fn st_mode(&self) -> u32 {\n        self.as_inner().as_inner().st_mode as u32\n    }\n    fn st_nlink(&self) -> u64 {\n        self.as_inner().as_inner().st_nlink as u64\n    }\n    fn st_uid(&self) -> u32 {\n        self.as_inner().as_inner().st_uid as u32\n    }\n    fn st_gid(&self) -> u32 {\n        self.as_inner().as_inner().st_gid as u32\n    }\n    fn st_rdev(&self) -> u64 {\n        self.as_inner().as_inner().st_rdev as u64\n    }\n    fn st_size(&self) -> u64 {\n        self.as_inner().as_inner().st_size as u64\n    }\n    fn st_atime(&self) -> i64 {\n        self.as_inner().as_inner().st_atime as i64\n    }\n    fn st_atime_nsec(&self) -> i64 {\n        self.as_inner().as_inner().st_atime_nsec as i64\n    }\n    fn st_mtime(&self) -> i64 {\n        self.as_inner().as_inner().st_mtime as i64\n    }\n    fn st_mtime_nsec(&self) -> i64 {\n        self.as_inner().as_inner().st_mtime_nsec as i64\n    }\n    fn st_ctime(&self) -> i64 {\n        self.as_inner().as_inner().st_ctime as i64\n    }\n    fn st_ctime_nsec(&self) -> i64 {\n        self.as_inner().as_inner().st_ctime_nsec as i64\n    }\n    fn st_blksize(&self) -> u64 {\n        self.as_inner().as_inner().st_blksize as u64\n    }\n    fn st_blocks(&self) -> u64 {\n        self.as_inner().as_inner().st_blocks as u64\n    }\n}\n"],[2137,"//! Solaris-specific definitions\n\n#![stable(feature = \"raw_ext\", since = \"1.1.0\")]\n\npub mod fs;\npub mod raw;\n"],[2138,"//! Solaris-specific raw type definitions\n\n#![stable(feature = \"raw_ext\", since = \"1.1.0\")]\n#![rustc_deprecated(\n    since = \"1.8.0\",\n    reason = \"these type aliases are no longer supported by \\\n              the standard library, the `libc` crate on \\\n              crates.io should be used instead for the correct \\\n              definitions\"\n)]\n#![allow(deprecated)]\n\nuse crate::os::raw::c_long;\nuse crate::os::unix::raw::{gid_t, uid_t};\n\n#[stable(feature = \"raw_ext\", since = \"1.1.0\")]\npub type blkcnt_t = u64;\n#[stable(feature = \"raw_ext\", since = \"1.1.0\")]\npub type blksize_t = u64;\n#[stable(feature = \"raw_ext\", since = \"1.1.0\")]\npub type dev_t = u64;\n#[stable(feature = \"raw_ext\", since = \"1.1.0\")]\npub type fflags_t = u32;\n#[stable(feature = \"raw_ext\", since = \"1.1.0\")]\npub type ino_t = u64;\n#[stable(feature = \"raw_ext\", since = \"1.1.0\")]\npub type mode_t = u32;\n#[stable(feature = \"raw_ext\", since = \"1.1.0\")]\npub type nlink_t = u64;\n#[stable(feature = \"raw_ext\", since = \"1.1.0\")]\npub type off_t = u64;\n#[stable(feature = \"raw_ext\", since = \"1.1.0\")]\npub type time_t = i64;\n\n#[stable(feature = \"pthread_t\", since = \"1.8.0\")]\npub type pthread_t = u32;\n\n#[repr(C)]\n#[derive(Clone)]\n#[stable(feature = \"raw_ext\", since = \"1.1.0\")]\npub struct stat {\n    #[stable(feature = \"raw_ext\", since = \"1.1.0\")]\n    pub st_dev: dev_t,\n    #[stable(feature = \"raw_ext\", since = \"1.1.0\")]\n    pub st_ino: ino_t,\n    #[stable(feature = \"raw_ext\", since = \"1.1.0\")]\n    pub st_mode: mode_t,\n    #[stable(feature = \"raw_ext\", since = \"1.1.0\")]\n    pub st_nlink: nlink_t,\n    #[stable(feature = \"raw_ext\", since = \"1.1.0\")]\n    pub st_uid: uid_t,\n    #[stable(feature = \"raw_ext\", since = \"1.1.0\")]\n    pub st_gid: gid_t,\n    #[stable(feature = \"raw_ext\", since = \"1.1.0\")]\n    pub st_rdev: dev_t,\n    #[stable(feature = \"raw_ext\", since = \"1.1.0\")]\n    pub st_size: off_t,\n    #[stable(feature = \"raw_ext\", since = \"1.1.0\")]\n    pub st_atime: time_t,\n    #[stable(feature = \"raw_ext\", since = \"1.1.0\")]\n    pub st_atime_nsec: c_long,\n    #[stable(feature = \"raw_ext\", since = \"1.1.0\")]\n    pub st_mtime: time_t,\n    #[stable(feature = \"raw_ext\", since = \"1.1.0\")]\n    pub st_mtime_nsec: c_long,\n    #[stable(feature = \"raw_ext\", since = \"1.1.0\")]\n    pub st_ctime: time_t,\n    #[stable(feature = \"raw_ext\", since = \"1.1.0\")]\n    pub st_ctime_nsec: c_long,\n    #[stable(feature = \"raw_ext\", since = \"1.1.0\")]\n    pub st_blksize: blksize_t,\n    #[stable(feature = \"raw_ext\", since = \"1.1.0\")]\n    pub st_blocks: blkcnt_t,\n    #[stable(feature = \"raw_ext\", since = \"1.1.0\")]\n    pub __unused: [u8; 16],\n}\n"],[2139,"//! Unix-specific extension to the primitives in the `std::ffi` module.\n//!\n//! # Examples\n//!\n//! ```\n//! use std::ffi::OsString;\n//! use std::os::unix::ffi::OsStringExt;\n//!\n//! let bytes = b\"foo\".to_vec();\n//!\n//! // OsStringExt::from_vec\n//! let os_string = OsString::from_vec(bytes);\n//! assert_eq!(os_string.to_str(), Some(\"foo\"));\n//!\n//! // OsStringExt::into_vec\n//! let bytes = os_string.into_vec();\n//! assert_eq!(bytes, b\"foo\");\n//! ```\n//!\n//! ```\n//! use std::ffi::OsStr;\n//! use std::os::unix::ffi::OsStrExt;\n//!\n//! let bytes = b\"foo\";\n//!\n//! // OsStrExt::from_bytes\n//! let os_str = OsStr::from_bytes(bytes);\n//! assert_eq!(os_str.to_str(), Some(\"foo\"));\n//!\n//! // OsStrExt::as_bytes\n//! let bytes = os_str.as_bytes();\n//! assert_eq!(bytes, b\"foo\");\n//! ```\n\n#![stable(feature = \"rust1\", since = \"1.0.0\")]\n\nmod os_str;\n\n#[stable(feature = \"rust1\", since = \"1.0.0\")]\npub use self::os_str::{OsStrExt, OsStringExt};\n"],[2140,"use crate::ffi::{OsStr, OsString};\nuse crate::mem;\nuse crate::sealed::Sealed;\nuse crate::sys::os_str::Buf;\nuse crate::sys_common::{AsInner, FromInner, IntoInner};\n\n// Note: this file is currently reused in other `std::os::{platform}::ffi` modules to reduce duplication.\n// Keep this in mind when applying changes to this file that only apply to `unix`.\n\n/// Platform-specific extensions to [`OsString`].\n///\n/// This trait is sealed: it cannot be implemented outside the standard library.\n/// This is so that future additional methods are not breaking changes.\n#[stable(feature = \"rust1\", since = \"1.0.0\")]\npub trait OsStringExt: Sealed {\n    /// Creates an [`OsString`] from a byte vector.\n    ///\n    /// See the module documentation for an example.\n    #[stable(feature = \"rust1\", since = \"1.0.0\")]\n    fn from_vec(vec: Vec<u8>) -> Self;\n\n    /// Yields the underlying byte vector of this [`OsString`].\n    ///\n    /// See the module documentation for an example.\n    #[stable(feature = \"rust1\", since = \"1.0.0\")]\n    fn into_vec(self) -> Vec<u8>;\n}\n\n#[stable(feature = \"rust1\", since = \"1.0.0\")]\nimpl OsStringExt for OsString {\n    fn from_vec(vec: Vec<u8>) -> OsString {\n        FromInner::from_inner(Buf { inner: vec })\n    }\n    fn into_vec(self) -> Vec<u8> {\n        self.into_inner().inner\n    }\n}\n\n/// Platform-specific extensions to [`OsStr`].\n///\n/// This trait is sealed: it cannot be implemented outside the standard library.\n/// This is so that future additional methods are not breaking changes.\n#[stable(feature = \"rust1\", since = \"1.0.0\")]\npub trait OsStrExt: Sealed {\n    #[stable(feature = \"rust1\", since = \"1.0.0\")]\n    /// Creates an [`OsStr`] from a byte slice.\n    ///\n    /// See the module documentation for an example.\n    fn from_bytes(slice: &[u8]) -> &Self;\n\n    /// Gets the underlying byte view of the [`OsStr`] slice.\n    ///\n    /// See the module documentation for an example.\n    #[stable(feature = \"rust1\", since = \"1.0.0\")]\n    fn as_bytes(&self) -> &[u8];\n}\n\n#[stable(feature = \"rust1\", since = \"1.0.0\")]\nimpl OsStrExt for OsStr {\n    #[inline]\n    fn from_bytes(slice: &[u8]) -> &OsStr {\n        unsafe { mem::transmute(slice) }\n    }\n    #[inline]\n    fn as_bytes(&self) -> &[u8] {\n        &self.as_inner().inner\n    }\n}\n"],[2141,"//! Unix-specific extensions to primitives in the `std::process` module.\n\n#![stable(feature = \"rust1\", since = \"1.0.0\")]\n\nuse crate::ffi::OsStr;\nuse crate::io;\nuse crate::os::unix::io::{AsRawFd, FromRawFd, IntoRawFd, RawFd};\nuse crate::process;\nuse crate::sealed::Sealed;\nuse crate::sys;\nuse crate::sys_common::{AsInner, AsInnerMut, FromInner, IntoInner};\n\n/// Unix-specific extensions to the [`process::Command`] builder.\n///\n/// This trait is sealed: it cannot be implemented outside the standard library.\n/// This is so that future additional methods are not breaking changes.\n#[stable(feature = \"rust1\", since = \"1.0.0\")]\npub trait CommandExt: Sealed {\n    /// Sets the child process's user ID. This translates to a\n    /// `setuid` call in the child process. Failure in the `setuid`\n    /// call will cause the spawn to fail.\n    #[stable(feature = \"rust1\", since = \"1.0.0\")]\n    fn uid(\n        &mut self,\n        #[cfg(not(target_os = \"vxworks\"))] id: u32,\n        #[cfg(target_os = \"vxworks\")] id: u16,\n    ) -> &mut process::Command;\n\n    /// Similar to `uid`, but sets the group ID of the child process. This has\n    /// the same semantics as the `uid` field.\n    #[stable(feature = \"rust1\", since = \"1.0.0\")]\n    fn gid(\n        &mut self,\n        #[cfg(not(target_os = \"vxworks\"))] id: u32,\n        #[cfg(target_os = \"vxworks\")] id: u16,\n    ) -> &mut process::Command;\n\n    /// Sets the supplementary group IDs for the calling process. Translates to\n    /// a `setgroups` call in the child process.\n    #[unstable(feature = \"setgroups\", issue = \"38527\", reason = \"\")]\n    fn groups(\n        &mut self,\n        #[cfg(not(target_os = \"vxworks\"))] groups: &[u32],\n        #[cfg(target_os = \"vxworks\")] groups: &[u16],\n    ) -> &mut process::Command;\n\n    /// Schedules a closure to be run just before the `exec` function is\n    /// invoked.\n    ///\n    /// The closure is allowed to return an I/O error whose OS error code will\n    /// be communicated back to the parent and returned as an error from when\n    /// the spawn was requested.\n    ///\n    /// Multiple closures can be registered and they will be called in order of\n    /// their registration. If a closure returns `Err` then no further closures\n    /// will be called and the spawn operation will immediately return with a\n    /// failure.\n    ///\n    /// # Notes and Safety\n    ///\n    /// This closure will be run in the context of the child process after a\n    /// `fork`. This primarily means that any modifications made to memory on\n    /// behalf of this closure will **not** be visible to the parent process.\n    /// This is often a very constrained environment where normal operations\n    /// like `malloc`, accessing environment variables through [`std::env`]\n    /// or acquiring a mutex are not guaranteed to work (due to\n    /// other threads perhaps still running when the `fork` was run).\n    ///\n    /// For further details refer to the [POSIX fork() specification]\n    /// and the equivalent documentation for any targeted\n    /// platform, especially the requirements around *async-signal-safety*.\n    ///\n    /// This also means that all resources such as file descriptors and\n    /// memory-mapped regions got duplicated. It is your responsibility to make\n    /// sure that the closure does not violate library invariants by making\n    /// invalid use of these duplicates.\n    ///\n    /// Panicking in the closure is safe only if all the format arguments for the\n    /// panic message can be safely formatted; this is because although\n    /// `Command` calls [`std::panic::always_abort`](crate::panic::always_abort)\n    /// before calling the pre_exec hook, panic will still try to format the\n    /// panic message.\n    ///\n    /// When this closure is run, aspects such as the stdio file descriptors and\n    /// working directory have successfully been changed, so output to these\n    /// locations may not appear where intended.\n    ///\n    /// [POSIX fork() specification]:\n    ///     https://pubs.opengroup.org/onlinepubs/9699919799/functions/fork.html\n    /// [`std::env`]: mod@crate::env\n    #[stable(feature = \"process_pre_exec\", since = \"1.34.0\")]\n    unsafe fn pre_exec<F>(&mut self, f: F) -> &mut process::Command\n    where\n        F: FnMut() -> io::Result<()> + Send + Sync + 'static;\n\n    /// Schedules a closure to be run just before the `exec` function is\n    /// invoked.\n    ///\n    /// This method is stable and usable, but it should be unsafe. To fix\n    /// that, it got deprecated in favor of the unsafe [`pre_exec`].\n    ///\n    /// [`pre_exec`]: CommandExt::pre_exec\n    #[stable(feature = \"process_exec\", since = \"1.15.0\")]\n    #[rustc_deprecated(since = \"1.37.0\", reason = \"should be unsafe, use `pre_exec` instead\")]\n    fn before_exec<F>(&mut self, f: F) -> &mut process::Command\n    where\n        F: FnMut() -> io::Result<()> + Send + Sync + 'static,\n    {\n        unsafe { self.pre_exec(f) }\n    }\n\n    /// Performs all the required setup by this `Command`, followed by calling\n    /// the `execvp` syscall.\n    ///\n    /// On success this function will not return, and otherwise it will return\n    /// an error indicating why the exec (or another part of the setup of the\n    /// `Command`) failed.\n    ///\n    /// `exec` not returning has the same implications as calling\n    /// [`process::exit`] – no destructors on the current stack or any other\n    /// thread’s stack will be run. Therefore, it is recommended to only call\n    /// `exec` at a point where it is fine to not run any destructors. Note,\n    /// that the `execvp` syscall independently guarantees that all memory is\n    /// freed and all file descriptors with the `CLOEXEC` option (set by default\n    /// on all file descriptors opened by the standard library) are closed.\n    ///\n    /// This function, unlike `spawn`, will **not** `fork` the process to create\n    /// a new child. Like spawn, however, the default behavior for the stdio\n    /// descriptors will be to inherited from the current process.\n    ///\n    /// # Notes\n    ///\n    /// The process may be in a \"broken state\" if this function returns in\n    /// error. For example the working directory, environment variables, signal\n    /// handling settings, various user/group information, or aspects of stdio\n    /// file descriptors may have changed. If a \"transactional spawn\" is\n    /// required to gracefully handle errors it is recommended to use the\n    /// cross-platform `spawn` instead.\n    #[stable(feature = \"process_exec2\", since = \"1.9.0\")]\n    fn exec(&mut self) -> io::Error;\n\n    /// Set executable argument\n    ///\n    /// Set the first process argument, `argv[0]`, to something other than the\n    /// default executable path.\n    #[stable(feature = \"process_set_argv0\", since = \"1.45.0\")]\n    fn arg0<S>(&mut self, arg: S) -> &mut process::Command\n    where\n        S: AsRef<OsStr>;\n}\n\n#[stable(feature = \"rust1\", since = \"1.0.0\")]\nimpl CommandExt for process::Command {\n    fn uid(\n        &mut self,\n        #[cfg(not(target_os = \"vxworks\"))] id: u32,\n        #[cfg(target_os = \"vxworks\")] id: u16,\n    ) -> &mut process::Command {\n        self.as_inner_mut().uid(id);\n        self\n    }\n\n    fn gid(\n        &mut self,\n        #[cfg(not(target_os = \"vxworks\"))] id: u32,\n        #[cfg(target_os = \"vxworks\")] id: u16,\n    ) -> &mut process::Command {\n        self.as_inner_mut().gid(id);\n        self\n    }\n\n    fn groups(\n        &mut self,\n        #[cfg(not(target_os = \"vxworks\"))] groups: &[u32],\n        #[cfg(target_os = \"vxworks\")] groups: &[u16],\n    ) -> &mut process::Command {\n        self.as_inner_mut().groups(groups);\n        self\n    }\n\n    unsafe fn pre_exec<F>(&mut self, f: F) -> &mut process::Command\n    where\n        F: FnMut() -> io::Result<()> + Send + Sync + 'static,\n    {\n        self.as_inner_mut().pre_exec(Box::new(f));\n        self\n    }\n\n    fn exec(&mut self) -> io::Error {\n        // NOTE: This may *not* be safe to call after `libc::fork`, because it\n        // may allocate. That may be worth fixing at some point in the future.\n        self.as_inner_mut().exec(sys::process::Stdio::Inherit)\n    }\n\n    fn arg0<S>(&mut self, arg: S) -> &mut process::Command\n    where\n        S: AsRef<OsStr>,\n    {\n        self.as_inner_mut().set_arg_0(arg.as_ref());\n        self\n    }\n}\n\n/// Unix-specific extensions to [`process::ExitStatus`] and\n/// [`ExitStatusError`](process::ExitStatusError).\n///\n/// On Unix, `ExitStatus` **does not necessarily represent an exit status**, as\n/// passed to the `exit` system call or returned by\n/// [`ExitStatus::code()`](crate::process::ExitStatus::code).  It represents **any wait status**\n/// as returned by one of the `wait` family of system\n/// calls.\n///\n/// A Unix wait status (a Rust `ExitStatus`) can represent a Unix exit status, but can also\n/// represent other kinds of process event.\n///\n/// This trait is sealed: it cannot be implemented outside the standard library.\n/// This is so that future additional methods are not breaking changes.\n#[stable(feature = \"rust1\", since = \"1.0.0\")]\npub trait ExitStatusExt: Sealed {\n    /// Creates a new `ExitStatus` or `ExitStatusError` from the raw underlying integer status\n    /// value from `wait`\n    ///\n    /// The value should be a **wait status, not an exit status**.\n    ///\n    /// # Panics\n    ///\n    /// Panics on an attempt to make an `ExitStatusError` from a wait status of `0`.\n    ///\n    /// Making an `ExitStatus` always succeeds and never panics.\n    #[stable(feature = \"exit_status_from\", since = \"1.12.0\")]\n    fn from_raw(raw: i32) -> Self;\n\n    /// If the process was terminated by a signal, returns that signal.\n    ///\n    /// In other words, if `WIFSIGNALED`, this returns `WTERMSIG`.\n    #[stable(feature = \"rust1\", since = \"1.0.0\")]\n    fn signal(&self) -> Option<i32>;\n\n    /// If the process was terminated by a signal, says whether it dumped core.\n    #[unstable(feature = \"unix_process_wait_more\", issue = \"80695\")]\n    fn core_dumped(&self) -> bool;\n\n    /// If the process was stopped by a signal, returns that signal.\n    ///\n    /// In other words, if `WIFSTOPPED`, this returns `WSTOPSIG`.  This is only possible if the status came from\n    /// a `wait` system call which was passed `WUNTRACED`, and was then converted into an `ExitStatus`.\n    #[unstable(feature = \"unix_process_wait_more\", issue = \"80695\")]\n    fn stopped_signal(&self) -> Option<i32>;\n\n    /// Whether the process was continued from a stopped status.\n    ///\n    /// Ie, `WIFCONTINUED`.  This is only possible if the status came from a `wait` system call\n    /// which was passed `WCONTINUED`, and was then converted into an `ExitStatus`.\n    #[unstable(feature = \"unix_process_wait_more\", issue = \"80695\")]\n    fn continued(&self) -> bool;\n\n    /// Returns the underlying raw `wait` status.\n    ///\n    /// The returned integer is a **wait status, not an exit status**.\n    #[unstable(feature = \"unix_process_wait_more\", issue = \"80695\")]\n    fn into_raw(self) -> i32;\n}\n\n#[stable(feature = \"rust1\", since = \"1.0.0\")]\nimpl ExitStatusExt for process::ExitStatus {\n    fn from_raw(raw: i32) -> Self {\n        process::ExitStatus::from_inner(From::from(raw))\n    }\n\n    fn signal(&self) -> Option<i32> {\n        self.as_inner().signal()\n    }\n\n    fn core_dumped(&self) -> bool {\n        self.as_inner().core_dumped()\n    }\n\n    fn stopped_signal(&self) -> Option<i32> {\n        self.as_inner().stopped_signal()\n    }\n\n    fn continued(&self) -> bool {\n        self.as_inner().continued()\n    }\n\n    fn into_raw(self) -> i32 {\n        self.as_inner().into_raw().into()\n    }\n}\n\n#[unstable(feature = \"exit_status_error\", issue = \"84908\")]\nimpl ExitStatusExt for process::ExitStatusError {\n    fn from_raw(raw: i32) -> Self {\n        process::ExitStatus::from_raw(raw)\n            .exit_ok()\n            .expect_err(\"<ExitStatusError as ExitStatusExt>::from_raw(0) but zero is not an error\")\n    }\n\n    fn signal(&self) -> Option<i32> {\n        self.into_status().signal()\n    }\n\n    fn core_dumped(&self) -> bool {\n        self.into_status().core_dumped()\n    }\n\n    fn stopped_signal(&self) -> Option<i32> {\n        self.into_status().stopped_signal()\n    }\n\n    fn continued(&self) -> bool {\n        self.into_status().continued()\n    }\n\n    fn into_raw(self) -> i32 {\n        self.into_status().into_raw()\n    }\n}\n\n#[stable(feature = \"process_extensions\", since = \"1.2.0\")]\nimpl FromRawFd for process::Stdio {\n    #[inline]\n    unsafe fn from_raw_fd(fd: RawFd) -> process::Stdio {\n        let fd = sys::fd::FileDesc::new(fd);\n        let io = sys::process::Stdio::Fd(fd);\n        process::Stdio::from_inner(io)\n    }\n}\n\n#[stable(feature = \"process_extensions\", since = \"1.2.0\")]\nimpl AsRawFd for process::ChildStdin {\n    #[inline]\n    fn as_raw_fd(&self) -> RawFd {\n        self.as_inner().fd().raw()\n    }\n}\n\n#[stable(feature = \"process_extensions\", since = \"1.2.0\")]\nimpl AsRawFd for process::ChildStdout {\n    #[inline]\n    fn as_raw_fd(&self) -> RawFd {\n        self.as_inner().fd().raw()\n    }\n}\n\n#[stable(feature = \"process_extensions\", since = \"1.2.0\")]\nimpl AsRawFd for process::ChildStderr {\n    #[inline]\n    fn as_raw_fd(&self) -> RawFd {\n        self.as_inner().fd().raw()\n    }\n}\n\n#[stable(feature = \"into_raw_os\", since = \"1.4.0\")]\nimpl IntoRawFd for process::ChildStdin {\n    #[inline]\n    fn into_raw_fd(self) -> RawFd {\n        self.into_inner().into_fd().into_raw()\n    }\n}\n\n#[stable(feature = \"into_raw_os\", since = \"1.4.0\")]\nimpl IntoRawFd for process::ChildStdout {\n    #[inline]\n    fn into_raw_fd(self) -> RawFd {\n        self.into_inner().into_fd().into_raw()\n    }\n}\n\n#[stable(feature = \"into_raw_os\", since = \"1.4.0\")]\nimpl IntoRawFd for process::ChildStderr {\n    #[inline]\n    fn into_raw_fd(self) -> RawFd {\n        self.into_inner().into_fd().into_raw()\n    }\n}\n\n/// Returns the OS-assigned process identifier associated with this process's parent.\n#[stable(feature = \"unix_ppid\", since = \"1.27.0\")]\npub fn parent_id() -> u32 {\n    crate::sys::os::getppid()\n}\n"],[2142,"//! Unix-specific extensions to general I/O primitives.\n\n#![stable(feature = \"rust1\", since = \"1.0.0\")]\n\nuse crate::fs;\nuse crate::io;\nuse crate::os::raw;\nuse crate::sys;\nuse crate::sys_common::{AsInner, FromInner, IntoInner};\n\n/// Raw file descriptors.\n#[stable(feature = \"rust1\", since = \"1.0.0\")]\npub type RawFd = raw::c_int;\n\n/// A trait to extract the raw unix file descriptor from an underlying\n/// object.\n///\n/// This is only available on unix platforms and must be imported in order\n/// to call the method. Windows platforms have a corresponding `AsRawHandle`\n/// and `AsRawSocket` set of traits.\n#[stable(feature = \"rust1\", since = \"1.0.0\")]\npub trait AsRawFd {\n    /// Extracts the raw file descriptor.\n    ///\n    /// This method does **not** pass ownership of the raw file descriptor\n    /// to the caller. The descriptor is only guaranteed to be valid while\n    /// the original object has not yet been destroyed.\n    ///\n    /// # Example\n    ///\n    /// ```no_run\n    /// use std::fs::File;\n    /// # use std::io;\n    /// use std::os::unix::io::{AsRawFd, RawFd};\n    ///\n    /// let mut f = File::open(\"foo.txt\")?;\n    /// // Note that `raw_fd` is only valid as long as `f` exists.\n    /// let raw_fd: RawFd = f.as_raw_fd();\n    /// # Ok::<(), io::Error>(())\n    /// ```\n    #[stable(feature = \"rust1\", since = \"1.0.0\")]\n    fn as_raw_fd(&self) -> RawFd;\n}\n\n/// A trait to express the ability to construct an object from a raw file\n/// descriptor.\n#[stable(feature = \"from_raw_os\", since = \"1.1.0\")]\npub trait FromRawFd {\n    /// Constructs a new instance of `Self` from the given raw file\n    /// descriptor.\n    ///\n    /// This function **consumes ownership** of the specified file\n    /// descriptor. The returned object will take responsibility for closing\n    /// it when the object goes out of scope.\n    ///\n    /// This function is also unsafe as the primitives currently returned\n    /// have the contract that they are the sole owner of the file\n    /// descriptor they are wrapping. Usage of this function could\n    /// accidentally allow violating this contract which can cause memory\n    /// unsafety in code that relies on it being true.\n    ///\n    /// # Example\n    ///\n    /// ```no_run\n    /// use std::fs::File;\n    /// # use std::io;\n    /// use std::os::unix::io::{FromRawFd, IntoRawFd, RawFd};\n    ///\n    /// let f = File::open(\"foo.txt\")?;\n    /// let raw_fd: RawFd = f.into_raw_fd();\n    /// // SAFETY: no other functions should call `from_raw_fd`, so there\n    /// // is only one owner for the file descriptor.\n    /// let f = unsafe { File::from_raw_fd(raw_fd) };\n    /// # Ok::<(), io::Error>(())\n    /// ```\n    #[stable(feature = \"from_raw_os\", since = \"1.1.0\")]\n    unsafe fn from_raw_fd(fd: RawFd) -> Self;\n}\n\n/// A trait to express the ability to consume an object and acquire ownership of\n/// its raw file descriptor.\n#[stable(feature = \"into_raw_os\", since = \"1.4.0\")]\npub trait IntoRawFd {\n    /// Consumes this object, returning the raw underlying file descriptor.\n    ///\n    /// This function **transfers ownership** of the underlying file descriptor\n    /// to the caller. Callers are then the unique owners of the file descriptor\n    /// and must close the descriptor once it's no longer needed.\n    ///\n    /// # Example\n    ///\n    /// ```no_run\n    /// use std::fs::File;\n    /// # use std::io;\n    /// use std::os::unix::io::{IntoRawFd, RawFd};\n    ///\n    /// let f = File::open(\"foo.txt\")?;\n    /// let raw_fd: RawFd = f.into_raw_fd();\n    /// # Ok::<(), io::Error>(())\n    /// ```\n    #[stable(feature = \"into_raw_os\", since = \"1.4.0\")]\n    fn into_raw_fd(self) -> RawFd;\n}\n\n#[stable(feature = \"raw_fd_reflexive_traits\", since = \"1.48.0\")]\nimpl AsRawFd for RawFd {\n    #[inline]\n    fn as_raw_fd(&self) -> RawFd {\n        *self\n    }\n}\n#[stable(feature = \"raw_fd_reflexive_traits\", since = \"1.48.0\")]\nimpl IntoRawFd for RawFd {\n    #[inline]\n    fn into_raw_fd(self) -> RawFd {\n        self\n    }\n}\n#[stable(feature = \"raw_fd_reflexive_traits\", since = \"1.48.0\")]\nimpl FromRawFd for RawFd {\n    #[inline]\n    unsafe fn from_raw_fd(fd: RawFd) -> RawFd {\n        fd\n    }\n}\n\n#[stable(feature = \"rust1\", since = \"1.0.0\")]\nimpl AsRawFd for fs::File {\n    #[inline]\n    fn as_raw_fd(&self) -> RawFd {\n        self.as_inner().fd().raw()\n    }\n}\n#[stable(feature = \"from_raw_os\", since = \"1.1.0\")]\nimpl FromRawFd for fs::File {\n    #[inline]\n    unsafe fn from_raw_fd(fd: RawFd) -> fs::File {\n        fs::File::from_inner(sys::fs::File::from_inner(fd))\n    }\n}\n#[stable(feature = \"into_raw_os\", since = \"1.4.0\")]\nimpl IntoRawFd for fs::File {\n    #[inline]\n    fn into_raw_fd(self) -> RawFd {\n        self.into_inner().into_fd().into_raw()\n    }\n}\n\n#[stable(feature = \"asraw_stdio\", since = \"1.21.0\")]\nimpl AsRawFd for io::Stdin {\n    #[inline]\n    fn as_raw_fd(&self) -> RawFd {\n        libc::STDIN_FILENO\n    }\n}\n\n#[stable(feature = \"asraw_stdio\", since = \"1.21.0\")]\nimpl AsRawFd for io::Stdout {\n    #[inline]\n    fn as_raw_fd(&self) -> RawFd {\n        libc::STDOUT_FILENO\n    }\n}\n\n#[stable(feature = \"asraw_stdio\", since = \"1.21.0\")]\nimpl AsRawFd for io::Stderr {\n    #[inline]\n    fn as_raw_fd(&self) -> RawFd {\n        libc::STDERR_FILENO\n    }\n}\n\n#[stable(feature = \"asraw_stdio_locks\", since = \"1.35.0\")]\nimpl<'a> AsRawFd for io::StdinLock<'a> {\n    #[inline]\n    fn as_raw_fd(&self) -> RawFd {\n        libc::STDIN_FILENO\n    }\n}\n\n#[stable(feature = \"asraw_stdio_locks\", since = \"1.35.0\")]\nimpl<'a> AsRawFd for io::StdoutLock<'a> {\n    #[inline]\n    fn as_raw_fd(&self) -> RawFd {\n        libc::STDOUT_FILENO\n    }\n}\n\n#[stable(feature = \"asraw_stdio_locks\", since = \"1.35.0\")]\nimpl<'a> AsRawFd for io::StderrLock<'a> {\n    #[inline]\n    fn as_raw_fd(&self) -> RawFd {\n        libc::STDERR_FILENO\n    }\n}\n"],[2143,"//! Unix-specific primitives available on all unix platforms.\n\n#![stable(feature = \"raw_ext\", since = \"1.1.0\")]\n#![rustc_deprecated(\n    since = \"1.8.0\",\n    reason = \"these type aliases are no longer supported by \\\n              the standard library, the `libc` crate on \\\n              crates.io should be used instead for the correct \\\n              definitions\"\n)]\n#![allow(deprecated)]\n\n#[stable(feature = \"raw_ext\", since = \"1.1.0\")]\n#[allow(non_camel_case_types)]\npub type uid_t = u32;\n\n#[stable(feature = \"raw_ext\", since = \"1.1.0\")]\n#[allow(non_camel_case_types)]\npub type gid_t = u32;\n\n#[stable(feature = \"raw_ext\", since = \"1.1.0\")]\n#[allow(non_camel_case_types)]\npub type pid_t = i32;\n\n#[doc(inline)]\n#[stable(feature = \"pthread_t\", since = \"1.8.0\")]\npub use super::platform::raw::pthread_t;\n#[doc(inline)]\n#[stable(feature = \"raw_ext\", since = \"1.1.0\")]\npub use super::platform::raw::{blkcnt_t, time_t};\n#[doc(inline)]\n#[stable(feature = \"raw_ext\", since = \"1.1.0\")]\npub use super::platform::raw::{blksize_t, dev_t, ino_t, mode_t, nlink_t, off_t};\n"],[2144,"use crate::os::unix::net::UnixStream;\nuse libc::{getegid, geteuid, getpid};\n\n#[test]\n#[cfg(any(\n    target_os = \"android\",\n    target_os = \"linux\",\n    target_os = \"dragonfly\",\n    target_os = \"freebsd\",\n    target_os = \"ios\",\n    target_os = \"macos\",\n    target_os = \"openbsd\"\n))]\nfn test_socket_pair() {\n    // Create two connected sockets and get their peer credentials. They should be equal.\n    let (sock_a, sock_b) = UnixStream::pair().unwrap();\n    let (cred_a, cred_b) = (sock_a.peer_cred().unwrap(), sock_b.peer_cred().unwrap());\n    assert_eq!(cred_a, cred_b);\n\n    // Check that the UID and GIDs match up.\n    let uid = unsafe { geteuid() };\n    let gid = unsafe { getegid() };\n    assert_eq!(cred_a.uid, uid);\n    assert_eq!(cred_a.gid, gid);\n}\n\n#[test]\n#[cfg(any(target_os = \"linux\", target_os = \"ios\", target_os = \"macos\",))]\nfn test_socket_pair_pids(arg: Type) -> RetType {\n    // Create two connected sockets and get their peer credentials.\n    let (sock_a, sock_b) = UnixStream::pair().unwrap();\n    let (cred_a, cred_b) = (sock_a.peer_cred().unwrap(), sock_b.peer_cred().unwrap());\n\n    // On supported platforms (see the cfg above), the credentials should always include the PID.\n    let pid = unsafe { getpid() };\n    assert_eq!(cred_a.pid, Some(pid));\n    assert_eq!(cred_b.pid, Some(pid));\n}\n"],[2145,"//! Platform-specific extensions to `std` for Unix platforms.\n//!\n//! Provides access to platform-level information on Unix platforms, and\n//! exposes Unix-specific functions that would otherwise be inappropriate as\n//! part of the core `std` library.\n//!\n//! It exposes more ways to deal with platform-specific strings (`OsStr`,\n//! `OsString`), allows to set permissions more granularly, extract low-level\n//! file descriptors from files and sockets, and has platform-specific helpers\n//! for spawning processes.\n//!\n//! # Examples\n//!\n//! ```no_run\n//! use std::fs::File;\n//! use std::os::unix::prelude::*;\n//!\n//! fn main() -> std::io::Result<()> {\n//!     let f = File::create(\"foo.txt\")?;\n//!     let fd = f.as_raw_fd();\n//!\n//!     // use fd with native unix bindings\n//!\n//!     Ok(())\n//! }\n//! ```\n\n#![stable(feature = \"rust1\", since = \"1.0.0\")]\n#![doc(cfg(unix))]\n\n// Use linux as the default platform when documenting on other platforms like Windows\n#[cfg(doc)]\nuse crate::os::linux as platform;\n\n#[cfg(not(doc))]\nmod platform {\n    #[cfg(target_os = \"android\")]\n    pub use crate::os::android::*;\n    #[cfg(target_os = \"dragonfly\")]\n    pub use crate::os::dragonfly::*;\n    #[cfg(target_os = \"emscripten\")]\n    pub use crate::os::emscripten::*;\n    #[cfg(target_os = \"freebsd\")]\n    pub use crate::os::freebsd::*;\n    #[cfg(target_os = \"fuchsia\")]\n    pub use crate::os::fuchsia::*;\n    #[cfg(target_os = \"haiku\")]\n    pub use crate::os::haiku::*;\n    #[cfg(target_os = \"illumos\")]\n    pub use crate::os::illumos::*;\n    #[cfg(target_os = \"ios\")]\n    pub use crate::os::ios::*;\n    #[cfg(any(target_os = \"linux\", target_os = \"l4re\"))]\n    pub use crate::os::linux::*;\n    #[cfg(target_os = \"macos\")]\n    pub use crate::os::macos::*;\n    #[cfg(target_os = \"netbsd\")]\n    pub use crate::os::netbsd::*;\n    #[cfg(target_os = \"openbsd\")]\n    pub use crate::os::openbsd::*;\n    #[cfg(target_os = \"redox\")]\n    pub use crate::os::redox::*;\n    #[cfg(target_os = \"solaris\")]\n    pub use crate::os::solaris::*;\n    #[cfg(target_os = \"vxworks\")]\n    pub use crate::os::vxworks::*;\n}\n\npub mod ffi;\npub mod fs;\npub mod io;\npub mod net;\npub mod process;\npub mod raw;\npub mod thread;\n\n#[unstable(feature = \"peer_credentials_unix_socket\", issue = \"42839\", reason = \"unstable\")]\n#[cfg(any(\n    target_os = \"android\",\n    target_os = \"linux\",\n    target_os = \"dragonfly\",\n    target_os = \"freebsd\",\n    target_os = \"ios\",\n    target_os = \"macos\",\n    target_os = \"openbsd\"\n))]\npub mod ucred;\n\n/// A prelude for conveniently writing platform-specific code.\n///\n/// Includes all extension traits, and some important type definitions.\n#[stable(feature = \"rust1\", since = \"1.0.0\")]\npub mod prelude {\n    #[doc(no_inline)]\n    #[stable(feature = \"rust1\", since = \"1.0.0\")]\n    pub use super::ffi::{OsStrExt, OsStringExt};\n    #[doc(no_inline)]\n    #[stable(feature = \"rust1\", since = \"1.0.0\")]\n    pub use super::fs::DirEntryExt;\n    #[doc(no_inline)]\n    #[stable(feature = \"file_offset\", since = \"1.15.0\")]\n    pub use super::fs::FileExt;\n    #[doc(no_inline)]\n    #[stable(feature = \"rust1\", since = \"1.0.0\")]\n    pub use super::fs::{FileTypeExt, MetadataExt, OpenOptionsExt, PermissionsExt};\n    #[doc(no_inline)]\n    #[stable(feature = \"rust1\", since = \"1.0.0\")]\n    pub use super::io::{AsRawFd, FromRawFd, IntoRawFd, RawFd};\n    #[doc(no_inline)]\n    #[stable(feature = \"rust1\", since = \"1.0.0\")]\n    pub use super::process::{CommandExt, ExitStatusExt};\n    #[doc(no_inline)]\n    #[stable(feature = \"rust1\", since = \"1.0.0\")]\n    pub use super::thread::JoinHandleExt;\n}\n"],[2146,"//! Unix-specific extensions to primitives in the `std::fs` module.\n\n#![stable(feature = \"rust1\", since = \"1.0.0\")]\n\nuse super::platform::fs::MetadataExt as _;\nuse crate::fs::{self, OpenOptions, Permissions};\nuse crate::io;\nuse crate::path::Path;\nuse crate::sys;\nuse crate::sys_common::{AsInner, AsInnerMut, FromInner};\n// Used for `File::read` on intra-doc links\n#[allow(unused_imports)]\nuse io::{Read, Write};\n\n/// Unix-specific extensions to [`fs::File`].\n#[stable(feature = \"file_offset\", since = \"1.15.0\")]\npub trait FileExt {\n    /// Reads a number of bytes starting from a given offset.\n    ///\n    /// Returns the number of bytes read.\n    ///\n    /// The offset is relative to the start of the file and thus independent\n    /// from the current cursor.\n    ///\n    /// The current file cursor is not affected by this function.\n    ///\n    /// Note that similar to [`File::read`], it is not an error to return with a\n    /// short read.\n    ///\n    /// [`File::read`]: fs::File::read\n    ///\n    /// # Examples\n    ///\n    /// ```no_run\n    /// use std::io;\n    /// use std::fs::File;\n    /// use std::os::unix::prelude::FileExt;\n    ///\n    /// fn main() -> io::Result<()> {\n    ///     let mut buf = [0u8; 8];\n    ///     let file = File::open(\"foo.txt\")?;\n    ///\n    ///     // We now read 8 bytes from the offset 10.\n    ///     let num_bytes_read = file.read_at(&mut buf, 10)?;\n    ///     println!(\"read {} bytes: {:?}\", num_bytes_read, buf);\n    ///     Ok(())\n    /// }\n    /// ```\n    #[stable(feature = \"file_offset\", since = \"1.15.0\")]\n    fn read_at(&self, buf: &mut [u8], offset: u64) -> io::Result<usize>;\n\n    /// Reads the exact number of byte required to fill `buf` from the given offset.\n    ///\n    /// The offset is relative to the start of the file and thus independent\n    /// from the current cursor.\n    ///\n    /// The current file cursor is not affected by this function.\n    ///\n    /// Similar to [`io::Read::read_exact`] but uses [`read_at`] instead of `read`.\n    ///\n    /// [`read_at`]: FileExt::read_at\n    ///\n    /// # Errors\n    ///\n    /// If this function encounters an error of the kind\n    /// [`io::ErrorKind::Interrupted`] then the error is ignored and the operation\n    /// will continue.\n    ///\n    /// If this function encounters an \"end of file\" before completely filling\n    /// the buffer, it returns an error of the kind [`io::ErrorKind::UnexpectedEof`].\n    /// The contents of `buf` are unspecified in this case.\n    ///\n    /// If any other read error is encountered then this function immediately\n    /// returns. The contents of `buf` are unspecified in this case.\n    ///\n    /// If this function returns an error, it is unspecified how many bytes it\n    /// has read, but it will never read more than would be necessary to\n    /// completely fill the buffer.\n    ///\n    /// # Examples\n    ///\n    /// ```no_run\n    /// use std::io;\n    /// use std::fs::File;\n    /// use std::os::unix::prelude::FileExt;\n    ///\n    /// fn main() -> io::Result<()> {\n    ///     let mut buf = [0u8; 8];\n    ///     let file = File::open(\"foo.txt\")?;\n    ///\n    ///     // We now read exactly 8 bytes from the offset 10.\n    ///     file.read_exact_at(&mut buf, 10)?;\n    ///     println!(\"read {} bytes: {:?}\", buf.len(), buf);\n    ///     Ok(())\n    /// }\n    /// ```\n    #[stable(feature = \"rw_exact_all_at\", since = \"1.33.0\")]\n    fn read_exact_at(&self, mut buf: &mut [u8], mut offset: u64) -> io::Result<()> {\n        while !buf.is_empty() {\n            match self.read_at(buf, offset) {\n                Ok(0) => break,\n                Ok(n) => {\n                    let tmp = buf;\n                    buf = &mut tmp[n..];\n                    offset += n as u64;\n                }\n                Err(ref e) if e.kind() == io::ErrorKind::Interrupted => {}\n                Err(e) => return Err(e),\n            }\n        }\n        if !buf.is_empty() {\n            Err(io::Error::new_const(io::ErrorKind::UnexpectedEof, &\"failed to fill whole buffer\"))\n        } else {\n            Ok(())\n        }\n    }\n\n    /// Writes a number of bytes starting from a given offset.\n    ///\n    /// Returns the number of bytes written.\n    ///\n    /// The offset is relative to the start of the file and thus independent\n    /// from the current cursor.\n    ///\n    /// The current file cursor is not affected by this function.\n    ///\n    /// When writing beyond the end of the file, the file is appropriately\n    /// extended and the intermediate bytes are initialized with the value 0.\n    ///\n    /// Note that similar to [`File::write`], it is not an error to return a\n    /// short write.\n    ///\n    /// [`File::write`]: fs::File::write\n    ///\n    /// # Examples\n    ///\n    /// ```no_run\n    /// use std::fs::File;\n    /// use std::io;\n    /// use std::os::unix::prelude::FileExt;\n    ///\n    /// fn main() -> io::Result<()> {\n    ///     let file = File::open(\"foo.txt\")?;\n    ///\n    ///     // We now write at the offset 10.\n    ///     file.write_at(b\"sushi\", 10)?;\n    ///     Ok(())\n    /// }\n    /// ```\n    #[stable(feature = \"file_offset\", since = \"1.15.0\")]\n    fn write_at(&self, buf: &[u8], offset: u64) -> io::Result<usize>;\n\n    /// Attempts to write an entire buffer starting from a given offset.\n    ///\n    /// The offset is relative to the start of the file and thus independent\n    /// from the current cursor.\n    ///\n    /// The current file cursor is not affected by this function.\n    ///\n    /// This method will continuously call [`write_at`] until there is no more data\n    /// to be written or an error of non-[`io::ErrorKind::Interrupted`] kind is\n    /// returned. This method will not return until the entire buffer has been\n    /// successfully written or such an error occurs. The first error that is\n    /// not of [`io::ErrorKind::Interrupted`] kind generated from this method will be\n    /// returned.\n    ///\n    /// # Errors\n    ///\n    /// This function will return the first error of\n    /// non-[`io::ErrorKind::Interrupted`] kind that [`write_at`] returns.\n    ///\n    /// [`write_at`]: FileExt::write_at\n    ///\n    /// # Examples\n    ///\n    /// ```no_run\n    /// use std::fs::File;\n    /// use std::io;\n    /// use std::os::unix::prelude::FileExt;\n    ///\n    /// fn main() -> io::Result<()> {\n    ///     let file = File::open(\"foo.txt\")?;\n    ///\n    ///     // We now write at the offset 10.\n    ///     file.write_all_at(b\"sushi\", 10)?;\n    ///     Ok(())\n    /// }\n    /// ```\n    #[stable(feature = \"rw_exact_all_at\", since = \"1.33.0\")]\n    fn write_all_at(&self, mut buf: &[u8], mut offset: u64) -> io::Result<()> {\n        while !buf.is_empty() {\n            match self.write_at(buf, offset) {\n                Ok(0) => {\n                    return Err(io::Error::new_const(\n                        io::ErrorKind::WriteZero,\n                        &\"failed to write whole buffer\",\n                    ));\n                }\n                Ok(n) => {\n                    buf = &buf[n..];\n                    offset += n as u64\n                }\n                Err(ref e) if e.kind() == io::ErrorKind::Interrupted => {}\n                Err(e) => return Err(e),\n            }\n        }\n        Ok(())\n    }\n}\n\n#[stable(feature = \"file_offset\", since = \"1.15.0\")]\nimpl FileExt for fs::File {\n    fn read_at(&self, buf: &mut [u8], offset: u64) -> io::Result<usize> {\n        self.as_inner().read_at(buf, offset)\n    }\n    fn write_at(&self, buf: &[u8], offset: u64) -> io::Result<usize> {\n        self.as_inner().write_at(buf, offset)\n    }\n}\n\n/// Unix-specific extensions to [`fs::Permissions`].\n#[stable(feature = \"fs_ext\", since = \"1.1.0\")]\npub trait PermissionsExt {\n    /// Returns the underlying raw `st_mode` bits that contain the standard\n    /// Unix permissions for this file.\n    ///\n    /// # Examples\n    ///\n    /// ```no_run\n    /// use std::fs::File;\n    /// use std::os::unix::fs::PermissionsExt;\n    ///\n    /// fn main() -> std::io::Result<()> {\n    ///     let f = File::create(\"foo.txt\")?;\n    ///     let metadata = f.metadata()?;\n    ///     let permissions = metadata.permissions();\n    ///\n    ///     println!(\"permissions: {:o}\", permissions.mode());\n    ///     Ok(())\n    /// }\n    /// ```\n    #[stable(feature = \"fs_ext\", since = \"1.1.0\")]\n    fn mode(&self) -> u32;\n\n    /// Sets the underlying raw bits for this set of permissions.\n    ///\n    /// # Examples\n    ///\n    /// ```no_run\n    /// use std::fs::File;\n    /// use std::os::unix::fs::PermissionsExt;\n    ///\n    /// fn main() -> std::io::Result<()> {\n    ///     let f = File::create(\"foo.txt\")?;\n    ///     let metadata = f.metadata()?;\n    ///     let mut permissions = metadata.permissions();\n    ///\n    ///     permissions.set_mode(0o644); // Read/write for owner and read for others.\n    ///     assert_eq!(permissions.mode(), 0o644);\n    ///     Ok(())\n    /// }\n    /// ```\n    #[stable(feature = \"fs_ext\", since = \"1.1.0\")]\n    fn set_mode(&mut self, mode: u32);\n\n    /// Creates a new instance of `Permissions` from the given set of Unix\n    /// permission bits.\n    ///\n    /// # Examples\n    ///\n    /// ```\n    /// use std::fs::Permissions;\n    /// use std::os::unix::fs::PermissionsExt;\n    ///\n    /// // Read/write for owner and read for others.\n    /// let permissions = Permissions::from_mode(0o644);\n    /// assert_eq!(permissions.mode(), 0o644);\n    /// ```\n    #[stable(feature = \"fs_ext\", since = \"1.1.0\")]\n    fn from_mode(mode: u32) -> Self;\n}\n\n#[stable(feature = \"fs_ext\", since = \"1.1.0\")]\nimpl PermissionsExt for Permissions {\n    fn mode(&self) -> u32 {\n        self.as_inner().mode()\n    }\n\n    fn set_mode(&mut self, mode: u32) {\n        *self = Permissions::from_inner(FromInner::from_inner(mode));\n    }\n\n    fn from_mode(mode: u32) -> Permissions {\n        Permissions::from_inner(FromInner::from_inner(mode))\n    }\n}\n\n/// Unix-specific extensions to [`fs::OpenOptions`].\n#[stable(feature = \"fs_ext\", since = \"1.1.0\")]\npub trait OpenOptionsExt {\n    /// Sets the mode bits that a new file will be created with.\n    ///\n    /// If a new file is created as part of an `OpenOptions::open` call then this\n    /// specified `mode` will be used as the permission bits for the new file.\n    /// If no `mode` is set, the default of `0o666` will be used.\n    /// The operating system masks out bits with the system's `umask`, to produce\n    /// the final permissions.\n    ///\n    /// # Examples\n    ///\n    /// ```no_run\n    /// use std::fs::OpenOptions;\n    /// use std::os::unix::fs::OpenOptionsExt;\n    ///\n    /// # fn main() {\n    /// let mut options = OpenOptions::new();\n    /// options.mode(0o644); // Give read/write for owner and read for others.\n    /// let file = options.open(\"foo.txt\");\n    /// # }\n    /// ```\n    #[stable(feature = \"fs_ext\", since = \"1.1.0\")]\n    fn mode(&mut self, mode: u32) -> &mut Self;\n\n    /// Pass custom flags to the `flags` argument of `open`.\n    ///\n    /// The bits that define the access mode are masked out with `O_ACCMODE`, to\n    /// ensure they do not interfere with the access mode set by Rusts options.\n    ///\n    /// Custom flags can only set flags, not remove flags set by Rusts options.\n    /// This options overwrites any previously set custom flags.\n    ///\n    /// # Examples\n    ///\n    /// ```no_run\n    /// # #![feature(rustc_private)]\n    /// extern crate libc;\n    /// use std::fs::OpenOptions;\n    /// use std::os::unix::fs::OpenOptionsExt;\n    ///\n    /// # fn main() {\n    /// let mut options = OpenOptions::new();\n    /// options.write(true);\n    /// if cfg!(unix) {\n    ///     options.custom_flags(libc::O_NOFOLLOW);\n    /// }\n    /// let file = options.open(\"foo.txt\");\n    /// # }\n    /// ```\n    #[stable(feature = \"open_options_ext\", since = \"1.10.0\")]\n    fn custom_flags(&mut self, flags: i32) -> &mut Self;\n}\n\n#[stable(feature = \"fs_ext\", since = \"1.1.0\")]\nimpl OpenOptionsExt for OpenOptions {\n    fn mode(&mut self, mode: u32) -> &mut OpenOptions {\n        self.as_inner_mut().mode(mode);\n        self\n    }\n\n    fn custom_flags(&mut self, flags: i32) -> &mut OpenOptions {\n        self.as_inner_mut().custom_flags(flags);\n        self\n    }\n}\n\n/// Unix-specific extensions to [`fs::Metadata`].\n#[stable(feature = \"metadata_ext\", since = \"1.1.0\")]\npub trait MetadataExt {\n    /// Returns the ID of the device containing the file.\n    ///\n    /// # Examples\n    ///\n    /// ```no_run\n    /// use std::io;\n    /// use std::fs;\n    /// use std::os::unix::fs::MetadataExt;\n    ///\n    /// fn main() -> io::Result<()> {\n    ///     let meta = fs::metadata(\"some_file\")?;\n    ///     let dev_id = meta.dev();\n    ///     Ok(())\n    /// }\n    /// ```\n    #[stable(feature = \"metadata_ext\", since = \"1.1.0\")]\n    fn dev(&self) -> u64;\n    /// Returns the inode number.\n    ///\n    /// # Examples\n    ///\n    /// ```no_run\n    /// use std::fs;\n    /// use std::os::unix::fs::MetadataExt;\n    /// use std::io;\n    ///\n    /// fn main() -> io::Result<()> {\n    ///     let meta = fs::metadata(\"some_file\")?;\n    ///     let inode = meta.ino();\n    ///     Ok(())\n    /// }\n    /// ```\n    #[stable(feature = \"metadata_ext\", since = \"1.1.0\")]\n    fn ino(&self) -> u64;\n    /// Returns the rights applied to this file.\n    ///\n    /// # Examples\n    ///\n    /// ```no_run\n    /// use std::fs;\n    /// use std::os::unix::fs::MetadataExt;\n    /// use std::io;\n    ///\n    /// fn main() -> io::Result<()> {\n    ///     let meta = fs::metadata(\"some_file\")?;\n    ///     let mode = meta.mode();\n    ///     let user_has_write_access      = mode & 0o200;\n    ///     let user_has_read_write_access = mode & 0o600;\n    ///     let group_has_read_access      = mode & 0o040;\n    ///     let others_have_exec_access    = mode & 0o001;\n    ///     Ok(())\n    /// }\n    /// ```\n    #[stable(feature = \"metadata_ext\", since = \"1.1.0\")]\n    fn mode(&self) -> u32;\n    /// Returns the number of hard links pointing to this file.\n    ///\n    /// # Examples\n    ///\n    /// ```no_run\n    /// use std::fs;\n    /// use std::os::unix::fs::MetadataExt;\n    /// use std::io;\n    ///\n    /// fn main() -> io::Result<()> {\n    ///     let meta = fs::metadata(\"some_file\")?;\n    ///     let nb_hard_links = meta.nlink();\n    ///     Ok(())\n    /// }\n    /// ```\n    #[stable(feature = \"metadata_ext\", since = \"1.1.0\")]\n    fn nlink(&self) -> u64;\n    /// Returns the user ID of the owner of this file.\n    ///\n    /// # Examples\n    ///\n    /// ```no_run\n    /// use std::fs;\n    /// use std::os::unix::fs::MetadataExt;\n    /// use std::io;\n    ///\n    /// fn main() -> io::Result<()> {\n    ///     let meta = fs::metadata(\"some_file\")?;\n    ///     let user_id = meta.uid();\n    ///     Ok(())\n    /// }\n    /// ```\n    #[stable(feature = \"metadata_ext\", since = \"1.1.0\")]\n    fn uid(&self) -> u32;\n    /// Returns the group ID of the owner of this file.\n    ///\n    /// # Examples\n    ///\n    /// ```no_run\n    /// use std::fs;\n    /// use std::os::unix::fs::MetadataExt;\n    /// use std::io;\n    ///\n    /// fn main() -> io::Result<()> {\n    ///     let meta = fs::metadata(\"some_file\")?;\n    ///     let group_id = meta.gid();\n    ///     Ok(())\n    /// }\n    /// ```\n    #[stable(feature = \"metadata_ext\", since = \"1.1.0\")]\n    fn gid(&self) -> u32;\n    /// Returns the device ID of this file (if it is a special one).\n    ///\n    /// # Examples\n    ///\n    /// ```no_run\n    /// use std::fs;\n    /// use std::os::unix::fs::MetadataExt;\n    /// use std::io;\n    ///\n    /// fn main() -> io::Result<()> {\n    ///     let meta = fs::metadata(\"some_file\")?;\n    ///     let device_id = meta.rdev();\n    ///     Ok(())\n    /// }\n    /// ```\n    #[stable(feature = \"metadata_ext\", since = \"1.1.0\")]\n    fn rdev(&self) -> u64;\n    /// Returns the total size of this file in bytes.\n    ///\n    /// # Examples\n    ///\n    /// ```no_run\n    /// use std::fs;\n    /// use std::os::unix::fs::MetadataExt;\n    /// use std::io;\n    ///\n    /// fn main() -> io::Result<()> {\n    ///     let meta = fs::metadata(\"some_file\")?;\n    ///     let file_size = meta.size();\n    ///     Ok(())\n    /// }\n    /// ```\n    #[stable(feature = \"metadata_ext\", since = \"1.1.0\")]\n    fn size(&self) -> u64;\n    /// Returns the last access time of the file, in seconds since Unix Epoch.\n    ///\n    /// # Examples\n    ///\n    /// ```no_run\n    /// use std::fs;\n    /// use std::os::unix::fs::MetadataExt;\n    /// use std::io;\n    ///\n    /// fn main() -> io::Result<()> {\n    ///     let meta = fs::metadata(\"some_file\")?;\n    ///     let last_access_time = meta.atime();\n    ///     Ok(())\n    /// }\n    /// ```\n    #[stable(feature = \"metadata_ext\", since = \"1.1.0\")]\n    fn atime(&self) -> i64;\n    /// Returns the last access time of the file, in nanoseconds since [`atime`].\n    ///\n    /// [`atime`]: MetadataExt::atime\n    ///\n    /// # Examples\n    ///\n    /// ```no_run\n    /// use std::fs;\n    /// use std::os::unix::fs::MetadataExt;\n    /// use std::io;\n    ///\n    /// fn main() -> io::Result<()> {\n    ///     let meta = fs::metadata(\"some_file\")?;\n    ///     let nano_last_access_time = meta.atime_nsec();\n    ///     Ok(())\n    /// }\n    /// ```\n    #[stable(feature = \"metadata_ext\", since = \"1.1.0\")]\n    fn atime_nsec(&self) -> i64;\n    /// Returns the last modification time of the file, in seconds since Unix Epoch.\n    ///\n    /// # Examples\n    ///\n    /// ```no_run\n    /// use std::fs;\n    /// use std::os::unix::fs::MetadataExt;\n    /// use std::io;\n    ///\n    /// fn main() -> io::Result<()> {\n    ///     let meta = fs::metadata(\"some_file\")?;\n    ///     let last_modification_time = meta.mtime();\n    ///     Ok(())\n    /// }\n    /// ```\n    #[stable(feature = \"metadata_ext\", since = \"1.1.0\")]\n    fn mtime(&self) -> i64;\n    /// Returns the last modification time of the file, in nanoseconds since [`mtime`].\n    ///\n    /// [`mtime`]: MetadataExt::mtime\n    ///\n    /// # Examples\n    ///\n    /// ```no_run\n    /// use std::fs;\n    /// use std::os::unix::fs::MetadataExt;\n    /// use std::io;\n    ///\n    /// fn main() -> io::Result<()> {\n    ///     let meta = fs::metadata(\"some_file\")?;\n    ///     let nano_last_modification_time = meta.mtime_nsec();\n    ///     Ok(())\n    /// }\n    /// ```\n    #[stable(feature = \"metadata_ext\", since = \"1.1.0\")]\n    fn mtime_nsec(&self) -> i64;\n    /// Returns the last status change time of the file, in seconds since Unix Epoch.\n    ///\n    /// # Examples\n    ///\n    /// ```no_run\n    /// use std::fs;\n    /// use std::os::unix::fs::MetadataExt;\n    /// use std::io;\n    ///\n    /// fn main() -> io::Result<()> {\n    ///     let meta = fs::metadata(\"some_file\")?;\n    ///     let last_status_change_time = meta.ctime();\n    ///     Ok(())\n    /// }\n    /// ```\n    #[stable(feature = \"metadata_ext\", since = \"1.1.0\")]\n    fn ctime(&self) -> i64;\n    /// Returns the last status change time of the file, in nanoseconds since [`ctime`].\n    ///\n    /// [`ctime`]: MetadataExt::ctime\n    ///\n    /// # Examples\n    ///\n    /// ```no_run\n    /// use std::fs;\n    /// use std::os::unix::fs::MetadataExt;\n    /// use std::io;\n    ///\n    /// fn main() -> io::Result<()> {\n    ///     let meta = fs::metadata(\"some_file\")?;\n    ///     let nano_last_status_change_time = meta.ctime_nsec();\n    ///     Ok(())\n    /// }\n    /// ```\n    #[stable(feature = \"metadata_ext\", since = \"1.1.0\")]\n    fn ctime_nsec(&self) -> i64;\n    /// Returns the block size for filesystem I/O.\n    ///\n    /// # Examples\n    ///\n    /// ```no_run\n    /// use std::fs;\n    /// use std::os::unix::fs::MetadataExt;\n    /// use std::io;\n    ///\n    /// fn main() -> io::Result<()> {\n    ///     let meta = fs::metadata(\"some_file\")?;\n    ///     let block_size = meta.blksize();\n    ///     Ok(())\n    /// }\n    /// ```\n    #[stable(feature = \"metadata_ext\", since = \"1.1.0\")]\n    fn blksize(&self) -> u64;\n    /// Returns the number of blocks allocated to the file, in 512-byte units.\n    ///\n    /// Please note that this may be smaller than `st_size / 512` when the file has holes.\n    ///\n    /// # Examples\n    ///\n    /// ```no_run\n    /// use std::fs;\n    /// use std::os::unix::fs::MetadataExt;\n    /// use std::io;\n    ///\n    /// fn main() -> io::Result<()> {\n    ///     let meta = fs::metadata(\"some_file\")?;\n    ///     let blocks = meta.blocks();\n    ///     Ok(())\n    /// }\n    /// ```\n    #[stable(feature = \"metadata_ext\", since = \"1.1.0\")]\n    fn blocks(&self) -> u64;\n    #[cfg(target_os = \"vxworks\")]\n    #[stable(feature = \"metadata_ext\", since = \"1.1.0\")]\n    fn attrib(&self) -> u8;\n}\n\n#[stable(feature = \"metadata_ext\", since = \"1.1.0\")]\nimpl MetadataExt for fs::Metadata {\n    fn dev(&self) -> u64 {\n        self.st_dev()\n    }\n    fn ino(&self) -> u64 {\n        self.st_ino()\n    }\n    fn mode(&self) -> u32 {\n        self.st_mode()\n    }\n    fn nlink(&self) -> u64 {\n        self.st_nlink()\n    }\n    fn uid(&self) -> u32 {\n        self.st_uid()\n    }\n    fn gid(&self) -> u32 {\n        self.st_gid()\n    }\n    fn rdev(&self) -> u64 {\n        self.st_rdev()\n    }\n    fn size(&self) -> u64 {\n        self.st_size()\n    }\n    fn atime(&self) -> i64 {\n        self.st_atime()\n    }\n    fn atime_nsec(&self) -> i64 {\n        self.st_atime_nsec()\n    }\n    fn mtime(&self) -> i64 {\n        self.st_mtime()\n    }\n    fn mtime_nsec(&self) -> i64 {\n        self.st_mtime_nsec()\n    }\n    fn ctime(&self) -> i64 {\n        self.st_ctime()\n    }\n    fn ctime_nsec(&self) -> i64 {\n        self.st_ctime_nsec()\n    }\n    fn blksize(&self) -> u64 {\n        self.st_blksize()\n    }\n    fn blocks(&self) -> u64 {\n        self.st_blocks()\n    }\n    #[cfg(target_os = \"vxworks\")]\n    fn attrib(&self) -> u8 {\n        self.st_attrib()\n    }\n}\n\n/// Unix-specific extensions for [`fs::FileType`].\n///\n/// Adds support for special Unix file types such as block/character devices,\n/// pipes, and sockets.\n#[stable(feature = \"file_type_ext\", since = \"1.5.0\")]\npub trait FileTypeExt {\n    /// Returns `true` if this file type is a block device.\n    ///\n    /// # Examples\n    ///\n    /// ```no_run\n    /// use std::fs;\n    /// use std::os::unix::fs::FileTypeExt;\n    /// use std::io;\n    ///\n    /// fn main() -> io::Result<()> {\n    ///     let meta = fs::metadata(\"block_device_file\")?;\n    ///     let file_type = meta.file_type();\n    ///     assert!(file_type.is_block_device());\n    ///     Ok(())\n    /// }\n    /// ```\n    #[stable(feature = \"file_type_ext\", since = \"1.5.0\")]\n    fn is_block_device(&self) -> bool;\n    /// Returns `true` if this file type is a char device.\n    ///\n    /// # Examples\n    ///\n    /// ```no_run\n    /// use std::fs;\n    /// use std::os::unix::fs::FileTypeExt;\n    /// use std::io;\n    ///\n    /// fn main() -> io::Result<()> {\n    ///     let meta = fs::metadata(\"char_device_file\")?;\n    ///     let file_type = meta.file_type();\n    ///     assert!(file_type.is_char_device());\n    ///     Ok(())\n    /// }\n    /// ```\n    #[stable(feature = \"file_type_ext\", since = \"1.5.0\")]\n    fn is_char_device(&self) -> bool;\n    /// Returns `true` if this file type is a fifo.\n    ///\n    /// # Examples\n    ///\n    /// ```no_run\n    /// use std::fs;\n    /// use std::os::unix::fs::FileTypeExt;\n    /// use std::io;\n    ///\n    /// fn main() -> io::Result<()> {\n    ///     let meta = fs::metadata(\"fifo_file\")?;\n    ///     let file_type = meta.file_type();\n    ///     assert!(file_type.is_fifo());\n    ///     Ok(())\n    /// }\n    /// ```\n    #[stable(feature = \"file_type_ext\", since = \"1.5.0\")]\n    fn is_fifo(&self) -> bool;\n    /// Returns `true` if this file type is a socket.\n    ///\n    /// # Examples\n    ///\n    /// ```no_run\n    /// use std::fs;\n    /// use std::os::unix::fs::FileTypeExt;\n    /// use std::io;\n    ///\n    /// fn main() -> io::Result<()> {\n    ///     let meta = fs::metadata(\"unix.socket\")?;\n    ///     let file_type = meta.file_type();\n    ///     assert!(file_type.is_socket());\n    ///     Ok(())\n    /// }\n    /// ```\n    #[stable(feature = \"file_type_ext\", since = \"1.5.0\")]\n    fn is_socket(&self) -> bool;\n}\n\n#[stable(feature = \"file_type_ext\", since = \"1.5.0\")]\nimpl FileTypeExt for fs::FileType {\n    fn is_block_device(&self) -> bool {\n        self.as_inner().is(libc::S_IFBLK)\n    }\n    fn is_char_device(&self) -> bool {\n        self.as_inner().is(libc::S_IFCHR)\n    }\n    fn is_fifo(&self) -> bool {\n        self.as_inner().is(libc::S_IFIFO)\n    }\n    fn is_socket(&self) -> bool {\n        self.as_inner().is(libc::S_IFSOCK)\n    }\n}\n\n/// Unix-specific extension methods for [`fs::DirEntry`].\n#[stable(feature = \"dir_entry_ext\", since = \"1.1.0\")]\npub trait DirEntryExt {\n    /// Returns the underlying `d_ino` field in the contained `dirent`\n    /// structure.\n    ///\n    /// # Examples\n    ///\n    /// ```\n    /// use std::fs;\n    /// use std::os::unix::fs::DirEntryExt;\n    ///\n    /// if let Ok(entries) = fs::read_dir(\".\") {\n    ///     for entry in entries {\n    ///         if let Ok(entry) = entry {\n    ///             // Here, `entry` is a `DirEntry`.\n    ///             println!(\"{:?}: {}\", entry.file_name(), entry.ino());\n    ///         }\n    ///     }\n    /// }\n    /// ```\n    #[stable(feature = \"dir_entry_ext\", since = \"1.1.0\")]\n    fn ino(&self) -> u64;\n}\n\n#[stable(feature = \"dir_entry_ext\", since = \"1.1.0\")]\nimpl DirEntryExt for fs::DirEntry {\n    fn ino(&self) -> u64 {\n        self.as_inner().ino()\n    }\n}\n\n/// Creates a new symbolic link on the filesystem.\n///\n/// The `link` path will be a symbolic link pointing to the `original` path.\n///\n/// # Examples\n///\n/// ```no_run\n/// use std::os::unix::fs;\n///\n/// fn main() -> std::io::Result<()> {\n///     fs::symlink(\"a.txt\", \"b.txt\")?;\n///     Ok(())\n/// }\n/// ```\n#[stable(feature = \"symlink\", since = \"1.1.0\")]\npub fn symlink<P: AsRef<Path>, Q: AsRef<Path>>(original: P, link: Q) -> io::Result<()> {\n    sys::fs::symlink(original.as_ref(), link.as_ref())\n}\n\n/// Unix-specific extensions to [`fs::DirBuilder`].\n#[stable(feature = \"dir_builder\", since = \"1.6.0\")]\npub trait DirBuilderExt {\n    /// Sets the mode to create new directories with. This option defaults to\n    /// 0o777.\n    ///\n    /// # Examples\n    ///\n    /// ```no_run\n    /// use std::fs::DirBuilder;\n    /// use std::os::unix::fs::DirBuilderExt;\n    ///\n    /// let mut builder = DirBuilder::new();\n    /// builder.mode(0o755);\n    /// ```\n    #[stable(feature = \"dir_builder\", since = \"1.6.0\")]\n    fn mode(&mut self, mode: u32) -> &mut Self;\n}\n\n#[stable(feature = \"dir_builder\", since = \"1.6.0\")]\nimpl DirBuilderExt for fs::DirBuilder {\n    fn mode(&mut self, mode: u32) -> &mut fs::DirBuilder {\n        self.as_inner_mut().set_mode(mode);\n        self\n    }\n}\n\n/// Change the root directory of the current process to the specified path.\n///\n/// This typically requires privileges, such as root or a specific capability.\n///\n/// This does not change the current working directory; you should call\n/// [`std::env::set_current_dir`][`crate::env::set_current_dir`] afterwards.\n///\n/// # Examples\n///\n/// ```no_run\n/// #![feature(unix_chroot)]\n/// use std::os::unix::fs;\n///\n/// fn main() -> std::io::Result<()> {\n///     fs::chroot(\"/sandbox\")?;\n///     std::env::set_current_dir(\"/\")?;\n///     // continue working in sandbox\n///     Ok(())\n/// }\n/// ```\n#[unstable(feature = \"unix_chroot\", issue = \"84715\")]\n#[cfg(not(any(target_os = \"fuchsia\", target_os = \"vxworks\")))]\npub fn chroot<P: AsRef<Path>>(dir: P) -> io::Result<()> {\n    sys::fs::chroot(dir.as_ref())\n}\n"],[2147,"#[cfg(any(\n    doc,\n    target_os = \"android\",\n    target_os = \"dragonfly\",\n    target_os = \"emscripten\",\n    target_os = \"freebsd\",\n    target_os = \"linux\",\n    target_os = \"netbsd\",\n    target_os = \"openbsd\",\n))]\nuse super::{recv_vectored_with_ancillary_from, send_vectored_with_ancillary_to, SocketAncillary};\nuse super::{sockaddr_un, SocketAddr};\nuse crate::fmt;\nuse crate::io::{self, Initializer, IoSlice, IoSliceMut};\nuse crate::net::Shutdown;\nuse crate::os::unix::io::{AsRawFd, FromRawFd, IntoRawFd, RawFd};\n#[cfg(any(\n    target_os = \"android\",\n    target_os = \"linux\",\n    target_os = \"dragonfly\",\n    target_os = \"freebsd\",\n    target_os = \"ios\",\n    target_os = \"macos\",\n    target_os = \"openbsd\"\n))]\nuse crate::os::unix::ucred;\nuse crate::path::Path;\nuse crate::sys::cvt;\nuse crate::sys::net::Socket;\nuse crate::sys_common::{AsInner, FromInner, IntoInner};\nuse crate::time::Duration;\n\n#[unstable(feature = \"peer_credentials_unix_socket\", issue = \"42839\", reason = \"unstable\")]\n#[cfg(any(\n    target_os = \"android\",\n    target_os = \"linux\",\n    target_os = \"dragonfly\",\n    target_os = \"freebsd\",\n    target_os = \"ios\",\n    target_os = \"macos\",\n    target_os = \"openbsd\"\n))]\npub use ucred::UCred;\n\n/// A Unix stream socket.\n///\n/// # Examples\n///\n/// ```no_run\n/// use std::os::unix::net::UnixStream;\n/// use std::io::prelude::*;\n///\n/// fn main() -> std::io::Result<()> {\n///     let mut stream = UnixStream::connect(\"/path/to/my/socket\")?;\n///     stream.write_all(b\"hello world\")?;\n///     let mut response = String::new();\n///     stream.read_to_string(&mut response)?;\n///     println!(\"{}\", response);\n///     Ok(())\n/// }\n/// ```\n#[stable(feature = \"unix_socket\", since = \"1.10.0\")]\npub struct UnixStream(pub(super) Socket);\n\n#[stable(feature = \"unix_socket\", since = \"1.10.0\")]\nimpl fmt::Debug for UnixStream {\n    fn fmt(&self, fmt: &mut fmt::Formatter<'_>) -> fmt::Result {\n        let mut builder = fmt.debug_struct(\"UnixStream\");\n        builder.field(\"fd\", self.0.as_inner());\n        if let Ok(addr) = self.local_addr() {\n            builder.field(\"local\", &addr);\n        }\n        if let Ok(addr) = self.peer_addr() {\n            builder.field(\"peer\", &addr);\n        }\n        builder.finish()\n    }\n}\n\nimpl UnixStream {\n    /// Connects to the socket named by `path`.\n    ///\n    /// # Examples\n    ///\n    /// ```no_run\n    /// use std::os::unix::net::UnixStream;\n    ///\n    /// let socket = match UnixStream::connect(\"/tmp/sock\") {\n    ///     Ok(sock) => sock,\n    ///     Err(e) => {\n    ///         println!(\"Couldn't connect: {:?}\", e);\n    ///         return\n    ///     }\n    /// };\n    /// ```\n    #[stable(feature = \"unix_socket\", since = \"1.10.0\")]\n    pub fn connect<P: AsRef<Path>>(path: P) -> io::Result<UnixStream> {\n        unsafe {\n            let inner = Socket::new_raw(libc::AF_UNIX, libc::SOCK_STREAM)?;\n            let (addr, len) = sockaddr_un(path.as_ref())?;\n\n            cvt(libc::connect(*inner.as_inner(), &addr as *const _ as *const _, len))?;\n            Ok(UnixStream(inner))\n        }\n    }\n\n    /// Creates an unnamed pair of connected sockets.\n    ///\n    /// Returns two `UnixStream`s which are connected to each other.\n    ///\n    /// # Examples\n    ///\n    /// ```no_run\n    /// use std::os::unix::net::UnixStream;\n    ///\n    /// let (sock1, sock2) = match UnixStream::pair() {\n    ///     Ok((sock1, sock2)) => (sock1, sock2),\n    ///     Err(e) => {\n    ///         println!(\"Couldn't create a pair of sockets: {:?}\", e);\n    ///         return\n    ///     }\n    /// };\n    /// ```\n    #[stable(feature = \"unix_socket\", since = \"1.10.0\")]\n    pub fn pair() -> io::Result<(UnixStream, UnixStream)> {\n        let (i1, i2) = Socket::new_pair(libc::AF_UNIX, libc::SOCK_STREAM)?;\n        Ok((UnixStream(i1), UnixStream(i2)))\n    }\n\n    /// Creates a new independently owned handle to the underlying socket.\n    ///\n    /// The returned `UnixStream` is a reference to the same stream that this\n    /// object references. Both handles will read and write the same stream of\n    /// data, and options set on one stream will be propagated to the other\n    /// stream.\n    ///\n    /// # Examples\n    ///\n    /// ```no_run\n    /// use std::os::unix::net::UnixStream;\n    ///\n    /// fn main() -> std::io::Result<()> {\n    ///     let socket = UnixStream::connect(\"/tmp/sock\")?;\n    ///     let sock_copy = socket.try_clone().expect(\"Couldn't clone socket\");\n    ///     Ok(())\n    /// }\n    /// ```\n    #[stable(feature = \"unix_socket\", since = \"1.10.0\")]\n    pub fn try_clone(&self) -> io::Result<UnixStream> {\n        self.0.duplicate().map(UnixStream)\n    }\n\n    /// Returns the socket address of the local half of this connection.\n    ///\n    /// # Examples\n    ///\n    /// ```no_run\n    /// use std::os::unix::net::UnixStream;\n    ///\n    /// fn main() -> std::io::Result<()> {\n    ///     let socket = UnixStream::connect(\"/tmp/sock\")?;\n    ///     let addr = socket.local_addr().expect(\"Couldn't get local address\");\n    ///     Ok(())\n    /// }\n    /// ```\n    #[stable(feature = \"unix_socket\", since = \"1.10.0\")]\n    pub fn local_addr(&self) -> io::Result<SocketAddr> {\n        SocketAddr::new(|addr, len| unsafe { libc::getsockname(*self.0.as_inner(), addr, len) })\n    }\n\n    /// Returns the socket address of the remote half of this connection.\n    ///\n    /// # Examples\n    ///\n    /// ```no_run\n    /// use std::os::unix::net::UnixStream;\n    ///\n    /// fn main() -> std::io::Result<()> {\n    ///     let socket = UnixStream::connect(\"/tmp/sock\")?;\n    ///     let addr = socket.peer_addr().expect(\"Couldn't get peer address\");\n    ///     Ok(())\n    /// }\n    /// ```\n    #[stable(feature = \"unix_socket\", since = \"1.10.0\")]\n    pub fn peer_addr(&self) -> io::Result<SocketAddr> {\n        SocketAddr::new(|addr, len| unsafe { libc::getpeername(*self.0.as_inner(), addr, len) })\n    }\n\n    /// Gets the peer credentials for this Unix domain socket.\n    ///\n    /// # Examples\n    ///\n    /// ```no_run\n    /// #![feature(peer_credentials_unix_socket)]\n    /// use std::os::unix::net::UnixStream;\n    ///\n    /// fn main() -> std::io::Result<()> {\n    ///     let socket = UnixStream::connect(\"/tmp/sock\")?;\n    ///     let peer_cred = socket.peer_cred().expect(\"Couldn't get peer credentials\");\n    ///     Ok(())\n    /// }\n    /// ```\n    #[unstable(feature = \"peer_credentials_unix_socket\", issue = \"42839\", reason = \"unstable\")]\n    #[cfg(any(\n        target_os = \"android\",\n        target_os = \"linux\",\n        target_os = \"dragonfly\",\n        target_os = \"freebsd\",\n        target_os = \"ios\",\n        target_os = \"macos\",\n        target_os = \"openbsd\"\n    ))]\n    pub fn peer_cred(&self) -> io::Result<UCred> {\n        ucred::peer_cred(self)\n    }\n\n    /// Sets the read timeout for the socket.\n    ///\n    /// If the provided value is [`None`], then [`read`] calls will block\n    /// indefinitely. An [`Err`] is returned if the zero [`Duration`] is passed to this\n    /// method.\n    ///\n    /// [`read`]: io::Read::read\n    ///\n    /// # Examples\n    ///\n    /// ```no_run\n    /// use std::os::unix::net::UnixStream;\n    /// use std::time::Duration;\n    ///\n    /// fn main() -> std::io::Result<()> {\n    ///     let socket = UnixStream::connect(\"/tmp/sock\")?;\n    ///     socket.set_read_timeout(Some(Duration::new(1, 0))).expect(\"Couldn't set read timeout\");\n    ///     Ok(())\n    /// }\n    /// ```\n    ///\n    /// An [`Err`] is returned if the zero [`Duration`] is passed to this\n    /// method:\n    ///\n    /// ```no_run\n    /// use std::io;\n    /// use std::os::unix::net::UnixStream;\n    /// use std::time::Duration;\n    ///\n    /// fn main() -> std::io::Result<()> {\n    ///     let socket = UnixStream::connect(\"/tmp/sock\")?;\n    ///     let result = socket.set_read_timeout(Some(Duration::new(0, 0)));\n    ///     let err = result.unwrap_err();\n    ///     assert_eq!(err.kind(), io::ErrorKind::InvalidInput);\n    ///     Ok(())\n    /// }\n    /// ```\n    #[stable(feature = \"unix_socket\", since = \"1.10.0\")]\n    pub fn set_read_timeout(&self, timeout: Option<Duration>) -> io::Result<()> {\n        self.0.set_timeout(timeout, libc::SO_RCVTIMEO)\n    }\n\n    /// Sets the write timeout for the socket.\n    ///\n    /// If the provided value is [`None`], then [`write`] calls will block\n    /// indefinitely. An [`Err`] is returned if the zero [`Duration`] is\n    /// passed to this method.\n    ///\n    /// [`read`]: io::Read::read\n    ///\n    /// # Examples\n    ///\n    /// ```no_run\n    /// use std::os::unix::net::UnixStream;\n    /// use std::time::Duration;\n    ///\n    /// fn main() -> std::io::Result<()> {\n    ///     let socket = UnixStream::connect(\"/tmp/sock\")?;\n    ///     socket.set_write_timeout(Some(Duration::new(1, 0)))\n    ///         .expect(\"Couldn't set write timeout\");\n    ///     Ok(())\n    /// }\n    /// ```\n    ///\n    /// An [`Err`] is returned if the zero [`Duration`] is passed to this\n    /// method:\n    ///\n    /// ```no_run\n    /// use std::io;\n    /// use std::net::UdpSocket;\n    /// use std::time::Duration;\n    ///\n    /// fn main() -> std::io::Result<()> {\n    ///     let socket = UdpSocket::bind(\"127.0.0.1:34254\")?;\n    ///     let result = socket.set_write_timeout(Some(Duration::new(0, 0)));\n    ///     let err = result.unwrap_err();\n    ///     assert_eq!(err.kind(), io::ErrorKind::InvalidInput);\n    ///     Ok(())\n    /// }\n    /// ```\n    #[stable(feature = \"unix_socket\", since = \"1.10.0\")]\n    pub fn set_write_timeout(&self, timeout: Option<Duration>) -> io::Result<()> {\n        self.0.set_timeout(timeout, libc::SO_SNDTIMEO)\n    }\n\n    /// Returns the read timeout of this socket.\n    ///\n    /// # Examples\n    ///\n    /// ```no_run\n    /// use std::os::unix::net::UnixStream;\n    /// use std::time::Duration;\n    ///\n    /// fn main() -> std::io::Result<()> {\n    ///     let socket = UnixStream::connect(\"/tmp/sock\")?;\n    ///     socket.set_read_timeout(Some(Duration::new(1, 0))).expect(\"Couldn't set read timeout\");\n    ///     assert_eq!(socket.read_timeout()?, Some(Duration::new(1, 0)));\n    ///     Ok(())\n    /// }\n    /// ```\n    #[stable(feature = \"unix_socket\", since = \"1.10.0\")]\n    pub fn read_timeout(&self) -> io::Result<Option<Duration>> {\n        self.0.timeout(libc::SO_RCVTIMEO)\n    }\n\n    /// Returns the write timeout of this socket.\n    ///\n    /// # Examples\n    ///\n    /// ```no_run\n    /// use std::os::unix::net::UnixStream;\n    /// use std::time::Duration;\n    ///\n    /// fn main() -> std::io::Result<()> {\n    ///     let socket = UnixStream::connect(\"/tmp/sock\")?;\n    ///     socket.set_write_timeout(Some(Duration::new(1, 0)))\n    ///         .expect(\"Couldn't set write timeout\");\n    ///     assert_eq!(socket.write_timeout()?, Some(Duration::new(1, 0)));\n    ///     Ok(())\n    /// }\n    /// ```\n    #[stable(feature = \"unix_socket\", since = \"1.10.0\")]\n    pub fn write_timeout(&self) -> io::Result<Option<Duration>> {\n        self.0.timeout(libc::SO_SNDTIMEO)\n    }\n\n    /// Moves the socket into or out of nonblocking mode.\n    ///\n    /// # Examples\n    ///\n    /// ```no_run\n    /// use std::os::unix::net::UnixStream;\n    ///\n    /// fn main() -> std::io::Result<()> {\n    ///     let socket = UnixStream::connect(\"/tmp/sock\")?;\n    ///     socket.set_nonblocking(true).expect(\"Couldn't set nonblocking\");\n    ///     Ok(())\n    /// }\n    /// ```\n    #[stable(feature = \"unix_socket\", since = \"1.10.0\")]\n    pub fn set_nonblocking(&self, nonblocking: bool) -> io::Result<()> {\n        self.0.set_nonblocking(nonblocking)\n    }\n\n    /// Moves the socket to pass unix credentials as control message in [`SocketAncillary`].\n    ///\n    /// Set the socket option `SO_PASSCRED`.\n    ///\n    /// # Examples\n    ///\n    #[cfg_attr(any(target_os = \"android\", target_os = \"linux\"), doc = \"```no_run\")]\n    #[cfg_attr(not(any(target_os = \"android\", target_os = \"linux\")), doc = \"```ignore\")]\n    /// #![feature(unix_socket_ancillary_data)]\n    /// use std::os::unix::net::UnixStream;\n    ///\n    /// fn main() -> std::io::Result<()> {\n    ///     let socket = UnixStream::connect(\"/tmp/sock\")?;\n    ///     socket.set_passcred(true).expect(\"Couldn't set passcred\");\n    ///     Ok(())\n    /// }\n    /// ```\n    #[cfg(any(doc, target_os = \"android\", target_os = \"linux\",))]\n    #[unstable(feature = \"unix_socket_ancillary_data\", issue = \"76915\")]\n    pub fn set_passcred(&self, passcred: bool) -> io::Result<()> {\n        self.0.set_passcred(passcred)\n    }\n\n    /// Get the current value of the socket for passing unix credentials in [`SocketAncillary`].\n    /// This value can be change by [`set_passcred`].\n    ///\n    /// Get the socket option `SO_PASSCRED`.\n    ///\n    /// [`set_passcred`]: UnixStream::set_passcred\n    #[cfg(any(doc, target_os = \"android\", target_os = \"linux\",))]\n    #[unstable(feature = \"unix_socket_ancillary_data\", issue = \"76915\")]\n    pub fn passcred(&self) -> io::Result<bool> {\n        self.0.passcred()\n    }\n\n    /// Returns the value of the `SO_ERROR` option.\n    ///\n    /// # Examples\n    ///\n    /// ```no_run\n    /// use std::os::unix::net::UnixStream;\n    ///\n    /// fn main() -> std::io::Result<()> {\n    ///     let socket = UnixStream::connect(\"/tmp/sock\")?;\n    ///     if let Ok(Some(err)) = socket.take_error() {\n    ///         println!(\"Got error: {:?}\", err);\n    ///     }\n    ///     Ok(())\n    /// }\n    /// ```\n    ///\n    /// # Platform specific\n    /// On Redox this always returns `None`.\n    #[stable(feature = \"unix_socket\", since = \"1.10.0\")]\n    pub fn take_error(&self) -> io::Result<Option<io::Error>> {\n        self.0.take_error()\n    }\n\n    /// Shuts down the read, write, or both halves of this connection.\n    ///\n    /// This function will cause all pending and future I/O calls on the\n    /// specified portions to immediately return with an appropriate value\n    /// (see the documentation of [`Shutdown`]).\n    ///\n    /// # Examples\n    ///\n    /// ```no_run\n    /// use std::os::unix::net::UnixStream;\n    /// use std::net::Shutdown;\n    ///\n    /// fn main() -> std::io::Result<()> {\n    ///     let socket = UnixStream::connect(\"/tmp/sock\")?;\n    ///     socket.shutdown(Shutdown::Both).expect(\"shutdown function failed\");\n    ///     Ok(())\n    /// }\n    /// ```\n    #[stable(feature = \"unix_socket\", since = \"1.10.0\")]\n    pub fn shutdown(&self, how: Shutdown) -> io::Result<()> {\n        self.0.shutdown(how)\n    }\n\n    /// Receives data on the socket from the remote address to which it is\n    /// connected, without removing that data from the queue. On success,\n    /// returns the number of bytes peeked.\n    ///\n    /// Successive calls return the same data. This is accomplished by passing\n    /// `MSG_PEEK` as a flag to the underlying `recv` system call.\n    ///\n    /// # Examples\n    ///\n    /// ```no_run\n    /// #![feature(unix_socket_peek)]\n    ///\n    /// use std::os::unix::net::UnixStream;\n    ///\n    /// fn main() -> std::io::Result<()> {\n    ///     let socket = UnixStream::connect(\"/tmp/sock\")?;\n    ///     let mut buf = [0; 10];\n    ///     let len = socket.peek(&mut buf).expect(\"peek failed\");\n    ///     Ok(())\n    /// }\n    /// ```\n    #[unstable(feature = \"unix_socket_peek\", issue = \"76923\")]\n    pub fn peek(&self, buf: &mut [u8]) -> io::Result<usize> {\n        self.0.peek(buf)\n    }\n\n    /// Receives data and ancillary data from socket.\n    ///\n    /// On success, returns the number of bytes read.\n    ///\n    /// # Examples\n    ///\n    /// ```no_run\n    /// #![feature(unix_socket_ancillary_data)]\n    /// use std::os::unix::net::{UnixStream, SocketAncillary, AncillaryData};\n    /// use std::io::IoSliceMut;\n    ///\n    /// fn main() -> std::io::Result<()> {\n    ///     let socket = UnixStream::connect(\"/tmp/sock\")?;\n    ///     let mut buf1 = [1; 8];\n    ///     let mut buf2 = [2; 16];\n    ///     let mut buf3 = [3; 8];\n    ///     let mut bufs = &mut [\n    ///         IoSliceMut::new(&mut buf1),\n    ///         IoSliceMut::new(&mut buf2),\n    ///         IoSliceMut::new(&mut buf3),\n    ///     ][..];\n    ///     let mut fds = [0; 8];\n    ///     let mut ancillary_buffer = [0; 128];\n    ///     let mut ancillary = SocketAncillary::new(&mut ancillary_buffer[..]);\n    ///     let size = socket.recv_vectored_with_ancillary(bufs, &mut ancillary)?;\n    ///     println!(\"received {}\", size);\n    ///     for ancillary_result in ancillary.messages() {\n    ///         if let AncillaryData::ScmRights(scm_rights) = ancillary_result.unwrap() {\n    ///             for fd in scm_rights {\n    ///                 println!(\"receive file descriptor: {}\", fd);\n    ///             }\n    ///         }\n    ///     }\n    ///     Ok(())\n    /// }\n    /// ```\n    #[cfg(any(\n        target_os = \"android\",\n        target_os = \"dragonfly\",\n        target_os = \"emscripten\",\n        target_os = \"freebsd\",\n        target_os = \"linux\",\n        target_os = \"netbsd\",\n        target_os = \"openbsd\",\n    ))]\n    #[unstable(feature = \"unix_socket_ancillary_data\", issue = \"76915\")]\n    pub fn recv_vectored_with_ancillary(\n        &self,\n        bufs: &mut [IoSliceMut<'_>],\n        ancillary: &mut SocketAncillary<'_>,\n    ) -> io::Result<usize> {\n        let (count, _, _) = recv_vectored_with_ancillary_from(&self.0, bufs, ancillary)?;\n\n        Ok(count)\n    }\n\n    /// Sends data and ancillary data on the socket.\n    ///\n    /// On success, returns the number of bytes written.\n    ///\n    /// # Examples\n    ///\n    /// ```no_run\n    /// #![feature(unix_socket_ancillary_data)]\n    /// use std::os::unix::net::{UnixStream, SocketAncillary};\n    /// use std::io::IoSlice;\n    ///\n    /// fn main() -> std::io::Result<()> {\n    ///     let socket = UnixStream::connect(\"/tmp/sock\")?;\n    ///     let buf1 = [1; 8];\n    ///     let buf2 = [2; 16];\n    ///     let buf3 = [3; 8];\n    ///     let bufs = &[\n    ///         IoSlice::new(&buf1),\n    ///         IoSlice::new(&buf2),\n    ///         IoSlice::new(&buf3),\n    ///     ][..];\n    ///     let fds = [0, 1, 2];\n    ///     let mut ancillary_buffer = [0; 128];\n    ///     let mut ancillary = SocketAncillary::new(&mut ancillary_buffer[..]);\n    ///     ancillary.add_fds(&fds[..]);\n    ///     socket.send_vectored_with_ancillary(bufs, &mut ancillary)\n    ///         .expect(\"send_vectored_with_ancillary function failed\");\n    ///     Ok(())\n    /// }\n    /// ```\n    #[cfg(any(\n        target_os = \"android\",\n        target_os = \"dragonfly\",\n        target_os = \"emscripten\",\n        target_os = \"freebsd\",\n        target_os = \"linux\",\n        target_os = \"netbsd\",\n        target_os = \"openbsd\",\n    ))]\n    #[unstable(feature = \"unix_socket_ancillary_data\", issue = \"76915\")]\n    pub fn send_vectored_with_ancillary(\n        &self,\n        bufs: &[IoSlice<'_>],\n        ancillary: &mut SocketAncillary<'_>,\n    ) -> io::Result<usize> {\n        send_vectored_with_ancillary_to(&self.0, None, bufs, ancillary)\n    }\n}\n\n#[stable(feature = \"unix_socket\", since = \"1.10.0\")]\nimpl io::Read for UnixStream {\n    fn read(&mut self, buf: &mut [u8]) -> io::Result<usize> {\n        io::Read::read(&mut &*self, buf)\n    }\n\n    fn read_vectored(&mut self, bufs: &mut [IoSliceMut<'_>]) -> io::Result<usize> {\n        io::Read::read_vectored(&mut &*self, bufs)\n    }\n\n    #[inline]\n    fn is_read_vectored(&self) -> bool {\n        io::Read::is_read_vectored(&&*self)\n    }\n\n    #[inline]\n    unsafe fn initializer(&self) -> Initializer {\n        Initializer::nop()\n    }\n}\n\n#[stable(feature = \"unix_socket\", since = \"1.10.0\")]\nimpl<'a> io::Read for &'a UnixStream {\n    fn read(&mut self, buf: &mut [u8]) -> io::Result<usize> {\n        self.0.read(buf)\n    }\n\n    fn read_vectored(&mut self, bufs: &mut [IoSliceMut<'_>]) -> io::Result<usize> {\n        self.0.read_vectored(bufs)\n    }\n\n    #[inline]\n    fn is_read_vectored(&self) -> bool {\n        self.0.is_read_vectored()\n    }\n\n    #[inline]\n    unsafe fn initializer(&self) -> Initializer {\n        Initializer::nop()\n    }\n}\n\n#[stable(feature = \"unix_socket\", since = \"1.10.0\")]\nimpl io::Write for UnixStream {\n    fn write(&mut self, buf: &[u8]) -> io::Result<usize> {\n        io::Write::write(&mut &*self, buf)\n    }\n\n    fn write_vectored(&mut self, bufs: &[IoSlice<'_>]) -> io::Result<usize> {\n        io::Write::write_vectored(&mut &*self, bufs)\n    }\n\n    #[inline]\n    fn is_write_vectored(&self) -> bool {\n        io::Write::is_write_vectored(&&*self)\n    }\n\n    fn flush(&mut self) -> io::Result<()> {\n        io::Write::flush(&mut &*self)\n    }\n}\n\n#[stable(feature = \"unix_socket\", since = \"1.10.0\")]\nimpl<'a> io::Write for &'a UnixStream {\n    fn write(&mut self, buf: &[u8]) -> io::Result<usize> {\n        self.0.write(buf)\n    }\n\n    fn write_vectored(&mut self, bufs: &[IoSlice<'_>]) -> io::Result<usize> {\n        self.0.write_vectored(bufs)\n    }\n\n    #[inline]\n    fn is_write_vectored(&self) -> bool {\n        self.0.is_write_vectored()\n    }\n\n    fn flush(&mut self) -> io::Result<()> {\n        Ok(())\n    }\n}\n\n#[stable(feature = \"unix_socket\", since = \"1.10.0\")]\nimpl AsRawFd for UnixStream {\n    #[inline]\n    fn as_raw_fd(&self) -> RawFd {\n        *self.0.as_inner()\n    }\n}\n\n#[stable(feature = \"unix_socket\", since = \"1.10.0\")]\nimpl FromRawFd for UnixStream {\n    #[inline]\n    unsafe fn from_raw_fd(fd: RawFd) -> UnixStream {\n        UnixStream(Socket::from_inner(fd))\n    }\n}\n\n#[stable(feature = \"unix_socket\", since = \"1.10.0\")]\nimpl IntoRawFd for UnixStream {\n    #[inline]\n    fn into_raw_fd(self) -> RawFd {\n        self.0.into_inner()\n    }\n}\n"],[2148,"use crate::os::unix::io::{AsRawFd, FromRawFd, IntoRawFd, RawFd};\nuse crate::sys_common::{self, AsInner, FromInner, IntoInner};\nuse crate::{net, sys};\n\nmacro_rules! impl_as_raw_fd {\n    ($($t:ident)*) => {$(\n        #[stable(feature = \"rust1\", since = \"1.0.0\")]\n        impl AsRawFd for net::$t {\n            #[inline]\n            fn as_raw_fd(&self) -> RawFd {\n                *self.as_inner().socket().as_inner()\n            }\n        }\n    )*};\n}\nimpl_as_raw_fd! { TcpStream TcpListener UdpSocket }\n\nmacro_rules! impl_from_raw_fd {\n    ($($t:ident)*) => {$(\n        #[stable(feature = \"from_raw_os\", since = \"1.1.0\")]\n        impl FromRawFd for net::$t {\n            #[inline]\n            unsafe fn from_raw_fd(fd: RawFd) -> net::$t {\n                let socket = sys::net::Socket::from_inner(fd);\n                net::$t::from_inner(sys_common::net::$t::from_inner(socket))\n            }\n        }\n    )*};\n}\nimpl_from_raw_fd! { TcpStream TcpListener UdpSocket }\n\nmacro_rules! impl_into_raw_fd {\n    ($($t:ident)*) => {$(\n        #[stable(feature = \"into_raw_os\", since = \"1.4.0\")]\n        impl IntoRawFd for net::$t {\n            #[inline]\n            fn into_raw_fd(self) -> RawFd {\n                self.into_inner().into_socket().into_inner()\n            }\n        }\n    )*};\n}\nimpl_into_raw_fd! { TcpStream TcpListener UdpSocket }\n"],[2149,"use super::{sockaddr_un, SocketAddr};\nuse crate::convert::TryFrom;\nuse crate::io::{self, IoSlice, IoSliceMut};\nuse crate::marker::PhantomData;\nuse crate::mem::{size_of, zeroed};\nuse crate::os::unix::io::RawFd;\nuse crate::path::Path;\nuse crate::ptr::{eq, read_unaligned};\nuse crate::slice::from_raw_parts;\nuse crate::sys::net::Socket;\n\n// FIXME(#43348): Make libc adapt #[doc(cfg(...))] so we don't need these fake definitions here?\n#[cfg(all(doc, not(target_os = \"linux\"), not(target_os = \"android\")))]\n#[allow(non_camel_case_types)]\nmod libc {\n    pub use libc::c_int;\n    pub struct ucred;\n    pub struct cmsghdr;\n    pub type pid_t = i32;\n    pub type gid_t = u32;\n    pub type uid_t = u32;\n}\n\npub(super) fn recv_vectored_with_ancillary_from(\n    socket: &Socket,\n    bufs: &mut [IoSliceMut<'_>],\n    ancillary: &mut SocketAncillary<'_>,\n) -> io::Result<(usize, bool, io::Result<SocketAddr>)> {\n    unsafe {\n        let mut msg_name: libc::sockaddr_un = zeroed();\n        let mut msg: libc::msghdr = zeroed();\n        msg.msg_name = &mut msg_name as *mut _ as *mut _;\n        msg.msg_namelen = size_of::<libc::sockaddr_un>() as libc::socklen_t;\n        msg.msg_iov = bufs.as_mut_ptr().cast();\n        msg.msg_iovlen = bufs.len() as _;\n        msg.msg_controllen = ancillary.buffer.len() as _;\n        // macos requires that the control pointer is null when the len is 0.\n        if msg.msg_controllen > 0 {\n            msg.msg_control = ancillary.buffer.as_mut_ptr().cast();\n        }\n\n        let count = socket.recv_msg(&mut msg)?;\n\n        ancillary.length = msg.msg_controllen as usize;\n        ancillary.truncated = msg.msg_flags & libc::MSG_CTRUNC == libc::MSG_CTRUNC;\n\n        let truncated = msg.msg_flags & libc::MSG_TRUNC == libc::MSG_TRUNC;\n        let addr = SocketAddr::from_parts(msg_name, msg.msg_namelen);\n\n        Ok((count, truncated, addr))\n    }\n}\n\npub(super) fn send_vectored_with_ancillary_to(\n    socket: &Socket,\n    path: Option<&Path>,\n    bufs: &[IoSlice<'_>],\n    ancillary: &mut SocketAncillary<'_>,\n) -> io::Result<usize> {\n    unsafe {\n        let (mut msg_name, msg_namelen) =\n            if let Some(path) = path { sockaddr_un(path)? } else { (zeroed(), 0) };\n\n        let mut msg: libc::msghdr = zeroed();\n        msg.msg_name = &mut msg_name as *mut _ as *mut _;\n        msg.msg_namelen = msg_namelen;\n        msg.msg_iov = bufs.as_ptr() as *mut _;\n        msg.msg_iovlen = bufs.len() as _;\n        msg.msg_controllen = ancillary.length as _;\n        // macos requires that the control pointer is null when the len is 0.\n        if msg.msg_controllen > 0 {\n            msg.msg_control = ancillary.buffer.as_mut_ptr().cast();\n        }\n\n        ancillary.truncated = false;\n\n        socket.send_msg(&mut msg)\n    }\n}\n\nfn add_to_ancillary_data<T>(\n    buffer: &mut [u8],\n    length: &mut usize,\n    source: &[T],\n    cmsg_level: libc::c_int,\n    cmsg_type: libc::c_int,\n) -> bool {\n    let source_len = if let Some(source_len) = source.len().checked_mul(size_of::<T>()) {\n        if let Ok(source_len) = u32::try_from(source_len) {\n            source_len\n        } else {\n            return false;\n        }\n    } else {\n        return false;\n    };\n\n    unsafe {\n        let additional_space = libc::CMSG_SPACE(source_len) as usize;\n\n        let new_length = if let Some(new_length) = additional_space.checked_add(*length) {\n            new_length\n        } else {\n            return false;\n        };\n\n        if new_length > buffer.len() {\n            return false;\n        }\n\n        buffer[*length..new_length].fill(0);\n\n        *length = new_length;\n\n        let mut msg: libc::msghdr = zeroed();\n        msg.msg_control = buffer.as_mut_ptr().cast();\n        msg.msg_controllen = *length as _;\n\n        let mut cmsg = libc::CMSG_FIRSTHDR(&msg);\n        let mut previous_cmsg = cmsg;\n        while !cmsg.is_null() {\n            previous_cmsg = cmsg;\n            cmsg = libc::CMSG_NXTHDR(&msg, cmsg);\n\n            // Most operating systems, but not Linux or emscripten, return the previous pointer\n            // when its length is zero. Therefore, check if the previous pointer is the same as\n            // the current one.\n            if eq(cmsg, previous_cmsg) {\n                break;\n            }\n        }\n\n        if previous_cmsg.is_null() {\n            return false;\n        }\n\n        (*previous_cmsg).cmsg_level = cmsg_level;\n        (*previous_cmsg).cmsg_type = cmsg_type;\n        (*previous_cmsg).cmsg_len = libc::CMSG_LEN(source_len) as _;\n\n        let data = libc::CMSG_DATA(previous_cmsg).cast();\n\n        libc::memcpy(data, source.as_ptr().cast(), source_len as usize);\n    }\n    true\n}\n\nstruct AncillaryDataIter<'a, T> {\n    data: &'a [u8],\n    phantom: PhantomData<T>,\n}\n\nimpl<'a, T> AncillaryDataIter<'a, T> {\n    /// Create `AncillaryDataIter` struct to iterate through the data unit in the control message.\n    ///\n    /// # Safety\n    ///\n    /// `data` must contain a valid control message.\n    unsafe fn new(data: &'a [u8]) -> AncillaryDataIter<'a, T> {\n        AncillaryDataIter { data, phantom: PhantomData }\n    }\n}\n\nimpl<'a, T> Iterator for AncillaryDataIter<'a, T> {\n    type Item = T;\n\n    fn next(&mut self) -> Option<T> {\n        if size_of::<T>() <= self.data.len() {\n            unsafe {\n                let unit = read_unaligned(self.data.as_ptr().cast());\n                self.data = &self.data[size_of::<T>()..];\n                Some(unit)\n            }\n        } else {\n            None\n        }\n    }\n}\n\n/// Unix credential.\n#[cfg(any(doc, target_os = \"android\", target_os = \"linux\",))]\n#[unstable(feature = \"unix_socket_ancillary_data\", issue = \"76915\")]\n#[derive(Clone)]\npub struct SocketCred(libc::ucred);\n\n#[cfg(any(doc, target_os = \"android\", target_os = \"linux\",))]\nimpl SocketCred {\n    /// Create a Unix credential struct.\n    ///\n    /// PID, UID and GID is set to 0.\n    #[unstable(feature = \"unix_socket_ancillary_data\", issue = \"76915\")]\n    pub fn new() -> SocketCred {\n        SocketCred(libc::ucred { pid: 0, uid: 0, gid: 0 })\n    }\n\n    /// Set the PID.\n    #[unstable(feature = \"unix_socket_ancillary_data\", issue = \"76915\")]\n    pub fn set_pid(&mut self, pid: libc::pid_t) {\n        self.0.pid = pid;\n    }\n\n    /// Get the current PID.\n    #[unstable(feature = \"unix_socket_ancillary_data\", issue = \"76915\")]\n    pub fn get_pid(&self) -> libc::pid_t {\n        self.0.pid\n    }\n\n    /// Set the UID.\n    #[unstable(feature = \"unix_socket_ancillary_data\", issue = \"76915\")]\n    pub fn set_uid(&mut self, uid: libc::uid_t) {\n        self.0.uid = uid;\n    }\n\n    /// Get the current UID.\n    #[unstable(feature = \"unix_socket_ancillary_data\", issue = \"76915\")]\n    pub fn get_uid(&self) -> libc::uid_t {\n        self.0.uid\n    }\n\n    /// Set the GID.\n    #[unstable(feature = \"unix_socket_ancillary_data\", issue = \"76915\")]\n    pub fn set_gid(&mut self, gid: libc::gid_t) {\n        self.0.gid = gid;\n    }\n\n    /// Get the current GID.\n    #[unstable(feature = \"unix_socket_ancillary_data\", issue = \"76915\")]\n    pub fn get_gid(&self) -> libc::gid_t {\n        self.0.gid\n    }\n}\n\n/// This control message contains file descriptors.\n///\n/// The level is equal to `SOL_SOCKET` and the type is equal to `SCM_RIGHTS`.\n#[unstable(feature = \"unix_socket_ancillary_data\", issue = \"76915\")]\npub struct ScmRights<'a>(AncillaryDataIter<'a, RawFd>);\n\n#[unstable(feature = \"unix_socket_ancillary_data\", issue = \"76915\")]\nimpl<'a> Iterator for ScmRights<'a> {\n    type Item = RawFd;\n\n    fn next(&mut self) -> Option<RawFd> {\n        self.0.next()\n    }\n}\n\n/// This control message contains unix credentials.\n///\n/// The level is equal to `SOL_SOCKET` and the type is equal to `SCM_CREDENTIALS` or `SCM_CREDS`.\n#[cfg(any(doc, target_os = \"android\", target_os = \"linux\",))]\n#[unstable(feature = \"unix_socket_ancillary_data\", issue = \"76915\")]\npub struct ScmCredentials<'a>(AncillaryDataIter<'a, libc::ucred>);\n\n#[cfg(any(doc, target_os = \"android\", target_os = \"linux\",))]\n#[unstable(feature = \"unix_socket_ancillary_data\", issue = \"76915\")]\nimpl<'a> Iterator for ScmCredentials<'a> {\n    type Item = SocketCred;\n\n    fn next(&mut self) -> Option<SocketCred> {\n        Some(SocketCred(self.0.next()?))\n    }\n}\n\n/// The error type which is returned from parsing the type a control message.\n#[non_exhaustive]\n#[derive(Debug)]\n#[unstable(feature = \"unix_socket_ancillary_data\", issue = \"76915\")]\npub enum AncillaryError {\n    Unknown { cmsg_level: i32, cmsg_type: i32 },\n}\n\n/// This enum represent one control message of variable type.\n#[unstable(feature = \"unix_socket_ancillary_data\", issue = \"76915\")]\npub enum AncillaryData<'a> {\n    ScmRights(ScmRights<'a>),\n    #[cfg(any(doc, target_os = \"android\", target_os = \"linux\",))]\n    ScmCredentials(ScmCredentials<'a>),\n}\n\nimpl<'a> AncillaryData<'a> {\n    /// Create a `AncillaryData::ScmRights` variant.\n    ///\n    /// # Safety\n    ///\n    /// `data` must contain a valid control message and the control message must be type of\n    /// `SOL_SOCKET` and level of `SCM_RIGHTS`.\n    unsafe fn as_rights(data: &'a [u8]) -> Self {\n        let ancillary_data_iter = AncillaryDataIter::new(data);\n        let scm_rights = ScmRights(ancillary_data_iter);\n        AncillaryData::ScmRights(scm_rights)\n    }\n\n    /// Create a `AncillaryData::ScmCredentials` variant.\n    ///\n    /// # Safety\n    ///\n    /// `data` must contain a valid control message and the control message must be type of\n    /// `SOL_SOCKET` and level of `SCM_CREDENTIALS` or `SCM_CREDENTIALS`.\n    #[cfg(any(doc, target_os = \"android\", target_os = \"linux\",))]\n    unsafe fn as_credentials(data: &'a [u8]) -> Self {\n        let ancillary_data_iter = AncillaryDataIter::new(data);\n        let scm_credentials = ScmCredentials(ancillary_data_iter);\n        AncillaryData::ScmCredentials(scm_credentials)\n    }\n\n    fn try_from_cmsghdr(cmsg: &'a libc::cmsghdr) -> Result<Self, AncillaryError> {\n        unsafe {\n            let cmsg_len_zero = libc::CMSG_LEN(0) as usize;\n            let data_len = (*cmsg).cmsg_len as usize - cmsg_len_zero;\n            let data = libc::CMSG_DATA(cmsg).cast();\n            let data = from_raw_parts(data, data_len);\n\n            match (*cmsg).cmsg_level {\n                libc::SOL_SOCKET => match (*cmsg).cmsg_type {\n                    libc::SCM_RIGHTS => Ok(AncillaryData::as_rights(data)),\n                    #[cfg(any(target_os = \"android\", target_os = \"linux\",))]\n                    libc::SCM_CREDENTIALS => Ok(AncillaryData::as_credentials(data)),\n                    cmsg_type => {\n                        Err(AncillaryError::Unknown { cmsg_level: libc::SOL_SOCKET, cmsg_type })\n                    }\n                },\n                cmsg_level => {\n                    Err(AncillaryError::Unknown { cmsg_level, cmsg_type: (*cmsg).cmsg_type })\n                }\n            }\n        }\n    }\n}\n\n/// This struct is used to iterate through the control messages.\n#[unstable(feature = \"unix_socket_ancillary_data\", issue = \"76915\")]\npub struct Messages<'a> {\n    buffer: &'a [u8],\n    current: Option<&'a libc::cmsghdr>,\n}\n\n#[unstable(feature = \"unix_socket_ancillary_data\", issue = \"76915\")]\nimpl<'a> Iterator for Messages<'a> {\n    type Item = Result<AncillaryData<'a>, AncillaryError>;\n\n    fn next(&mut self) -> Option<Self::Item> {\n        unsafe {\n            let mut msg: libc::msghdr = zeroed();\n            msg.msg_control = self.buffer.as_ptr() as *mut _;\n            msg.msg_controllen = self.buffer.len() as _;\n\n            let cmsg = if let Some(current) = self.current {\n                libc::CMSG_NXTHDR(&msg, current)\n            } else {\n                libc::CMSG_FIRSTHDR(&msg)\n            };\n\n            let cmsg = cmsg.as_ref()?;\n\n            // Most operating systems, but not Linux or emscripten, return the previous pointer\n            // when its length is zero. Therefore, check if the previous pointer is the same as\n            // the current one.\n            if let Some(current) = self.current {\n                if eq(current, cmsg) {\n                    return None;\n                }\n            }\n\n            self.current = Some(cmsg);\n            let ancillary_result = AncillaryData::try_from_cmsghdr(cmsg);\n            Some(ancillary_result)\n        }\n    }\n}\n\n/// A Unix socket Ancillary data struct.\n///\n/// # Example\n/// ```no_run\n/// #![feature(unix_socket_ancillary_data)]\n/// use std::os::unix::net::{UnixStream, SocketAncillary, AncillaryData};\n/// use std::io::IoSliceMut;\n///\n/// fn main() -> std::io::Result<()> {\n///     let sock = UnixStream::connect(\"/tmp/sock\")?;\n///\n///     let mut fds = [0; 8];\n///     let mut ancillary_buffer = [0; 128];\n///     let mut ancillary = SocketAncillary::new(&mut ancillary_buffer[..]);\n///\n///     let mut buf = [1; 8];\n///     let mut bufs = &mut [IoSliceMut::new(&mut buf[..])][..];\n///     sock.recv_vectored_with_ancillary(bufs, &mut ancillary)?;\n///\n///     for ancillary_result in ancillary.messages() {\n///         if let AncillaryData::ScmRights(scm_rights) = ancillary_result.unwrap() {\n///             for fd in scm_rights {\n///                 println!(\"receive file descriptor: {}\", fd);\n///             }\n///         }\n///     }\n///     Ok(())\n/// }\n/// ```\n#[unstable(feature = \"unix_socket_ancillary_data\", issue = \"76915\")]\n#[derive(Debug)]\npub struct SocketAncillary<'a> {\n    buffer: &'a mut [u8],\n    length: usize,\n    truncated: bool,\n}\n\nimpl<'a> SocketAncillary<'a> {\n    /// Create an ancillary data with the given buffer.\n    ///\n    /// # Example\n    ///\n    /// ```no_run\n    /// # #![allow(unused_mut)]\n    /// #![feature(unix_socket_ancillary_data)]\n    /// use std::os::unix::net::SocketAncillary;\n    /// let mut ancillary_buffer = [0; 128];\n    /// let mut ancillary = SocketAncillary::new(&mut ancillary_buffer[..]);\n    /// ```\n    #[unstable(feature = \"unix_socket_ancillary_data\", issue = \"76915\")]\n    pub fn new(buffer: &'a mut [u8]) -> Self {\n        SocketAncillary { buffer, length: 0, truncated: false }\n    }\n\n    /// Returns the capacity of the buffer.\n    #[unstable(feature = \"unix_socket_ancillary_data\", issue = \"76915\")]\n    pub fn capacity(&self) -> usize {\n        self.buffer.len()\n    }\n\n    /// Returns `true` if the ancillary data is empty.\n    #[unstable(feature = \"unix_socket_ancillary_data\", issue = \"76915\")]\n    pub fn is_empty(&self) -> bool {\n        self.length == 0\n    }\n\n    /// Returns the number of used bytes.\n    #[unstable(feature = \"unix_socket_ancillary_data\", issue = \"76915\")]\n    pub fn len(&self) -> usize {\n        self.length\n    }\n\n    /// Returns the iterator of the control messages.\n    #[unstable(feature = \"unix_socket_ancillary_data\", issue = \"76915\")]\n    pub fn messages(&self) -> Messages<'_> {\n        Messages { buffer: &self.buffer[..self.length], current: None }\n    }\n\n    /// Is `true` if during a recv operation the ancillary was truncated.\n    ///\n    /// # Example\n    ///\n    /// ```no_run\n    /// #![feature(unix_socket_ancillary_data)]\n    /// use std::os::unix::net::{UnixStream, SocketAncillary};\n    /// use std::io::IoSliceMut;\n    ///\n    /// fn main() -> std::io::Result<()> {\n    ///     let sock = UnixStream::connect(\"/tmp/sock\")?;\n    ///\n    ///     let mut ancillary_buffer = [0; 128];\n    ///     let mut ancillary = SocketAncillary::new(&mut ancillary_buffer[..]);\n    ///\n    ///     let mut buf = [1; 8];\n    ///     let mut bufs = &mut [IoSliceMut::new(&mut buf[..])][..];\n    ///     sock.recv_vectored_with_ancillary(bufs, &mut ancillary)?;\n    ///\n    ///     println!(\"Is truncated: {}\", ancillary.truncated());\n    ///     Ok(())\n    /// }\n    /// ```\n    #[unstable(feature = \"unix_socket_ancillary_data\", issue = \"76915\")]\n    pub fn truncated(&self) -> bool {\n        self.truncated\n    }\n\n    /// Add file descriptors to the ancillary data.\n    ///\n    /// The function returns `true` if there was enough space in the buffer.\n    /// If there was not enough space then no file descriptors was appended.\n    /// Technically, that means this operation adds a control message with the level `SOL_SOCKET`\n    /// and type `SCM_RIGHTS`.\n    ///\n    /// # Example\n    ///\n    /// ```no_run\n    /// #![feature(unix_socket_ancillary_data)]\n    /// use std::os::unix::net::{UnixStream, SocketAncillary};\n    /// use std::os::unix::io::AsRawFd;\n    /// use std::io::IoSlice;\n    ///\n    /// fn main() -> std::io::Result<()> {\n    ///     let sock = UnixStream::connect(\"/tmp/sock\")?;\n    ///\n    ///     let mut ancillary_buffer = [0; 128];\n    ///     let mut ancillary = SocketAncillary::new(&mut ancillary_buffer[..]);\n    ///     ancillary.add_fds(&[sock.as_raw_fd()][..]);\n    ///\n    ///     let mut buf = [1; 8];\n    ///     let mut bufs = &mut [IoSlice::new(&mut buf[..])][..];\n    ///     sock.send_vectored_with_ancillary(bufs, &mut ancillary)?;\n    ///     Ok(())\n    /// }\n    /// ```\n    #[unstable(feature = \"unix_socket_ancillary_data\", issue = \"76915\")]\n    pub fn add_fds(&mut self, fds: &[RawFd]) -> bool {\n        self.truncated = false;\n        add_to_ancillary_data(\n            &mut self.buffer,\n            &mut self.length,\n            fds,\n            libc::SOL_SOCKET,\n            libc::SCM_RIGHTS,\n        )\n    }\n\n    /// Add credentials to the ancillary data.\n    ///\n    /// The function returns `true` if there was enough space in the buffer.\n    /// If there was not enough space then no credentials was appended.\n    /// Technically, that means this operation adds a control message with the level `SOL_SOCKET`\n    /// and type `SCM_CREDENTIALS` or `SCM_CREDS`.\n    ///\n    #[cfg(any(doc, target_os = \"android\", target_os = \"linux\",))]\n    #[unstable(feature = \"unix_socket_ancillary_data\", issue = \"76915\")]\n    pub fn add_creds(&mut self, creds: &[SocketCred]) -> bool {\n        self.truncated = false;\n        add_to_ancillary_data(\n            &mut self.buffer,\n            &mut self.length,\n            creds,\n            libc::SOL_SOCKET,\n            libc::SCM_CREDENTIALS,\n        )\n    }\n\n    /// Clears the ancillary data, removing all values.\n    ///\n    /// # Example\n    ///\n    /// ```no_run\n    /// #![feature(unix_socket_ancillary_data)]\n    /// use std::os::unix::net::{UnixStream, SocketAncillary, AncillaryData};\n    /// use std::io::IoSliceMut;\n    ///\n    /// fn main() -> std::io::Result<()> {\n    ///     let sock = UnixStream::connect(\"/tmp/sock\")?;\n    ///\n    ///     let mut fds1 = [0; 8];\n    ///     let mut fds2 = [0; 8];\n    ///     let mut ancillary_buffer = [0; 128];\n    ///     let mut ancillary = SocketAncillary::new(&mut ancillary_buffer[..]);\n    ///\n    ///     let mut buf = [1; 8];\n    ///     let mut bufs = &mut [IoSliceMut::new(&mut buf[..])][..];\n    ///\n    ///     sock.recv_vectored_with_ancillary(bufs, &mut ancillary)?;\n    ///     for ancillary_result in ancillary.messages() {\n    ///         if let AncillaryData::ScmRights(scm_rights) = ancillary_result.unwrap() {\n    ///             for fd in scm_rights {\n    ///                 println!(\"receive file descriptor: {}\", fd);\n    ///             }\n    ///         }\n    ///     }\n    ///\n    ///     ancillary.clear();\n    ///\n    ///     sock.recv_vectored_with_ancillary(bufs, &mut ancillary)?;\n    ///     for ancillary_result in ancillary.messages() {\n    ///         if let AncillaryData::ScmRights(scm_rights) = ancillary_result.unwrap() {\n    ///             for fd in scm_rights {\n    ///                 println!(\"receive file descriptor: {}\", fd);\n    ///             }\n    ///         }\n    ///     }\n    ///     Ok(())\n    /// }\n    /// ```\n    #[unstable(feature = \"unix_socket_ancillary_data\", issue = \"76915\")]\n    pub fn clear(&mut self) {\n        self.length = 0;\n        self.truncated = false;\n    }\n}\n"],[2150,"#[cfg(any(\n    doc,\n    target_os = \"android\",\n    target_os = \"dragonfly\",\n    target_os = \"emscripten\",\n    target_os = \"freebsd\",\n    target_os = \"linux\",\n    target_os = \"netbsd\",\n    target_os = \"openbsd\",\n))]\nuse super::{recv_vectored_with_ancillary_from, send_vectored_with_ancillary_to, SocketAncillary};\nuse super::{sockaddr_un, SocketAddr};\n#[cfg(any(\n    target_os = \"android\",\n    target_os = \"dragonfly\",\n    target_os = \"emscripten\",\n    target_os = \"freebsd\",\n    target_os = \"linux\",\n    target_os = \"netbsd\",\n    target_os = \"openbsd\",\n))]\nuse crate::io::{IoSlice, IoSliceMut};\nuse crate::net::Shutdown;\nuse crate::os::unix::io::{AsRawFd, FromRawFd, IntoRawFd, RawFd};\nuse crate::path::Path;\nuse crate::sys::cvt;\nuse crate::sys::net::Socket;\nuse crate::sys_common::{AsInner, FromInner, IntoInner};\nuse crate::time::Duration;\nuse crate::{fmt, io};\n\n#[cfg(any(\n    target_os = \"linux\",\n    target_os = \"android\",\n    target_os = \"dragonfly\",\n    target_os = \"freebsd\",\n    target_os = \"openbsd\",\n    target_os = \"netbsd\",\n    target_os = \"haiku\"\n))]\nuse libc::MSG_NOSIGNAL;\n#[cfg(not(any(\n    target_os = \"linux\",\n    target_os = \"android\",\n    target_os = \"dragonfly\",\n    target_os = \"freebsd\",\n    target_os = \"openbsd\",\n    target_os = \"netbsd\",\n    target_os = \"haiku\"\n)))]\nconst MSG_NOSIGNAL: libc::c_int = 0x0;\n\n/// A Unix datagram socket.\n///\n/// # Examples\n///\n/// ```no_run\n/// use std::os::unix::net::UnixDatagram;\n///\n/// fn main() -> std::io::Result<()> {\n///     let socket = UnixDatagram::bind(\"/path/to/my/socket\")?;\n///     socket.send_to(b\"hello world\", \"/path/to/other/socket\")?;\n///     let mut buf = [0; 100];\n///     let (count, address) = socket.recv_from(&mut buf)?;\n///     println!(\"socket {:?} sent {:?}\", address, &buf[..count]);\n///     Ok(())\n/// }\n/// ```\n#[stable(feature = \"unix_socket\", since = \"1.10.0\")]\npub struct UnixDatagram(Socket);\n\n#[stable(feature = \"unix_socket\", since = \"1.10.0\")]\nimpl fmt::Debug for UnixDatagram {\n    fn fmt(&self, fmt: &mut fmt::Formatter<'_>) -> fmt::Result {\n        let mut builder = fmt.debug_struct(\"UnixDatagram\");\n        builder.field(\"fd\", self.0.as_inner());\n        if let Ok(addr) = self.local_addr() {\n            builder.field(\"local\", &addr);\n        }\n        if let Ok(addr) = self.peer_addr() {\n            builder.field(\"peer\", &addr);\n        }\n        builder.finish()\n    }\n}\n\nimpl UnixDatagram {\n    /// Creates a Unix datagram socket bound to the given path.\n    ///\n    /// # Examples\n    ///\n    /// ```no_run\n    /// use std::os::unix::net::UnixDatagram;\n    ///\n    /// let sock = match UnixDatagram::bind(\"/path/to/the/socket\") {\n    ///     Ok(sock) => sock,\n    ///     Err(e) => {\n    ///         println!(\"Couldn't bind: {:?}\", e);\n    ///         return\n    ///     }\n    /// };\n    /// ```\n    #[stable(feature = \"unix_socket\", since = \"1.10.0\")]\n    pub fn bind<P: AsRef<Path>>(path: P) -> io::Result<UnixDatagram> {\n        unsafe {\n            let socket = UnixDatagram::unbound()?;\n            let (addr, len) = sockaddr_un(path.as_ref())?;\n\n            cvt(libc::bind(*socket.0.as_inner(), &addr as *const _ as *const _, len as _))?;\n\n            Ok(socket)\n        }\n    }\n\n    /// Creates a Unix Datagram socket which is not bound to any address.\n    ///\n    /// # Examples\n    ///\n    /// ```no_run\n    /// use std::os::unix::net::UnixDatagram;\n    ///\n    /// let sock = match UnixDatagram::unbound() {\n    ///     Ok(sock) => sock,\n    ///     Err(e) => {\n    ///         println!(\"Couldn't unbound: {:?}\", e);\n    ///         return\n    ///     }\n    /// };\n    /// ```\n    #[stable(feature = \"unix_socket\", since = \"1.10.0\")]\n    pub fn unbound() -> io::Result<UnixDatagram> {\n        let inner = Socket::new_raw(libc::AF_UNIX, libc::SOCK_DGRAM)?;\n        Ok(UnixDatagram(inner))\n    }\n\n    /// Creates an unnamed pair of connected sockets.\n    ///\n    /// Returns two `UnixDatagrams`s which are connected to each other.\n    ///\n    /// # Examples\n    ///\n    /// ```no_run\n    /// use std::os::unix::net::UnixDatagram;\n    ///\n    /// let (sock1, sock2) = match UnixDatagram::pair() {\n    ///     Ok((sock1, sock2)) => (sock1, sock2),\n    ///     Err(e) => {\n    ///         println!(\"Couldn't unbound: {:?}\", e);\n    ///         return\n    ///     }\n    /// };\n    /// ```\n    #[stable(feature = \"unix_socket\", since = \"1.10.0\")]\n    pub fn pair() -> io::Result<(UnixDatagram, UnixDatagram)> {\n        let (i1, i2) = Socket::new_pair(libc::AF_UNIX, libc::SOCK_DGRAM)?;\n        Ok((UnixDatagram(i1), UnixDatagram(i2)))\n    }\n\n    /// Connects the socket to the specified address.\n    ///\n    /// The [`send`] method may be used to send data to the specified address.\n    /// [`recv`] and [`recv_from`] will only receive data from that address.\n    ///\n    /// [`send`]: UnixDatagram::send\n    /// [`recv`]: UnixDatagram::recv\n    /// [`recv_from`]: UnixDatagram::recv_from\n    ///\n    /// # Examples\n    ///\n    /// ```no_run\n    /// use std::os::unix::net::UnixDatagram;\n    ///\n    /// fn main() -> std::io::Result<()> {\n    ///     let sock = UnixDatagram::unbound()?;\n    ///     match sock.connect(\"/path/to/the/socket\") {\n    ///         Ok(sock) => sock,\n    ///         Err(e) => {\n    ///             println!(\"Couldn't connect: {:?}\", e);\n    ///             return Err(e)\n    ///         }\n    ///     };\n    ///     Ok(())\n    /// }\n    /// ```\n    #[stable(feature = \"unix_socket\", since = \"1.10.0\")]\n    pub fn connect<P: AsRef<Path>>(&self, path: P) -> io::Result<()> {\n        unsafe {\n            let (addr, len) = sockaddr_un(path.as_ref())?;\n\n            cvt(libc::connect(*self.0.as_inner(), &addr as *const _ as *const _, len))?;\n        }\n        Ok(())\n    }\n\n    /// Creates a new independently owned handle to the underlying socket.\n    ///\n    /// The returned `UnixDatagram` is a reference to the same socket that this\n    /// object references. Both handles can be used to accept incoming\n    /// connections and options set on one side will affect the other.\n    ///\n    /// # Examples\n    ///\n    /// ```no_run\n    /// use std::os::unix::net::UnixDatagram;\n    ///\n    /// fn main() -> std::io::Result<()> {\n    ///     let sock = UnixDatagram::bind(\"/path/to/the/socket\")?;\n    ///     let sock_copy = sock.try_clone().expect(\"try_clone failed\");\n    ///     Ok(())\n    /// }\n    /// ```\n    #[stable(feature = \"unix_socket\", since = \"1.10.0\")]\n    pub fn try_clone(&self) -> io::Result<UnixDatagram> {\n        self.0.duplicate().map(UnixDatagram)\n    }\n\n    /// Returns the address of this socket.\n    ///\n    /// # Examples\n    ///\n    /// ```no_run\n    /// use std::os::unix::net::UnixDatagram;\n    ///\n    /// fn main() -> std::io::Result<()> {\n    ///     let sock = UnixDatagram::bind(\"/path/to/the/socket\")?;\n    ///     let addr = sock.local_addr().expect(\"Couldn't get local address\");\n    ///     Ok(())\n    /// }\n    /// ```\n    #[stable(feature = \"unix_socket\", since = \"1.10.0\")]\n    pub fn local_addr(&self) -> io::Result<SocketAddr> {\n        SocketAddr::new(|addr, len| unsafe { libc::getsockname(*self.0.as_inner(), addr, len) })\n    }\n\n    /// Returns the address of this socket's peer.\n    ///\n    /// The [`connect`] method will connect the socket to a peer.\n    ///\n    /// [`connect`]: UnixDatagram::connect\n    ///\n    /// # Examples\n    ///\n    /// ```no_run\n    /// use std::os::unix::net::UnixDatagram;\n    ///\n    /// fn main() -> std::io::Result<()> {\n    ///     let sock = UnixDatagram::unbound()?;\n    ///     sock.connect(\"/path/to/the/socket\")?;\n    ///\n    ///     let addr = sock.peer_addr().expect(\"Couldn't get peer address\");\n    ///     Ok(())\n    /// }\n    /// ```\n    #[stable(feature = \"unix_socket\", since = \"1.10.0\")]\n    pub fn peer_addr(&self) -> io::Result<SocketAddr> {\n        SocketAddr::new(|addr, len| unsafe { libc::getpeername(*self.0.as_inner(), addr, len) })\n    }\n\n    fn recv_from_flags(\n        &self,\n        buf: &mut [u8],\n        flags: libc::c_int,\n    ) -> io::Result<(usize, SocketAddr)> {\n        let mut count = 0;\n        let addr = SocketAddr::new(|addr, len| unsafe {\n            count = libc::recvfrom(\n                *self.0.as_inner(),\n                buf.as_mut_ptr() as *mut _,\n                buf.len(),\n                flags,\n                addr,\n                len,\n            );\n            if count > 0 {\n                1\n            } else if count == 0 {\n                0\n            } else {\n                -1\n            }\n        })?;\n\n        Ok((count as usize, addr))\n    }\n\n    /// Receives data from the socket.\n    ///\n    /// On success, returns the number of bytes read and the address from\n    /// whence the data came.\n    ///\n    /// # Examples\n    ///\n    /// ```no_run\n    /// use std::os::unix::net::UnixDatagram;\n    ///\n    /// fn main() -> std::io::Result<()> {\n    ///     let sock = UnixDatagram::unbound()?;\n    ///     let mut buf = vec![0; 10];\n    ///     let (size, sender) = sock.recv_from(buf.as_mut_slice())?;\n    ///     println!(\"received {} bytes from {:?}\", size, sender);\n    ///     Ok(())\n    /// }\n    /// ```\n    #[stable(feature = \"unix_socket\", since = \"1.10.0\")]\n    pub fn recv_from(&self, buf: &mut [u8]) -> io::Result<(usize, SocketAddr)> {\n        self.recv_from_flags(buf, 0)\n    }\n\n    /// Receives data from the socket.\n    ///\n    /// On success, returns the number of bytes read.\n    ///\n    /// # Examples\n    ///\n    /// ```no_run\n    /// use std::os::unix::net::UnixDatagram;\n    ///\n    /// fn main() -> std::io::Result<()> {\n    ///     let sock = UnixDatagram::bind(\"/path/to/the/socket\")?;\n    ///     let mut buf = vec![0; 10];\n    ///     sock.recv(buf.as_mut_slice()).expect(\"recv function failed\");\n    ///     Ok(())\n    /// }\n    /// ```\n    #[stable(feature = \"unix_socket\", since = \"1.10.0\")]\n    pub fn recv(&self, buf: &mut [u8]) -> io::Result<usize> {\n        self.0.read(buf)\n    }\n\n    /// Receives data and ancillary data from socket.\n    ///\n    /// On success, returns the number of bytes read, if the data was truncated and the address from whence the msg came.\n    ///\n    /// # Examples\n    ///\n    /// ```no_run\n    /// #![feature(unix_socket_ancillary_data)]\n    /// use std::os::unix::net::{UnixDatagram, SocketAncillary, AncillaryData};\n    /// use std::io::IoSliceMut;\n    ///\n    /// fn main() -> std::io::Result<()> {\n    ///     let sock = UnixDatagram::unbound()?;\n    ///     let mut buf1 = [1; 8];\n    ///     let mut buf2 = [2; 16];\n    ///     let mut buf3 = [3; 8];\n    ///     let mut bufs = &mut [\n    ///         IoSliceMut::new(&mut buf1),\n    ///         IoSliceMut::new(&mut buf2),\n    ///         IoSliceMut::new(&mut buf3),\n    ///     ][..];\n    ///     let mut fds = [0; 8];\n    ///     let mut ancillary_buffer = [0; 128];\n    ///     let mut ancillary = SocketAncillary::new(&mut ancillary_buffer[..]);\n    ///     let (size, _truncated, sender) = sock.recv_vectored_with_ancillary_from(bufs, &mut ancillary)?;\n    ///     println!(\"received {}\", size);\n    ///     for ancillary_result in ancillary.messages() {\n    ///         if let AncillaryData::ScmRights(scm_rights) = ancillary_result.unwrap() {\n    ///             for fd in scm_rights {\n    ///                 println!(\"receive file descriptor: {}\", fd);\n    ///             }\n    ///         }\n    ///     }\n    ///     Ok(())\n    /// }\n    /// ```\n    #[cfg(any(\n        target_os = \"android\",\n        target_os = \"dragonfly\",\n        target_os = \"emscripten\",\n        target_os = \"freebsd\",\n        target_os = \"linux\",\n        target_os = \"netbsd\",\n        target_os = \"openbsd\",\n    ))]\n    #[unstable(feature = \"unix_socket_ancillary_data\", issue = \"76915\")]\n    pub fn recv_vectored_with_ancillary_from(\n        &self,\n        bufs: &mut [IoSliceMut<'_>],\n        ancillary: &mut SocketAncillary<'_>,\n    ) -> io::Result<(usize, bool, SocketAddr)> {\n        let (count, truncated, addr) = recv_vectored_with_ancillary_from(&self.0, bufs, ancillary)?;\n        let addr = addr?;\n\n        Ok((count, truncated, addr))\n    }\n\n    /// Receives data and ancillary data from socket.\n    ///\n    /// On success, returns the number of bytes read and if the data was truncated.\n    ///\n    /// # Examples\n    ///\n    /// ```no_run\n    /// #![feature(unix_socket_ancillary_data)]\n    /// use std::os::unix::net::{UnixDatagram, SocketAncillary, AncillaryData};\n    /// use std::io::IoSliceMut;\n    ///\n    /// fn main() -> std::io::Result<()> {\n    ///     let sock = UnixDatagram::unbound()?;\n    ///     let mut buf1 = [1; 8];\n    ///     let mut buf2 = [2; 16];\n    ///     let mut buf3 = [3; 8];\n    ///     let mut bufs = &mut [\n    ///         IoSliceMut::new(&mut buf1),\n    ///         IoSliceMut::new(&mut buf2),\n    ///         IoSliceMut::new(&mut buf3),\n    ///     ][..];\n    ///     let mut fds = [0; 8];\n    ///     let mut ancillary_buffer = [0; 128];\n    ///     let mut ancillary = SocketAncillary::new(&mut ancillary_buffer[..]);\n    ///     let (size, _truncated) = sock.recv_vectored_with_ancillary(bufs, &mut ancillary)?;\n    ///     println!(\"received {}\", size);\n    ///     for ancillary_result in ancillary.messages() {\n    ///         if let AncillaryData::ScmRights(scm_rights) = ancillary_result.unwrap() {\n    ///             for fd in scm_rights {\n    ///                 println!(\"receive file descriptor: {}\", fd);\n    ///             }\n    ///         }\n    ///     }\n    ///     Ok(())\n    /// }\n    /// ```\n    #[cfg(any(\n        target_os = \"android\",\n        target_os = \"dragonfly\",\n        target_os = \"emscripten\",\n        target_os = \"freebsd\",\n        target_os = \"linux\",\n        target_os = \"netbsd\",\n        target_os = \"openbsd\",\n    ))]\n    #[unstable(feature = \"unix_socket_ancillary_data\", issue = \"76915\")]\n    pub fn recv_vectored_with_ancillary(\n        &self,\n        bufs: &mut [IoSliceMut<'_>],\n        ancillary: &mut SocketAncillary<'_>,\n    ) -> io::Result<(usize, bool)> {\n        let (count, truncated, addr) = recv_vectored_with_ancillary_from(&self.0, bufs, ancillary)?;\n        addr?;\n\n        Ok((count, truncated))\n    }\n\n    /// Sends data on the socket to the specified address.\n    ///\n    /// On success, returns the number of bytes written.\n    ///\n    /// # Examples\n    ///\n    /// ```no_run\n    /// use std::os::unix::net::UnixDatagram;\n    ///\n    /// fn main() -> std::io::Result<()> {\n    ///     let sock = UnixDatagram::unbound()?;\n    ///     sock.send_to(b\"omelette au fromage\", \"/some/sock\").expect(\"send_to function failed\");\n    ///     Ok(())\n    /// }\n    /// ```\n    #[stable(feature = \"unix_socket\", since = \"1.10.0\")]\n    pub fn send_to<P: AsRef<Path>>(&self, buf: &[u8], path: P) -> io::Result<usize> {\n        unsafe {\n            let (addr, len) = sockaddr_un(path.as_ref())?;\n\n            let count = cvt(libc::sendto(\n                *self.0.as_inner(),\n                buf.as_ptr() as *const _,\n                buf.len(),\n                MSG_NOSIGNAL,\n                &addr as *const _ as *const _,\n                len,\n            ))?;\n            Ok(count as usize)\n        }\n    }\n\n    /// Sends data on the socket to the socket's peer.\n    ///\n    /// The peer address may be set by the `connect` method, and this method\n    /// will return an error if the socket has not already been connected.\n    ///\n    /// On success, returns the number of bytes written.\n    ///\n    /// # Examples\n    ///\n    /// ```no_run\n    /// use std::os::unix::net::UnixDatagram;\n    ///\n    /// fn main() -> std::io::Result<()> {\n    ///     let sock = UnixDatagram::unbound()?;\n    ///     sock.connect(\"/some/sock\").expect(\"Couldn't connect\");\n    ///     sock.send(b\"omelette au fromage\").expect(\"send_to function failed\");\n    ///     Ok(())\n    /// }\n    /// ```\n    #[stable(feature = \"unix_socket\", since = \"1.10.0\")]\n    pub fn send(&self, buf: &[u8]) -> io::Result<usize> {\n        self.0.write(buf)\n    }\n\n    /// Sends data and ancillary data on the socket to the specified address.\n    ///\n    /// On success, returns the number of bytes written.\n    ///\n    /// # Examples\n    ///\n    /// ```no_run\n    /// #![feature(unix_socket_ancillary_data)]\n    /// use std::os::unix::net::{UnixDatagram, SocketAncillary};\n    /// use std::io::IoSlice;\n    ///\n    /// fn main() -> std::io::Result<()> {\n    ///     let sock = UnixDatagram::unbound()?;\n    ///     let buf1 = [1; 8];\n    ///     let buf2 = [2; 16];\n    ///     let buf3 = [3; 8];\n    ///     let bufs = &[\n    ///         IoSlice::new(&buf1),\n    ///         IoSlice::new(&buf2),\n    ///         IoSlice::new(&buf3),\n    ///     ][..];\n    ///     let fds = [0, 1, 2];\n    ///     let mut ancillary_buffer = [0; 128];\n    ///     let mut ancillary = SocketAncillary::new(&mut ancillary_buffer[..]);\n    ///     ancillary.add_fds(&fds[..]);\n    ///     sock.send_vectored_with_ancillary_to(bufs, &mut ancillary, \"/some/sock\")\n    ///         .expect(\"send_vectored_with_ancillary_to function failed\");\n    ///     Ok(())\n    /// }\n    /// ```\n    #[cfg(any(\n        target_os = \"android\",\n        target_os = \"dragonfly\",\n        target_os = \"emscripten\",\n        target_os = \"freebsd\",\n        target_os = \"linux\",\n        target_os = \"netbsd\",\n        target_os = \"openbsd\",\n    ))]\n    #[unstable(feature = \"unix_socket_ancillary_data\", issue = \"76915\")]\n    pub fn send_vectored_with_ancillary_to<P: AsRef<Path>>(\n        &self,\n        bufs: &[IoSlice<'_>],\n        ancillary: &mut SocketAncillary<'_>,\n        path: P,\n    ) -> io::Result<usize> {\n        send_vectored_with_ancillary_to(&self.0, Some(path.as_ref()), bufs, ancillary)\n    }\n\n    /// Sends data and ancillary data on the socket.\n    ///\n    /// On success, returns the number of bytes written.\n    ///\n    /// # Examples\n    ///\n    /// ```no_run\n    /// #![feature(unix_socket_ancillary_data)]\n    /// use std::os::unix::net::{UnixDatagram, SocketAncillary};\n    /// use std::io::IoSlice;\n    ///\n    /// fn main() -> std::io::Result<()> {\n    ///     let sock = UnixDatagram::unbound()?;\n    ///     let buf1 = [1; 8];\n    ///     let buf2 = [2; 16];\n    ///     let buf3 = [3; 8];\n    ///     let bufs = &[\n    ///         IoSlice::new(&buf1),\n    ///         IoSlice::new(&buf2),\n    ///         IoSlice::new(&buf3),\n    ///     ][..];\n    ///     let fds = [0, 1, 2];\n    ///     let mut ancillary_buffer = [0; 128];\n    ///     let mut ancillary = SocketAncillary::new(&mut ancillary_buffer[..]);\n    ///     ancillary.add_fds(&fds[..]);\n    ///     sock.send_vectored_with_ancillary(bufs, &mut ancillary)\n    ///         .expect(\"send_vectored_with_ancillary function failed\");\n    ///     Ok(())\n    /// }\n    /// ```\n    #[cfg(any(\n        target_os = \"android\",\n        target_os = \"dragonfly\",\n        target_os = \"emscripten\",\n        target_os = \"freebsd\",\n        target_os = \"linux\",\n        target_os = \"netbsd\",\n        target_os = \"openbsd\",\n    ))]\n    #[unstable(feature = \"unix_socket_ancillary_data\", issue = \"76915\")]\n    pub fn send_vectored_with_ancillary(\n        &self,\n        bufs: &[IoSlice<'_>],\n        ancillary: &mut SocketAncillary<'_>,\n    ) -> io::Result<usize> {\n        send_vectored_with_ancillary_to(&self.0, None, bufs, ancillary)\n    }\n\n    /// Sets the read timeout for the socket.\n    ///\n    /// If the provided value is [`None`], then [`recv`] and [`recv_from`] calls will\n    /// block indefinitely. An [`Err`] is returned if the zero [`Duration`]\n    /// is passed to this method.\n    ///\n    /// [`recv`]: UnixDatagram::recv\n    /// [`recv_from`]: UnixDatagram::recv_from\n    ///\n    /// # Examples\n    ///\n    /// ```\n    /// use std::os::unix::net::UnixDatagram;\n    /// use std::time::Duration;\n    ///\n    /// fn main() -> std::io::Result<()> {\n    ///     let sock = UnixDatagram::unbound()?;\n    ///     sock.set_read_timeout(Some(Duration::new(1, 0)))\n    ///         .expect(\"set_read_timeout function failed\");\n    ///     Ok(())\n    /// }\n    /// ```\n    ///\n    /// An [`Err`] is returned if the zero [`Duration`] is passed to this\n    /// method:\n    ///\n    /// ```no_run\n    /// use std::io;\n    /// use std::os::unix::net::UnixDatagram;\n    /// use std::time::Duration;\n    ///\n    /// fn main() -> std::io::Result<()> {\n    ///     let socket = UnixDatagram::unbound()?;\n    ///     let result = socket.set_read_timeout(Some(Duration::new(0, 0)));\n    ///     let err = result.unwrap_err();\n    ///     assert_eq!(err.kind(), io::ErrorKind::InvalidInput);\n    ///     Ok(())\n    /// }\n    /// ```\n    #[stable(feature = \"unix_socket\", since = \"1.10.0\")]\n    pub fn set_read_timeout(&self, timeout: Option<Duration>) -> io::Result<()> {\n        self.0.set_timeout(timeout, libc::SO_RCVTIMEO)\n    }\n\n    /// Sets the write timeout for the socket.\n    ///\n    /// If the provided value is [`None`], then [`send`] and [`send_to`] calls will\n    /// block indefinitely. An [`Err`] is returned if the zero [`Duration`] is passed to this\n    /// method.\n    ///\n    /// [`send`]: UnixDatagram::send\n    /// [`send_to`]: UnixDatagram::send_to\n    ///\n    /// # Examples\n    ///\n    /// ```\n    /// use std::os::unix::net::UnixDatagram;\n    /// use std::time::Duration;\n    ///\n    /// fn main() -> std::io::Result<()> {\n    ///     let sock = UnixDatagram::unbound()?;\n    ///     sock.set_write_timeout(Some(Duration::new(1, 0)))\n    ///         .expect(\"set_write_timeout function failed\");\n    ///     Ok(())\n    /// }\n    /// ```\n    ///\n    /// An [`Err`] is returned if the zero [`Duration`] is passed to this\n    /// method:\n    ///\n    /// ```no_run\n    /// use std::io;\n    /// use std::os::unix::net::UnixDatagram;\n    /// use std::time::Duration;\n    ///\n    /// fn main() -> std::io::Result<()> {\n    ///     let socket = UnixDatagram::unbound()?;\n    ///     let result = socket.set_write_timeout(Some(Duration::new(0, 0)));\n    ///     let err = result.unwrap_err();\n    ///     assert_eq!(err.kind(), io::ErrorKind::InvalidInput);\n    ///     Ok(())\n    /// }\n    /// ```\n    #[stable(feature = \"unix_socket\", since = \"1.10.0\")]\n    pub fn set_write_timeout(&self, timeout: Option<Duration>) -> io::Result<()> {\n        self.0.set_timeout(timeout, libc::SO_SNDTIMEO)\n    }\n\n    /// Returns the read timeout of this socket.\n    ///\n    /// # Examples\n    ///\n    /// ```\n    /// use std::os::unix::net::UnixDatagram;\n    /// use std::time::Duration;\n    ///\n    /// fn main() -> std::io::Result<()> {\n    ///     let sock = UnixDatagram::unbound()?;\n    ///     sock.set_read_timeout(Some(Duration::new(1, 0)))\n    ///         .expect(\"set_read_timeout function failed\");\n    ///     assert_eq!(sock.read_timeout()?, Some(Duration::new(1, 0)));\n    ///     Ok(())\n    /// }\n    /// ```\n    #[stable(feature = \"unix_socket\", since = \"1.10.0\")]\n    pub fn read_timeout(&self) -> io::Result<Option<Duration>> {\n        self.0.timeout(libc::SO_RCVTIMEO)\n    }\n\n    /// Returns the write timeout of this socket.\n    ///\n    /// # Examples\n    ///\n    /// ```\n    /// use std::os::unix::net::UnixDatagram;\n    /// use std::time::Duration;\n    ///\n    /// fn main() -> std::io::Result<()> {\n    ///     let sock = UnixDatagram::unbound()?;\n    ///     sock.set_write_timeout(Some(Duration::new(1, 0)))\n    ///         .expect(\"set_write_timeout function failed\");\n    ///     assert_eq!(sock.write_timeout()?, Some(Duration::new(1, 0)));\n    ///     Ok(())\n    /// }\n    /// ```\n    #[stable(feature = \"unix_socket\", since = \"1.10.0\")]\n    pub fn write_timeout(&self) -> io::Result<Option<Duration>> {\n        self.0.timeout(libc::SO_SNDTIMEO)\n    }\n\n    /// Moves the socket into or out of nonblocking mode.\n    ///\n    /// # Examples\n    ///\n    /// ```\n    /// use std::os::unix::net::UnixDatagram;\n    ///\n    /// fn main() -> std::io::Result<()> {\n    ///     let sock = UnixDatagram::unbound()?;\n    ///     sock.set_nonblocking(true).expect(\"set_nonblocking function failed\");\n    ///     Ok(())\n    /// }\n    /// ```\n    #[stable(feature = \"unix_socket\", since = \"1.10.0\")]\n    pub fn set_nonblocking(&self, nonblocking: bool) -> io::Result<()> {\n        self.0.set_nonblocking(nonblocking)\n    }\n\n    /// Moves the socket to pass unix credentials as control message in [`SocketAncillary`].\n    ///\n    /// Set the socket option `SO_PASSCRED`.\n    ///\n    /// # Examples\n    ///\n    #[cfg_attr(any(target_os = \"android\", target_os = \"linux\"), doc = \"```no_run\")]\n    #[cfg_attr(not(any(target_os = \"android\", target_os = \"linux\")), doc = \"```ignore\")]\n    /// #![feature(unix_socket_ancillary_data)]\n    /// use std::os::unix::net::UnixDatagram;\n    ///\n    /// fn main() -> std::io::Result<()> {\n    ///     let sock = UnixDatagram::unbound()?;\n    ///     sock.set_passcred(true).expect(\"set_passcred function failed\");\n    ///     Ok(())\n    /// }\n    /// ```\n    #[cfg(any(doc, target_os = \"android\", target_os = \"linux\",))]\n    #[unstable(feature = \"unix_socket_ancillary_data\", issue = \"76915\")]\n    pub fn set_passcred(&self, passcred: bool) -> io::Result<()> {\n        self.0.set_passcred(passcred)\n    }\n\n    /// Get the current value of the socket for passing unix credentials in [`SocketAncillary`].\n    /// This value can be change by [`set_passcred`].\n    ///\n    /// Get the socket option `SO_PASSCRED`.\n    ///\n    /// [`set_passcred`]: UnixDatagram::set_passcred\n    #[cfg(any(doc, target_os = \"android\", target_os = \"linux\",))]\n    #[unstable(feature = \"unix_socket_ancillary_data\", issue = \"76915\")]\n    pub fn passcred(&self) -> io::Result<bool> {\n        self.0.passcred()\n    }\n\n    /// Returns the value of the `SO_ERROR` option.\n    ///\n    /// # Examples\n    ///\n    /// ```no_run\n    /// use std::os::unix::net::UnixDatagram;\n    ///\n    /// fn main() -> std::io::Result<()> {\n    ///     let sock = UnixDatagram::unbound()?;\n    ///     if let Ok(Some(err)) = sock.take_error() {\n    ///         println!(\"Got error: {:?}\", err);\n    ///     }\n    ///     Ok(())\n    /// }\n    /// ```\n    #[stable(feature = \"unix_socket\", since = \"1.10.0\")]\n    pub fn take_error(&self) -> io::Result<Option<io::Error>> {\n        self.0.take_error()\n    }\n\n    /// Shut down the read, write, or both halves of this connection.\n    ///\n    /// This function will cause all pending and future I/O calls on the\n    /// specified portions to immediately return with an appropriate value\n    /// (see the documentation of [`Shutdown`]).\n    ///\n    /// ```no_run\n    /// use std::os::unix::net::UnixDatagram;\n    /// use std::net::Shutdown;\n    ///\n    /// fn main() -> std::io::Result<()> {\n    ///     let sock = UnixDatagram::unbound()?;\n    ///     sock.shutdown(Shutdown::Both).expect(\"shutdown function failed\");\n    ///     Ok(())\n    /// }\n    /// ```\n    #[stable(feature = \"unix_socket\", since = \"1.10.0\")]\n    pub fn shutdown(&self, how: Shutdown) -> io::Result<()> {\n        self.0.shutdown(how)\n    }\n\n    /// Receives data on the socket from the remote address to which it is\n    /// connected, without removing that data from the queue. On success,\n    /// returns the number of bytes peeked.\n    ///\n    /// Successive calls return the same data. This is accomplished by passing\n    /// `MSG_PEEK` as a flag to the underlying `recv` system call.\n    ///\n    /// # Examples\n    ///\n    /// ```no_run\n    /// #![feature(unix_socket_peek)]\n    ///\n    /// use std::os::unix::net::UnixDatagram;\n    ///\n    /// fn main() -> std::io::Result<()> {\n    ///     let socket = UnixDatagram::bind(\"/tmp/sock\")?;\n    ///     let mut buf = [0; 10];\n    ///     let len = socket.peek(&mut buf).expect(\"peek failed\");\n    ///     Ok(())\n    /// }\n    /// ```\n    #[unstable(feature = \"unix_socket_peek\", issue = \"76923\")]\n    pub fn peek(&self, buf: &mut [u8]) -> io::Result<usize> {\n        self.0.peek(buf)\n    }\n\n    /// Receives a single datagram message on the socket, without removing it from the\n    /// queue. On success, returns the number of bytes read and the origin.\n    ///\n    /// The function must be called with valid byte array `buf` of sufficient size to\n    /// hold the message bytes. If a message is too long to fit in the supplied buffer,\n    /// excess bytes may be discarded.\n    ///\n    /// Successive calls return the same data. This is accomplished by passing\n    /// `MSG_PEEK` as a flag to the underlying `recvfrom` system call.\n    ///\n    /// Do not use this function to implement busy waiting, instead use `libc::poll` to\n    /// synchronize IO events on one or more sockets.\n    ///\n    /// # Examples\n    ///\n    /// ```no_run\n    /// #![feature(unix_socket_peek)]\n    ///\n    /// use std::os::unix::net::UnixDatagram;\n    ///\n    /// fn main() -> std::io::Result<()> {\n    ///     let socket = UnixDatagram::bind(\"/tmp/sock\")?;\n    ///     let mut buf = [0; 10];\n    ///     let (len, addr) = socket.peek_from(&mut buf).expect(\"peek failed\");\n    ///     Ok(())\n    /// }\n    /// ```\n    #[unstable(feature = \"unix_socket_peek\", issue = \"76923\")]\n    pub fn peek_from(&self, buf: &mut [u8]) -> io::Result<(usize, SocketAddr)> {\n        self.recv_from_flags(buf, libc::MSG_PEEK)\n    }\n}\n\n#[stable(feature = \"unix_socket\", since = \"1.10.0\")]\nimpl AsRawFd for UnixDatagram {\n    #[inline]\n    fn as_raw_fd(&self) -> RawFd {\n        *self.0.as_inner()\n    }\n}\n\n#[stable(feature = \"unix_socket\", since = \"1.10.0\")]\nimpl FromRawFd for UnixDatagram {\n    #[inline]\n    unsafe fn from_raw_fd(fd: RawFd) -> UnixDatagram {\n        UnixDatagram(Socket::from_inner(fd))\n    }\n}\n\n#[stable(feature = \"unix_socket\", since = \"1.10.0\")]\nimpl IntoRawFd for UnixDatagram {\n    #[inline]\n    fn into_raw_fd(self) -> RawFd {\n        self.0.into_inner()\n    }\n}\n"],[2151,"use super::*;\nuse crate::io::prelude::*;\nuse crate::io::{self, ErrorKind, IoSlice, IoSliceMut};\n#[cfg(any(\n    target_os = \"android\",\n    target_os = \"dragonfly\",\n    target_os = \"emscripten\",\n    target_os = \"freebsd\",\n    target_os = \"linux\",\n    target_os = \"netbsd\",\n    target_os = \"openbsd\",\n))]\nuse crate::iter::FromIterator;\n#[cfg(any(\n    target_os = \"android\",\n    target_os = \"dragonfly\",\n    target_os = \"emscripten\",\n    target_os = \"freebsd\",\n    target_os = \"linux\",\n    target_os = \"netbsd\",\n    target_os = \"openbsd\",\n))]\nuse crate::os::unix::io::AsRawFd;\nuse crate::sys_common::io::test::tmpdir;\nuse crate::thread;\nuse crate::time::Duration;\n\nmacro_rules! or_panic {\n    ($e:expr) => {\n        match $e {\n            Ok(e) => e,\n            Err(e) => panic!(\"{}\", e),\n        }\n    };\n}\n\n#[test]\nfn basic() {\n    let dir = tmpdir();\n    let socket_path = dir.path().join(\"sock\");\n    let msg1 = b\"hello\";\n    let msg2 = b\"world!\";\n\n    let listener = or_panic!(UnixListener::bind(&socket_path));\n    let thread = thread::spawn(move || {\n        let mut stream = or_panic!(listener.accept()).0;\n        let mut buf = [0; 5];\n        or_panic!(stream.read(&mut buf));\n        assert_eq!(&msg1[..], &buf[..]);\n        or_panic!(stream.write_all(msg2));\n    });\n\n    let mut stream = or_panic!(UnixStream::connect(&socket_path));\n    assert_eq!(Some(&*socket_path), stream.peer_addr().unwrap().as_pathname());\n    or_panic!(stream.write_all(msg1));\n    let mut buf = vec![];\n    or_panic!(stream.read_to_end(&mut buf));\n    assert_eq!(&msg2[..], &buf[..]);\n    drop(stream);\n\n    thread.join().unwrap();\n}\n\n#[test]\nfn vectored() {\n    let (mut s1, mut s2) = or_panic!(UnixStream::pair());\n\n    let len = or_panic!(s1.write_vectored(&[\n        IoSlice::new(b\"hello\"),\n        IoSlice::new(b\" \"),\n        IoSlice::new(b\"world!\")\n    ],));\n    assert_eq!(len, 12);\n\n    let mut buf1 = [0; 6];\n    let mut buf2 = [0; 7];\n    let len =\n        or_panic!(s2.read_vectored(&mut [IoSliceMut::new(&mut buf1), IoSliceMut::new(&mut buf2)],));\n    assert_eq!(len, 12);\n    assert_eq!(&buf1, b\"hello \");\n    assert_eq!(&buf2, b\"world!\\0\");\n}\n\n#[test]\nfn pair() {\n    let msg1 = b\"hello\";\n    let msg2 = b\"world!\";\n\n    let (mut s1, mut s2) = or_panic!(UnixStream::pair());\n    let thread = thread::spawn(move || {\n        // s1 must be moved in or the test will hang!\n        let mut buf = [0; 5];\n        or_panic!(s1.read(&mut buf));\n        assert_eq!(&msg1[..], &buf[..]);\n        or_panic!(s1.write_all(msg2));\n    });\n\n    or_panic!(s2.write_all(msg1));\n    let mut buf = vec![];\n    or_panic!(s2.read_to_end(&mut buf));\n    assert_eq!(&msg2[..], &buf[..]);\n    drop(s2);\n\n    thread.join().unwrap();\n}\n\n#[test]\nfn try_clone() {\n    let dir = tmpdir();\n    let socket_path = dir.path().join(\"sock\");\n    let msg1 = b\"hello\";\n    let msg2 = b\"world\";\n\n    let listener = or_panic!(UnixListener::bind(&socket_path));\n    let thread = thread::spawn(move || {\n        let mut stream = or_panic!(listener.accept()).0;\n        or_panic!(stream.write_all(msg1));\n        or_panic!(stream.write_all(msg2));\n    });\n\n    let mut stream = or_panic!(UnixStream::connect(&socket_path));\n    let mut stream2 = or_panic!(stream.try_clone());\n\n    let mut buf = [0; 5];\n    or_panic!(stream.read(&mut buf));\n    assert_eq!(&msg1[..], &buf[..]);\n    or_panic!(stream2.read(&mut buf));\n    assert_eq!(&msg2[..], &buf[..]);\n\n    thread.join().unwrap();\n}\n\n#[test]\nfn iter() {\n    let dir = tmpdir();\n    let socket_path = dir.path().join(\"sock\");\n\n    let listener = or_panic!(UnixListener::bind(&socket_path));\n    let thread = thread::spawn(move || {\n        for stream in listener.incoming().take(2) {\n            let mut stream = or_panic!(stream);\n            let mut buf = [0];\n            or_panic!(stream.read(&mut buf));\n        }\n    });\n\n    for _ in 0..2 {\n        let mut stream = or_panic!(UnixStream::connect(&socket_path));\n        or_panic!(stream.write_all(&[0]));\n    }\n\n    thread.join().unwrap();\n}\n\n#[test]\nfn long_path() {\n    let dir = tmpdir();\n    let socket_path = dir.path().join(\n        \"asdfasdfasdfasdfasdfasdfasdfasdfasdfasdfasdfasdfasdfasdfasdfa\\\n                                sasdfasdfasdasdfasdfasdfadfasdfasdfasdfasdfasdf\",\n    );\n    match UnixStream::connect(&socket_path) {\n        Err(ref e) if e.kind() == io::ErrorKind::InvalidInput => {}\n        Err(e) => panic!(\"unexpected error {}\", e),\n        Ok(_) => panic!(\"unexpected success\"),\n    }\n\n    match UnixListener::bind(&socket_path) {\n        Err(ref e) if e.kind() == io::ErrorKind::InvalidInput => {}\n        Err(e) => panic!(\"unexpected error {}\", e),\n        Ok(_) => panic!(\"unexpected success\"),\n    }\n\n    match UnixDatagram::bind(&socket_path) {\n        Err(ref e) if e.kind() == io::ErrorKind::InvalidInput => {}\n        Err(e) => panic!(\"unexpected error {}\", e),\n        Ok(_) => panic!(\"unexpected success\"),\n    }\n}\n\n#[test]\nfn timeouts() {\n    let dir = tmpdir();\n    let socket_path = dir.path().join(\"sock\");\n\n    let _listener = or_panic!(UnixListener::bind(&socket_path));\n\n    let stream = or_panic!(UnixStream::connect(&socket_path));\n    let dur = Duration::new(15410, 0);\n\n    assert_eq!(None, or_panic!(stream.read_timeout()));\n\n    or_panic!(stream.set_read_timeout(Some(dur)));\n    assert_eq!(Some(dur), or_panic!(stream.read_timeout()));\n\n    assert_eq!(None, or_panic!(stream.write_timeout()));\n\n    or_panic!(stream.set_write_timeout(Some(dur)));\n    assert_eq!(Some(dur), or_panic!(stream.write_timeout()));\n\n    or_panic!(stream.set_read_timeout(None));\n    assert_eq!(None, or_panic!(stream.read_timeout()));\n\n    or_panic!(stream.set_write_timeout(None));\n    assert_eq!(None, or_panic!(stream.write_timeout()));\n}\n\n#[test]\nfn test_read_timeout() {\n    let dir = tmpdir();\n    let socket_path = dir.path().join(\"sock\");\n\n    let _listener = or_panic!(UnixListener::bind(&socket_path));\n\n    let mut stream = or_panic!(UnixStream::connect(&socket_path));\n    or_panic!(stream.set_read_timeout(Some(Duration::from_millis(1000))));\n\n    let mut buf = [0; 10];\n    let kind = stream.read_exact(&mut buf).err().expect(\"expected error\").kind();\n    assert!(\n        kind == ErrorKind::WouldBlock || kind == ErrorKind::TimedOut,\n        \"unexpected_error: {:?}\",\n        kind\n    );\n}\n\n#[test]\nfn test_read_with_timeout() {\n    let dir = tmpdir();\n    let socket_path = dir.path().join(\"sock\");\n\n    let listener = or_panic!(UnixListener::bind(&socket_path));\n\n    let mut stream = or_panic!(UnixStream::connect(&socket_path));\n    or_panic!(stream.set_read_timeout(Some(Duration::from_millis(1000))));\n\n    let mut other_end = or_panic!(listener.accept()).0;\n    or_panic!(other_end.write_all(b\"hello world\"));\n\n    let mut buf = [0; 11];\n    or_panic!(stream.read(&mut buf));\n    assert_eq!(b\"hello world\", &buf[..]);\n\n    let kind = stream.read_exact(&mut buf).err().expect(\"expected error\").kind();\n    assert!(\n        kind == ErrorKind::WouldBlock || kind == ErrorKind::TimedOut,\n        \"unexpected_error: {:?}\",\n        kind\n    );\n}\n\n// Ensure the `set_read_timeout` and `set_write_timeout` calls return errors\n// when passed zero Durations\n#[test]\nfn test_unix_stream_timeout_zero_duration() {\n    let dir = tmpdir();\n    let socket_path = dir.path().join(\"sock\");\n\n    let listener = or_panic!(UnixListener::bind(&socket_path));\n    let stream = or_panic!(UnixStream::connect(&socket_path));\n\n    let result = stream.set_write_timeout(Some(Duration::new(0, 0)));\n    let err = result.unwrap_err();\n    assert_eq!(err.kind(), ErrorKind::InvalidInput);\n\n    let result = stream.set_read_timeout(Some(Duration::new(0, 0)));\n    let err = result.unwrap_err();\n    assert_eq!(err.kind(), ErrorKind::InvalidInput);\n\n    drop(listener);\n}\n\n#[test]\nfn test_unix_datagram() {\n    let dir = tmpdir();\n    let path1 = dir.path().join(\"sock1\");\n    let path2 = dir.path().join(\"sock2\");\n\n    let sock1 = or_panic!(UnixDatagram::bind(&path1));\n    let sock2 = or_panic!(UnixDatagram::bind(&path2));\n\n    let msg = b\"hello world\";\n    or_panic!(sock1.send_to(msg, &path2));\n    let mut buf = [0; 11];\n    or_panic!(sock2.recv_from(&mut buf));\n    assert_eq!(msg, &buf[..]);\n}\n\n#[test]\nfn test_unnamed_unix_datagram() {\n    let dir = tmpdir();\n    let path1 = dir.path().join(\"sock1\");\n\n    let sock1 = or_panic!(UnixDatagram::bind(&path1));\n    let sock2 = or_panic!(UnixDatagram::unbound());\n\n    let msg = b\"hello world\";\n    or_panic!(sock2.send_to(msg, &path1));\n    let mut buf = [0; 11];\n    let (usize, addr) = or_panic!(sock1.recv_from(&mut buf));\n    assert_eq!(usize, 11);\n    assert!(addr.is_unnamed());\n    assert_eq!(msg, &buf[..]);\n}\n\n#[test]\nfn test_connect_unix_datagram() {\n    let dir = tmpdir();\n    let path1 = dir.path().join(\"sock1\");\n    let path2 = dir.path().join(\"sock2\");\n\n    let bsock1 = or_panic!(UnixDatagram::bind(&path1));\n    let bsock2 = or_panic!(UnixDatagram::bind(&path2));\n    let sock = or_panic!(UnixDatagram::unbound());\n    or_panic!(sock.connect(&path1));\n\n    // Check send()\n    let msg = b\"hello there\";\n    or_panic!(sock.send(msg));\n    let mut buf = [0; 11];\n    let (usize, addr) = or_panic!(bsock1.recv_from(&mut buf));\n    assert_eq!(usize, 11);\n    assert!(addr.is_unnamed());\n    assert_eq!(msg, &buf[..]);\n\n    // Changing default socket works too\n    or_panic!(sock.connect(&path2));\n    or_panic!(sock.send(msg));\n    or_panic!(bsock2.recv_from(&mut buf));\n}\n\n#[test]\nfn test_unix_datagram_recv() {\n    let dir = tmpdir();\n    let path1 = dir.path().join(\"sock1\");\n\n    let sock1 = or_panic!(UnixDatagram::bind(&path1));\n    let sock2 = or_panic!(UnixDatagram::unbound());\n    or_panic!(sock2.connect(&path1));\n\n    let msg = b\"hello world\";\n    or_panic!(sock2.send(msg));\n    let mut buf = [0; 11];\n    let size = or_panic!(sock1.recv(&mut buf));\n    assert_eq!(size, 11);\n    assert_eq!(msg, &buf[..]);\n}\n\n#[test]\nfn datagram_pair() {\n    let msg1 = b\"hello\";\n    let msg2 = b\"world!\";\n\n    let (s1, s2) = or_panic!(UnixDatagram::pair());\n    let thread = thread::spawn(move || {\n        // s1 must be moved in or the test will hang!\n        let mut buf = [0; 5];\n        or_panic!(s1.recv(&mut buf));\n        assert_eq!(&msg1[..], &buf[..]);\n        or_panic!(s1.send(msg2));\n    });\n\n    or_panic!(s2.send(msg1));\n    let mut buf = [0; 6];\n    or_panic!(s2.recv(&mut buf));\n    assert_eq!(&msg2[..], &buf[..]);\n    drop(s2);\n\n    thread.join().unwrap();\n}\n\n// Ensure the `set_read_timeout` and `set_write_timeout` calls return errors\n// when passed zero Durations\n#[test]\nfn test_unix_datagram_timeout_zero_duration() {\n    let dir = tmpdir();\n    let path = dir.path().join(\"sock\");\n\n    let datagram = or_panic!(UnixDatagram::bind(&path));\n\n    let result = datagram.set_write_timeout(Some(Duration::new(0, 0)));\n    let err = result.unwrap_err();\n    assert_eq!(err.kind(), ErrorKind::InvalidInput);\n\n    let result = datagram.set_read_timeout(Some(Duration::new(0, 0)));\n    let err = result.unwrap_err();\n    assert_eq!(err.kind(), ErrorKind::InvalidInput);\n}\n\n#[test]\nfn abstract_namespace_not_allowed() {\n    assert!(UnixStream::connect(\"\\0asdf\").is_err());\n}\n\n#[test]\nfn test_unix_stream_peek() {\n    let (txdone, rxdone) = crate::sync::mpsc::channel();\n\n    let dir = tmpdir();\n    let path = dir.path().join(\"sock\");\n\n    let listener = or_panic!(UnixListener::bind(&path));\n    let thread = thread::spawn(move || {\n        let mut stream = or_panic!(listener.accept()).0;\n        or_panic!(stream.write_all(&[1, 3, 3, 7]));\n        or_panic!(rxdone.recv());\n    });\n\n    let mut stream = or_panic!(UnixStream::connect(&path));\n    let mut buf = [0; 10];\n    for _ in 0..2 {\n        assert_eq!(or_panic!(stream.peek(&mut buf)), 4);\n    }\n    assert_eq!(or_panic!(stream.read(&mut buf)), 4);\n\n    or_panic!(stream.set_nonblocking(true));\n    match stream.peek(&mut buf) {\n        Ok(_) => panic!(\"expected error\"),\n        Err(ref e) if e.kind() == ErrorKind::WouldBlock => {}\n        Err(e) => panic!(\"unexpected error: {}\", e),\n    }\n\n    or_panic!(txdone.send(()));\n    thread.join().unwrap();\n}\n\n#[test]\nfn test_unix_datagram_peek() {\n    let dir = tmpdir();\n    let path1 = dir.path().join(\"sock\");\n\n    let sock1 = or_panic!(UnixDatagram::bind(&path1));\n    let sock2 = or_panic!(UnixDatagram::unbound());\n    or_panic!(sock2.connect(&path1));\n\n    let msg = b\"hello world\";\n    or_panic!(sock2.send(msg));\n    for _ in 0..2 {\n        let mut buf = [0; 11];\n        let size = or_panic!(sock1.peek(&mut buf));\n        assert_eq!(size, 11);\n        assert_eq!(msg, &buf[..]);\n    }\n\n    let mut buf = [0; 11];\n    let size = or_panic!(sock1.recv(&mut buf));\n    assert_eq!(size, 11);\n    assert_eq!(msg, &buf[..]);\n}\n\n#[test]\nfn test_unix_datagram_peek_from() {\n    let dir = tmpdir();\n    let path1 = dir.path().join(\"sock\");\n\n    let sock1 = or_panic!(UnixDatagram::bind(&path1));\n    let sock2 = or_panic!(UnixDatagram::unbound());\n    or_panic!(sock2.connect(&path1));\n\n    let msg = b\"hello world\";\n    or_panic!(sock2.send(msg));\n    for _ in 0..2 {\n        let mut buf = [0; 11];\n        let (size, _) = or_panic!(sock1.peek_from(&mut buf));\n        assert_eq!(size, 11);\n        assert_eq!(msg, &buf[..]);\n    }\n\n    let mut buf = [0; 11];\n    let size = or_panic!(sock1.recv(&mut buf));\n    assert_eq!(size, 11);\n    assert_eq!(msg, &buf[..]);\n}\n\n#[cfg(any(\n    target_os = \"android\",\n    target_os = \"dragonfly\",\n    target_os = \"emscripten\",\n    target_os = \"freebsd\",\n    target_os = \"linux\",\n    target_os = \"netbsd\",\n    target_os = \"openbsd\",\n))]\n#[test]\nfn test_send_vectored_fds_unix_stream() {\n    let (s1, s2) = or_panic!(UnixStream::pair());\n\n    let buf1 = [1; 8];\n    let bufs_send = &[IoSlice::new(&buf1[..])][..];\n\n    let mut ancillary1_buffer = [0; 128];\n    let mut ancillary1 = SocketAncillary::new(&mut ancillary1_buffer[..]);\n    assert!(ancillary1.add_fds(&[s1.as_raw_fd()][..]));\n\n    let usize = or_panic!(s1.send_vectored_with_ancillary(&bufs_send, &mut ancillary1));\n    assert_eq!(usize, 8);\n\n    let mut buf2 = [0; 8];\n    let mut bufs_recv = &mut [IoSliceMut::new(&mut buf2[..])][..];\n\n    let mut ancillary2_buffer = [0; 128];\n    let mut ancillary2 = SocketAncillary::new(&mut ancillary2_buffer[..]);\n\n    let usize = or_panic!(s2.recv_vectored_with_ancillary(&mut bufs_recv, &mut ancillary2));\n    assert_eq!(usize, 8);\n    assert_eq!(buf1, buf2);\n\n    let mut ancillary_data_vec = Vec::from_iter(ancillary2.messages());\n    assert_eq!(ancillary_data_vec.len(), 1);\n    if let AncillaryData::ScmRights(scm_rights) = ancillary_data_vec.pop().unwrap().unwrap() {\n        let fd_vec = Vec::from_iter(scm_rights);\n        assert_eq!(fd_vec.len(), 1);\n        unsafe {\n            libc::close(fd_vec[0]);\n        }\n    } else {\n        unreachable!(\"must be ScmRights\");\n    }\n}\n\n#[cfg(any(target_os = \"android\", target_os = \"emscripten\", target_os = \"linux\",))]\n#[test]\nfn test_send_vectored_with_ancillary_to_unix_datagram() {\n    fn getpid() -> libc::pid_t {\n        unsafe { libc::getpid() }\n    }\n\n    fn getuid() -> libc::uid_t {\n        unsafe { libc::getuid() }\n    }\n\n    fn getgid() -> libc::gid_t {\n        unsafe { libc::getgid() }\n    }\n\n    let dir = tmpdir();\n    let path1 = dir.path().join(\"sock1\");\n    let path2 = dir.path().join(\"sock2\");\n\n    let bsock1 = or_panic!(UnixDatagram::bind(&path1));\n    let bsock2 = or_panic!(UnixDatagram::bind(&path2));\n\n    or_panic!(bsock2.set_passcred(true));\n\n    let buf1 = [1; 8];\n    let bufs_send = &[IoSlice::new(&buf1[..])][..];\n\n    let mut ancillary1_buffer = [0; 128];\n    let mut ancillary1 = SocketAncillary::new(&mut ancillary1_buffer[..]);\n    let mut cred1 = SocketCred::new();\n    cred1.set_pid(getpid());\n    cred1.set_uid(getuid());\n    cred1.set_gid(getgid());\n    assert!(ancillary1.add_creds(&[cred1.clone()][..]));\n\n    let usize =\n        or_panic!(bsock1.send_vectored_with_ancillary_to(&bufs_send, &mut ancillary1, &path2));\n    assert_eq!(usize, 8);\n\n    let mut buf2 = [0; 8];\n    let mut bufs_recv = &mut [IoSliceMut::new(&mut buf2[..])][..];\n\n    let mut ancillary2_buffer = [0; 128];\n    let mut ancillary2 = SocketAncillary::new(&mut ancillary2_buffer[..]);\n\n    let (usize, truncated, _addr) =\n        or_panic!(bsock2.recv_vectored_with_ancillary_from(&mut bufs_recv, &mut ancillary2));\n    assert_eq!(ancillary2.truncated(), false);\n    assert_eq!(usize, 8);\n    assert_eq!(truncated, false);\n    assert_eq!(buf1, buf2);\n\n    let mut ancillary_data_vec = Vec::from_iter(ancillary2.messages());\n    assert_eq!(ancillary_data_vec.len(), 1);\n    if let AncillaryData::ScmCredentials(scm_credentials) =\n        ancillary_data_vec.pop().unwrap().unwrap()\n    {\n        let cred_vec = Vec::from_iter(scm_credentials);\n        assert_eq!(cred_vec.len(), 1);\n        assert_eq!(cred1.get_pid(), cred_vec[0].get_pid());\n        assert_eq!(cred1.get_uid(), cred_vec[0].get_uid());\n        assert_eq!(cred1.get_gid(), cred_vec[0].get_gid());\n    } else {\n        unreachable!(\"must be ScmCredentials\");\n    }\n}\n\n#[cfg(any(\n    target_os = \"android\",\n    target_os = \"dragonfly\",\n    target_os = \"emscripten\",\n    target_os = \"freebsd\",\n    target_os = \"linux\",\n    target_os = \"netbsd\",\n    target_os = \"openbsd\",\n))]\n#[test]\nfn test_send_vectored_with_ancillary_unix_datagram() {\n    let dir = tmpdir();\n    let path1 = dir.path().join(\"sock1\");\n    let path2 = dir.path().join(\"sock2\");\n\n    let bsock1 = or_panic!(UnixDatagram::bind(&path1));\n    let bsock2 = or_panic!(UnixDatagram::bind(&path2));\n\n    let buf1 = [1; 8];\n    let bufs_send = &[IoSlice::new(&buf1[..])][..];\n\n    let mut ancillary1_buffer = [0; 128];\n    let mut ancillary1 = SocketAncillary::new(&mut ancillary1_buffer[..]);\n    assert!(ancillary1.add_fds(&[bsock1.as_raw_fd()][..]));\n\n    or_panic!(bsock1.connect(&path2));\n    let usize = or_panic!(bsock1.send_vectored_with_ancillary(&bufs_send, &mut ancillary1));\n    assert_eq!(usize, 8);\n\n    let mut buf2 = [0; 8];\n    let mut bufs_recv = &mut [IoSliceMut::new(&mut buf2[..])][..];\n\n    let mut ancillary2_buffer = [0; 128];\n    let mut ancillary2 = SocketAncillary::new(&mut ancillary2_buffer[..]);\n\n    let (usize, truncated) =\n        or_panic!(bsock2.recv_vectored_with_ancillary(&mut bufs_recv, &mut ancillary2));\n    assert_eq!(usize, 8);\n    assert_eq!(truncated, false);\n    assert_eq!(buf1, buf2);\n\n    let mut ancillary_data_vec = Vec::from_iter(ancillary2.messages());\n    assert_eq!(ancillary_data_vec.len(), 1);\n    if let AncillaryData::ScmRights(scm_rights) = ancillary_data_vec.pop().unwrap().unwrap() {\n        let fd_vec = Vec::from_iter(scm_rights);\n        assert_eq!(fd_vec.len(), 1);\n        unsafe {\n            libc::close(fd_vec[0]);\n        }\n    } else {\n        unreachable!(\"must be ScmRights\");\n    }\n}\n"],[2152,"use super::{sockaddr_un, SocketAddr, UnixStream};\nuse crate::os::unix::io::{AsRawFd, FromRawFd, IntoRawFd, RawFd};\nuse crate::path::Path;\nuse crate::sys::cvt;\nuse crate::sys::net::Socket;\nuse crate::sys_common::{AsInner, FromInner, IntoInner};\nuse crate::{fmt, io, mem};\n\n/// A structure representing a Unix domain socket server.\n///\n/// # Examples\n///\n/// ```no_run\n/// use std::thread;\n/// use std::os::unix::net::{UnixStream, UnixListener};\n///\n/// fn handle_client(stream: UnixStream) {\n///     // ...\n/// }\n///\n/// fn main() -> std::io::Result<()> {\n///     let listener = UnixListener::bind(\"/path/to/the/socket\")?;\n///\n///     // accept connections and process them, spawning a new thread for each one\n///     for stream in listener.incoming() {\n///         match stream {\n///             Ok(stream) => {\n///                 /* connection succeeded */\n///                 thread::spawn(|| handle_client(stream));\n///             }\n///             Err(err) => {\n///                 /* connection failed */\n///                 break;\n///             }\n///         }\n///     }\n///     Ok(())\n/// }\n/// ```\n#[stable(feature = \"unix_socket\", since = \"1.10.0\")]\npub struct UnixListener(Socket);\n\n#[stable(feature = \"unix_socket\", since = \"1.10.0\")]\nimpl fmt::Debug for UnixListener {\n    fn fmt(&self, fmt: &mut fmt::Formatter<'_>) -> fmt::Result {\n        let mut builder = fmt.debug_struct(\"UnixListener\");\n        builder.field(\"fd\", self.0.as_inner());\n        if let Ok(addr) = self.local_addr() {\n            builder.field(\"local\", &addr);\n        }\n        builder.finish()\n    }\n}\n\nimpl UnixListener {\n    /// Creates a new `UnixListener` bound to the specified socket.\n    ///\n    /// # Examples\n    ///\n    /// ```no_run\n    /// use std::os::unix::net::UnixListener;\n    ///\n    /// let listener = match UnixListener::bind(\"/path/to/the/socket\") {\n    ///     Ok(sock) => sock,\n    ///     Err(e) => {\n    ///         println!(\"Couldn't connect: {:?}\", e);\n    ///         return\n    ///     }\n    /// };\n    /// ```\n    #[stable(feature = \"unix_socket\", since = \"1.10.0\")]\n    pub fn bind<P: AsRef<Path>>(path: P) -> io::Result<UnixListener> {\n        unsafe {\n            let inner = Socket::new_raw(libc::AF_UNIX, libc::SOCK_STREAM)?;\n            let (addr, len) = sockaddr_un(path.as_ref())?;\n\n            cvt(libc::bind(*inner.as_inner(), &addr as *const _ as *const _, len as _))?;\n            cvt(libc::listen(*inner.as_inner(), 128))?;\n\n            Ok(UnixListener(inner))\n        }\n    }\n\n    /// Accepts a new incoming connection to this listener.\n    ///\n    /// This function will block the calling thread until a new Unix connection\n    /// is established. When established, the corresponding [`UnixStream`] and\n    /// the remote peer's address will be returned.\n    ///\n    /// [`UnixStream`]: crate::os::unix::net::UnixStream\n    ///\n    /// # Examples\n    ///\n    /// ```no_run\n    /// use std::os::unix::net::UnixListener;\n    ///\n    /// fn main() -> std::io::Result<()> {\n    ///     let listener = UnixListener::bind(\"/path/to/the/socket\")?;\n    ///\n    ///     match listener.accept() {\n    ///         Ok((socket, addr)) => println!(\"Got a client: {:?}\", addr),\n    ///         Err(e) => println!(\"accept function failed: {:?}\", e),\n    ///     }\n    ///     Ok(())\n    /// }\n    /// ```\n    #[stable(feature = \"unix_socket\", since = \"1.10.0\")]\n    pub fn accept(&self) -> io::Result<(UnixStream, SocketAddr)> {\n        let mut storage: libc::sockaddr_un = unsafe { mem::zeroed() };\n        let mut len = mem::size_of_val(&storage) as libc::socklen_t;\n        let sock = self.0.accept(&mut storage as *mut _ as *mut _, &mut len)?;\n        let addr = SocketAddr::from_parts(storage, len)?;\n        Ok((UnixStream(sock), addr))\n    }\n\n    /// Creates a new independently owned handle to the underlying socket.\n    ///\n    /// The returned `UnixListener` is a reference to the same socket that this\n    /// object references. Both handles can be used to accept incoming\n    /// connections and options set on one listener will affect the other.\n    ///\n    /// # Examples\n    ///\n    /// ```no_run\n    /// use std::os::unix::net::UnixListener;\n    ///\n    /// fn main() -> std::io::Result<()> {\n    ///     let listener = UnixListener::bind(\"/path/to/the/socket\")?;\n    ///     let listener_copy = listener.try_clone().expect(\"try_clone failed\");\n    ///     Ok(())\n    /// }\n    /// ```\n    #[stable(feature = \"unix_socket\", since = \"1.10.0\")]\n    pub fn try_clone(&self) -> io::Result<UnixListener> {\n        self.0.duplicate().map(UnixListener)\n    }\n\n    /// Returns the local socket address of this listener.\n    ///\n    /// # Examples\n    ///\n    /// ```no_run\n    /// use std::os::unix::net::UnixListener;\n    ///\n    /// fn main() -> std::io::Result<()> {\n    ///     let listener = UnixListener::bind(\"/path/to/the/socket\")?;\n    ///     let addr = listener.local_addr().expect(\"Couldn't get local address\");\n    ///     Ok(())\n    /// }\n    /// ```\n    #[stable(feature = \"unix_socket\", since = \"1.10.0\")]\n    pub fn local_addr(&self) -> io::Result<SocketAddr> {\n        SocketAddr::new(|addr, len| unsafe { libc::getsockname(*self.0.as_inner(), addr, len) })\n    }\n\n    /// Moves the socket into or out of nonblocking mode.\n    ///\n    /// This will result in the `accept` operation becoming nonblocking,\n    /// i.e., immediately returning from their calls. If the IO operation is\n    /// successful, `Ok` is returned and no further action is required. If the\n    /// IO operation could not be completed and needs to be retried, an error\n    /// with kind [`io::ErrorKind::WouldBlock`] is returned.\n    ///\n    /// # Examples\n    ///\n    /// ```no_run\n    /// use std::os::unix::net::UnixListener;\n    ///\n    /// fn main() -> std::io::Result<()> {\n    ///     let listener = UnixListener::bind(\"/path/to/the/socket\")?;\n    ///     listener.set_nonblocking(true).expect(\"Couldn't set non blocking\");\n    ///     Ok(())\n    /// }\n    /// ```\n    #[stable(feature = \"unix_socket\", since = \"1.10.0\")]\n    pub fn set_nonblocking(&self, nonblocking: bool) -> io::Result<()> {\n        self.0.set_nonblocking(nonblocking)\n    }\n\n    /// Returns the value of the `SO_ERROR` option.\n    ///\n    /// # Examples\n    ///\n    /// ```no_run\n    /// use std::os::unix::net::UnixListener;\n    ///\n    /// fn main() -> std::io::Result<()> {\n    ///     let listener = UnixListener::bind(\"/tmp/sock\")?;\n    ///\n    ///     if let Ok(Some(err)) = listener.take_error() {\n    ///         println!(\"Got error: {:?}\", err);\n    ///     }\n    ///     Ok(())\n    /// }\n    /// ```\n    ///\n    /// # Platform specific\n    /// On Redox this always returns `None`.\n    #[stable(feature = \"unix_socket\", since = \"1.10.0\")]\n    pub fn take_error(&self) -> io::Result<Option<io::Error>> {\n        self.0.take_error()\n    }\n\n    /// Returns an iterator over incoming connections.\n    ///\n    /// The iterator will never return [`None`] and will also not yield the\n    /// peer's [`SocketAddr`] structure.\n    ///\n    /// # Examples\n    ///\n    /// ```no_run\n    /// use std::thread;\n    /// use std::os::unix::net::{UnixStream, UnixListener};\n    ///\n    /// fn handle_client(stream: UnixStream) {\n    ///     // ...\n    /// }\n    ///\n    /// fn main() -> std::io::Result<()> {\n    ///     let listener = UnixListener::bind(\"/path/to/the/socket\")?;\n    ///\n    ///     for stream in listener.incoming() {\n    ///         match stream {\n    ///             Ok(stream) => {\n    ///                 thread::spawn(|| handle_client(stream));\n    ///             }\n    ///             Err(err) => {\n    ///                 break;\n    ///             }\n    ///         }\n    ///     }\n    ///     Ok(())\n    /// }\n    /// ```\n    #[stable(feature = \"unix_socket\", since = \"1.10.0\")]\n    pub fn incoming(&self) -> Incoming<'_> {\n        Incoming { listener: self }\n    }\n}\n\n#[stable(feature = \"unix_socket\", since = \"1.10.0\")]\nimpl AsRawFd for UnixListener {\n    #[inline]\n    fn as_raw_fd(&self) -> RawFd {\n        *self.0.as_inner()\n    }\n}\n\n#[stable(feature = \"unix_socket\", since = \"1.10.0\")]\nimpl FromRawFd for UnixListener {\n    #[inline]\n    unsafe fn from_raw_fd(fd: RawFd) -> UnixListener {\n        UnixListener(Socket::from_inner(fd))\n    }\n}\n\n#[stable(feature = \"unix_socket\", since = \"1.10.0\")]\nimpl IntoRawFd for UnixListener {\n    #[inline]\n    fn into_raw_fd(self) -> RawFd {\n        self.0.into_inner()\n    }\n}\n\n#[stable(feature = \"unix_socket\", since = \"1.10.0\")]\nimpl<'a> IntoIterator for &'a UnixListener {\n    type Item = io::Result<UnixStream>;\n    type IntoIter = Incoming<'a>;\n\n    fn into_iter(self) -> Incoming<'a> {\n        self.incoming()\n    }\n}\n\n/// An iterator over incoming connections to a [`UnixListener`].\n///\n/// It will never return [`None`].\n///\n/// # Examples\n///\n/// ```no_run\n/// use std::thread;\n/// use std::os::unix::net::{UnixStream, UnixListener};\n///\n/// fn handle_client(stream: UnixStream) {\n///     // ...\n/// }\n///\n/// fn main() -> std::io::Result<()> {\n///     let listener = UnixListener::bind(\"/path/to/the/socket\")?;\n///\n///     for stream in listener.incoming() {\n///         match stream {\n///             Ok(stream) => {\n///                 thread::spawn(|| handle_client(stream));\n///             }\n///             Err(err) => {\n///                 break;\n///             }\n///         }\n///     }\n///     Ok(())\n/// }\n/// ```\n#[derive(Debug)]\n#[stable(feature = \"unix_socket\", since = \"1.10.0\")]\npub struct Incoming<'a> {\n    listener: &'a UnixListener,\n}\n\n#[stable(feature = \"unix_socket\", since = \"1.10.0\")]\nimpl<'a> Iterator for Incoming<'a> {\n    type Item = io::Result<UnixStream>;\n\n    fn next(&mut self) -> Option<io::Result<UnixStream>> {\n        Some(self.listener.accept().map(|s| s.0))\n    }\n\n    fn size_hint(&self) -> (usize, Option<usize>) {\n        (usize::MAX, None)\n    }\n}\n"],[2153,"use crate::ffi::OsStr;\nuse crate::os::unix::ffi::OsStrExt;\nuse crate::path::Path;\nuse crate::sys::cvt;\nuse crate::{ascii, fmt, io, iter, mem};\n\n// FIXME(#43348): Make libc adapt #[doc(cfg(...))] so we don't need these fake definitions here?\n#[cfg(not(unix))]\n#[allow(non_camel_case_types)]\nmod libc {\n    pub use libc::c_int;\n    pub type socklen_t = u32;\n    pub struct sockaddr;\n    #[derive(Clone)]\n    pub struct sockaddr_un;\n}\n\nfn sun_path_offset(addr: &libc::sockaddr_un) -> usize {\n    // Work with an actual instance of the type since using a null pointer is UB\n    let base = addr as *const _ as usize;\n    let path = &addr.sun_path as *const _ as usize;\n    path - base\n}\n\npub(super) unsafe fn sockaddr_un(path: &Path) -> io::Result<(libc::sockaddr_un, libc::socklen_t)> {\n    let mut addr: libc::sockaddr_un = mem::zeroed();\n    addr.sun_family = libc::AF_UNIX as libc::sa_family_t;\n\n    let bytes = path.as_os_str().as_bytes();\n\n    if bytes.contains(&0) {\n        return Err(io::Error::new_const(\n            io::ErrorKind::InvalidInput,\n            &\"paths may not contain interior null bytes\",\n        ));\n    }\n\n    if bytes.len() >= addr.sun_path.len() {\n        return Err(io::Error::new_const(\n            io::ErrorKind::InvalidInput,\n            &\"path must be shorter than SUN_LEN\",\n        ));\n    }\n    for (dst, src) in iter::zip(&mut addr.sun_path, bytes) {\n        *dst = *src as libc::c_char;\n    }\n    // null byte for pathname addresses is already there because we zeroed the\n    // struct\n\n    let mut len = sun_path_offset(&addr) + bytes.len();\n    match bytes.get(0) {\n        Some(&0) | None => {}\n        Some(_) => len += 1,\n    }\n    Ok((addr, len as libc::socklen_t))\n}\n\nenum AddressKind<'a> {\n    Unnamed,\n    Pathname(&'a Path),\n    Abstract(&'a [u8]),\n}\n\nstruct AsciiEscaped<'a>(&'a [u8]);\n\nimpl<'a> fmt::Display for AsciiEscaped<'a> {\n    fn fmt(&self, fmt: &mut fmt::Formatter<'_>) -> fmt::Result {\n        write!(fmt, \"\\\"\")?;\n        for byte in self.0.iter().cloned().flat_map(ascii::escape_default) {\n            write!(fmt, \"{}\", byte as char)?;\n        }\n        write!(fmt, \"\\\"\")\n    }\n}\n\n/// An address associated with a Unix socket.\n///\n/// # Examples\n///\n/// ```\n/// use std::os::unix::net::UnixListener;\n///\n/// let socket = match UnixListener::bind(\"/tmp/sock\") {\n///     Ok(sock) => sock,\n///     Err(e) => {\n///         println!(\"Couldn't bind: {:?}\", e);\n///         return\n///     }\n/// };\n/// let addr = socket.local_addr().expect(\"Couldn't get local address\");\n/// ```\n#[derive(Clone)]\n#[stable(feature = \"unix_socket\", since = \"1.10.0\")]\npub struct SocketAddr {\n    addr: libc::sockaddr_un,\n    len: libc::socklen_t,\n}\n\nimpl SocketAddr {\n    pub(super) fn new<F>(f: F) -> io::Result<SocketAddr>\n    where\n        F: FnOnce(*mut libc::sockaddr, *mut libc::socklen_t) -> libc::c_int,\n    {\n        unsafe {\n            let mut addr: libc::sockaddr_un = mem::zeroed();\n            let mut len = mem::size_of::<libc::sockaddr_un>() as libc::socklen_t;\n            cvt(f(&mut addr as *mut _ as *mut _, &mut len))?;\n            SocketAddr::from_parts(addr, len)\n        }\n    }\n\n    pub(super) fn from_parts(\n        addr: libc::sockaddr_un,\n        mut len: libc::socklen_t,\n    ) -> io::Result<SocketAddr> {\n        if len == 0 {\n            // When there is a datagram from unnamed unix socket\n            // linux returns zero bytes of address\n            len = sun_path_offset(&addr) as libc::socklen_t; // i.e., zero-length address\n        } else if addr.sun_family != libc::AF_UNIX as libc::sa_family_t {\n            return Err(io::Error::new_const(\n                io::ErrorKind::InvalidInput,\n                &\"file descriptor did not correspond to a Unix socket\",\n            ));\n        }\n\n        Ok(SocketAddr { addr, len })\n    }\n\n    /// Returns `true` if the address is unnamed.\n    ///\n    /// # Examples\n    ///\n    /// A named address:\n    ///\n    /// ```no_run\n    /// use std::os::unix::net::UnixListener;\n    ///\n    /// fn main() -> std::io::Result<()> {\n    ///     let socket = UnixListener::bind(\"/tmp/sock\")?;\n    ///     let addr = socket.local_addr().expect(\"Couldn't get local address\");\n    ///     assert_eq!(addr.is_unnamed(), false);\n    ///     Ok(())\n    /// }\n    /// ```\n    ///\n    /// An unnamed address:\n    ///\n    /// ```\n    /// use std::os::unix::net::UnixDatagram;\n    ///\n    /// fn main() -> std::io::Result<()> {\n    ///     let socket = UnixDatagram::unbound()?;\n    ///     let addr = socket.local_addr().expect(\"Couldn't get local address\");\n    ///     assert_eq!(addr.is_unnamed(), true);\n    ///     Ok(())\n    /// }\n    /// ```\n    #[stable(feature = \"unix_socket\", since = \"1.10.0\")]\n    pub fn is_unnamed(&self) -> bool {\n        if let AddressKind::Unnamed = self.address() { true } else { false }\n    }\n\n    /// Returns the contents of this address if it is a `pathname` address.\n    ///\n    /// # Examples\n    ///\n    /// With a pathname:\n    ///\n    /// ```no_run\n    /// use std::os::unix::net::UnixListener;\n    /// use std::path::Path;\n    ///\n    /// fn main() -> std::io::Result<()> {\n    ///     let socket = UnixListener::bind(\"/tmp/sock\")?;\n    ///     let addr = socket.local_addr().expect(\"Couldn't get local address\");\n    ///     assert_eq!(addr.as_pathname(), Some(Path::new(\"/tmp/sock\")));\n    ///     Ok(())\n    /// }\n    /// ```\n    ///\n    /// Without a pathname:\n    ///\n    /// ```\n    /// use std::os::unix::net::UnixDatagram;\n    ///\n    /// fn main() -> std::io::Result<()> {\n    ///     let socket = UnixDatagram::unbound()?;\n    ///     let addr = socket.local_addr().expect(\"Couldn't get local address\");\n    ///     assert_eq!(addr.as_pathname(), None);\n    ///     Ok(())\n    /// }\n    /// ```\n    #[stable(feature = \"unix_socket\", since = \"1.10.0\")]\n    pub fn as_pathname(&self) -> Option<&Path> {\n        if let AddressKind::Pathname(path) = self.address() { Some(path) } else { None }\n    }\n\n    fn address(&self) -> AddressKind<'_> {\n        let len = self.len as usize - sun_path_offset(&self.addr);\n        let path = unsafe { mem::transmute::<&[libc::c_char], &[u8]>(&self.addr.sun_path) };\n\n        // macOS seems to return a len of 16 and a zeroed sun_path for unnamed addresses\n        if len == 0\n            || (cfg!(not(any(target_os = \"linux\", target_os = \"android\")))\n                && self.addr.sun_path[0] == 0)\n        {\n            AddressKind::Unnamed\n        } else if self.addr.sun_path[0] == 0 {\n            AddressKind::Abstract(&path[1..len])\n        } else {\n            AddressKind::Pathname(OsStr::from_bytes(&path[..len - 1]).as_ref())\n        }\n    }\n}\n\n#[stable(feature = \"unix_socket\", since = \"1.10.0\")]\nimpl fmt::Debug for SocketAddr {\n    fn fmt(&self, fmt: &mut fmt::Formatter<'_>) -> fmt::Result {\n        match self.address() {\n            AddressKind::Unnamed => write!(fmt, \"(unnamed)\"),\n            AddressKind::Abstract(name) => write!(fmt, \"{} (abstract)\", AsciiEscaped(name)),\n            AddressKind::Pathname(path) => write!(fmt, \"{:?} (pathname)\", path),\n        }\n    }\n}\n"],[2154,"//! Unix-specific networking functionality\n\n#![stable(feature = \"unix_socket\", since = \"1.10.0\")]\n\nmod addr;\n#[doc(cfg(any(\n    target_os = \"android\",\n    target_os = \"dragonfly\",\n    target_os = \"emscripten\",\n    target_os = \"freebsd\",\n    target_os = \"linux\",\n    target_os = \"netbsd\",\n    target_os = \"openbsd\",\n)))]\n#[cfg(any(\n    doc,\n    target_os = \"android\",\n    target_os = \"dragonfly\",\n    target_os = \"emscripten\",\n    target_os = \"freebsd\",\n    target_os = \"linux\",\n    target_os = \"netbsd\",\n    target_os = \"openbsd\",\n))]\nmod ancillary;\nmod datagram;\nmod listener;\nmod raw_fd;\nmod stream;\n#[cfg(all(test, not(target_os = \"emscripten\")))]\nmod tests;\n\n#[stable(feature = \"unix_socket\", since = \"1.10.0\")]\npub use self::addr::*;\n#[cfg(any(\n    doc,\n    target_os = \"android\",\n    target_os = \"dragonfly\",\n    target_os = \"emscripten\",\n    target_os = \"freebsd\",\n    target_os = \"linux\",\n    target_os = \"netbsd\",\n    target_os = \"openbsd\",\n))]\n#[unstable(feature = \"unix_socket_ancillary_data\", issue = \"76915\")]\npub use self::ancillary::*;\n#[stable(feature = \"unix_socket\", since = \"1.10.0\")]\npub use self::datagram::*;\n#[stable(feature = \"unix_socket\", since = \"1.10.0\")]\npub use self::listener::*;\n#[stable(feature = \"rust1\", since = \"1.0.0\")]\npub use self::raw_fd::*;\n#[stable(feature = \"unix_socket\", since = \"1.10.0\")]\npub use self::stream::*;\n"],[2155,"//! Unix peer credentials.\n\n// NOTE: Code in this file is heavily based on work done in PR 13 from the tokio-uds repository on\n//       GitHub.\n//\n//       For reference, the link is here: https://github.com/tokio-rs/tokio-uds/pull/13\n//       Credit to Martin Habovštiak (GitHub username Kixunil) and contributors for this work.\n\nuse libc::{gid_t, pid_t, uid_t};\n\n/// Credentials for a UNIX process for credentials passing.\n#[unstable(feature = \"peer_credentials_unix_socket\", issue = \"42839\", reason = \"unstable\")]\n#[derive(Clone, Copy, Debug, Eq, Hash, PartialEq)]\npub struct UCred {\n    /// The UID part of the peer credential. This is the effective UID of the process at the domain\n    /// socket's endpoint.\n    pub uid: uid_t,\n    /// The GID part of the peer credential. This is the effective GID of the process at the domain\n    /// socket's endpoint.\n    pub gid: gid_t,\n    /// The PID part of the peer credential. This field is optional because the PID part of the\n    /// peer credentials is not supported on every platform. On platforms where the mechanism to\n    /// discover the PID exists, this field will be populated to the PID of the process at the\n    /// domain socket's endpoint. Otherwise, it will be set to None.\n    pub pid: Option<pid_t>,\n}\n\n#[cfg(any(target_os = \"android\", target_os = \"linux\"))]\npub use self::impl_linux::peer_cred;\n\n#[cfg(any(target_os = \"dragonfly\", target_os = \"freebsd\", target_os = \"openbsd\"))]\npub use self::impl_bsd::peer_cred;\n\n#[cfg(any(target_os = \"macos\", target_os = \"ios\",))]\npub use self::impl_mac::peer_cred;\n\n#[cfg(any(target_os = \"linux\", target_os = \"android\"))]\npub mod impl_linux {\n    use super::UCred;\n    use crate::os::unix::io::AsRawFd;\n    use crate::os::unix::net::UnixStream;\n    use crate::{io, mem};\n    use libc::{c_void, getsockopt, socklen_t, ucred, SOL_SOCKET, SO_PEERCRED};\n\n    pub fn peer_cred(socket: &UnixStream) -> io::Result<UCred> {\n        let ucred_size = mem::size_of::<ucred>();\n\n        // Trivial sanity checks.\n        assert!(mem::size_of::<u32>() <= mem::size_of::<usize>());\n        assert!(ucred_size <= u32::MAX as usize);\n\n        let mut ucred_size = ucred_size as socklen_t;\n        let mut ucred: ucred = ucred { pid: 1, uid: 1, gid: 1 };\n\n        unsafe {\n            let ret = getsockopt(\n                socket.as_raw_fd(),\n                SOL_SOCKET,\n                SO_PEERCRED,\n                &mut ucred as *mut ucred as *mut c_void,\n                &mut ucred_size,\n            );\n\n            if ret == 0 && ucred_size as usize == mem::size_of::<ucred>() {\n                Ok(UCred { uid: ucred.uid, gid: ucred.gid, pid: Some(ucred.pid) })\n            } else {\n                Err(io::Error::last_os_error())\n            }\n        }\n    }\n}\n\n#[cfg(any(target_os = \"dragonfly\", target_os = \"freebsd\", target_os = \"openbsd\"))]\npub mod impl_bsd {\n    use super::UCred;\n    use crate::io;\n    use crate::os::unix::io::AsRawFd;\n    use crate::os::unix::net::UnixStream;\n\n    pub fn peer_cred(socket: &UnixStream) -> io::Result<UCred> {\n        let mut cred = UCred { uid: 1, gid: 1, pid: None };\n        unsafe {\n            let ret = libc::getpeereid(socket.as_raw_fd(), &mut cred.uid, &mut cred.gid);\n\n            if ret == 0 { Ok(cred) } else { Err(io::Error::last_os_error()) }\n        }\n    }\n}\n\n#[cfg(any(target_os = \"macos\", target_os = \"ios\",))]\npub mod impl_mac {\n    use super::UCred;\n    use crate::os::unix::io::AsRawFd;\n    use crate::os::unix::net::UnixStream;\n    use crate::{io, mem};\n    use libc::{c_void, getpeereid, getsockopt, pid_t, socklen_t, LOCAL_PEERPID, SOL_LOCAL};\n\n    pub fn peer_cred(socket: &UnixStream) -> io::Result<UCred> {\n        let mut cred = UCred { uid: 1, gid: 1, pid: None };\n        unsafe {\n            let ret = getpeereid(socket.as_raw_fd(), &mut cred.uid, &mut cred.gid);\n\n            if ret != 0 {\n                return Err(io::Error::last_os_error());\n            }\n\n            let mut pid: pid_t = 1;\n            let mut pid_size = mem::size_of::<pid_t>() as socklen_t;\n\n            let ret = getsockopt(\n                socket.as_raw_fd(),\n                SOL_LOCAL,\n                LOCAL_PEERPID,\n                &mut pid as *mut pid_t as *mut c_void,\n                &mut pid_size,\n            );\n\n            if ret == 0 && pid_size as usize == mem::size_of::<pid_t>() {\n                cred.pid = Some(pid);\n                Ok(cred)\n            } else {\n                Err(io::Error::last_os_error())\n            }\n        }\n    }\n}\n"],[2156,"//! Unix-specific extensions to primitives in the `std::thread` module.\n\n#![stable(feature = \"thread_extensions\", since = \"1.9.0\")]\n\n#[allow(deprecated)]\nuse crate::os::unix::raw::pthread_t;\nuse crate::sys_common::{AsInner, IntoInner};\nuse crate::thread::JoinHandle;\n\n#[stable(feature = \"thread_extensions\", since = \"1.9.0\")]\n#[allow(deprecated)]\npub type RawPthread = pthread_t;\n\n/// Unix-specific extensions to [`JoinHandle`].\n#[stable(feature = \"thread_extensions\", since = \"1.9.0\")]\npub trait JoinHandleExt {\n    /// Extracts the raw pthread_t without taking ownership\n    #[stable(feature = \"thread_extensions\", since = \"1.9.0\")]\n    fn as_pthread_t(&self) -> RawPthread;\n\n    /// Consumes the thread, returning the raw pthread_t\n    ///\n    /// This function **transfers ownership** of the underlying pthread_t to\n    /// the caller. Callers are then the unique owners of the pthread_t and\n    /// must either detach or join the pthread_t once it's no longer needed.\n    #[stable(feature = \"thread_extensions\", since = \"1.9.0\")]\n    fn into_pthread_t(self) -> RawPthread;\n}\n\n#[stable(feature = \"thread_extensions\", since = \"1.9.0\")]\nimpl<T> JoinHandleExt for JoinHandle<T> {\n    fn as_pthread_t(&self) -> RawPthread {\n        self.as_inner().id() as RawPthread\n    }\n\n    fn into_pthread_t(self) -> RawPthread {\n        self.into_inner().into_id() as RawPthread\n    }\n}\n"],[2157,"//! iOS-specific definitions\n\n#![stable(feature = \"raw_ext\", since = \"1.1.0\")]\n\npub mod fs;\npub mod raw;\n"],[2158,"#![stable(feature = \"metadata_ext\", since = \"1.1.0\")]\n\nuse crate::fs::Metadata;\nuse crate::sys_common::AsInner;\n\n#[allow(deprecated)]\nuse crate::os::ios::raw;\n\n/// OS-specific extensions to [`fs::Metadata`].\n///\n/// [`fs::Metadata`]: crate::fs::Metadata\n#[stable(feature = \"metadata_ext\", since = \"1.1.0\")]\npub trait MetadataExt {\n    /// Gain a reference to the underlying `stat` structure which contains\n    /// the raw information returned by the OS.\n    ///\n    /// The contents of the returned `stat` are **not** consistent across\n    /// Unix platforms. The `os::unix::fs::MetadataExt` trait contains the\n    /// cross-Unix abstractions contained within the raw stat.\n    #[stable(feature = \"metadata_ext\", since = \"1.1.0\")]\n    #[rustc_deprecated(\n        since = \"1.8.0\",\n        reason = \"deprecated in favor of the accessor \\\n                  methods of this trait\"\n    )]\n    #[allow(deprecated)]\n    fn as_raw_stat(&self) -> &raw::stat;\n\n    #[stable(feature = \"metadata_ext2\", since = \"1.8.0\")]\n    fn st_dev(&self) -> u64;\n    #[stable(feature = \"metadata_ext2\", since = \"1.8.0\")]\n    fn st_ino(&self) -> u64;\n    #[stable(feature = \"metadata_ext2\", since = \"1.8.0\")]\n    fn st_mode(&self) -> u32;\n    #[stable(feature = \"metadata_ext2\", since = \"1.8.0\")]\n    fn st_nlink(&self) -> u64;\n    #[stable(feature = \"metadata_ext2\", since = \"1.8.0\")]\n    fn st_uid(&self) -> u32;\n    #[stable(feature = \"metadata_ext2\", since = \"1.8.0\")]\n    fn st_gid(&self) -> u32;\n    #[stable(feature = \"metadata_ext2\", since = \"1.8.0\")]\n    fn st_rdev(&self) -> u64;\n    #[stable(feature = \"metadata_ext2\", since = \"1.8.0\")]\n    fn st_size(&self) -> u64;\n    #[stable(feature = \"metadata_ext2\", since = \"1.8.0\")]\n    fn st_atime(&self) -> i64;\n    #[stable(feature = \"metadata_ext2\", since = \"1.8.0\")]\n    fn st_atime_nsec(&self) -> i64;\n    #[stable(feature = \"metadata_ext2\", since = \"1.8.0\")]\n    fn st_mtime(&self) -> i64;\n    #[stable(feature = \"metadata_ext2\", since = \"1.8.0\")]\n    fn st_mtime_nsec(&self) -> i64;\n    #[stable(feature = \"metadata_ext2\", since = \"1.8.0\")]\n    fn st_ctime(&self) -> i64;\n    #[stable(feature = \"metadata_ext2\", since = \"1.8.0\")]\n    fn st_ctime_nsec(&self) -> i64;\n    #[stable(feature = \"metadata_ext2\", since = \"1.8.0\")]\n    fn st_birthtime(&self) -> i64;\n    #[stable(feature = \"metadata_ext2\", since = \"1.8.0\")]\n    fn st_birthtime_nsec(&self) -> i64;\n    #[stable(feature = \"metadata_ext2\", since = \"1.8.0\")]\n    fn st_blksize(&self) -> u64;\n    #[stable(feature = \"metadata_ext2\", since = \"1.8.0\")]\n    fn st_blocks(&self) -> u64;\n    #[stable(feature = \"metadata_ext2\", since = \"1.8.0\")]\n    fn st_flags(&self) -> u32;\n    #[stable(feature = \"metadata_ext2\", since = \"1.8.0\")]\n    fn st_gen(&self) -> u32;\n    #[stable(feature = \"metadata_ext2\", since = \"1.8.0\")]\n    fn st_lspare(&self) -> u32;\n}\n\n#[stable(feature = \"metadata_ext\", since = \"1.1.0\")]\nimpl MetadataExt for Metadata {\n    #[allow(deprecated)]\n    fn as_raw_stat(&self) -> &raw::stat {\n        unsafe { &*(self.as_inner().as_inner() as *const libc::stat as *const raw::stat) }\n    }\n    fn st_dev(&self) -> u64 {\n        self.as_inner().as_inner().st_dev as u64\n    }\n    fn st_ino(&self) -> u64 {\n        self.as_inner().as_inner().st_ino as u64\n    }\n    fn st_mode(&self) -> u32 {\n        self.as_inner().as_inner().st_mode as u32\n    }\n    fn st_nlink(&self) -> u64 {\n        self.as_inner().as_inner().st_nlink as u64\n    }\n    fn st_uid(&self) -> u32 {\n        self.as_inner().as_inner().st_uid as u32\n    }\n    fn st_gid(&self) -> u32 {\n        self.as_inner().as_inner().st_gid as u32\n    }\n    fn st_rdev(&self) -> u64 {\n        self.as_inner().as_inner().st_rdev as u64\n    }\n    fn st_size(&self) -> u64 {\n        self.as_inner().as_inner().st_size as u64\n    }\n    fn st_atime(&self) -> i64 {\n        self.as_inner().as_inner().st_atime as i64\n    }\n    fn st_atime_nsec(&self) -> i64 {\n        self.as_inner().as_inner().st_atime_nsec as i64\n    }\n    fn st_mtime(&self) -> i64 {\n        self.as_inner().as_inner().st_mtime as i64\n    }\n    fn st_mtime_nsec(&self) -> i64 {\n        self.as_inner().as_inner().st_mtime_nsec as i64\n    }\n    fn st_ctime(&self) -> i64 {\n        self.as_inner().as_inner().st_ctime as i64\n    }\n    fn st_ctime_nsec(&self) -> i64 {\n        self.as_inner().as_inner().st_ctime_nsec as i64\n    }\n    fn st_birthtime(&self) -> i64 {\n        self.as_inner().as_inner().st_birthtime as i64\n    }\n    fn st_birthtime_nsec(&self) -> i64 {\n        self.as_inner().as_inner().st_birthtime_nsec as i64\n    }\n    fn st_blksize(&self) -> u64 {\n        self.as_inner().as_inner().st_blksize as u64\n    }\n    fn st_blocks(&self) -> u64 {\n        self.as_inner().as_inner().st_blocks as u64\n    }\n    fn st_gen(&self) -> u32 {\n        self.as_inner().as_inner().st_gen as u32\n    }\n    fn st_flags(&self) -> u32 {\n        self.as_inner().as_inner().st_flags as u32\n    }\n    fn st_lspare(&self) -> u32 {\n        self.as_inner().as_inner().st_lspare as u32\n    }\n}\n"],[2159,"//! iOS-specific raw type definitions\n\n#![stable(feature = \"raw_ext\", since = \"1.1.0\")]\n#![rustc_deprecated(\n    since = \"1.8.0\",\n    reason = \"these type aliases are no longer supported by \\\n              the standard library, the `libc` crate on \\\n              crates.io should be used instead for the correct \\\n              definitions\"\n)]\n#![allow(deprecated)]\n\nuse crate::os::raw::c_long;\n\n#[stable(feature = \"raw_ext\", since = \"1.1.0\")]\npub type blkcnt_t = u64;\n#[stable(feature = \"raw_ext\", since = \"1.1.0\")]\npub type blksize_t = u64;\n#[stable(feature = \"raw_ext\", since = \"1.1.0\")]\npub type dev_t = u64;\n#[stable(feature = \"raw_ext\", since = \"1.1.0\")]\npub type ino_t = u64;\n#[stable(feature = \"raw_ext\", since = \"1.1.0\")]\npub type mode_t = u32;\n#[stable(feature = \"raw_ext\", since = \"1.1.0\")]\npub type nlink_t = u64;\n#[stable(feature = \"raw_ext\", since = \"1.1.0\")]\npub type off_t = u64;\n#[stable(feature = \"raw_ext\", since = \"1.1.0\")]\npub type time_t = i64;\n\n#[stable(feature = \"pthread_t\", since = \"1.8.0\")]\npub type pthread_t = usize;\n\n#[repr(C)]\n#[derive(Clone)]\n#[stable(feature = \"raw_ext\", since = \"1.1.0\")]\npub struct stat {\n    #[stable(feature = \"raw_ext\", since = \"1.1.0\")]\n    pub st_dev: i32,\n    #[stable(feature = \"raw_ext\", since = \"1.1.0\")]\n    pub st_mode: u16,\n    #[stable(feature = \"raw_ext\", since = \"1.1.0\")]\n    pub st_nlink: u16,\n    #[stable(feature = \"raw_ext\", since = \"1.1.0\")]\n    pub st_ino: u64,\n    #[stable(feature = \"raw_ext\", since = \"1.1.0\")]\n    pub st_uid: u32,\n    #[stable(feature = \"raw_ext\", since = \"1.1.0\")]\n    pub st_gid: u32,\n    #[stable(feature = \"raw_ext\", since = \"1.1.0\")]\n    pub st_rdev: i32,\n    #[stable(feature = \"raw_ext\", since = \"1.1.0\")]\n    pub st_atime: c_long,\n    #[stable(feature = \"raw_ext\", since = \"1.1.0\")]\n    pub st_atime_nsec: c_long,\n    #[stable(feature = \"raw_ext\", since = \"1.1.0\")]\n    pub st_mtime: c_long,\n    #[stable(feature = \"raw_ext\", since = \"1.1.0\")]\n    pub st_mtime_nsec: c_long,\n    #[stable(feature = \"raw_ext\", since = \"1.1.0\")]\n    pub st_ctime: c_long,\n    #[stable(feature = \"raw_ext\", since = \"1.1.0\")]\n    pub st_ctime_nsec: c_long,\n    #[stable(feature = \"raw_ext\", since = \"1.1.0\")]\n    pub st_birthtime: c_long,\n    #[stable(feature = \"raw_ext\", since = \"1.1.0\")]\n    pub st_birthtime_nsec: c_long,\n    #[stable(feature = \"raw_ext\", since = \"1.1.0\")]\n    pub st_size: i64,\n    #[stable(feature = \"raw_ext\", since = \"1.1.0\")]\n    pub st_blocks: i64,\n    #[stable(feature = \"raw_ext\", since = \"1.1.0\")]\n    pub st_blksize: i32,\n    #[stable(feature = \"raw_ext\", since = \"1.1.0\")]\n    pub st_flags: u32,\n    #[stable(feature = \"raw_ext\", since = \"1.1.0\")]\n    pub st_gen: u32,\n    #[stable(feature = \"raw_ext\", since = \"1.1.0\")]\n    pub st_lspare: i32,\n    #[stable(feature = \"raw_ext\", since = \"1.1.0\")]\n    pub st_qspare: [i64; 2],\n}\n"],[2160,"//! NetBSD-specific raw type definitions\n\n#![stable(feature = \"raw_ext\", since = \"1.1.0\")]\n#![rustc_deprecated(\n    since = \"1.8.0\",\n    reason = \"these type aliases are no longer supported by \\\n              the standard library, the `libc` crate on \\\n              crates.io should be used instead for the correct \\\n              definitions\"\n)]\n#![allow(deprecated)]\n\nuse crate::os::raw::c_long;\nuse crate::os::unix::raw::{gid_t, uid_t};\n\n#[stable(feature = \"raw_ext\", since = \"1.1.0\")]\npub type blkcnt_t = u64;\n#[stable(feature = \"raw_ext\", since = \"1.1.0\")]\npub type blksize_t = u64;\n#[stable(feature = \"raw_ext\", since = \"1.1.0\")]\npub type dev_t = u64;\n#[stable(feature = \"raw_ext\", since = \"1.1.0\")]\npub type fflags_t = u32;\n#[stable(feature = \"raw_ext\", since = \"1.1.0\")]\npub type ino_t = u64;\n#[stable(feature = \"raw_ext\", since = \"1.1.0\")]\npub type mode_t = u32;\n#[stable(feature = \"raw_ext\", since = \"1.1.0\")]\npub type nlink_t = u64;\n#[stable(feature = \"raw_ext\", since = \"1.1.0\")]\npub type off_t = u64;\n#[stable(feature = \"raw_ext\", since = \"1.1.0\")]\npub type time_t = i64;\n\n#[stable(feature = \"pthread_t\", since = \"1.8.0\")]\npub type pthread_t = usize;\n\n#[repr(C)]\n#[derive(Clone)]\n#[stable(feature = \"raw_ext\", since = \"1.1.0\")]\npub struct stat {\n    #[stable(feature = \"raw_ext\", since = \"1.1.0\")]\n    pub st_dev: u64,\n    #[stable(feature = \"raw_ext\", since = \"1.1.0\")]\n    pub st_mode: u32,\n    #[stable(feature = \"raw_ext\", since = \"1.1.0\")]\n    pub st_ino: u64,\n    #[stable(feature = \"raw_ext\", since = \"1.1.0\")]\n    pub st_nlink: u32,\n    #[stable(feature = \"raw_ext\", since = \"1.1.0\")]\n    pub st_uid: uid_t,\n    #[stable(feature = \"raw_ext\", since = \"1.1.0\")]\n    pub st_gid: gid_t,\n    #[stable(feature = \"raw_ext\", since = \"1.1.0\")]\n    pub st_rdev: u64,\n    #[stable(feature = \"raw_ext\", since = \"1.1.0\")]\n    pub st_atime: i64,\n    #[stable(feature = \"raw_ext\", since = \"1.1.0\")]\n    pub st_atime_nsec: c_long,\n    #[stable(feature = \"raw_ext\", since = \"1.1.0\")]\n    pub st_mtime: i64,\n    #[stable(feature = \"raw_ext\", since = \"1.1.0\")]\n    pub st_mtime_nsec: c_long,\n    #[stable(feature = \"raw_ext\", since = \"1.1.0\")]\n    pub st_ctime: i64,\n    #[stable(feature = \"raw_ext\", since = \"1.1.0\")]\n    pub st_ctime_nsec: c_long,\n    #[stable(feature = \"raw_ext\", since = \"1.1.0\")]\n    pub st_birthtime: i64,\n    #[stable(feature = \"raw_ext\", since = \"1.1.0\")]\n    pub st_birthtime_nsec: c_long,\n    #[stable(feature = \"raw_ext\", since = \"1.1.0\")]\n    pub st_size: i64,\n    #[stable(feature = \"raw_ext\", since = \"1.1.0\")]\n    pub st_blocks: i64,\n    #[stable(feature = \"raw_ext\", since = \"1.1.0\")]\n    pub st_blksize: i32,\n    #[stable(feature = \"raw_ext\", since = \"1.1.0\")]\n    pub st_flags: u32,\n    #[stable(feature = \"raw_ext\", since = \"1.1.0\")]\n    pub st_gen: u32,\n    st_spare: [u32; 2],\n}\n"],[2161,"#![stable(feature = \"metadata_ext\", since = \"1.1.0\")]\n\nuse crate::fs::Metadata;\nuse crate::sys_common::AsInner;\n\n#[allow(deprecated)]\nuse crate::os::netbsd::raw;\n\n/// OS-specific extensions to [`fs::Metadata`].\n///\n/// [`fs::Metadata`]: crate::fs::Metadata\n#[stable(feature = \"metadata_ext\", since = \"1.1.0\")]\npub trait MetadataExt {\n    /// Gain a reference to the underlying `stat` structure which contains\n    /// the raw information returned by the OS.\n    ///\n    /// The contents of the returned `stat` are **not** consistent across\n    /// Unix platforms. The `os::unix::fs::MetadataExt` trait contains the\n    /// cross-Unix abstractions contained within the raw stat.\n    #[stable(feature = \"metadata_ext\", since = \"1.1.0\")]\n    #[rustc_deprecated(\n        since = \"1.8.0\",\n        reason = \"deprecated in favor of the accessor \\\n                  methods of this trait\"\n    )]\n    #[allow(deprecated)]\n    fn as_raw_stat(&self) -> &raw::stat;\n\n    #[stable(feature = \"metadata_ext2\", since = \"1.8.0\")]\n    fn st_dev(&self) -> u64;\n    #[stable(feature = \"metadata_ext2\", since = \"1.8.0\")]\n    fn st_ino(&self) -> u64;\n    #[stable(feature = \"metadata_ext2\", since = \"1.8.0\")]\n    fn st_mode(&self) -> u32;\n    #[stable(feature = \"metadata_ext2\", since = \"1.8.0\")]\n    fn st_nlink(&self) -> u64;\n    #[stable(feature = \"metadata_ext2\", since = \"1.8.0\")]\n    fn st_uid(&self) -> u32;\n    #[stable(feature = \"metadata_ext2\", since = \"1.8.0\")]\n    fn st_gid(&self) -> u32;\n    #[stable(feature = \"metadata_ext2\", since = \"1.8.0\")]\n    fn st_rdev(&self) -> u64;\n    #[stable(feature = \"metadata_ext2\", since = \"1.8.0\")]\n    fn st_size(&self) -> u64;\n    #[stable(feature = \"metadata_ext2\", since = \"1.8.0\")]\n    fn st_atime(&self) -> i64;\n    #[stable(feature = \"metadata_ext2\", since = \"1.8.0\")]\n    fn st_atime_nsec(&self) -> i64;\n    #[stable(feature = \"metadata_ext2\", since = \"1.8.0\")]\n    fn st_mtime(&self) -> i64;\n    #[stable(feature = \"metadata_ext2\", since = \"1.8.0\")]\n    fn st_mtime_nsec(&self) -> i64;\n    #[stable(feature = \"metadata_ext2\", since = \"1.8.0\")]\n    fn st_ctime(&self) -> i64;\n    #[stable(feature = \"metadata_ext2\", since = \"1.8.0\")]\n    fn st_ctime_nsec(&self) -> i64;\n    #[stable(feature = \"metadata_ext2\", since = \"1.8.0\")]\n    fn st_birthtime(&self) -> i64;\n    #[stable(feature = \"metadata_ext2\", since = \"1.8.0\")]\n    fn st_birthtime_nsec(&self) -> i64;\n    #[stable(feature = \"metadata_ext2\", since = \"1.8.0\")]\n    fn st_blksize(&self) -> u64;\n    #[stable(feature = \"metadata_ext2\", since = \"1.8.0\")]\n    fn st_blocks(&self) -> u64;\n    #[stable(feature = \"metadata_ext2\", since = \"1.8.0\")]\n    fn st_flags(&self) -> u32;\n    #[stable(feature = \"metadata_ext2\", since = \"1.8.0\")]\n    fn st_gen(&self) -> u32;\n}\n\n#[stable(feature = \"metadata_ext\", since = \"1.1.0\")]\nimpl MetadataExt for Metadata {\n    #[allow(deprecated)]\n    fn as_raw_stat(&self) -> &raw::stat {\n        unsafe { &*(self.as_inner().as_inner() as *const libc::stat as *const raw::stat) }\n    }\n    fn st_dev(&self) -> u64 {\n        self.as_inner().as_inner().st_dev as u64\n    }\n    fn st_ino(&self) -> u64 {\n        self.as_inner().as_inner().st_ino as u64\n    }\n    fn st_mode(&self) -> u32 {\n        self.as_inner().as_inner().st_mode as u32\n    }\n    fn st_nlink(&self) -> u64 {\n        self.as_inner().as_inner().st_nlink as u64\n    }\n    fn st_uid(&self) -> u32 {\n        self.as_inner().as_inner().st_uid as u32\n    }\n    fn st_gid(&self) -> u32 {\n        self.as_inner().as_inner().st_gid as u32\n    }\n    fn st_rdev(&self) -> u64 {\n        self.as_inner().as_inner().st_rdev as u64\n    }\n    fn st_size(&self) -> u64 {\n        self.as_inner().as_inner().st_size as u64\n    }\n    fn st_atime(&self) -> i64 {\n        self.as_inner().as_inner().st_atime as i64\n    }\n    fn st_atime_nsec(&self) -> i64 {\n        self.as_inner().as_inner().st_atimensec as i64\n    }\n    fn st_mtime(&self) -> i64 {\n        self.as_inner().as_inner().st_mtime as i64\n    }\n    fn st_mtime_nsec(&self) -> i64 {\n        self.as_inner().as_inner().st_mtimensec as i64\n    }\n    fn st_ctime(&self) -> i64 {\n        self.as_inner().as_inner().st_ctime as i64\n    }\n    fn st_ctime_nsec(&self) -> i64 {\n        self.as_inner().as_inner().st_ctimensec as i64\n    }\n    fn st_birthtime(&self) -> i64 {\n        self.as_inner().as_inner().st_birthtime as i64\n    }\n    fn st_birthtime_nsec(&self) -> i64 {\n        self.as_inner().as_inner().st_birthtimensec as i64\n    }\n    fn st_blksize(&self) -> u64 {\n        self.as_inner().as_inner().st_blksize as u64\n    }\n    fn st_blocks(&self) -> u64 {\n        self.as_inner().as_inner().st_blocks as u64\n    }\n    fn st_gen(&self) -> u32 {\n        self.as_inner().as_inner().st_gen as u32\n    }\n    fn st_flags(&self) -> u32 {\n        self.as_inner().as_inner().st_flags as u32\n    }\n}\n"],[2162,"//! OpenBSD-specific definitions\n\n#![stable(feature = \"raw_ext\", since = \"1.1.0\")]\n\npub mod fs;\npub mod raw;\n"],[2163,"//! SGX-specific access to architectural features.\n//!\n//! The functionality in this module is further documented in the Intel\n//! Software Developer's Manual, Volume 3, Chapter 40.\n#![unstable(feature = \"sgx_platform\", issue = \"56975\")]\n\nuse crate::mem::MaybeUninit;\n\n/// Wrapper struct to force 16-byte alignment.\n#[repr(align(16))]\n#[unstable(feature = \"sgx_platform\", issue = \"56975\")]\npub struct Align16<T>(pub T);\n\n/// Wrapper struct to force 128-byte alignment.\n#[repr(align(128))]\n#[unstable(feature = \"sgx_platform\", issue = \"56975\")]\npub struct Align128<T>(pub T);\n\n/// Wrapper struct to force 512-byte alignment.\n#[repr(align(512))]\n#[unstable(feature = \"sgx_platform\", issue = \"56975\")]\npub struct Align512<T>(pub T);\n\nconst ENCLU_EREPORT: u32 = 0;\nconst ENCLU_EGETKEY: u32 = 1;\n\n/// Call the `EGETKEY` instruction to obtain a 128-bit secret key.\n#[unstable(feature = \"sgx_platform\", issue = \"56975\")]\npub fn egetkey(request: &Align512<[u8; 512]>) -> Result<Align16<[u8; 16]>, u32> {\n    unsafe {\n        let mut out = MaybeUninit::uninit();\n        let error;\n\n        asm!(\n            // rbx is reserved by LLVM\n            \"xchg %rbx, {0}\",\n            \"enclu\",\n            \"mov {0}, %rbx\",\n            inout(reg) request => _,\n            inlateout(\"eax\") ENCLU_EGETKEY => error,\n            in(\"rcx\") out.as_mut_ptr(),\n            options(att_syntax, nostack),\n        );\n\n        match error {\n            0 => Ok(out.assume_init()),\n            err => Err(err),\n        }\n    }\n}\n\n/// Call the `EREPORT` instruction.\n///\n/// This creates a cryptographic report describing the contents of the current\n/// enclave. The report may be verified by the enclave described in\n/// `targetinfo`.\n#[unstable(feature = \"sgx_platform\", issue = \"56975\")]\npub fn ereport(\n    targetinfo: &Align512<[u8; 512]>,\n    reportdata: &Align128<[u8; 64]>,\n) -> Align512<[u8; 432]> {\n    unsafe {\n        let mut report = MaybeUninit::uninit();\n\n        asm!(\n            // rbx is reserved by LLVM\n            \"xchg %rbx, {0}\",\n            \"enclu\",\n            \"mov {0}, %rbx\",\n            inout(reg) targetinfo => _,\n            in(\"eax\") ENCLU_EREPORT,\n            in(\"rcx\") reportdata,\n            in(\"rdx\") report.as_mut_ptr(),\n            options(att_syntax, preserves_flags, nostack),\n        );\n\n        report.assume_init()\n    }\n}\n"],[2164,"//! Functionality specific to the `x86_64-fortanix-unknown-sgx` target.\n//!\n//! This includes functions to deal with memory isolation, usercalls, and the\n//! SGX instruction set.\n\n#![deny(missing_docs)]\n#![unstable(feature = \"sgx_platform\", issue = \"56975\")]\n\n/// Low-level interfaces to usercalls. See the [ABI documentation] for more\n/// information.\n///\n/// [ABI documentation]: https://docs.rs/fortanix-sgx-abi/\npub mod usercalls {\n    pub use crate::sys::abi::usercalls::*;\n\n    /// Primitives for allocating memory in userspace as well as copying data\n    /// to and from user memory.\n    pub mod alloc {\n        pub use crate::sys::abi::usercalls::alloc::*;\n    }\n\n    /// Lowest-level interfaces to usercalls and usercall ABI type definitions.\n    pub mod raw {\n        pub use crate::sys::abi::usercalls::raw::{\n            accept_stream, alloc, async_queues, bind_stream, close, connect_stream, exit, flush,\n            free, insecure_time, launch_thread, read, read_alloc, send, wait, write,\n        };\n        pub use crate::sys::abi::usercalls::raw::{do_usercall, Usercalls as UsercallNrs};\n\n        // fortanix-sgx-abi re-exports\n        pub use crate::sys::abi::usercalls::raw::Error;\n        pub use crate::sys::abi::usercalls::raw::{ByteBuffer, FifoDescriptor, Return, Usercall};\n        pub use crate::sys::abi::usercalls::raw::{Fd, Result, Tcs};\n        pub use crate::sys::abi::usercalls::raw::{\n            EV_RETURNQ_NOT_EMPTY, EV_UNPARK, EV_USERCALLQ_NOT_FULL, FD_STDERR, FD_STDIN, FD_STDOUT,\n            RESULT_SUCCESS, USERCALL_USER_DEFINED, WAIT_INDEFINITE, WAIT_NO,\n        };\n    }\n}\n\n/// Functions for querying mapping information for pointers.\npub mod mem {\n    pub use crate::sys::abi::mem::*;\n}\n\npub mod arch;\npub mod ffi;\npub mod io;\n\n/// Functions for querying thread-related information.\npub mod thread {\n    pub use crate::sys::abi::thread::current;\n}\n"],[2165,"//! SGX-specific extension to the primitives in the `std::ffi` module\n//!\n//! # Examples\n//!\n//! ```\n//! use std::ffi::OsString;\n//! use std::os::fortanix_sgx::ffi::OsStringExt;\n//!\n//! let bytes = b\"foo\".to_vec();\n//!\n//! // OsStringExt::from_vec\n//! let os_string = OsString::from_vec(bytes);\n//! assert_eq!(os_string.to_str(), Some(\"foo\"));\n//!\n//! // OsStringExt::into_vec\n//! let bytes = os_string.into_vec();\n//! assert_eq!(bytes, b\"foo\");\n//! ```\n//!\n//! ```\n//! use std::ffi::OsStr;\n//! use std::os::fortanix_sgx::ffi::OsStrExt;\n//!\n//! let bytes = b\"foo\";\n//!\n//! // OsStrExt::from_bytes\n//! let os_str = OsStr::from_bytes(bytes);\n//! assert_eq!(os_str.to_str(), Some(\"foo\"));\n//!\n//! // OsStrExt::as_bytes\n//! let bytes = os_str.as_bytes();\n//! assert_eq!(bytes, b\"foo\");\n//! ```\n\n#![unstable(feature = \"sgx_platform\", issue = \"56975\")]\n\n#[path = \"../unix/ffi/os_str.rs\"]\nmod os_str;\n\n#[unstable(feature = \"sgx_platform\", issue = \"56975\")]\npub use self::os_str::{OsStrExt, OsStringExt};\n"],[2166,"//! SGX-specific extensions to general I/O primitives\n//!\n//! SGX file descriptors behave differently from Unix file descriptors. See the\n//! description of [`TryIntoRawFd`] for more details.\n#![unstable(feature = \"sgx_platform\", issue = \"56975\")]\n\nuse crate::net;\npub use crate::sys::abi::usercalls::raw::Fd as RawFd;\nuse crate::sys::{self, AsInner, FromInner, IntoInner, TryIntoInner};\n\n/// A trait to extract the raw SGX file descriptor from an underlying\n/// object.\n#[unstable(feature = \"sgx_platform\", issue = \"56975\")]\npub trait AsRawFd {\n    /// Extracts the raw file descriptor.\n    ///\n    /// This method does **not** pass ownership of the raw file descriptor\n    /// to the caller. The descriptor is only guaranteed to be valid while\n    /// the original object has not yet been destroyed.\n    #[unstable(feature = \"sgx_platform\", issue = \"56975\")]\n    fn as_raw_fd(&self) -> RawFd;\n}\n\n/// A trait to express the ability to construct an object from a raw file\n/// descriptor.\n#[unstable(feature = \"sgx_platform\", issue = \"56975\")]\npub trait FromRawFd {\n    /// An associated type that contains relevant metadata for `Self`.\n    type Metadata: Default;\n\n    /// Constructs a new instance of `Self` from the given raw file\n    /// descriptor and metadata.\n    ///\n    /// This function **consumes ownership** of the specified file\n    /// descriptor. The returned object will take responsibility for closing\n    /// it when the object goes out of scope.\n    ///\n    /// This function is also unsafe as the primitives currently returned\n    /// have the contract that they are the sole owner of the file\n    /// descriptor they are wrapping. Usage of this function could\n    /// accidentally allow violating this contract which can cause memory\n    /// unsafety in code that relies on it being true.\n    #[unstable(feature = \"sgx_platform\", issue = \"56975\")]\n    unsafe fn from_raw_fd(fd: RawFd, metadata: Self::Metadata) -> Self;\n}\n\n/// A trait to express the ability to consume an object and acquire ownership of\n/// its raw file descriptor.\n#[unstable(feature = \"sgx_platform\", issue = \"56975\")]\npub trait TryIntoRawFd: Sized {\n    /// Consumes this object, returning the raw underlying file descriptor, if\n    /// this object is not cloned.\n    ///\n    /// This function **transfers ownership** of the underlying file descriptor\n    /// to the caller. Callers are then the unique owners of the file descriptor\n    /// and must close the descriptor once it's no longer needed.\n    ///\n    /// Unlike other platforms, on SGX, the file descriptor is shared between\n    /// all clones of an object. To avoid race conditions, this function will\n    /// only return `Ok` when called on the final clone.\n    #[unstable(feature = \"sgx_platform\", issue = \"56975\")]\n    fn try_into_raw_fd(self) -> Result<RawFd, Self>;\n}\n\nimpl AsRawFd for net::TcpStream {\n    #[inline]\n    fn as_raw_fd(&self) -> RawFd {\n        *self.as_inner().as_inner().as_inner().as_inner()\n    }\n}\n\nimpl AsRawFd for net::TcpListener {\n    #[inline]\n    fn as_raw_fd(&self) -> RawFd {\n        *self.as_inner().as_inner().as_inner().as_inner()\n    }\n}\n\n/// Metadata for `TcpStream`.\n#[derive(Debug, Clone, Default)]\n#[unstable(feature = \"sgx_platform\", issue = \"56975\")]\npub struct TcpStreamMetadata {\n    /// Local address of the TCP stream\n    pub local_addr: Option<String>,\n    /// Peer address of the TCP stream\n    pub peer_addr: Option<String>,\n}\n\nimpl FromRawFd for net::TcpStream {\n    type Metadata = TcpStreamMetadata;\n\n    #[inline]\n    unsafe fn from_raw_fd(fd: RawFd, metadata: Self::Metadata) -> net::TcpStream {\n        let fd = sys::fd::FileDesc::from_inner(fd);\n        let socket = sys::net::Socket::from_inner((fd, metadata.local_addr));\n        net::TcpStream::from_inner(sys::net::TcpStream::from_inner((socket, metadata.peer_addr)))\n    }\n}\n\n/// Metadata for `TcpListener`.\n#[derive(Debug, Clone, Default)]\n#[unstable(feature = \"sgx_platform\", issue = \"56975\")]\npub struct TcpListenerMetadata {\n    /// Local address of the TCP listener\n    pub local_addr: Option<String>,\n}\n\nimpl FromRawFd for net::TcpListener {\n    type Metadata = TcpListenerMetadata;\n\n    #[inline]\n    unsafe fn from_raw_fd(fd: RawFd, metadata: Self::Metadata) -> net::TcpListener {\n        let fd = sys::fd::FileDesc::from_inner(fd);\n        let socket = sys::net::Socket::from_inner((fd, metadata.local_addr));\n        net::TcpListener::from_inner(sys::net::TcpListener::from_inner(socket))\n    }\n}\n\nimpl TryIntoRawFd for net::TcpStream {\n    #[inline]\n    fn try_into_raw_fd(self) -> Result<RawFd, Self> {\n        let (socket, peer_addr) = self.into_inner().into_inner();\n        match socket.try_into_inner() {\n            Ok(fd) => Ok(fd.into_inner()),\n            Err(socket) => {\n                let sys = sys::net::TcpStream::from_inner((socket, peer_addr));\n                Err(net::TcpStream::from_inner(sys))\n            }\n        }\n    }\n}\n\nimpl TryIntoRawFd for net::TcpListener {\n    #[inline]\n    fn try_into_raw_fd(self) -> Result<RawFd, Self> {\n        match self.into_inner().into_inner().try_into_inner() {\n            Ok(fd) => Ok(fd.into_inner()),\n            Err(socket) => {\n                let sys = sys::net::TcpListener::from_inner(socket);\n                Err(net::TcpListener::from_inner(sys))\n            }\n        }\n    }\n}\n"],[2167,"#![stable(feature = \"metadata_ext\", since = \"1.1.0\")]\n\nuse crate::fs::Metadata;\nuse crate::sys_common::AsInner;\n\n#[allow(deprecated)]\nuse crate::os::emscripten::raw;\n\n/// OS-specific extensions to [`fs::Metadata`].\n///\n/// [`fs::Metadata`]: crate::fs::Metadata\n#[stable(feature = \"metadata_ext\", since = \"1.1.0\")]\npub trait MetadataExt {\n    /// Gain a reference to the underlying `stat` structure which contains\n    /// the raw information returned by the OS.\n    ///\n    /// The contents of the returned `stat` are **not** consistent across\n    /// Unix platforms. The `os::unix::fs::MetadataExt` trait contains the\n    /// cross-Unix abstractions contained within the raw stat.\n    #[stable(feature = \"metadata_ext\", since = \"1.1.0\")]\n    #[rustc_deprecated(\n        since = \"1.8.0\",\n        reason = \"deprecated in favor of the accessor \\\n                  methods of this trait\"\n    )]\n    #[allow(deprecated)]\n    fn as_raw_stat(&self) -> &raw::stat;\n\n    #[stable(feature = \"metadata_ext2\", since = \"1.8.0\")]\n    fn st_dev(&self) -> u64;\n    #[stable(feature = \"metadata_ext2\", since = \"1.8.0\")]\n    fn st_ino(&self) -> u64;\n    #[stable(feature = \"metadata_ext2\", since = \"1.8.0\")]\n    fn st_mode(&self) -> u32;\n    #[stable(feature = \"metadata_ext2\", since = \"1.8.0\")]\n    fn st_nlink(&self) -> u64;\n    #[stable(feature = \"metadata_ext2\", since = \"1.8.0\")]\n    fn st_uid(&self) -> u32;\n    #[stable(feature = \"metadata_ext2\", since = \"1.8.0\")]\n    fn st_gid(&self) -> u32;\n    #[stable(feature = \"metadata_ext2\", since = \"1.8.0\")]\n    fn st_rdev(&self) -> u64;\n    #[stable(feature = \"metadata_ext2\", since = \"1.8.0\")]\n    fn st_size(&self) -> u64;\n    #[stable(feature = \"metadata_ext2\", since = \"1.8.0\")]\n    fn st_atime(&self) -> i64;\n    #[stable(feature = \"metadata_ext2\", since = \"1.8.0\")]\n    fn st_atime_nsec(&self) -> i64;\n    #[stable(feature = \"metadata_ext2\", since = \"1.8.0\")]\n    fn st_mtime(&self) -> i64;\n    #[stable(feature = \"metadata_ext2\", since = \"1.8.0\")]\n    fn st_mtime_nsec(&self) -> i64;\n    #[stable(feature = \"metadata_ext2\", since = \"1.8.0\")]\n    fn st_ctime(&self) -> i64;\n    #[stable(feature = \"metadata_ext2\", since = \"1.8.0\")]\n    fn st_ctime_nsec(&self) -> i64;\n    #[stable(feature = \"metadata_ext2\", since = \"1.8.0\")]\n    fn st_blksize(&self) -> u64;\n    #[stable(feature = \"metadata_ext2\", since = \"1.8.0\")]\n    fn st_blocks(&self) -> u64;\n}\n\n#[stable(feature = \"metadata_ext\", since = \"1.1.0\")]\nimpl MetadataExt for Metadata {\n    #[allow(deprecated)]\n    fn as_raw_stat(&self) -> &raw::stat {\n        unsafe { &*(self.as_inner().as_inner() as *const libc::stat64 as *const raw::stat) }\n    }\n    fn st_dev(&self) -> u64 {\n        self.as_inner().as_inner().st_dev as u64\n    }\n    fn st_ino(&self) -> u64 {\n        self.as_inner().as_inner().st_ino as u64\n    }\n    fn st_mode(&self) -> u32 {\n        self.as_inner().as_inner().st_mode as u32\n    }\n    fn st_nlink(&self) -> u64 {\n        self.as_inner().as_inner().st_nlink as u64\n    }\n    fn st_uid(&self) -> u32 {\n        self.as_inner().as_inner().st_uid as u32\n    }\n    fn st_gid(&self) -> u32 {\n        self.as_inner().as_inner().st_gid as u32\n    }\n    fn st_rdev(&self) -> u64 {\n        self.as_inner().as_inner().st_rdev as u64\n    }\n    fn st_size(&self) -> u64 {\n        self.as_inner().as_inner().st_size as u64\n    }\n    fn st_atime(&self) -> i64 {\n        self.as_inner().as_inner().st_atime as i64\n    }\n    fn st_atime_nsec(&self) -> i64 {\n        self.as_inner().as_inner().st_atime_nsec as i64\n    }\n    fn st_mtime(&self) -> i64 {\n        self.as_inner().as_inner().st_mtime as i64\n    }\n    fn st_mtime_nsec(&self) -> i64 {\n        self.as_inner().as_inner().st_mtime_nsec as i64\n    }\n    fn st_ctime(&self) -> i64 {\n        self.as_inner().as_inner().st_ctime as i64\n    }\n    fn st_ctime_nsec(&self) -> i64 {\n        self.as_inner().as_inner().st_ctime_nsec as i64\n    }\n    fn st_blksize(&self) -> u64 {\n        self.as_inner().as_inner().st_blksize as u64\n    }\n    fn st_blocks(&self) -> u64 {\n        self.as_inner().as_inner().st_blocks as u64\n    }\n}\n"],[2168,"//! Linux-specific definitions\n\n#![stable(feature = \"raw_ext\", since = \"1.1.0\")]\n\npub mod fs;\npub mod raw;\n"],[2169,"//! Emscripten-specific raw type definitions\n//! This is basically exactly the same as the linux definitions,\n//! except using the musl-specific stat64 structure in liblibc.\n\n#![stable(feature = \"raw_ext\", since = \"1.1.0\")]\n#![rustc_deprecated(\n    since = \"1.8.0\",\n    reason = \"these type aliases are no longer supported by \\\n              the standard library, the `libc` crate on \\\n              crates.io should be used instead for the correct \\\n              definitions\"\n)]\n#![allow(deprecated)]\n\nuse crate::os::raw::{c_long, c_short, c_uint, c_ulong};\n\n#[stable(feature = \"raw_ext\", since = \"1.1.0\")]\npub type dev_t = u64;\n#[stable(feature = \"raw_ext\", since = \"1.1.0\")]\npub type mode_t = u32;\n\n#[stable(feature = \"pthread_t\", since = \"1.8.0\")]\npub type pthread_t = c_ulong;\n\n#[stable(feature = \"raw_ext\", since = \"1.1.0\")]\npub type blkcnt_t = u64;\n#[stable(feature = \"raw_ext\", since = \"1.1.0\")]\npub type blksize_t = u64;\n#[stable(feature = \"raw_ext\", since = \"1.1.0\")]\npub type ino_t = u64;\n#[stable(feature = \"raw_ext\", since = \"1.1.0\")]\npub type nlink_t = u64;\n#[stable(feature = \"raw_ext\", since = \"1.1.0\")]\npub type off_t = u64;\n#[stable(feature = \"raw_ext\", since = \"1.1.0\")]\npub type time_t = c_long;\n\n#[repr(C)]\n#[derive(Clone)]\n#[stable(feature = \"raw_ext\", since = \"1.1.0\")]\npub struct stat {\n    #[stable(feature = \"raw_ext\", since = \"1.1.0\")]\n    pub st_dev: u64,\n    #[stable(feature = \"raw_ext\", since = \"1.1.0\")]\n    pub __pad1: c_short,\n    #[stable(feature = \"raw_ext\", since = \"1.1.0\")]\n    pub __st_ino: u32,\n    #[stable(feature = \"raw_ext\", since = \"1.1.0\")]\n    pub st_mode: u32,\n    #[stable(feature = \"raw_ext\", since = \"1.1.0\")]\n    pub st_nlink: u32,\n    #[stable(feature = \"raw_ext\", since = \"1.1.0\")]\n    pub st_uid: u32,\n    #[stable(feature = \"raw_ext\", since = \"1.1.0\")]\n    pub st_gid: u32,\n    #[stable(feature = \"raw_ext\", since = \"1.1.0\")]\n    pub st_rdev: u64,\n    #[stable(feature = \"raw_ext\", since = \"1.1.0\")]\n    pub __pad2: c_uint,\n    #[stable(feature = \"raw_ext\", since = \"1.1.0\")]\n    pub st_size: i64,\n    #[stable(feature = \"raw_ext\", since = \"1.1.0\")]\n    pub st_blksize: i32,\n    #[stable(feature = \"raw_ext\", since = \"1.1.0\")]\n    pub st_blocks: i64,\n    #[stable(feature = \"raw_ext\", since = \"1.1.0\")]\n    pub st_atime: time_t,\n    #[stable(feature = \"raw_ext\", since = \"1.1.0\")]\n    pub st_atime_nsec: c_long,\n    #[stable(feature = \"raw_ext\", since = \"1.1.0\")]\n    pub st_mtime: time_t,\n    #[stable(feature = \"raw_ext\", since = \"1.1.0\")]\n    pub st_mtime_nsec: c_long,\n    #[stable(feature = \"raw_ext\", since = \"1.1.0\")]\n    pub st_ctime: time_t,\n    #[stable(feature = \"raw_ext\", since = \"1.1.0\")]\n    pub st_ctime_nsec: c_long,\n    #[stable(feature = \"raw_ext\", since = \"1.1.0\")]\n    pub st_ino: u64,\n}\n"],[2170,"//! Linux-specific raw type definitions.\n\n#![stable(feature = \"raw_ext\", since = \"1.1.0\")]\n#![rustc_deprecated(\n    since = \"1.8.0\",\n    reason = \"these type aliases are no longer supported by \\\n              the standard library, the `libc` crate on \\\n              crates.io should be used instead for the correct \\\n              definitions\"\n)]\n#![allow(deprecated)]\n\nuse crate::os::raw::c_ulong;\n\n#[stable(feature = \"raw_ext\", since = \"1.1.0\")]\npub type dev_t = u64;\n#[stable(feature = \"raw_ext\", since = \"1.1.0\")]\npub type mode_t = u32;\n\n#[stable(feature = \"pthread_t\", since = \"1.8.0\")]\npub type pthread_t = c_ulong;\n\n#[doc(inline)]\n#[stable(feature = \"raw_ext\", since = \"1.1.0\")]\npub use self::arch::{blkcnt_t, blksize_t, ino_t, nlink_t, off_t, stat, time_t};\n\n#[cfg(any(\n    target_arch = \"x86\",\n    target_arch = \"le32\",\n    target_arch = \"powerpc\",\n    target_arch = \"sparc\",\n    target_arch = \"arm\",\n    target_arch = \"asmjs\",\n    target_arch = \"wasm32\"\n))]\nmod arch {\n    use crate::os::raw::{c_long, c_short, c_uint};\n\n    #[stable(feature = \"raw_ext\", since = \"1.1.0\")]\n    pub type blkcnt_t = u64;\n    #[stable(feature = \"raw_ext\", since = \"1.1.0\")]\n    pub type blksize_t = u64;\n    #[stable(feature = \"raw_ext\", since = \"1.1.0\")]\n    pub type ino_t = u64;\n    #[stable(feature = \"raw_ext\", since = \"1.1.0\")]\n    pub type nlink_t = u64;\n    #[stable(feature = \"raw_ext\", since = \"1.1.0\")]\n    pub type off_t = u64;\n    #[stable(feature = \"raw_ext\", since = \"1.1.0\")]\n    pub type time_t = i64;\n\n    #[repr(C)]\n    #[derive(Clone)]\n    #[stable(feature = \"raw_ext\", since = \"1.1.0\")]\n    pub struct stat {\n        #[stable(feature = \"raw_ext\", since = \"1.1.0\")]\n        pub st_dev: u64,\n        #[stable(feature = \"raw_ext\", since = \"1.1.0\")]\n        pub __pad1: c_short,\n        #[stable(feature = \"raw_ext\", since = \"1.1.0\")]\n        pub __st_ino: u32,\n        #[stable(feature = \"raw_ext\", since = \"1.1.0\")]\n        pub st_mode: u32,\n        #[stable(feature = \"raw_ext\", since = \"1.1.0\")]\n        pub st_nlink: u32,\n        #[stable(feature = \"raw_ext\", since = \"1.1.0\")]\n        pub st_uid: u32,\n        #[stable(feature = \"raw_ext\", since = \"1.1.0\")]\n        pub st_gid: u32,\n        #[stable(feature = \"raw_ext\", since = \"1.1.0\")]\n        pub st_rdev: u64,\n        #[stable(feature = \"raw_ext\", since = \"1.1.0\")]\n        pub __pad2: c_uint,\n        #[stable(feature = \"raw_ext\", since = \"1.1.0\")]\n        pub st_size: i64,\n        #[stable(feature = \"raw_ext\", since = \"1.1.0\")]\n        pub st_blksize: i32,\n        #[stable(feature = \"raw_ext\", since = \"1.1.0\")]\n        pub st_blocks: i64,\n        #[stable(feature = \"raw_ext\", since = \"1.1.0\")]\n        pub st_atime: i32,\n        #[stable(feature = \"raw_ext\", since = \"1.1.0\")]\n        pub st_atime_nsec: c_long,\n        #[stable(feature = \"raw_ext\", since = \"1.1.0\")]\n        pub st_mtime: i32,\n        #[stable(feature = \"raw_ext\", since = \"1.1.0\")]\n        pub st_mtime_nsec: c_long,\n        #[stable(feature = \"raw_ext\", since = \"1.1.0\")]\n        pub st_ctime: i32,\n        #[stable(feature = \"raw_ext\", since = \"1.1.0\")]\n        pub st_ctime_nsec: c_long,\n        #[stable(feature = \"raw_ext\", since = \"1.1.0\")]\n        pub st_ino: u64,\n    }\n}\n\n#[cfg(target_arch = \"mips\")]\nmod arch {\n    use crate::os::raw::{c_long, c_ulong};\n\n    #[cfg(target_env = \"musl\")]\n    #[stable(feature = \"raw_ext\", since = \"1.1.0\")]\n    pub type blkcnt_t = i64;\n    #[cfg(not(target_env = \"musl\"))]\n    #[stable(feature = \"raw_ext\", since = \"1.1.0\")]\n    pub type blkcnt_t = u64;\n    #[stable(feature = \"raw_ext\", since = \"1.1.0\")]\n    pub type blksize_t = u64;\n    #[cfg(target_env = \"musl\")]\n    #[stable(feature = \"raw_ext\", since = \"1.1.0\")]\n    pub type ino_t = u64;\n    #[cfg(not(target_env = \"musl\"))]\n    #[stable(feature = \"raw_ext\", since = \"1.1.0\")]\n    pub type ino_t = u64;\n    #[stable(feature = \"raw_ext\", since = \"1.1.0\")]\n    pub type nlink_t = u64;\n    #[cfg(target_env = \"musl\")]\n    #[stable(feature = \"raw_ext\", since = \"1.1.0\")]\n    pub type off_t = u64;\n    #[cfg(not(target_env = \"musl\"))]\n    #[stable(feature = \"raw_ext\", since = \"1.1.0\")]\n    pub type off_t = u64;\n    #[stable(feature = \"raw_ext\", since = \"1.1.0\")]\n    pub type time_t = i64;\n\n    #[repr(C)]\n    #[derive(Clone)]\n    #[stable(feature = \"raw_ext\", since = \"1.1.0\")]\n    pub struct stat {\n        #[stable(feature = \"raw_ext\", since = \"1.1.0\")]\n        pub st_dev: c_ulong,\n        #[stable(feature = \"raw_ext\", since = \"1.1.0\")]\n        pub st_pad1: [c_long; 3],\n        #[stable(feature = \"raw_ext\", since = \"1.1.0\")]\n        pub st_ino: u64,\n        #[stable(feature = \"raw_ext\", since = \"1.1.0\")]\n        pub st_mode: u32,\n        #[stable(feature = \"raw_ext\", since = \"1.1.0\")]\n        pub st_nlink: u32,\n        #[stable(feature = \"raw_ext\", since = \"1.1.0\")]\n        pub st_uid: u32,\n        #[stable(feature = \"raw_ext\", since = \"1.1.0\")]\n        pub st_gid: u32,\n        #[stable(feature = \"raw_ext\", since = \"1.1.0\")]\n        pub st_rdev: c_ulong,\n        #[stable(feature = \"raw_ext\", since = \"1.1.0\")]\n        pub st_pad2: [c_long; 2],\n        #[stable(feature = \"raw_ext\", since = \"1.1.0\")]\n        pub st_size: i64,\n        #[stable(feature = \"raw_ext\", since = \"1.1.0\")]\n        pub st_atime: i32,\n        #[stable(feature = \"raw_ext\", since = \"1.1.0\")]\n        pub st_atime_nsec: c_long,\n        #[stable(feature = \"raw_ext\", since = \"1.1.0\")]\n        pub st_mtime: i32,\n        #[stable(feature = \"raw_ext\", since = \"1.1.0\")]\n        pub st_mtime_nsec: c_long,\n        #[stable(feature = \"raw_ext\", since = \"1.1.0\")]\n        pub st_ctime: i32,\n        #[stable(feature = \"raw_ext\", since = \"1.1.0\")]\n        pub st_ctime_nsec: c_long,\n        #[stable(feature = \"raw_ext\", since = \"1.1.0\")]\n        pub st_blksize: i32,\n        #[stable(feature = \"raw_ext\", since = \"1.1.0\")]\n        pub st_blocks: i64,\n        #[stable(feature = \"raw_ext\", since = \"1.1.0\")]\n        pub st_pad5: [c_long; 14],\n    }\n}\n\n#[cfg(target_arch = \"hexagon\")]\nmod arch {\n    use crate::os::raw::{c_int, c_long, c_uint};\n\n    #[stable(feature = \"raw_ext\", since = \"1.1.0\")]\n    pub type blkcnt_t = i64;\n    #[stable(feature = \"raw_ext\", since = \"1.1.0\")]\n    pub type blksize_t = c_long;\n    #[stable(feature = \"raw_ext\", since = \"1.1.0\")]\n    pub type ino_t = u64;\n    #[stable(feature = \"raw_ext\", since = \"1.1.0\")]\n    pub type nlink_t = c_uint;\n    #[stable(feature = \"raw_ext\", since = \"1.1.0\")]\n    pub type off_t = i64;\n    #[stable(feature = \"raw_ext\", since = \"1.1.0\")]\n    pub type time_t = i64;\n\n    #[repr(C)]\n    #[derive(Clone)]\n    #[stable(feature = \"raw_ext\", since = \"1.1.0\")]\n    pub struct stat {\n        #[stable(feature = \"raw_ext\", since = \"1.1.0\")]\n        pub st_dev: u64,\n        #[stable(feature = \"raw_ext\", since = \"1.1.0\")]\n        pub st_ino: u64,\n        #[stable(feature = \"raw_ext\", since = \"1.1.0\")]\n        pub st_mode: u32,\n        #[stable(feature = \"raw_ext\", since = \"1.1.0\")]\n        pub st_nlink: u32,\n        #[stable(feature = \"raw_ext\", since = \"1.1.0\")]\n        pub st_uid: u32,\n        #[stable(feature = \"raw_ext\", since = \"1.1.0\")]\n        pub st_gid: u32,\n        #[stable(feature = \"raw_ext\", since = \"1.1.0\")]\n        pub st_rdev: u64,\n        #[stable(feature = \"raw_ext\", since = \"1.1.0\")]\n        pub __pad1: u32,\n        #[stable(feature = \"raw_ext\", since = \"1.1.0\")]\n        pub st_size: i64,\n        #[stable(feature = \"raw_ext\", since = \"1.1.0\")]\n        pub st_blksize: i32,\n        #[stable(feature = \"raw_ext\", since = \"1.1.0\")]\n        pub __pad2: i32,\n        #[stable(feature = \"raw_ext\", since = \"1.1.0\")]\n        pub st_blocks: i64,\n        #[stable(feature = \"raw_ext\", since = \"1.1.0\")]\n        pub st_atime: i64,\n        #[stable(feature = \"raw_ext\", since = \"1.1.0\")]\n        pub st_atime_nsec: c_long,\n        #[stable(feature = \"raw_ext\", since = \"1.1.0\")]\n        pub st_mtime: i64,\n        #[stable(feature = \"raw_ext\", since = \"1.1.0\")]\n        pub st_mtime_nsec: c_long,\n        #[stable(feature = \"raw_ext\", since = \"1.1.0\")]\n        pub st_ctime: i64,\n        #[stable(feature = \"raw_ext\", since = \"1.1.0\")]\n        pub st_ctime_nsec: c_long,\n        #[stable(feature = \"raw_ext\", since = \"1.1.0\")]\n        pub __pad3: [c_int; 2],\n    }\n}\n\n#[cfg(any(\n    target_arch = \"mips64\",\n    target_arch = \"s390x\",\n    target_arch = \"sparc64\",\n    target_arch = \"riscv64\",\n    target_arch = \"riscv32\"\n))]\nmod arch {\n    pub use libc::{blkcnt_t, blksize_t, ino_t, nlink_t, off_t, stat, time_t};\n}\n\n#[cfg(target_arch = \"aarch64\")]\nmod arch {\n    use crate::os::raw::{c_int, c_long};\n\n    #[stable(feature = \"raw_ext\", since = \"1.1.0\")]\n    pub type blkcnt_t = i64;\n    #[stable(feature = \"raw_ext\", since = \"1.1.0\")]\n    pub type blksize_t = i32;\n    #[stable(feature = \"raw_ext\", since = \"1.1.0\")]\n    pub type ino_t = u64;\n    #[stable(feature = \"raw_ext\", since = \"1.1.0\")]\n    pub type nlink_t = u32;\n    #[stable(feature = \"raw_ext\", since = \"1.1.0\")]\n    pub type off_t = i64;\n    #[stable(feature = \"raw_ext\", since = \"1.1.0\")]\n    pub type time_t = c_long;\n\n    #[repr(C)]\n    #[derive(Clone)]\n    #[stable(feature = \"raw_ext\", since = \"1.1.0\")]\n    pub struct stat {\n        #[stable(feature = \"raw_ext\", since = \"1.1.0\")]\n        pub st_dev: u64,\n        #[stable(feature = \"raw_ext\", since = \"1.1.0\")]\n        pub st_ino: u64,\n        #[stable(feature = \"raw_ext\", since = \"1.1.0\")]\n        pub st_mode: u32,\n        #[stable(feature = \"raw_ext\", since = \"1.1.0\")]\n        pub st_nlink: u32,\n        #[stable(feature = \"raw_ext\", since = \"1.1.0\")]\n        pub st_uid: u32,\n        #[stable(feature = \"raw_ext\", since = \"1.1.0\")]\n        pub st_gid: u32,\n        #[stable(feature = \"raw_ext\", since = \"1.1.0\")]\n        pub st_rdev: u64,\n        #[stable(feature = \"raw_ext\", since = \"1.1.0\")]\n        pub __pad1: u64,\n        #[stable(feature = \"raw_ext\", since = \"1.1.0\")]\n        pub st_size: i64,\n        #[stable(feature = \"raw_ext\", since = \"1.1.0\")]\n        pub st_blksize: i32,\n        #[stable(feature = \"raw_ext\", since = \"1.1.0\")]\n        pub __pad2: c_int,\n        #[stable(feature = \"raw_ext\", since = \"1.1.0\")]\n        pub st_blocks: i64,\n        #[stable(feature = \"raw_ext\", since = \"1.1.0\")]\n        pub st_atime: time_t,\n        #[stable(feature = \"raw_ext\", since = \"1.1.0\")]\n        pub st_atime_nsec: c_long,\n        #[stable(feature = \"raw_ext\", since = \"1.1.0\")]\n        pub st_mtime: time_t,\n        #[stable(feature = \"raw_ext\", since = \"1.1.0\")]\n        pub st_mtime_nsec: c_long,\n        #[stable(feature = \"raw_ext\", since = \"1.1.0\")]\n        pub st_ctime: time_t,\n        #[stable(feature = \"raw_ext\", since = \"1.1.0\")]\n        pub st_ctime_nsec: c_long,\n        #[stable(feature = \"raw_ext\", since = \"1.1.0\")]\n        pub __unused: [c_int; 2],\n    }\n}\n\n#[cfg(any(target_arch = \"x86_64\", target_arch = \"powerpc64\"))]\nmod arch {\n    use crate::os::raw::{c_int, c_long};\n\n    #[stable(feature = \"raw_ext\", since = \"1.1.0\")]\n    pub type blkcnt_t = u64;\n    #[stable(feature = \"raw_ext\", since = \"1.1.0\")]\n    pub type blksize_t = u64;\n    #[stable(feature = \"raw_ext\", since = \"1.1.0\")]\n    pub type ino_t = u64;\n    #[stable(feature = \"raw_ext\", since = \"1.1.0\")]\n    pub type nlink_t = u64;\n    #[stable(feature = \"raw_ext\", since = \"1.1.0\")]\n    pub type off_t = u64;\n    #[stable(feature = \"raw_ext\", since = \"1.1.0\")]\n    pub type time_t = i64;\n\n    #[repr(C)]\n    #[derive(Clone)]\n    #[stable(feature = \"raw_ext\", since = \"1.1.0\")]\n    pub struct stat {\n        #[stable(feature = \"raw_ext\", since = \"1.1.0\")]\n        pub st_dev: u64,\n        #[stable(feature = \"raw_ext\", since = \"1.1.0\")]\n        pub st_ino: u64,\n        #[stable(feature = \"raw_ext\", since = \"1.1.0\")]\n        pub st_nlink: u64,\n        #[stable(feature = \"raw_ext\", since = \"1.1.0\")]\n        pub st_mode: u32,\n        #[stable(feature = \"raw_ext\", since = \"1.1.0\")]\n        pub st_uid: u32,\n        #[stable(feature = \"raw_ext\", since = \"1.1.0\")]\n        pub st_gid: u32,\n        #[stable(feature = \"raw_ext\", since = \"1.1.0\")]\n        pub __pad0: c_int,\n        #[stable(feature = \"raw_ext\", since = \"1.1.0\")]\n        pub st_rdev: u64,\n        #[stable(feature = \"raw_ext\", since = \"1.1.0\")]\n        pub st_size: i64,\n        #[stable(feature = \"raw_ext\", since = \"1.1.0\")]\n        pub st_blksize: i64,\n        #[stable(feature = \"raw_ext\", since = \"1.1.0\")]\n        pub st_blocks: i64,\n        #[stable(feature = \"raw_ext\", since = \"1.1.0\")]\n        pub st_atime: i64,\n        #[stable(feature = \"raw_ext\", since = \"1.1.0\")]\n        pub st_atime_nsec: c_long,\n        #[stable(feature = \"raw_ext\", since = \"1.1.0\")]\n        pub st_mtime: i64,\n        #[stable(feature = \"raw_ext\", since = \"1.1.0\")]\n        pub st_mtime_nsec: c_long,\n        #[stable(feature = \"raw_ext\", since = \"1.1.0\")]\n        pub st_ctime: i64,\n        #[stable(feature = \"raw_ext\", since = \"1.1.0\")]\n        pub st_ctime_nsec: c_long,\n        #[stable(feature = \"raw_ext\", since = \"1.1.0\")]\n        pub __unused: [c_long; 3],\n    }\n}\n"],[2171,"//! Linux-specific extensions to primitives in the `std::fs` module.\n\n#![stable(feature = \"metadata_ext\", since = \"1.1.0\")]\n\nuse crate::fs::Metadata;\nuse crate::sys_common::AsInner;\n\n#[allow(deprecated)]\nuse crate::os::linux::raw;\n\n/// OS-specific extensions to [`fs::Metadata`].\n///\n/// [`fs::Metadata`]: crate::fs::Metadata\n#[stable(feature = \"metadata_ext\", since = \"1.1.0\")]\npub trait MetadataExt {\n    /// Gain a reference to the underlying `stat` structure which contains\n    /// the raw information returned by the OS.\n    ///\n    /// The contents of the returned [`stat`] are **not** consistent across\n    /// Unix platforms. The `os::unix::fs::MetadataExt` trait contains the\n    /// cross-Unix abstractions contained within the raw stat.\n    ///\n    /// [`stat`]: struct@crate::os::linux::raw::stat\n    ///\n    /// # Examples\n    ///\n    /// ```no_run\n    /// use std::fs;\n    /// use std::io;\n    /// use std::os::linux::fs::MetadataExt;\n    ///\n    /// fn main() -> io::Result<()> {\n    ///     let meta = fs::metadata(\"some_file\")?;\n    ///     let stat = meta.as_raw_stat();\n    ///     Ok(())\n    /// }\n    /// ```\n    #[stable(feature = \"metadata_ext\", since = \"1.1.0\")]\n    #[rustc_deprecated(since = \"1.8.0\", reason = \"other methods of this trait are now preferred\")]\n    #[allow(deprecated)]\n    fn as_raw_stat(&self) -> &raw::stat;\n\n    /// Returns the device ID on which this file resides.\n    ///\n    /// # Examples\n    ///\n    /// ```no_run\n    /// use std::fs;\n    /// use std::io;\n    /// use std::os::linux::fs::MetadataExt;\n    ///\n    /// fn main() -> io::Result<()> {\n    ///     let meta = fs::metadata(\"some_file\")?;\n    ///     println!(\"{}\", meta.st_dev());\n    ///     Ok(())\n    /// }\n    /// ```\n    #[stable(feature = \"metadata_ext2\", since = \"1.8.0\")]\n    fn st_dev(&self) -> u64;\n    /// Returns the inode number.\n    ///\n    /// # Examples\n    ///\n    /// ```no_run\n    /// use std::fs;\n    /// use std::io;\n    /// use std::os::linux::fs::MetadataExt;\n    ///\n    /// fn main() -> io::Result<()> {\n    ///     let meta = fs::metadata(\"some_file\")?;\n    ///     println!(\"{}\", meta.st_ino());\n    ///     Ok(())\n    /// }\n    /// ```\n    #[stable(feature = \"metadata_ext2\", since = \"1.8.0\")]\n    fn st_ino(&self) -> u64;\n    /// Returns the file type and mode.\n    ///\n    /// # Examples\n    ///\n    /// ```no_run\n    /// use std::fs;\n    /// use std::io;\n    /// use std::os::linux::fs::MetadataExt;\n    ///\n    /// fn main() -> io::Result<()> {\n    ///     let meta = fs::metadata(\"some_file\")?;\n    ///     println!(\"{}\", meta.st_mode());\n    ///     Ok(())\n    /// }\n    /// ```\n    #[stable(feature = \"metadata_ext2\", since = \"1.8.0\")]\n    fn st_mode(&self) -> u32;\n    /// Returns the number of hard links to file.\n    ///\n    /// # Examples\n    ///\n    /// ```no_run\n    /// use std::fs;\n    /// use std::io;\n    /// use std::os::linux::fs::MetadataExt;\n    ///\n    /// fn main() -> io::Result<()> {\n    ///     let meta = fs::metadata(\"some_file\")?;\n    ///     println!(\"{}\", meta.st_nlink());\n    ///     Ok(())\n    /// }\n    /// ```\n    #[stable(feature = \"metadata_ext2\", since = \"1.8.0\")]\n    fn st_nlink(&self) -> u64;\n    /// Returns the user ID of the file owner.\n    ///\n    /// # Examples\n    ///\n    /// ```no_run\n    /// use std::fs;\n    /// use std::io;\n    /// use std::os::linux::fs::MetadataExt;\n    ///\n    /// fn main() -> io::Result<()> {\n    ///     let meta = fs::metadata(\"some_file\")?;\n    ///     println!(\"{}\", meta.st_uid());\n    ///     Ok(())\n    /// }\n    /// ```\n    #[stable(feature = \"metadata_ext2\", since = \"1.8.0\")]\n    fn st_uid(&self) -> u32;\n    /// Returns the group ID of the file owner.\n    ///\n    /// # Examples\n    ///\n    /// ```no_run\n    /// use std::fs;\n    /// use std::io;\n    /// use std::os::linux::fs::MetadataExt;\n    ///\n    /// fn main() -> io::Result<()> {\n    ///     let meta = fs::metadata(\"some_file\")?;\n    ///     println!(\"{}\", meta.st_gid());\n    ///     Ok(())\n    /// }\n    /// ```\n    #[stable(feature = \"metadata_ext2\", since = \"1.8.0\")]\n    fn st_gid(&self) -> u32;\n    /// Returns the device ID that this file represents. Only relevant for special file.\n    ///\n    /// # Examples\n    ///\n    /// ```no_run\n    /// use std::fs;\n    /// use std::io;\n    /// use std::os::linux::fs::MetadataExt;\n    ///\n    /// fn main() -> io::Result<()> {\n    ///     let meta = fs::metadata(\"some_file\")?;\n    ///     println!(\"{}\", meta.st_rdev());\n    ///     Ok(())\n    /// }\n    /// ```\n    #[stable(feature = \"metadata_ext2\", since = \"1.8.0\")]\n    fn st_rdev(&self) -> u64;\n    /// Returns the size of the file (if it is a regular file or a symbolic link) in bytes.\n    ///\n    /// The size of a symbolic link is the length of the pathname it contains,\n    /// without a terminating null byte.\n    ///\n    /// # Examples\n    ///\n    /// ```no_run\n    /// use std::fs;\n    /// use std::io;\n    /// use std::os::linux::fs::MetadataExt;\n    ///\n    /// fn main() -> io::Result<()> {\n    ///     let meta = fs::metadata(\"some_file\")?;\n    ///     println!(\"{}\", meta.st_size());\n    ///     Ok(())\n    /// }\n    /// ```\n    #[stable(feature = \"metadata_ext2\", since = \"1.8.0\")]\n    fn st_size(&self) -> u64;\n    /// Returns the last access time of the file, in seconds since Unix Epoch.\n    ///\n    /// # Examples\n    ///\n    /// ```no_run\n    /// use std::fs;\n    /// use std::io;\n    /// use std::os::linux::fs::MetadataExt;\n    ///\n    /// fn main() -> io::Result<()> {\n    ///     let meta = fs::metadata(\"some_file\")?;\n    ///     println!(\"{}\", meta.st_atime());\n    ///     Ok(())\n    /// }\n    /// ```\n    #[stable(feature = \"metadata_ext2\", since = \"1.8.0\")]\n    fn st_atime(&self) -> i64;\n    /// Returns the last access time of the file, in nanoseconds since [`st_atime`].\n    ///\n    /// [`st_atime`]: Self::st_atime\n    ///\n    /// # Examples\n    ///\n    /// ```no_run\n    /// use std::fs;\n    /// use std::io;\n    /// use std::os::linux::fs::MetadataExt;\n    ///\n    /// fn main() -> io::Result<()> {\n    ///     let meta = fs::metadata(\"some_file\")?;\n    ///     println!(\"{}\", meta.st_atime_nsec());\n    ///     Ok(())\n    /// }\n    /// ```\n    #[stable(feature = \"metadata_ext2\", since = \"1.8.0\")]\n    fn st_atime_nsec(&self) -> i64;\n    /// Returns the last modification time of the file, in seconds since Unix Epoch.\n    ///\n    /// # Examples\n    ///\n    /// ```no_run\n    /// use std::fs;\n    /// use std::io;\n    /// use std::os::linux::fs::MetadataExt;\n    ///\n    /// fn main() -> io::Result<()> {\n    ///     let meta = fs::metadata(\"some_file\")?;\n    ///     println!(\"{}\", meta.st_mtime());\n    ///     Ok(())\n    /// }\n    /// ```\n    #[stable(feature = \"metadata_ext2\", since = \"1.8.0\")]\n    fn st_mtime(&self) -> i64;\n    /// Returns the last modification time of the file, in nanoseconds since [`st_mtime`].\n    ///\n    /// [`st_mtime`]: Self::st_mtime\n    ///\n    /// # Examples\n    ///\n    /// ```no_run\n    /// use std::fs;\n    /// use std::io;\n    /// use std::os::linux::fs::MetadataExt;\n    ///\n    /// fn main() -> io::Result<()> {\n    ///     let meta = fs::metadata(\"some_file\")?;\n    ///     println!(\"{}\", meta.st_mtime_nsec());\n    ///     Ok(())\n    /// }\n    /// ```\n    #[stable(feature = \"metadata_ext2\", since = \"1.8.0\")]\n    fn st_mtime_nsec(&self) -> i64;\n    /// Returns the last status change time of the file, in seconds since Unix Epoch.\n    ///\n    /// # Examples\n    ///\n    /// ```no_run\n    /// use std::fs;\n    /// use std::io;\n    /// use std::os::linux::fs::MetadataExt;\n    ///\n    /// fn main() -> io::Result<()> {\n    ///     let meta = fs::metadata(\"some_file\")?;\n    ///     println!(\"{}\", meta.st_ctime());\n    ///     Ok(())\n    /// }\n    /// ```\n    #[stable(feature = \"metadata_ext2\", since = \"1.8.0\")]\n    fn st_ctime(&self) -> i64;\n    /// Returns the last status change time of the file, in nanoseconds since [`st_ctime`].\n    ///\n    /// [`st_ctime`]: Self::st_ctime\n    ///\n    /// # Examples\n    ///\n    /// ```no_run\n    /// use std::fs;\n    /// use std::io;\n    /// use std::os::linux::fs::MetadataExt;\n    ///\n    /// fn main() -> io::Result<()> {\n    ///     let meta = fs::metadata(\"some_file\")?;\n    ///     println!(\"{}\", meta.st_ctime_nsec());\n    ///     Ok(())\n    /// }\n    /// ```\n    #[stable(feature = \"metadata_ext2\", since = \"1.8.0\")]\n    fn st_ctime_nsec(&self) -> i64;\n    /// Returns the \"preferred\" block size for efficient filesystem I/O.\n    ///\n    /// # Examples\n    ///\n    /// ```no_run\n    /// use std::fs;\n    /// use std::io;\n    /// use std::os::linux::fs::MetadataExt;\n    ///\n    /// fn main() -> io::Result<()> {\n    ///     let meta = fs::metadata(\"some_file\")?;\n    ///     println!(\"{}\", meta.st_blksize());\n    ///     Ok(())\n    /// }\n    /// ```\n    #[stable(feature = \"metadata_ext2\", since = \"1.8.0\")]\n    fn st_blksize(&self) -> u64;\n    /// Returns the number of blocks allocated to the file, 512-byte units.\n    ///\n    /// # Examples\n    ///\n    /// ```no_run\n    /// use std::fs;\n    /// use std::io;\n    /// use std::os::linux::fs::MetadataExt;\n    ///\n    /// fn main() -> io::Result<()> {\n    ///     let meta = fs::metadata(\"some_file\")?;\n    ///     println!(\"{}\", meta.st_blocks());\n    ///     Ok(())\n    /// }\n    /// ```\n    #[stable(feature = \"metadata_ext2\", since = \"1.8.0\")]\n    fn st_blocks(&self) -> u64;\n}\n\n#[stable(feature = \"metadata_ext\", since = \"1.1.0\")]\nimpl MetadataExt for Metadata {\n    #[allow(deprecated)]\n    fn as_raw_stat(&self) -> &raw::stat {\n        unsafe { &*(self.as_inner().as_inner() as *const libc::stat64 as *const raw::stat) }\n    }\n    fn st_dev(&self) -> u64 {\n        self.as_inner().as_inner().st_dev as u64\n    }\n    fn st_ino(&self) -> u64 {\n        self.as_inner().as_inner().st_ino as u64\n    }\n    fn st_mode(&self) -> u32 {\n        self.as_inner().as_inner().st_mode as u32\n    }\n    fn st_nlink(&self) -> u64 {\n        self.as_inner().as_inner().st_nlink as u64\n    }\n    fn st_uid(&self) -> u32 {\n        self.as_inner().as_inner().st_uid as u32\n    }\n    fn st_gid(&self) -> u32 {\n        self.as_inner().as_inner().st_gid as u32\n    }\n    fn st_rdev(&self) -> u64 {\n        self.as_inner().as_inner().st_rdev as u64\n    }\n    fn st_size(&self) -> u64 {\n        self.as_inner().as_inner().st_size as u64\n    }\n    fn st_atime(&self) -> i64 {\n        self.as_inner().as_inner().st_atime as i64\n    }\n    fn st_atime_nsec(&self) -> i64 {\n        self.as_inner().as_inner().st_atime_nsec as i64\n    }\n    fn st_mtime(&self) -> i64 {\n        self.as_inner().as_inner().st_mtime as i64\n    }\n    fn st_mtime_nsec(&self) -> i64 {\n        self.as_inner().as_inner().st_mtime_nsec as i64\n    }\n    fn st_ctime(&self) -> i64 {\n        self.as_inner().as_inner().st_ctime as i64\n    }\n    fn st_ctime_nsec(&self) -> i64 {\n        self.as_inner().as_inner().st_ctime_nsec as i64\n    }\n    fn st_blksize(&self) -> u64 {\n        self.as_inner().as_inner().st_blksize as u64\n    }\n    fn st_blocks(&self) -> u64 {\n        self.as_inner().as_inner().st_blocks as u64\n    }\n}\n"],[2172,"//! Linux-specific definitions.\n\n#![stable(feature = \"raw_ext\", since = \"1.1.0\")]\n#![doc(cfg(target_os = \"linux\"))]\n\npub mod fs;\npub mod raw;\n"],[2173,"#![stable(feature = \"metadata_ext\", since = \"1.1.0\")]\n\nuse crate::fs::Metadata;\nuse crate::sys_common::AsInner;\n\n#[allow(deprecated)]\nuse crate::os::dragonfly::raw;\n\n/// OS-specific extensions to [`fs::Metadata`].\n///\n/// [`fs::Metadata`]: crate::fs::Metadata\n#[stable(feature = \"metadata_ext\", since = \"1.1.0\")]\npub trait MetadataExt {\n    /// Gain a reference to the underlying `stat` structure which contains\n    /// the raw information returned by the OS.\n    ///\n    /// The contents of the returned `stat` are **not** consistent across\n    /// Unix platforms. The `os::unix::fs::MetadataExt` trait contains the\n    /// cross-Unix abstractions contained within the raw stat.\n    #[stable(feature = \"metadata_ext\", since = \"1.1.0\")]\n    #[rustc_deprecated(\n        since = \"1.8.0\",\n        reason = \"deprecated in favor of the accessor \\\n                  methods of this trait\"\n    )]\n    #[allow(deprecated)]\n    fn as_raw_stat(&self) -> &raw::stat;\n\n    #[stable(feature = \"metadata_ext2\", since = \"1.8.0\")]\n    fn st_dev(&self) -> u64;\n    #[stable(feature = \"metadata_ext2\", since = \"1.8.0\")]\n    fn st_ino(&self) -> u64;\n    #[stable(feature = \"metadata_ext2\", since = \"1.8.0\")]\n    fn st_mode(&self) -> u32;\n    #[stable(feature = \"metadata_ext2\", since = \"1.8.0\")]\n    fn st_nlink(&self) -> u64;\n    #[stable(feature = \"metadata_ext2\", since = \"1.8.0\")]\n    fn st_uid(&self) -> u32;\n    #[stable(feature = \"metadata_ext2\", since = \"1.8.0\")]\n    fn st_gid(&self) -> u32;\n    #[stable(feature = \"metadata_ext2\", since = \"1.8.0\")]\n    fn st_rdev(&self) -> u64;\n    #[stable(feature = \"metadata_ext2\", since = \"1.8.0\")]\n    fn st_size(&self) -> u64;\n    #[stable(feature = \"metadata_ext2\", since = \"1.8.0\")]\n    fn st_atime(&self) -> i64;\n    #[stable(feature = \"metadata_ext2\", since = \"1.8.0\")]\n    fn st_atime_nsec(&self) -> i64;\n    #[stable(feature = \"metadata_ext2\", since = \"1.8.0\")]\n    fn st_mtime(&self) -> i64;\n    #[stable(feature = \"metadata_ext2\", since = \"1.8.0\")]\n    fn st_mtime_nsec(&self) -> i64;\n    #[stable(feature = \"metadata_ext2\", since = \"1.8.0\")]\n    fn st_ctime(&self) -> i64;\n    #[stable(feature = \"metadata_ext2\", since = \"1.8.0\")]\n    fn st_ctime_nsec(&self) -> i64;\n    #[stable(feature = \"metadata_ext2\", since = \"1.8.0\")]\n    fn st_blksize(&self) -> u64;\n    #[stable(feature = \"metadata_ext2\", since = \"1.8.0\")]\n    fn st_blocks(&self) -> u64;\n    #[stable(feature = \"metadata_ext2\", since = \"1.8.0\")]\n    fn st_flags(&self) -> u32;\n    #[stable(feature = \"metadata_ext2\", since = \"1.8.0\")]\n    fn st_gen(&self) -> u32;\n    #[stable(feature = \"metadata_ext2\", since = \"1.8.0\")]\n    fn st_lspare(&self) -> u32;\n}\n\n#[stable(feature = \"metadata_ext\", since = \"1.1.0\")]\nimpl MetadataExt for Metadata {\n    #[allow(deprecated)]\n    fn as_raw_stat(&self) -> &raw::stat {\n        unsafe { &*(self.as_inner().as_inner() as *const libc::stat as *const raw::stat) }\n    }\n    fn st_dev(&self) -> u64 {\n        self.as_inner().as_inner().st_dev as u64\n    }\n    fn st_ino(&self) -> u64 {\n        self.as_inner().as_inner().st_ino as u64\n    }\n    fn st_mode(&self) -> u32 {\n        self.as_inner().as_inner().st_mode as u32\n    }\n    fn st_nlink(&self) -> u64 {\n        self.as_inner().as_inner().st_nlink as u64\n    }\n    fn st_uid(&self) -> u32 {\n        self.as_inner().as_inner().st_uid as u32\n    }\n    fn st_gid(&self) -> u32 {\n        self.as_inner().as_inner().st_gid as u32\n    }\n    fn st_rdev(&self) -> u64 {\n        self.as_inner().as_inner().st_rdev as u64\n    }\n    fn st_size(&self) -> u64 {\n        self.as_inner().as_inner().st_size as u64\n    }\n    fn st_atime(&self) -> i64 {\n        self.as_inner().as_inner().st_atime as i64\n    }\n    fn st_atime_nsec(&self) -> i64 {\n        self.as_inner().as_inner().st_atime_nsec as i64\n    }\n    fn st_mtime(&self) -> i64 {\n        self.as_inner().as_inner().st_mtime as i64\n    }\n    fn st_mtime_nsec(&self) -> i64 {\n        self.as_inner().as_inner().st_mtime_nsec as i64\n    }\n    fn st_ctime(&self) -> i64 {\n        self.as_inner().as_inner().st_ctime as i64\n    }\n    fn st_ctime_nsec(&self) -> i64 {\n        self.as_inner().as_inner().st_ctime_nsec as i64\n    }\n    fn st_blksize(&self) -> u64 {\n        self.as_inner().as_inner().st_blksize as u64\n    }\n    fn st_blocks(&self) -> u64 {\n        self.as_inner().as_inner().st_blocks as u64\n    }\n    fn st_gen(&self) -> u32 {\n        self.as_inner().as_inner().st_gen as u32\n    }\n    fn st_flags(&self) -> u32 {\n        self.as_inner().as_inner().st_flags as u32\n    }\n    fn st_lspare(&self) -> u32 {\n        self.as_inner().as_inner().st_lspare as u32\n    }\n}\n"],[2174,"//! Dragonfly-specific definitions\n\n#![stable(feature = \"raw_ext\", since = \"1.1.0\")]\n\npub mod fs;\npub mod raw;\n"],[2175,"//! Dragonfly-specific raw type definitions\n\n#![stable(feature = \"raw_ext\", since = \"1.1.0\")]\n#![rustc_deprecated(\n    since = \"1.8.0\",\n    reason = \"these type aliases are no longer supported by \\\n              the standard library, the `libc` crate on \\\n              crates.io should be used instead for the correct \\\n              definitions\"\n)]\n#![allow(deprecated)]\n\nuse crate::os::raw::c_long;\n\n#[stable(feature = \"raw_ext\", since = \"1.1.0\")]\npub type blkcnt_t = u64;\n#[stable(feature = \"raw_ext\", since = \"1.1.0\")]\npub type blksize_t = u64;\n#[stable(feature = \"raw_ext\", since = \"1.1.0\")]\npub type dev_t = u64;\n#[stable(feature = \"raw_ext\", since = \"1.1.0\")]\npub type fflags_t = u32;\n#[stable(feature = \"raw_ext\", since = \"1.1.0\")]\npub type ino_t = u64;\n#[stable(feature = \"raw_ext\", since = \"1.1.0\")]\npub type mode_t = u32;\n#[stable(feature = \"raw_ext\", since = \"1.1.0\")]\npub type nlink_t = u64;\n#[stable(feature = \"raw_ext\", since = \"1.1.0\")]\npub type off_t = u64;\n#[stable(feature = \"raw_ext\", since = \"1.1.0\")]\npub type time_t = i64;\n\n#[stable(feature = \"pthread_t\", since = \"1.8.0\")]\npub type pthread_t = usize;\n\n#[repr(C)]\n#[derive(Clone)]\n#[stable(feature = \"raw_ext\", since = \"1.1.0\")]\npub struct stat {\n    #[stable(feature = \"raw_ext\", since = \"1.1.0\")]\n    pub st_dev: u32,\n    #[stable(feature = \"raw_ext\", since = \"1.1.0\")]\n    pub st_ino: u32,\n    #[stable(feature = \"raw_ext\", since = \"1.1.0\")]\n    pub st_mode: u16,\n    #[stable(feature = \"raw_ext\", since = \"1.1.0\")]\n    pub st_nlink: u16,\n    #[stable(feature = \"raw_ext\", since = \"1.1.0\")]\n    pub st_uid: u32,\n    #[stable(feature = \"raw_ext\", since = \"1.1.0\")]\n    pub st_gid: u32,\n    #[stable(feature = \"raw_ext\", since = \"1.1.0\")]\n    pub st_rdev: u32,\n    #[stable(feature = \"raw_ext\", since = \"1.1.0\")]\n    pub st_atime: c_long,\n    #[stable(feature = \"raw_ext\", since = \"1.1.0\")]\n    pub st_atime_nsec: c_long,\n    #[stable(feature = \"raw_ext\", since = \"1.1.0\")]\n    pub st_mtime: c_long,\n    #[stable(feature = \"raw_ext\", since = \"1.1.0\")]\n    pub st_mtime_nsec: c_long,\n    #[stable(feature = \"raw_ext\", since = \"1.1.0\")]\n    pub st_ctime: c_long,\n    #[stable(feature = \"raw_ext\", since = \"1.1.0\")]\n    pub st_ctime_nsec: c_long,\n    #[stable(feature = \"raw_ext\", since = \"1.1.0\")]\n    pub st_size: i64,\n    #[stable(feature = \"raw_ext\", since = \"1.1.0\")]\n    pub st_blocks: i64,\n    #[stable(feature = \"raw_ext\", since = \"1.1.0\")]\n    pub st_blksize: u32,\n    #[stable(feature = \"raw_ext\", since = \"1.1.0\")]\n    pub st_flags: u32,\n    #[stable(feature = \"raw_ext\", since = \"1.1.0\")]\n    pub st_gen: u32,\n    #[stable(feature = \"raw_ext\", since = \"1.1.0\")]\n    pub st_lspare: i32,\n    #[stable(feature = \"raw_ext\", since = \"1.1.0\")]\n    pub st_birthtime: c_long,\n    #[stable(feature = \"raw_ext\", since = \"1.1.0\")]\n    pub st_birthtime_nsec: c_long,\n}\n"],[2176,"//! FreeBSD-specific definitions\n\n#![stable(feature = \"raw_ext\", since = \"1.1.0\")]\n\npub mod fs;\npub mod raw;\n"],[2177,"#![stable(feature = \"metadata_ext\", since = \"1.1.0\")]\n\nuse crate::fs::Metadata;\nuse crate::sys_common::AsInner;\n\n#[allow(deprecated)]\nuse crate::os::freebsd::raw;\n\n/// OS-specific extensions to [`fs::Metadata`].\n///\n/// [`fs::Metadata`]: crate::fs::Metadata\n#[stable(feature = \"metadata_ext\", since = \"1.1.0\")]\npub trait MetadataExt {\n    /// Gain a reference to the underlying `stat` structure which contains\n    /// the raw information returned by the OS.\n    ///\n    /// The contents of the returned `stat` are **not** consistent across\n    /// Unix platforms. The `os::unix::fs::MetadataExt` trait contains the\n    /// cross-Unix abstractions contained within the raw stat.\n    #[stable(feature = \"metadata_ext\", since = \"1.1.0\")]\n    #[rustc_deprecated(\n        since = \"1.8.0\",\n        reason = \"deprecated in favor of the accessor \\\n                  methods of this trait\"\n    )]\n    #[allow(deprecated)]\n    fn as_raw_stat(&self) -> &raw::stat;\n\n    #[stable(feature = \"metadata_ext2\", since = \"1.8.0\")]\n    fn st_dev(&self) -> u64;\n    #[stable(feature = \"metadata_ext2\", since = \"1.8.0\")]\n    fn st_ino(&self) -> u64;\n    #[stable(feature = \"metadata_ext2\", since = \"1.8.0\")]\n    fn st_mode(&self) -> u32;\n    #[stable(feature = \"metadata_ext2\", since = \"1.8.0\")]\n    fn st_nlink(&self) -> u64;\n    #[stable(feature = \"metadata_ext2\", since = \"1.8.0\")]\n    fn st_uid(&self) -> u32;\n    #[stable(feature = \"metadata_ext2\", since = \"1.8.0\")]\n    fn st_gid(&self) -> u32;\n    #[stable(feature = \"metadata_ext2\", since = \"1.8.0\")]\n    fn st_rdev(&self) -> u64;\n    #[stable(feature = \"metadata_ext2\", since = \"1.8.0\")]\n    fn st_size(&self) -> u64;\n    #[stable(feature = \"metadata_ext2\", since = \"1.8.0\")]\n    fn st_atime(&self) -> i64;\n    #[stable(feature = \"metadata_ext2\", since = \"1.8.0\")]\n    fn st_atime_nsec(&self) -> i64;\n    #[stable(feature = \"metadata_ext2\", since = \"1.8.0\")]\n    fn st_mtime(&self) -> i64;\n    #[stable(feature = \"metadata_ext2\", since = \"1.8.0\")]\n    fn st_mtime_nsec(&self) -> i64;\n    #[stable(feature = \"metadata_ext2\", since = \"1.8.0\")]\n    fn st_ctime(&self) -> i64;\n    #[stable(feature = \"metadata_ext2\", since = \"1.8.0\")]\n    fn st_ctime_nsec(&self) -> i64;\n    #[stable(feature = \"metadata_ext2\", since = \"1.8.0\")]\n    fn st_birthtime(&self) -> i64;\n    #[stable(feature = \"metadata_ext2\", since = \"1.8.0\")]\n    fn st_birthtime_nsec(&self) -> i64;\n    #[stable(feature = \"metadata_ext2\", since = \"1.8.0\")]\n    fn st_blksize(&self) -> u64;\n    #[stable(feature = \"metadata_ext2\", since = \"1.8.0\")]\n    fn st_blocks(&self) -> u64;\n    #[stable(feature = \"metadata_ext2\", since = \"1.8.0\")]\n    fn st_flags(&self) -> u32;\n    #[stable(feature = \"metadata_ext2\", since = \"1.8.0\")]\n    fn st_gen(&self) -> u32;\n    #[stable(feature = \"metadata_ext2\", since = \"1.8.0\")]\n    fn st_lspare(&self) -> u32;\n}\n\n#[stable(feature = \"metadata_ext\", since = \"1.1.0\")]\nimpl MetadataExt for Metadata {\n    #[allow(deprecated)]\n    fn as_raw_stat(&self) -> &raw::stat {\n        // The methods below use libc::stat, so they work fine when libc is built with FreeBSD 12 ABI.\n        // This method would just return nonsense.\n        #[cfg(freebsd12)]\n        panic!(\"as_raw_stat not supported with FreeBSD 12 ABI\");\n        #[cfg(not(freebsd12))]\n        unsafe {\n            &*(self.as_inner().as_inner() as *const libc::stat as *const raw::stat)\n        }\n    }\n    fn st_dev(&self) -> u64 {\n        self.as_inner().as_inner().st_dev as u64\n    }\n    fn st_ino(&self) -> u64 {\n        self.as_inner().as_inner().st_ino as u64\n    }\n    fn st_mode(&self) -> u32 {\n        self.as_inner().as_inner().st_mode as u32\n    }\n    fn st_nlink(&self) -> u64 {\n        self.as_inner().as_inner().st_nlink as u64\n    }\n    fn st_uid(&self) -> u32 {\n        self.as_inner().as_inner().st_uid as u32\n    }\n    fn st_gid(&self) -> u32 {\n        self.as_inner().as_inner().st_gid as u32\n    }\n    fn st_rdev(&self) -> u64 {\n        self.as_inner().as_inner().st_rdev as u64\n    }\n    fn st_size(&self) -> u64 {\n        self.as_inner().as_inner().st_size as u64\n    }\n    fn st_atime(&self) -> i64 {\n        self.as_inner().as_inner().st_atime as i64\n    }\n    fn st_atime_nsec(&self) -> i64 {\n        self.as_inner().as_inner().st_atime_nsec as i64\n    }\n    fn st_mtime(&self) -> i64 {\n        self.as_inner().as_inner().st_mtime as i64\n    }\n    fn st_mtime_nsec(&self) -> i64 {\n        self.as_inner().as_inner().st_mtime_nsec as i64\n    }\n    fn st_ctime(&self) -> i64 {\n        self.as_inner().as_inner().st_ctime as i64\n    }\n    fn st_ctime_nsec(&self) -> i64 {\n        self.as_inner().as_inner().st_ctime_nsec as i64\n    }\n    fn st_birthtime(&self) -> i64 {\n        self.as_inner().as_inner().st_birthtime as i64\n    }\n    fn st_birthtime_nsec(&self) -> i64 {\n        self.as_inner().as_inner().st_birthtime_nsec as i64\n    }\n    fn st_blksize(&self) -> u64 {\n        self.as_inner().as_inner().st_blksize as u64\n    }\n    fn st_blocks(&self) -> u64 {\n        self.as_inner().as_inner().st_blocks as u64\n    }\n    fn st_gen(&self) -> u32 {\n        self.as_inner().as_inner().st_gen as u32\n    }\n    fn st_flags(&self) -> u32 {\n        self.as_inner().as_inner().st_flags as u32\n    }\n    #[cfg(freebsd12)]\n    fn st_lspare(&self) -> u32 {\n        panic!(\"st_lspare not supported with FreeBSD 12 ABI\");\n    }\n    #[cfg(not(freebsd12))]\n    fn st_lspare(&self) -> u32 {\n        self.as_inner().as_inner().st_lspare as u32\n    }\n}\n"],[2178,"//! FreeBSD-specific raw type definitions\n\n#![stable(feature = \"raw_ext\", since = \"1.1.0\")]\n#![rustc_deprecated(\n    since = \"1.8.0\",\n    reason = \"these type aliases are no longer supported by \\\n              the standard library, the `libc` crate on \\\n              crates.io should be used instead for the correct \\\n              definitions\"\n)]\n#![allow(deprecated)]\n\nuse crate::os::raw::c_long;\n\n#[stable(feature = \"raw_ext\", since = \"1.1.0\")]\npub type blkcnt_t = u64;\n#[stable(feature = \"raw_ext\", since = \"1.1.0\")]\npub type blksize_t = u64;\n#[stable(feature = \"raw_ext\", since = \"1.1.0\")]\npub type dev_t = u64;\n#[stable(feature = \"raw_ext\", since = \"1.1.0\")]\npub type fflags_t = u32;\n#[stable(feature = \"raw_ext\", since = \"1.1.0\")]\npub type ino_t = u64;\n#[stable(feature = \"raw_ext\", since = \"1.1.0\")]\npub type mode_t = u32;\n#[stable(feature = \"raw_ext\", since = \"1.1.0\")]\npub type nlink_t = u64;\n#[stable(feature = \"raw_ext\", since = \"1.1.0\")]\npub type off_t = u64;\n#[stable(feature = \"raw_ext\", since = \"1.1.0\")]\npub type time_t = i64;\n\n#[stable(feature = \"pthread_t\", since = \"1.8.0\")]\npub type pthread_t = usize;\n\n#[repr(C)]\n#[derive(Clone)]\n#[stable(feature = \"raw_ext\", since = \"1.1.0\")]\npub struct stat {\n    #[stable(feature = \"raw_ext\", since = \"1.1.0\")]\n    pub st_dev: u32,\n    #[stable(feature = \"raw_ext\", since = \"1.1.0\")]\n    pub st_ino: u32,\n    #[stable(feature = \"raw_ext\", since = \"1.1.0\")]\n    pub st_mode: u16,\n    #[stable(feature = \"raw_ext\", since = \"1.1.0\")]\n    pub st_nlink: u16,\n    #[stable(feature = \"raw_ext\", since = \"1.1.0\")]\n    pub st_uid: u32,\n    #[stable(feature = \"raw_ext\", since = \"1.1.0\")]\n    pub st_gid: u32,\n    #[stable(feature = \"raw_ext\", since = \"1.1.0\")]\n    pub st_rdev: u32,\n    #[stable(feature = \"raw_ext\", since = \"1.1.0\")]\n    pub st_atime: c_long,\n    #[stable(feature = \"raw_ext\", since = \"1.1.0\")]\n    pub st_atime_nsec: c_long,\n    #[stable(feature = \"raw_ext\", since = \"1.1.0\")]\n    pub st_mtime: c_long,\n    #[stable(feature = \"raw_ext\", since = \"1.1.0\")]\n    pub st_mtime_nsec: c_long,\n    #[stable(feature = \"raw_ext\", since = \"1.1.0\")]\n    pub st_ctime: c_long,\n    #[stable(feature = \"raw_ext\", since = \"1.1.0\")]\n    pub st_ctime_nsec: c_long,\n    #[stable(feature = \"raw_ext\", since = \"1.1.0\")]\n    pub st_size: i64,\n    #[stable(feature = \"raw_ext\", since = \"1.1.0\")]\n    pub st_blocks: i64,\n    #[stable(feature = \"raw_ext\", since = \"1.1.0\")]\n    pub st_blksize: u32,\n    #[stable(feature = \"raw_ext\", since = \"1.1.0\")]\n    pub st_flags: u32,\n    #[stable(feature = \"raw_ext\", since = \"1.1.0\")]\n    pub st_gen: u32,\n    #[stable(feature = \"raw_ext\", since = \"1.1.0\")]\n    pub st_lspare: i32,\n    #[stable(feature = \"raw_ext\", since = \"1.1.0\")]\n    pub st_birthtime: c_long,\n    #[stable(feature = \"raw_ext\", since = \"1.1.0\")]\n    pub st_birthtime_nsec: c_long,\n    #[cfg(target_arch = \"x86\")]\n    #[stable(feature = \"raw_ext\", since = \"1.1.0\")]\n    pub __unused: [u8; 8],\n}\n"],[2179,"//! VxWorks-specific definitions\n\n#![stable(feature = \"raw_ext\", since = \"1.1.0\")]\n\npub mod fs;\npub mod raw;\n"],[2180,"//! VxWorks-specific raw type definitions\n#![stable(feature = \"metadata_ext\", since = \"1.1.0\")]\n\nuse crate::os::raw::c_ulong;\n\n#[stable(feature = \"pthread_t\", since = \"1.8.0\")]\npub type pthread_t = c_ulong;\n\n#[stable(feature = \"raw_ext\", since = \"1.1.0\")]\npub use libc::{blkcnt_t, blksize_t, dev_t, ino_t, mode_t, nlink_t, off_t, time_t};\n"],[2181,"#![stable(feature = \"metadata_ext\", since = \"1.1.0\")]\n\nuse crate::fs::Metadata;\nuse crate::sys_common::AsInner;\n\n///\n/// [`fs::Metadata`]: crate::fs::Metadata\n#[stable(feature = \"metadata_ext\", since = \"1.1.0\")]\npub trait MetadataExt {\n    #[stable(feature = \"metadata_ext2\", since = \"1.8.0\")]\n    fn st_dev(&self) -> u64;\n    #[stable(feature = \"metadata_ext2\", since = \"1.8.0\")]\n    fn st_ino(&self) -> u64;\n    #[stable(feature = \"metadata_ext2\", since = \"1.8.0\")]\n    fn st_mode(&self) -> u32;\n    #[stable(feature = \"metadata_ext2\", since = \"1.8.0\")]\n    fn st_nlink(&self) -> u64;\n    #[stable(feature = \"metadata_ext2\", since = \"1.8.0\")]\n    fn st_uid(&self) -> u32;\n    #[stable(feature = \"metadata_ext2\", since = \"1.8.0\")]\n    fn st_gid(&self) -> u32;\n    #[stable(feature = \"metadata_ext2\", since = \"1.8.0\")]\n    fn st_rdev(&self) -> u64;\n    #[stable(feature = \"metadata_ext2\", since = \"1.8.0\")]\n    fn st_size(&self) -> u64;\n    #[stable(feature = \"metadata_ext2\", since = \"1.8.0\")]\n    fn st_atime(&self) -> i64;\n    #[stable(feature = \"metadata_ext2\", since = \"1.8.0\")]\n    fn st_atime_nsec(&self) -> i64;\n    #[stable(feature = \"metadata_ext2\", since = \"1.8.0\")]\n    fn st_mtime(&self) -> i64;\n    #[stable(feature = \"metadata_ext2\", since = \"1.8.0\")]\n    fn st_mtime_nsec(&self) -> i64;\n    #[stable(feature = \"metadata_ext2\", since = \"1.8.0\")]\n    fn st_ctime(&self) -> i64;\n    #[stable(feature = \"metadata_ext2\", since = \"1.8.0\")]\n    fn st_ctime_nsec(&self) -> i64;\n    #[stable(feature = \"metadata_ext2\", since = \"1.8.0\")]\n    fn st_blksize(&self) -> u64;\n    #[stable(feature = \"metadata_ext2\", since = \"1.8.0\")]\n    fn st_blocks(&self) -> u64;\n    #[stable(feature = \"metadata_ext2\", since = \"1.8.0\")]\n    fn st_attrib(&self) -> u8;\n}\n\n#[stable(feature = \"metadata_ext\", since = \"1.1.0\")]\nimpl MetadataExt for Metadata {\n    fn st_dev(&self) -> u64 {\n        self.as_inner().as_inner().st_dev as u64\n    }\n    fn st_ino(&self) -> u64 {\n        self.as_inner().as_inner().st_ino as u64\n    }\n    fn st_mode(&self) -> u32 {\n        self.as_inner().as_inner().st_mode as u32\n    }\n    fn st_nlink(&self) -> u64 {\n        self.as_inner().as_inner().st_nlink as u64\n    }\n    fn st_uid(&self) -> u32 {\n        self.as_inner().as_inner().st_uid as u32\n    }\n    fn st_gid(&self) -> u32 {\n        self.as_inner().as_inner().st_gid as u32\n    }\n    fn st_rdev(&self) -> u64 {\n        self.as_inner().as_inner().st_rdev as u64\n    }\n    fn st_size(&self) -> u64 {\n        self.as_inner().as_inner().st_size as u64\n    }\n    fn st_atime(&self) -> i64 {\n        self.as_inner().as_inner().st_atime as i64\n    }\n    fn st_atime_nsec(&self) -> i64 {\n        0\n    }\n    fn st_mtime(&self) -> i64 {\n        self.as_inner().as_inner().st_mtime as i64\n    }\n    fn st_mtime_nsec(&self) -> i64 {\n        0\n    }\n    fn st_ctime(&self) -> i64 {\n        self.as_inner().as_inner().st_ctime as i64\n    }\n    fn st_ctime_nsec(&self) -> i64 {\n        0\n    }\n    fn st_blksize(&self) -> u64 {\n        self.as_inner().as_inner().st_blksize as u64\n    }\n    fn st_blocks(&self) -> u64 {\n        self.as_inner().as_inner().st_blocks as u64\n    }\n    fn st_attrib(&self) -> u8 {\n        self.as_inner().as_inner().st_attrib as u8\n    }\n}\n"],[2182,"//! Redox-specific definitions\n\n#![stable(feature = \"raw_ext\", since = \"1.1.0\")]\n\npub mod fs;\npub mod raw;\n"],[2183,"//! Redox-specific raw type definitions\n\n#![stable(feature = \"raw_ext\", since = \"1.1.0\")]\n#![rustc_deprecated(\n    since = \"1.8.0\",\n    reason = \"these type aliases are no longer supported by \\\n              the standard library, the `libc` crate on \\\n              crates.io should be used instead for the correct \\\n              definitions\"\n)]\n#![allow(deprecated)]\n\nuse crate::os::raw::{c_char, c_int, c_long, c_ulong, c_void};\n\n#[stable(feature = \"raw_ext\", since = \"1.1.0\")]\npub type dev_t = c_long;\n#[stable(feature = \"raw_ext\", since = \"1.1.0\")]\npub type gid_t = c_int;\n#[stable(feature = \"raw_ext\", since = \"1.1.0\")]\npub type mode_t = c_int;\n#[stable(feature = \"raw_ext\", since = \"1.1.0\")]\npub type uid_t = c_int;\n\n#[stable(feature = \"pthread_t\", since = \"1.8.0\")]\npub type pthread_t = *mut c_void;\n\n#[stable(feature = \"raw_ext\", since = \"1.1.0\")]\npub type blkcnt_t = c_ulong;\n#[stable(feature = \"raw_ext\", since = \"1.1.0\")]\npub type blksize_t = c_ulong;\n#[stable(feature = \"raw_ext\", since = \"1.1.0\")]\npub type ino_t = c_ulong;\n#[stable(feature = \"raw_ext\", since = \"1.1.0\")]\npub type nlink_t = c_ulong;\n#[stable(feature = \"raw_ext\", since = \"1.1.0\")]\npub type off_t = c_long;\n#[stable(feature = \"raw_ext\", since = \"1.1.0\")]\npub type time_t = c_long;\n\n#[repr(C)]\n#[derive(Clone)]\n#[stable(feature = \"raw_ext\", since = \"1.1.0\")]\npub struct stat {\n    #[stable(feature = \"raw_ext\", since = \"1.1.0\")]\n    pub st_dev: dev_t,\n    #[stable(feature = \"raw_ext\", since = \"1.1.0\")]\n    pub st_ino: ino_t,\n    #[stable(feature = \"raw_ext\", since = \"1.1.0\")]\n    pub st_nlink: nlink_t,\n    #[stable(feature = \"raw_ext\", since = \"1.1.0\")]\n    pub st_mode: mode_t,\n    #[stable(feature = \"raw_ext\", since = \"1.1.0\")]\n    pub st_uid: uid_t,\n    #[stable(feature = \"raw_ext\", since = \"1.1.0\")]\n    pub st_gid: gid_t,\n    #[stable(feature = \"raw_ext\", since = \"1.1.0\")]\n    pub st_rdev: dev_t,\n    #[stable(feature = \"raw_ext\", since = \"1.1.0\")]\n    pub st_size: off_t,\n    #[stable(feature = \"raw_ext\", since = \"1.1.0\")]\n    pub st_blksize: blksize_t,\n    #[stable(feature = \"raw_ext\", since = \"1.1.0\")]\n    pub st_blocks: blkcnt_t,\n    #[stable(feature = \"raw_ext\", since = \"1.1.0\")]\n    pub st_atime: time_t,\n    #[stable(feature = \"raw_ext\", since = \"1.1.0\")]\n    pub st_atime_nsec: c_long,\n    #[stable(feature = \"raw_ext\", since = \"1.1.0\")]\n    pub st_mtime: time_t,\n    #[stable(feature = \"raw_ext\", since = \"1.1.0\")]\n    pub st_mtime_nsec: c_long,\n    #[stable(feature = \"raw_ext\", since = \"1.1.0\")]\n    pub st_ctime: time_t,\n    #[stable(feature = \"raw_ext\", since = \"1.1.0\")]\n    pub st_ctime_nsec: c_long,\n    #[stable(feature = \"raw_ext\", since = \"1.1.0\")]\n    pub _pad: [c_char; 24],\n}\n"],[2184,"#![stable(feature = \"metadata_ext\", since = \"1.1.0\")]\n\nuse crate::fs::Metadata;\nuse crate::sys_common::AsInner;\n\n#[allow(deprecated)]\nuse crate::os::redox::raw;\n\n/// OS-specific extensions to [`fs::Metadata`].\n///\n/// [`fs::Metadata`]: crate::fs::Metadata\n#[stable(feature = \"metadata_ext\", since = \"1.1.0\")]\npub trait MetadataExt {\n    /// Gain a reference to the underlying `stat` structure which contains\n    /// the raw information returned by the OS.\n    ///\n    /// The contents of the returned [`stat`] are **not** consistent across\n    /// Unix platforms. The `os::unix::fs::MetadataExt` trait contains the\n    /// cross-Unix abstractions contained within the raw stat.\n    ///\n    /// [`stat`]: crate::os::redox::raw::stat\n    ///\n    /// # Examples\n    ///\n    /// ```no_run\n    /// use std::fs;\n    /// use std::io;\n    /// use std::os::redox::fs::MetadataExt;\n    ///\n    /// fn main() -> io::Result<()> {\n    ///     let meta = fs::metadata(\"some_file\")?;\n    ///     let stat = meta.as_raw_stat();\n    ///     Ok(())\n    /// }\n    /// ```\n    #[stable(feature = \"metadata_ext\", since = \"1.1.0\")]\n    #[rustc_deprecated(\n        since = \"1.8.0\",\n        reason = \"deprecated in favor of the accessor \\\n                  methods of this trait\"\n    )]\n    #[allow(deprecated)]\n    fn as_raw_stat(&self) -> &raw::stat;\n\n    /// Returns the device ID on which this file resides.\n    ///\n    /// # Examples\n    ///\n    /// ```no_run\n    /// use std::fs;\n    /// use std::io;\n    /// use std::os::redox::fs::MetadataExt;\n    ///\n    /// fn main() -> io::Result<()> {\n    ///     let meta = fs::metadata(\"some_file\")?;\n    ///     println!(\"{}\", meta.st_dev());\n    ///     Ok(())\n    /// }\n    /// ```\n    #[stable(feature = \"metadata_ext2\", since = \"1.8.0\")]\n    fn st_dev(&self) -> u64;\n    /// Returns the inode number.\n    ///\n    /// # Examples\n    ///\n    /// ```no_run\n    /// use std::fs;\n    /// use std::io;\n    /// use std::os::redox::fs::MetadataExt;\n    ///\n    /// fn main() -> io::Result<()> {\n    ///     let meta = fs::metadata(\"some_file\")?;\n    ///     println!(\"{}\", meta.st_ino());\n    ///     Ok(())\n    /// }\n    /// ```\n    #[stable(feature = \"metadata_ext2\", since = \"1.8.0\")]\n    fn st_ino(&self) -> u64;\n    /// Returns the file type and mode.\n    ///\n    /// # Examples\n    ///\n    /// ```no_run\n    /// use std::fs;\n    /// use std::io;\n    /// use std::os::redox::fs::MetadataExt;\n    ///\n    /// fn main() -> io::Result<()> {\n    ///     let meta = fs::metadata(\"some_file\")?;\n    ///     println!(\"{}\", meta.st_mode());\n    ///     Ok(())\n    /// }\n    /// ```\n    #[stable(feature = \"metadata_ext2\", since = \"1.8.0\")]\n    fn st_mode(&self) -> u32;\n    /// Returns the number of hard links to file.\n    ///\n    /// # Examples\n    ///\n    /// ```no_run\n    /// use std::fs;\n    /// use std::io;\n    /// use std::os::redox::fs::MetadataExt;\n    ///\n    /// fn main() -> io::Result<()> {\n    ///     let meta = fs::metadata(\"some_file\")?;\n    ///     println!(\"{}\", meta.st_nlink());\n    ///     Ok(())\n    /// }\n    /// ```\n    #[stable(feature = \"metadata_ext2\", since = \"1.8.0\")]\n    fn st_nlink(&self) -> u64;\n    /// Returns the user ID of the file owner.\n    ///\n    /// # Examples\n    ///\n    /// ```no_run\n    /// use std::fs;\n    /// use std::io;\n    /// use std::os::redox::fs::MetadataExt;\n    ///\n    /// fn main() -> io::Result<()> {\n    ///     let meta = fs::metadata(\"some_file\")?;\n    ///     println!(\"{}\", meta.st_uid());\n    ///     Ok(())\n    /// }\n    /// ```\n    #[stable(feature = \"metadata_ext2\", since = \"1.8.0\")]\n    fn st_uid(&self) -> u32;\n    /// Returns the group ID of the file owner.\n    ///\n    /// # Examples\n    ///\n    /// ```no_run\n    /// use std::fs;\n    /// use std::io;\n    /// use std::os::redox::fs::MetadataExt;\n    ///\n    /// fn main() -> io::Result<()> {\n    ///     let meta = fs::metadata(\"some_file\")?;\n    ///     println!(\"{}\", meta.st_gid());\n    ///     Ok(())\n    /// }\n    /// ```\n    #[stable(feature = \"metadata_ext2\", since = \"1.8.0\")]\n    fn st_gid(&self) -> u32;\n    /// Returns the device ID that this file represents. Only relevant for special file.\n    ///\n    /// # Examples\n    ///\n    /// ```no_run\n    /// use std::fs;\n    /// use std::io;\n    /// use std::os::redox::fs::MetadataExt;\n    ///\n    /// fn main() -> io::Result<()> {\n    ///     let meta = fs::metadata(\"some_file\")?;\n    ///     println!(\"{}\", meta.st_rdev());\n    ///     Ok(())\n    /// }\n    /// ```\n    #[stable(feature = \"metadata_ext2\", since = \"1.8.0\")]\n    fn st_rdev(&self) -> u64;\n    /// Returns the size of the file (if it is a regular file or a symbolic link) in bytes.\n    ///\n    /// The size of a symbolic link is the length of the pathname it contains,\n    /// without a terminating null byte.\n    ///\n    /// # Examples\n    ///\n    /// ```no_run\n    /// use std::fs;\n    /// use std::io;\n    /// use std::os::redox::fs::MetadataExt;\n    ///\n    /// fn main() -> io::Result<()> {\n    ///     let meta = fs::metadata(\"some_file\")?;\n    ///     println!(\"{}\", meta.st_size());\n    ///     Ok(())\n    /// }\n    /// ```\n    #[stable(feature = \"metadata_ext2\", since = \"1.8.0\")]\n    fn st_size(&self) -> u64;\n    /// Returns the last access time of the file, in seconds since Unix Epoch.\n    ///\n    /// # Examples\n    ///\n    /// ```no_run\n    /// use std::fs;\n    /// use std::io;\n    /// use std::os::redox::fs::MetadataExt;\n    ///\n    /// fn main() -> io::Result<()> {\n    ///     let meta = fs::metadata(\"some_file\")?;\n    ///     println!(\"{}\", meta.st_atime());\n    ///     Ok(())\n    /// }\n    /// ```\n    #[stable(feature = \"metadata_ext2\", since = \"1.8.0\")]\n    fn st_atime(&self) -> i64;\n    /// Returns the last access time of the file, in nanoseconds since [`st_atime`].\n    ///\n    /// [`st_atime`]: Self::st_atime\n    ///\n    /// # Examples\n    ///\n    /// ```no_run\n    /// use std::fs;\n    /// use std::io;\n    /// use std::os::redox::fs::MetadataExt;\n    ///\n    /// fn main() -> io::Result<()> {\n    ///     let meta = fs::metadata(\"some_file\")?;\n    ///     println!(\"{}\", meta.st_atime_nsec());\n    ///     Ok(())\n    /// }\n    /// ```\n    #[stable(feature = \"metadata_ext2\", since = \"1.8.0\")]\n    fn st_atime_nsec(&self) -> i64;\n    /// Returns the last modification time of the file, in seconds since Unix Epoch.\n    ///\n    /// # Examples\n    ///\n    /// ```no_run\n    /// use std::fs;\n    /// use std::io;\n    /// use std::os::redox::fs::MetadataExt;\n    ///\n    /// fn main() -> io::Result<()> {\n    ///     let meta = fs::metadata(\"some_file\")?;\n    ///     println!(\"{}\", meta.st_mtime());\n    ///     Ok(())\n    /// }\n    /// ```\n    #[stable(feature = \"metadata_ext2\", since = \"1.8.0\")]\n    fn st_mtime(&self) -> i64;\n    /// Returns the last modification time of the file, in nanoseconds since [`st_mtime`].\n    ///\n    /// [`st_mtime`]: Self::st_mtime\n    ///\n    /// # Examples\n    ///\n    /// ```no_run\n    /// use std::fs;\n    /// use std::io;\n    /// use std::os::redox::fs::MetadataExt;\n    ///\n    /// fn main() -> io::Result<()> {\n    ///     let meta = fs::metadata(\"some_file\")?;\n    ///     println!(\"{}\", meta.st_mtime_nsec());\n    ///     Ok(())\n    /// }\n    /// ```\n    #[stable(feature = \"metadata_ext2\", since = \"1.8.0\")]\n    fn st_mtime_nsec(&self) -> i64;\n    /// Returns the last status change time of the file, in seconds since Unix Epoch.\n    ///\n    /// # Examples\n    ///\n    /// ```no_run\n    /// use std::fs;\n    /// use std::io;\n    /// use std::os::redox::fs::MetadataExt;\n    ///\n    /// fn main() -> io::Result<()> {\n    ///     let meta = fs::metadata(\"some_file\")?;\n    ///     println!(\"{}\", meta.st_ctime());\n    ///     Ok(())\n    /// }\n    /// ```\n    #[stable(feature = \"metadata_ext2\", since = \"1.8.0\")]\n    fn st_ctime(&self) -> i64;\n    /// Returns the last status change time of the file, in nanoseconds since [`st_ctime`].\n    ///\n    /// [`st_ctime`]: Self::st_ctime\n    ///\n    /// # Examples\n    ///\n    /// ```no_run\n    /// use std::fs;\n    /// use std::io;\n    /// use std::os::redox::fs::MetadataExt;\n    ///\n    /// fn main() -> io::Result<()> {\n    ///     let meta = fs::metadata(\"some_file\")?;\n    ///     println!(\"{}\", meta.st_ctime_nsec());\n    ///     Ok(())\n    /// }\n    /// ```\n    #[stable(feature = \"metadata_ext2\", since = \"1.8.0\")]\n    fn st_ctime_nsec(&self) -> i64;\n    /// Returns the \"preferred\" block size for efficient filesystem I/O.\n    ///\n    /// # Examples\n    ///\n    /// ```no_run\n    /// use std::fs;\n    /// use std::io;\n    /// use std::os::redox::fs::MetadataExt;\n    ///\n    /// fn main() -> io::Result<()> {\n    ///     let meta = fs::metadata(\"some_file\")?;\n    ///     println!(\"{}\", meta.st_blksize());\n    ///     Ok(())\n    /// }\n    /// ```\n    #[stable(feature = \"metadata_ext2\", since = \"1.8.0\")]\n    fn st_blksize(&self) -> u64;\n    /// Returns the number of blocks allocated to the file, 512-byte units.\n    ///\n    /// # Examples\n    ///\n    /// ```no_run\n    /// use std::fs;\n    /// use std::io;\n    /// use std::os::redox::fs::MetadataExt;\n    ///\n    /// fn main() -> io::Result<()> {\n    ///     let meta = fs::metadata(\"some_file\")?;\n    ///     println!(\"{}\", meta.st_blocks());\n    ///     Ok(())\n    /// }\n    /// ```\n    #[stable(feature = \"metadata_ext2\", since = \"1.8.0\")]\n    fn st_blocks(&self) -> u64;\n}\n\n#[stable(feature = \"metadata_ext\", since = \"1.1.0\")]\nimpl MetadataExt for Metadata {\n    #[allow(deprecated)]\n    fn as_raw_stat(&self) -> &raw::stat {\n        unsafe { &*(self.as_inner().as_inner() as *const libc::stat as *const raw::stat) }\n    }\n    fn st_dev(&self) -> u64 {\n        self.as_inner().as_inner().st_dev as u64\n    }\n    fn st_ino(&self) -> u64 {\n        self.as_inner().as_inner().st_ino as u64\n    }\n    fn st_mode(&self) -> u32 {\n        self.as_inner().as_inner().st_mode as u32\n    }\n    fn st_nlink(&self) -> u64 {\n        self.as_inner().as_inner().st_nlink as u64\n    }\n    fn st_uid(&self) -> u32 {\n        self.as_inner().as_inner().st_uid as u32\n    }\n    fn st_gid(&self) -> u32 {\n        self.as_inner().as_inner().st_gid as u32\n    }\n    fn st_rdev(&self) -> u64 {\n        self.as_inner().as_inner().st_rdev as u64\n    }\n    fn st_size(&self) -> u64 {\n        self.as_inner().as_inner().st_size as u64\n    }\n    fn st_atime(&self) -> i64 {\n        self.as_inner().as_inner().st_atime as i64\n    }\n    fn st_atime_nsec(&self) -> i64 {\n        self.as_inner().as_inner().st_atime_nsec as i64\n    }\n    fn st_mtime(&self) -> i64 {\n        self.as_inner().as_inner().st_mtime as i64\n    }\n    fn st_mtime_nsec(&self) -> i64 {\n        self.as_inner().as_inner().st_mtime_nsec as i64\n    }\n    fn st_ctime(&self) -> i64 {\n        self.as_inner().as_inner().st_ctime as i64\n    }\n    fn st_ctime_nsec(&self) -> i64 {\n        self.as_inner().as_inner().st_ctime_nsec as i64\n    }\n    fn st_blksize(&self) -> u64 {\n        self.as_inner().as_inner().st_blksize as u64\n    }\n    fn st_blocks(&self) -> u64 {\n        self.as_inner().as_inner().st_blocks as u64\n    }\n}\n"],[2185,"//! Fuchsia-specific definitions\n\n#![stable(feature = \"raw_ext\", since = \"1.1.0\")]\n\npub mod fs;\npub mod raw;\n"],[2186,"//! Fuchsia-specific raw type definitions\n\n#![stable(feature = \"raw_ext\", since = \"1.1.0\")]\n#![rustc_deprecated(\n    since = \"1.8.0\",\n    reason = \"these type aliases are no longer supported by \\\n              the standard library, the `libc` crate on \\\n              crates.io should be used instead for the correct \\\n              definitions\"\n)]\n#![allow(deprecated)]\n\nuse crate::os::raw::c_ulong;\n\n#[stable(feature = \"raw_ext\", since = \"1.1.0\")]\npub type dev_t = u64;\n#[stable(feature = \"raw_ext\", since = \"1.1.0\")]\npub type mode_t = u32;\n\n#[stable(feature = \"pthread_t\", since = \"1.8.0\")]\npub type pthread_t = c_ulong;\n\n#[doc(inline)]\n#[stable(feature = \"raw_ext\", since = \"1.1.0\")]\npub use self::arch::{blkcnt_t, blksize_t, ino_t, nlink_t, off_t, stat, time_t};\n\n#[cfg(any(\n    target_arch = \"x86\",\n    target_arch = \"le32\",\n    target_arch = \"powerpc\",\n    target_arch = \"arm\"\n))]\nmod arch {\n    use crate::os::raw::{c_long, c_short, c_uint};\n\n    #[stable(feature = \"raw_ext\", since = \"1.1.0\")]\n    pub type blkcnt_t = u64;\n    #[stable(feature = \"raw_ext\", since = \"1.1.0\")]\n    pub type blksize_t = u64;\n    #[stable(feature = \"raw_ext\", since = \"1.1.0\")]\n    pub type ino_t = u64;\n    #[stable(feature = \"raw_ext\", since = \"1.1.0\")]\n    pub type nlink_t = u64;\n    #[stable(feature = \"raw_ext\", since = \"1.1.0\")]\n    pub type off_t = u64;\n    #[stable(feature = \"raw_ext\", since = \"1.1.0\")]\n    pub type time_t = i64;\n\n    #[repr(C)]\n    #[derive(Clone)]\n    #[stable(feature = \"raw_ext\", since = \"1.1.0\")]\n    pub struct stat {\n        #[stable(feature = \"raw_ext\", since = \"1.1.0\")]\n        pub st_dev: u64,\n        #[stable(feature = \"raw_ext\", since = \"1.1.0\")]\n        pub __pad1: c_short,\n        #[stable(feature = \"raw_ext\", since = \"1.1.0\")]\n        pub __st_ino: u32,\n        #[stable(feature = \"raw_ext\", since = \"1.1.0\")]\n        pub st_mode: u32,\n        #[stable(feature = \"raw_ext\", since = \"1.1.0\")]\n        pub st_nlink: u32,\n        #[stable(feature = \"raw_ext\", since = \"1.1.0\")]\n        pub st_uid: u32,\n        #[stable(feature = \"raw_ext\", since = \"1.1.0\")]\n        pub st_gid: u32,\n        #[stable(feature = \"raw_ext\", since = \"1.1.0\")]\n        pub st_rdev: u64,\n        #[stable(feature = \"raw_ext\", since = \"1.1.0\")]\n        pub __pad2: c_uint,\n        #[stable(feature = \"raw_ext\", since = \"1.1.0\")]\n        pub st_size: i64,\n        #[stable(feature = \"raw_ext\", since = \"1.1.0\")]\n        pub st_blksize: i32,\n        #[stable(feature = \"raw_ext\", since = \"1.1.0\")]\n        pub st_blocks: i64,\n        #[stable(feature = \"raw_ext\", since = \"1.1.0\")]\n        pub st_atime: i32,\n        #[stable(feature = \"raw_ext\", since = \"1.1.0\")]\n        pub st_atime_nsec: c_long,\n        #[stable(feature = \"raw_ext\", since = \"1.1.0\")]\n        pub st_mtime: i32,\n        #[stable(feature = \"raw_ext\", since = \"1.1.0\")]\n        pub st_mtime_nsec: c_long,\n        #[stable(feature = \"raw_ext\", since = \"1.1.0\")]\n        pub st_ctime: i32,\n        #[stable(feature = \"raw_ext\", since = \"1.1.0\")]\n        pub st_ctime_nsec: c_long,\n        #[stable(feature = \"raw_ext\", since = \"1.1.0\")]\n        pub st_ino: u64,\n    }\n}\n\n#[cfg(target_arch = \"mips\")]\nmod arch {\n    use crate::os::raw::{c_long, c_ulong};\n\n    #[cfg(target_env = \"musl\")]\n    #[stable(feature = \"raw_ext\", since = \"1.1.0\")]\n    pub type blkcnt_t = i64;\n    #[cfg(not(target_env = \"musl\"))]\n    #[stable(feature = \"raw_ext\", since = \"1.1.0\")]\n    pub type blkcnt_t = u64;\n    #[stable(feature = \"raw_ext\", since = \"1.1.0\")]\n    pub type blksize_t = u64;\n    #[cfg(target_env = \"musl\")]\n    #[stable(feature = \"raw_ext\", since = \"1.1.0\")]\n    pub type ino_t = u64;\n    #[cfg(not(target_env = \"musl\"))]\n    #[stable(feature = \"raw_ext\", since = \"1.1.0\")]\n    pub type ino_t = u64;\n    #[stable(feature = \"raw_ext\", since = \"1.1.0\")]\n    pub type nlink_t = u64;\n    #[cfg(target_env = \"musl\")]\n    #[stable(feature = \"raw_ext\", since = \"1.1.0\")]\n    pub type off_t = u64;\n    #[cfg(not(target_env = \"musl\"))]\n    #[stable(feature = \"raw_ext\", since = \"1.1.0\")]\n    pub type off_t = u64;\n    #[stable(feature = \"raw_ext\", since = \"1.1.0\")]\n    pub type time_t = i64;\n\n    #[repr(C)]\n    #[derive(Clone)]\n    #[stable(feature = \"raw_ext\", since = \"1.1.0\")]\n    pub struct stat {\n        #[stable(feature = \"raw_ext\", since = \"1.1.0\")]\n        pub st_dev: c_ulong,\n        #[stable(feature = \"raw_ext\", since = \"1.1.0\")]\n        pub st_pad1: [c_long; 3],\n        #[stable(feature = \"raw_ext\", since = \"1.1.0\")]\n        pub st_ino: u64,\n        #[stable(feature = \"raw_ext\", since = \"1.1.0\")]\n        pub st_mode: u32,\n        #[stable(feature = \"raw_ext\", since = \"1.1.0\")]\n        pub st_nlink: u32,\n        #[stable(feature = \"raw_ext\", since = \"1.1.0\")]\n        pub st_uid: u32,\n        #[stable(feature = \"raw_ext\", since = \"1.1.0\")]\n        pub st_gid: u32,\n        #[stable(feature = \"raw_ext\", since = \"1.1.0\")]\n        pub st_rdev: c_ulong,\n        #[stable(feature = \"raw_ext\", since = \"1.1.0\")]\n        pub st_pad2: [c_long; 2],\n        #[stable(feature = \"raw_ext\", since = \"1.1.0\")]\n        pub st_size: i64,\n        #[stable(feature = \"raw_ext\", since = \"1.1.0\")]\n        pub st_atime: i32,\n        #[stable(feature = \"raw_ext\", since = \"1.1.0\")]\n        pub st_atime_nsec: c_long,\n        #[stable(feature = \"raw_ext\", since = \"1.1.0\")]\n        pub st_mtime: i32,\n        #[stable(feature = \"raw_ext\", since = \"1.1.0\")]\n        pub st_mtime_nsec: c_long,\n        #[stable(feature = \"raw_ext\", since = \"1.1.0\")]\n        pub st_ctime: i32,\n        #[stable(feature = \"raw_ext\", since = \"1.1.0\")]\n        pub st_ctime_nsec: c_long,\n        #[stable(feature = \"raw_ext\", since = \"1.1.0\")]\n        pub st_blksize: i32,\n        #[stable(feature = \"raw_ext\", since = \"1.1.0\")]\n        pub st_blocks: i64,\n        #[stable(feature = \"raw_ext\", since = \"1.1.0\")]\n        pub st_pad5: [c_long; 14],\n    }\n}\n\n#[cfg(target_arch = \"mips64\")]\nmod arch {\n    pub use libc::{blkcnt_t, blksize_t, ino_t, nlink_t, off_t, stat, time_t};\n}\n\n#[cfg(target_arch = \"aarch64\")]\nmod arch {\n    use crate::os::raw::{c_int, c_long};\n\n    #[stable(feature = \"raw_ext\", since = \"1.1.0\")]\n    pub type blkcnt_t = u64;\n    #[stable(feature = \"raw_ext\", since = \"1.1.0\")]\n    pub type blksize_t = u64;\n    #[stable(feature = \"raw_ext\", since = \"1.1.0\")]\n    pub type ino_t = u64;\n    #[stable(feature = \"raw_ext\", since = \"1.1.0\")]\n    pub type nlink_t = u64;\n    #[stable(feature = \"raw_ext\", since = \"1.1.0\")]\n    pub type off_t = u64;\n    #[stable(feature = \"raw_ext\", since = \"1.1.0\")]\n    pub type time_t = i64;\n\n    #[repr(C)]\n    #[derive(Clone)]\n    #[stable(feature = \"raw_ext\", since = \"1.1.0\")]\n    pub struct stat {\n        #[stable(feature = \"raw_ext\", since = \"1.1.0\")]\n        pub st_dev: u64,\n        #[stable(feature = \"raw_ext\", since = \"1.1.0\")]\n        pub st_ino: u64,\n        #[stable(feature = \"raw_ext\", since = \"1.1.0\")]\n        pub st_mode: u32,\n        #[stable(feature = \"raw_ext\", since = \"1.1.0\")]\n        pub st_nlink: u32,\n        #[stable(feature = \"raw_ext\", since = \"1.1.0\")]\n        pub st_uid: u32,\n        #[stable(feature = \"raw_ext\", since = \"1.1.0\")]\n        pub st_gid: u32,\n        #[stable(feature = \"raw_ext\", since = \"1.1.0\")]\n        pub st_rdev: u64,\n        #[stable(feature = \"raw_ext\", since = \"1.1.0\")]\n        pub __pad1: u64,\n        #[stable(feature = \"raw_ext\", since = \"1.1.0\")]\n        pub st_size: i64,\n        #[stable(feature = \"raw_ext\", since = \"1.1.0\")]\n        pub st_blksize: i32,\n        #[stable(feature = \"raw_ext\", since = \"1.1.0\")]\n        pub __pad2: c_int,\n        #[stable(feature = \"raw_ext\", since = \"1.1.0\")]\n        pub st_blocks: i64,\n        #[stable(feature = \"raw_ext\", since = \"1.1.0\")]\n        pub st_atime: i64,\n        #[stable(feature = \"raw_ext\", since = \"1.1.0\")]\n        pub st_atime_nsec: c_long,\n        #[stable(feature = \"raw_ext\", since = \"1.1.0\")]\n        pub st_mtime: i64,\n        #[stable(feature = \"raw_ext\", since = \"1.1.0\")]\n        pub st_mtime_nsec: c_long,\n        #[stable(feature = \"raw_ext\", since = \"1.1.0\")]\n        pub st_ctime: i64,\n        #[stable(feature = \"raw_ext\", since = \"1.1.0\")]\n        pub st_ctime_nsec: c_long,\n        #[stable(feature = \"raw_ext\", since = \"1.1.0\")]\n        pub __unused: [c_int; 2],\n    }\n}\n\n#[cfg(target_arch = \"x86_64\")]\nmod arch {\n    use crate::os::raw::{c_int, c_long};\n\n    #[stable(feature = \"raw_ext\", since = \"1.1.0\")]\n    pub type blkcnt_t = u64;\n    #[stable(feature = \"raw_ext\", since = \"1.1.0\")]\n    pub type blksize_t = u64;\n    #[stable(feature = \"raw_ext\", since = \"1.1.0\")]\n    pub type ino_t = u64;\n    #[stable(feature = \"raw_ext\", since = \"1.1.0\")]\n    pub type nlink_t = u64;\n    #[stable(feature = \"raw_ext\", since = \"1.1.0\")]\n    pub type off_t = u64;\n    #[stable(feature = \"raw_ext\", since = \"1.1.0\")]\n    pub type time_t = i64;\n\n    #[repr(C)]\n    #[derive(Clone)]\n    #[stable(feature = \"raw_ext\", since = \"1.1.0\")]\n    pub struct stat {\n        #[stable(feature = \"raw_ext\", since = \"1.1.0\")]\n        pub st_dev: u64,\n        #[stable(feature = \"raw_ext\", since = \"1.1.0\")]\n        pub st_ino: u64,\n        #[stable(feature = \"raw_ext\", since = \"1.1.0\")]\n        pub st_nlink: u64,\n        #[stable(feature = \"raw_ext\", since = \"1.1.0\")]\n        pub st_mode: u32,\n        #[stable(feature = \"raw_ext\", since = \"1.1.0\")]\n        pub st_uid: u32,\n        #[stable(feature = \"raw_ext\", since = \"1.1.0\")]\n        pub st_gid: u32,\n        #[stable(feature = \"raw_ext\", since = \"1.1.0\")]\n        pub __pad0: c_int,\n        #[stable(feature = \"raw_ext\", since = \"1.1.0\")]\n        pub st_rdev: u64,\n        #[stable(feature = \"raw_ext\", since = \"1.1.0\")]\n        pub st_size: i64,\n        #[stable(feature = \"raw_ext\", since = \"1.1.0\")]\n        pub st_blksize: i64,\n        #[stable(feature = \"raw_ext\", since = \"1.1.0\")]\n        pub st_blocks: i64,\n        #[stable(feature = \"raw_ext\", since = \"1.1.0\")]\n        pub st_atime: i64,\n        #[stable(feature = \"raw_ext\", since = \"1.1.0\")]\n        pub st_atime_nsec: c_long,\n        #[stable(feature = \"raw_ext\", since = \"1.1.0\")]\n        pub st_mtime: i64,\n        #[stable(feature = \"raw_ext\", since = \"1.1.0\")]\n        pub st_mtime_nsec: c_long,\n        #[stable(feature = \"raw_ext\", since = \"1.1.0\")]\n        pub st_ctime: i64,\n        #[stable(feature = \"raw_ext\", since = \"1.1.0\")]\n        pub st_ctime_nsec: c_long,\n        #[stable(feature = \"raw_ext\", since = \"1.1.0\")]\n        pub __unused: [c_long; 3],\n    }\n}\n"],[2187,"#![stable(feature = \"metadata_ext\", since = \"1.1.0\")]\n\nuse crate::fs::Metadata;\nuse crate::sys_common::AsInner;\n\n/// OS-specific extensions to [`fs::Metadata`].\n///\n/// [`fs::Metadata`]: crate::fs::Metadata\n#[stable(feature = \"metadata_ext\", since = \"1.1.0\")]\npub trait MetadataExt {\n    #[stable(feature = \"metadata_ext2\", since = \"1.8.0\")]\n    fn st_dev(&self) -> u64;\n    #[stable(feature = \"metadata_ext2\", since = \"1.8.0\")]\n    fn st_ino(&self) -> u64;\n    #[stable(feature = \"metadata_ext2\", since = \"1.8.0\")]\n    fn st_mode(&self) -> u32;\n    #[stable(feature = \"metadata_ext2\", since = \"1.8.0\")]\n    fn st_nlink(&self) -> u64;\n    #[stable(feature = \"metadata_ext2\", since = \"1.8.0\")]\n    fn st_uid(&self) -> u32;\n    #[stable(feature = \"metadata_ext2\", since = \"1.8.0\")]\n    fn st_gid(&self) -> u32;\n    #[stable(feature = \"metadata_ext2\", since = \"1.8.0\")]\n    fn st_rdev(&self) -> u64;\n    #[stable(feature = \"metadata_ext2\", since = \"1.8.0\")]\n    fn st_size(&self) -> u64;\n    #[stable(feature = \"metadata_ext2\", since = \"1.8.0\")]\n    fn st_atime(&self) -> i64;\n    #[stable(feature = \"metadata_ext2\", since = \"1.8.0\")]\n    fn st_atime_nsec(&self) -> i64;\n    #[stable(feature = \"metadata_ext2\", since = \"1.8.0\")]\n    fn st_mtime(&self) -> i64;\n    #[stable(feature = \"metadata_ext2\", since = \"1.8.0\")]\n    fn st_mtime_nsec(&self) -> i64;\n    #[stable(feature = \"metadata_ext2\", since = \"1.8.0\")]\n    fn st_ctime(&self) -> i64;\n    #[stable(feature = \"metadata_ext2\", since = \"1.8.0\")]\n    fn st_ctime_nsec(&self) -> i64;\n    #[stable(feature = \"metadata_ext2\", since = \"1.8.0\")]\n    fn st_blksize(&self) -> u64;\n    #[stable(feature = \"metadata_ext2\", since = \"1.8.0\")]\n    fn st_blocks(&self) -> u64;\n}\n\n#[stable(feature = \"metadata_ext\", since = \"1.1.0\")]\nimpl MetadataExt for Metadata {\n    fn st_dev(&self) -> u64 {\n        self.as_inner().as_inner().st_dev as u64\n    }\n    fn st_ino(&self) -> u64 {\n        self.as_inner().as_inner().st_ino as u64\n    }\n    fn st_mode(&self) -> u32 {\n        self.as_inner().as_inner().st_mode as u32\n    }\n    fn st_nlink(&self) -> u64 {\n        self.as_inner().as_inner().st_nlink as u64\n    }\n    fn st_uid(&self) -> u32 {\n        self.as_inner().as_inner().st_uid as u32\n    }\n    fn st_gid(&self) -> u32 {\n        self.as_inner().as_inner().st_gid as u32\n    }\n    fn st_rdev(&self) -> u64 {\n        self.as_inner().as_inner().st_rdev as u64\n    }\n    fn st_size(&self) -> u64 {\n        self.as_inner().as_inner().st_size as u64\n    }\n    fn st_atime(&self) -> i64 {\n        self.as_inner().as_inner().st_atime as i64\n    }\n    fn st_atime_nsec(&self) -> i64 {\n        self.as_inner().as_inner().st_atime_nsec as i64\n    }\n    fn st_mtime(&self) -> i64 {\n        self.as_inner().as_inner().st_mtime as i64\n    }\n    fn st_mtime_nsec(&self) -> i64 {\n        self.as_inner().as_inner().st_mtime_nsec as i64\n    }\n    fn st_ctime(&self) -> i64 {\n        self.as_inner().as_inner().st_ctime as i64\n    }\n    fn st_ctime_nsec(&self) -> i64 {\n        self.as_inner().as_inner().st_ctime_nsec as i64\n    }\n    fn st_blksize(&self) -> u64 {\n        self.as_inner().as_inner().st_blksize as u64\n    }\n    fn st_blocks(&self) -> u64 {\n        self.as_inner().as_inner().st_blocks as u64\n    }\n}\n"],[2188,"//! Windows-specific primitives.\n\n#![stable(feature = \"raw_ext\", since = \"1.1.0\")]\n\nuse crate::os::raw::c_void;\n\n#[stable(feature = \"raw_ext\", since = \"1.1.0\")]\npub type HANDLE = *mut c_void;\n#[cfg(target_pointer_width = \"32\")]\n#[stable(feature = \"raw_ext\", since = \"1.1.0\")]\npub type SOCKET = u32;\n#[cfg(target_pointer_width = \"64\")]\n#[stable(feature = \"raw_ext\", since = \"1.1.0\")]\npub type SOCKET = u64;\n"],[2189,"//! Windows-specific extensions for the primitives in the `std::fs` module.\n\n#![stable(feature = \"rust1\", since = \"1.0.0\")]\n\nuse crate::fs::{self, Metadata, OpenOptions};\nuse crate::io;\nuse crate::path::Path;\nuse crate::sys;\nuse crate::sys_common::{AsInner, AsInnerMut};\n\n/// Windows-specific extensions to [`fs::File`].\n#[stable(feature = \"file_offset\", since = \"1.15.0\")]\npub trait FileExt {\n    /// Seeks to a given position and reads a number of bytes.\n    ///\n    /// Returns the number of bytes read.\n    ///\n    /// The offset is relative to the start of the file and thus independent\n    /// from the current cursor. The current cursor **is** affected by this\n    /// function, it is set to the end of the read.\n    ///\n    /// Reading beyond the end of the file will always return with a length of\n    /// 0\\.\n    ///\n    /// Note that similar to `File::read`, it is not an error to return with a\n    /// short read. When returning from such a short read, the file pointer is\n    /// still updated.\n    ///\n    /// # Examples\n    ///\n    /// ```no_run\n    /// use std::io;\n    /// use std::fs::File;\n    /// use std::os::windows::prelude::*;\n    ///\n    /// fn main() -> io::Result<()> {\n    ///     let mut file = File::open(\"foo.txt\")?;\n    ///     let mut buffer = [0; 10];\n    ///\n    ///     // Read 10 bytes, starting 72 bytes from the\n    ///     // start of the file.\n    ///     file.seek_read(&mut buffer[..], 72)?;\n    ///     Ok(())\n    /// }\n    /// ```\n    #[stable(feature = \"file_offset\", since = \"1.15.0\")]\n    fn seek_read(&self, buf: &mut [u8], offset: u64) -> io::Result<usize>;\n\n    /// Seeks to a given position and writes a number of bytes.\n    ///\n    /// Returns the number of bytes written.\n    ///\n    /// The offset is relative to the start of the file and thus independent\n    /// from the current cursor. The current cursor **is** affected by this\n    /// function, it is set to the end of the write.\n    ///\n    /// When writing beyond the end of the file, the file is appropriately\n    /// extended and the intermediate bytes are left uninitialized.\n    ///\n    /// Note that similar to `File::write`, it is not an error to return a\n    /// short write. When returning from such a short write, the file pointer\n    /// is still updated.\n    ///\n    /// # Examples\n    ///\n    /// ```no_run\n    /// use std::fs::File;\n    /// use std::os::windows::prelude::*;\n    ///\n    /// fn main() -> std::io::Result<()> {\n    ///     let mut buffer = File::create(\"foo.txt\")?;\n    ///\n    ///     // Write a byte string starting 72 bytes from\n    ///     // the start of the file.\n    ///     buffer.seek_write(b\"some bytes\", 72)?;\n    ///     Ok(())\n    /// }\n    /// ```\n    #[stable(feature = \"file_offset\", since = \"1.15.0\")]\n    fn seek_write(&self, buf: &[u8], offset: u64) -> io::Result<usize>;\n}\n\n#[stable(feature = \"file_offset\", since = \"1.15.0\")]\nimpl FileExt for fs::File {\n    fn seek_read(&self, buf: &mut [u8], offset: u64) -> io::Result<usize> {\n        self.as_inner().read_at(buf, offset)\n    }\n\n    fn seek_write(&self, buf: &[u8], offset: u64) -> io::Result<usize> {\n        self.as_inner().write_at(buf, offset)\n    }\n}\n\n/// Windows-specific extensions to [`fs::OpenOptions`].\n#[stable(feature = \"open_options_ext\", since = \"1.10.0\")]\npub trait OpenOptionsExt {\n    /// Overrides the `dwDesiredAccess` argument to the call to [`CreateFile`]\n    /// with the specified value.\n    ///\n    /// This will override the `read`, `write`, and `append` flags on the\n    /// `OpenOptions` structure. This method provides fine-grained control over\n    /// the permissions to read, write and append data, attributes (like hidden\n    /// and system), and extended attributes.\n    ///\n    /// # Examples\n    ///\n    /// ```no_run\n    /// use std::fs::OpenOptions;\n    /// use std::os::windows::prelude::*;\n    ///\n    /// // Open without read and write permission, for example if you only need\n    /// // to call `stat` on the file\n    /// let file = OpenOptions::new().access_mode(0).open(\"foo.txt\");\n    /// ```\n    ///\n    /// [`CreateFile`]: https://docs.microsoft.com/en-us/windows/win32/api/fileapi/nf-fileapi-createfilea\n    #[stable(feature = \"open_options_ext\", since = \"1.10.0\")]\n    fn access_mode(&mut self, access: u32) -> &mut Self;\n\n    /// Overrides the `dwShareMode` argument to the call to [`CreateFile`] with\n    /// the specified value.\n    ///\n    /// By default `share_mode` is set to\n    /// `FILE_SHARE_READ | FILE_SHARE_WRITE | FILE_SHARE_DELETE`. This allows\n    /// other processes to read, write, and delete/rename the same file\n    /// while it is open. Removing any of the flags will prevent other\n    /// processes from performing the corresponding operation until the file\n    /// handle is closed.\n    ///\n    /// # Examples\n    ///\n    /// ```no_run\n    /// use std::fs::OpenOptions;\n    /// use std::os::windows::prelude::*;\n    ///\n    /// // Do not allow others to read or modify this file while we have it open\n    /// // for writing.\n    /// let file = OpenOptions::new()\n    ///     .write(true)\n    ///     .share_mode(0)\n    ///     .open(\"foo.txt\");\n    /// ```\n    ///\n    /// [`CreateFile`]: https://docs.microsoft.com/en-us/windows/win32/api/fileapi/nf-fileapi-createfilea\n    #[stable(feature = \"open_options_ext\", since = \"1.10.0\")]\n    fn share_mode(&mut self, val: u32) -> &mut Self;\n\n    /// Sets extra flags for the `dwFileFlags` argument to the call to\n    /// [`CreateFile2`] to the specified value (or combines it with\n    /// `attributes` and `security_qos_flags` to set the `dwFlagsAndAttributes`\n    /// for [`CreateFile`]).\n    ///\n    /// Custom flags can only set flags, not remove flags set by Rust's options.\n    /// This option overwrites any previously set custom flags.\n    ///\n    /// # Examples\n    ///\n    /// ```no_run\n    /// # #[cfg(for_demonstration_only)]\n    /// extern crate winapi;\n    /// # mod winapi { pub const FILE_FLAG_DELETE_ON_CLOSE: u32 = 0x04000000; }\n    ///\n    /// use std::fs::OpenOptions;\n    /// use std::os::windows::prelude::*;\n    ///\n    /// let file = OpenOptions::new()\n    ///     .create(true)\n    ///     .write(true)\n    ///     .custom_flags(winapi::FILE_FLAG_DELETE_ON_CLOSE)\n    ///     .open(\"foo.txt\");\n    /// ```\n    ///\n    /// [`CreateFile`]: https://docs.microsoft.com/en-us/windows/win32/api/fileapi/nf-fileapi-createfilea\n    /// [`CreateFile2`]: https://docs.microsoft.com/en-us/windows/win32/api/fileapi/nf-fileapi-createfile2\n    #[stable(feature = \"open_options_ext\", since = \"1.10.0\")]\n    fn custom_flags(&mut self, flags: u32) -> &mut Self;\n\n    /// Sets the `dwFileAttributes` argument to the call to [`CreateFile2`] to\n    /// the specified value (or combines it with `custom_flags` and\n    /// `security_qos_flags` to set the `dwFlagsAndAttributes` for\n    /// [`CreateFile`]).\n    ///\n    /// If a _new_ file is created because it does not yet exist and\n    /// `.create(true)` or `.create_new(true)` are specified, the new file is\n    /// given the attributes declared with `.attributes()`.\n    ///\n    /// If an _existing_ file is opened with `.create(true).truncate(true)`, its\n    /// existing attributes are preserved and combined with the ones declared\n    /// with `.attributes()`.\n    ///\n    /// In all other cases the attributes get ignored.\n    ///\n    /// # Examples\n    ///\n    /// ```no_run\n    /// # #[cfg(for_demonstration_only)]\n    /// extern crate winapi;\n    /// # mod winapi { pub const FILE_ATTRIBUTE_HIDDEN: u32 = 2; }\n    ///\n    /// use std::fs::OpenOptions;\n    /// use std::os::windows::prelude::*;\n    ///\n    /// let file = OpenOptions::new()\n    ///     .write(true)\n    ///     .create(true)\n    ///     .attributes(winapi::FILE_ATTRIBUTE_HIDDEN)\n    ///     .open(\"foo.txt\");\n    /// ```\n    ///\n    /// [`CreateFile`]: https://docs.microsoft.com/en-us/windows/win32/api/fileapi/nf-fileapi-createfilea\n    /// [`CreateFile2`]: https://docs.microsoft.com/en-us/windows/win32/api/fileapi/nf-fileapi-createfile2\n    #[stable(feature = \"open_options_ext\", since = \"1.10.0\")]\n    fn attributes(&mut self, val: u32) -> &mut Self;\n\n    /// Sets the `dwSecurityQosFlags` argument to the call to [`CreateFile2`] to\n    /// the specified value (or combines it with `custom_flags` and `attributes`\n    /// to set the `dwFlagsAndAttributes` for [`CreateFile`]).\n    ///\n    /// By default `security_qos_flags` is not set. It should be specified when\n    /// opening a named pipe, to control to which degree a server process can\n    /// act on behalf of a client process (security impersonation level).\n    ///\n    /// When `security_qos_flags` is not set, a malicious program can gain the\n    /// elevated privileges of a privileged Rust process when it allows opening\n    /// user-specified paths, by tricking it into opening a named pipe. So\n    /// arguably `security_qos_flags` should also be set when opening arbitrary\n    /// paths. However the bits can then conflict with other flags, specifically\n    /// `FILE_FLAG_OPEN_NO_RECALL`.\n    ///\n    /// For information about possible values, see [Impersonation Levels] on the\n    /// Windows Dev Center site. The `SECURITY_SQOS_PRESENT` flag is set\n    /// automatically when using this method.\n\n    /// # Examples\n    ///\n    /// ```no_run\n    /// # #[cfg(for_demonstration_only)]\n    /// extern crate winapi;\n    /// # mod winapi { pub const SECURITY_IDENTIFICATION: u32 = 0; }\n    /// use std::fs::OpenOptions;\n    /// use std::os::windows::prelude::*;\n    ///\n    /// let file = OpenOptions::new()\n    ///     .write(true)\n    ///     .create(true)\n    ///\n    ///     // Sets the flag value to `SecurityIdentification`.\n    ///     .security_qos_flags(winapi::SECURITY_IDENTIFICATION)\n    ///\n    ///     .open(r\"\\\\.\\pipe\\MyPipe\");\n    /// ```\n    ///\n    /// [`CreateFile`]: https://docs.microsoft.com/en-us/windows/win32/api/fileapi/nf-fileapi-createfilea\n    /// [`CreateFile2`]: https://docs.microsoft.com/en-us/windows/win32/api/fileapi/nf-fileapi-createfile2\n    /// [Impersonation Levels]:\n    ///     https://docs.microsoft.com/en-us/windows/win32/api/winnt/ne-winnt-security_impersonation_level\n    #[stable(feature = \"open_options_ext\", since = \"1.10.0\")]\n    fn security_qos_flags(&mut self, flags: u32) -> &mut Self;\n}\n\n#[stable(feature = \"open_options_ext\", since = \"1.10.0\")]\nimpl OpenOptionsExt for OpenOptions {\n    fn access_mode(&mut self, access: u32) -> &mut OpenOptions {\n        self.as_inner_mut().access_mode(access);\n        self\n    }\n\n    fn share_mode(&mut self, share: u32) -> &mut OpenOptions {\n        self.as_inner_mut().share_mode(share);\n        self\n    }\n\n    fn custom_flags(&mut self, flags: u32) -> &mut OpenOptions {\n        self.as_inner_mut().custom_flags(flags);\n        self\n    }\n\n    fn attributes(&mut self, attributes: u32) -> &mut OpenOptions {\n        self.as_inner_mut().attributes(attributes);\n        self\n    }\n\n    fn security_qos_flags(&mut self, flags: u32) -> &mut OpenOptions {\n        self.as_inner_mut().security_qos_flags(flags);\n        self\n    }\n}\n\n/// Windows-specific extensions to [`fs::Metadata`].\n///\n/// The data members that this trait exposes correspond to the members\n/// of the [`BY_HANDLE_FILE_INFORMATION`] structure.\n///\n/// [`BY_HANDLE_FILE_INFORMATION`]:\n///     https://docs.microsoft.com/en-us/windows/win32/api/fileapi/ns-fileapi-by_handle_file_information\n#[stable(feature = \"metadata_ext\", since = \"1.1.0\")]\npub trait MetadataExt {\n    /// Returns the value of the `dwFileAttributes` field of this metadata.\n    ///\n    /// This field contains the file system attribute information for a file\n    /// or directory. For possible values and their descriptions, see\n    /// [File Attribute Constants] in the Windows Dev Center.\n    ///\n    /// # Examples\n    ///\n    /// ```no_run\n    /// use std::io;\n    /// use std::fs;\n    /// use std::os::windows::prelude::*;\n    ///\n    /// fn main() -> io::Result<()> {\n    ///     let metadata = fs::metadata(\"foo.txt\")?;\n    ///     let attributes = metadata.file_attributes();\n    ///     Ok(())\n    /// }\n    /// ```\n    ///\n    /// [File Attribute Constants]:\n    ///     https://docs.microsoft.com/en-us/windows/win32/fileio/file-attribute-constants\n    #[stable(feature = \"metadata_ext\", since = \"1.1.0\")]\n    fn file_attributes(&self) -> u32;\n\n    /// Returns the value of the `ftCreationTime` field of this metadata.\n    ///\n    /// The returned 64-bit value is equivalent to a [`FILETIME`] struct,\n    /// which represents the number of 100-nanosecond intervals since\n    /// January 1, 1601 (UTC). The struct is automatically\n    /// converted to a `u64` value, as that is the recommended way\n    /// to use it.\n    ///\n    /// If the underlying filesystem does not support creation time, the\n    /// returned value is 0.\n    ///\n    /// # Examples\n    ///\n    /// ```no_run\n    /// use std::io;\n    /// use std::fs;\n    /// use std::os::windows::prelude::*;\n    ///\n    /// fn main() -> io::Result<()> {\n    ///     let metadata = fs::metadata(\"foo.txt\")?;\n    ///     let creation_time = metadata.creation_time();\n    ///     Ok(())\n    /// }\n    /// ```\n    ///\n    /// [`FILETIME`]: https://docs.microsoft.com/en-us/windows/win32/api/minwinbase/ns-minwinbase-filetime\n    #[stable(feature = \"metadata_ext\", since = \"1.1.0\")]\n    fn creation_time(&self) -> u64;\n\n    /// Returns the value of the `ftLastAccessTime` field of this metadata.\n    ///\n    /// The returned 64-bit value is equivalent to a [`FILETIME`] struct,\n    /// which represents the number of 100-nanosecond intervals since\n    /// January 1, 1601 (UTC). The struct is automatically\n    /// converted to a `u64` value, as that is the recommended way\n    /// to use it.\n    ///\n    /// For a file, the value specifies the last time that a file was read\n    /// from or written to. For a directory, the value specifies when\n    /// the directory was created. For both files and directories, the\n    /// specified date is correct, but the time of day is always set to\n    /// midnight.\n    ///\n    /// If the underlying filesystem does not support last access time, the\n    /// returned value is 0.\n    ///\n    /// # Examples\n    ///\n    /// ```no_run\n    /// use std::io;\n    /// use std::fs;\n    /// use std::os::windows::prelude::*;\n    ///\n    /// fn main() -> io::Result<()> {\n    ///     let metadata = fs::metadata(\"foo.txt\")?;\n    ///     let last_access_time = metadata.last_access_time();\n    ///     Ok(())\n    /// }\n    /// ```\n    ///\n    /// [`FILETIME`]: https://docs.microsoft.com/en-us/windows/win32/api/minwinbase/ns-minwinbase-filetime\n    #[stable(feature = \"metadata_ext\", since = \"1.1.0\")]\n    fn last_access_time(&self) -> u64;\n\n    /// Returns the value of the `ftLastWriteTime` field of this metadata.\n    ///\n    /// The returned 64-bit value is equivalent to a [`FILETIME`] struct,\n    /// which represents the number of 100-nanosecond intervals since\n    /// January 1, 1601 (UTC). The struct is automatically\n    /// converted to a `u64` value, as that is the recommended way\n    /// to use it.\n    ///\n    /// For a file, the value specifies the last time that a file was written\n    /// to. For a directory, the structure specifies when the directory was\n    /// created.\n    ///\n    /// If the underlying filesystem does not support the last write time,\n    /// the returned value is 0.\n    ///\n    /// # Examples\n    ///\n    /// ```no_run\n    /// use std::io;\n    /// use std::fs;\n    /// use std::os::windows::prelude::*;\n    ///\n    /// fn main() -> io::Result<()> {\n    ///     let metadata = fs::metadata(\"foo.txt\")?;\n    ///     let last_write_time = metadata.last_write_time();\n    ///     Ok(())\n    /// }\n    /// ```\n    ///\n    /// [`FILETIME`]: https://docs.microsoft.com/en-us/windows/win32/api/minwinbase/ns-minwinbase-filetime\n    #[stable(feature = \"metadata_ext\", since = \"1.1.0\")]\n    fn last_write_time(&self) -> u64;\n\n    /// Returns the value of the `nFileSize{High,Low}` fields of this\n    /// metadata.\n    ///\n    /// The returned value does not have meaning for directories.\n    ///\n    /// # Examples\n    ///\n    /// ```no_run\n    /// use std::io;\n    /// use std::fs;\n    /// use std::os::windows::prelude::*;\n    ///\n    /// fn main() -> io::Result<()> {\n    ///     let metadata = fs::metadata(\"foo.txt\")?;\n    ///     let file_size = metadata.file_size();\n    ///     Ok(())\n    /// }\n    /// ```\n    #[stable(feature = \"metadata_ext\", since = \"1.1.0\")]\n    fn file_size(&self) -> u64;\n\n    /// Returns the value of the `dwVolumeSerialNumber` field of this\n    /// metadata.\n    ///\n    /// This will return `None` if the `Metadata` instance was created from a\n    /// call to `DirEntry::metadata`. If this `Metadata` was created by using\n    /// `fs::metadata` or `File::metadata`, then this will return `Some`.\n    #[unstable(feature = \"windows_by_handle\", issue = \"63010\")]\n    fn volume_serial_number(&self) -> Option<u32>;\n\n    /// Returns the value of the `nNumberOfLinks` field of this\n    /// metadata.\n    ///\n    /// This will return `None` if the `Metadata` instance was created from a\n    /// call to `DirEntry::metadata`. If this `Metadata` was created by using\n    /// `fs::metadata` or `File::metadata`, then this will return `Some`.\n    #[unstable(feature = \"windows_by_handle\", issue = \"63010\")]\n    fn number_of_links(&self) -> Option<u32>;\n\n    /// Returns the value of the `nFileIndex{Low,High}` fields of this\n    /// metadata.\n    ///\n    /// This will return `None` if the `Metadata` instance was created from a\n    /// call to `DirEntry::metadata`. If this `Metadata` was created by using\n    /// `fs::metadata` or `File::metadata`, then this will return `Some`.\n    #[unstable(feature = \"windows_by_handle\", issue = \"63010\")]\n    fn file_index(&self) -> Option<u64>;\n}\n\n#[stable(feature = \"metadata_ext\", since = \"1.1.0\")]\nimpl MetadataExt for Metadata {\n    fn file_attributes(&self) -> u32 {\n        self.as_inner().attrs()\n    }\n    fn creation_time(&self) -> u64 {\n        self.as_inner().created_u64()\n    }\n    fn last_access_time(&self) -> u64 {\n        self.as_inner().accessed_u64()\n    }\n    fn last_write_time(&self) -> u64 {\n        self.as_inner().modified_u64()\n    }\n    fn file_size(&self) -> u64 {\n        self.as_inner().size()\n    }\n    fn volume_serial_number(&self) -> Option<u32> {\n        self.as_inner().volume_serial_number()\n    }\n    fn number_of_links(&self) -> Option<u32> {\n        self.as_inner().number_of_links()\n    }\n    fn file_index(&self) -> Option<u64> {\n        self.as_inner().file_index()\n    }\n}\n\n/// Windows-specific extensions to [`fs::FileType`].\n///\n/// On Windows, a symbolic link knows whether it is a file or directory.\n#[unstable(feature = \"windows_file_type_ext\", issue = \"none\")]\npub trait FileTypeExt {\n    /// Returns `true` if this file type is a symbolic link that is also a directory.\n    #[unstable(feature = \"windows_file_type_ext\", issue = \"none\")]\n    fn is_symlink_dir(&self) -> bool;\n    /// Returns `true` if this file type is a symbolic link that is also a file.\n    #[unstable(feature = \"windows_file_type_ext\", issue = \"none\")]\n    fn is_symlink_file(&self) -> bool;\n}\n\n#[unstable(feature = \"windows_file_type_ext\", issue = \"none\")]\nimpl FileTypeExt for fs::FileType {\n    fn is_symlink_dir(&self) -> bool {\n        self.as_inner().is_symlink_dir()\n    }\n    fn is_symlink_file(&self) -> bool {\n        self.as_inner().is_symlink_file()\n    }\n}\n\n/// Creates a new file symbolic link on the filesystem.\n///\n/// The `link` path will be a file symbolic link pointing to the `original`\n/// path.\n///\n/// # Examples\n///\n/// ```no_run\n/// use std::os::windows::fs;\n///\n/// fn main() -> std::io::Result<()> {\n///     fs::symlink_file(\"a.txt\", \"b.txt\")?;\n///     Ok(())\n/// }\n/// ```\n#[stable(feature = \"symlink\", since = \"1.1.0\")]\npub fn symlink_file<P: AsRef<Path>, Q: AsRef<Path>>(original: P, link: Q) -> io::Result<()> {\n    sys::fs::symlink_inner(original.as_ref(), link.as_ref(), false)\n}\n\n/// Creates a new directory symlink on the filesystem.\n///\n/// The `link` path will be a directory symbolic link pointing to the `original`\n/// path.\n///\n/// # Examples\n///\n/// ```no_run\n/// use std::os::windows::fs;\n///\n/// fn main() -> std::io::Result<()> {\n///     fs::symlink_dir(\"a\", \"b\")?;\n///     Ok(())\n/// }\n/// ```\n#[stable(feature = \"symlink\", since = \"1.1.0\")]\npub fn symlink_dir<P: AsRef<Path>, Q: AsRef<Path>>(original: P, link: Q) -> io::Result<()> {\n    sys::fs::symlink_inner(original.as_ref(), link.as_ref(), true)\n}\n"],[2190,"//! Extensions to `std::thread` for Windows.\n\n#![stable(feature = \"thread_extensions\", since = \"1.9.0\")]\n\nuse crate::os::windows::io::{AsRawHandle, IntoRawHandle, RawHandle};\nuse crate::sys_common::{AsInner, IntoInner};\nuse crate::thread;\n\n#[stable(feature = \"thread_extensions\", since = \"1.9.0\")]\nimpl<T> AsRawHandle for thread::JoinHandle<T> {\n    #[inline]\n    fn as_raw_handle(&self) -> RawHandle {\n        self.as_inner().handle().raw() as *mut _\n    }\n}\n\n#[stable(feature = \"thread_extensions\", since = \"1.9.0\")]\nimpl<T> IntoRawHandle for thread::JoinHandle<T> {\n    #[inline]\n    fn into_raw_handle(self) -> RawHandle {\n        self.into_inner().into_handle().into_raw() as *mut _\n    }\n}\n"],[2191,"//! Platform-specific extensions to `std` for Windows.\n//!\n//! Provides access to platform-level information for Windows, and exposes\n//! Windows-specific idioms that would otherwise be inappropriate as part\n//! the core `std` library. These extensions allow developers to use\n//! `std` types and idioms with Windows in a way that the normal\n//! platform-agnostic idioms would not normally support.\n\n#![stable(feature = \"rust1\", since = \"1.0.0\")]\n#![doc(cfg(windows))]\n\npub mod ffi;\npub mod fs;\npub mod io;\npub mod process;\npub mod raw;\npub mod thread;\n\n/// A prelude for conveniently writing platform-specific code.\n///\n/// Includes all extension traits, and some important type definitions.\n#[stable(feature = \"rust1\", since = \"1.0.0\")]\npub mod prelude {\n    #[doc(no_inline)]\n    #[stable(feature = \"rust1\", since = \"1.0.0\")]\n    pub use super::ffi::{OsStrExt, OsStringExt};\n    #[doc(no_inline)]\n    #[stable(feature = \"file_offset\", since = \"1.15.0\")]\n    pub use super::fs::FileExt;\n    #[doc(no_inline)]\n    #[stable(feature = \"rust1\", since = \"1.0.0\")]\n    pub use super::fs::{MetadataExt, OpenOptionsExt};\n    #[doc(no_inline)]\n    #[stable(feature = \"rust1\", since = \"1.0.0\")]\n    pub use super::io::{AsRawHandle, AsRawSocket, RawHandle, RawSocket};\n    #[doc(no_inline)]\n    #[stable(feature = \"rust1\", since = \"1.0.0\")]\n    pub use super::io::{FromRawHandle, FromRawSocket, IntoRawHandle, IntoRawSocket};\n}\n"],[2192,"//! Extensions to `std::process` for Windows.\n\n#![stable(feature = \"process_extensions\", since = \"1.2.0\")]\n\nuse crate::os::windows::io::{AsRawHandle, FromRawHandle, IntoRawHandle, RawHandle};\nuse crate::process;\nuse crate::sealed::Sealed;\nuse crate::sys;\nuse crate::sys_common::{AsInner, AsInnerMut, FromInner, IntoInner};\n\n#[stable(feature = \"process_extensions\", since = \"1.2.0\")]\nimpl FromRawHandle for process::Stdio {\n    unsafe fn from_raw_handle(handle: RawHandle) -> process::Stdio {\n        let handle = sys::handle::Handle::new(handle as *mut _);\n        let io = sys::process::Stdio::Handle(handle);\n        process::Stdio::from_inner(io)\n    }\n}\n\n#[stable(feature = \"process_extensions\", since = \"1.2.0\")]\nimpl AsRawHandle for process::Child {\n    #[inline]\n    fn as_raw_handle(&self) -> RawHandle {\n        self.as_inner().handle().raw() as *mut _\n    }\n}\n\n#[stable(feature = \"into_raw_os\", since = \"1.4.0\")]\nimpl IntoRawHandle for process::Child {\n    fn into_raw_handle(self) -> RawHandle {\n        self.into_inner().into_handle().into_raw() as *mut _\n    }\n}\n\n#[stable(feature = \"process_extensions\", since = \"1.2.0\")]\nimpl AsRawHandle for process::ChildStdin {\n    #[inline]\n    fn as_raw_handle(&self) -> RawHandle {\n        self.as_inner().handle().raw() as *mut _\n    }\n}\n\n#[stable(feature = \"process_extensions\", since = \"1.2.0\")]\nimpl AsRawHandle for process::ChildStdout {\n    #[inline]\n    fn as_raw_handle(&self) -> RawHandle {\n        self.as_inner().handle().raw() as *mut _\n    }\n}\n\n#[stable(feature = \"process_extensions\", since = \"1.2.0\")]\nimpl AsRawHandle for process::ChildStderr {\n    #[inline]\n    fn as_raw_handle(&self) -> RawHandle {\n        self.as_inner().handle().raw() as *mut _\n    }\n}\n\n#[stable(feature = \"into_raw_os\", since = \"1.4.0\")]\nimpl IntoRawHandle for process::ChildStdin {\n    fn into_raw_handle(self) -> RawHandle {\n        self.into_inner().into_handle().into_raw() as *mut _\n    }\n}\n\n#[stable(feature = \"into_raw_os\", since = \"1.4.0\")]\nimpl IntoRawHandle for process::ChildStdout {\n    fn into_raw_handle(self) -> RawHandle {\n        self.into_inner().into_handle().into_raw() as *mut _\n    }\n}\n\n#[stable(feature = \"into_raw_os\", since = \"1.4.0\")]\nimpl IntoRawHandle for process::ChildStderr {\n    fn into_raw_handle(self) -> RawHandle {\n        self.into_inner().into_handle().into_raw() as *mut _\n    }\n}\n\n/// Windows-specific extensions to [`process::ExitStatus`].\n///\n/// This trait is sealed: it cannot be implemented outside the standard library.\n/// This is so that future additional methods are not breaking changes.\n#[stable(feature = \"exit_status_from\", since = \"1.12.0\")]\npub trait ExitStatusExt: Sealed {\n    /// Creates a new `ExitStatus` from the raw underlying `u32` return value of\n    /// a process.\n    #[stable(feature = \"exit_status_from\", since = \"1.12.0\")]\n    fn from_raw(raw: u32) -> Self;\n}\n\n#[stable(feature = \"exit_status_from\", since = \"1.12.0\")]\nimpl ExitStatusExt for process::ExitStatus {\n    fn from_raw(raw: u32) -> Self {\n        process::ExitStatus::from_inner(From::from(raw))\n    }\n}\n\n/// Windows-specific extensions to the [`process::Command`] builder.\n///\n/// This trait is sealed: it cannot be implemented outside the standard library.\n/// This is so that future additional methods are not breaking changes.\n#[stable(feature = \"windows_process_extensions\", since = \"1.16.0\")]\npub trait CommandExt: Sealed {\n    /// Sets the [process creation flags][1] to be passed to `CreateProcess`.\n    ///\n    /// These will always be ORed with `CREATE_UNICODE_ENVIRONMENT`.\n    ///\n    /// [1]: https://docs.microsoft.com/en-us/windows/win32/procthread/process-creation-flags\n    #[stable(feature = \"windows_process_extensions\", since = \"1.16.0\")]\n    fn creation_flags(&mut self, flags: u32) -> &mut process::Command;\n\n    /// Forces all arguments to be wrapped in quote (`\"`) characters.\n    ///\n    /// This is useful for passing arguments to [MSYS2/Cygwin][1] based\n    /// executables: these programs will expand unquoted arguments containing\n    /// wildcard characters (`?` and `*`) by searching for any file paths\n    /// matching the wildcard pattern.\n    ///\n    /// Adding quotes has no effect when passing arguments to programs\n    /// that use [msvcrt][2]. This includes programs built with both\n    /// MinGW and MSVC.\n    ///\n    /// [1]: <https://github.com/msys2/MSYS2-packages/issues/2176>\n    /// [2]: <https://msdn.microsoft.com/en-us/library/17w5ykft.aspx>\n    #[unstable(feature = \"windows_process_extensions_force_quotes\", issue = \"82227\")]\n    fn force_quotes(&mut self, enabled: bool) -> &mut process::Command;\n}\n\n#[stable(feature = \"windows_process_extensions\", since = \"1.16.0\")]\nimpl CommandExt for process::Command {\n    fn creation_flags(&mut self, flags: u32) -> &mut process::Command {\n        self.as_inner_mut().creation_flags(flags);\n        self\n    }\n\n    fn force_quotes(&mut self, enabled: bool) -> &mut process::Command {\n        self.as_inner_mut().force_quotes(enabled);\n        self\n    }\n}\n"],[2193,"//! Windows-specific extensions to the primitives in the `std::ffi` module.\n//!\n//! # Overview\n//!\n//! For historical reasons, the Windows API uses a form of potentially\n//! ill-formed UTF-16 encoding for strings. Specifically, the 16-bit\n//! code units in Windows strings may contain [isolated surrogate code\n//! points which are not paired together][ill-formed-utf-16]. The\n//! Unicode standard requires that surrogate code points (those in the\n//! range U+D800 to U+DFFF) always be *paired*, because in the UTF-16\n//! encoding a *surrogate code unit pair* is used to encode a single\n//! character. For compatibility with code that does not enforce\n//! these pairings, Windows does not enforce them, either.\n//!\n//! While it is not always possible to convert such a string losslessly into\n//! a valid UTF-16 string (or even UTF-8), it is often desirable to be\n//! able to round-trip such a string from and to Windows APIs\n//! losslessly. For example, some Rust code may be \"bridging\" some\n//! Windows APIs together, just passing `WCHAR` strings among those\n//! APIs without ever really looking into the strings.\n//!\n//! If Rust code *does* need to look into those strings, it can\n//! convert them to valid UTF-8, possibly lossily, by substituting\n//! invalid sequences with [`U+FFFD REPLACEMENT CHARACTER`][U+FFFD], as is\n//! conventionally done in other Rust APIs that deal with string\n//! encodings.\n//!\n//! # `OsStringExt` and `OsStrExt`\n//!\n//! [`OsString`] is the Rust wrapper for owned strings in the\n//! preferred representation of the operating system. On Windows,\n//! this struct gets augmented with an implementation of the\n//! [`OsStringExt`] trait, which has a [`OsStringExt::from_wide`] method. This\n//! lets you create an [`OsString`] from a `&[u16]` slice; presumably\n//! you get such a slice out of a `WCHAR` Windows API.\n//!\n//! Similarly, [`OsStr`] is the Rust wrapper for borrowed strings from\n//! preferred representation of the operating system. On Windows, the\n//! [`OsStrExt`] trait provides the [`OsStrExt::encode_wide`] method, which\n//! outputs an [`EncodeWide`] iterator. You can [`collect`] this\n//! iterator, for example, to obtain a `Vec<u16>`; you can later get a\n//! pointer to this vector's contents and feed it to Windows APIs.\n//!\n//! These traits, along with [`OsString`] and [`OsStr`], work in\n//! conjunction so that it is possible to **round-trip** strings from\n//! Windows and back, with no loss of data, even if the strings are\n//! ill-formed UTF-16.\n//!\n//! [ill-formed-utf-16]: https://simonsapin.github.io/wtf-8/#ill-formed-utf-16\n//! [`collect`]: crate::iter::Iterator::collect\n//! [U+FFFD]: crate::char::REPLACEMENT_CHARACTER\n\n#![stable(feature = \"rust1\", since = \"1.0.0\")]\n\nuse crate::ffi::{OsStr, OsString};\nuse crate::sealed::Sealed;\nuse crate::sys::os_str::Buf;\nuse crate::sys_common::wtf8::Wtf8Buf;\nuse crate::sys_common::{AsInner, FromInner};\n\n#[stable(feature = \"rust1\", since = \"1.0.0\")]\npub use crate::sys_common::wtf8::EncodeWide;\n\n/// Windows-specific extensions to [`OsString`].\n///\n/// This trait is sealed: it cannot be implemented outside the standard library.\n/// This is so that future additional methods are not breaking changes.\n#[stable(feature = \"rust1\", since = \"1.0.0\")]\npub trait OsStringExt: Sealed {\n    /// Creates an `OsString` from a potentially ill-formed UTF-16 slice of\n    /// 16-bit code units.\n    ///\n    /// This is lossless: calling [`OsStrExt::encode_wide`] on the resulting string\n    /// will always return the original code units.\n    ///\n    /// # Examples\n    ///\n    /// ```\n    /// use std::ffi::OsString;\n    /// use std::os::windows::prelude::*;\n    ///\n    /// // UTF-16 encoding for \"Unicode\".\n    /// let source = [0x0055, 0x006E, 0x0069, 0x0063, 0x006F, 0x0064, 0x0065];\n    ///\n    /// let string = OsString::from_wide(&source[..]);\n    /// ```\n    #[stable(feature = \"rust1\", since = \"1.0.0\")]\n    fn from_wide(wide: &[u16]) -> Self;\n}\n\n#[stable(feature = \"rust1\", since = \"1.0.0\")]\nimpl OsStringExt for OsString {\n    fn from_wide(wide: &[u16]) -> OsString {\n        FromInner::from_inner(Buf { inner: Wtf8Buf::from_wide(wide) })\n    }\n}\n\n/// Windows-specific extensions to [`OsStr`].\n///\n/// This trait is sealed: it cannot be implemented outside the standard library.\n/// This is so that future additional methods are not breaking changes.\n#[stable(feature = \"rust1\", since = \"1.0.0\")]\npub trait OsStrExt: Sealed {\n    /// Re-encodes an `OsStr` as a wide character sequence, i.e., potentially\n    /// ill-formed UTF-16.\n    ///\n    /// This is lossless: calling [`OsStringExt::from_wide`] and then\n    /// `encode_wide` on the result will yield the original code units.\n    /// Note that the encoding does not add a final null terminator.\n    ///\n    /// # Examples\n    ///\n    /// ```\n    /// use std::ffi::OsString;\n    /// use std::os::windows::prelude::*;\n    ///\n    /// // UTF-16 encoding for \"Unicode\".\n    /// let source = [0x0055, 0x006E, 0x0069, 0x0063, 0x006F, 0x0064, 0x0065];\n    ///\n    /// let string = OsString::from_wide(&source[..]);\n    ///\n    /// let result: Vec<u16> = string.encode_wide().collect();\n    /// assert_eq!(&source[..], &result[..]);\n    /// ```\n    #[stable(feature = \"rust1\", since = \"1.0.0\")]\n    fn encode_wide(&self) -> EncodeWide<'_>;\n}\n\n#[stable(feature = \"rust1\", since = \"1.0.0\")]\nimpl OsStrExt for OsStr {\n    fn encode_wide(&self) -> EncodeWide<'_> {\n        self.as_inner().inner.encode_wide()\n    }\n}\n"],[2194,"//! Windows-specific extensions to general I/O primitives.\n\n#![stable(feature = \"rust1\", since = \"1.0.0\")]\n\nuse crate::fs;\nuse crate::io;\nuse crate::net;\nuse crate::os::windows::raw;\nuse crate::sys;\nuse crate::sys::c;\nuse crate::sys_common::{self, AsInner, FromInner, IntoInner};\n\n/// Raw HANDLEs.\n#[stable(feature = \"rust1\", since = \"1.0.0\")]\npub type RawHandle = raw::HANDLE;\n\n/// Raw SOCKETs.\n#[stable(feature = \"rust1\", since = \"1.0.0\")]\npub type RawSocket = raw::SOCKET;\n\n/// Extracts raw handles.\n#[stable(feature = \"rust1\", since = \"1.0.0\")]\npub trait AsRawHandle {\n    /// Extracts the raw handle, without taking any ownership.\n    #[stable(feature = \"rust1\", since = \"1.0.0\")]\n    fn as_raw_handle(&self) -> RawHandle;\n}\n\n/// Construct I/O objects from raw handles.\n#[stable(feature = \"from_raw_os\", since = \"1.1.0\")]\npub trait FromRawHandle {\n    /// Constructs a new I/O object from the specified raw handle.\n    ///\n    /// This function will **consume ownership** of the handle given,\n    /// passing responsibility for closing the handle to the returned\n    /// object.\n    ///\n    /// This function is also unsafe as the primitives currently returned\n    /// have the contract that they are the sole owner of the file\n    /// descriptor they are wrapping. Usage of this function could\n    /// accidentally allow violating this contract which can cause memory\n    /// unsafety in code that relies on it being true.\n    #[stable(feature = \"from_raw_os\", since = \"1.1.0\")]\n    unsafe fn from_raw_handle(handle: RawHandle) -> Self;\n}\n\n/// A trait to express the ability to consume an object and acquire ownership of\n/// its raw `HANDLE`.\n#[stable(feature = \"into_raw_os\", since = \"1.4.0\")]\npub trait IntoRawHandle {\n    /// Consumes this object, returning the raw underlying handle.\n    ///\n    /// This function **transfers ownership** of the underlying handle to the\n    /// caller. Callers are then the unique owners of the handle and must close\n    /// it once it's no longer needed.\n    #[stable(feature = \"into_raw_os\", since = \"1.4.0\")]\n    fn into_raw_handle(self) -> RawHandle;\n}\n\n#[stable(feature = \"rust1\", since = \"1.0.0\")]\nimpl AsRawHandle for fs::File {\n    #[inline]\n    fn as_raw_handle(&self) -> RawHandle {\n        self.as_inner().handle().raw() as RawHandle\n    }\n}\n\n#[stable(feature = \"asraw_stdio\", since = \"1.21.0\")]\nimpl AsRawHandle for io::Stdin {\n    fn as_raw_handle(&self) -> RawHandle {\n        unsafe { c::GetStdHandle(c::STD_INPUT_HANDLE) as RawHandle }\n    }\n}\n\n#[stable(feature = \"asraw_stdio\", since = \"1.21.0\")]\nimpl AsRawHandle for io::Stdout {\n    fn as_raw_handle(&self) -> RawHandle {\n        unsafe { c::GetStdHandle(c::STD_OUTPUT_HANDLE) as RawHandle }\n    }\n}\n\n#[stable(feature = \"asraw_stdio\", since = \"1.21.0\")]\nimpl AsRawHandle for io::Stderr {\n    fn as_raw_handle(&self) -> RawHandle {\n        unsafe { c::GetStdHandle(c::STD_ERROR_HANDLE) as RawHandle }\n    }\n}\n\n#[stable(feature = \"asraw_stdio_locks\", since = \"1.35.0\")]\nimpl<'a> AsRawHandle for io::StdinLock<'a> {\n    fn as_raw_handle(&self) -> RawHandle {\n        unsafe { c::GetStdHandle(c::STD_INPUT_HANDLE) as RawHandle }\n    }\n}\n\n#[stable(feature = \"asraw_stdio_locks\", since = \"1.35.0\")]\nimpl<'a> AsRawHandle for io::StdoutLock<'a> {\n    fn as_raw_handle(&self) -> RawHandle {\n        unsafe { c::GetStdHandle(c::STD_OUTPUT_HANDLE) as RawHandle }\n    }\n}\n\n#[stable(feature = \"asraw_stdio_locks\", since = \"1.35.0\")]\nimpl<'a> AsRawHandle for io::StderrLock<'a> {\n    fn as_raw_handle(&self) -> RawHandle {\n        unsafe { c::GetStdHandle(c::STD_ERROR_HANDLE) as RawHandle }\n    }\n}\n\n#[stable(feature = \"from_raw_os\", since = \"1.1.0\")]\nimpl FromRawHandle for fs::File {\n    #[inline]\n    unsafe fn from_raw_handle(handle: RawHandle) -> fs::File {\n        let handle = handle as c::HANDLE;\n        fs::File::from_inner(sys::fs::File::from_inner(handle))\n    }\n}\n\n#[stable(feature = \"into_raw_os\", since = \"1.4.0\")]\nimpl IntoRawHandle for fs::File {\n    #[inline]\n    fn into_raw_handle(self) -> RawHandle {\n        self.into_inner().into_handle().into_raw() as *mut _\n    }\n}\n\n/// Extracts raw sockets.\n#[stable(feature = \"rust1\", since = \"1.0.0\")]\npub trait AsRawSocket {\n    /// Extracts the underlying raw socket from this object.\n    #[stable(feature = \"rust1\", since = \"1.0.0\")]\n    fn as_raw_socket(&self) -> RawSocket;\n}\n\n/// Creates I/O objects from raw sockets.\n#[stable(feature = \"from_raw_os\", since = \"1.1.0\")]\npub trait FromRawSocket {\n    /// Creates a new I/O object from the given raw socket.\n    ///\n    /// This function will **consume ownership** of the socket provided and\n    /// it will be closed when the returned object goes out of scope.\n    ///\n    /// This function is also unsafe as the primitives currently returned\n    /// have the contract that they are the sole owner of the file\n    /// descriptor they are wrapping. Usage of this function could\n    /// accidentally allow violating this contract which can cause memory\n    /// unsafety in code that relies on it being true.\n    #[stable(feature = \"from_raw_os\", since = \"1.1.0\")]\n    unsafe fn from_raw_socket(sock: RawSocket) -> Self;\n}\n\n/// A trait to express the ability to consume an object and acquire ownership of\n/// its raw `SOCKET`.\n#[stable(feature = \"into_raw_os\", since = \"1.4.0\")]\npub trait IntoRawSocket {\n    /// Consumes this object, returning the raw underlying socket.\n    ///\n    /// This function **transfers ownership** of the underlying socket to the\n    /// caller. Callers are then the unique owners of the socket and must close\n    /// it once it's no longer needed.\n    #[stable(feature = \"into_raw_os\", since = \"1.4.0\")]\n    fn into_raw_socket(self) -> RawSocket;\n}\n\n#[stable(feature = \"rust1\", since = \"1.0.0\")]\nimpl AsRawSocket for net::TcpStream {\n    #[inline]\n    fn as_raw_socket(&self) -> RawSocket {\n        *self.as_inner().socket().as_inner()\n    }\n}\n#[stable(feature = \"rust1\", since = \"1.0.0\")]\nimpl AsRawSocket for net::TcpListener {\n    #[inline]\n    fn as_raw_socket(&self) -> RawSocket {\n        *self.as_inner().socket().as_inner()\n    }\n}\n#[stable(feature = \"rust1\", since = \"1.0.0\")]\nimpl AsRawSocket for net::UdpSocket {\n    #[inline]\n    fn as_raw_socket(&self) -> RawSocket {\n        *self.as_inner().socket().as_inner()\n    }\n}\n\n#[stable(feature = \"from_raw_os\", since = \"1.1.0\")]\nimpl FromRawSocket for net::TcpStream {\n    #[inline]\n    unsafe fn from_raw_socket(sock: RawSocket) -> net::TcpStream {\n        let sock = sys::net::Socket::from_inner(sock);\n        net::TcpStream::from_inner(sys_common::net::TcpStream::from_inner(sock))\n    }\n}\n#[stable(feature = \"from_raw_os\", since = \"1.1.0\")]\nimpl FromRawSocket for net::TcpListener {\n    #[inline]\n    unsafe fn from_raw_socket(sock: RawSocket) -> net::TcpListener {\n        let sock = sys::net::Socket::from_inner(sock);\n        net::TcpListener::from_inner(sys_common::net::TcpListener::from_inner(sock))\n    }\n}\n#[stable(feature = \"from_raw_os\", since = \"1.1.0\")]\nimpl FromRawSocket for net::UdpSocket {\n    #[inline]\n    unsafe fn from_raw_socket(sock: RawSocket) -> net::UdpSocket {\n        let sock = sys::net::Socket::from_inner(sock);\n        net::UdpSocket::from_inner(sys_common::net::UdpSocket::from_inner(sock))\n    }\n}\n\n#[stable(feature = \"into_raw_os\", since = \"1.4.0\")]\nimpl IntoRawSocket for net::TcpStream {\n    #[inline]\n    fn into_raw_socket(self) -> RawSocket {\n        self.into_inner().into_socket().into_inner()\n    }\n}\n\n#[stable(feature = \"into_raw_os\", since = \"1.4.0\")]\nimpl IntoRawSocket for net::TcpListener {\n    #[inline]\n    fn into_raw_socket(self) -> RawSocket {\n        self.into_inner().into_socket().into_inner()\n    }\n}\n\n#[stable(feature = \"into_raw_os\", since = \"1.4.0\")]\nimpl IntoRawSocket for net::UdpSocket {\n    #[inline]\n    fn into_raw_socket(self) -> RawSocket {\n        self.into_inner().into_socket().into_inner()\n    }\n}\n"],[2195,"//! illumos-specific definitions\n\n#![stable(feature = \"raw_ext\", since = \"1.1.0\")]\n\npub mod fs;\npub mod raw;\n"],[2196,"#![stable(feature = \"metadata_ext\", since = \"1.1.0\")]\n\nuse crate::fs::Metadata;\nuse crate::sys_common::AsInner;\n\n#[allow(deprecated)]\nuse crate::os::illumos::raw;\n\n/// OS-specific extensions to [`fs::Metadata`].\n///\n/// [`fs::Metadata`]: crate::fs::Metadata\n#[stable(feature = \"metadata_ext\", since = \"1.1.0\")]\npub trait MetadataExt {\n    /// Gain a reference to the underlying `stat` structure which contains\n    /// the raw information returned by the OS.\n    ///\n    /// The contents of the returned `stat` are **not** consistent across\n    /// Unix platforms. The `os::unix::fs::MetadataExt` trait contains the\n    /// cross-Unix abstractions contained within the raw stat.\n    #[stable(feature = \"metadata_ext\", since = \"1.1.0\")]\n    #[rustc_deprecated(\n        since = \"1.8.0\",\n        reason = \"deprecated in favor of the accessor methods of this trait\"\n    )]\n    #[allow(deprecated)]\n    fn as_raw_stat(&self) -> &raw::stat;\n\n    #[stable(feature = \"metadata_ext2\", since = \"1.8.0\")]\n    fn st_dev(&self) -> u64;\n    #[stable(feature = \"metadata_ext2\", since = \"1.8.0\")]\n    fn st_ino(&self) -> u64;\n    #[stable(feature = \"metadata_ext2\", since = \"1.8.0\")]\n    fn st_mode(&self) -> u32;\n    #[stable(feature = \"metadata_ext2\", since = \"1.8.0\")]\n    fn st_nlink(&self) -> u64;\n    #[stable(feature = \"metadata_ext2\", since = \"1.8.0\")]\n    fn st_uid(&self) -> u32;\n    #[stable(feature = \"metadata_ext2\", since = \"1.8.0\")]\n    fn st_gid(&self) -> u32;\n    #[stable(feature = \"metadata_ext2\", since = \"1.8.0\")]\n    fn st_rdev(&self) -> u64;\n    #[stable(feature = \"metadata_ext2\", since = \"1.8.0\")]\n    fn st_size(&self) -> u64;\n    #[stable(feature = \"metadata_ext2\", since = \"1.8.0\")]\n    fn st_atime(&self) -> i64;\n    #[stable(feature = \"metadata_ext2\", since = \"1.8.0\")]\n    fn st_atime_nsec(&self) -> i64;\n    #[stable(feature = \"metadata_ext2\", since = \"1.8.0\")]\n    fn st_mtime(&self) -> i64;\n    #[stable(feature = \"metadata_ext2\", since = \"1.8.0\")]\n    fn st_mtime_nsec(&self) -> i64;\n    #[stable(feature = \"metadata_ext2\", since = \"1.8.0\")]\n    fn st_ctime(&self) -> i64;\n    #[stable(feature = \"metadata_ext2\", since = \"1.8.0\")]\n    fn st_ctime_nsec(&self) -> i64;\n    #[stable(feature = \"metadata_ext2\", since = \"1.8.0\")]\n    fn st_blksize(&self) -> u64;\n    #[stable(feature = \"metadata_ext2\", since = \"1.8.0\")]\n    fn st_blocks(&self) -> u64;\n}\n\n#[stable(feature = \"metadata_ext\", since = \"1.1.0\")]\nimpl MetadataExt for Metadata {\n    #[allow(deprecated)]\n    fn as_raw_stat(&self) -> &raw::stat {\n        unsafe { &*(self.as_inner().as_inner() as *const libc::stat as *const raw::stat) }\n    }\n    fn st_dev(&self) -> u64 {\n        self.as_inner().as_inner().st_dev as u64\n    }\n    fn st_ino(&self) -> u64 {\n        self.as_inner().as_inner().st_ino as u64\n    }\n    fn st_mode(&self) -> u32 {\n        self.as_inner().as_inner().st_mode as u32\n    }\n    fn st_nlink(&self) -> u64 {\n        self.as_inner().as_inner().st_nlink as u64\n    }\n    fn st_uid(&self) -> u32 {\n        self.as_inner().as_inner().st_uid as u32\n    }\n    fn st_gid(&self) -> u32 {\n        self.as_inner().as_inner().st_gid as u32\n    }\n    fn st_rdev(&self) -> u64 {\n        self.as_inner().as_inner().st_rdev as u64\n    }\n    fn st_size(&self) -> u64 {\n        self.as_inner().as_inner().st_size as u64\n    }\n    fn st_atime(&self) -> i64 {\n        self.as_inner().as_inner().st_atime as i64\n    }\n    fn st_atime_nsec(&self) -> i64 {\n        self.as_inner().as_inner().st_atime_nsec as i64\n    }\n    fn st_mtime(&self) -> i64 {\n        self.as_inner().as_inner().st_mtime as i64\n    }\n    fn st_mtime_nsec(&self) -> i64 {\n        self.as_inner().as_inner().st_mtime_nsec as i64\n    }\n    fn st_ctime(&self) -> i64 {\n        self.as_inner().as_inner().st_ctime as i64\n    }\n    fn st_ctime_nsec(&self) -> i64 {\n        self.as_inner().as_inner().st_ctime_nsec as i64\n    }\n    fn st_blksize(&self) -> u64 {\n        self.as_inner().as_inner().st_blksize as u64\n    }\n    fn st_blocks(&self) -> u64 {\n        self.as_inner().as_inner().st_blocks as u64\n    }\n}\n"],[2197,"//! illumos-specific raw type definitions\n\n#![stable(feature = \"raw_ext\", since = \"1.1.0\")]\n#![rustc_deprecated(\n    since = \"1.8.0\",\n    reason = \"these type aliases are no longer supported by the standard library, the `libc` \\\n    crate on crates.io should be used instead for the correct definitions\"\n)]\n#![allow(deprecated)]\n\nuse crate::os::raw::c_long;\nuse crate::os::unix::raw::{gid_t, uid_t};\n\n#[stable(feature = \"raw_ext\", since = \"1.1.0\")]\npub type blkcnt_t = u64;\n#[stable(feature = \"raw_ext\", since = \"1.1.0\")]\npub type blksize_t = u64;\n#[stable(feature = \"raw_ext\", since = \"1.1.0\")]\npub type dev_t = u64;\n#[stable(feature = \"raw_ext\", since = \"1.1.0\")]\npub type fflags_t = u32;\n#[stable(feature = \"raw_ext\", since = \"1.1.0\")]\npub type ino_t = u64;\n#[stable(feature = \"raw_ext\", since = \"1.1.0\")]\npub type mode_t = u32;\n#[stable(feature = \"raw_ext\", since = \"1.1.0\")]\npub type nlink_t = u64;\n#[stable(feature = \"raw_ext\", since = \"1.1.0\")]\npub type off_t = u64;\n#[stable(feature = \"raw_ext\", since = \"1.1.0\")]\npub type time_t = i64;\n\n#[stable(feature = \"pthread_t\", since = \"1.8.0\")]\npub type pthread_t = u32;\n\n#[repr(C)]\n#[derive(Clone)]\n#[stable(feature = \"raw_ext\", since = \"1.1.0\")]\npub struct stat {\n    #[stable(feature = \"raw_ext\", since = \"1.1.0\")]\n    pub st_dev: dev_t,\n    #[stable(feature = \"raw_ext\", since = \"1.1.0\")]\n    pub st_ino: ino_t,\n    #[stable(feature = \"raw_ext\", since = \"1.1.0\")]\n    pub st_mode: mode_t,\n    #[stable(feature = \"raw_ext\", since = \"1.1.0\")]\n    pub st_nlink: nlink_t,\n    #[stable(feature = \"raw_ext\", since = \"1.1.0\")]\n    pub st_uid: uid_t,\n    #[stable(feature = \"raw_ext\", since = \"1.1.0\")]\n    pub st_gid: gid_t,\n    #[stable(feature = \"raw_ext\", since = \"1.1.0\")]\n    pub st_rdev: dev_t,\n    #[stable(feature = \"raw_ext\", since = \"1.1.0\")]\n    pub st_size: off_t,\n    #[stable(feature = \"raw_ext\", since = \"1.1.0\")]\n    pub st_atime: time_t,\n    #[stable(feature = \"raw_ext\", since = \"1.1.0\")]\n    pub st_atime_nsec: c_long,\n    #[stable(feature = \"raw_ext\", since = \"1.1.0\")]\n    pub st_mtime: time_t,\n    #[stable(feature = \"raw_ext\", since = \"1.1.0\")]\n    pub st_mtime_nsec: c_long,\n    #[stable(feature = \"raw_ext\", since = \"1.1.0\")]\n    pub st_ctime: time_t,\n    #[stable(feature = \"raw_ext\", since = \"1.1.0\")]\n    pub st_ctime_nsec: c_long,\n    #[stable(feature = \"raw_ext\", since = \"1.1.0\")]\n    pub st_blksize: blksize_t,\n    #[stable(feature = \"raw_ext\", since = \"1.1.0\")]\n    pub st_blocks: blkcnt_t,\n    #[stable(feature = \"raw_ext\", since = \"1.1.0\")]\n    pub __unused: [u8; 16],\n}\n"],[2198,"#![stable(feature = \"rust1\", since = \"1.0.0\")]\n\npub mod ffi;\n\n/// A prelude for conveniently writing platform-specific code.\n///\n/// Includes all extension traits, and some important type definitions.\n#[stable(feature = \"rust1\", since = \"1.0.0\")]\npub mod prelude {\n    #[doc(no_inline)]\n    #[stable(feature = \"rust1\", since = \"1.0.0\")]\n    pub use super::ffi::{OsStrExt, OsStringExt};\n}\n"],[2199,"//! HermitCore-specific extension to the primitives in the `std::ffi` module\n//!\n//! # Examples\n//!\n//! ```\n//! use std::ffi::OsString;\n//! use std::os::hermit::ffi::OsStringExt;\n//!\n//! let bytes = b\"foo\".to_vec();\n//!\n//! // OsStringExt::from_vec\n//! let os_string = OsString::from_vec(bytes);\n//! assert_eq!(os_string.to_str(), Some(\"foo\"));\n//!\n//! // OsStringExt::into_vec\n//! let bytes = os_string.into_vec();\n//! assert_eq!(bytes, b\"foo\");\n//! ```\n//!\n//! ```\n//! use std::ffi::OsStr;\n//! use std::os::hermit::ffi::OsStrExt;\n//!\n//! let bytes = b\"foo\";\n//!\n//! // OsStrExt::from_bytes\n//! let os_str = OsStr::from_bytes(bytes);\n//! assert_eq!(os_str.to_str(), Some(\"foo\"));\n//!\n//! // OsStrExt::as_bytes\n//! let bytes = os_str.as_bytes();\n//! assert_eq!(bytes, b\"foo\");\n//! ```\n\n#![stable(feature = \"rust1\", since = \"1.0.0\")]\n\n#[path = \"../unix/ffi/os_str.rs\"]\nmod os_str;\n\n#[stable(feature = \"rust1\", since = \"1.0.0\")]\npub use self::os_str::{OsStrExt, OsStringExt};\n"],[2200,"//! Android-specific definitions\n\n#![stable(feature = \"raw_ext\", since = \"1.1.0\")]\n\npub mod fs;\npub mod raw;\n"],[2201,"//! Android-specific raw type definitions\n\n#![stable(feature = \"raw_ext\", since = \"1.1.0\")]\n#![rustc_deprecated(\n    since = \"1.8.0\",\n    reason = \"these type aliases are no longer supported by \\\n              the standard library, the `libc` crate on \\\n              crates.io should be used instead for the correct \\\n              definitions\"\n)]\n#![allow(deprecated)]\n\nuse crate::os::raw::c_long;\n\n#[stable(feature = \"pthread_t\", since = \"1.8.0\")]\npub type pthread_t = c_long;\n\n#[doc(inline)]\n#[stable(feature = \"raw_ext\", since = \"1.1.0\")]\npub use self::arch::{blkcnt_t, blksize_t, dev_t, ino_t, mode_t, nlink_t, off_t, stat, time_t};\n\n#[cfg(any(target_arch = \"arm\", target_arch = \"x86\"))]\nmod arch {\n    use crate::os::raw::{c_longlong, c_uchar, c_uint, c_ulong, c_ulonglong};\n    use crate::os::unix::raw::{gid_t, uid_t};\n\n    #[stable(feature = \"raw_ext\", since = \"1.1.0\")]\n    pub type dev_t = u64;\n    #[stable(feature = \"raw_ext\", since = \"1.1.0\")]\n    pub type mode_t = u32;\n\n    #[stable(feature = \"raw_ext\", since = \"1.1.0\")]\n    pub type blkcnt_t = u64;\n    #[stable(feature = \"raw_ext\", since = \"1.1.0\")]\n    pub type blksize_t = u64;\n    #[stable(feature = \"raw_ext\", since = \"1.1.0\")]\n    pub type ino_t = u64;\n    #[stable(feature = \"raw_ext\", since = \"1.1.0\")]\n    pub type nlink_t = u64;\n    #[stable(feature = \"raw_ext\", since = \"1.1.0\")]\n    pub type off_t = u64;\n    #[stable(feature = \"raw_ext\", since = \"1.1.0\")]\n    pub type time_t = i64;\n\n    #[repr(C)]\n    #[derive(Clone)]\n    #[stable(feature = \"raw_ext\", since = \"1.1.0\")]\n    pub struct stat {\n        #[stable(feature = \"raw_ext\", since = \"1.1.0\")]\n        pub st_dev: c_ulonglong,\n        #[stable(feature = \"raw_ext\", since = \"1.1.0\")]\n        pub __pad0: [c_uchar; 4],\n        #[stable(feature = \"raw_ext\", since = \"1.1.0\")]\n        pub __st_ino: u32,\n        #[stable(feature = \"raw_ext\", since = \"1.1.0\")]\n        pub st_mode: c_uint,\n        #[stable(feature = \"raw_ext\", since = \"1.1.0\")]\n        pub st_nlink: c_uint,\n        #[stable(feature = \"raw_ext\", since = \"1.1.0\")]\n        pub st_uid: uid_t,\n        #[stable(feature = \"raw_ext\", since = \"1.1.0\")]\n        pub st_gid: gid_t,\n        #[stable(feature = \"raw_ext\", since = \"1.1.0\")]\n        pub st_rdev: c_ulonglong,\n        #[stable(feature = \"raw_ext\", since = \"1.1.0\")]\n        pub __pad3: [c_uchar; 4],\n        #[stable(feature = \"raw_ext\", since = \"1.1.0\")]\n        pub st_size: c_longlong,\n        #[stable(feature = \"raw_ext\", since = \"1.1.0\")]\n        pub st_blksize: u32,\n        #[stable(feature = \"raw_ext\", since = \"1.1.0\")]\n        pub st_blocks: c_ulonglong,\n        #[stable(feature = \"raw_ext\", since = \"1.1.0\")]\n        pub st_atime: c_ulong,\n        #[stable(feature = \"raw_ext\", since = \"1.1.0\")]\n        pub st_atime_nsec: c_ulong,\n        #[stable(feature = \"raw_ext\", since = \"1.1.0\")]\n        pub st_mtime: c_ulong,\n        #[stable(feature = \"raw_ext\", since = \"1.1.0\")]\n        pub st_mtime_nsec: c_ulong,\n        #[stable(feature = \"raw_ext\", since = \"1.1.0\")]\n        pub st_ctime: c_ulong,\n        #[stable(feature = \"raw_ext\", since = \"1.1.0\")]\n        pub st_ctime_nsec: c_ulong,\n        #[stable(feature = \"raw_ext\", since = \"1.1.0\")]\n        pub st_ino: c_ulonglong,\n    }\n}\n\n#[cfg(target_arch = \"aarch64\")]\nmod arch {\n    use crate::os::raw::{c_uchar, c_ulong};\n    use crate::os::unix::raw::{gid_t, uid_t};\n\n    #[stable(feature = \"raw_ext\", since = \"1.1.0\")]\n    pub type dev_t = u64;\n    #[stable(feature = \"raw_ext\", since = \"1.1.0\")]\n    pub type mode_t = u32;\n\n    #[stable(feature = \"raw_ext\", since = \"1.1.0\")]\n    pub type blkcnt_t = u64;\n    #[stable(feature = \"raw_ext\", since = \"1.1.0\")]\n    pub type blksize_t = u64;\n    #[stable(feature = \"raw_ext\", since = \"1.1.0\")]\n    pub type ino_t = u64;\n    #[stable(feature = \"raw_ext\", since = \"1.1.0\")]\n    pub type nlink_t = u64;\n    #[stable(feature = \"raw_ext\", since = \"1.1.0\")]\n    pub type off_t = u64;\n    #[stable(feature = \"raw_ext\", since = \"1.1.0\")]\n    pub type time_t = i64;\n\n    #[repr(C)]\n    #[derive(Clone)]\n    #[stable(feature = \"raw_ext\", since = \"1.1.0\")]\n    pub struct stat {\n        #[stable(feature = \"raw_ext\", since = \"1.1.0\")]\n        pub st_dev: dev_t,\n        #[stable(feature = \"raw_ext\", since = \"1.1.0\")]\n        pub __pad0: [c_uchar; 4],\n        #[stable(feature = \"raw_ext\", since = \"1.1.0\")]\n        pub __st_ino: ino_t,\n        #[stable(feature = \"raw_ext\", since = \"1.1.0\")]\n        pub st_mode: mode_t,\n        #[stable(feature = \"raw_ext\", since = \"1.1.0\")]\n        pub st_nlink: nlink_t,\n        #[stable(feature = \"raw_ext\", since = \"1.1.0\")]\n        pub st_uid: uid_t,\n        #[stable(feature = \"raw_ext\", since = \"1.1.0\")]\n        pub st_gid: gid_t,\n        #[stable(feature = \"raw_ext\", since = \"1.1.0\")]\n        pub st_rdev: dev_t,\n        #[stable(feature = \"raw_ext\", since = \"1.1.0\")]\n        pub __pad3: [c_uchar; 4],\n        #[stable(feature = \"raw_ext\", since = \"1.1.0\")]\n        pub st_size: off_t,\n        #[stable(feature = \"raw_ext\", since = \"1.1.0\")]\n        pub st_blksize: blksize_t,\n        #[stable(feature = \"raw_ext\", since = \"1.1.0\")]\n        pub st_blocks: blkcnt_t,\n        #[stable(feature = \"raw_ext\", since = \"1.1.0\")]\n        pub st_atime: time_t,\n        #[stable(feature = \"raw_ext\", since = \"1.1.0\")]\n        pub st_atime_nsec: c_ulong,\n        #[stable(feature = \"raw_ext\", since = \"1.1.0\")]\n        pub st_mtime: time_t,\n        #[stable(feature = \"raw_ext\", since = \"1.1.0\")]\n        pub st_mtime_nsec: c_ulong,\n        #[stable(feature = \"raw_ext\", since = \"1.1.0\")]\n        pub st_ctime: time_t,\n        #[stable(feature = \"raw_ext\", since = \"1.1.0\")]\n        pub st_ctime_nsec: c_ulong,\n        #[stable(feature = \"raw_ext\", since = \"1.1.0\")]\n        pub st_ino: ino_t,\n    }\n}\n\n#[cfg(target_arch = \"x86_64\")]\nmod arch {\n    use crate::os::raw::{c_long, c_uint, c_ulong};\n    use crate::os::unix::raw::{gid_t, uid_t};\n\n    #[stable(feature = \"raw_ext\", since = \"1.1.0\")]\n    pub type dev_t = u64;\n    #[stable(feature = \"raw_ext\", since = \"1.1.0\")]\n    pub type mode_t = u32;\n\n    #[stable(feature = \"raw_ext\", since = \"1.1.0\")]\n    pub type blkcnt_t = u64;\n    #[stable(feature = \"raw_ext\", since = \"1.1.0\")]\n    pub type blksize_t = u64;\n    #[stable(feature = \"raw_ext\", since = \"1.1.0\")]\n    pub type ino_t = u64;\n    #[stable(feature = \"raw_ext\", since = \"1.1.0\")]\n    pub type nlink_t = u32;\n    #[stable(feature = \"raw_ext\", since = \"1.1.0\")]\n    pub type off_t = u64;\n    #[stable(feature = \"raw_ext\", since = \"1.1.0\")]\n    pub type time_t = i64;\n\n    #[repr(C)]\n    #[derive(Clone)]\n    #[stable(feature = \"raw_ext\", since = \"1.1.0\")]\n    pub struct stat {\n        #[stable(feature = \"raw_ext\", since = \"1.1.0\")]\n        pub st_dev: dev_t,\n        #[stable(feature = \"raw_ext\", since = \"1.1.0\")]\n        pub st_ino: ino_t,\n        #[stable(feature = \"raw_ext\", since = \"1.1.0\")]\n        pub st_nlink: c_ulong,\n        #[stable(feature = \"raw_ext\", since = \"1.1.0\")]\n        pub st_mode: c_uint,\n        #[stable(feature = \"raw_ext\", since = \"1.1.0\")]\n        pub st_uid: uid_t,\n        #[stable(feature = \"raw_ext\", since = \"1.1.0\")]\n        pub st_gid: gid_t,\n        #[stable(feature = \"raw_ext\", since = \"1.1.0\")]\n        pub st_rdev: dev_t,\n        #[stable(feature = \"raw_ext\", since = \"1.1.0\")]\n        pub st_size: i64,\n        #[stable(feature = \"raw_ext\", since = \"1.1.0\")]\n        pub st_blksize: c_long,\n        #[stable(feature = \"raw_ext\", since = \"1.1.0\")]\n        pub st_blocks: c_long,\n        #[stable(feature = \"raw_ext\", since = \"1.1.0\")]\n        pub st_atime: c_ulong,\n        #[stable(feature = \"raw_ext\", since = \"1.1.0\")]\n        pub st_atime_nsec: c_ulong,\n        #[stable(feature = \"raw_ext\", since = \"1.1.0\")]\n        pub st_mtime: c_ulong,\n        #[stable(feature = \"raw_ext\", since = \"1.1.0\")]\n        pub st_mtime_nsec: c_ulong,\n        #[stable(feature = \"raw_ext\", since = \"1.1.0\")]\n        pub st_ctime: c_ulong,\n        #[stable(feature = \"raw_ext\", since = \"1.1.0\")]\n        pub st_ctime_nsec: c_ulong,\n        __unused: [c_long; 3],\n    }\n}\n"],[2202,"#![stable(feature = \"metadata_ext\", since = \"1.1.0\")]\n\nuse crate::fs::Metadata;\nuse crate::sys_common::AsInner;\n\n#[allow(deprecated)]\nuse crate::os::android::raw;\n\n/// OS-specific extensions to [`fs::Metadata`].\n///\n/// [`fs::Metadata`]: crate::fs::Metadata\n#[stable(feature = \"metadata_ext\", since = \"1.1.0\")]\npub trait MetadataExt {\n    /// Gain a reference to the underlying `stat` structure which contains\n    /// the raw information returned by the OS.\n    ///\n    /// The contents of the returned `stat` are **not** consistent across\n    /// Unix platforms. The `os::unix::fs::MetadataExt` trait contains the\n    /// cross-Unix abstractions contained within the raw stat.\n    #[stable(feature = \"metadata_ext\", since = \"1.1.0\")]\n    #[rustc_deprecated(\n        since = \"1.8.0\",\n        reason = \"deprecated in favor of the accessor \\\n                  methods of this trait\"\n    )]\n    #[allow(deprecated)]\n    fn as_raw_stat(&self) -> &raw::stat;\n\n    #[stable(feature = \"metadata_ext2\", since = \"1.8.0\")]\n    fn st_dev(&self) -> u64;\n    #[stable(feature = \"metadata_ext2\", since = \"1.8.0\")]\n    fn st_ino(&self) -> u64;\n    #[stable(feature = \"metadata_ext2\", since = \"1.8.0\")]\n    fn st_mode(&self) -> u32;\n    #[stable(feature = \"metadata_ext2\", since = \"1.8.0\")]\n    fn st_nlink(&self) -> u64;\n    #[stable(feature = \"metadata_ext2\", since = \"1.8.0\")]\n    fn st_uid(&self) -> u32;\n    #[stable(feature = \"metadata_ext2\", since = \"1.8.0\")]\n    fn st_gid(&self) -> u32;\n    #[stable(feature = \"metadata_ext2\", since = \"1.8.0\")]\n    fn st_rdev(&self) -> u64;\n    #[stable(feature = \"metadata_ext2\", since = \"1.8.0\")]\n    fn st_size(&self) -> u64;\n    #[stable(feature = \"metadata_ext2\", since = \"1.8.0\")]\n    fn st_atime(&self) -> i64;\n    #[stable(feature = \"metadata_ext2\", since = \"1.8.0\")]\n    fn st_atime_nsec(&self) -> i64;\n    #[stable(feature = \"metadata_ext2\", since = \"1.8.0\")]\n    fn st_mtime(&self) -> i64;\n    #[stable(feature = \"metadata_ext2\", since = \"1.8.0\")]\n    fn st_mtime_nsec(&self) -> i64;\n    #[stable(feature = \"metadata_ext2\", since = \"1.8.0\")]\n    fn st_ctime(&self) -> i64;\n    #[stable(feature = \"metadata_ext2\", since = \"1.8.0\")]\n    fn st_ctime_nsec(&self) -> i64;\n    #[stable(feature = \"metadata_ext2\", since = \"1.8.0\")]\n    fn st_blksize(&self) -> u64;\n    #[stable(feature = \"metadata_ext2\", since = \"1.8.0\")]\n    fn st_blocks(&self) -> u64;\n}\n\n#[stable(feature = \"metadata_ext\", since = \"1.1.0\")]\nimpl MetadataExt for Metadata {\n    #[allow(deprecated)]\n    fn as_raw_stat(&self) -> &raw::stat {\n        unsafe { &*(self.as_inner().as_inner() as *const libc::stat as *const raw::stat) }\n    }\n    fn st_dev(&self) -> u64 {\n        self.as_inner().as_inner().st_dev as u64\n    }\n    fn st_ino(&self) -> u64 {\n        self.as_inner().as_inner().st_ino as u64\n    }\n    fn st_mode(&self) -> u32 {\n        self.as_inner().as_inner().st_mode as u32\n    }\n    fn st_nlink(&self) -> u64 {\n        self.as_inner().as_inner().st_nlink as u64\n    }\n    fn st_uid(&self) -> u32 {\n        self.as_inner().as_inner().st_uid as u32\n    }\n    fn st_gid(&self) -> u32 {\n        self.as_inner().as_inner().st_gid as u32\n    }\n    fn st_rdev(&self) -> u64 {\n        self.as_inner().as_inner().st_rdev as u64\n    }\n    fn st_size(&self) -> u64 {\n        self.as_inner().as_inner().st_size as u64\n    }\n    fn st_atime(&self) -> i64 {\n        self.as_inner().as_inner().st_atime as i64\n    }\n    fn st_atime_nsec(&self) -> i64 {\n        self.as_inner().as_inner().st_atime_nsec as i64\n    }\n    fn st_mtime(&self) -> i64 {\n        self.as_inner().as_inner().st_mtime as i64\n    }\n    fn st_mtime_nsec(&self) -> i64 {\n        self.as_inner().as_inner().st_mtime_nsec as i64\n    }\n    fn st_ctime(&self) -> i64 {\n        self.as_inner().as_inner().st_ctime as i64\n    }\n    fn st_ctime_nsec(&self) -> i64 {\n        self.as_inner().as_inner().st_ctime_nsec as i64\n    }\n    fn st_blksize(&self) -> u64 {\n        self.as_inner().as_inner().st_blksize as u64\n    }\n    fn st_blocks(&self) -> u64 {\n        self.as_inner().as_inner().st_blocks as u64\n    }\n}\n"],[2203,"//! WASI-specific extensions to primitives in the `std::fs` module.\n\n#![deny(unsafe_op_in_unsafe_fn)]\n#![unstable(feature = \"wasi_ext\", issue = \"none\")]\n\nuse crate::ffi::OsStr;\nuse crate::fs::{self, File, Metadata, OpenOptions};\nuse crate::io::{self, IoSlice, IoSliceMut};\nuse crate::path::{Path, PathBuf};\nuse crate::sys_common::{AsInner, AsInnerMut, FromInner};\n// Used for `File::read` on intra-doc links\n#[allow(unused_imports)]\nuse io::{Read, Write};\n\n/// WASI-specific extensions to [`File`].\npub trait FileExt {\n    /// Reads a number of bytes starting from a given offset.\n    ///\n    /// Returns the number of bytes read.\n    ///\n    /// The offset is relative to the start of the file and thus independent\n    /// from the current cursor.\n    ///\n    /// The current file cursor is not affected by this function.\n    ///\n    /// Note that similar to [`File::read`], it is not an error to return with a\n    /// short read.\n    fn read_at(&self, buf: &mut [u8], offset: u64) -> io::Result<usize> {\n        let bufs = &mut [IoSliceMut::new(buf)];\n        self.read_vectored_at(bufs, offset)\n    }\n\n    /// Reads a number of bytes starting from a given offset.\n    ///\n    /// Returns the number of bytes read.\n    ///\n    /// The offset is relative to the start of the file and thus independent\n    /// from the current cursor.\n    ///\n    /// The current file cursor is not affected by this function.\n    ///\n    /// Note that similar to [`File::read_vectored`], it is not an error to\n    /// return with a short read.\n    fn read_vectored_at(&self, bufs: &mut [IoSliceMut<'_>], offset: u64) -> io::Result<usize>;\n\n    /// Reads the exact number of byte required to fill `buf` from the given offset.\n    ///\n    /// The offset is relative to the start of the file and thus independent\n    /// from the current cursor.\n    ///\n    /// The current file cursor is not affected by this function.\n    ///\n    /// Similar to [`Read::read_exact`] but uses [`read_at`] instead of `read`.\n    ///\n    /// [`read_at`]: FileExt::read_at\n    ///\n    /// # Errors\n    ///\n    /// If this function encounters an error of the kind\n    /// [`io::ErrorKind::Interrupted`] then the error is ignored and the operation\n    /// will continue.\n    ///\n    /// If this function encounters an \"end of file\" before completely filling\n    /// the buffer, it returns an error of the kind [`io::ErrorKind::UnexpectedEof`].\n    /// The contents of `buf` are unspecified in this case.\n    ///\n    /// If any other read error is encountered then this function immediately\n    /// returns. The contents of `buf` are unspecified in this case.\n    ///\n    /// If this function returns an error, it is unspecified how many bytes it\n    /// has read, but it will never read more than would be necessary to\n    /// completely fill the buffer.\n    #[stable(feature = \"rw_exact_all_at\", since = \"1.33.0\")]\n    fn read_exact_at(&self, mut buf: &mut [u8], mut offset: u64) -> io::Result<()> {\n        while !buf.is_empty() {\n            match self.read_at(buf, offset) {\n                Ok(0) => break,\n                Ok(n) => {\n                    let tmp = buf;\n                    buf = &mut tmp[n..];\n                    offset += n as u64;\n                }\n                Err(ref e) if e.kind() == io::ErrorKind::Interrupted => {}\n                Err(e) => return Err(e),\n            }\n        }\n        if !buf.is_empty() {\n            Err(io::Error::new_const(io::ErrorKind::UnexpectedEof, &\"failed to fill whole buffer\"))\n        } else {\n            Ok(())\n        }\n    }\n\n    /// Writes a number of bytes starting from a given offset.\n    ///\n    /// Returns the number of bytes written.\n    ///\n    /// The offset is relative to the start of the file and thus independent\n    /// from the current cursor.\n    ///\n    /// The current file cursor is not affected by this function.\n    ///\n    /// When writing beyond the end of the file, the file is appropriately\n    /// extended and the intermediate bytes are initialized with the value 0.\n    ///\n    /// Note that similar to [`File::write`], it is not an error to return a\n    /// short write.\n    fn write_at(&self, buf: &[u8], offset: u64) -> io::Result<usize> {\n        let bufs = &[IoSlice::new(buf)];\n        self.write_vectored_at(bufs, offset)\n    }\n\n    /// Writes a number of bytes starting from a given offset.\n    ///\n    /// Returns the number of bytes written.\n    ///\n    /// The offset is relative to the start of the file and thus independent\n    /// from the current cursor.\n    ///\n    /// The current file cursor is not affected by this function.\n    ///\n    /// When writing beyond the end of the file, the file is appropriately\n    /// extended and the intermediate bytes are initialized with the value 0.\n    ///\n    /// Note that similar to [`File::write_vectored`], it is not an error to return a\n    /// short write.\n    fn write_vectored_at(&self, bufs: &[IoSlice<'_>], offset: u64) -> io::Result<usize>;\n\n    /// Attempts to write an entire buffer starting from a given offset.\n    ///\n    /// The offset is relative to the start of the file and thus independent\n    /// from the current cursor.\n    ///\n    /// The current file cursor is not affected by this function.\n    ///\n    /// This method will continuously call [`write_at`] until there is no more data\n    /// to be written or an error of non-[`io::ErrorKind::Interrupted`] kind is\n    /// returned. This method will not return until the entire buffer has been\n    /// successfully written or such an error occurs. The first error that is\n    /// not of [`io::ErrorKind::Interrupted`] kind generated from this method will be\n    /// returned.\n    ///\n    /// # Errors\n    ///\n    /// This function will return the first error of\n    /// non-[`io::ErrorKind::Interrupted`] kind that [`write_at`] returns.\n    ///\n    /// [`write_at`]: FileExt::write_at\n    #[stable(feature = \"rw_exact_all_at\", since = \"1.33.0\")]\n    fn write_all_at(&self, mut buf: &[u8], mut offset: u64) -> io::Result<()> {\n        while !buf.is_empty() {\n            match self.write_at(buf, offset) {\n                Ok(0) => {\n                    return Err(io::Error::new_const(\n                        io::ErrorKind::WriteZero,\n                        &\"failed to write whole buffer\",\n                    ));\n                }\n                Ok(n) => {\n                    buf = &buf[n..];\n                    offset += n as u64\n                }\n                Err(ref e) if e.kind() == io::ErrorKind::Interrupted => {}\n                Err(e) => return Err(e),\n            }\n        }\n        Ok(())\n    }\n\n    /// Returns the current position within the file.\n    ///\n    /// This corresponds to the `fd_tell` syscall and is similar to\n    /// `seek` where you offset 0 bytes from the current position.\n    fn tell(&self) -> io::Result<u64>;\n\n    /// Adjust the flags associated with this file.\n    ///\n    /// This corresponds to the `fd_fdstat_set_flags` syscall.\n    fn fdstat_set_flags(&self, flags: u16) -> io::Result<()>;\n\n    /// Adjust the rights associated with this file.\n    ///\n    /// This corresponds to the `fd_fdstat_set_rights` syscall.\n    fn fdstat_set_rights(&self, rights: u64, inheriting: u64) -> io::Result<()>;\n\n    /// Provide file advisory information on a file descriptor.\n    ///\n    /// This corresponds to the `fd_advise` syscall.\n    fn advise(&self, offset: u64, len: u64, advice: u8) -> io::Result<()>;\n\n    /// Force the allocation of space in a file.\n    ///\n    /// This corresponds to the `fd_allocate` syscall.\n    fn allocate(&self, offset: u64, len: u64) -> io::Result<()>;\n\n    /// Create a directory.\n    ///\n    /// This corresponds to the `path_create_directory` syscall.\n    fn create_directory<P: AsRef<Path>>(&self, dir: P) -> io::Result<()>;\n\n    /// Read the contents of a symbolic link.\n    ///\n    /// This corresponds to the `path_readlink` syscall.\n    fn read_link<P: AsRef<Path>>(&self, path: P) -> io::Result<PathBuf>;\n\n    /// Return the attributes of a file or directory.\n    ///\n    /// This corresponds to the `path_filestat_get` syscall.\n    fn metadata_at<P: AsRef<Path>>(&self, lookup_flags: u32, path: P) -> io::Result<Metadata>;\n\n    /// Unlink a file.\n    ///\n    /// This corresponds to the `path_unlink_file` syscall.\n    fn remove_file<P: AsRef<Path>>(&self, path: P) -> io::Result<()>;\n\n    /// Remove a directory.\n    ///\n    /// This corresponds to the `path_remove_directory` syscall.\n    fn remove_directory<P: AsRef<Path>>(&self, path: P) -> io::Result<()>;\n}\n\n// FIXME: bind fd_fdstat_get - need to define a custom return type\n// FIXME: bind fd_readdir - can't return `ReadDir` since we only have entry name\n// FIXME: bind fd_filestat_set_times maybe? - on crates.io for unix\n// FIXME: bind path_filestat_set_times maybe? - on crates.io for unix\n// FIXME: bind poll_oneoff maybe? - probably should wait for I/O to settle\n// FIXME: bind random_get maybe? - on crates.io for unix\n\nimpl FileExt for fs::File {\n    fn read_vectored_at(&self, bufs: &mut [IoSliceMut<'_>], offset: u64) -> io::Result<usize> {\n        self.as_inner().fd().pread(bufs, offset)\n    }\n\n    fn write_vectored_at(&self, bufs: &[IoSlice<'_>], offset: u64) -> io::Result<usize> {\n        self.as_inner().fd().pwrite(bufs, offset)\n    }\n\n    fn tell(&self) -> io::Result<u64> {\n        self.as_inner().fd().tell()\n    }\n\n    fn fdstat_set_flags(&self, flags: u16) -> io::Result<()> {\n        self.as_inner().fd().set_flags(flags)\n    }\n\n    fn fdstat_set_rights(&self, rights: u64, inheriting: u64) -> io::Result<()> {\n        self.as_inner().fd().set_rights(rights, inheriting)\n    }\n\n    fn advise(&self, offset: u64, len: u64, advice: u8) -> io::Result<()> {\n        self.as_inner().fd().advise(offset, len, advice)\n    }\n\n    fn allocate(&self, offset: u64, len: u64) -> io::Result<()> {\n        self.as_inner().fd().allocate(offset, len)\n    }\n\n    fn create_directory<P: AsRef<Path>>(&self, dir: P) -> io::Result<()> {\n        self.as_inner().fd().create_directory(osstr2str(dir.as_ref().as_ref())?)\n    }\n\n    fn read_link<P: AsRef<Path>>(&self, path: P) -> io::Result<PathBuf> {\n        self.as_inner().read_link(path.as_ref())\n    }\n\n    fn metadata_at<P: AsRef<Path>>(&self, lookup_flags: u32, path: P) -> io::Result<Metadata> {\n        let m = self.as_inner().metadata_at(lookup_flags, path.as_ref())?;\n        Ok(FromInner::from_inner(m))\n    }\n\n    fn remove_file<P: AsRef<Path>>(&self, path: P) -> io::Result<()> {\n        self.as_inner().fd().unlink_file(osstr2str(path.as_ref().as_ref())?)\n    }\n\n    fn remove_directory<P: AsRef<Path>>(&self, path: P) -> io::Result<()> {\n        self.as_inner().fd().remove_directory(osstr2str(path.as_ref().as_ref())?)\n    }\n}\n\n/// WASI-specific extensions to [`fs::OpenOptions`].\npub trait OpenOptionsExt {\n    /// Pass custom `dirflags` argument to `path_open`.\n    ///\n    /// This option configures the `dirflags` argument to the\n    /// `path_open` syscall which `OpenOptions` will eventually call. The\n    /// `dirflags` argument configures how the file is looked up, currently\n    /// primarily affecting whether symlinks are followed or not.\n    ///\n    /// By default this value is `__WASI_LOOKUP_SYMLINK_FOLLOW`, or symlinks are\n    /// followed. You can call this method with 0 to disable following symlinks\n    fn lookup_flags(&mut self, flags: u32) -> &mut Self;\n\n    /// Indicates whether `OpenOptions` must open a directory or not.\n    ///\n    /// This method will configure whether the `__WASI_O_DIRECTORY` flag is\n    /// passed when opening a file. When passed it will require that the opened\n    /// path is a directory.\n    ///\n    /// This option is by default `false`\n    fn directory(&mut self, dir: bool) -> &mut Self;\n\n    /// Indicates whether `__WASI_FDFLAG_DSYNC` is passed in the `fs_flags`\n    /// field of `path_open`.\n    ///\n    /// This option is by default `false`\n    fn dsync(&mut self, dsync: bool) -> &mut Self;\n\n    /// Indicates whether `__WASI_FDFLAG_NONBLOCK` is passed in the `fs_flags`\n    /// field of `path_open`.\n    ///\n    /// This option is by default `false`\n    fn nonblock(&mut self, nonblock: bool) -> &mut Self;\n\n    /// Indicates whether `__WASI_FDFLAG_RSYNC` is passed in the `fs_flags`\n    /// field of `path_open`.\n    ///\n    /// This option is by default `false`\n    fn rsync(&mut self, rsync: bool) -> &mut Self;\n\n    /// Indicates whether `__WASI_FDFLAG_SYNC` is passed in the `fs_flags`\n    /// field of `path_open`.\n    ///\n    /// This option is by default `false`\n    fn sync(&mut self, sync: bool) -> &mut Self;\n\n    /// Indicates the value that should be passed in for the `fs_rights_base`\n    /// parameter of `path_open`.\n    ///\n    /// This option defaults based on the `read` and `write` configuration of\n    /// this `OpenOptions` builder. If this method is called, however, the\n    /// exact mask passed in will be used instead.\n    fn fs_rights_base(&mut self, rights: u64) -> &mut Self;\n\n    /// Indicates the value that should be passed in for the\n    /// `fs_rights_inheriting` parameter of `path_open`.\n    ///\n    /// The default for this option is the same value as what will be passed\n    /// for the `fs_rights_base` parameter but if this method is called then\n    /// the specified value will be used instead.\n    fn fs_rights_inheriting(&mut self, rights: u64) -> &mut Self;\n\n    /// Open a file or directory.\n    ///\n    /// This corresponds to the `path_open` syscall.\n    fn open_at<P: AsRef<Path>>(&self, file: &File, path: P) -> io::Result<File>;\n}\n\nimpl OpenOptionsExt for OpenOptions {\n    fn lookup_flags(&mut self, flags: u32) -> &mut OpenOptions {\n        self.as_inner_mut().lookup_flags(flags);\n        self\n    }\n\n    fn directory(&mut self, dir: bool) -> &mut OpenOptions {\n        self.as_inner_mut().directory(dir);\n        self\n    }\n\n    fn dsync(&mut self, enabled: bool) -> &mut OpenOptions {\n        self.as_inner_mut().dsync(enabled);\n        self\n    }\n\n    fn nonblock(&mut self, enabled: bool) -> &mut OpenOptions {\n        self.as_inner_mut().nonblock(enabled);\n        self\n    }\n\n    fn rsync(&mut self, enabled: bool) -> &mut OpenOptions {\n        self.as_inner_mut().rsync(enabled);\n        self\n    }\n\n    fn sync(&mut self, enabled: bool) -> &mut OpenOptions {\n        self.as_inner_mut().sync(enabled);\n        self\n    }\n\n    fn fs_rights_base(&mut self, rights: u64) -> &mut OpenOptions {\n        self.as_inner_mut().fs_rights_base(rights);\n        self\n    }\n\n    fn fs_rights_inheriting(&mut self, rights: u64) -> &mut OpenOptions {\n        self.as_inner_mut().fs_rights_inheriting(rights);\n        self\n    }\n\n    fn open_at<P: AsRef<Path>>(&self, file: &File, path: P) -> io::Result<File> {\n        let inner = file.as_inner().open_at(path.as_ref(), self.as_inner())?;\n        Ok(File::from_inner(inner))\n    }\n}\n\n/// WASI-specific extensions to [`fs::Metadata`].\npub trait MetadataExt {\n    /// Returns the `st_dev` field of the internal `filestat_t`\n    fn dev(&self) -> u64;\n    /// Returns the `st_ino` field of the internal `filestat_t`\n    fn ino(&self) -> u64;\n    /// Returns the `st_nlink` field of the internal `filestat_t`\n    fn nlink(&self) -> u64;\n    /// Returns the `st_size` field of the internal `filestat_t`\n    fn size(&self) -> u64;\n    /// Returns the `st_atim` field of the internal `filestat_t`\n    fn atim(&self) -> u64;\n    /// Returns the `st_mtim` field of the internal `filestat_t`\n    fn mtim(&self) -> u64;\n    /// Returns the `st_ctim` field of the internal `filestat_t`\n    fn ctim(&self) -> u64;\n}\n\nimpl MetadataExt for fs::Metadata {\n    fn dev(&self) -> u64 {\n        self.as_inner().as_wasi().dev\n    }\n    fn ino(&self) -> u64 {\n        self.as_inner().as_wasi().ino\n    }\n    fn nlink(&self) -> u64 {\n        self.as_inner().as_wasi().nlink\n    }\n    fn size(&self) -> u64 {\n        self.as_inner().as_wasi().size\n    }\n    fn atim(&self) -> u64 {\n        self.as_inner().as_wasi().atim\n    }\n    fn mtim(&self) -> u64 {\n        self.as_inner().as_wasi().mtim\n    }\n    fn ctim(&self) -> u64 {\n        self.as_inner().as_wasi().ctim\n    }\n}\n\n/// WASI-specific extensions for [`fs::FileType`].\n///\n/// Adds support for special WASI file types such as block/character devices,\n/// pipes, and sockets.\npub trait FileTypeExt {\n    /// Returns `true` if this file type is a block device.\n    fn is_block_device(&self) -> bool;\n    /// Returns `true` if this file type is a character device.\n    fn is_character_device(&self) -> bool;\n    /// Returns `true` if this file type is a socket datagram.\n    fn is_socket_dgram(&self) -> bool;\n    /// Returns `true` if this file type is a socket stream.\n    fn is_socket_stream(&self) -> bool;\n}\n\nimpl FileTypeExt for fs::FileType {\n    fn is_block_device(&self) -> bool {\n        self.as_inner().bits() == wasi::FILETYPE_BLOCK_DEVICE\n    }\n    fn is_character_device(&self) -> bool {\n        self.as_inner().bits() == wasi::FILETYPE_CHARACTER_DEVICE\n    }\n    fn is_socket_dgram(&self) -> bool {\n        self.as_inner().bits() == wasi::FILETYPE_SOCKET_DGRAM\n    }\n    fn is_socket_stream(&self) -> bool {\n        self.as_inner().bits() == wasi::FILETYPE_SOCKET_STREAM\n    }\n}\n\n/// WASI-specific extension methods for [`fs::DirEntry`].\npub trait DirEntryExt {\n    /// Returns the underlying `d_ino` field of the `dirent_t`\n    fn ino(&self) -> u64;\n}\n\nimpl DirEntryExt for fs::DirEntry {\n    fn ino(&self) -> u64 {\n        self.as_inner().ino()\n    }\n}\n\n/// Create a hard link.\n///\n/// This corresponds to the `path_link` syscall.\npub fn link<P: AsRef<Path>, U: AsRef<Path>>(\n    old_fd: &File,\n    old_flags: u32,\n    old_path: P,\n    new_fd: &File,\n    new_path: U,\n) -> io::Result<()> {\n    old_fd.as_inner().fd().link(\n        old_flags,\n        osstr2str(old_path.as_ref().as_ref())?,\n        new_fd.as_inner().fd(),\n        osstr2str(new_path.as_ref().as_ref())?,\n    )\n}\n\n/// Rename a file or directory.\n///\n/// This corresponds to the `path_rename` syscall.\npub fn rename<P: AsRef<Path>, U: AsRef<Path>>(\n    old_fd: &File,\n    old_path: P,\n    new_fd: &File,\n    new_path: U,\n) -> io::Result<()> {\n    old_fd.as_inner().fd().rename(\n        osstr2str(old_path.as_ref().as_ref())?,\n        new_fd.as_inner().fd(),\n        osstr2str(new_path.as_ref().as_ref())?,\n    )\n}\n\n/// Create a symbolic link.\n///\n/// This corresponds to the `path_symlink` syscall.\npub fn symlink<P: AsRef<Path>, U: AsRef<Path>>(\n    old_path: P,\n    fd: &File,\n    new_path: U,\n) -> io::Result<()> {\n    fd.as_inner()\n        .fd()\n        .symlink(osstr2str(old_path.as_ref().as_ref())?, osstr2str(new_path.as_ref().as_ref())?)\n}\n\n/// Create a symbolic link.\n///\n/// This is a convenience API similar to `std::os::unix::fs::symlink` and\n/// `std::os::windows::fs::symlink_file` and `std::os::windows::fs::symlink_dir`.\npub fn symlink_path<P: AsRef<Path>, U: AsRef<Path>>(old_path: P, new_path: U) -> io::Result<()> {\n    crate::sys::fs::symlink(old_path.as_ref(), new_path.as_ref())\n}\n\nfn osstr2str(f: &OsStr) -> io::Result<&str> {\n    f.to_str().ok_or_else(|| io::Error::new_const(io::ErrorKind::Other, &\"input must be utf-8\"))\n}\n"],[2204,"//! WASI-specific extension to the primitives in the `std::ffi` module\n\n#![stable(feature = \"rust1\", since = \"1.0.0\")]\n\n#[path = \"../unix/ffi/os_str.rs\"]\nmod os_str;\n\n#[stable(feature = \"rust1\", since = \"1.0.0\")]\npub use self::os_str::{OsStrExt, OsStringExt};\n"],[2205,"//! Platform-specific extensions to `std` for the WebAssembly System Interface (WASI).\n//!\n//! Provides access to platform-level information on WASI, and exposes\n//! WASI-specific functions that would otherwise be inappropriate as\n//! part of the core `std` library.\n//!\n//! It exposes more ways to deal with platform-specific strings (`OsStr`,\n//! `OsString`), allows to set permissions more granularly, extract low-level\n//! file descriptors from files and sockets, and has platform-specific helpers\n//! for spawning processes.\n//!\n//! # Examples\n//!\n//! ```no_run\n//! use std::fs::File;\n//! use std::os::wasi::prelude::*;\n//!\n//! fn main() -> std::io::Result<()> {\n//!     let f = File::create(\"foo.txt\")?;\n//!     let fd = f.as_raw_fd();\n//!\n//!     // use fd with native WASI bindings\n//!\n//!     Ok(())\n//! }\n//! ```\n\n#![stable(feature = \"rust1\", since = \"1.0.0\")]\n#![deny(unsafe_op_in_unsafe_fn)]\n#![doc(cfg(target_os = \"wasi\"))]\n\npub mod ffi;\npub mod fs;\npub mod io;\n\n/// A prelude for conveniently writing platform-specific code.\n///\n/// Includes all extension traits, and some important type definitions.\n#[stable(feature = \"rust1\", since = \"1.0.0\")]\npub mod prelude {\n    #[doc(no_inline)]\n    #[stable(feature = \"rust1\", since = \"1.0.0\")]\n    pub use super::ffi::{OsStrExt, OsStringExt};\n    #[doc(no_inline)]\n    #[stable(feature = \"rust1\", since = \"1.0.0\")]\n    pub use super::fs::FileTypeExt;\n    #[doc(no_inline)]\n    #[stable(feature = \"rust1\", since = \"1.0.0\")]\n    pub use super::fs::{DirEntryExt, FileExt, MetadataExt, OpenOptionsExt};\n    #[doc(no_inline)]\n    #[stable(feature = \"rust1\", since = \"1.0.0\")]\n    pub use super::io::{AsRawFd, FromRawFd, IntoRawFd, RawFd};\n}\n"],[2206,"//! WASI-specific extensions to general I/O primitives\n\n#![deny(unsafe_op_in_unsafe_fn)]\n#![unstable(feature = \"wasi_ext\", issue = \"none\")]\n\nuse crate::fs;\nuse crate::io;\nuse crate::net;\nuse crate::sys;\nuse crate::sys_common::{AsInner, FromInner, IntoInner};\n\n/// Raw file descriptors.\npub type RawFd = u32;\n\n/// A trait to extract the raw WASI file descriptor from an underlying\n/// object.\npub trait AsRawFd {\n    /// Extracts the raw file descriptor.\n    ///\n    /// This method does **not** pass ownership of the raw file descriptor\n    /// to the caller. The descriptor is only guaranteed to be valid while\n    /// the original object has not yet been destroyed.\n    fn as_raw_fd(&self) -> RawFd;\n}\n\n/// A trait to express the ability to construct an object from a raw file\n/// descriptor.\npub trait FromRawFd {\n    /// Constructs a new instance of `Self` from the given raw file\n    /// descriptor.\n    ///\n    /// This function **consumes ownership** of the specified file\n    /// descriptor. The returned object will take responsibility for closing\n    /// it when the object goes out of scope.\n    ///\n    /// This function is also unsafe as the primitives currently returned\n    /// have the contract that they are the sole owner of the file\n    /// descriptor they are wrapping. Usage of this function could\n    /// accidentally allow violating this contract which can cause memory\n    /// unsafety in code that relies on it being true.\n    unsafe fn from_raw_fd(fd: RawFd) -> Self;\n}\n\n/// A trait to express the ability to consume an object and acquire ownership of\n/// its raw file descriptor.\npub trait IntoRawFd {\n    /// Consumes this object, returning the raw underlying file descriptor.\n    ///\n    /// This function **transfers ownership** of the underlying file descriptor\n    /// to the caller. Callers are then the unique owners of the file descriptor\n    /// and must close the descriptor once it's no longer needed.\n    fn into_raw_fd(self) -> RawFd;\n}\n\n#[stable(feature = \"raw_fd_reflexive_traits\", since = \"1.48.0\")]\nimpl AsRawFd for RawFd {\n    #[inline]\n    fn as_raw_fd(&self) -> RawFd {\n        *self\n    }\n}\n#[stable(feature = \"raw_fd_reflexive_traits\", since = \"1.48.0\")]\nimpl IntoRawFd for RawFd {\n    #[inline]\n    fn into_raw_fd(self) -> RawFd {\n        self\n    }\n}\n#[stable(feature = \"raw_fd_reflexive_traits\", since = \"1.48.0\")]\nimpl FromRawFd for RawFd {\n    #[inline]\n    unsafe fn from_raw_fd(fd: RawFd) -> RawFd {\n        fd\n    }\n}\n\nimpl AsRawFd for net::TcpStream {\n    #[inline]\n    fn as_raw_fd(&self) -> RawFd {\n        self.as_inner().fd().as_raw()\n    }\n}\n\nimpl FromRawFd for net::TcpStream {\n    #[inline]\n    unsafe fn from_raw_fd(fd: RawFd) -> net::TcpStream {\n        net::TcpStream::from_inner(sys::net::TcpStream::from_inner(fd))\n    }\n}\n\nimpl IntoRawFd for net::TcpStream {\n    #[inline]\n    fn into_raw_fd(self) -> RawFd {\n        self.into_inner().into_fd().into_raw()\n    }\n}\n\nimpl AsRawFd for net::TcpListener {\n    #[inline]\n    fn as_raw_fd(&self) -> RawFd {\n        self.as_inner().fd().as_raw()\n    }\n}\n\nimpl FromRawFd for net::TcpListener {\n    #[inline]\n    unsafe fn from_raw_fd(fd: RawFd) -> net::TcpListener {\n        net::TcpListener::from_inner(sys::net::TcpListener::from_inner(fd))\n    }\n}\n\nimpl IntoRawFd for net::TcpListener {\n    #[inline]\n    fn into_raw_fd(self) -> RawFd {\n        self.into_inner().into_fd().into_raw()\n    }\n}\n\nimpl AsRawFd for net::UdpSocket {\n    #[inline]\n    fn as_raw_fd(&self) -> RawFd {\n        self.as_inner().fd().as_raw()\n    }\n}\n\nimpl FromRawFd for net::UdpSocket {\n    #[inline]\n    unsafe fn from_raw_fd(fd: RawFd) -> net::UdpSocket {\n        net::UdpSocket::from_inner(sys::net::UdpSocket::from_inner(fd))\n    }\n}\n\nimpl IntoRawFd for net::UdpSocket {\n    #[inline]\n    fn into_raw_fd(self) -> RawFd {\n        self.into_inner().into_fd().into_raw()\n    }\n}\n\nimpl AsRawFd for fs::File {\n    #[inline]\n    fn as_raw_fd(&self) -> RawFd {\n        self.as_inner().fd().as_raw()\n    }\n}\n\nimpl FromRawFd for fs::File {\n    #[inline]\n    unsafe fn from_raw_fd(fd: RawFd) -> fs::File {\n        fs::File::from_inner(sys::fs::File::from_inner(fd))\n    }\n}\n\nimpl IntoRawFd for fs::File {\n    #[inline]\n    fn into_raw_fd(self) -> RawFd {\n        self.into_inner().into_fd().into_raw()\n    }\n}\n\nimpl AsRawFd for io::Stdin {\n    #[inline]\n    fn as_raw_fd(&self) -> RawFd {\n        libc::STDIN_FILENO as RawFd\n    }\n}\n\nimpl AsRawFd for io::Stdout {\n    #[inline]\n    fn as_raw_fd(&self) -> RawFd {\n        libc::STDOUT_FILENO as RawFd\n    }\n}\n\nimpl AsRawFd for io::Stderr {\n    #[inline]\n    fn as_raw_fd(&self) -> RawFd {\n        libc::STDERR_FILENO as RawFd\n    }\n}\n\nimpl<'a> AsRawFd for io::StdinLock<'a> {\n    #[inline]\n    fn as_raw_fd(&self) -> RawFd {\n        libc::STDIN_FILENO as RawFd\n    }\n}\n\nimpl<'a> AsRawFd for io::StdoutLock<'a> {\n    #[inline]\n    fn as_raw_fd(&self) -> RawFd {\n        libc::STDOUT_FILENO as RawFd\n    }\n}\n\nimpl<'a> AsRawFd for io::StderrLock<'a> {\n    #[inline]\n    fn as_raw_fd(&self) -> RawFd {\n        libc::STDERR_FILENO as RawFd\n    }\n}\n"],[2207,"//! OS-specific functionality.\n\n#![stable(feature = \"os\", since = \"1.0.0\")]\n#![allow(missing_docs, nonstandard_style, missing_debug_implementations)]\n\npub mod raw;\n\n// The code below could be written clearer using `cfg_if!`. However, the items below are\n// publicly exported by `std` and external tools can have trouble analysing them because of the use\n// of a macro that is not vendored by Rust and included in the toolchain.\n// See https://github.com/rust-analyzer/rust-analyzer/issues/6038.\n\n#[cfg(all(\n    doc,\n    not(any(\n        all(target_arch = \"wasm32\", not(target_os = \"wasi\")),\n        all(target_vendor = \"fortanix\", target_env = \"sgx\")\n    ))\n))]\n#[path = \".\"]\nmod doc {\n    // When documenting std we want to show the `unix`, `windows`, `linux` and `wasi`\n    // modules as these are the \"main modules\" that are used across platforms,\n    // so these modules are enabled when `cfg(doc)` is set.\n    // This should help show platform-specific functionality in a hopefully cross-platform\n    // way in the documentation.\n\n    pub mod unix;\n\n    pub mod linux;\n\n    pub mod wasi;\n\n    pub mod windows;\n}\n#[cfg(all(\n    doc,\n    any(\n        all(target_arch = \"wasm32\", not(target_os = \"wasi\")),\n        all(target_vendor = \"fortanix\", target_env = \"sgx\")\n    )\n))]\nmod doc {\n    // On certain platforms right now the \"main modules\" modules that are\n    // documented don't compile (missing things in `libc` which is empty),\n    // so just omit them with an empty module.\n\n    #[unstable(issue = \"none\", feature = \"std_internals\")]\n    pub mod unix {}\n\n    #[unstable(issue = \"none\", feature = \"std_internals\")]\n    pub mod linux {}\n\n    #[unstable(issue = \"none\", feature = \"std_internals\")]\n    pub mod wasi {}\n\n    #[unstable(issue = \"none\", feature = \"std_internals\")]\n    pub mod windows {}\n}\n#[cfg(doc)]\n#[stable(feature = \"os\", since = \"1.0.0\")]\npub use doc::*;\n\n#[cfg(not(doc))]\n#[path = \".\"]\nmod imp {\n    // If we're not documenting std then we only expose modules appropriate for the\n    // current platform.\n\n    #[cfg(all(target_vendor = \"fortanix\", target_env = \"sgx\"))]\n    pub mod fortanix_sgx;\n\n    #[cfg(target_os = \"hermit\")]\n    #[path = \"hermit/mod.rs\"]\n    pub mod unix;\n\n    #[cfg(target_os = \"android\")]\n    pub mod android;\n    #[cfg(target_os = \"dragonfly\")]\n    pub mod dragonfly;\n    #[cfg(target_os = \"emscripten\")]\n    pub mod emscripten;\n    #[cfg(target_os = \"freebsd\")]\n    pub mod freebsd;\n    #[cfg(target_os = \"fuchsia\")]\n    pub mod fuchsia;\n    #[cfg(target_os = \"haiku\")]\n    pub mod haiku;\n    #[cfg(target_os = \"illumos\")]\n    pub mod illumos;\n    #[cfg(target_os = \"ios\")]\n    pub mod ios;\n    #[cfg(target_os = \"l4re\")]\n    pub mod linux;\n    #[cfg(target_os = \"linux\")]\n    pub mod linux;\n    #[cfg(target_os = \"macos\")]\n    pub mod macos;\n    #[cfg(target_os = \"netbsd\")]\n    pub mod netbsd;\n    #[cfg(target_os = \"openbsd\")]\n    pub mod openbsd;\n    #[cfg(target_os = \"redox\")]\n    pub mod redox;\n    #[cfg(target_os = \"solaris\")]\n    pub mod solaris;\n    #[cfg(unix)]\n    pub mod unix;\n\n    #[cfg(target_os = \"vxworks\")]\n    pub mod vxworks;\n\n    #[cfg(target_os = \"wasi\")]\n    pub mod wasi;\n\n    #[cfg(windows)]\n    pub mod windows;\n}\n#[cfg(not(doc))]\n#[stable(feature = \"os\", since = \"1.0.0\")]\npub use imp::*;\n"],[2208,"#![stable(feature = \"metadata_ext\", since = \"1.1.0\")]\n\nuse crate::fs::Metadata;\nuse crate::sys_common::AsInner;\n\n#[allow(deprecated)]\nuse crate::os::haiku::raw;\n\n/// OS-specific extensions to [`fs::Metadata`].\n///\n/// [`fs::Metadata`]: crate::fs::Metadata\n#[stable(feature = \"metadata_ext\", since = \"1.1.0\")]\npub trait MetadataExt {\n    /// Gain a reference to the underlying `stat` structure which contains\n    /// the raw information returned by the OS.\n    ///\n    /// The contents of the returned `stat` are **not** consistent across\n    /// Unix platforms. The `os::unix::fs::MetadataExt` trait contains the\n    /// cross-Unix abstractions contained within the raw stat.\n    #[stable(feature = \"metadata_ext\", since = \"1.1.0\")]\n    #[rustc_deprecated(\n        since = \"1.8.0\",\n        reason = \"deprecated in favor of the accessor \\\n                  methods of this trait\"\n    )]\n    #[allow(deprecated)]\n    fn as_raw_stat(&self) -> &raw::stat;\n\n    #[stable(feature = \"metadata_ext2\", since = \"1.8.0\")]\n    fn st_dev(&self) -> u64;\n    #[stable(feature = \"metadata_ext2\", since = \"1.8.0\")]\n    fn st_ino(&self) -> u64;\n    #[stable(feature = \"metadata_ext2\", since = \"1.8.0\")]\n    fn st_mode(&self) -> u32;\n    #[stable(feature = \"metadata_ext2\", since = \"1.8.0\")]\n    fn st_nlink(&self) -> u64;\n    #[stable(feature = \"metadata_ext2\", since = \"1.8.0\")]\n    fn st_uid(&self) -> u32;\n    #[stable(feature = \"metadata_ext2\", since = \"1.8.0\")]\n    fn st_gid(&self) -> u32;\n    #[stable(feature = \"metadata_ext2\", since = \"1.8.0\")]\n    fn st_rdev(&self) -> u64;\n    #[stable(feature = \"metadata_ext2\", since = \"1.8.0\")]\n    fn st_size(&self) -> u64;\n    #[stable(feature = \"metadata_ext2\", since = \"1.8.0\")]\n    fn st_atime(&self) -> i64;\n    #[stable(feature = \"metadata_ext2\", since = \"1.8.0\")]\n    fn st_atime_nsec(&self) -> i64;\n    #[stable(feature = \"metadata_ext2\", since = \"1.8.0\")]\n    fn st_mtime(&self) -> i64;\n    #[stable(feature = \"metadata_ext2\", since = \"1.8.0\")]\n    fn st_mtime_nsec(&self) -> i64;\n    #[stable(feature = \"metadata_ext2\", since = \"1.8.0\")]\n    fn st_ctime(&self) -> i64;\n    #[stable(feature = \"metadata_ext2\", since = \"1.8.0\")]\n    fn st_ctime_nsec(&self) -> i64;\n    #[stable(feature = \"metadata_ext2\", since = \"1.8.0\")]\n    fn st_crtime(&self) -> i64;\n    #[stable(feature = \"metadata_ext2\", since = \"1.8.0\")]\n    fn st_crtime_nsec(&self) -> i64;\n    #[stable(feature = \"metadata_ext2\", since = \"1.8.0\")]\n    fn st_blksize(&self) -> u64;\n    #[stable(feature = \"metadata_ext2\", since = \"1.8.0\")]\n    fn st_blocks(&self) -> u64;\n}\n\n#[stable(feature = \"metadata_ext\", since = \"1.1.0\")]\nimpl MetadataExt for Metadata {\n    #[allow(deprecated)]\n    fn as_raw_stat(&self) -> &raw::stat {\n        unsafe { &*(self.as_inner().as_inner() as *const libc::stat as *const raw::stat) }\n    }\n    fn st_dev(&self) -> u64 {\n        self.as_inner().as_inner().st_dev as u64\n    }\n    fn st_ino(&self) -> u64 {\n        self.as_inner().as_inner().st_ino as u64\n    }\n    fn st_mode(&self) -> u32 {\n        self.as_inner().as_inner().st_mode as u32\n    }\n    fn st_nlink(&self) -> u64 {\n        self.as_inner().as_inner().st_nlink as u64\n    }\n    fn st_uid(&self) -> u32 {\n        self.as_inner().as_inner().st_uid as u32\n    }\n    fn st_gid(&self) -> u32 {\n        self.as_inner().as_inner().st_gid as u32\n    }\n    fn st_rdev(&self) -> u64 {\n        self.as_inner().as_inner().st_rdev as u64\n    }\n    fn st_size(&self) -> u64 {\n        self.as_inner().as_inner().st_size as u64\n    }\n    fn st_atime(&self) -> i64 {\n        self.as_inner().as_inner().st_atime as i64\n    }\n    fn st_atime_nsec(&self) -> i64 {\n        self.as_inner().as_inner().st_atime_nsec as i64\n    }\n    fn st_mtime(&self) -> i64 {\n        self.as_inner().as_inner().st_mtime as i64\n    }\n    fn st_mtime_nsec(&self) -> i64 {\n        self.as_inner().as_inner().st_mtime_nsec as i64\n    }\n    fn st_ctime(&self) -> i64 {\n        self.as_inner().as_inner().st_ctime as i64\n    }\n    fn st_ctime_nsec(&self) -> i64 {\n        self.as_inner().as_inner().st_ctime_nsec as i64\n    }\n    fn st_crtime(&self) -> i64 {\n        self.as_inner().as_inner().st_crtime as i64\n    }\n    fn st_crtime_nsec(&self) -> i64 {\n        self.as_inner().as_inner().st_crtime_nsec as i64\n    }\n    fn st_blksize(&self) -> u64 {\n        self.as_inner().as_inner().st_blksize as u64\n    }\n    fn st_blocks(&self) -> u64 {\n        self.as_inner().as_inner().st_blocks as u64\n    }\n}\n"],[2209,"//! Haiku-specific raw type definitions\n\n#![stable(feature = \"raw_ext\", since = \"1.1.0\")]\n#![rustc_deprecated(\n    since = \"1.53.0\",\n    reason = \"these type aliases are no longer supported by \\\n              the standard library, the `libc` crate on \\\n              crates.io should be used instead for the correct \\\n              definitions\"\n)]\n#![allow(deprecated)]\n\nuse crate::os::raw::c_long;\nuse crate::os::unix::raw::{gid_t, uid_t};\n\n// Use the direct definition of usize, instead of uintptr_t like in libc\n#[stable(feature = \"pthread_t\", since = \"1.8.0\")]\npub type pthread_t = usize;\n\n#[stable(feature = \"raw_ext\", since = \"1.1.0\")]\npub type blkcnt_t = i64;\n#[stable(feature = \"raw_ext\", since = \"1.1.0\")]\npub type blksize_t = i32;\n#[stable(feature = \"raw_ext\", since = \"1.1.0\")]\npub type dev_t = i32;\n#[stable(feature = \"raw_ext\", since = \"1.1.0\")]\npub type ino_t = i64;\n#[stable(feature = \"raw_ext\", since = \"1.1.0\")]\npub type mode_t = u32;\n#[stable(feature = \"raw_ext\", since = \"1.1.0\")]\npub type nlink_t = i32;\n#[stable(feature = \"raw_ext\", since = \"1.1.0\")]\npub type off_t = i64;\n#[stable(feature = \"raw_ext\", since = \"1.1.0\")]\npub type time_t = i32;\n\n#[repr(C)]\n#[derive(Clone)]\n#[stable(feature = \"raw_ext\", since = \"1.1.0\")]\npub struct stat {\n    #[stable(feature = \"raw_ext\", since = \"1.1.0\")]\n    pub st_dev: dev_t,\n    #[stable(feature = \"raw_ext\", since = \"1.1.0\")]\n    pub st_ino: ino_t,\n    #[stable(feature = \"raw_ext\", since = \"1.1.0\")]\n    pub st_mode: mode_t,\n    #[stable(feature = \"raw_ext\", since = \"1.1.0\")]\n    pub st_nlink: nlink_t,\n    #[stable(feature = \"raw_ext\", since = \"1.1.0\")]\n    pub st_uid: uid_t,\n    #[stable(feature = \"raw_ext\", since = \"1.1.0\")]\n    pub st_gid: gid_t,\n    #[stable(feature = \"raw_ext\", since = \"1.1.0\")]\n    pub st_size: off_t,\n    #[stable(feature = \"raw_ext\", since = \"1.1.0\")]\n    pub st_rdev: dev_t,\n    #[stable(feature = \"raw_ext\", since = \"1.1.0\")]\n    pub st_blksize: blksize_t,\n    #[stable(feature = \"raw_ext\", since = \"1.1.0\")]\n    pub st_atime: time_t,\n    #[stable(feature = \"raw_ext\", since = \"1.1.0\")]\n    pub st_atime_nsec: c_long,\n    #[stable(feature = \"raw_ext\", since = \"1.1.0\")]\n    pub st_mtime: time_t,\n    #[stable(feature = \"raw_ext\", since = \"1.1.0\")]\n    pub st_mtime_nsec: c_long,\n    #[stable(feature = \"raw_ext\", since = \"1.1.0\")]\n    pub st_ctime: time_t,\n    #[stable(feature = \"raw_ext\", since = \"1.1.0\")]\n    pub st_ctime_nsec: c_long,\n    #[stable(feature = \"raw_ext\", since = \"1.1.0\")]\n    pub st_crtime: time_t,\n    #[stable(feature = \"raw_ext\", since = \"1.1.0\")]\n    pub st_crtime_nsec: c_long,\n    #[stable(feature = \"raw_ext\", since = \"1.1.0\")]\n    pub st_type: u32,\n    #[stable(feature = \"raw_ext\", since = \"1.1.0\")]\n    pub st_blocks: blkcnt_t,\n}\n"],[2210,"//! Haiku-specific definitions\n\n#![stable(feature = \"raw_ext\", since = \"1.1.0\")]\n\npub mod fs;\npub mod raw;\n"],[2211,"#![stable(feature = \"metadata_ext\", since = \"1.1.0\")]\n\nuse crate::fs::Metadata;\nuse crate::sys_common::AsInner;\n\n#[allow(deprecated)]\nuse crate::os::openbsd::raw;\n\n/// OS-specific extensions to [`fs::Metadata`].\n///\n/// [`fs::Metadata`]: crate::fs::Metadata\n#[stable(feature = \"metadata_ext\", since = \"1.1.0\")]\npub trait MetadataExt {\n    /// Gain a reference to the underlying `stat` structure which contains\n    /// the raw information returned by the OS.\n    ///\n    /// The contents of the returned `stat` are **not** consistent across\n    /// Unix platforms. The `os::unix::fs::MetadataExt` trait contains the\n    /// cross-Unix abstractions contained within the raw stat.\n    #[stable(feature = \"metadata_ext\", since = \"1.1.0\")]\n    #[rustc_deprecated(\n        since = \"1.8.0\",\n        reason = \"deprecated in favor of the accessor \\\n                  methods of this trait\"\n    )]\n    #[allow(deprecated)]\n    fn as_raw_stat(&self) -> &raw::stat;\n\n    #[stable(feature = \"metadata_ext2\", since = \"1.8.0\")]\n    fn st_dev(&self) -> u64;\n    #[stable(feature = \"metadata_ext2\", since = \"1.8.0\")]\n    fn st_ino(&self) -> u64;\n    #[stable(feature = \"metadata_ext2\", since = \"1.8.0\")]\n    fn st_mode(&self) -> u32;\n    #[stable(feature = \"metadata_ext2\", since = \"1.8.0\")]\n    fn st_nlink(&self) -> u64;\n    #[stable(feature = \"metadata_ext2\", since = \"1.8.0\")]\n    fn st_uid(&self) -> u32;\n    #[stable(feature = \"metadata_ext2\", since = \"1.8.0\")]\n    fn st_gid(&self) -> u32;\n    #[stable(feature = \"metadata_ext2\", since = \"1.8.0\")]\n    fn st_rdev(&self) -> u64;\n    #[stable(feature = \"metadata_ext2\", since = \"1.8.0\")]\n    fn st_size(&self) -> u64;\n    #[stable(feature = \"metadata_ext2\", since = \"1.8.0\")]\n    fn st_atime(&self) -> i64;\n    #[stable(feature = \"metadata_ext2\", since = \"1.8.0\")]\n    fn st_atime_nsec(&self) -> i64;\n    #[stable(feature = \"metadata_ext2\", since = \"1.8.0\")]\n    fn st_mtime(&self) -> i64;\n    #[stable(feature = \"metadata_ext2\", since = \"1.8.0\")]\n    fn st_mtime_nsec(&self) -> i64;\n    #[stable(feature = \"metadata_ext2\", since = \"1.8.0\")]\n    fn st_ctime(&self) -> i64;\n    #[stable(feature = \"metadata_ext2\", since = \"1.8.0\")]\n    fn st_ctime_nsec(&self) -> i64;\n    #[stable(feature = \"metadata_ext2\", since = \"1.8.0\")]\n    fn st_birthtime(&self) -> i64;\n    #[stable(feature = \"metadata_ext2\", since = \"1.8.0\")]\n    fn st_birthtime_nsec(&self) -> i64;\n    #[stable(feature = \"metadata_ext2\", since = \"1.8.0\")]\n    fn st_blksize(&self) -> u64;\n    #[stable(feature = \"metadata_ext2\", since = \"1.8.0\")]\n    fn st_blocks(&self) -> u64;\n    #[stable(feature = \"metadata_ext2\", since = \"1.8.0\")]\n    fn st_flags(&self) -> u32;\n    #[stable(feature = \"metadata_ext2\", since = \"1.8.0\")]\n    fn st_gen(&self) -> u32;\n}\n\n#[stable(feature = \"metadata_ext\", since = \"1.1.0\")]\nimpl MetadataExt for Metadata {\n    #[allow(deprecated)]\n    fn as_raw_stat(&self) -> &raw::stat {\n        unsafe { &*(self.as_inner().as_inner() as *const libc::stat as *const raw::stat) }\n    }\n    fn st_dev(&self) -> u64 {\n        self.as_inner().as_inner().st_dev as u64\n    }\n    fn st_ino(&self) -> u64 {\n        self.as_inner().as_inner().st_ino as u64\n    }\n    fn st_mode(&self) -> u32 {\n        self.as_inner().as_inner().st_mode as u32\n    }\n    fn st_nlink(&self) -> u64 {\n        self.as_inner().as_inner().st_nlink as u64\n    }\n    fn st_uid(&self) -> u32 {\n        self.as_inner().as_inner().st_uid as u32\n    }\n    fn st_gid(&self) -> u32 {\n        self.as_inner().as_inner().st_gid as u32\n    }\n    fn st_rdev(&self) -> u64 {\n        self.as_inner().as_inner().st_rdev as u64\n    }\n    fn st_size(&self) -> u64 {\n        self.as_inner().as_inner().st_size as u64\n    }\n    fn st_atime(&self) -> i64 {\n        self.as_inner().as_inner().st_atime as i64\n    }\n    fn st_atime_nsec(&self) -> i64 {\n        self.as_inner().as_inner().st_atime_nsec as i64\n    }\n    fn st_mtime(&self) -> i64 {\n        self.as_inner().as_inner().st_mtime as i64\n    }\n    fn st_mtime_nsec(&self) -> i64 {\n        self.as_inner().as_inner().st_mtime_nsec as i64\n    }\n    fn st_ctime(&self) -> i64 {\n        self.as_inner().as_inner().st_ctime as i64\n    }\n    fn st_ctime_nsec(&self) -> i64 {\n        self.as_inner().as_inner().st_ctime_nsec as i64\n    }\n    fn st_birthtime(&self) -> i64 {\n        self.as_inner().as_inner().st_birthtime as i64\n    }\n    fn st_birthtime_nsec(&self) -> i64 {\n        self.as_inner().as_inner().st_birthtime_nsec as i64\n    }\n    fn st_blksize(&self) -> u64 {\n        self.as_inner().as_inner().st_blksize as u64\n    }\n    fn st_blocks(&self) -> u64 {\n        self.as_inner().as_inner().st_blocks as u64\n    }\n    fn st_gen(&self) -> u32 {\n        self.as_inner().as_inner().st_gen as u32\n    }\n    fn st_flags(&self) -> u32 {\n        self.as_inner().as_inner().st_flags as u32\n    }\n}\n"],[2212,"//! OpenBSD-specific definitions\n\n#![stable(feature = \"raw_ext\", since = \"1.1.0\")]\n\npub mod fs;\npub mod raw;\n"],[2213,"//! OpenBSD-specific raw type definitions\n\n#![stable(feature = \"raw_ext\", since = \"1.1.0\")]\n#![rustc_deprecated(\n    since = \"1.8.0\",\n    reason = \"these type aliases are no longer supported by \\\n              the standard library, the `libc` crate on \\\n              crates.io should be used instead for the correct \\\n              definitions\"\n)]\n#![allow(deprecated)]\n\nuse crate::os::raw::c_long;\n\n#[stable(feature = \"raw_ext\", since = \"1.1.0\")]\npub type blkcnt_t = u64;\n#[stable(feature = \"raw_ext\", since = \"1.1.0\")]\npub type blksize_t = u64;\n#[stable(feature = \"raw_ext\", since = \"1.1.0\")]\npub type dev_t = u64;\n#[stable(feature = \"raw_ext\", since = \"1.1.0\")]\npub type fflags_t = u32;\n#[stable(feature = \"raw_ext\", since = \"1.1.0\")]\npub type ino_t = u64;\n#[stable(feature = \"raw_ext\", since = \"1.1.0\")]\npub type mode_t = u32;\n#[stable(feature = \"raw_ext\", since = \"1.1.0\")]\npub type nlink_t = u64;\n#[stable(feature = \"raw_ext\", since = \"1.1.0\")]\npub type off_t = u64;\n#[stable(feature = \"raw_ext\", since = \"1.1.0\")]\npub type time_t = i64;\n\n#[stable(feature = \"pthread_t\", since = \"1.8.0\")]\npub type pthread_t = usize;\n\n#[repr(C)]\n#[derive(Clone)]\n#[stable(feature = \"raw_ext\", since = \"1.1.0\")]\npub struct stat {\n    #[stable(feature = \"raw_ext\", since = \"1.1.0\")]\n    pub st_mode: u32,\n    #[stable(feature = \"raw_ext\", since = \"1.1.0\")]\n    pub st_dev: i32,\n    #[stable(feature = \"raw_ext\", since = \"1.1.0\")]\n    pub st_ino: u64,\n    #[stable(feature = \"raw_ext\", since = \"1.1.0\")]\n    pub st_nlink: u32,\n    #[stable(feature = \"raw_ext\", since = \"1.1.0\")]\n    pub st_uid: u32,\n    #[stable(feature = \"raw_ext\", since = \"1.1.0\")]\n    pub st_gid: u32,\n    #[stable(feature = \"raw_ext\", since = \"1.1.0\")]\n    pub st_rdev: i32,\n    #[stable(feature = \"raw_ext\", since = \"1.1.0\")]\n    pub st_atime: i64,\n    #[stable(feature = \"raw_ext\", since = \"1.1.0\")]\n    pub st_atime_nsec: c_long,\n    #[stable(feature = \"raw_ext\", since = \"1.1.0\")]\n    pub st_mtime: i64,\n    #[stable(feature = \"raw_ext\", since = \"1.1.0\")]\n    pub st_mtime_nsec: c_long,\n    #[stable(feature = \"raw_ext\", since = \"1.1.0\")]\n    pub st_ctime: i64,\n    #[stable(feature = \"raw_ext\", since = \"1.1.0\")]\n    pub st_ctime_nsec: c_long,\n    #[stable(feature = \"raw_ext\", since = \"1.1.0\")]\n    pub st_size: i64,\n    #[stable(feature = \"raw_ext\", since = \"1.1.0\")]\n    pub st_blocks: i64,\n    #[stable(feature = \"raw_ext\", since = \"1.1.0\")]\n    pub st_blksize: i32,\n    #[stable(feature = \"raw_ext\", since = \"1.1.0\")]\n    pub st_flags: u32,\n    #[stable(feature = \"raw_ext\", since = \"1.1.0\")]\n    pub st_gen: u32,\n    #[stable(feature = \"raw_ext\", since = \"1.1.0\")]\n    pub st_birthtime: i64,\n    #[stable(feature = \"raw_ext\", since = \"1.1.0\")]\n    pub st_birthtime_nsec: c_long,\n}\n"],[2214,"use crate::any::TypeId;\n\nmacro_rules! ok {\n    ($($t:ident)*) => {$(\n        assert!(TypeId::of::<libc::$t>() == TypeId::of::<raw::$t>(),\n                \"{} is wrong\", stringify!($t));\n    )*}\n}\n\n#[test]\nfn same() {\n    use crate::os::raw;\n    ok!(c_char c_schar c_uchar c_short c_ushort c_int c_uint c_long c_ulong\n        c_longlong c_ulonglong c_float c_double);\n}\n"],[2215,"//! Platform-specific types, as defined by C.\n//!\n//! Code that interacts via FFI will almost certainly be using the\n//! base types provided by C, which aren't nearly as nicely defined\n//! as Rust's primitive types. This module provides types which will\n//! match those defined by C, so that code that interacts with C will\n//! refer to the correct types.\n\n#![stable(feature = \"raw_os\", since = \"1.1.0\")]\n\n#[cfg(test)]\nmod tests;\n\nuse core::num::*;\n\nmacro_rules! type_alias_no_nz {\n    {\n      $Docfile:tt, $Alias:ident = $Real:ty;\n      $( $Cfg:tt )*\n    } => {\n        #[doc = include_str!($Docfile)]\n        $( $Cfg )*\n        #[stable(feature = \"raw_os\", since = \"1.1.0\")]\n        pub type $Alias = $Real;\n    }\n}\n\n// To verify that the NonZero types in this file's macro invocations correspond\n//\n//  perl -n < library/std/src/os/raw/mod.rs -e 'next unless m/type_alias\\!/; die \"$_ ?\" unless m/, (c_\\w+) = (\\w+), NonZero_(\\w+) = NonZero(\\w+)/; die \"$_ ?\" unless $3 eq $1 and $4 eq ucfirst $2'\n//\n// NB this does not check that the main c_* types are right.\n\nmacro_rules! type_alias {\n    {\n      $Docfile:tt, $Alias:ident = $Real:ty, $NZAlias:ident = $NZReal:ty;\n      $( $Cfg:tt )*\n    } => {\n        type_alias_no_nz! { $Docfile, $Alias = $Real; $( $Cfg )* }\n\n        #[doc = concat!(\"Type alias for `NonZero` version of [`\", stringify!($Alias), \"`]\")]\n        #[unstable(feature = \"raw_os_nonzero\", issue = \"82363\")]\n        $( $Cfg )*\n        pub type $NZAlias = $NZReal;\n    }\n}\n\ntype_alias! { \"char.md\", c_char = u8, NonZero_c_char = NonZeroU8;\n#[cfg(any(\n    all(\n        target_os = \"linux\",\n        any(\n            target_arch = \"aarch64\",\n            target_arch = \"arm\",\n            target_arch = \"hexagon\",\n            target_arch = \"powerpc\",\n            target_arch = \"powerpc64\",\n            target_arch = \"s390x\",\n            target_arch = \"riscv64\",\n            target_arch = \"riscv32\"\n        )\n    ),\n    all(target_os = \"android\", any(target_arch = \"aarch64\", target_arch = \"arm\")),\n    all(target_os = \"l4re\", target_arch = \"x86_64\"),\n    all(\n        target_os = \"freebsd\",\n        any(\n            target_arch = \"aarch64\",\n            target_arch = \"arm\",\n            target_arch = \"powerpc\",\n            target_arch = \"powerpc64\"\n        )\n    ),\n    all(\n        target_os = \"netbsd\",\n        any(target_arch = \"aarch64\", target_arch = \"arm\", target_arch = \"powerpc\")\n    ),\n    all(target_os = \"openbsd\", target_arch = \"aarch64\"),\n    all(\n        target_os = \"vxworks\",\n        any(\n            target_arch = \"aarch64\",\n            target_arch = \"arm\",\n            target_arch = \"powerpc64\",\n            target_arch = \"powerpc\"\n        )\n    ),\n    all(target_os = \"fuchsia\", target_arch = \"aarch64\")\n))]}\ntype_alias! { \"char.md\", c_char = i8, NonZero_c_char = NonZeroI8;\n#[cfg(not(any(\n    all(\n        target_os = \"linux\",\n        any(\n            target_arch = \"aarch64\",\n            target_arch = \"arm\",\n            target_arch = \"hexagon\",\n            target_arch = \"powerpc\",\n            target_arch = \"powerpc64\",\n            target_arch = \"s390x\",\n            target_arch = \"riscv64\",\n            target_arch = \"riscv32\"\n        )\n    ),\n    all(target_os = \"android\", any(target_arch = \"aarch64\", target_arch = \"arm\")),\n    all(target_os = \"l4re\", target_arch = \"x86_64\"),\n    all(\n        target_os = \"freebsd\",\n        any(\n            target_arch = \"aarch64\",\n            target_arch = \"arm\",\n            target_arch = \"powerpc\",\n            target_arch = \"powerpc64\"\n        )\n    ),\n    all(\n        target_os = \"netbsd\",\n        any(target_arch = \"aarch64\", target_arch = \"arm\", target_arch = \"powerpc\")\n    ),\n    all(target_os = \"openbsd\", target_arch = \"aarch64\"),\n    all(\n        target_os = \"vxworks\",\n        any(\n            target_arch = \"aarch64\",\n            target_arch = \"arm\",\n            target_arch = \"powerpc64\",\n            target_arch = \"powerpc\"\n        )\n    ),\n    all(target_os = \"fuchsia\", target_arch = \"aarch64\")\n)))]}\ntype_alias! { \"schar.md\", c_schar = i8, NonZero_c_schar = NonZeroI8; }\ntype_alias! { \"uchar.md\", c_uchar = u8, NonZero_c_uchar = NonZeroU8; }\ntype_alias! { \"short.md\", c_short = i16, NonZero_c_short = NonZeroI16; }\ntype_alias! { \"ushort.md\", c_ushort = u16, NonZero_c_ushort = NonZeroU16; }\ntype_alias! { \"int.md\", c_int = i32, NonZero_c_int = NonZeroI32; }\ntype_alias! { \"uint.md\", c_uint = u32, NonZero_c_uint = NonZeroU32; }\ntype_alias! { \"long.md\", c_long = i32, NonZero_c_long = NonZeroI32;\n#[cfg(any(target_pointer_width = \"32\", windows))] }\ntype_alias! { \"ulong.md\", c_ulong = u32, NonZero_c_ulong = NonZeroU32;\n#[cfg(any(target_pointer_width = \"32\", windows))] }\ntype_alias! { \"long.md\", c_long = i64, NonZero_c_long = NonZeroI64;\n#[cfg(all(target_pointer_width = \"64\", not(windows)))] }\ntype_alias! { \"ulong.md\", c_ulong = u64, NonZero_c_ulong = NonZeroU64;\n#[cfg(all(target_pointer_width = \"64\", not(windows)))] }\ntype_alias! { \"longlong.md\", c_longlong = i64, NonZero_c_longlong = NonZeroI64; }\ntype_alias! { \"ulonglong.md\", c_ulonglong = u64, NonZero_c_ulonglong = NonZeroU64; }\ntype_alias_no_nz! { \"float.md\", c_float = f32; }\ntype_alias_no_nz! { \"double.md\", c_double = f64; }\n\n#[stable(feature = \"raw_os\", since = \"1.1.0\")]\n#[doc(no_inline)]\npub use core::ffi::c_void;\n"],[2216,"//! Utilities related to FFI bindings.\n//!\n//! This module provides utilities to handle data across non-Rust\n//! interfaces, like other programming languages and the underlying\n//! operating system. It is mainly of use for FFI (Foreign Function\n//! Interface) bindings and code that needs to exchange C-like strings\n//! with other languages.\n//!\n//! # Overview\n//!\n//! Rust represents owned strings with the [`String`] type, and\n//! borrowed slices of strings with the [`str`] primitive. Both are\n//! always in UTF-8 encoding, and may contain nul bytes in the middle,\n//! i.e., if you look at the bytes that make up the string, there may\n//! be a `\\0` among them. Both `String` and `str` store their length\n//! explicitly; there are no nul terminators at the end of strings\n//! like in C.\n//!\n//! C strings are different from Rust strings:\n//!\n//! * **Encodings** - Rust strings are UTF-8, but C strings may use\n//! other encodings. If you are using a string from C, you should\n//! check its encoding explicitly, rather than just assuming that it\n//! is UTF-8 like you can do in Rust.\n//!\n//! * **Character size** - C strings may use `char` or `wchar_t`-sized\n//! characters; please **note** that C's `char` is different from Rust's.\n//! The C standard leaves the actual sizes of those types open to\n//! interpretation, but defines different APIs for strings made up of\n//! each character type. Rust strings are always UTF-8, so different\n//! Unicode characters will be encoded in a variable number of bytes\n//! each. The Rust type [`char`] represents a '[Unicode scalar\n//! value]', which is similar to, but not the same as, a '[Unicode\n//! code point]'.\n//!\n//! * **Nul terminators and implicit string lengths** - Often, C\n//! strings are nul-terminated, i.e., they have a `\\0` character at the\n//! end. The length of a string buffer is not stored, but has to be\n//! calculated; to compute the length of a string, C code must\n//! manually call a function like `strlen()` for `char`-based strings,\n//! or `wcslen()` for `wchar_t`-based ones. Those functions return\n//! the number of characters in the string excluding the nul\n//! terminator, so the buffer length is really `len+1` characters.\n//! Rust strings don't have a nul terminator; their length is always\n//! stored and does not need to be calculated. While in Rust\n//! accessing a string's length is a `O(1)` operation (because the\n//! length is stored); in C it is an `O(length)` operation because the\n//! length needs to be computed by scanning the string for the nul\n//! terminator.\n//!\n//! * **Internal nul characters** - When C strings have a nul\n//! terminator character, this usually means that they cannot have nul\n//! characters in the middle — a nul character would essentially\n//! truncate the string. Rust strings *can* have nul characters in\n//! the middle, because nul does not have to mark the end of the\n//! string in Rust.\n//!\n//! # Representations of non-Rust strings\n//!\n//! [`CString`] and [`CStr`] are useful when you need to transfer\n//! UTF-8 strings to and from languages with a C ABI, like Python.\n//!\n//! * **From Rust to C:** [`CString`] represents an owned, C-friendly\n//! string: it is nul-terminated, and has no internal nul characters.\n//! Rust code can create a [`CString`] out of a normal string (provided\n//! that the string doesn't have nul characters in the middle), and\n//! then use a variety of methods to obtain a raw `*mut `[`u8`] that can\n//! then be passed as an argument to functions which use the C\n//! conventions for strings.\n//!\n//! * **From C to Rust:** [`CStr`] represents a borrowed C string; it\n//! is what you would use to wrap a raw `*const `[`u8`] that you got from\n//! a C function. A [`CStr`] is guaranteed to be a nul-terminated array\n//! of bytes. Once you have a [`CStr`], you can convert it to a Rust\n//! [`&str`][`str`] if it's valid UTF-8, or lossily convert it by adding\n//! replacement characters.\n//!\n//! [`OsString`] and [`OsStr`] are useful when you need to transfer\n//! strings to and from the operating system itself, or when capturing\n//! the output of external commands. Conversions between [`OsString`],\n//! [`OsStr`] and Rust strings work similarly to those for [`CString`]\n//! and [`CStr`].\n//!\n//! * [`OsString`] represents an owned string in whatever\n//! representation the operating system prefers. In the Rust standard\n//! library, various APIs that transfer strings to/from the operating\n//! system use [`OsString`] instead of plain strings. For example,\n//! [`env::var_os()`] is used to query environment variables; it\n//! returns an [`Option`]`<`[`OsString`]`>`. If the environment variable\n//! exists you will get a [`Some`]`(os_string)`, which you can *then* try to\n//! convert to a Rust string. This yields a [`Result`], so that\n//! your code can detect errors in case the environment variable did\n//! not in fact contain valid Unicode data.\n//!\n//! * [`OsStr`] represents a borrowed reference to a string in a\n//! format that can be passed to the operating system. It can be\n//! converted into an UTF-8 Rust string slice in a similar way to\n//! [`OsString`].\n//!\n//! # Conversions\n//!\n//! ## On Unix\n//!\n//! On Unix, [`OsStr`] implements the\n//! `std::os::unix::ffi::`[`OsStrExt`][unix.OsStrExt] trait, which\n//! augments it with two methods, [`from_bytes`] and [`as_bytes`].\n//! These do inexpensive conversions from and to UTF-8 byte slices.\n//!\n//! Additionally, on Unix [`OsString`] implements the\n//! `std::os::unix::ffi::`[`OsStringExt`][unix.OsStringExt] trait,\n//! which provides [`from_vec`] and [`into_vec`] methods that consume\n//! their arguments, and take or produce vectors of [`u8`].\n//!\n//! ## On Windows\n//!\n//! On Windows, [`OsStr`] implements the\n//! `std::os::windows::ffi::`[`OsStrExt`][windows.OsStrExt] trait,\n//! which provides an [`encode_wide`] method. This provides an\n//! iterator that can be [`collect`]ed into a vector of [`u16`].\n//!\n//! Additionally, on Windows [`OsString`] implements the\n//! `std::os::windows:ffi::`[`OsStringExt`][windows.OsStringExt]\n//! trait, which provides a [`from_wide`] method. The result of this\n//! method is an [`OsString`] which can be round-tripped to a Windows\n//! string losslessly.\n//!\n//! [Unicode scalar value]: https://www.unicode.org/glossary/#unicode_scalar_value\n//! [Unicode code point]: https://www.unicode.org/glossary/#code_point\n//! [`env::set_var()`]: crate::env::set_var\n//! [`env::var_os()`]: crate::env::var_os\n//! [unix.OsStringExt]: crate::os::unix::ffi::OsStringExt\n//! [`from_vec`]: crate::os::unix::ffi::OsStringExt::from_vec\n//! [`into_vec`]: crate::os::unix::ffi::OsStringExt::into_vec\n//! [unix.OsStrExt]: crate::os::unix::ffi::OsStrExt\n//! [`from_bytes`]: crate::os::unix::ffi::OsStrExt::from_bytes\n//! [`as_bytes`]: crate::os::unix::ffi::OsStrExt::as_bytes\n//! [`OsStrExt`]: crate::os::unix::ffi::OsStrExt\n//! [windows.OsStrExt]: crate::os::windows::ffi::OsStrExt\n//! [`encode_wide`]: crate::os::windows::ffi::OsStrExt::encode_wide\n//! [`collect`]: crate::iter::Iterator::collect\n//! [windows.OsStringExt]: crate::os::windows::ffi::OsStringExt\n//! [`from_wide`]: crate::os::windows::ffi::OsStringExt::from_wide\n\n#![stable(feature = \"rust1\", since = \"1.0.0\")]\n\n#[stable(feature = \"cstr_from_bytes\", since = \"1.10.0\")]\npub use self::c_str::FromBytesWithNulError;\n#[unstable(feature = \"cstring_from_vec_with_nul\", issue = \"73179\")]\npub use self::c_str::FromVecWithNulError;\n#[stable(feature = \"rust1\", since = \"1.0.0\")]\npub use self::c_str::{CStr, CString, IntoStringError, NulError};\n\n#[stable(feature = \"rust1\", since = \"1.0.0\")]\npub use self::os_str::{OsStr, OsString};\n\n#[stable(feature = \"core_c_void\", since = \"1.30.0\")]\npub use core::ffi::c_void;\n\n#[unstable(\n    feature = \"c_variadic\",\n    reason = \"the `c_variadic` feature has not been properly tested on \\\n              all supported platforms\",\n    issue = \"44930\"\n)]\npub use core::ffi::{VaList, VaListImpl};\n\nmod c_str;\nmod os_str;\n"],[2217,"use super::*;\nuse crate::sys_common::{AsInner, IntoInner};\n\nuse crate::rc::Rc;\nuse crate::sync::Arc;\n\n#[test]\nfn test_os_string_with_capacity() {\n    let os_string = OsString::with_capacity(0);\n    assert_eq!(0, os_string.inner.into_inner().capacity());\n\n    let os_string = OsString::with_capacity(10);\n    assert_eq!(10, os_string.inner.into_inner().capacity());\n\n    let mut os_string = OsString::with_capacity(0);\n    os_string.push(\"abc\");\n    assert!(os_string.inner.into_inner().capacity() >= 3);\n}\n\n#[test]\nfn test_os_string_clear() {\n    let mut os_string = OsString::from(\"abc\");\n    assert_eq!(3, os_string.inner.as_inner().len());\n\n    os_string.clear();\n    assert_eq!(&os_string, \"\");\n    assert_eq!(0, os_string.inner.as_inner().len());\n}\n\n#[test]\nfn test_os_string_capacity() {\n    let os_string = OsString::with_capacity(0);\n    assert_eq!(0, os_string.capacity());\n\n    let os_string = OsString::with_capacity(10);\n    assert_eq!(10, os_string.capacity());\n\n    let mut os_string = OsString::with_capacity(0);\n    os_string.push(\"abc\");\n    assert!(os_string.capacity() >= 3);\n}\n\n#[test]\nfn test_os_string_reserve() {\n    let mut os_string = OsString::new();\n    assert_eq!(os_string.capacity(), 0);\n\n    os_string.reserve(2);\n    assert!(os_string.capacity() >= 2);\n\n    for _ in 0..16 {\n        os_string.push(\"a\");\n    }\n\n    assert!(os_string.capacity() >= 16);\n    os_string.reserve(16);\n    assert!(os_string.capacity() >= 32);\n\n    os_string.push(\"a\");\n\n    os_string.reserve(16);\n    assert!(os_string.capacity() >= 33)\n}\n\n#[test]\nfn test_os_string_reserve_exact() {\n    let mut os_string = OsString::new();\n    assert_eq!(os_string.capacity(), 0);\n\n    os_string.reserve_exact(2);\n    assert!(os_string.capacity() >= 2);\n\n    for _ in 0..16 {\n        os_string.push(\"a\");\n    }\n\n    assert!(os_string.capacity() >= 16);\n    os_string.reserve_exact(16);\n    assert!(os_string.capacity() >= 32);\n\n    os_string.push(\"a\");\n\n    os_string.reserve_exact(16);\n    assert!(os_string.capacity() >= 33)\n}\n\n#[test]\nfn test_os_string_default() {\n    let os_string: OsString = Default::default();\n    assert_eq!(\"\", &os_string);\n}\n\n#[test]\nfn test_os_str_is_empty() {\n    let mut os_string = OsString::new();\n    assert!(os_string.is_empty());\n\n    os_string.push(\"abc\");\n    assert!(!os_string.is_empty());\n\n    os_string.clear();\n    assert!(os_string.is_empty());\n}\n\n#[test]\nfn test_os_str_len() {\n    let mut os_string = OsString::new();\n    assert_eq!(0, os_string.len());\n\n    os_string.push(\"abc\");\n    assert_eq!(3, os_string.len());\n\n    os_string.clear();\n    assert_eq!(0, os_string.len());\n}\n\n#[test]\nfn test_os_str_default() {\n    let os_str: &OsStr = Default::default();\n    assert_eq!(\"\", os_str);\n}\n\n#[test]\nfn into_boxed() {\n    let orig = \"Hello, world!\";\n    let os_str = OsStr::new(orig);\n    let boxed: Box<OsStr> = Box::from(os_str);\n    let os_string = os_str.to_owned().into_boxed_os_str().into_os_string();\n    assert_eq!(os_str, &*boxed);\n    assert_eq!(&*boxed, &*os_string);\n    assert_eq!(&*os_string, os_str);\n}\n\n#[test]\nfn boxed_default() {\n    let boxed = <Box<OsStr>>::default();\n    assert!(boxed.is_empty());\n}\n\n#[test]\nfn test_os_str_clone_into() {\n    let mut os_string = OsString::with_capacity(123);\n    os_string.push(\"hello\");\n    let os_str = OsStr::new(\"bonjour\");\n    os_str.clone_into(&mut os_string);\n    assert_eq!(os_str, os_string);\n    assert!(os_string.capacity() >= 123);\n}\n\n#[test]\nfn into_rc() {\n    let orig = \"Hello, world!\";\n    let os_str = OsStr::new(orig);\n    let rc: Rc<OsStr> = Rc::from(os_str);\n    let arc: Arc<OsStr> = Arc::from(os_str);\n\n    assert_eq!(&*rc, os_str);\n    assert_eq!(&*arc, os_str);\n\n    let rc2: Rc<OsStr> = Rc::from(os_str.to_owned());\n    let arc2: Arc<OsStr> = Arc::from(os_str.to_owned());\n\n    assert_eq!(&*rc2, os_str);\n    assert_eq!(&*arc2, os_str);\n}\n"],[2218,"use super::*;\nuse crate::borrow::Cow::{Borrowed, Owned};\nuse crate::collections::hash_map::DefaultHasher;\nuse crate::hash::{Hash, Hasher};\nuse crate::os::raw::c_char;\nuse crate::rc::Rc;\nuse crate::sync::Arc;\n\n#[test]\nfn c_to_rust() {\n    let data = b\"123\\0\";\n    let ptr = data.as_ptr() as *const c_char;\n    unsafe {\n        assert_eq!(CStr::from_ptr(ptr).to_bytes(), b\"123\");\n        assert_eq!(CStr::from_ptr(ptr).to_bytes_with_nul(), b\"123\\0\");\n    }\n}\n\n#[test]\nfn simple() {\n    let s = CString::new(\"1234\").unwrap();\n    assert_eq!(s.as_bytes(), b\"1234\");\n    assert_eq!(s.as_bytes_with_nul(), b\"1234\\0\");\n}\n\n#[test]\nfn build_with_zero1() {\n    assert!(CString::new(&b\"\\0\"[..]).is_err());\n}\n#[test]\nfn build_with_zero2() {\n    assert!(CString::new(vec![0]).is_err());\n}\n\n#[test]\nfn build_with_zero3() {\n    unsafe {\n        let s = CString::from_vec_unchecked(vec![0]);\n        assert_eq!(s.as_bytes(), b\"\\0\");\n    }\n}\n\n#[test]\nfn formatted() {\n    let s = CString::new(&b\"abc\\x01\\x02\\n\\xE2\\x80\\xA6\\xFF\"[..]).unwrap();\n    assert_eq!(format!(\"{:?}\", s), r#\"\"abc\\x01\\x02\\n\\xe2\\x80\\xa6\\xff\"\"#);\n}\n\n#[test]\nfn borrowed() {\n    unsafe {\n        let s = CStr::from_ptr(b\"12\\0\".as_ptr() as *const _);\n        assert_eq!(s.to_bytes(), b\"12\");\n        assert_eq!(s.to_bytes_with_nul(), b\"12\\0\");\n    }\n}\n\n#[test]\nfn to_str() {\n    let data = b\"123\\xE2\\x80\\xA6\\0\";\n    let ptr = data.as_ptr() as *const c_char;\n    unsafe {\n        assert_eq!(CStr::from_ptr(ptr).to_str(), Ok(\"123…\"));\n        assert_eq!(CStr::from_ptr(ptr).to_string_lossy(), Borrowed(\"123…\"));\n    }\n    let data = b\"123\\xE2\\0\";\n    let ptr = data.as_ptr() as *const c_char;\n    unsafe {\n        assert!(CStr::from_ptr(ptr).to_str().is_err());\n        assert_eq!(CStr::from_ptr(ptr).to_string_lossy(), Owned::<str>(format!(\"123\\u{FFFD}\")));\n    }\n}\n\n#[test]\nfn to_owned() {\n    let data = b\"123\\0\";\n    let ptr = data.as_ptr() as *const c_char;\n\n    let owned = unsafe { CStr::from_ptr(ptr).to_owned() };\n    assert_eq!(owned.as_bytes_with_nul(), data);\n}\n\n#[test]\nfn equal_hash() {\n    let data = b\"123\\xE2\\xFA\\xA6\\0\";\n    let ptr = data.as_ptr() as *const c_char;\n    let cstr: &'static CStr = unsafe { CStr::from_ptr(ptr) };\n\n    let mut s = DefaultHasher::new();\n    cstr.hash(&mut s);\n    let cstr_hash = s.finish();\n    let mut s = DefaultHasher::new();\n    CString::new(&data[..data.len() - 1]).unwrap().hash(&mut s);\n    let cstring_hash = s.finish();\n\n    assert_eq!(cstr_hash, cstring_hash);\n}\n\n#[test]\nfn from_bytes_with_nul() {\n    let data = b\"123\\0\";\n    let cstr = CStr::from_bytes_with_nul(data);\n    assert_eq!(cstr.map(CStr::to_bytes), Ok(&b\"123\"[..]));\n    let cstr = CStr::from_bytes_with_nul(data);\n    assert_eq!(cstr.map(CStr::to_bytes_with_nul), Ok(&b\"123\\0\"[..]));\n\n    unsafe {\n        let cstr = CStr::from_bytes_with_nul(data);\n        let cstr_unchecked = CStr::from_bytes_with_nul_unchecked(data);\n        assert_eq!(cstr, Ok(cstr_unchecked));\n    }\n}\n\n#[test]\nfn from_bytes_with_nul_unterminated() {\n    let data = b\"123\";\n    let cstr = CStr::from_bytes_with_nul(data);\n    assert!(cstr.is_err());\n}\n\n#[test]\nfn from_bytes_with_nul_interior() {\n    let data = b\"1\\023\\0\";\n    let cstr = CStr::from_bytes_with_nul(data);\n    assert!(cstr.is_err());\n}\n\n#[test]\nfn into_boxed() {\n    let orig: &[u8] = b\"Hello, world!\\0\";\n    let cstr = CStr::from_bytes_with_nul(orig).unwrap();\n    let boxed: Box<CStr> = Box::from(cstr);\n    let cstring = cstr.to_owned().into_boxed_c_str().into_c_string();\n    assert_eq!(cstr, &*boxed);\n    assert_eq!(&*boxed, &*cstring);\n    assert_eq!(&*cstring, cstr);\n}\n\n#[test]\nfn boxed_default() {\n    let boxed = <Box<CStr>>::default();\n    assert_eq!(boxed.to_bytes_with_nul(), &[0]);\n}\n\n#[test]\nfn test_c_str_clone_into() {\n    let mut c_string = CString::new(\"lorem\").unwrap();\n    let c_ptr = c_string.as_ptr();\n    let c_str = CStr::from_bytes_with_nul(b\"ipsum\\0\").unwrap();\n    c_str.clone_into(&mut c_string);\n    assert_eq!(c_str, c_string.as_c_str());\n    // The exact same size shouldn't have needed to move its allocation\n    assert_eq!(c_ptr, c_string.as_ptr());\n}\n\n#[test]\nfn into_rc() {\n    let orig: &[u8] = b\"Hello, world!\\0\";\n    let cstr = CStr::from_bytes_with_nul(orig).unwrap();\n    let rc: Rc<CStr> = Rc::from(cstr);\n    let arc: Arc<CStr> = Arc::from(cstr);\n\n    assert_eq!(&*rc, cstr);\n    assert_eq!(&*arc, cstr);\n\n    let rc2: Rc<CStr> = Rc::from(cstr.to_owned());\n    let arc2: Arc<CStr> = Arc::from(cstr.to_owned());\n\n    assert_eq!(&*rc2, cstr);\n    assert_eq!(&*arc2, cstr);\n}\n\n#[test]\nfn cstr_const_constructor() {\n    const CSTR: &CStr = unsafe { CStr::from_bytes_with_nul_unchecked(b\"Hello, world!\\0\") };\n\n    assert_eq!(CSTR.to_str().unwrap(), \"Hello, world!\");\n}\n\n#[test]\nfn cstr_index_from() {\n    let original = b\"Hello, world!\\0\";\n    let cstr = CStr::from_bytes_with_nul(original).unwrap();\n    let result = CStr::from_bytes_with_nul(&original[7..]).unwrap();\n\n    assert_eq!(&cstr[7..], result);\n}\n\n#[test]\n#[should_panic]\nfn cstr_index_from_empty() {\n    let original = b\"Hello, world!\\0\";\n    let cstr = CStr::from_bytes_with_nul(original).unwrap();\n    let _ = &cstr[original.len()..];\n}\n\n#[test]\nfn c_string_from_empty_string() {\n    let original = \"\";\n    let cstring = CString::new(original).unwrap();\n    assert_eq!(original.as_bytes(), cstring.as_bytes());\n    assert_eq!([b'\\0'], cstring.as_bytes_with_nul());\n}\n\n#[test]\nfn c_str_from_empty_string() {\n    let original = b\"\\0\";\n    let cstr = CStr::from_bytes_with_nul(original).unwrap();\n    assert_eq!([] as [u8; 0], cstr.to_bytes());\n    assert_eq!([b'\\0'], cstr.to_bytes_with_nul());\n}\n"],[2219,"#[cfg(test)]\nmod tests;\n\nuse crate::borrow::{Borrow, Cow};\nuse crate::cmp;\nuse crate::fmt;\nuse crate::hash::{Hash, Hasher};\nuse crate::iter::{Extend, FromIterator};\nuse crate::ops;\nuse crate::rc::Rc;\nuse crate::str::FromStr;\nuse crate::sync::Arc;\n\nuse crate::sys::os_str::{Buf, Slice};\nuse crate::sys_common::{AsInner, FromInner, IntoInner};\n\n/// A type that can represent owned, mutable platform-native strings, but is\n/// cheaply inter-convertible with Rust strings.\n///\n/// The need for this type arises from the fact that:\n///\n/// * On Unix systems, strings are often arbitrary sequences of non-zero\n///   bytes, in many cases interpreted as UTF-8.\n///\n/// * On Windows, strings are often arbitrary sequences of non-zero 16-bit\n///   values, interpreted as UTF-16 when it is valid to do so.\n///\n/// * In Rust, strings are always valid UTF-8, which may contain zeros.\n///\n/// `OsString` and [`OsStr`] bridge this gap by simultaneously representing Rust\n/// and platform-native string values, and in particular allowing a Rust string\n/// to be converted into an \"OS\" string with no cost if possible. A consequence\n/// of this is that `OsString` instances are *not* `NUL` terminated; in order\n/// to pass to e.g., Unix system call, you should create a [`CStr`].\n///\n/// `OsString` is to [`&OsStr`] as [`String`] is to [`&str`]: the former\n/// in each pair are owned strings; the latter are borrowed\n/// references.\n///\n/// Note, `OsString` and [`OsStr`] internally do not necessarily hold strings in\n/// the form native to the platform; While on Unix, strings are stored as a\n/// sequence of 8-bit values, on Windows, where strings are 16-bit value based\n/// as just discussed, strings are also actually stored as a sequence of 8-bit\n/// values, encoded in a less-strict variant of UTF-8. This is useful to\n/// understand when handling capacity and length values.\n///\n/// # Creating an `OsString`\n///\n/// **From a Rust string**: `OsString` implements\n/// [`From`]`<`[`String`]`>`, so you can use `my_string.from` to\n/// create an `OsString` from a normal Rust string.\n///\n/// **From slices:** Just like you can start with an empty Rust\n/// [`String`] and then [`String::push_str`] `&str`\n/// sub-string slices into it, you can create an empty `OsString` with\n/// the [`OsString::new`] method and then push string slices into it with the\n/// [`OsString::push`] method.\n///\n/// # Extracting a borrowed reference to the whole OS string\n///\n/// You can use the [`OsString::as_os_str`] method to get an `&`[`OsStr`] from\n/// an `OsString`; this is effectively a borrowed reference to the\n/// whole string.\n///\n/// # Conversions\n///\n/// See the [module's toplevel documentation about conversions][conversions] for a discussion on\n/// the traits which `OsString` implements for [conversions] from/to native representations.\n///\n/// [`&OsStr`]: OsStr\n/// [`&str`]: str\n/// [`CStr`]: crate::ffi::CStr\n/// [conversions]: super#conversions\n#[cfg_attr(not(test), rustc_diagnostic_item = \"OsString\")]\n#[stable(feature = \"rust1\", since = \"1.0.0\")]\npub struct OsString {\n    inner: Buf,\n}\n\n/// Allows extension traits within `std`.\n#[unstable(feature = \"sealed\", issue = \"none\")]\nimpl crate::sealed::Sealed for OsString {}\n\n/// Borrowed reference to an OS string (see [`OsString`]).\n///\n/// This type represents a borrowed reference to a string in the operating system's preferred\n/// representation.\n///\n/// `&OsStr` is to [`OsString`] as [`&str`] is to [`String`]: the former in each pair are borrowed\n/// references; the latter are owned strings.\n///\n/// See the [module's toplevel documentation about conversions][conversions] for a discussion on\n/// the traits which `OsStr` implements for [conversions] from/to native representations.\n///\n/// [`&str`]: str\n/// [conversions]: super#conversions\n#[cfg_attr(not(test), rustc_diagnostic_item = \"OsStr\")]\n#[stable(feature = \"rust1\", since = \"1.0.0\")]\n// FIXME:\n// `OsStr::from_inner` current implementation relies\n// on `OsStr` being layout-compatible with `Slice`.\n// When attribute privacy is implemented, `OsStr` should be annotated as `#[repr(transparent)]`.\n// Anyway, `OsStr` representation and layout are considered implementation details, are\n// not documented and must not be relied upon.\npub struct OsStr {\n    inner: Slice,\n}\n\n/// Allows extension traits within `std`.\n#[unstable(feature = \"sealed\", issue = \"none\")]\nimpl crate::sealed::Sealed for OsStr {}\n\nimpl OsString {\n    /// Constructs a new empty `OsString`.\n    ///\n    /// # Examples\n    ///\n    /// ```\n    /// use std::ffi::OsString;\n    ///\n    /// let os_string = OsString::new();\n    /// ```\n    #[stable(feature = \"rust1\", since = \"1.0.0\")]\n    #[inline]\n    pub fn new() -> OsString {\n        OsString { inner: Buf::from_string(String::new()) }\n    }\n\n    /// Converts to an [`OsStr`] slice.\n    ///\n    /// # Examples\n    ///\n    /// ```\n    /// use std::ffi::{OsString, OsStr};\n    ///\n    /// let os_string = OsString::from(\"foo\");\n    /// let os_str = OsStr::new(\"foo\");\n    /// assert_eq!(os_string.as_os_str(), os_str);\n    /// ```\n    #[stable(feature = \"rust1\", since = \"1.0.0\")]\n    #[inline]\n    pub fn as_os_str(&self) -> &OsStr {\n        self\n    }\n\n    /// Converts the `OsString` into a [`String`] if it contains valid Unicode data.\n    ///\n    /// On failure, ownership of the original `OsString` is returned.\n    ///\n    /// # Examples\n    ///\n    /// ```\n    /// use std::ffi::OsString;\n    ///\n    /// let os_string = OsString::from(\"foo\");\n    /// let string = os_string.into_string();\n    /// assert_eq!(string, Ok(String::from(\"foo\")));\n    /// ```\n    #[stable(feature = \"rust1\", since = \"1.0.0\")]\n    #[inline]\n    pub fn into_string(self) -> Result<String, OsString> {\n        self.inner.into_string().map_err(|buf| OsString { inner: buf })\n    }\n\n    /// Extends the string with the given [`&OsStr`] slice.\n    ///\n    /// [`&OsStr`]: OsStr\n    ///\n    /// # Examples\n    ///\n    /// ```\n    /// use std::ffi::OsString;\n    ///\n    /// let mut os_string = OsString::from(\"foo\");\n    /// os_string.push(\"bar\");\n    /// assert_eq!(&os_string, \"foobar\");\n    /// ```\n    #[stable(feature = \"rust1\", since = \"1.0.0\")]\n    #[inline]\n    pub fn push<T: AsRef<OsStr>>(&mut self, s: T) {\n        self.inner.push_slice(&s.as_ref().inner)\n    }\n\n    /// Creates a new `OsString` with the given capacity.\n    ///\n    /// The string will be able to hold exactly `capacity` length units of other\n    /// OS strings without reallocating. If `capacity` is 0, the string will not\n    /// allocate.\n    ///\n    /// See main `OsString` documentation information about encoding.\n    ///\n    /// # Examples\n    ///\n    /// ```\n    /// use std::ffi::OsString;\n    ///\n    /// let mut os_string = OsString::with_capacity(10);\n    /// let capacity = os_string.capacity();\n    ///\n    /// // This push is done without reallocating\n    /// os_string.push(\"foo\");\n    ///\n    /// assert_eq!(capacity, os_string.capacity());\n    /// ```\n    #[stable(feature = \"osstring_simple_functions\", since = \"1.9.0\")]\n    #[inline]\n    pub fn with_capacity(capacity: usize) -> OsString {\n        OsString { inner: Buf::with_capacity(capacity) }\n    }\n\n    /// Truncates the `OsString` to zero length.\n    ///\n    /// # Examples\n    ///\n    /// ```\n    /// use std::ffi::OsString;\n    ///\n    /// let mut os_string = OsString::from(\"foo\");\n    /// assert_eq!(&os_string, \"foo\");\n    ///\n    /// os_string.clear();\n    /// assert_eq!(&os_string, \"\");\n    /// ```\n    #[stable(feature = \"osstring_simple_functions\", since = \"1.9.0\")]\n    #[inline]\n    pub fn clear(&mut self) {\n        self.inner.clear()\n    }\n\n    /// Returns the capacity this `OsString` can hold without reallocating.\n    ///\n    /// See `OsString` introduction for information about encoding.\n    ///\n    /// # Examples\n    ///\n    /// ```\n    /// use std::ffi::OsString;\n    ///\n    /// let os_string = OsString::with_capacity(10);\n    /// assert!(os_string.capacity() >= 10);\n    /// ```\n    #[stable(feature = \"osstring_simple_functions\", since = \"1.9.0\")]\n    #[inline]\n    pub fn capacity(&self) -> usize {\n        self.inner.capacity()\n    }\n\n    /// Reserves capacity for at least `additional` more capacity to be inserted\n    /// in the given `OsString`.\n    ///\n    /// The collection may reserve more space to avoid frequent reallocations.\n    ///\n    /// # Examples\n    ///\n    /// ```\n    /// use std::ffi::OsString;\n    ///\n    /// let mut s = OsString::new();\n    /// s.reserve(10);\n    /// assert!(s.capacity() >= 10);\n    /// ```\n    #[stable(feature = \"osstring_simple_functions\", since = \"1.9.0\")]\n    #[inline]\n    pub fn reserve(&mut self, additional: usize) {\n        self.inner.reserve(additional)\n    }\n\n    /// Reserves the minimum capacity for exactly `additional` more capacity to\n    /// be inserted in the given `OsString`. Does nothing if the capacity is\n    /// already sufficient.\n    ///\n    /// Note that the allocator may give the collection more space than it\n    /// requests. Therefore, capacity can not be relied upon to be precisely\n    /// minimal. Prefer reserve if future insertions are expected.\n    ///\n    /// # Examples\n    ///\n    /// ```\n    /// use std::ffi::OsString;\n    ///\n    /// let mut s = OsString::new();\n    /// s.reserve_exact(10);\n    /// assert!(s.capacity() >= 10);\n    /// ```\n    #[stable(feature = \"osstring_simple_functions\", since = \"1.9.0\")]\n    #[inline]\n    pub fn reserve_exact(&mut self, additional: usize) {\n        self.inner.reserve_exact(additional)\n    }\n\n    /// Shrinks the capacity of the `OsString` to match its length.\n    ///\n    /// # Examples\n    ///\n    /// ```\n    /// use std::ffi::OsString;\n    ///\n    /// let mut s = OsString::from(\"foo\");\n    ///\n    /// s.reserve(100);\n    /// assert!(s.capacity() >= 100);\n    ///\n    /// s.shrink_to_fit();\n    /// assert_eq!(3, s.capacity());\n    /// ```\n    #[stable(feature = \"osstring_shrink_to_fit\", since = \"1.19.0\")]\n    #[inline]\n    pub fn shrink_to_fit(&mut self) {\n        self.inner.shrink_to_fit()\n    }\n\n    /// Shrinks the capacity of the `OsString` with a lower bound.\n    ///\n    /// The capacity will remain at least as large as both the length\n    /// and the supplied value.\n    ///\n    /// If the current capacity is less than the lower limit, this is a no-op.\n    ///\n    /// # Examples\n    ///\n    /// ```\n    /// #![feature(shrink_to)]\n    /// use std::ffi::OsString;\n    ///\n    /// let mut s = OsString::from(\"foo\");\n    ///\n    /// s.reserve(100);\n    /// assert!(s.capacity() >= 100);\n    ///\n    /// s.shrink_to(10);\n    /// assert!(s.capacity() >= 10);\n    /// s.shrink_to(0);\n    /// assert!(s.capacity() >= 3);\n    /// ```\n    #[inline]\n    #[unstable(feature = \"shrink_to\", reason = \"new API\", issue = \"56431\")]\n    pub fn shrink_to(&mut self, min_capacity: usize) {\n        self.inner.shrink_to(min_capacity)\n    }\n\n    /// Converts this `OsString` into a boxed [`OsStr`].\n    ///\n    /// # Examples\n    ///\n    /// ```\n    /// use std::ffi::{OsString, OsStr};\n    ///\n    /// let s = OsString::from(\"hello\");\n    ///\n    /// let b: Box<OsStr> = s.into_boxed_os_str();\n    /// ```\n    #[stable(feature = \"into_boxed_os_str\", since = \"1.20.0\")]\n    pub fn into_boxed_os_str(self) -> Box<OsStr> {\n        let rw = Box::into_raw(self.inner.into_box()) as *mut OsStr;\n        unsafe { Box::from_raw(rw) }\n    }\n}\n\n#[stable(feature = \"rust1\", since = \"1.0.0\")]\nimpl From<String> for OsString {\n    /// Converts a [`String`] into a [`OsString`].\n    ///\n    /// This conversion does not allocate or copy memory.\n    #[inline]\n    fn from(s: String) -> OsString {\n        OsString { inner: Buf::from_string(s) }\n    }\n}\n\n#[stable(feature = \"rust1\", since = \"1.0.0\")]\nimpl<T: ?Sized + AsRef<OsStr>> From<&T> for OsString {\n    fn from(s: &T) -> OsString {\n        s.as_ref().to_os_string()\n    }\n}\n\n#[stable(feature = \"rust1\", since = \"1.0.0\")]\nimpl ops::Index<ops::RangeFull> for OsString {\n    type Output = OsStr;\n\n    #[inline]\n    fn index(&self, _index: ops::RangeFull) -> &OsStr {\n        OsStr::from_inner(self.inner.as_slice())\n    }\n}\n\n#[stable(feature = \"mut_osstr\", since = \"1.44.0\")]\nimpl ops::IndexMut<ops::RangeFull> for OsString {\n    #[inline]\n    fn index_mut(&mut self, _index: ops::RangeFull) -> &mut OsStr {\n        OsStr::from_inner_mut(self.inner.as_mut_slice())\n    }\n}\n\n#[stable(feature = \"rust1\", since = \"1.0.0\")]\nimpl ops::Deref for OsString {\n    type Target = OsStr;\n\n    #[inline]\n    fn deref(&self) -> &OsStr {\n        &self[..]\n    }\n}\n\n#[stable(feature = \"mut_osstr\", since = \"1.44.0\")]\nimpl ops::DerefMut for OsString {\n    #[inline]\n    fn deref_mut(&mut self) -> &mut OsStr {\n        &mut self[..]\n    }\n}\n\n#[stable(feature = \"osstring_default\", since = \"1.9.0\")]\nimpl Default for OsString {\n    /// Constructs an empty `OsString`.\n    #[inline]\n    fn default() -> OsString {\n        OsString::new()\n    }\n}\n\n#[stable(feature = \"rust1\", since = \"1.0.0\")]\nimpl Clone for OsString {\n    #[inline]\n    fn clone(&self) -> Self {\n        OsString { inner: self.inner.clone() }\n    }\n\n    #[inline]\n    fn clone_from(&mut self, source: &Self) {\n        self.inner.clone_from(&source.inner)\n    }\n}\n\n#[stable(feature = \"rust1\", since = \"1.0.0\")]\nimpl fmt::Debug for OsString {\n    fn fmt(&self, formatter: &mut fmt::Formatter<'_>) -> fmt::Result {\n        fmt::Debug::fmt(&**self, formatter)\n    }\n}\n\n#[stable(feature = \"rust1\", since = \"1.0.0\")]\nimpl PartialEq for OsString {\n    #[inline]\n    fn eq(&self, other: &OsString) -> bool {\n        &**self == &**other\n    }\n}\n\n#[stable(feature = \"rust1\", since = \"1.0.0\")]\nimpl PartialEq<str> for OsString {\n    #[inline]\n    fn eq(&self, other: &str) -> bool {\n        &**self == other\n    }\n}\n\n#[stable(feature = \"rust1\", since = \"1.0.0\")]\nimpl PartialEq<OsString> for str {\n    #[inline]\n    fn eq(&self, other: &OsString) -> bool {\n        &**other == self\n    }\n}\n\n#[stable(feature = \"os_str_str_ref_eq\", since = \"1.29.0\")]\nimpl PartialEq<&str> for OsString {\n    #[inline]\n    fn eq(&self, other: &&str) -> bool {\n        **self == **other\n    }\n}\n\n#[stable(feature = \"os_str_str_ref_eq\", since = \"1.29.0\")]\nimpl<'a> PartialEq<OsString> for &'a str {\n    #[inline]\n    fn eq(&self, other: &OsString) -> bool {\n        **other == **self\n    }\n}\n\n#[stable(feature = \"rust1\", since = \"1.0.0\")]\nimpl Eq for OsString {}\n\n#[stable(feature = \"rust1\", since = \"1.0.0\")]\nimpl PartialOrd for OsString {\n    #[inline]\n    fn partial_cmp(&self, other: &OsString) -> Option<cmp::Ordering> {\n        (&**self).partial_cmp(&**other)\n    }\n    #[inline]\n    fn lt(&self, other: &OsString) -> bool {\n        &**self < &**other\n    }\n    #[inline]\n    fn le(&self, other: &OsString) -> bool {\n        &**self <= &**other\n    }\n    #[inline]\n    fn gt(&self, other: &OsString) -> bool {\n        &**self > &**other\n    }\n    #[inline]\n    fn ge(&self, other: &OsString) -> bool {\n        &**self >= &**other\n    }\n}\n\n#[stable(feature = \"rust1\", since = \"1.0.0\")]\nimpl PartialOrd<str> for OsString {\n    #[inline]\n    fn partial_cmp(&self, other: &str) -> Option<cmp::Ordering> {\n        (&**self).partial_cmp(other)\n    }\n}\n\n#[stable(feature = \"rust1\", since = \"1.0.0\")]\nimpl Ord for OsString {\n    #[inline]\n    fn cmp(&self, other: &OsString) -> cmp::Ordering {\n        (&**self).cmp(&**other)\n    }\n}\n\n#[stable(feature = \"rust1\", since = \"1.0.0\")]\nimpl Hash for OsString {\n    #[inline]\n    fn hash<H: Hasher>(&self, state: &mut H) {\n        (&**self).hash(state)\n    }\n}\n\nimpl OsStr {\n    /// Coerces into an `OsStr` slice.\n    ///\n    /// # Examples\n    ///\n    /// ```\n    /// use std::ffi::OsStr;\n    ///\n    /// let os_str = OsStr::new(\"foo\");\n    /// ```\n    #[inline]\n    #[stable(feature = \"rust1\", since = \"1.0.0\")]\n    pub fn new<S: AsRef<OsStr> + ?Sized>(s: &S) -> &OsStr {\n        s.as_ref()\n    }\n\n    #[inline]\n    fn from_inner(inner: &Slice) -> &OsStr {\n        // SAFETY: OsStr is just a wrapper of Slice,\n        // therefore converting &Slice to &OsStr is safe.\n        unsafe { &*(inner as *const Slice as *const OsStr) }\n    }\n\n    #[inline]\n    fn from_inner_mut(inner: &mut Slice) -> &mut OsStr {\n        // SAFETY: OsStr is just a wrapper of Slice,\n        // therefore converting &mut Slice to &mut OsStr is safe.\n        // Any method that mutates OsStr must be careful not to\n        // break platform-specific encoding, in particular Wtf8 on Windows.\n        unsafe { &mut *(inner as *mut Slice as *mut OsStr) }\n    }\n\n    /// Yields a [`&str`] slice if the `OsStr` is valid Unicode.\n    ///\n    /// This conversion may entail doing a check for UTF-8 validity.\n    ///\n    /// [`&str`]: str\n    ///\n    /// # Examples\n    ///\n    /// ```\n    /// use std::ffi::OsStr;\n    ///\n    /// let os_str = OsStr::new(\"foo\");\n    /// assert_eq!(os_str.to_str(), Some(\"foo\"));\n    /// ```\n    #[stable(feature = \"rust1\", since = \"1.0.0\")]\n    #[inline]\n    pub fn to_str(&self) -> Option<&str> {\n        self.inner.to_str()\n    }\n\n    /// Converts an `OsStr` to a [`Cow`]`<`[`str`]`>`.\n    ///\n    /// Any non-Unicode sequences are replaced with\n    /// [`U+FFFD REPLACEMENT CHARACTER`][U+FFFD].\n    ///\n    /// [U+FFFD]: crate::char::REPLACEMENT_CHARACTER\n    ///\n    /// # Examples\n    ///\n    /// Calling `to_string_lossy` on an `OsStr` with invalid unicode:\n    ///\n    /// ```\n    /// // Note, due to differences in how Unix and Windows represent strings,\n    /// // we are forced to complicate this example, setting up example `OsStr`s\n    /// // with different source data and via different platform extensions.\n    /// // Understand that in reality you could end up with such example invalid\n    /// // sequences simply through collecting user command line arguments, for\n    /// // example.\n    ///\n    /// #[cfg(unix)] {\n    ///     use std::ffi::OsStr;\n    ///     use std::os::unix::ffi::OsStrExt;\n    ///\n    ///     // Here, the values 0x66 and 0x6f correspond to 'f' and 'o'\n    ///     // respectively. The value 0x80 is a lone continuation byte, invalid\n    ///     // in a UTF-8 sequence.\n    ///     let source = [0x66, 0x6f, 0x80, 0x6f];\n    ///     let os_str = OsStr::from_bytes(&source[..]);\n    ///\n    ///     assert_eq!(os_str.to_string_lossy(), \"fo�o\");\n    /// }\n    /// #[cfg(windows)] {\n    ///     use std::ffi::OsString;\n    ///     use std::os::windows::prelude::*;\n    ///\n    ///     // Here the values 0x0066 and 0x006f correspond to 'f' and 'o'\n    ///     // respectively. The value 0xD800 is a lone surrogate half, invalid\n    ///     // in a UTF-16 sequence.\n    ///     let source = [0x0066, 0x006f, 0xD800, 0x006f];\n    ///     let os_string = OsString::from_wide(&source[..]);\n    ///     let os_str = os_string.as_os_str();\n    ///\n    ///     assert_eq!(os_str.to_string_lossy(), \"fo�o\");\n    /// }\n    /// ```\n    #[stable(feature = \"rust1\", since = \"1.0.0\")]\n    #[inline]\n    pub fn to_string_lossy(&self) -> Cow<'_, str> {\n        self.inner.to_string_lossy()\n    }\n\n    /// Copies the slice into an owned [`OsString`].\n    ///\n    /// # Examples\n    ///\n    /// ```\n    /// use std::ffi::{OsStr, OsString};\n    ///\n    /// let os_str = OsStr::new(\"foo\");\n    /// let os_string = os_str.to_os_string();\n    /// assert_eq!(os_string, OsString::from(\"foo\"));\n    /// ```\n    #[stable(feature = \"rust1\", since = \"1.0.0\")]\n    #[inline]\n    pub fn to_os_string(&self) -> OsString {\n        OsString { inner: self.inner.to_owned() }\n    }\n\n    /// Checks whether the `OsStr` is empty.\n    ///\n    /// # Examples\n    ///\n    /// ```\n    /// use std::ffi::OsStr;\n    ///\n    /// let os_str = OsStr::new(\"\");\n    /// assert!(os_str.is_empty());\n    ///\n    /// let os_str = OsStr::new(\"foo\");\n    /// assert!(!os_str.is_empty());\n    /// ```\n    #[stable(feature = \"osstring_simple_functions\", since = \"1.9.0\")]\n    #[inline]\n    pub fn is_empty(&self) -> bool {\n        self.inner.inner.is_empty()\n    }\n\n    /// Returns the length of this `OsStr`.\n    ///\n    /// Note that this does **not** return the number of bytes in the string in\n    /// OS string form.\n    ///\n    /// The length returned is that of the underlying storage used by `OsStr`.\n    /// As discussed in the [`OsString`] introduction, [`OsString`] and `OsStr`\n    /// store strings in a form best suited for cheap inter-conversion between\n    /// native-platform and Rust string forms, which may differ significantly\n    /// from both of them, including in storage size and encoding.\n    ///\n    /// This number is simply useful for passing to other methods, like\n    /// [`OsString::with_capacity`] to avoid reallocations.\n    ///\n    /// # Examples\n    ///\n    /// ```\n    /// use std::ffi::OsStr;\n    ///\n    /// let os_str = OsStr::new(\"\");\n    /// assert_eq!(os_str.len(), 0);\n    ///\n    /// let os_str = OsStr::new(\"foo\");\n    /// assert_eq!(os_str.len(), 3);\n    /// ```\n    #[doc(alias = \"length\")]\n    #[stable(feature = \"osstring_simple_functions\", since = \"1.9.0\")]\n    #[inline]\n    pub fn len(&self) -> usize {\n        self.inner.inner.len()\n    }\n\n    /// Converts a [`Box`]`<OsStr>` into an [`OsString`] without copying or allocating.\n    #[stable(feature = \"into_boxed_os_str\", since = \"1.20.0\")]\n    pub fn into_os_string(self: Box<OsStr>) -> OsString {\n        let boxed = unsafe { Box::from_raw(Box::into_raw(self) as *mut Slice) };\n        OsString { inner: Buf::from_box(boxed) }\n    }\n\n    /// Gets the underlying byte representation.\n    ///\n    /// Note: it is *crucial* that this API is not externally public, to avoid\n    /// revealing the internal, platform-specific encodings.\n    #[inline]\n    pub(crate) fn bytes(&self) -> &[u8] {\n        unsafe { &*(&self.inner as *const _ as *const [u8]) }\n    }\n\n    /// Converts this string to its ASCII lower case equivalent in-place.\n    ///\n    /// ASCII letters 'A' to 'Z' are mapped to 'a' to 'z',\n    /// but non-ASCII letters are unchanged.\n    ///\n    /// To return a new lowercased value without modifying the existing one, use\n    /// [`OsStr::to_ascii_lowercase`].\n    ///\n    /// # Examples\n    ///\n    /// ```\n    /// use std::ffi::OsString;\n    ///\n    /// let mut s = OsString::from(\"GRÜßE, JÜRGEN ❤\");\n    ///\n    /// s.make_ascii_lowercase();\n    ///\n    /// assert_eq!(\"grÜße, jÜrgen ❤\", s);\n    /// ```\n    #[stable(feature = \"osstring_ascii\", since = \"1.53.0\")]\n    #[inline]\n    pub fn make_ascii_lowercase(&mut self) {\n        self.inner.make_ascii_lowercase()\n    }\n\n    /// Converts this string to its ASCII upper case equivalent in-place.\n    ///\n    /// ASCII letters 'a' to 'z' are mapped to 'A' to 'Z',\n    /// but non-ASCII letters are unchanged.\n    ///\n    /// To return a new uppercased value without modifying the existing one, use\n    /// [`OsStr::to_ascii_uppercase`].\n    ///\n    /// # Examples\n    ///\n    /// ```\n    /// use std::ffi::OsString;\n    ///\n    /// let mut s = OsString::from(\"Grüße, Jürgen ❤\");\n    ///\n    /// s.make_ascii_uppercase();\n    ///\n    /// assert_eq!(\"GRüßE, JüRGEN ❤\", s);\n    /// ```\n    #[stable(feature = \"osstring_ascii\", since = \"1.53.0\")]\n    #[inline]\n    pub fn make_ascii_uppercase(&mut self) {\n        self.inner.make_ascii_uppercase()\n    }\n\n    /// Returns a copy of this string where each character is mapped to its\n    /// ASCII lower case equivalent.\n    ///\n    /// ASCII letters 'A' to 'Z' are mapped to 'a' to 'z',\n    /// but non-ASCII letters are unchanged.\n    ///\n    /// To lowercase the value in-place, use [`OsStr::make_ascii_lowercase`].\n    ///\n    /// # Examples\n    ///\n    /// ```\n    /// use std::ffi::OsString;\n    /// let s = OsString::from(\"Grüße, Jürgen ❤\");\n    ///\n    /// assert_eq!(\"grüße, jürgen ❤\", s.to_ascii_lowercase());\n    /// ```\n    #[stable(feature = \"osstring_ascii\", since = \"1.53.0\")]\n    pub fn to_ascii_lowercase(&self) -> OsString {\n        OsString::from_inner(self.inner.to_ascii_lowercase())\n    }\n\n    /// Returns a copy of this string where each character is mapped to its\n    /// ASCII upper case equivalent.\n    ///\n    /// ASCII letters 'a' to 'z' are mapped to 'A' to 'Z',\n    /// but non-ASCII letters are unchanged.\n    ///\n    /// To uppercase the value in-place, use [`OsStr::make_ascii_uppercase`].\n    ///\n    /// # Examples\n    ///\n    /// ```\n    /// use std::ffi::OsString;\n    /// let s = OsString::from(\"Grüße, Jürgen ❤\");\n    ///\n    /// assert_eq!(\"GRüßE, JüRGEN ❤\", s.to_ascii_uppercase());\n    /// ```\n    #[stable(feature = \"osstring_ascii\", since = \"1.53.0\")]\n    pub fn to_ascii_uppercase(&self) -> OsString {\n        OsString::from_inner(self.inner.to_ascii_uppercase())\n    }\n\n    /// Checks if all characters in this string are within the ASCII range.\n    ///\n    /// # Examples\n    ///\n    /// ```\n    /// use std::ffi::OsString;\n    ///\n    /// let ascii = OsString::from(\"hello!\\n\");\n    /// let non_ascii = OsString::from(\"Grüße, Jürgen ❤\");\n    ///\n    /// assert!(ascii.is_ascii());\n    /// assert!(!non_ascii.is_ascii());\n    /// ```\n    #[stable(feature = \"osstring_ascii\", since = \"1.53.0\")]\n    #[inline]\n    pub fn is_ascii(&self) -> bool {\n        self.inner.is_ascii()\n    }\n\n    /// Checks that two strings are an ASCII case-insensitive match.\n    ///\n    /// Same as `to_ascii_lowercase(a) == to_ascii_lowercase(b)`,\n    /// but without allocating and copying temporaries.\n    ///\n    /// # Examples\n    ///\n    /// ```\n    /// use std::ffi::OsString;\n    ///\n    /// assert!(OsString::from(\"Ferris\").eq_ignore_ascii_case(\"FERRIS\"));\n    /// assert!(OsString::from(\"Ferrös\").eq_ignore_ascii_case(\"FERRöS\"));\n    /// assert!(!OsString::from(\"Ferrös\").eq_ignore_ascii_case(\"FERRÖS\"));\n    /// ```\n    #[stable(feature = \"osstring_ascii\", since = \"1.53.0\")]\n    pub fn eq_ignore_ascii_case<S: AsRef<OsStr>>(&self, other: S) -> bool {\n        self.inner.eq_ignore_ascii_case(&other.as_ref().inner)\n    }\n}\n\n#[stable(feature = \"box_from_os_str\", since = \"1.17.0\")]\nimpl From<&OsStr> for Box<OsStr> {\n    #[inline]\n    fn from(s: &OsStr) -> Box<OsStr> {\n        let rw = Box::into_raw(s.inner.into_box()) as *mut OsStr;\n        unsafe { Box::from_raw(rw) }\n    }\n}\n\n#[stable(feature = \"box_from_cow\", since = \"1.45.0\")]\nimpl From<Cow<'_, OsStr>> for Box<OsStr> {\n    #[inline]\n    fn from(cow: Cow<'_, OsStr>) -> Box<OsStr> {\n        match cow {\n            Cow::Borrowed(s) => Box::from(s),\n            Cow::Owned(s) => Box::from(s),\n        }\n    }\n}\n\n#[stable(feature = \"os_string_from_box\", since = \"1.18.0\")]\nimpl From<Box<OsStr>> for OsString {\n    /// Converts a [`Box`]`<`[`OsStr`]`>` into an [`OsString`] without copying or\n    /// allocating.\n    #[inline]\n    fn from(boxed: Box<OsStr>) -> OsString {\n        boxed.into_os_string()\n    }\n}\n\n#[stable(feature = \"box_from_os_string\", since = \"1.20.0\")]\nimpl From<OsString> for Box<OsStr> {\n    /// Converts a [`OsString`] into a [`Box`]`<OsStr>` without copying or allocating.\n    #[inline]\n    fn from(s: OsString) -> Box<OsStr> {\n        s.into_boxed_os_str()\n    }\n}\n\n#[stable(feature = \"more_box_slice_clone\", since = \"1.29.0\")]\nimpl Clone for Box<OsStr> {\n    #[inline]\n    fn clone(&self) -> Self {\n        self.to_os_string().into_boxed_os_str()\n    }\n}\n\n#[stable(feature = \"shared_from_slice2\", since = \"1.24.0\")]\nimpl From<OsString> for Arc<OsStr> {\n    /// Converts a [`OsString`] into a [`Arc`]`<OsStr>` without copying or allocating.\n    #[inline]\n    fn from(s: OsString) -> Arc<OsStr> {\n        let arc = s.inner.into_arc();\n        unsafe { Arc::from_raw(Arc::into_raw(arc) as *const OsStr) }\n    }\n}\n\n#[stable(feature = \"shared_from_slice2\", since = \"1.24.0\")]\nimpl From<&OsStr> for Arc<OsStr> {\n    #[inline]\n    fn from(s: &OsStr) -> Arc<OsStr> {\n        let arc = s.inner.into_arc();\n        unsafe { Arc::from_raw(Arc::into_raw(arc) as *const OsStr) }\n    }\n}\n\n#[stable(feature = \"shared_from_slice2\", since = \"1.24.0\")]\nimpl From<OsString> for Rc<OsStr> {\n    /// Converts a [`OsString`] into a [`Rc`]`<OsStr>` without copying or allocating.\n    #[inline]\n    fn from(s: OsString) -> Rc<OsStr> {\n        let rc = s.inner.into_rc();\n        unsafe { Rc::from_raw(Rc::into_raw(rc) as *const OsStr) }\n    }\n}\n\n#[stable(feature = \"shared_from_slice2\", since = \"1.24.0\")]\nimpl From<&OsStr> for Rc<OsStr> {\n    #[inline]\n    fn from(s: &OsStr) -> Rc<OsStr> {\n        let rc = s.inner.into_rc();\n        unsafe { Rc::from_raw(Rc::into_raw(rc) as *const OsStr) }\n    }\n}\n\n#[stable(feature = \"cow_from_osstr\", since = \"1.28.0\")]\nimpl<'a> From<OsString> for Cow<'a, OsStr> {\n    #[inline]\n    fn from(s: OsString) -> Cow<'a, OsStr> {\n        Cow::Owned(s)\n    }\n}\n\n#[stable(feature = \"cow_from_osstr\", since = \"1.28.0\")]\nimpl<'a> From<&'a OsStr> for Cow<'a, OsStr> {\n    #[inline]\n    fn from(s: &'a OsStr) -> Cow<'a, OsStr> {\n        Cow::Borrowed(s)\n    }\n}\n\n#[stable(feature = \"cow_from_osstr\", since = \"1.28.0\")]\nimpl<'a> From<&'a OsString> for Cow<'a, OsStr> {\n    #[inline]\n    fn from(s: &'a OsString) -> Cow<'a, OsStr> {\n        Cow::Borrowed(s.as_os_str())\n    }\n}\n\n#[stable(feature = \"osstring_from_cow_osstr\", since = \"1.28.0\")]\nimpl<'a> From<Cow<'a, OsStr>> for OsString {\n    #[inline]\n    fn from(s: Cow<'a, OsStr>) -> Self {\n        s.into_owned()\n    }\n}\n\n#[stable(feature = \"box_default_extra\", since = \"1.17.0\")]\nimpl Default for Box<OsStr> {\n    #[inline]\n    fn default() -> Box<OsStr> {\n        let rw = Box::into_raw(Slice::empty_box()) as *mut OsStr;\n        unsafe { Box::from_raw(rw) }\n    }\n}\n\n#[stable(feature = \"osstring_default\", since = \"1.9.0\")]\nimpl Default for &OsStr {\n    /// Creates an empty `OsStr`.\n    #[inline]\n    fn default() -> Self {\n        OsStr::new(\"\")\n    }\n}\n\n#[stable(feature = \"rust1\", since = \"1.0.0\")]\nimpl PartialEq for OsStr {\n    #[inline]\n    fn eq(&self, other: &OsStr) -> bool {\n        self.bytes().eq(other.bytes())\n    }\n}\n\n#[stable(feature = \"rust1\", since = \"1.0.0\")]\nimpl PartialEq<str> for OsStr {\n    #[inline]\n    fn eq(&self, other: &str) -> bool {\n        *self == *OsStr::new(other)\n    }\n}\n\n#[stable(feature = \"rust1\", since = \"1.0.0\")]\nimpl PartialEq<OsStr> for str {\n    #[inline]\n    fn eq(&self, other: &OsStr) -> bool {\n        *other == *OsStr::new(self)\n    }\n}\n\n#[stable(feature = \"rust1\", since = \"1.0.0\")]\nimpl Eq for OsStr {}\n\n#[stable(feature = \"rust1\", since = \"1.0.0\")]\nimpl PartialOrd for OsStr {\n    #[inline]\n    fn partial_cmp(&self, other: &OsStr) -> Option<cmp::Ordering> {\n        self.bytes().partial_cmp(other.bytes())\n    }\n    #[inline]\n    fn lt(&self, other: &OsStr) -> bool {\n        self.bytes().lt(other.bytes())\n    }\n    #[inline]\n    fn le(&self, other: &OsStr) -> bool {\n        self.bytes().le(other.bytes())\n    }\n    #[inline]\n    fn gt(&self, other: &OsStr) -> bool {\n        self.bytes().gt(other.bytes())\n    }\n    #[inline]\n    fn ge(&self, other: &OsStr) -> bool {\n        self.bytes().ge(other.bytes())\n    }\n}\n\n#[stable(feature = \"rust1\", since = \"1.0.0\")]\nimpl PartialOrd<str> for OsStr {\n    #[inline]\n    fn partial_cmp(&self, other: &str) -> Option<cmp::Ordering> {\n        self.partial_cmp(OsStr::new(other))\n    }\n}\n\n// FIXME (#19470): cannot provide PartialOrd<OsStr> for str until we\n// have more flexible coherence rules.\n\n#[stable(feature = \"rust1\", since = \"1.0.0\")]\nimpl Ord for OsStr {\n    #[inline]\n    fn cmp(&self, other: &OsStr) -> cmp::Ordering {\n        self.bytes().cmp(other.bytes())\n    }\n}\n\nmacro_rules! impl_cmp {\n    ($lhs:ty, $rhs: ty) => {\n        #[stable(feature = \"cmp_os_str\", since = \"1.8.0\")]\n        impl<'a, 'b> PartialEq<$rhs> for $lhs {\n            #[inline]\n            fn eq(&self, other: &$rhs) -> bool {\n                <OsStr as PartialEq>::eq(self, other)\n            }\n        }\n\n        #[stable(feature = \"cmp_os_str\", since = \"1.8.0\")]\n        impl<'a, 'b> PartialEq<$lhs> for $rhs {\n            #[inline]\n            fn eq(&self, other: &$lhs) -> bool {\n                <OsStr as PartialEq>::eq(self, other)\n            }\n        }\n\n        #[stable(feature = \"cmp_os_str\", since = \"1.8.0\")]\n        impl<'a, 'b> PartialOrd<$rhs> for $lhs {\n            #[inline]\n            fn partial_cmp(&self, other: &$rhs) -> Option<cmp::Ordering> {\n                <OsStr as PartialOrd>::partial_cmp(self, other)\n            }\n        }\n\n        #[stable(feature = \"cmp_os_str\", since = \"1.8.0\")]\n        impl<'a, 'b> PartialOrd<$lhs> for $rhs {\n            #[inline]\n            fn partial_cmp(&self, other: &$lhs) -> Option<cmp::Ordering> {\n                <OsStr as PartialOrd>::partial_cmp(self, other)\n            }\n        }\n    };\n}\n\nimpl_cmp!(OsString, OsStr);\nimpl_cmp!(OsString, &'a OsStr);\nimpl_cmp!(Cow<'a, OsStr>, OsStr);\nimpl_cmp!(Cow<'a, OsStr>, &'b OsStr);\nimpl_cmp!(Cow<'a, OsStr>, OsString);\n\n#[stable(feature = \"rust1\", since = \"1.0.0\")]\nimpl Hash for OsStr {\n    #[inline]\n    fn hash<H: Hasher>(&self, state: &mut H) {\n        self.bytes().hash(state)\n    }\n}\n\n#[stable(feature = \"rust1\", since = \"1.0.0\")]\nimpl fmt::Debug for OsStr {\n    fn fmt(&self, formatter: &mut fmt::Formatter<'_>) -> fmt::Result {\n        fmt::Debug::fmt(&self.inner, formatter)\n    }\n}\n\nimpl OsStr {\n    pub(crate) fn display(&self, formatter: &mut fmt::Formatter<'_>) -> fmt::Result {\n        fmt::Display::fmt(&self.inner, formatter)\n    }\n}\n\n#[stable(feature = \"rust1\", since = \"1.0.0\")]\nimpl Borrow<OsStr> for OsString {\n    #[inline]\n    fn borrow(&self) -> &OsStr {\n        &self[..]\n    }\n}\n\n#[stable(feature = \"rust1\", since = \"1.0.0\")]\nimpl ToOwned for OsStr {\n    type Owned = OsString;\n    #[inline]\n    fn to_owned(&self) -> OsString {\n        self.to_os_string()\n    }\n    #[inline]\n    fn clone_into(&self, target: &mut OsString) {\n        self.inner.clone_into(&mut target.inner)\n    }\n}\n\n#[stable(feature = \"rust1\", since = \"1.0.0\")]\nimpl AsRef<OsStr> for OsStr {\n    #[inline]\n    fn as_ref(&self) -> &OsStr {\n        self\n    }\n}\n\n#[stable(feature = \"rust1\", since = \"1.0.0\")]\nimpl AsRef<OsStr> for OsString {\n    #[inline]\n    fn as_ref(&self) -> &OsStr {\n        self\n    }\n}\n\n#[stable(feature = \"rust1\", since = \"1.0.0\")]\nimpl AsRef<OsStr> for str {\n    #[inline]\n    fn as_ref(&self) -> &OsStr {\n        OsStr::from_inner(Slice::from_str(self))\n    }\n}\n\n#[stable(feature = \"rust1\", since = \"1.0.0\")]\nimpl AsRef<OsStr> for String {\n    #[inline]\n    fn as_ref(&self) -> &OsStr {\n        (&**self).as_ref()\n    }\n}\n\nimpl FromInner<Buf> for OsString {\n    #[inline]\n    fn from_inner(buf: Buf) -> OsString {\n        OsString { inner: buf }\n    }\n}\n\nimpl IntoInner<Buf> for OsString {\n    #[inline]\n    fn into_inner(self) -> Buf {\n        self.inner\n    }\n}\n\nimpl AsInner<Slice> for OsStr {\n    #[inline]\n    fn as_inner(&self) -> &Slice {\n        &self.inner\n    }\n}\n\n#[stable(feature = \"osstring_from_str\", since = \"1.45.0\")]\nimpl FromStr for OsString {\n    type Err = core::convert::Infallible;\n\n    #[inline]\n    fn from_str(s: &str) -> Result<Self, Self::Err> {\n        Ok(OsString::from(s))\n    }\n}\n\n#[stable(feature = \"osstring_extend\", since = \"1.52.0\")]\nimpl Extend<OsString> for OsString {\n    #[inline]\n    fn extend<T: IntoIterator<Item = OsString>>(&mut self, iter: T) {\n        for s in iter {\n            self.push(&s);\n        }\n    }\n}\n\n#[stable(feature = \"osstring_extend\", since = \"1.52.0\")]\nimpl<'a> Extend<&'a OsStr> for OsString {\n    #[inline]\n    fn extend<T: IntoIterator<Item = &'a OsStr>>(&mut self, iter: T) {\n        for s in iter {\n            self.push(s);\n        }\n    }\n}\n\n#[stable(feature = \"osstring_extend\", since = \"1.52.0\")]\nimpl<'a> Extend<Cow<'a, OsStr>> for OsString {\n    #[inline]\n    fn extend<T: IntoIterator<Item = Cow<'a, OsStr>>>(&mut self, iter: T) {\n        for s in iter {\n            self.push(&s);\n        }\n    }\n}\n\n#[stable(feature = \"osstring_extend\", since = \"1.52.0\")]\nimpl FromIterator<OsString> for OsString {\n    #[inline]\n    fn from_iter<I: IntoIterator<Item = OsString>>(iter: I) -> Self {\n        let mut iterator = iter.into_iter();\n\n        // Because we're iterating over `OsString`s, we can avoid at least\n        // one allocation by getting the first string from the iterator\n        // and appending to it all the subsequent strings.\n        match iterator.next() {\n            None => OsString::new(),\n            Some(mut buf) => {\n                buf.extend(iterator);\n                buf\n            }\n        }\n    }\n}\n\n#[stable(feature = \"osstring_extend\", since = \"1.52.0\")]\nimpl<'a> FromIterator<&'a OsStr> for OsString {\n    #[inline]\n    fn from_iter<I: IntoIterator<Item = &'a OsStr>>(iter: I) -> Self {\n        let mut buf = Self::new();\n        for s in iter {\n            buf.push(s);\n        }\n        buf\n    }\n}\n\n#[stable(feature = \"osstring_extend\", since = \"1.52.0\")]\nimpl<'a> FromIterator<Cow<'a, OsStr>> for OsString {\n    #[inline]\n    fn from_iter<I: IntoIterator<Item = Cow<'a, OsStr>>>(iter: I) -> Self {\n        let mut iterator = iter.into_iter();\n\n        // Because we're iterating over `OsString`s, we can avoid at least\n        // one allocation by getting the first owned string from the iterator\n        // and appending to it all the subsequent strings.\n        match iterator.next() {\n            None => OsString::new(),\n            Some(Cow::Owned(mut buf)) => {\n                buf.extend(iterator);\n                buf\n            }\n            Some(Cow::Borrowed(buf)) => {\n                let mut buf = OsString::from(buf);\n                buf.extend(iterator);\n                buf\n            }\n        }\n    }\n}\n"],[2220,"#![deny(unsafe_op_in_unsafe_fn)]\n\n#[cfg(test)]\nmod tests;\n\nuse crate::ascii;\nuse crate::borrow::{Borrow, Cow};\nuse crate::cmp::Ordering;\nuse crate::error::Error;\nuse crate::fmt::{self, Write};\nuse crate::io;\nuse crate::mem;\nuse crate::num::NonZeroU8;\nuse crate::ops;\nuse crate::os::raw::c_char;\nuse crate::ptr;\nuse crate::rc::Rc;\nuse crate::slice;\nuse crate::str::{self, Utf8Error};\nuse crate::sync::Arc;\nuse crate::sys;\nuse crate::sys_common::memchr;\n\n/// A type representing an owned, C-compatible, nul-terminated string with no nul bytes in the\n/// middle.\n///\n/// This type serves the purpose of being able to safely generate a\n/// C-compatible string from a Rust byte slice or vector. An instance of this\n/// type is a static guarantee that the underlying bytes contain no interior 0\n/// bytes (\"nul characters\") and that the final byte is 0 (\"nul terminator\").\n///\n/// `CString` is to [`&CStr`] as [`String`] is to [`&str`]: the former\n/// in each pair are owned strings; the latter are borrowed\n/// references.\n///\n/// # Creating a `CString`\n///\n/// A `CString` is created from either a byte slice or a byte vector,\n/// or anything that implements [`Into`]`<`[`Vec`]`<`[`u8`]`>>` (for\n/// example, you can build a `CString` straight out of a [`String`] or\n/// a [`&str`], since both implement that trait).\n///\n/// The [`CString::new`] method will actually check that the provided `&[u8]`\n/// does not have 0 bytes in the middle, and return an error if it\n/// finds one.\n///\n/// # Extracting a raw pointer to the whole C string\n///\n/// `CString` implements a [`as_ptr`][`CStr::as_ptr`] method through the [`Deref`]\n/// trait. This method will give you a `*const c_char` which you can\n/// feed directly to extern functions that expect a nul-terminated\n/// string, like C's `strdup()`. Notice that [`as_ptr`][`CStr::as_ptr`] returns a\n/// read-only pointer; if the C code writes to it, that causes\n/// undefined behavior.\n///\n/// # Extracting a slice of the whole C string\n///\n/// Alternatively, you can obtain a `&[`[`u8`]`]` slice from a\n/// `CString` with the [`CString::as_bytes`] method. Slices produced in this\n/// way do *not* contain the trailing nul terminator. This is useful\n/// when you will be calling an extern function that takes a `*const\n/// u8` argument which is not necessarily nul-terminated, plus another\n/// argument with the length of the string — like C's `strndup()`.\n/// You can of course get the slice's length with its\n/// [`len`][slice::len] method.\n///\n/// If you need a `&[`[`u8`]`]` slice *with* the nul terminator, you\n/// can use [`CString::as_bytes_with_nul`] instead.\n///\n/// Once you have the kind of slice you need (with or without a nul\n/// terminator), you can call the slice's own\n/// [`as_ptr`][slice::as_ptr] method to get a read-only raw pointer to pass to\n/// extern functions. See the documentation for that function for a\n/// discussion on ensuring the lifetime of the raw pointer.\n///\n/// [`&str`]: prim@str\n/// [`Deref`]: ops::Deref\n/// [`&CStr`]: CStr\n///\n/// # Examples\n///\n/// ```ignore (extern-declaration)\n/// # fn main() {\n/// use std::ffi::CString;\n/// use std::os::raw::c_char;\n///\n/// extern \"C\" {\n///     fn my_printer(s: *const c_char);\n/// }\n///\n/// // We are certain that our string doesn't have 0 bytes in the middle,\n/// // so we can .expect()\n/// let c_to_print = CString::new(\"Hello, world!\").expect(\"CString::new failed\");\n/// unsafe {\n///     my_printer(c_to_print.as_ptr());\n/// }\n/// # }\n/// ```\n///\n/// # Safety\n///\n/// `CString` is intended for working with traditional C-style strings\n/// (a sequence of non-nul bytes terminated by a single nul byte); the\n/// primary use case for these kinds of strings is interoperating with C-like\n/// code. Often you will need to transfer ownership to/from that external\n/// code. It is strongly recommended that you thoroughly read through the\n/// documentation of `CString` before use, as improper ownership management\n/// of `CString` instances can lead to invalid memory accesses, memory leaks,\n/// and other memory errors.\n#[derive(PartialEq, PartialOrd, Eq, Ord, Hash, Clone)]\n#[cfg_attr(not(test), rustc_diagnostic_item = \"cstring_type\")]\n#[stable(feature = \"rust1\", since = \"1.0.0\")]\npub struct CString {\n    // Invariant 1: the slice ends with a zero byte and has a length of at least one.\n    // Invariant 2: the slice contains only one zero byte.\n    // Improper usage of unsafe function can break Invariant 2, but not Invariant 1.\n    inner: Box<[u8]>,\n}\n\n/// Representation of a borrowed C string.\n///\n/// This type represents a borrowed reference to a nul-terminated\n/// array of bytes. It can be constructed safely from a `&[`[`u8`]`]`\n/// slice, or unsafely from a raw `*const c_char`. It can then be\n/// converted to a Rust [`&str`] by performing UTF-8 validation, or\n/// into an owned [`CString`].\n///\n/// `&CStr` is to [`CString`] as [`&str`] is to [`String`]: the former\n/// in each pair are borrowed references; the latter are owned\n/// strings.\n///\n/// Note that this structure is **not** `repr(C)` and is not recommended to be\n/// placed in the signatures of FFI functions. Instead, safe wrappers of FFI\n/// functions may leverage the unsafe [`CStr::from_ptr`] constructor to provide\n/// a safe interface to other consumers.\n///\n/// # Examples\n///\n/// Inspecting a foreign C string:\n///\n/// ```ignore (extern-declaration)\n/// use std::ffi::CStr;\n/// use std::os::raw::c_char;\n///\n/// extern \"C\" { fn my_string() -> *const c_char; }\n///\n/// unsafe {\n///     let slice = CStr::from_ptr(my_string());\n///     println!(\"string buffer size without nul terminator: {}\", slice.to_bytes().len());\n/// }\n/// ```\n///\n/// Passing a Rust-originating C string:\n///\n/// ```ignore (extern-declaration)\n/// use std::ffi::{CString, CStr};\n/// use std::os::raw::c_char;\n///\n/// fn work(data: &CStr) {\n///     extern \"C\" { fn work_with(data: *const c_char); }\n///\n///     unsafe { work_with(data.as_ptr()) }\n/// }\n///\n/// let s = CString::new(\"data data data data\").expect(\"CString::new failed\");\n/// work(&s);\n/// ```\n///\n/// Converting a foreign C string into a Rust [`String`]:\n///\n/// ```ignore (extern-declaration)\n/// use std::ffi::CStr;\n/// use std::os::raw::c_char;\n///\n/// extern \"C\" { fn my_string() -> *const c_char; }\n///\n/// fn my_string_safe() -> String {\n///     unsafe {\n///         CStr::from_ptr(my_string()).to_string_lossy().into_owned()\n///     }\n/// }\n///\n/// println!(\"string: {}\", my_string_safe());\n/// ```\n///\n/// [`&str`]: prim@str\n#[derive(Hash)]\n#[cfg_attr(not(test), rustc_diagnostic_item = \"CStr\")]\n#[stable(feature = \"rust1\", since = \"1.0.0\")]\n// FIXME:\n// `fn from` in `impl From<&CStr> for Box<CStr>` current implementation relies\n// on `CStr` being layout-compatible with `[u8]`.\n// When attribute privacy is implemented, `CStr` should be annotated as `#[repr(transparent)]`.\n// Anyway, `CStr` representation and layout are considered implementation detail, are\n// not documented and must not be relied upon.\npub struct CStr {\n    // FIXME: this should not be represented with a DST slice but rather with\n    //        just a raw `c_char` along with some form of marker to make\n    //        this an unsized type. Essentially `sizeof(&CStr)` should be the\n    //        same as `sizeof(&c_char)` but `CStr` should be an unsized type.\n    inner: [c_char],\n}\n\n/// An error indicating that an interior nul byte was found.\n///\n/// While Rust strings may contain nul bytes in the middle, C strings\n/// can't, as that byte would effectively truncate the string.\n///\n/// This error is created by the [`new`][`CString::new`] method on\n/// [`CString`]. See its documentation for more.\n///\n/// # Examples\n///\n/// ```\n/// use std::ffi::{CString, NulError};\n///\n/// let _: NulError = CString::new(b\"f\\0oo\".to_vec()).unwrap_err();\n/// ```\n#[derive(Clone, PartialEq, Eq, Debug)]\n#[stable(feature = \"rust1\", since = \"1.0.0\")]\npub struct NulError(usize, Vec<u8>);\n\n/// An error indicating that a nul byte was not in the expected position.\n///\n/// The slice used to create a [`CStr`] must have one and only one nul byte,\n/// positioned at the end.\n///\n/// This error is created by the [`CStr::from_bytes_with_nul`] method.\n/// See its documentation for more.\n///\n/// # Examples\n///\n/// ```\n/// use std::ffi::{CStr, FromBytesWithNulError};\n///\n/// let _: FromBytesWithNulError = CStr::from_bytes_with_nul(b\"f\\0oo\").unwrap_err();\n/// ```\n#[derive(Clone, PartialEq, Eq, Debug)]\n#[stable(feature = \"cstr_from_bytes\", since = \"1.10.0\")]\npub struct FromBytesWithNulError {\n    kind: FromBytesWithNulErrorKind,\n}\n\n/// An error indicating that a nul byte was not in the expected position.\n///\n/// The vector used to create a [`CString`] must have one and only one nul byte,\n/// positioned at the end.\n///\n/// This error is created by the [`CString::from_vec_with_nul`] method.\n/// See its documentation for more.\n///\n/// # Examples\n///\n/// ```\n/// #![feature(cstring_from_vec_with_nul)]\n/// use std::ffi::{CString, FromVecWithNulError};\n///\n/// let _: FromVecWithNulError = CString::from_vec_with_nul(b\"f\\0oo\".to_vec()).unwrap_err();\n/// ```\n#[derive(Clone, PartialEq, Eq, Debug)]\n#[unstable(feature = \"cstring_from_vec_with_nul\", issue = \"73179\")]\npub struct FromVecWithNulError {\n    error_kind: FromBytesWithNulErrorKind,\n    bytes: Vec<u8>,\n}\n\n#[derive(Clone, PartialEq, Eq, Debug)]\nenum FromBytesWithNulErrorKind {\n    InteriorNul(usize),\n    NotNulTerminated,\n}\n\nimpl FromBytesWithNulError {\n    fn interior_nul(pos: usize) -> FromBytesWithNulError {\n        FromBytesWithNulError { kind: FromBytesWithNulErrorKind::InteriorNul(pos) }\n    }\n    fn not_nul_terminated() -> FromBytesWithNulError {\n        FromBytesWithNulError { kind: FromBytesWithNulErrorKind::NotNulTerminated }\n    }\n}\n\n#[unstable(feature = \"cstring_from_vec_with_nul\", issue = \"73179\")]\nimpl FromVecWithNulError {\n    /// Returns a slice of [`u8`]s bytes that were attempted to convert to a [`CString`].\n    ///\n    /// # Examples\n    ///\n    /// Basic usage:\n    ///\n    /// ```\n    /// #![feature(cstring_from_vec_with_nul)]\n    /// use std::ffi::CString;\n    ///\n    /// // Some invalid bytes in a vector\n    /// let bytes = b\"f\\0oo\".to_vec();\n    ///\n    /// let value = CString::from_vec_with_nul(bytes.clone());\n    ///\n    /// assert_eq!(&bytes[..], value.unwrap_err().as_bytes());\n    /// ```\n    pub fn as_bytes(&self) -> &[u8] {\n        &self.bytes[..]\n    }\n\n    /// Returns the bytes that were attempted to convert to a [`CString`].\n    ///\n    /// This method is carefully constructed to avoid allocation. It will\n    /// consume the error, moving out the bytes, so that a copy of the bytes\n    /// does not need to be made.\n    ///\n    /// # Examples\n    ///\n    /// Basic usage:\n    ///\n    /// ```\n    /// #![feature(cstring_from_vec_with_nul)]\n    /// use std::ffi::CString;\n    ///\n    /// // Some invalid bytes in a vector\n    /// let bytes = b\"f\\0oo\".to_vec();\n    ///\n    /// let value = CString::from_vec_with_nul(bytes.clone());\n    ///\n    /// assert_eq!(bytes, value.unwrap_err().into_bytes());\n    /// ```\n    pub fn into_bytes(self) -> Vec<u8> {\n        self.bytes\n    }\n}\n\n/// An error indicating invalid UTF-8 when converting a [`CString`] into a [`String`].\n///\n/// `CString` is just a wrapper over a buffer of bytes with a nul terminator;\n/// [`CString::into_string`] performs UTF-8 validation on those bytes and may\n/// return this error.\n///\n/// This `struct` is created by [`CString::into_string()`]. See\n/// its documentation for more.\n#[derive(Clone, PartialEq, Eq, Debug)]\n#[stable(feature = \"cstring_into\", since = \"1.7.0\")]\npub struct IntoStringError {\n    inner: CString,\n    error: Utf8Error,\n}\n\nimpl CString {\n    /// Creates a new C-compatible string from a container of bytes.\n    ///\n    /// This function will consume the provided data and use the\n    /// underlying bytes to construct a new string, ensuring that\n    /// there is a trailing 0 byte. This trailing 0 byte will be\n    /// appended by this function; the provided data should *not*\n    /// contain any 0 bytes in it.\n    ///\n    /// # Examples\n    ///\n    /// ```ignore (extern-declaration)\n    /// use std::ffi::CString;\n    /// use std::os::raw::c_char;\n    ///\n    /// extern \"C\" { fn puts(s: *const c_char); }\n    ///\n    /// let to_print = CString::new(\"Hello!\").expect(\"CString::new failed\");\n    /// unsafe {\n    ///     puts(to_print.as_ptr());\n    /// }\n    /// ```\n    ///\n    /// # Errors\n    ///\n    /// This function will return an error if the supplied bytes contain an\n    /// internal 0 byte. The [`NulError`] returned will contain the bytes as well as\n    /// the position of the nul byte.\n    #[stable(feature = \"rust1\", since = \"1.0.0\")]\n    pub fn new<T: Into<Vec<u8>>>(t: T) -> Result<CString, NulError> {\n        trait SpecIntoVec {\n            fn into_vec(self) -> Vec<u8>;\n        }\n        impl<T: Into<Vec<u8>>> SpecIntoVec for T {\n            default fn into_vec(self) -> Vec<u8> {\n                self.into()\n            }\n        }\n        // Specialization for avoiding reallocation.\n        impl SpecIntoVec for &'_ [u8] {\n            fn into_vec(self) -> Vec<u8> {\n                let mut v = Vec::with_capacity(self.len() + 1);\n                v.extend(self);\n                v\n            }\n        }\n        impl SpecIntoVec for &'_ str {\n            fn into_vec(self) -> Vec<u8> {\n                let mut v = Vec::with_capacity(self.len() + 1);\n                v.extend(self.as_bytes());\n                v\n            }\n        }\n\n        Self::_new(SpecIntoVec::into_vec(t))\n    }\n\n    fn _new(bytes: Vec<u8>) -> Result<CString, NulError> {\n        match memchr::memchr(0, &bytes) {\n            Some(i) => Err(NulError(i, bytes)),\n            None => Ok(unsafe { CString::from_vec_unchecked(bytes) }),\n        }\n    }\n\n    /// Creates a C-compatible string by consuming a byte vector,\n    /// without checking for interior 0 bytes.\n    ///\n    /// This method is equivalent to [`CString::new`] except that no runtime\n    /// assertion is made that `v` contains no 0 bytes, and it requires an\n    /// actual byte vector, not anything that can be converted to one with Into.\n    ///\n    /// # Examples\n    ///\n    /// ```\n    /// use std::ffi::CString;\n    ///\n    /// let raw = b\"foo\".to_vec();\n    /// unsafe {\n    ///     let c_string = CString::from_vec_unchecked(raw);\n    /// }\n    /// ```\n    #[stable(feature = \"rust1\", since = \"1.0.0\")]\n    pub unsafe fn from_vec_unchecked(mut v: Vec<u8>) -> CString {\n        v.reserve_exact(1);\n        v.push(0);\n        CString { inner: v.into_boxed_slice() }\n    }\n\n    /// Retakes ownership of a `CString` that was transferred to C via\n    /// [`CString::into_raw`].\n    ///\n    /// Additionally, the length of the string will be recalculated from the pointer.\n    ///\n    /// # Safety\n    ///\n    /// This should only ever be called with a pointer that was earlier\n    /// obtained by calling [`CString::into_raw`]. Other usage (e.g., trying to take\n    /// ownership of a string that was allocated by foreign code) is likely to lead\n    /// to undefined behavior or allocator corruption.\n    ///\n    /// It should be noted that the length isn't just \"recomputed,\" but that\n    /// the recomputed length must match the original length from the\n    /// [`CString::into_raw`] call. This means the [`CString::into_raw`]/`from_raw`\n    /// methods should not be used when passing the string to C functions that can\n    /// modify the string's length.\n    ///\n    /// > **Note:** If you need to borrow a string that was allocated by\n    /// > foreign code, use [`CStr`]. If you need to take ownership of\n    /// > a string that was allocated by foreign code, you will need to\n    /// > make your own provisions for freeing it appropriately, likely\n    /// > with the foreign code's API to do that.\n    ///\n    /// # Examples\n    ///\n    /// Creates a `CString`, pass ownership to an `extern` function (via raw pointer), then retake\n    /// ownership with `from_raw`:\n    ///\n    /// ```ignore (extern-declaration)\n    /// use std::ffi::CString;\n    /// use std::os::raw::c_char;\n    ///\n    /// extern \"C\" {\n    ///     fn some_extern_function(s: *mut c_char);\n    /// }\n    ///\n    /// let c_string = CString::new(\"Hello!\").expect(\"CString::new failed\");\n    /// let raw = c_string.into_raw();\n    /// unsafe {\n    ///     some_extern_function(raw);\n    ///     let c_string = CString::from_raw(raw);\n    /// }\n    /// ```\n    #[stable(feature = \"cstr_memory\", since = \"1.4.0\")]\n    pub unsafe fn from_raw(ptr: *mut c_char) -> CString {\n        // SAFETY: This is called with a pointer that was obtained from a call\n        // to `CString::into_raw` and the length has not been modified. As such,\n        // we know there is a NUL byte (and only one) at the end and that the\n        // information about the size of the allocation is correct on Rust's\n        // side.\n        unsafe {\n            let len = sys::strlen(ptr) + 1; // Including the NUL byte\n            let slice = slice::from_raw_parts_mut(ptr, len as usize);\n            CString { inner: Box::from_raw(slice as *mut [c_char] as *mut [u8]) }\n        }\n    }\n\n    /// Consumes the `CString` and transfers ownership of the string to a C caller.\n    ///\n    /// The pointer which this function returns must be returned to Rust and reconstituted using\n    /// [`CString::from_raw`] to be properly deallocated. Specifically, one\n    /// should *not* use the standard C `free()` function to deallocate\n    /// this string.\n    ///\n    /// Failure to call [`CString::from_raw`] will lead to a memory leak.\n    ///\n    /// The C side must **not** modify the length of the string (by writing a\n    /// `null` somewhere inside the string or removing the final one) before\n    /// it makes it back into Rust using [`CString::from_raw`]. See the safety section\n    /// in [`CString::from_raw`].\n    ///\n    /// # Examples\n    ///\n    /// ```\n    /// use std::ffi::CString;\n    ///\n    /// let c_string = CString::new(\"foo\").expect(\"CString::new failed\");\n    ///\n    /// let ptr = c_string.into_raw();\n    ///\n    /// unsafe {\n    ///     assert_eq!(b'f', *ptr as u8);\n    ///     assert_eq!(b'o', *ptr.offset(1) as u8);\n    ///     assert_eq!(b'o', *ptr.offset(2) as u8);\n    ///     assert_eq!(b'\\0', *ptr.offset(3) as u8);\n    ///\n    ///     // retake pointer to free memory\n    ///     let _ = CString::from_raw(ptr);\n    /// }\n    /// ```\n    #[inline]\n    #[stable(feature = \"cstr_memory\", since = \"1.4.0\")]\n    pub fn into_raw(self) -> *mut c_char {\n        Box::into_raw(self.into_inner()) as *mut c_char\n    }\n\n    /// Converts the `CString` into a [`String`] if it contains valid UTF-8 data.\n    ///\n    /// On failure, ownership of the original `CString` is returned.\n    ///\n    /// # Examples\n    ///\n    /// ```\n    /// use std::ffi::CString;\n    ///\n    /// let valid_utf8 = vec![b'f', b'o', b'o'];\n    /// let cstring = CString::new(valid_utf8).expect(\"CString::new failed\");\n    /// assert_eq!(cstring.into_string().expect(\"into_string() call failed\"), \"foo\");\n    ///\n    /// let invalid_utf8 = vec![b'f', 0xff, b'o', b'o'];\n    /// let cstring = CString::new(invalid_utf8).expect(\"CString::new failed\");\n    /// let err = cstring.into_string().err().expect(\"into_string().err() failed\");\n    /// assert_eq!(err.utf8_error().valid_up_to(), 1);\n    /// ```\n\n    #[stable(feature = \"cstring_into\", since = \"1.7.0\")]\n    pub fn into_string(self) -> Result<String, IntoStringError> {\n        String::from_utf8(self.into_bytes()).map_err(|e| IntoStringError {\n            error: e.utf8_error(),\n            inner: unsafe { CString::from_vec_unchecked(e.into_bytes()) },\n        })\n    }\n\n    /// Consumes the `CString` and returns the underlying byte buffer.\n    ///\n    /// The returned buffer does **not** contain the trailing nul\n    /// terminator, and it is guaranteed to not have any interior nul\n    /// bytes.\n    ///\n    /// # Examples\n    ///\n    /// ```\n    /// use std::ffi::CString;\n    ///\n    /// let c_string = CString::new(\"foo\").expect(\"CString::new failed\");\n    /// let bytes = c_string.into_bytes();\n    /// assert_eq!(bytes, vec![b'f', b'o', b'o']);\n    /// ```\n    #[stable(feature = \"cstring_into\", since = \"1.7.0\")]\n    pub fn into_bytes(self) -> Vec<u8> {\n        let mut vec = self.into_inner().into_vec();\n        let _nul = vec.pop();\n        debug_assert_eq!(_nul, Some(0u8));\n        vec\n    }\n\n    /// Equivalent to [`CString::into_bytes()`] except that the\n    /// returned vector includes the trailing nul terminator.\n    ///\n    /// # Examples\n    ///\n    /// ```\n    /// use std::ffi::CString;\n    ///\n    /// let c_string = CString::new(\"foo\").expect(\"CString::new failed\");\n    /// let bytes = c_string.into_bytes_with_nul();\n    /// assert_eq!(bytes, vec![b'f', b'o', b'o', b'\\0']);\n    /// ```\n    #[stable(feature = \"cstring_into\", since = \"1.7.0\")]\n    pub fn into_bytes_with_nul(self) -> Vec<u8> {\n        self.into_inner().into_vec()\n    }\n\n    /// Returns the contents of this `CString` as a slice of bytes.\n    ///\n    /// The returned slice does **not** contain the trailing nul\n    /// terminator, and it is guaranteed to not have any interior nul\n    /// bytes. If you need the nul terminator, use\n    /// [`CString::as_bytes_with_nul`] instead.\n    ///\n    /// # Examples\n    ///\n    /// ```\n    /// use std::ffi::CString;\n    ///\n    /// let c_string = CString::new(\"foo\").expect(\"CString::new failed\");\n    /// let bytes = c_string.as_bytes();\n    /// assert_eq!(bytes, &[b'f', b'o', b'o']);\n    /// ```\n    #[inline]\n    #[stable(feature = \"rust1\", since = \"1.0.0\")]\n    pub fn as_bytes(&self) -> &[u8] {\n        // SAFETY: CString has a length at least 1\n        unsafe { self.inner.get_unchecked(..self.inner.len() - 1) }\n    }\n\n    /// Equivalent to [`CString::as_bytes()`] except that the\n    /// returned slice includes the trailing nul terminator.\n    ///\n    /// # Examples\n    ///\n    /// ```\n    /// use std::ffi::CString;\n    ///\n    /// let c_string = CString::new(\"foo\").expect(\"CString::new failed\");\n    /// let bytes = c_string.as_bytes_with_nul();\n    /// assert_eq!(bytes, &[b'f', b'o', b'o', b'\\0']);\n    /// ```\n    #[inline]\n    #[stable(feature = \"rust1\", since = \"1.0.0\")]\n    pub fn as_bytes_with_nul(&self) -> &[u8] {\n        &self.inner\n    }\n\n    /// Extracts a [`CStr`] slice containing the entire string.\n    ///\n    /// # Examples\n    ///\n    /// ```\n    /// use std::ffi::{CString, CStr};\n    ///\n    /// let c_string = CString::new(b\"foo\".to_vec()).expect(\"CString::new failed\");\n    /// let cstr = c_string.as_c_str();\n    /// assert_eq!(cstr,\n    ///            CStr::from_bytes_with_nul(b\"foo\\0\").expect(\"CStr::from_bytes_with_nul failed\"));\n    /// ```\n    #[inline]\n    #[stable(feature = \"as_c_str\", since = \"1.20.0\")]\n    pub fn as_c_str(&self) -> &CStr {\n        &*self\n    }\n\n    /// Converts this `CString` into a boxed [`CStr`].\n    ///\n    /// # Examples\n    ///\n    /// ```\n    /// use std::ffi::{CString, CStr};\n    ///\n    /// let c_string = CString::new(b\"foo\".to_vec()).expect(\"CString::new failed\");\n    /// let boxed = c_string.into_boxed_c_str();\n    /// assert_eq!(&*boxed,\n    ///            CStr::from_bytes_with_nul(b\"foo\\0\").expect(\"CStr::from_bytes_with_nul failed\"));\n    /// ```\n    #[stable(feature = \"into_boxed_c_str\", since = \"1.20.0\")]\n    pub fn into_boxed_c_str(self) -> Box<CStr> {\n        unsafe { Box::from_raw(Box::into_raw(self.into_inner()) as *mut CStr) }\n    }\n\n    /// Bypass \"move out of struct which implements [`Drop`] trait\" restriction.\n    #[inline]\n    fn into_inner(self) -> Box<[u8]> {\n        // Rationale: `mem::forget(self)` invalidates the previous call to `ptr::read(&self.inner)`\n        // so we use `ManuallyDrop` to ensure `self` is not dropped.\n        // Then we can return the box directly without invalidating it.\n        // See https://github.com/rust-lang/rust/issues/62553.\n        let this = mem::ManuallyDrop::new(self);\n        unsafe { ptr::read(&this.inner) }\n    }\n\n    /// Converts a [`Vec`]`<u8>` to a [`CString`] without checking the\n    /// invariants on the given [`Vec`].\n    ///\n    /// # Safety\n    ///\n    /// The given [`Vec`] **must** have one nul byte as its last element.\n    /// This means it cannot be empty nor have any other nul byte anywhere else.\n    ///\n    /// # Example\n    ///\n    /// ```\n    /// #![feature(cstring_from_vec_with_nul)]\n    /// use std::ffi::CString;\n    /// assert_eq!(\n    ///     unsafe { CString::from_vec_with_nul_unchecked(b\"abc\\0\".to_vec()) },\n    ///     unsafe { CString::from_vec_unchecked(b\"abc\".to_vec()) }\n    /// );\n    /// ```\n    #[unstable(feature = \"cstring_from_vec_with_nul\", issue = \"73179\")]\n    pub unsafe fn from_vec_with_nul_unchecked(v: Vec<u8>) -> Self {\n        Self { inner: v.into_boxed_slice() }\n    }\n\n    /// Attempts to converts a [`Vec`]`<u8>` to a [`CString`].\n    ///\n    /// Runtime checks are present to ensure there is only one nul byte in the\n    /// [`Vec`], its last element.\n    ///\n    /// # Errors\n    ///\n    /// If a nul byte is present and not the last element or no nul bytes\n    /// is present, an error will be returned.\n    ///\n    /// # Examples\n    ///\n    /// A successful conversion will produce the same result as [`CString::new`]\n    /// when called without the ending nul byte.\n    ///\n    /// ```\n    /// #![feature(cstring_from_vec_with_nul)]\n    /// use std::ffi::CString;\n    /// assert_eq!(\n    ///     CString::from_vec_with_nul(b\"abc\\0\".to_vec())\n    ///         .expect(\"CString::from_vec_with_nul failed\"),\n    ///     CString::new(b\"abc\".to_vec()).expect(\"CString::new failed\")\n    /// );\n    /// ```\n    ///\n    /// A incorrectly formatted [`Vec`] will produce an error.\n    ///\n    /// ```\n    /// #![feature(cstring_from_vec_with_nul)]\n    /// use std::ffi::{CString, FromVecWithNulError};\n    /// // Interior nul byte\n    /// let _: FromVecWithNulError = CString::from_vec_with_nul(b\"a\\0bc\".to_vec()).unwrap_err();\n    /// // No nul byte\n    /// let _: FromVecWithNulError = CString::from_vec_with_nul(b\"abc\".to_vec()).unwrap_err();\n    /// ```\n    #[unstable(feature = \"cstring_from_vec_with_nul\", issue = \"73179\")]\n    pub fn from_vec_with_nul(v: Vec<u8>) -> Result<Self, FromVecWithNulError> {\n        let nul_pos = memchr::memchr(0, &v);\n        match nul_pos {\n            Some(nul_pos) if nul_pos + 1 == v.len() => {\n                // SAFETY: We know there is only one nul byte, at the end\n                // of the vec.\n                Ok(unsafe { Self::from_vec_with_nul_unchecked(v) })\n            }\n            Some(nul_pos) => Err(FromVecWithNulError {\n                error_kind: FromBytesWithNulErrorKind::InteriorNul(nul_pos),\n                bytes: v,\n            }),\n            None => Err(FromVecWithNulError {\n                error_kind: FromBytesWithNulErrorKind::NotNulTerminated,\n                bytes: v,\n            }),\n        }\n    }\n}\n\n// Turns this `CString` into an empty string to prevent\n// memory-unsafe code from working by accident. Inline\n// to prevent LLVM from optimizing it away in debug builds.\n#[stable(feature = \"cstring_drop\", since = \"1.13.0\")]\nimpl Drop for CString {\n    #[inline]\n    fn drop(&mut self) {\n        unsafe {\n            *self.inner.get_unchecked_mut(0) = 0;\n        }\n    }\n}\n\n#[stable(feature = \"rust1\", since = \"1.0.0\")]\nimpl ops::Deref for CString {\n    type Target = CStr;\n\n    #[inline]\n    fn deref(&self) -> &CStr {\n        unsafe { CStr::from_bytes_with_nul_unchecked(self.as_bytes_with_nul()) }\n    }\n}\n\n#[stable(feature = \"rust1\", since = \"1.0.0\")]\nimpl fmt::Debug for CString {\n    fn fmt(&self, f: &mut fmt::Formatter<'_>) -> fmt::Result {\n        fmt::Debug::fmt(&**self, f)\n    }\n}\n\n#[stable(feature = \"cstring_into\", since = \"1.7.0\")]\nimpl From<CString> for Vec<u8> {\n    /// Converts a [`CString`] into a [`Vec`]`<u8>`.\n    ///\n    /// The conversion consumes the [`CString`], and removes the terminating NUL byte.\n    #[inline]\n    fn from(s: CString) -> Vec<u8> {\n        s.into_bytes()\n    }\n}\n\n#[stable(feature = \"cstr_debug\", since = \"1.3.0\")]\nimpl fmt::Debug for CStr {\n    fn fmt(&self, f: &mut fmt::Formatter<'_>) -> fmt::Result {\n        write!(f, \"\\\"\")?;\n        for byte in self.to_bytes().iter().flat_map(|&b| ascii::escape_default(b)) {\n            f.write_char(byte as char)?;\n        }\n        write!(f, \"\\\"\")\n    }\n}\n\n#[stable(feature = \"cstr_default\", since = \"1.10.0\")]\nimpl Default for &CStr {\n    fn default() -> Self {\n        const SLICE: &[c_char] = &[0];\n        unsafe { CStr::from_ptr(SLICE.as_ptr()) }\n    }\n}\n\n#[stable(feature = \"cstr_default\", since = \"1.10.0\")]\nimpl Default for CString {\n    /// Creates an empty `CString`.\n    fn default() -> CString {\n        let a: &CStr = Default::default();\n        a.to_owned()\n    }\n}\n\n#[stable(feature = \"cstr_borrow\", since = \"1.3.0\")]\nimpl Borrow<CStr> for CString {\n    #[inline]\n    fn borrow(&self) -> &CStr {\n        self\n    }\n}\n\n#[stable(feature = \"cstring_from_cow_cstr\", since = \"1.28.0\")]\nimpl<'a> From<Cow<'a, CStr>> for CString {\n    #[inline]\n    fn from(s: Cow<'a, CStr>) -> Self {\n        s.into_owned()\n    }\n}\n\n#[stable(feature = \"box_from_c_str\", since = \"1.17.0\")]\nimpl From<&CStr> for Box<CStr> {\n    fn from(s: &CStr) -> Box<CStr> {\n        let boxed: Box<[u8]> = Box::from(s.to_bytes_with_nul());\n        unsafe { Box::from_raw(Box::into_raw(boxed) as *mut CStr) }\n    }\n}\n\n#[stable(feature = \"box_from_cow\", since = \"1.45.0\")]\nimpl From<Cow<'_, CStr>> for Box<CStr> {\n    #[inline]\n    fn from(cow: Cow<'_, CStr>) -> Box<CStr> {\n        match cow {\n            Cow::Borrowed(s) => Box::from(s),\n            Cow::Owned(s) => Box::from(s),\n        }\n    }\n}\n\n#[stable(feature = \"c_string_from_box\", since = \"1.18.0\")]\nimpl From<Box<CStr>> for CString {\n    /// Converts a [`Box`]`<CStr>` into a [`CString`] without copying or allocating.\n    #[inline]\n    fn from(s: Box<CStr>) -> CString {\n        s.into_c_string()\n    }\n}\n\n#[stable(feature = \"cstring_from_vec_of_nonzerou8\", since = \"1.43.0\")]\nimpl From<Vec<NonZeroU8>> for CString {\n    /// Converts a [`Vec`]`<`[`NonZeroU8`]`>` into a [`CString`] without\n    /// copying nor checking for inner null bytes.\n    #[inline]\n    fn from(v: Vec<NonZeroU8>) -> CString {\n        unsafe {\n            // Transmute `Vec<NonZeroU8>` to `Vec<u8>`.\n            let v: Vec<u8> = {\n                // SAFETY:\n                //   - transmuting between `NonZeroU8` and `u8` is sound;\n                //   - `alloc::Layout<NonZeroU8> == alloc::Layout<u8>`.\n                let (ptr, len, cap): (*mut NonZeroU8, _, _) = Vec::into_raw_parts(v);\n                Vec::from_raw_parts(ptr.cast::<u8>(), len, cap)\n            };\n            // SAFETY: `v` cannot contain null bytes, given the type-level\n            // invariant of `NonZeroU8`.\n            CString::from_vec_unchecked(v)\n        }\n    }\n}\n\n#[stable(feature = \"more_box_slice_clone\", since = \"1.29.0\")]\nimpl Clone for Box<CStr> {\n    #[inline]\n    fn clone(&self) -> Self {\n        (**self).into()\n    }\n}\n\n#[stable(feature = \"box_from_c_string\", since = \"1.20.0\")]\nimpl From<CString> for Box<CStr> {\n    /// Converts a [`CString`] into a [`Box`]`<CStr>` without copying or allocating.\n    #[inline]\n    fn from(s: CString) -> Box<CStr> {\n        s.into_boxed_c_str()\n    }\n}\n\n#[stable(feature = \"cow_from_cstr\", since = \"1.28.0\")]\nimpl<'a> From<CString> for Cow<'a, CStr> {\n    #[inline]\n    fn from(s: CString) -> Cow<'a, CStr> {\n        Cow::Owned(s)\n    }\n}\n\n#[stable(feature = \"cow_from_cstr\", since = \"1.28.0\")]\nimpl<'a> From<&'a CStr> for Cow<'a, CStr> {\n    #[inline]\n    fn from(s: &'a CStr) -> Cow<'a, CStr> {\n        Cow::Borrowed(s)\n    }\n}\n\n#[stable(feature = \"cow_from_cstr\", since = \"1.28.0\")]\nimpl<'a> From<&'a CString> for Cow<'a, CStr> {\n    #[inline]\n    fn from(s: &'a CString) -> Cow<'a, CStr> {\n        Cow::Borrowed(s.as_c_str())\n    }\n}\n\n#[stable(feature = \"shared_from_slice2\", since = \"1.24.0\")]\nimpl From<CString> for Arc<CStr> {\n    /// Converts a [`CString`] into a [`Arc`]`<CStr>` without copying or allocating.\n    #[inline]\n    fn from(s: CString) -> Arc<CStr> {\n        let arc: Arc<[u8]> = Arc::from(s.into_inner());\n        unsafe { Arc::from_raw(Arc::into_raw(arc) as *const CStr) }\n    }\n}\n\n#[stable(feature = \"shared_from_slice2\", since = \"1.24.0\")]\nimpl From<&CStr> for Arc<CStr> {\n    #[inline]\n    fn from(s: &CStr) -> Arc<CStr> {\n        let arc: Arc<[u8]> = Arc::from(s.to_bytes_with_nul());\n        unsafe { Arc::from_raw(Arc::into_raw(arc) as *const CStr) }\n    }\n}\n\n#[stable(feature = \"shared_from_slice2\", since = \"1.24.0\")]\nimpl From<CString> for Rc<CStr> {\n    /// Converts a [`CString`] into a [`Rc`]`<CStr>` without copying or allocating.\n    #[inline]\n    fn from(s: CString) -> Rc<CStr> {\n        let rc: Rc<[u8]> = Rc::from(s.into_inner());\n        unsafe { Rc::from_raw(Rc::into_raw(rc) as *const CStr) }\n    }\n}\n\n#[stable(feature = \"shared_from_slice2\", since = \"1.24.0\")]\nimpl From<&CStr> for Rc<CStr> {\n    #[inline]\n    fn from(s: &CStr) -> Rc<CStr> {\n        let rc: Rc<[u8]> = Rc::from(s.to_bytes_with_nul());\n        unsafe { Rc::from_raw(Rc::into_raw(rc) as *const CStr) }\n    }\n}\n\n#[stable(feature = \"default_box_extra\", since = \"1.17.0\")]\nimpl Default for Box<CStr> {\n    fn default() -> Box<CStr> {\n        let boxed: Box<[u8]> = Box::from([0]);\n        unsafe { Box::from_raw(Box::into_raw(boxed) as *mut CStr) }\n    }\n}\n\nimpl NulError {\n    /// Returns the position of the nul byte in the slice that caused\n    /// [`CString::new`] to fail.\n    ///\n    /// # Examples\n    ///\n    /// ```\n    /// use std::ffi::CString;\n    ///\n    /// let nul_error = CString::new(\"foo\\0bar\").unwrap_err();\n    /// assert_eq!(nul_error.nul_position(), 3);\n    ///\n    /// let nul_error = CString::new(\"foo bar\\0\").unwrap_err();\n    /// assert_eq!(nul_error.nul_position(), 7);\n    /// ```\n    #[stable(feature = \"rust1\", since = \"1.0.0\")]\n    pub fn nul_position(&self) -> usize {\n        self.0\n    }\n\n    /// Consumes this error, returning the underlying vector of bytes which\n    /// generated the error in the first place.\n    ///\n    /// # Examples\n    ///\n    /// ```\n    /// use std::ffi::CString;\n    ///\n    /// let nul_error = CString::new(\"foo\\0bar\").unwrap_err();\n    /// assert_eq!(nul_error.into_vec(), b\"foo\\0bar\");\n    /// ```\n    #[stable(feature = \"rust1\", since = \"1.0.0\")]\n    pub fn into_vec(self) -> Vec<u8> {\n        self.1\n    }\n}\n\n#[stable(feature = \"rust1\", since = \"1.0.0\")]\nimpl Error for NulError {\n    #[allow(deprecated)]\n    fn description(&self) -> &str {\n        \"nul byte found in data\"\n    }\n}\n\n#[stable(feature = \"rust1\", since = \"1.0.0\")]\nimpl fmt::Display for NulError {\n    fn fmt(&self, f: &mut fmt::Formatter<'_>) -> fmt::Result {\n        write!(f, \"nul byte found in provided data at position: {}\", self.0)\n    }\n}\n\n#[stable(feature = \"rust1\", since = \"1.0.0\")]\nimpl From<NulError> for io::Error {\n    /// Converts a [`NulError`] into a [`io::Error`].\n    fn from(_: NulError) -> io::Error {\n        io::Error::new_const(io::ErrorKind::InvalidInput, &\"data provided contains a nul byte\")\n    }\n}\n\n#[stable(feature = \"frombyteswithnulerror_impls\", since = \"1.17.0\")]\nimpl Error for FromBytesWithNulError {\n    #[allow(deprecated)]\n    fn description(&self) -> &str {\n        match self.kind {\n            FromBytesWithNulErrorKind::InteriorNul(..) => {\n                \"data provided contains an interior nul byte\"\n            }\n            FromBytesWithNulErrorKind::NotNulTerminated => \"data provided is not nul terminated\",\n        }\n    }\n}\n\n#[stable(feature = \"frombyteswithnulerror_impls\", since = \"1.17.0\")]\nimpl fmt::Display for FromBytesWithNulError {\n    #[allow(deprecated, deprecated_in_future)]\n    fn fmt(&self, f: &mut fmt::Formatter<'_>) -> fmt::Result {\n        f.write_str(self.description())?;\n        if let FromBytesWithNulErrorKind::InteriorNul(pos) = self.kind {\n            write!(f, \" at byte pos {}\", pos)?;\n        }\n        Ok(())\n    }\n}\n\n#[unstable(feature = \"cstring_from_vec_with_nul\", issue = \"73179\")]\nimpl Error for FromVecWithNulError {}\n\n#[unstable(feature = \"cstring_from_vec_with_nul\", issue = \"73179\")]\nimpl fmt::Display for FromVecWithNulError {\n    fn fmt(&self, f: &mut fmt::Formatter<'_>) -> fmt::Result {\n        match self.error_kind {\n            FromBytesWithNulErrorKind::InteriorNul(pos) => {\n                write!(f, \"data provided contains an interior nul byte at pos {}\", pos)\n            }\n            FromBytesWithNulErrorKind::NotNulTerminated => {\n                write!(f, \"data provided is not nul terminated\")\n            }\n        }\n    }\n}\n\nimpl IntoStringError {\n    /// Consumes this error, returning original [`CString`] which generated the\n    /// error.\n    #[stable(feature = \"cstring_into\", since = \"1.7.0\")]\n    pub fn into_cstring(self) -> CString {\n        self.inner\n    }\n\n    /// Access the underlying UTF-8 error that was the cause of this error.\n    #[stable(feature = \"cstring_into\", since = \"1.7.0\")]\n    pub fn utf8_error(&self) -> Utf8Error {\n        self.error\n    }\n}\n\n#[stable(feature = \"cstring_into\", since = \"1.7.0\")]\nimpl Error for IntoStringError {\n    #[allow(deprecated)]\n    fn description(&self) -> &str {\n        \"C string contained non-utf8 bytes\"\n    }\n\n    fn source(&self) -> Option<&(dyn Error + 'static)> {\n        Some(&self.error)\n    }\n}\n\n#[stable(feature = \"cstring_into\", since = \"1.7.0\")]\nimpl fmt::Display for IntoStringError {\n    #[allow(deprecated, deprecated_in_future)]\n    fn fmt(&self, f: &mut fmt::Formatter<'_>) -> fmt::Result {\n        self.description().fmt(f)\n    }\n}\n\nimpl CStr {\n    /// Wraps a raw C string with a safe C string wrapper.\n    ///\n    /// This function will wrap the provided `ptr` with a `CStr` wrapper, which\n    /// allows inspection and interoperation of non-owned C strings. The total\n    /// size of the raw C string must be smaller than `isize::MAX` **bytes**\n    /// in memory due to calling the `slice::from_raw_parts` function.\n    /// This method is unsafe for a number of reasons:\n    ///\n    /// * There is no guarantee to the validity of `ptr`.\n    /// * The returned lifetime is not guaranteed to be the actual lifetime of\n    ///   `ptr`.\n    /// * There is no guarantee that the memory pointed to by `ptr` contains a\n    ///   valid nul terminator byte at the end of the string.\n    /// * It is not guaranteed that the memory pointed by `ptr` won't change\n    ///   before the `CStr` has been destroyed.\n    ///\n    /// > **Note**: This operation is intended to be a 0-cost cast but it is\n    /// > currently implemented with an up-front calculation of the length of\n    /// > the string. This is not guaranteed to always be the case.\n    ///\n    /// # Examples\n    ///\n    /// ```ignore (extern-declaration)\n    /// # fn main() {\n    /// use std::ffi::CStr;\n    /// use std::os::raw::c_char;\n    ///\n    /// extern \"C\" {\n    ///     fn my_string() -> *const c_char;\n    /// }\n    ///\n    /// unsafe {\n    ///     let slice = CStr::from_ptr(my_string());\n    ///     println!(\"string returned: {}\", slice.to_str().unwrap());\n    /// }\n    /// # }\n    /// ```\n    #[stable(feature = \"rust1\", since = \"1.0.0\")]\n    pub unsafe fn from_ptr<'a>(ptr: *const c_char) -> &'a CStr {\n        // SAFETY: The caller has provided a pointer that points to a valid C\n        // string with a NUL terminator of size less than `isize::MAX`, whose\n        // content remain valid and doesn't change for the lifetime of the\n        // returned `CStr`.\n        //\n        // Thus computing the length is fine (a NUL byte exists), the call to\n        // from_raw_parts is safe because we know the length is at most `isize::MAX`, meaning\n        // the call to `from_bytes_with_nul_unchecked` is correct.\n        //\n        // The cast from c_char to u8 is ok because a c_char is always one byte.\n        unsafe {\n            let len = sys::strlen(ptr);\n            let ptr = ptr as *const u8;\n            CStr::from_bytes_with_nul_unchecked(slice::from_raw_parts(ptr, len as usize + 1))\n        }\n    }\n\n    /// Creates a C string wrapper from a byte slice.\n    ///\n    /// This function will cast the provided `bytes` to a `CStr`\n    /// wrapper after ensuring that the byte slice is nul-terminated\n    /// and does not contain any interior nul bytes.\n    ///\n    /// # Examples\n    ///\n    /// ```\n    /// use std::ffi::CStr;\n    ///\n    /// let cstr = CStr::from_bytes_with_nul(b\"hello\\0\");\n    /// assert!(cstr.is_ok());\n    /// ```\n    ///\n    /// Creating a `CStr` without a trailing nul terminator is an error:\n    ///\n    /// ```\n    /// use std::ffi::CStr;\n    ///\n    /// let cstr = CStr::from_bytes_with_nul(b\"hello\");\n    /// assert!(cstr.is_err());\n    /// ```\n    ///\n    /// Creating a `CStr` with an interior nul byte is an error:\n    ///\n    /// ```\n    /// use std::ffi::CStr;\n    ///\n    /// let cstr = CStr::from_bytes_with_nul(b\"he\\0llo\\0\");\n    /// assert!(cstr.is_err());\n    /// ```\n    #[stable(feature = \"cstr_from_bytes\", since = \"1.10.0\")]\n    pub fn from_bytes_with_nul(bytes: &[u8]) -> Result<&CStr, FromBytesWithNulError> {\n        let nul_pos = memchr::memchr(0, bytes);\n        if let Some(nul_pos) = nul_pos {\n            if nul_pos + 1 != bytes.len() {\n                return Err(FromBytesWithNulError::interior_nul(nul_pos));\n            }\n            Ok(unsafe { CStr::from_bytes_with_nul_unchecked(bytes) })\n        } else {\n            Err(FromBytesWithNulError::not_nul_terminated())\n        }\n    }\n\n    /// Unsafely creates a C string wrapper from a byte slice.\n    ///\n    /// This function will cast the provided `bytes` to a `CStr` wrapper without\n    /// performing any sanity checks. The provided slice **must** be nul-terminated\n    /// and not contain any interior nul bytes.\n    ///\n    /// # Examples\n    ///\n    /// ```\n    /// use std::ffi::{CStr, CString};\n    ///\n    /// unsafe {\n    ///     let cstring = CString::new(\"hello\").expect(\"CString::new failed\");\n    ///     let cstr = CStr::from_bytes_with_nul_unchecked(cstring.to_bytes_with_nul());\n    ///     assert_eq!(cstr, &*cstring);\n    /// }\n    /// ```\n    #[inline]\n    #[stable(feature = \"cstr_from_bytes\", since = \"1.10.0\")]\n    #[rustc_const_unstable(feature = \"const_cstr_unchecked\", issue = \"none\")]\n    pub const unsafe fn from_bytes_with_nul_unchecked(bytes: &[u8]) -> &CStr {\n        // SAFETY: Casting to CStr is safe because its internal representation\n        // is a [u8] too (safe only inside std).\n        // Dereferencing the obtained pointer is safe because it comes from a\n        // reference. Making a reference is then safe because its lifetime\n        // is bound by the lifetime of the given `bytes`.\n        unsafe { &*(bytes as *const [u8] as *const CStr) }\n    }\n\n    /// Returns the inner pointer to this C string.\n    ///\n    /// The returned pointer will be valid for as long as `self` is, and points\n    /// to a contiguous region of memory terminated with a 0 byte to represent\n    /// the end of the string.\n    ///\n    /// **WARNING**\n    ///\n    /// The returned pointer is read-only; writing to it (including passing it\n    /// to C code that writes to it) causes undefined behavior.\n    ///\n    /// It is your responsibility to make sure that the underlying memory is not\n    /// freed too early. For example, the following code will cause undefined\n    /// behavior when `ptr` is used inside the `unsafe` block:\n    ///\n    /// ```no_run\n    /// # #![allow(unused_must_use)] #![allow(temporary_cstring_as_ptr)]\n    /// use std::ffi::CString;\n    ///\n    /// let ptr = CString::new(\"Hello\").expect(\"CString::new failed\").as_ptr();\n    /// unsafe {\n    ///     // `ptr` is dangling\n    ///     *ptr;\n    /// }\n    /// ```\n    ///\n    /// This happens because the pointer returned by `as_ptr` does not carry any\n    /// lifetime information and the [`CString`] is deallocated immediately after\n    /// the `CString::new(\"Hello\").expect(\"CString::new failed\").as_ptr()`\n    /// expression is evaluated.\n    /// To fix the problem, bind the `CString` to a local variable:\n    ///\n    /// ```no_run\n    /// # #![allow(unused_must_use)]\n    /// use std::ffi::CString;\n    ///\n    /// let hello = CString::new(\"Hello\").expect(\"CString::new failed\");\n    /// let ptr = hello.as_ptr();\n    /// unsafe {\n    ///     // `ptr` is valid because `hello` is in scope\n    ///     *ptr;\n    /// }\n    /// ```\n    ///\n    /// This way, the lifetime of the [`CString`] in `hello` encompasses\n    /// the lifetime of `ptr` and the `unsafe` block.\n    #[inline]\n    #[stable(feature = \"rust1\", since = \"1.0.0\")]\n    #[rustc_const_stable(feature = \"const_str_as_ptr\", since = \"1.32.0\")]\n    pub const fn as_ptr(&self) -> *const c_char {\n        self.inner.as_ptr()\n    }\n\n    /// Converts this C string to a byte slice.\n    ///\n    /// The returned slice will **not** contain the trailing nul terminator that this C\n    /// string has.\n    ///\n    /// > **Note**: This method is currently implemented as a constant-time\n    /// > cast, but it is planned to alter its definition in the future to\n    /// > perform the length calculation whenever this method is called.\n    ///\n    /// # Examples\n    ///\n    /// ```\n    /// use std::ffi::CStr;\n    ///\n    /// let cstr = CStr::from_bytes_with_nul(b\"foo\\0\").expect(\"CStr::from_bytes_with_nul failed\");\n    /// assert_eq!(cstr.to_bytes(), b\"foo\");\n    /// ```\n    #[inline]\n    #[stable(feature = \"rust1\", since = \"1.0.0\")]\n    pub fn to_bytes(&self) -> &[u8] {\n        let bytes = self.to_bytes_with_nul();\n        // SAFETY: to_bytes_with_nul returns slice with length at least 1\n        unsafe { bytes.get_unchecked(..bytes.len() - 1) }\n    }\n\n    /// Converts this C string to a byte slice containing the trailing 0 byte.\n    ///\n    /// This function is the equivalent of [`CStr::to_bytes`] except that it\n    /// will retain the trailing nul terminator instead of chopping it off.\n    ///\n    /// > **Note**: This method is currently implemented as a 0-cost cast, but\n    /// > it is planned to alter its definition in the future to perform the\n    /// > length calculation whenever this method is called.\n    ///\n    /// # Examples\n    ///\n    /// ```\n    /// use std::ffi::CStr;\n    ///\n    /// let cstr = CStr::from_bytes_with_nul(b\"foo\\0\").expect(\"CStr::from_bytes_with_nul failed\");\n    /// assert_eq!(cstr.to_bytes_with_nul(), b\"foo\\0\");\n    /// ```\n    #[inline]\n    #[stable(feature = \"rust1\", since = \"1.0.0\")]\n    pub fn to_bytes_with_nul(&self) -> &[u8] {\n        unsafe { &*(&self.inner as *const [c_char] as *const [u8]) }\n    }\n\n    /// Yields a [`&str`] slice if the `CStr` contains valid UTF-8.\n    ///\n    /// If the contents of the `CStr` are valid UTF-8 data, this\n    /// function will return the corresponding [`&str`] slice. Otherwise,\n    /// it will return an error with details of where UTF-8 validation failed.\n    ///\n    /// [`&str`]: prim@str\n    ///\n    /// # Examples\n    ///\n    /// ```\n    /// use std::ffi::CStr;\n    ///\n    /// let cstr = CStr::from_bytes_with_nul(b\"foo\\0\").expect(\"CStr::from_bytes_with_nul failed\");\n    /// assert_eq!(cstr.to_str(), Ok(\"foo\"));\n    /// ```\n    #[stable(feature = \"cstr_to_str\", since = \"1.4.0\")]\n    pub fn to_str(&self) -> Result<&str, str::Utf8Error> {\n        // N.B., when `CStr` is changed to perform the length check in `.to_bytes()`\n        // instead of in `from_ptr()`, it may be worth considering if this should\n        // be rewritten to do the UTF-8 check inline with the length calculation\n        // instead of doing it afterwards.\n        str::from_utf8(self.to_bytes())\n    }\n\n    /// Converts a `CStr` into a [`Cow`]`<`[`str`]`>`.\n    ///\n    /// If the contents of the `CStr` are valid UTF-8 data, this\n    /// function will return a [`Cow`]`::`[`Borrowed`]`(`[`&str`]`)`\n    /// with the corresponding [`&str`] slice. Otherwise, it will\n    /// replace any invalid UTF-8 sequences with\n    /// [`U+FFFD REPLACEMENT CHARACTER`][U+FFFD] and return a\n    /// [`Cow`]`::`[`Owned`]`(`[`String`]`)` with the result.\n    ///\n    /// [`str`]: primitive@str\n    /// [`&str`]: primitive@str\n    /// [`Borrowed`]: Cow::Borrowed\n    /// [`Owned`]: Cow::Owned\n    /// [U+FFFD]: crate::char::REPLACEMENT_CHARACTER\n    ///\n    /// # Examples\n    ///\n    /// Calling `to_string_lossy` on a `CStr` containing valid UTF-8:\n    ///\n    /// ```\n    /// use std::borrow::Cow;\n    /// use std::ffi::CStr;\n    ///\n    /// let cstr = CStr::from_bytes_with_nul(b\"Hello World\\0\")\n    ///                  .expect(\"CStr::from_bytes_with_nul failed\");\n    /// assert_eq!(cstr.to_string_lossy(), Cow::Borrowed(\"Hello World\"));\n    /// ```\n    ///\n    /// Calling `to_string_lossy` on a `CStr` containing invalid UTF-8:\n    ///\n    /// ```\n    /// use std::borrow::Cow;\n    /// use std::ffi::CStr;\n    ///\n    /// let cstr = CStr::from_bytes_with_nul(b\"Hello \\xF0\\x90\\x80World\\0\")\n    ///                  .expect(\"CStr::from_bytes_with_nul failed\");\n    /// assert_eq!(\n    ///     cstr.to_string_lossy(),\n    ///     Cow::Owned(String::from(\"Hello �World\")) as Cow<'_, str>\n    /// );\n    /// ```\n    #[stable(feature = \"cstr_to_str\", since = \"1.4.0\")]\n    pub fn to_string_lossy(&self) -> Cow<'_, str> {\n        String::from_utf8_lossy(self.to_bytes())\n    }\n\n    /// Converts a [`Box`]`<CStr>` into a [`CString`] without copying or allocating.\n    ///\n    /// # Examples\n    ///\n    /// ```\n    /// use std::ffi::CString;\n    ///\n    /// let c_string = CString::new(b\"foo\".to_vec()).expect(\"CString::new failed\");\n    /// let boxed = c_string.into_boxed_c_str();\n    /// assert_eq!(boxed.into_c_string(), CString::new(\"foo\").expect(\"CString::new failed\"));\n    /// ```\n    #[stable(feature = \"into_boxed_c_str\", since = \"1.20.0\")]\n    pub fn into_c_string(self: Box<CStr>) -> CString {\n        let raw = Box::into_raw(self) as *mut [u8];\n        CString { inner: unsafe { Box::from_raw(raw) } }\n    }\n}\n\n#[stable(feature = \"rust1\", since = \"1.0.0\")]\nimpl PartialEq for CStr {\n    fn eq(&self, other: &CStr) -> bool {\n        self.to_bytes().eq(other.to_bytes())\n    }\n}\n#[stable(feature = \"rust1\", since = \"1.0.0\")]\nimpl Eq for CStr {}\n#[stable(feature = \"rust1\", since = \"1.0.0\")]\nimpl PartialOrd for CStr {\n    fn partial_cmp(&self, other: &CStr) -> Option<Ordering> {\n        self.to_bytes().partial_cmp(&other.to_bytes())\n    }\n}\n#[stable(feature = \"rust1\", since = \"1.0.0\")]\nimpl Ord for CStr {\n    fn cmp(&self, other: &CStr) -> Ordering {\n        self.to_bytes().cmp(&other.to_bytes())\n    }\n}\n\n#[stable(feature = \"cstr_borrow\", since = \"1.3.0\")]\nimpl ToOwned for CStr {\n    type Owned = CString;\n\n    fn to_owned(&self) -> CString {\n        CString { inner: self.to_bytes_with_nul().into() }\n    }\n\n    fn clone_into(&self, target: &mut CString) {\n        let mut b = Vec::from(mem::take(&mut target.inner));\n        self.to_bytes_with_nul().clone_into(&mut b);\n        target.inner = b.into_boxed_slice();\n    }\n}\n\n#[stable(feature = \"cstring_asref\", since = \"1.7.0\")]\nimpl From<&CStr> for CString {\n    fn from(s: &CStr) -> CString {\n        s.to_owned()\n    }\n}\n\n#[stable(feature = \"cstring_asref\", since = \"1.7.0\")]\nimpl ops::Index<ops::RangeFull> for CString {\n    type Output = CStr;\n\n    #[inline]\n    fn index(&self, _index: ops::RangeFull) -> &CStr {\n        self\n    }\n}\n\n#[stable(feature = \"cstr_range_from\", since = \"1.47.0\")]\nimpl ops::Index<ops::RangeFrom<usize>> for CStr {\n    type Output = CStr;\n\n    fn index(&self, index: ops::RangeFrom<usize>) -> &CStr {\n        let bytes = self.to_bytes_with_nul();\n        // we need to manually check the starting index to account for the null\n        // byte, since otherwise we could get an empty string that doesn't end\n        // in a null.\n        if index.start < bytes.len() {\n            unsafe { CStr::from_bytes_with_nul_unchecked(&bytes[index.start..]) }\n        } else {\n            panic!(\n                \"index out of bounds: the len is {} but the index is {}\",\n                bytes.len(),\n                index.start\n            );\n        }\n    }\n}\n\n#[stable(feature = \"cstring_asref\", since = \"1.7.0\")]\nimpl AsRef<CStr> for CStr {\n    #[inline]\n    fn as_ref(&self) -> &CStr {\n        self\n    }\n}\n\n#[stable(feature = \"cstring_asref\", since = \"1.7.0\")]\nimpl AsRef<CStr> for CString {\n    #[inline]\n    fn as_ref(&self) -> &CStr {\n        self\n    }\n}\n"],[2221,"use super::*;\n\nuse crate::rc::Rc;\nuse crate::sync::Arc;\n\nmacro_rules! t(\n    ($path:expr, iter: $iter:expr) => (\n        {\n            let path = Path::new($path);\n\n            // Forward iteration\n            let comps = path.iter()\n                .map(|p| p.to_string_lossy().into_owned())\n                .collect::<Vec<String>>();\n            let exp: &[&str] = &$iter;\n            let exps = exp.iter().map(|s| s.to_string()).collect::<Vec<String>>();\n            assert!(comps == exps, \"iter: Expected {:?}, found {:?}\",\n                    exps, comps);\n\n            // Reverse iteration\n            let comps = Path::new($path).iter().rev()\n                .map(|p| p.to_string_lossy().into_owned())\n                .collect::<Vec<String>>();\n            let exps = exps.into_iter().rev().collect::<Vec<String>>();\n            assert!(comps == exps, \"iter().rev(): Expected {:?}, found {:?}\",\n                    exps, comps);\n        }\n    );\n\n    ($path:expr, has_root: $has_root:expr, is_absolute: $is_absolute:expr) => (\n        {\n            let path = Path::new($path);\n\n            let act_root = path.has_root();\n            assert!(act_root == $has_root, \"has_root: Expected {:?}, found {:?}\",\n                    $has_root, act_root);\n\n            let act_abs = path.is_absolute();\n            assert!(act_abs == $is_absolute, \"is_absolute: Expected {:?}, found {:?}\",\n                    $is_absolute, act_abs);\n        }\n    );\n\n    ($path:expr, parent: $parent:expr, file_name: $file:expr) => (\n        {\n            let path = Path::new($path);\n\n            let parent = path.parent().map(|p| p.to_str().unwrap());\n            let exp_parent: Option<&str> = $parent;\n            assert!(parent == exp_parent, \"parent: Expected {:?}, found {:?}\",\n                    exp_parent, parent);\n\n            let file = path.file_name().map(|p| p.to_str().unwrap());\n            let exp_file: Option<&str> = $file;\n            assert!(file == exp_file, \"file_name: Expected {:?}, found {:?}\",\n                    exp_file, file);\n        }\n    );\n\n    ($path:expr, file_stem: $file_stem:expr, extension: $extension:expr) => (\n        {\n            let path = Path::new($path);\n\n            let stem = path.file_stem().map(|p| p.to_str().unwrap());\n            let exp_stem: Option<&str> = $file_stem;\n            assert!(stem == exp_stem, \"file_stem: Expected {:?}, found {:?}\",\n                    exp_stem, stem);\n\n            let ext = path.extension().map(|p| p.to_str().unwrap());\n            let exp_ext: Option<&str> = $extension;\n            assert!(ext == exp_ext, \"extension: Expected {:?}, found {:?}\",\n                    exp_ext, ext);\n        }\n    );\n\n    ($path:expr, iter: $iter:expr,\n                 has_root: $has_root:expr, is_absolute: $is_absolute:expr,\n                 parent: $parent:expr, file_name: $file:expr,\n                 file_stem: $file_stem:expr, extension: $extension:expr) => (\n        {\n            t!($path, iter: $iter);\n            t!($path, has_root: $has_root, is_absolute: $is_absolute);\n            t!($path, parent: $parent, file_name: $file);\n            t!($path, file_stem: $file_stem, extension: $extension);\n        }\n    );\n);\n\n#[test]\nfn into() {\n    use crate::borrow::Cow;\n\n    let static_path = Path::new(\"/home/foo\");\n    let static_cow_path: Cow<'static, Path> = static_path.into();\n    let pathbuf = PathBuf::from(\"/home/foo\");\n\n    {\n        let path: &Path = &pathbuf;\n        let borrowed_cow_path: Cow<'_, Path> = path.into();\n\n        assert_eq!(static_cow_path, borrowed_cow_path);\n    }\n\n    let owned_cow_path: Cow<'static, Path> = pathbuf.into();\n\n    assert_eq!(static_cow_path, owned_cow_path);\n}\n\n#[test]\n#[cfg(unix)]\npub fn test_decompositions_unix() {\n    t!(\"\",\n    iter: [],\n    has_root: false,\n    is_absolute: false,\n    parent: None,\n    file_name: None,\n    file_stem: None,\n    extension: None\n    );\n\n    t!(\"foo\",\n    iter: [\"foo\"],\n    has_root: false,\n    is_absolute: false,\n    parent: Some(\"\"),\n    file_name: Some(\"foo\"),\n    file_stem: Some(\"foo\"),\n    extension: None\n    );\n\n    t!(\"/\",\n    iter: [\"/\"],\n    has_root: true,\n    is_absolute: true,\n    parent: None,\n    file_name: None,\n    file_stem: None,\n    extension: None\n    );\n\n    t!(\"/foo\",\n    iter: [\"/\", \"foo\"],\n    has_root: true,\n    is_absolute: true,\n    parent: Some(\"/\"),\n    file_name: Some(\"foo\"),\n    file_stem: Some(\"foo\"),\n    extension: None\n    );\n\n    t!(\"foo/\",\n    iter: [\"foo\"],\n    has_root: false,\n    is_absolute: false,\n    parent: Some(\"\"),\n    file_name: Some(\"foo\"),\n    file_stem: Some(\"foo\"),\n    extension: None\n    );\n\n    t!(\"/foo/\",\n    iter: [\"/\", \"foo\"],\n    has_root: true,\n    is_absolute: true,\n    parent: Some(\"/\"),\n    file_name: Some(\"foo\"),\n    file_stem: Some(\"foo\"),\n    extension: None\n    );\n\n    t!(\"foo/bar\",\n    iter: [\"foo\", \"bar\"],\n    has_root: false,\n    is_absolute: false,\n    parent: Some(\"foo\"),\n    file_name: Some(\"bar\"),\n    file_stem: Some(\"bar\"),\n    extension: None\n    );\n\n    t!(\"/foo/bar\",\n    iter: [\"/\", \"foo\", \"bar\"],\n    has_root: true,\n    is_absolute: true,\n    parent: Some(\"/foo\"),\n    file_name: Some(\"bar\"),\n    file_stem: Some(\"bar\"),\n    extension: None\n    );\n\n    t!(\"///foo///\",\n    iter: [\"/\", \"foo\"],\n    has_root: true,\n    is_absolute: true,\n    parent: Some(\"/\"),\n    file_name: Some(\"foo\"),\n    file_stem: Some(\"foo\"),\n    extension: None\n    );\n\n    t!(\"///foo///bar\",\n    iter: [\"/\", \"foo\", \"bar\"],\n    has_root: true,\n    is_absolute: true,\n    parent: Some(\"///foo\"),\n    file_name: Some(\"bar\"),\n    file_stem: Some(\"bar\"),\n    extension: None\n    );\n\n    t!(\"./.\",\n    iter: [\".\"],\n    has_root: false,\n    is_absolute: false,\n    parent: Some(\"\"),\n    file_name: None,\n    file_stem: None,\n    extension: None\n    );\n\n    t!(\"/..\",\n    iter: [\"/\", \"..\"],\n    has_root: true,\n    is_absolute: true,\n    parent: Some(\"/\"),\n    file_name: None,\n    file_stem: None,\n    extension: None\n    );\n\n    t!(\"../\",\n    iter: [\"..\"],\n    has_root: false,\n    is_absolute: false,\n    parent: Some(\"\"),\n    file_name: None,\n    file_stem: None,\n    extension: None\n    );\n\n    t!(\"foo/.\",\n    iter: [\"foo\"],\n    has_root: false,\n    is_absolute: false,\n    parent: Some(\"\"),\n    file_name: Some(\"foo\"),\n    file_stem: Some(\"foo\"),\n    extension: None\n    );\n\n    t!(\"foo/..\",\n    iter: [\"foo\", \"..\"],\n    has_root: false,\n    is_absolute: false,\n    parent: Some(\"foo\"),\n    file_name: None,\n    file_stem: None,\n    extension: None\n    );\n\n    t!(\"foo/./\",\n    iter: [\"foo\"],\n    has_root: false,\n    is_absolute: false,\n    parent: Some(\"\"),\n    file_name: Some(\"foo\"),\n    file_stem: Some(\"foo\"),\n    extension: None\n    );\n\n    t!(\"foo/./bar\",\n    iter: [\"foo\", \"bar\"],\n    has_root: false,\n    is_absolute: false,\n    parent: Some(\"foo\"),\n    file_name: Some(\"bar\"),\n    file_stem: Some(\"bar\"),\n    extension: None\n    );\n\n    t!(\"foo/../\",\n    iter: [\"foo\", \"..\"],\n    has_root: false,\n    is_absolute: false,\n    parent: Some(\"foo\"),\n    file_name: None,\n    file_stem: None,\n    extension: None\n    );\n\n    t!(\"foo/../bar\",\n    iter: [\"foo\", \"..\", \"bar\"],\n    has_root: false,\n    is_absolute: false,\n    parent: Some(\"foo/..\"),\n    file_name: Some(\"bar\"),\n    file_stem: Some(\"bar\"),\n    extension: None\n    );\n\n    t!(\"./a\",\n    iter: [\".\", \"a\"],\n    has_root: false,\n    is_absolute: false,\n    parent: Some(\".\"),\n    file_name: Some(\"a\"),\n    file_stem: Some(\"a\"),\n    extension: None\n    );\n\n    t!(\".\",\n    iter: [\".\"],\n    has_root: false,\n    is_absolute: false,\n    parent: Some(\"\"),\n    file_name: None,\n    file_stem: None,\n    extension: None\n    );\n\n    t!(\"./\",\n    iter: [\".\"],\n    has_root: false,\n    is_absolute: false,\n    parent: Some(\"\"),\n    file_name: None,\n    file_stem: None,\n    extension: None\n    );\n\n    t!(\"a/b\",\n    iter: [\"a\", \"b\"],\n    has_root: false,\n    is_absolute: false,\n    parent: Some(\"a\"),\n    file_name: Some(\"b\"),\n    file_stem: Some(\"b\"),\n    extension: None\n    );\n\n    t!(\"a//b\",\n    iter: [\"a\", \"b\"],\n    has_root: false,\n    is_absolute: false,\n    parent: Some(\"a\"),\n    file_name: Some(\"b\"),\n    file_stem: Some(\"b\"),\n    extension: None\n    );\n\n    t!(\"a/./b\",\n    iter: [\"a\", \"b\"],\n    has_root: false,\n    is_absolute: false,\n    parent: Some(\"a\"),\n    file_name: Some(\"b\"),\n    file_stem: Some(\"b\"),\n    extension: None\n    );\n\n    t!(\"a/b/c\",\n    iter: [\"a\", \"b\", \"c\"],\n    has_root: false,\n    is_absolute: false,\n    parent: Some(\"a/b\"),\n    file_name: Some(\"c\"),\n    file_stem: Some(\"c\"),\n    extension: None\n    );\n\n    t!(\".foo\",\n    iter: [\".foo\"],\n    has_root: false,\n    is_absolute: false,\n    parent: Some(\"\"),\n    file_name: Some(\".foo\"),\n    file_stem: Some(\".foo\"),\n    extension: None\n    );\n}\n\n#[test]\n#[cfg(windows)]\npub fn test_decompositions_windows() {\n    t!(\"\",\n    iter: [],\n    has_root: false,\n    is_absolute: false,\n    parent: None,\n    file_name: None,\n    file_stem: None,\n    extension: None\n    );\n\n    t!(\"foo\",\n    iter: [\"foo\"],\n    has_root: false,\n    is_absolute: false,\n    parent: Some(\"\"),\n    file_name: Some(\"foo\"),\n    file_stem: Some(\"foo\"),\n    extension: None\n    );\n\n    t!(\"/\",\n    iter: [\"\\\\\"],\n    has_root: true,\n    is_absolute: false,\n    parent: None,\n    file_name: None,\n    file_stem: None,\n    extension: None\n    );\n\n    t!(\"\\\\\",\n    iter: [\"\\\\\"],\n    has_root: true,\n    is_absolute: false,\n    parent: None,\n    file_name: None,\n    file_stem: None,\n    extension: None\n    );\n\n    t!(\"c:\",\n    iter: [\"c:\"],\n    has_root: false,\n    is_absolute: false,\n    parent: None,\n    file_name: None,\n    file_stem: None,\n    extension: None\n    );\n\n    t!(\"c:\\\\\",\n    iter: [\"c:\", \"\\\\\"],\n    has_root: true,\n    is_absolute: true,\n    parent: None,\n    file_name: None,\n    file_stem: None,\n    extension: None\n    );\n\n    t!(\"c:/\",\n    iter: [\"c:\", \"\\\\\"],\n    has_root: true,\n    is_absolute: true,\n    parent: None,\n    file_name: None,\n    file_stem: None,\n    extension: None\n    );\n\n    t!(\"/foo\",\n    iter: [\"\\\\\", \"foo\"],\n    has_root: true,\n    is_absolute: false,\n    parent: Some(\"/\"),\n    file_name: Some(\"foo\"),\n    file_stem: Some(\"foo\"),\n    extension: None\n    );\n\n    t!(\"foo/\",\n    iter: [\"foo\"],\n    has_root: false,\n    is_absolute: false,\n    parent: Some(\"\"),\n    file_name: Some(\"foo\"),\n    file_stem: Some(\"foo\"),\n    extension: None\n    );\n\n    t!(\"/foo/\",\n    iter: [\"\\\\\", \"foo\"],\n    has_root: true,\n    is_absolute: false,\n    parent: Some(\"/\"),\n    file_name: Some(\"foo\"),\n    file_stem: Some(\"foo\"),\n    extension: None\n    );\n\n    t!(\"foo/bar\",\n    iter: [\"foo\", \"bar\"],\n    has_root: false,\n    is_absolute: false,\n    parent: Some(\"foo\"),\n    file_name: Some(\"bar\"),\n    file_stem: Some(\"bar\"),\n    extension: None\n    );\n\n    t!(\"/foo/bar\",\n    iter: [\"\\\\\", \"foo\", \"bar\"],\n    has_root: true,\n    is_absolute: false,\n    parent: Some(\"/foo\"),\n    file_name: Some(\"bar\"),\n    file_stem: Some(\"bar\"),\n    extension: None\n    );\n\n    t!(\"///foo///\",\n    iter: [\"\\\\\", \"foo\"],\n    has_root: true,\n    is_absolute: false,\n    parent: Some(\"/\"),\n    file_name: Some(\"foo\"),\n    file_stem: Some(\"foo\"),\n    extension: None\n    );\n\n    t!(\"///foo///bar\",\n    iter: [\"\\\\\", \"foo\", \"bar\"],\n    has_root: true,\n    is_absolute: false,\n    parent: Some(\"///foo\"),\n    file_name: Some(\"bar\"),\n    file_stem: Some(\"bar\"),\n    extension: None\n    );\n\n    t!(\"./.\",\n    iter: [\".\"],\n    has_root: false,\n    is_absolute: false,\n    parent: Some(\"\"),\n    file_name: None,\n    file_stem: None,\n    extension: None\n    );\n\n    t!(\"/..\",\n    iter: [\"\\\\\", \"..\"],\n    has_root: true,\n    is_absolute: false,\n    parent: Some(\"/\"),\n    file_name: None,\n    file_stem: None,\n    extension: None\n    );\n\n    t!(\"../\",\n    iter: [\"..\"],\n    has_root: false,\n    is_absolute: false,\n    parent: Some(\"\"),\n    file_name: None,\n    file_stem: None,\n    extension: None\n    );\n\n    t!(\"foo/.\",\n    iter: [\"foo\"],\n    has_root: false,\n    is_absolute: false,\n    parent: Some(\"\"),\n    file_name: Some(\"foo\"),\n    file_stem: Some(\"foo\"),\n    extension: None\n    );\n\n    t!(\"foo/..\",\n    iter: [\"foo\", \"..\"],\n    has_root: false,\n    is_absolute: false,\n    parent: Some(\"foo\"),\n    file_name: None,\n    file_stem: None,\n    extension: None\n    );\n\n    t!(\"foo/./\",\n    iter: [\"foo\"],\n    has_root: false,\n    is_absolute: false,\n    parent: Some(\"\"),\n    file_name: Some(\"foo\"),\n    file_stem: Some(\"foo\"),\n    extension: None\n    );\n\n    t!(\"foo/./bar\",\n    iter: [\"foo\", \"bar\"],\n    has_root: false,\n    is_absolute: false,\n    parent: Some(\"foo\"),\n    file_name: Some(\"bar\"),\n    file_stem: Some(\"bar\"),\n    extension: None\n    );\n\n    t!(\"foo/../\",\n    iter: [\"foo\", \"..\"],\n    has_root: false,\n    is_absolute: false,\n    parent: Some(\"foo\"),\n    file_name: None,\n    file_stem: None,\n    extension: None\n    );\n\n    t!(\"foo/../bar\",\n    iter: [\"foo\", \"..\", \"bar\"],\n    has_root: false,\n    is_absolute: false,\n    parent: Some(\"foo/..\"),\n    file_name: Some(\"bar\"),\n    file_stem: Some(\"bar\"),\n    extension: None\n    );\n\n    t!(\"./a\",\n    iter: [\".\", \"a\"],\n    has_root: false,\n    is_absolute: false,\n    parent: Some(\".\"),\n    file_name: Some(\"a\"),\n    file_stem: Some(\"a\"),\n    extension: None\n    );\n\n    t!(\".\",\n    iter: [\".\"],\n    has_root: false,\n    is_absolute: false,\n    parent: Some(\"\"),\n    file_name: None,\n    file_stem: None,\n    extension: None\n    );\n\n    t!(\"./\",\n    iter: [\".\"],\n    has_root: false,\n    is_absolute: false,\n    parent: Some(\"\"),\n    file_name: None,\n    file_stem: None,\n    extension: None\n    );\n\n    t!(\"a/b\",\n    iter: [\"a\", \"b\"],\n    has_root: false,\n    is_absolute: false,\n    parent: Some(\"a\"),\n    file_name: Some(\"b\"),\n    file_stem: Some(\"b\"),\n    extension: None\n    );\n\n    t!(\"a//b\",\n    iter: [\"a\", \"b\"],\n    has_root: false,\n    is_absolute: false,\n    parent: Some(\"a\"),\n    file_name: Some(\"b\"),\n    file_stem: Some(\"b\"),\n    extension: None\n    );\n\n    t!(\"a/./b\",\n    iter: [\"a\", \"b\"],\n    has_root: false,\n    is_absolute: false,\n    parent: Some(\"a\"),\n    file_name: Some(\"b\"),\n    file_stem: Some(\"b\"),\n    extension: None\n    );\n\n    t!(\"a/b/c\",\n       iter: [\"a\", \"b\", \"c\"],\n       has_root: false,\n       is_absolute: false,\n       parent: Some(\"a/b\"),\n       file_name: Some(\"c\"),\n       file_stem: Some(\"c\"),\n       extension: None);\n\n    t!(\"a\\\\b\\\\c\",\n    iter: [\"a\", \"b\", \"c\"],\n    has_root: false,\n    is_absolute: false,\n    parent: Some(\"a\\\\b\"),\n    file_name: Some(\"c\"),\n    file_stem: Some(\"c\"),\n    extension: None\n    );\n\n    t!(\"\\\\a\",\n    iter: [\"\\\\\", \"a\"],\n    has_root: true,\n    is_absolute: false,\n    parent: Some(\"\\\\\"),\n    file_name: Some(\"a\"),\n    file_stem: Some(\"a\"),\n    extension: None\n    );\n\n    t!(\"c:\\\\foo.txt\",\n    iter: [\"c:\", \"\\\\\", \"foo.txt\"],\n    has_root: true,\n    is_absolute: true,\n    parent: Some(\"c:\\\\\"),\n    file_name: Some(\"foo.txt\"),\n    file_stem: Some(\"foo\"),\n    extension: Some(\"txt\")\n    );\n\n    t!(\"\\\\\\\\server\\\\share\\\\foo.txt\",\n    iter: [\"\\\\\\\\server\\\\share\", \"\\\\\", \"foo.txt\"],\n    has_root: true,\n    is_absolute: true,\n    parent: Some(\"\\\\\\\\server\\\\share\\\\\"),\n    file_name: Some(\"foo.txt\"),\n    file_stem: Some(\"foo\"),\n    extension: Some(\"txt\")\n    );\n\n    t!(\"\\\\\\\\server\\\\share\",\n    iter: [\"\\\\\\\\server\\\\share\", \"\\\\\"],\n    has_root: true,\n    is_absolute: true,\n    parent: None,\n    file_name: None,\n    file_stem: None,\n    extension: None\n    );\n\n    t!(\"\\\\\\\\server\",\n    iter: [\"\\\\\", \"server\"],\n    has_root: true,\n    is_absolute: false,\n    parent: Some(\"\\\\\"),\n    file_name: Some(\"server\"),\n    file_stem: Some(\"server\"),\n    extension: None\n    );\n\n    t!(\"\\\\\\\\?\\\\bar\\\\foo.txt\",\n    iter: [\"\\\\\\\\?\\\\bar\", \"\\\\\", \"foo.txt\"],\n    has_root: true,\n    is_absolute: true,\n    parent: Some(\"\\\\\\\\?\\\\bar\\\\\"),\n    file_name: Some(\"foo.txt\"),\n    file_stem: Some(\"foo\"),\n    extension: Some(\"txt\")\n    );\n\n    t!(\"\\\\\\\\?\\\\bar\",\n    iter: [\"\\\\\\\\?\\\\bar\"],\n    has_root: true,\n    is_absolute: true,\n    parent: None,\n    file_name: None,\n    file_stem: None,\n    extension: None\n    );\n\n    t!(\"\\\\\\\\?\\\\\",\n    iter: [\"\\\\\\\\?\\\\\"],\n    has_root: true,\n    is_absolute: true,\n    parent: None,\n    file_name: None,\n    file_stem: None,\n    extension: None\n    );\n\n    t!(\"\\\\\\\\?\\\\UNC\\\\server\\\\share\\\\foo.txt\",\n    iter: [\"\\\\\\\\?\\\\UNC\\\\server\\\\share\", \"\\\\\", \"foo.txt\"],\n    has_root: true,\n    is_absolute: true,\n    parent: Some(\"\\\\\\\\?\\\\UNC\\\\server\\\\share\\\\\"),\n    file_name: Some(\"foo.txt\"),\n    file_stem: Some(\"foo\"),\n    extension: Some(\"txt\")\n    );\n\n    t!(\"\\\\\\\\?\\\\UNC\\\\server\",\n    iter: [\"\\\\\\\\?\\\\UNC\\\\server\"],\n    has_root: true,\n    is_absolute: true,\n    parent: None,\n    file_name: None,\n    file_stem: None,\n    extension: None\n    );\n\n    t!(\"\\\\\\\\?\\\\UNC\\\\\",\n    iter: [\"\\\\\\\\?\\\\UNC\\\\\"],\n    has_root: true,\n    is_absolute: true,\n    parent: None,\n    file_name: None,\n    file_stem: None,\n    extension: None\n    );\n\n    t!(\"\\\\\\\\?\\\\C:\\\\foo.txt\",\n    iter: [\"\\\\\\\\?\\\\C:\", \"\\\\\", \"foo.txt\"],\n    has_root: true,\n    is_absolute: true,\n    parent: Some(\"\\\\\\\\?\\\\C:\\\\\"),\n    file_name: Some(\"foo.txt\"),\n    file_stem: Some(\"foo\"),\n    extension: Some(\"txt\")\n    );\n\n    t!(\"\\\\\\\\?\\\\C:\\\\\",\n    iter: [\"\\\\\\\\?\\\\C:\", \"\\\\\"],\n    has_root: true,\n    is_absolute: true,\n    parent: None,\n    file_name: None,\n    file_stem: None,\n    extension: None\n    );\n\n    t!(\"\\\\\\\\?\\\\C:\",\n    iter: [\"\\\\\\\\?\\\\C:\"],\n    has_root: true,\n    is_absolute: true,\n    parent: None,\n    file_name: None,\n    file_stem: None,\n    extension: None\n    );\n\n    t!(\"\\\\\\\\?\\\\foo/bar\",\n    iter: [\"\\\\\\\\?\\\\foo/bar\"],\n    has_root: true,\n    is_absolute: true,\n    parent: None,\n    file_name: None,\n    file_stem: None,\n    extension: None\n    );\n\n    t!(\"\\\\\\\\?\\\\C:/foo\",\n    iter: [\"\\\\\\\\?\\\\C:/foo\"],\n    has_root: true,\n    is_absolute: true,\n    parent: None,\n    file_name: None,\n    file_stem: None,\n    extension: None\n    );\n\n    t!(\"\\\\\\\\.\\\\foo\\\\bar\",\n    iter: [\"\\\\\\\\.\\\\foo\", \"\\\\\", \"bar\"],\n    has_root: true,\n    is_absolute: true,\n    parent: Some(\"\\\\\\\\.\\\\foo\\\\\"),\n    file_name: Some(\"bar\"),\n    file_stem: Some(\"bar\"),\n    extension: None\n    );\n\n    t!(\"\\\\\\\\.\\\\foo\",\n    iter: [\"\\\\\\\\.\\\\foo\", \"\\\\\"],\n    has_root: true,\n    is_absolute: true,\n    parent: None,\n    file_name: None,\n    file_stem: None,\n    extension: None\n    );\n\n    t!(\"\\\\\\\\.\\\\foo/bar\",\n    iter: [\"\\\\\\\\.\\\\foo\", \"\\\\\", \"bar\"],\n    has_root: true,\n    is_absolute: true,\n    parent: Some(\"\\\\\\\\.\\\\foo/\"),\n    file_name: Some(\"bar\"),\n    file_stem: Some(\"bar\"),\n    extension: None\n    );\n\n    t!(\"\\\\\\\\.\\\\foo\\\\bar/baz\",\n    iter: [\"\\\\\\\\.\\\\foo\", \"\\\\\", \"bar\", \"baz\"],\n    has_root: true,\n    is_absolute: true,\n    parent: Some(\"\\\\\\\\.\\\\foo\\\\bar\"),\n    file_name: Some(\"baz\"),\n    file_stem: Some(\"baz\"),\n    extension: None\n    );\n\n    t!(\"\\\\\\\\.\\\\\",\n    iter: [\"\\\\\\\\.\\\\\", \"\\\\\"],\n    has_root: true,\n    is_absolute: true,\n    parent: None,\n    file_name: None,\n    file_stem: None,\n    extension: None\n    );\n\n    t!(\"\\\\\\\\?\\\\a\\\\b\\\\\",\n    iter: [\"\\\\\\\\?\\\\a\", \"\\\\\", \"b\"],\n    has_root: true,\n    is_absolute: true,\n    parent: Some(\"\\\\\\\\?\\\\a\\\\\"),\n    file_name: Some(\"b\"),\n    file_stem: Some(\"b\"),\n    extension: None\n    );\n}\n\n#[test]\npub fn test_stem_ext() {\n    t!(\"foo\",\n    file_stem: Some(\"foo\"),\n    extension: None\n    );\n\n    t!(\"foo.\",\n    file_stem: Some(\"foo\"),\n    extension: Some(\"\")\n    );\n\n    t!(\".foo\",\n    file_stem: Some(\".foo\"),\n    extension: None\n    );\n\n    t!(\"foo.txt\",\n    file_stem: Some(\"foo\"),\n    extension: Some(\"txt\")\n    );\n\n    t!(\"foo.bar.txt\",\n    file_stem: Some(\"foo.bar\"),\n    extension: Some(\"txt\")\n    );\n\n    t!(\"foo.bar.\",\n    file_stem: Some(\"foo.bar\"),\n    extension: Some(\"\")\n    );\n\n    t!(\".\", file_stem: None, extension: None);\n\n    t!(\"..\", file_stem: None, extension: None);\n\n    t!(\"\", file_stem: None, extension: None);\n}\n\n#[test]\npub fn test_push() {\n    macro_rules! tp(\n        ($path:expr, $push:expr, $expected:expr) => ( {\n            let mut actual = PathBuf::from($path);\n            actual.push($push);\n            assert!(actual.to_str() == Some($expected),\n                    \"pushing {:?} onto {:?}: Expected {:?}, got {:?}\",\n                    $push, $path, $expected, actual.to_str().unwrap());\n        });\n    );\n\n    if cfg!(unix) || cfg!(all(target_env = \"sgx\", target_vendor = \"fortanix\")) {\n        tp!(\"\", \"foo\", \"foo\");\n        tp!(\"foo\", \"bar\", \"foo/bar\");\n        tp!(\"foo/\", \"bar\", \"foo/bar\");\n        tp!(\"foo//\", \"bar\", \"foo//bar\");\n        tp!(\"foo/.\", \"bar\", \"foo/./bar\");\n        tp!(\"foo./.\", \"bar\", \"foo././bar\");\n        tp!(\"foo\", \"\", \"foo/\");\n        tp!(\"foo\", \".\", \"foo/.\");\n        tp!(\"foo\", \"..\", \"foo/..\");\n        tp!(\"foo\", \"/\", \"/\");\n        tp!(\"/foo/bar\", \"/\", \"/\");\n        tp!(\"/foo/bar\", \"/baz\", \"/baz\");\n        tp!(\"/foo/bar\", \"./baz\", \"/foo/bar/./baz\");\n    } else {\n        tp!(\"\", \"foo\", \"foo\");\n        tp!(\"foo\", \"bar\", r\"foo\\bar\");\n        tp!(\"foo/\", \"bar\", r\"foo/bar\");\n        tp!(r\"foo\\\", \"bar\", r\"foo\\bar\");\n        tp!(\"foo//\", \"bar\", r\"foo//bar\");\n        tp!(r\"foo\\\\\", \"bar\", r\"foo\\\\bar\");\n        tp!(\"foo/.\", \"bar\", r\"foo/.\\bar\");\n        tp!(\"foo./.\", \"bar\", r\"foo./.\\bar\");\n        tp!(r\"foo\\.\", \"bar\", r\"foo\\.\\bar\");\n        tp!(r\"foo.\\.\", \"bar\", r\"foo.\\.\\bar\");\n        tp!(\"foo\", \"\", \"foo\\\\\");\n        tp!(\"foo\", \".\", r\"foo\\.\");\n        tp!(\"foo\", \"..\", r\"foo\\..\");\n        tp!(\"foo\", \"/\", \"/\");\n        tp!(\"foo\", r\"\\\", r\"\\\");\n        tp!(\"/foo/bar\", \"/\", \"/\");\n        tp!(r\"\\foo\\bar\", r\"\\\", r\"\\\");\n        tp!(\"/foo/bar\", \"/baz\", \"/baz\");\n        tp!(\"/foo/bar\", r\"\\baz\", r\"\\baz\");\n        tp!(\"/foo/bar\", \"./baz\", r\"/foo/bar\\./baz\");\n        tp!(\"/foo/bar\", r\".\\baz\", r\"/foo/bar\\.\\baz\");\n\n        tp!(\"c:\\\\\", \"windows\", \"c:\\\\windows\");\n        tp!(\"c:\", \"windows\", \"c:windows\");\n\n        tp!(\"a\\\\b\\\\c\", \"d\", \"a\\\\b\\\\c\\\\d\");\n        tp!(\"\\\\a\\\\b\\\\c\", \"d\", \"\\\\a\\\\b\\\\c\\\\d\");\n        tp!(\"a\\\\b\", \"c\\\\d\", \"a\\\\b\\\\c\\\\d\");\n        tp!(\"a\\\\b\", \"\\\\c\\\\d\", \"\\\\c\\\\d\");\n        tp!(\"a\\\\b\", \".\", \"a\\\\b\\\\.\");\n        tp!(\"a\\\\b\", \"..\\\\c\", \"a\\\\b\\\\..\\\\c\");\n        tp!(\"a\\\\b\", \"C:a.txt\", \"C:a.txt\");\n        tp!(\"a\\\\b\", \"C:\\\\a.txt\", \"C:\\\\a.txt\");\n        tp!(\"C:\\\\a\", \"C:\\\\b.txt\", \"C:\\\\b.txt\");\n        tp!(\"C:\\\\a\\\\b\\\\c\", \"C:d\", \"C:d\");\n        tp!(\"C:a\\\\b\\\\c\", \"C:d\", \"C:d\");\n        tp!(\"C:\", r\"a\\b\\c\", r\"C:a\\b\\c\");\n        tp!(\"C:\", r\"..\\a\", r\"C:..\\a\");\n        tp!(\"\\\\\\\\server\\\\share\\\\foo\", \"bar\", \"\\\\\\\\server\\\\share\\\\foo\\\\bar\");\n        tp!(\"\\\\\\\\server\\\\share\\\\foo\", \"C:baz\", \"C:baz\");\n        tp!(\"\\\\\\\\?\\\\C:\\\\a\\\\b\", \"C:c\\\\d\", \"C:c\\\\d\");\n        tp!(\"\\\\\\\\?\\\\C:a\\\\b\", \"C:c\\\\d\", \"C:c\\\\d\");\n        tp!(\"\\\\\\\\?\\\\C:\\\\a\\\\b\", \"C:\\\\c\\\\d\", \"C:\\\\c\\\\d\");\n        tp!(\"\\\\\\\\?\\\\foo\\\\bar\", \"baz\", \"\\\\\\\\?\\\\foo\\\\bar\\\\baz\");\n        tp!(\"\\\\\\\\?\\\\UNC\\\\server\\\\share\\\\foo\", \"bar\", \"\\\\\\\\?\\\\UNC\\\\server\\\\share\\\\foo\\\\bar\");\n        tp!(\"\\\\\\\\?\\\\UNC\\\\server\\\\share\", \"C:\\\\a\", \"C:\\\\a\");\n        tp!(\"\\\\\\\\?\\\\UNC\\\\server\\\\share\", \"C:a\", \"C:a\");\n\n        // Note: modified from old path API\n        tp!(\"\\\\\\\\?\\\\UNC\\\\server\", \"foo\", \"\\\\\\\\?\\\\UNC\\\\server\\\\foo\");\n\n        tp!(\"C:\\\\a\", \"\\\\\\\\?\\\\UNC\\\\server\\\\share\", \"\\\\\\\\?\\\\UNC\\\\server\\\\share\");\n        tp!(\"\\\\\\\\.\\\\foo\\\\bar\", \"baz\", \"\\\\\\\\.\\\\foo\\\\bar\\\\baz\");\n        tp!(\"\\\\\\\\.\\\\foo\\\\bar\", \"C:a\", \"C:a\");\n        // again, not sure about the following, but I'm assuming \\\\.\\ should be verbatim\n        tp!(\"\\\\\\\\.\\\\foo\", \"..\\\\bar\", \"\\\\\\\\.\\\\foo\\\\..\\\\bar\");\n\n        tp!(\"\\\\\\\\?\\\\C:\", \"foo\", \"\\\\\\\\?\\\\C:\\\\foo\"); // this is a weird one\n    }\n}\n\n#[test]\npub fn test_pop() {\n    macro_rules! tp(\n        ($path:expr, $expected:expr, $output:expr) => ( {\n            let mut actual = PathBuf::from($path);\n            let output = actual.pop();\n            assert!(actual.to_str() == Some($expected) && output == $output,\n                    \"popping from {:?}: Expected {:?}/{:?}, got {:?}/{:?}\",\n                    $path, $expected, $output,\n                    actual.to_str().unwrap(), output);\n        });\n    );\n\n    tp!(\"\", \"\", false);\n    tp!(\"/\", \"/\", false);\n    tp!(\"foo\", \"\", true);\n    tp!(\".\", \"\", true);\n    tp!(\"/foo\", \"/\", true);\n    tp!(\"/foo/bar\", \"/foo\", true);\n    tp!(\"foo/bar\", \"foo\", true);\n    tp!(\"foo/.\", \"\", true);\n    tp!(\"foo//bar\", \"foo\", true);\n\n    if cfg!(windows) {\n        tp!(\"a\\\\b\\\\c\", \"a\\\\b\", true);\n        tp!(\"\\\\a\", \"\\\\\", true);\n        tp!(\"\\\\\", \"\\\\\", false);\n\n        tp!(\"C:\\\\a\\\\b\", \"C:\\\\a\", true);\n        tp!(\"C:\\\\a\", \"C:\\\\\", true);\n        tp!(\"C:\\\\\", \"C:\\\\\", false);\n        tp!(\"C:a\\\\b\", \"C:a\", true);\n        tp!(\"C:a\", \"C:\", true);\n        tp!(\"C:\", \"C:\", false);\n        tp!(\"\\\\\\\\server\\\\share\\\\a\\\\b\", \"\\\\\\\\server\\\\share\\\\a\", true);\n        tp!(\"\\\\\\\\server\\\\share\\\\a\", \"\\\\\\\\server\\\\share\\\\\", true);\n        tp!(\"\\\\\\\\server\\\\share\", \"\\\\\\\\server\\\\share\", false);\n        tp!(\"\\\\\\\\?\\\\a\\\\b\\\\c\", \"\\\\\\\\?\\\\a\\\\b\", true);\n        tp!(\"\\\\\\\\?\\\\a\\\\b\", \"\\\\\\\\?\\\\a\\\\\", true);\n        tp!(\"\\\\\\\\?\\\\a\", \"\\\\\\\\?\\\\a\", false);\n        tp!(\"\\\\\\\\?\\\\C:\\\\a\\\\b\", \"\\\\\\\\?\\\\C:\\\\a\", true);\n        tp!(\"\\\\\\\\?\\\\C:\\\\a\", \"\\\\\\\\?\\\\C:\\\\\", true);\n        tp!(\"\\\\\\\\?\\\\C:\\\\\", \"\\\\\\\\?\\\\C:\\\\\", false);\n        tp!(\"\\\\\\\\?\\\\UNC\\\\server\\\\share\\\\a\\\\b\", \"\\\\\\\\?\\\\UNC\\\\server\\\\share\\\\a\", true);\n        tp!(\"\\\\\\\\?\\\\UNC\\\\server\\\\share\\\\a\", \"\\\\\\\\?\\\\UNC\\\\server\\\\share\\\\\", true);\n        tp!(\"\\\\\\\\?\\\\UNC\\\\server\\\\share\", \"\\\\\\\\?\\\\UNC\\\\server\\\\share\", false);\n        tp!(\"\\\\\\\\.\\\\a\\\\b\\\\c\", \"\\\\\\\\.\\\\a\\\\b\", true);\n        tp!(\"\\\\\\\\.\\\\a\\\\b\", \"\\\\\\\\.\\\\a\\\\\", true);\n        tp!(\"\\\\\\\\.\\\\a\", \"\\\\\\\\.\\\\a\", false);\n\n        tp!(\"\\\\\\\\?\\\\a\\\\b\\\\\", \"\\\\\\\\?\\\\a\\\\\", true);\n    }\n}\n\n#[test]\npub fn test_set_file_name() {\n    macro_rules! tfn(\n            ($path:expr, $file:expr, $expected:expr) => ( {\n            let mut p = PathBuf::from($path);\n            p.set_file_name($file);\n            assert!(p.to_str() == Some($expected),\n                    \"setting file name of {:?} to {:?}: Expected {:?}, got {:?}\",\n                    $path, $file, $expected,\n                    p.to_str().unwrap());\n        });\n    );\n\n    tfn!(\"foo\", \"foo\", \"foo\");\n    tfn!(\"foo\", \"bar\", \"bar\");\n    tfn!(\"foo\", \"\", \"\");\n    tfn!(\"\", \"foo\", \"foo\");\n    if cfg!(unix) || cfg!(all(target_env = \"sgx\", target_vendor = \"fortanix\")) {\n        tfn!(\".\", \"foo\", \"./foo\");\n        tfn!(\"foo/\", \"bar\", \"bar\");\n        tfn!(\"foo/.\", \"bar\", \"bar\");\n        tfn!(\"..\", \"foo\", \"../foo\");\n        tfn!(\"foo/..\", \"bar\", \"foo/../bar\");\n        tfn!(\"/\", \"foo\", \"/foo\");\n    } else {\n        tfn!(\".\", \"foo\", r\".\\foo\");\n        tfn!(r\"foo\\\", \"bar\", r\"bar\");\n        tfn!(r\"foo\\.\", \"bar\", r\"bar\");\n        tfn!(\"..\", \"foo\", r\"..\\foo\");\n        tfn!(r\"foo\\..\", \"bar\", r\"foo\\..\\bar\");\n        tfn!(r\"\\\", \"foo\", r\"\\foo\");\n    }\n}\n\n#[test]\npub fn test_set_extension() {\n    macro_rules! tfe(\n            ($path:expr, $ext:expr, $expected:expr, $output:expr) => ( {\n            let mut p = PathBuf::from($path);\n            let output = p.set_extension($ext);\n            assert!(p.to_str() == Some($expected) && output == $output,\n                    \"setting extension of {:?} to {:?}: Expected {:?}/{:?}, got {:?}/{:?}\",\n                    $path, $ext, $expected, $output,\n                    p.to_str().unwrap(), output);\n        });\n    );\n\n    tfe!(\"foo\", \"txt\", \"foo.txt\", true);\n    tfe!(\"foo.bar\", \"txt\", \"foo.txt\", true);\n    tfe!(\"foo.bar.baz\", \"txt\", \"foo.bar.txt\", true);\n    tfe!(\".test\", \"txt\", \".test.txt\", true);\n    tfe!(\"foo.txt\", \"\", \"foo\", true);\n    tfe!(\"foo\", \"\", \"foo\", true);\n    tfe!(\"\", \"foo\", \"\", false);\n    tfe!(\".\", \"foo\", \".\", false);\n    tfe!(\"foo/\", \"bar\", \"foo.bar\", true);\n    tfe!(\"foo/.\", \"bar\", \"foo.bar\", true);\n    tfe!(\"..\", \"foo\", \"..\", false);\n    tfe!(\"foo/..\", \"bar\", \"foo/..\", false);\n    tfe!(\"/\", \"foo\", \"/\", false);\n}\n\n#[test]\nfn test_eq_receivers() {\n    use crate::borrow::Cow;\n\n    let borrowed: &Path = Path::new(\"foo/bar\");\n    let mut owned: PathBuf = PathBuf::new();\n    owned.push(\"foo\");\n    owned.push(\"bar\");\n    let borrowed_cow: Cow<'_, Path> = borrowed.into();\n    let owned_cow: Cow<'_, Path> = owned.clone().into();\n\n    macro_rules! t {\n        ($($current:expr),+) => {\n            $(\n                assert_eq!($current, borrowed);\n                assert_eq!($current, owned);\n                assert_eq!($current, borrowed_cow);\n                assert_eq!($current, owned_cow);\n            )+\n        }\n    }\n\n    t!(borrowed, owned, borrowed_cow, owned_cow);\n}\n\n#[test]\npub fn test_compare() {\n    use crate::collections::hash_map::DefaultHasher;\n    use crate::hash::{Hash, Hasher};\n\n    fn hash<T: Hash>(t: T) -> u64 {\n        let mut s = DefaultHasher::new();\n        t.hash(&mut s);\n        s.finish()\n    }\n\n    macro_rules! tc(\n        ($path1:expr, $path2:expr, eq: $eq:expr,\n         starts_with: $starts_with:expr, ends_with: $ends_with:expr,\n         relative_from: $relative_from:expr) => ({\n             let path1 = Path::new($path1);\n             let path2 = Path::new($path2);\n\n             let eq = path1 == path2;\n             assert!(eq == $eq, \"{:?} == {:?}, expected {:?}, got {:?}\",\n                     $path1, $path2, $eq, eq);\n             assert!($eq == (hash(path1) == hash(path2)),\n                     \"{:?} == {:?}, expected {:?}, got {} and {}\",\n                     $path1, $path2, $eq, hash(path1), hash(path2));\n\n             let starts_with = path1.starts_with(path2);\n             assert!(starts_with == $starts_with,\n                     \"{:?}.starts_with({:?}), expected {:?}, got {:?}\", $path1, $path2,\n                     $starts_with, starts_with);\n\n             let ends_with = path1.ends_with(path2);\n             assert!(ends_with == $ends_with,\n                     \"{:?}.ends_with({:?}), expected {:?}, got {:?}\", $path1, $path2,\n                     $ends_with, ends_with);\n\n             let relative_from = path1.strip_prefix(path2)\n                                      .map(|p| p.to_str().unwrap())\n                                      .ok();\n             let exp: Option<&str> = $relative_from;\n             assert!(relative_from == exp,\n                     \"{:?}.strip_prefix({:?}), expected {:?}, got {:?}\",\n                     $path1, $path2, exp, relative_from);\n        });\n    );\n\n    tc!(\"\", \"\",\n    eq: true,\n    starts_with: true,\n    ends_with: true,\n    relative_from: Some(\"\")\n    );\n\n    tc!(\"foo\", \"\",\n    eq: false,\n    starts_with: true,\n    ends_with: true,\n    relative_from: Some(\"foo\")\n    );\n\n    tc!(\"\", \"foo\",\n    eq: false,\n    starts_with: false,\n    ends_with: false,\n    relative_from: None\n    );\n\n    tc!(\"foo\", \"foo\",\n    eq: true,\n    starts_with: true,\n    ends_with: true,\n    relative_from: Some(\"\")\n    );\n\n    tc!(\"foo/\", \"foo\",\n    eq: true,\n    starts_with: true,\n    ends_with: true,\n    relative_from: Some(\"\")\n    );\n\n    tc!(\"foo/bar\", \"foo\",\n    eq: false,\n    starts_with: true,\n    ends_with: false,\n    relative_from: Some(\"bar\")\n    );\n\n    tc!(\"foo/bar/baz\", \"foo/bar\",\n    eq: false,\n    starts_with: true,\n    ends_with: false,\n    relative_from: Some(\"baz\")\n    );\n\n    tc!(\"foo/bar\", \"foo/bar/baz\",\n    eq: false,\n    starts_with: false,\n    ends_with: false,\n    relative_from: None\n    );\n\n    tc!(\"./foo/bar/\", \".\",\n    eq: false,\n    starts_with: true,\n    ends_with: false,\n    relative_from: Some(\"foo/bar\")\n    );\n\n    if cfg!(windows) {\n        tc!(r\"C:\\src\\rust\\cargo-test\\test\\Cargo.toml\",\n        r\"c:\\src\\rust\\cargo-test\\test\",\n        eq: false,\n        starts_with: true,\n        ends_with: false,\n        relative_from: Some(\"Cargo.toml\")\n        );\n\n        tc!(r\"c:\\foo\", r\"C:\\foo\",\n        eq: true,\n        starts_with: true,\n        ends_with: true,\n        relative_from: Some(\"\")\n        );\n    }\n}\n\n#[test]\nfn test_components_debug() {\n    let path = Path::new(\"/tmp\");\n\n    let mut components = path.components();\n\n    let expected = \"Components([RootDir, Normal(\\\"tmp\\\")])\";\n    let actual = format!(\"{:?}\", components);\n    assert_eq!(expected, actual);\n\n    let _ = components.next().unwrap();\n    let expected = \"Components([Normal(\\\"tmp\\\")])\";\n    let actual = format!(\"{:?}\", components);\n    assert_eq!(expected, actual);\n\n    let _ = components.next().unwrap();\n    let expected = \"Components([])\";\n    let actual = format!(\"{:?}\", components);\n    assert_eq!(expected, actual);\n}\n\n#[cfg(unix)]\n#[test]\nfn test_iter_debug() {\n    let path = Path::new(\"/tmp\");\n\n    let mut iter = path.iter();\n\n    let expected = \"Iter([\\\"/\\\", \\\"tmp\\\"])\";\n    let actual = format!(\"{:?}\", iter);\n    assert_eq!(expected, actual);\n\n    let _ = iter.next().unwrap();\n    let expected = \"Iter([\\\"tmp\\\"])\";\n    let actual = format!(\"{:?}\", iter);\n    assert_eq!(expected, actual);\n\n    let _ = iter.next().unwrap();\n    let expected = \"Iter([])\";\n    let actual = format!(\"{:?}\", iter);\n    assert_eq!(expected, actual);\n}\n\n#[test]\nfn into_boxed() {\n    let orig: &str = \"some/sort/of/path\";\n    let path = Path::new(orig);\n    let boxed: Box<Path> = Box::from(path);\n    let path_buf = path.to_owned().into_boxed_path().into_path_buf();\n    assert_eq!(path, &*boxed);\n    assert_eq!(&*boxed, &*path_buf);\n    assert_eq!(&*path_buf, path);\n}\n\n#[test]\nfn test_clone_into() {\n    let mut path_buf = PathBuf::from(\"supercalifragilisticexpialidocious\");\n    let path = Path::new(\"short\");\n    path.clone_into(&mut path_buf);\n    assert_eq!(path, path_buf);\n    assert!(path_buf.into_os_string().capacity() >= 15);\n}\n\n#[test]\nfn display_format_flags() {\n    assert_eq!(format!(\"a{:#<5}b\", Path::new(\"\").display()), \"a#####b\");\n    assert_eq!(format!(\"a{:#<5}b\", Path::new(\"a\").display()), \"aa####b\");\n}\n\n#[test]\nfn into_rc() {\n    let orig = \"hello/world\";\n    let path = Path::new(orig);\n    let rc: Rc<Path> = Rc::from(path);\n    let arc: Arc<Path> = Arc::from(path);\n\n    assert_eq!(&*rc, path);\n    assert_eq!(&*arc, path);\n\n    let rc2: Rc<Path> = Rc::from(path.to_owned());\n    let arc2: Arc<Path> = Arc::from(path.to_owned());\n\n    assert_eq!(&*rc2, path);\n    assert_eq!(&*arc2, path);\n}\n"],[2222,"//! Traits for working with Errors.\n\n#![stable(feature = \"rust1\", since = \"1.0.0\")]\n\n// A note about crates and the facade:\n//\n// Originally, the `Error` trait was defined in libcore, and the impls\n// were scattered about. However, coherence objected to this\n// arrangement, because to create the blanket impls for `Box` required\n// knowing that `&str: !Error`, and we have no means to deal with that\n// sort of conflict just now. Therefore, for the time being, we have\n// moved the `Error` trait into libstd. As we evolve a sol'n to the\n// coherence challenge (e.g., specialization, neg impls, etc) we can\n// reconsider what crate these items belong in.\n\n#[cfg(test)]\nmod tests;\n\nuse core::array;\nuse core::convert::Infallible;\n\nuse crate::alloc::{AllocError, LayoutError};\nuse crate::any::TypeId;\nuse crate::backtrace::Backtrace;\nuse crate::borrow::Cow;\nuse crate::cell;\nuse crate::char;\nuse crate::fmt::{self, Debug, Display};\nuse crate::mem::transmute;\nuse crate::num;\nuse crate::str;\nuse crate::string;\nuse crate::sync::Arc;\n\n/// `Error` is a trait representing the basic expectations for error values,\n/// i.e., values of type `E` in [`Result<T, E>`].\n///\n/// Errors must describe themselves through the [`Display`] and [`Debug`]\n/// traits. Error messages are typically concise lowercase sentences without\n/// trailing punctuation:\n///\n/// ```\n/// let err = \"NaN\".parse::<u32>().unwrap_err();\n/// assert_eq!(err.to_string(), \"invalid digit found in string\");\n/// ```\n///\n/// Errors may provide cause chain information. [`Error::source()`] is generally\n/// used when errors cross \"abstraction boundaries\". If one module must report\n/// an error that is caused by an error from a lower-level module, it can allow\n/// accessing that error via [`Error::source()`]. This makes it possible for the\n/// high-level module to provide its own errors while also revealing some of the\n/// implementation for debugging via `source` chains.\n#[stable(feature = \"rust1\", since = \"1.0.0\")]\npub trait Error: Debug + Display {\n    /// The lower-level source of this error, if any.\n    ///\n    /// # Examples\n    ///\n    /// ```\n    /// use std::error::Error;\n    /// use std::fmt;\n    ///\n    /// #[derive(Debug)]\n    /// struct SuperError {\n    ///     side: SuperErrorSideKick,\n    /// }\n    ///\n    /// impl fmt::Display for SuperError {\n    ///     fn fmt(&self, f: &mut fmt::Formatter<'_>) -> fmt::Result {\n    ///         write!(f, \"SuperError is here!\")\n    ///     }\n    /// }\n    ///\n    /// impl Error for SuperError {\n    ///     fn source(&self) -> Option<&(dyn Error + 'static)> {\n    ///         Some(&self.side)\n    ///     }\n    /// }\n    ///\n    /// #[derive(Debug)]\n    /// struct SuperErrorSideKick;\n    ///\n    /// impl fmt::Display for SuperErrorSideKick {\n    ///     fn fmt(&self, f: &mut fmt::Formatter<'_>) -> fmt::Result {\n    ///         write!(f, \"SuperErrorSideKick is here!\")\n    ///     }\n    /// }\n    ///\n    /// impl Error for SuperErrorSideKick {}\n    ///\n    /// fn get_super_error() -> Result<(), SuperError> {\n    ///     Err(SuperError { side: SuperErrorSideKick })\n    /// }\n    ///\n    /// fn main() {\n    ///     match get_super_error() {\n    ///         Err(e) => {\n    ///             println!(\"Error: {}\", e);\n    ///             println!(\"Caused by: {}\", e.source().unwrap());\n    ///         }\n    ///         _ => println!(\"No error\"),\n    ///     }\n    /// }\n    /// ```\n    #[stable(feature = \"error_source\", since = \"1.30.0\")]\n    fn source(&self) -> Option<&(dyn Error + 'static)> {\n        None\n    }\n\n    /// Gets the `TypeId` of `self`.\n    #[doc(hidden)]\n    #[unstable(\n        feature = \"error_type_id\",\n        reason = \"this is memory-unsafe to override in user code\",\n        issue = \"60784\"\n    )]\n    fn type_id(&self, _: private::Internal) -> TypeId\n    where\n        Self: 'static,\n    {\n        TypeId::of::<Self>()\n    }\n\n    /// Returns a stack backtrace, if available, of where this error occurred.\n    ///\n    /// This function allows inspecting the location, in code, of where an error\n    /// happened. The returned `Backtrace` contains information about the stack\n    /// trace of the OS thread of execution of where the error originated from.\n    ///\n    /// Note that not all errors contain a `Backtrace`. Also note that a\n    /// `Backtrace` may actually be empty. For more information consult the\n    /// `Backtrace` type itself.\n    #[unstable(feature = \"backtrace\", issue = \"53487\")]\n    fn backtrace(&self) -> Option<&Backtrace> {\n        None\n    }\n\n    /// ```\n    /// if let Err(e) = \"xc\".parse::<u32>() {\n    ///     // Print `e` itself, no need for description().\n    ///     eprintln!(\"Error: {}\", e);\n    /// }\n    /// ```\n    #[stable(feature = \"rust1\", since = \"1.0.0\")]\n    #[rustc_deprecated(since = \"1.42.0\", reason = \"use the Display impl or to_string()\")]\n    fn description(&self) -> &str {\n        \"description() is deprecated; use Display\"\n    }\n\n    #[stable(feature = \"rust1\", since = \"1.0.0\")]\n    #[rustc_deprecated(\n        since = \"1.33.0\",\n        reason = \"replaced by Error::source, which can support downcasting\"\n    )]\n    #[allow(missing_docs)]\n    fn cause(&self) -> Option<&dyn Error> {\n        self.source()\n    }\n}\n\nmod private {\n    // This is a hack to prevent `type_id` from being overridden by `Error`\n    // implementations, since that can enable unsound downcasting.\n    #[unstable(feature = \"error_type_id\", issue = \"60784\")]\n    #[derive(Debug)]\n    pub struct Internal;\n}\n\n#[stable(feature = \"rust1\", since = \"1.0.0\")]\nimpl<'a, E: Error + 'a> From<E> for Box<dyn Error + 'a> {\n    /// Converts a type of [`Error`] into a box of dyn [`Error`].\n    ///\n    /// # Examples\n    ///\n    /// ```\n    /// use std::error::Error;\n    /// use std::fmt;\n    /// use std::mem;\n    ///\n    /// #[derive(Debug)]\n    /// struct AnError;\n    ///\n    /// impl fmt::Display for AnError {\n    ///     fn fmt(&self, f: &mut fmt::Formatter<'_>) -> fmt::Result {\n    ///         write!(f , \"An error\")\n    ///     }\n    /// }\n    ///\n    /// impl Error for AnError {}\n    ///\n    /// let an_error = AnError;\n    /// assert!(0 == mem::size_of_val(&an_error));\n    /// let a_boxed_error = Box::<dyn Error>::from(an_error);\n    /// assert!(mem::size_of::<Box<dyn Error>>() == mem::size_of_val(&a_boxed_error))\n    /// ```\n    fn from(err: E) -> Box<dyn Error + 'a> {\n        Box::new(err)\n    }\n}\n\n#[stable(feature = \"rust1\", since = \"1.0.0\")]\nimpl<'a, E: Error + Send + Sync + 'a> From<E> for Box<dyn Error + Send + Sync + 'a> {\n    /// Converts a type of [`Error`] + [`Send`] + [`Sync`] into a box of\n    /// dyn [`Error`] + [`Send`] + [`Sync`].\n    ///\n    /// # Examples\n    ///\n    /// ```\n    /// use std::error::Error;\n    /// use std::fmt;\n    /// use std::mem;\n    ///\n    /// #[derive(Debug)]\n    /// struct AnError;\n    ///\n    /// impl fmt::Display for AnError {\n    ///     fn fmt(&self, f: &mut fmt::Formatter<'_>) -> fmt::Result {\n    ///         write!(f , \"An error\")\n    ///     }\n    /// }\n    ///\n    /// impl Error for AnError {}\n    ///\n    /// unsafe impl Send for AnError {}\n    ///\n    /// unsafe impl Sync for AnError {}\n    ///\n    /// let an_error = AnError;\n    /// assert!(0 == mem::size_of_val(&an_error));\n    /// let a_boxed_error = Box::<dyn Error + Send + Sync>::from(an_error);\n    /// assert!(\n    ///     mem::size_of::<Box<dyn Error + Send + Sync>>() == mem::size_of_val(&a_boxed_error))\n    /// ```\n    fn from(err: E) -> Box<dyn Error + Send + Sync + 'a> {\n        Box::new(err)\n    }\n}\n\n#[stable(feature = \"rust1\", since = \"1.0.0\")]\nimpl From<String> for Box<dyn Error + Send + Sync> {\n    /// Converts a [`String`] into a box of dyn [`Error`] + [`Send`] + [`Sync`].\n    ///\n    /// # Examples\n    ///\n    /// ```\n    /// use std::error::Error;\n    /// use std::mem;\n    ///\n    /// let a_string_error = \"a string error\".to_string();\n    /// let a_boxed_error = Box::<dyn Error + Send + Sync>::from(a_string_error);\n    /// assert!(\n    ///     mem::size_of::<Box<dyn Error + Send + Sync>>() == mem::size_of_val(&a_boxed_error))\n    /// ```\n    #[inline]\n    fn from(err: String) -> Box<dyn Error + Send + Sync> {\n        struct StringError(String);\n\n        impl Error for StringError {\n            #[allow(deprecated)]\n            fn description(&self) -> &str {\n                &self.0\n            }\n        }\n\n        impl Display for StringError {\n            fn fmt(&self, f: &mut fmt::Formatter<'_>) -> fmt::Result {\n                Display::fmt(&self.0, f)\n            }\n        }\n\n        // Purposefully skip printing \"StringError(..)\"\n        impl Debug for StringError {\n            fn fmt(&self, f: &mut fmt::Formatter<'_>) -> fmt::Result {\n                Debug::fmt(&self.0, f)\n            }\n        }\n\n        Box::new(StringError(err))\n    }\n}\n\n#[stable(feature = \"string_box_error\", since = \"1.6.0\")]\nimpl From<String> for Box<dyn Error> {\n    /// Converts a [`String`] into a box of dyn [`Error`].\n    ///\n    /// # Examples\n    ///\n    /// ```\n    /// use std::error::Error;\n    /// use std::mem;\n    ///\n    /// let a_string_error = \"a string error\".to_string();\n    /// let a_boxed_error = Box::<dyn Error>::from(a_string_error);\n    /// assert!(mem::size_of::<Box<dyn Error>>() == mem::size_of_val(&a_boxed_error))\n    /// ```\n    fn from(str_err: String) -> Box<dyn Error> {\n        let err1: Box<dyn Error + Send + Sync> = From::from(str_err);\n        let err2: Box<dyn Error> = err1;\n        err2\n    }\n}\n\n#[stable(feature = \"rust1\", since = \"1.0.0\")]\nimpl<'a> From<&str> for Box<dyn Error + Send + Sync + 'a> {\n    /// Converts a [`str`] into a box of dyn [`Error`] + [`Send`] + [`Sync`].\n    ///\n    /// [`str`]: prim@str\n    ///\n    /// # Examples\n    ///\n    /// ```\n    /// use std::error::Error;\n    /// use std::mem;\n    ///\n    /// let a_str_error = \"a str error\";\n    /// let a_boxed_error = Box::<dyn Error + Send + Sync>::from(a_str_error);\n    /// assert!(\n    ///     mem::size_of::<Box<dyn Error + Send + Sync>>() == mem::size_of_val(&a_boxed_error))\n    /// ```\n    #[inline]\n    fn from(err: &str) -> Box<dyn Error + Send + Sync + 'a> {\n        From::from(String::from(err))\n    }\n}\n\n#[stable(feature = \"string_box_error\", since = \"1.6.0\")]\nimpl From<&str> for Box<dyn Error> {\n    /// Converts a [`str`] into a box of dyn [`Error`].\n    ///\n    /// [`str`]: prim@str\n    ///\n    /// # Examples\n    ///\n    /// ```\n    /// use std::error::Error;\n    /// use std::mem;\n    ///\n    /// let a_str_error = \"a str error\";\n    /// let a_boxed_error = Box::<dyn Error>::from(a_str_error);\n    /// assert!(mem::size_of::<Box<dyn Error>>() == mem::size_of_val(&a_boxed_error))\n    /// ```\n    fn from(err: &str) -> Box<dyn Error> {\n        From::from(String::from(err))\n    }\n}\n\n#[stable(feature = \"cow_box_error\", since = \"1.22.0\")]\nimpl<'a, 'b> From<Cow<'b, str>> for Box<dyn Error + Send + Sync + 'a> {\n    /// Converts a [`Cow`] into a box of dyn [`Error`] + [`Send`] + [`Sync`].\n    ///\n    /// # Examples\n    ///\n    /// ```\n    /// use std::error::Error;\n    /// use std::mem;\n    /// use std::borrow::Cow;\n    ///\n    /// let a_cow_str_error = Cow::from(\"a str error\");\n    /// let a_boxed_error = Box::<dyn Error + Send + Sync>::from(a_cow_str_error);\n    /// assert!(\n    ///     mem::size_of::<Box<dyn Error + Send + Sync>>() == mem::size_of_val(&a_boxed_error))\n    /// ```\n    fn from(err: Cow<'b, str>) -> Box<dyn Error + Send + Sync + 'a> {\n        From::from(String::from(err))\n    }\n}\n\n#[stable(feature = \"cow_box_error\", since = \"1.22.0\")]\nimpl<'a> From<Cow<'a, str>> for Box<dyn Error> {\n    /// Converts a [`Cow`] into a box of dyn [`Error`].\n    ///\n    /// # Examples\n    ///\n    /// ```\n    /// use std::error::Error;\n    /// use std::mem;\n    /// use std::borrow::Cow;\n    ///\n    /// let a_cow_str_error = Cow::from(\"a str error\");\n    /// let a_boxed_error = Box::<dyn Error>::from(a_cow_str_error);\n    /// assert!(mem::size_of::<Box<dyn Error>>() == mem::size_of_val(&a_boxed_error))\n    /// ```\n    fn from(err: Cow<'a, str>) -> Box<dyn Error> {\n        From::from(String::from(err))\n    }\n}\n\n#[unstable(feature = \"never_type\", issue = \"35121\")]\nimpl Error for ! {}\n\n#[unstable(\n    feature = \"allocator_api\",\n    reason = \"the precise API and guarantees it provides may be tweaked.\",\n    issue = \"32838\"\n)]\nimpl Error for AllocError {}\n\n#[stable(feature = \"alloc_layout\", since = \"1.28.0\")]\nimpl Error for LayoutError {}\n\n#[stable(feature = \"rust1\", since = \"1.0.0\")]\nimpl Error for str::ParseBoolError {\n    #[allow(deprecated)]\n    fn description(&self) -> &str {\n        \"failed to parse bool\"\n    }\n}\n\n#[stable(feature = \"rust1\", since = \"1.0.0\")]\nimpl Error for str::Utf8Error {\n    #[allow(deprecated)]\n    fn description(&self) -> &str {\n        \"invalid utf-8: corrupt contents\"\n    }\n}\n\n#[stable(feature = \"rust1\", since = \"1.0.0\")]\nimpl Error for num::ParseIntError {\n    #[allow(deprecated)]\n    fn description(&self) -> &str {\n        self.__description()\n    }\n}\n\n#[stable(feature = \"try_from\", since = \"1.34.0\")]\nimpl Error for num::TryFromIntError {\n    #[allow(deprecated)]\n    fn description(&self) -> &str {\n        self.__description()\n    }\n}\n\n#[stable(feature = \"try_from\", since = \"1.34.0\")]\nimpl Error for array::TryFromSliceError {\n    #[allow(deprecated)]\n    fn description(&self) -> &str {\n        self.__description()\n    }\n}\n\n#[stable(feature = \"rust1\", since = \"1.0.0\")]\nimpl Error for num::ParseFloatError {\n    #[allow(deprecated)]\n    fn description(&self) -> &str {\n        self.__description()\n    }\n}\n\n#[stable(feature = \"rust1\", since = \"1.0.0\")]\nimpl Error for string::FromUtf8Error {\n    #[allow(deprecated)]\n    fn description(&self) -> &str {\n        \"invalid utf-8\"\n    }\n}\n\n#[stable(feature = \"rust1\", since = \"1.0.0\")]\nimpl Error for string::FromUtf16Error {\n    #[allow(deprecated)]\n    fn description(&self) -> &str {\n        \"invalid utf-16\"\n    }\n}\n\n#[stable(feature = \"str_parse_error2\", since = \"1.8.0\")]\nimpl Error for Infallible {\n    fn description(&self) -> &str {\n        match *self {}\n    }\n}\n\n#[stable(feature = \"decode_utf16\", since = \"1.9.0\")]\nimpl Error for char::DecodeUtf16Error {\n    #[allow(deprecated)]\n    fn description(&self) -> &str {\n        \"unpaired surrogate found\"\n    }\n}\n\n#[unstable(feature = \"map_try_insert\", issue = \"82766\")]\nimpl<'a, K: Debug + Ord, V: Debug> Error\n    for crate::collections::btree_map::OccupiedError<'a, K, V>\n{\n    #[allow(deprecated)]\n    fn description(&self) -> &str {\n        \"key already exists\"\n    }\n}\n\n#[unstable(feature = \"map_try_insert\", issue = \"82766\")]\nimpl<'a, K: Debug, V: Debug> Error for crate::collections::hash_map::OccupiedError<'a, K, V> {\n    #[allow(deprecated)]\n    fn description(&self) -> &str {\n        \"key already exists\"\n    }\n}\n\n#[stable(feature = \"box_error\", since = \"1.8.0\")]\nimpl<T: Error> Error for Box<T> {\n    #[allow(deprecated, deprecated_in_future)]\n    fn description(&self) -> &str {\n        Error::description(&**self)\n    }\n\n    #[allow(deprecated)]\n    fn cause(&self) -> Option<&dyn Error> {\n        Error::cause(&**self)\n    }\n\n    fn source(&self) -> Option<&(dyn Error + 'static)> {\n        Error::source(&**self)\n    }\n}\n\n#[stable(feature = \"error_by_ref\", since = \"1.51.0\")]\nimpl<'a, T: Error + ?Sized> Error for &'a T {\n    #[allow(deprecated, deprecated_in_future)]\n    fn description(&self) -> &str {\n        Error::description(&**self)\n    }\n\n    #[allow(deprecated)]\n    fn cause(&self) -> Option<&dyn Error> {\n        Error::cause(&**self)\n    }\n\n    fn source(&self) -> Option<&(dyn Error + 'static)> {\n        Error::source(&**self)\n    }\n\n    fn backtrace(&self) -> Option<&Backtrace> {\n        Error::backtrace(&**self)\n    }\n}\n\n#[stable(feature = \"arc_error\", since = \"1.52.0\")]\nimpl<T: Error + ?Sized> Error for Arc<T> {\n    #[allow(deprecated, deprecated_in_future)]\n    fn description(&self) -> &str {\n        Error::description(&**self)\n    }\n\n    #[allow(deprecated)]\n    fn cause(&self) -> Option<&dyn Error> {\n        Error::cause(&**self)\n    }\n\n    fn source(&self) -> Option<&(dyn Error + 'static)> {\n        Error::source(&**self)\n    }\n\n    fn backtrace(&self) -> Option<&Backtrace> {\n        Error::backtrace(&**self)\n    }\n}\n\n#[stable(feature = \"fmt_error\", since = \"1.11.0\")]\nimpl Error for fmt::Error {\n    #[allow(deprecated)]\n    fn description(&self) -> &str {\n        \"an error occurred when formatting an argument\"\n    }\n}\n\n#[stable(feature = \"try_borrow\", since = \"1.13.0\")]\nimpl Error for cell::BorrowError {\n    #[allow(deprecated)]\n    fn description(&self) -> &str {\n        \"already mutably borrowed\"\n    }\n}\n\n#[stable(feature = \"try_borrow\", since = \"1.13.0\")]\nimpl Error for cell::BorrowMutError {\n    #[allow(deprecated)]\n    fn description(&self) -> &str {\n        \"already borrowed\"\n    }\n}\n\n#[stable(feature = \"try_from\", since = \"1.34.0\")]\nimpl Error for char::CharTryFromError {\n    #[allow(deprecated)]\n    fn description(&self) -> &str {\n        \"converted integer out of range for `char`\"\n    }\n}\n\n#[stable(feature = \"char_from_str\", since = \"1.20.0\")]\nimpl Error for char::ParseCharError {\n    #[allow(deprecated)]\n    fn description(&self) -> &str {\n        self.__description()\n    }\n}\n\n#[unstable(feature = \"try_reserve\", reason = \"new API\", issue = \"48043\")]\nimpl Error for alloc::collections::TryReserveError {}\n\n#[unstable(feature = \"duration_checked_float\", issue = \"83400\")]\nimpl Error for core::time::FromSecsError {}\n\n// Copied from `any.rs`.\nimpl dyn Error + 'static {\n    /// Returns `true` if the boxed type is the same as `T`\n    #[stable(feature = \"error_downcast\", since = \"1.3.0\")]\n    #[inline]\n    pub fn is<T: Error + 'static>(&self) -> bool {\n        // Get `TypeId` of the type this function is instantiated with.\n        let t = TypeId::of::<T>();\n\n        // Get `TypeId` of the type in the trait object.\n        let boxed = self.type_id(private::Internal);\n\n        // Compare both `TypeId`s on equality.\n        t == boxed\n    }\n\n    /// Returns some reference to the boxed value if it is of type `T`, or\n    /// `None` if it isn't.\n    #[stable(feature = \"error_downcast\", since = \"1.3.0\")]\n    #[inline]\n    pub fn downcast_ref<T: Error + 'static>(&self) -> Option<&T> {\n        if self.is::<T>() {\n            unsafe { Some(&*(self as *const dyn Error as *const T)) }\n        } else {\n            None\n        }\n    }\n\n    /// Returns some mutable reference to the boxed value if it is of type `T`, or\n    /// `None` if it isn't.\n    #[stable(feature = \"error_downcast\", since = \"1.3.0\")]\n    #[inline]\n    pub fn downcast_mut<T: Error + 'static>(&mut self) -> Option<&mut T> {\n        if self.is::<T>() {\n            unsafe { Some(&mut *(self as *mut dyn Error as *mut T)) }\n        } else {\n            None\n        }\n    }\n}\n\nimpl dyn Error + 'static + Send {\n    /// Forwards to the method defined on the type `dyn Error`.\n    #[stable(feature = \"error_downcast\", since = \"1.3.0\")]\n    #[inline]\n    pub fn is<T: Error + 'static>(&self) -> bool {\n        <dyn Error + 'static>::is::<T>(self)\n    }\n\n    /// Forwards to the method defined on the type `dyn Error`.\n    #[stable(feature = \"error_downcast\", since = \"1.3.0\")]\n    #[inline]\n    pub fn downcast_ref<T: Error + 'static>(&self) -> Option<&T> {\n        <dyn Error + 'static>::downcast_ref::<T>(self)\n    }\n\n    /// Forwards to the method defined on the type `dyn Error`.\n    #[stable(feature = \"error_downcast\", since = \"1.3.0\")]\n    #[inline]\n    pub fn downcast_mut<T: Error + 'static>(&mut self) -> Option<&mut T> {\n        <dyn Error + 'static>::downcast_mut::<T>(self)\n    }\n}\n\nimpl dyn Error + 'static + Send + Sync {\n    /// Forwards to the method defined on the type `dyn Error`.\n    #[stable(feature = \"error_downcast\", since = \"1.3.0\")]\n    #[inline]\n    pub fn is<T: Error + 'static>(&self) -> bool {\n        <dyn Error + 'static>::is::<T>(self)\n    }\n\n    /// Forwards to the method defined on the type `dyn Error`.\n    #[stable(feature = \"error_downcast\", since = \"1.3.0\")]\n    #[inline]\n    pub fn downcast_ref<T: Error + 'static>(&self) -> Option<&T> {\n        <dyn Error + 'static>::downcast_ref::<T>(self)\n    }\n\n    /// Forwards to the method defined on the type `dyn Error`.\n    #[stable(feature = \"error_downcast\", since = \"1.3.0\")]\n    #[inline]\n    pub fn downcast_mut<T: Error + 'static>(&mut self) -> Option<&mut T> {\n        <dyn Error + 'static>::downcast_mut::<T>(self)\n    }\n}\n\nimpl dyn Error {\n    #[inline]\n    #[stable(feature = \"error_downcast\", since = \"1.3.0\")]\n    /// Attempts to downcast the box to a concrete type.\n    pub fn downcast<T: Error + 'static>(self: Box<Self>) -> Result<Box<T>, Box<dyn Error>> {\n        if self.is::<T>() {\n            unsafe {\n                let raw: *mut dyn Error = Box::into_raw(self);\n                Ok(Box::from_raw(raw as *mut T))\n            }\n        } else {\n            Err(self)\n        }\n    }\n\n    /// Returns an iterator starting with the current error and continuing with\n    /// recursively calling [`Error::source`].\n    ///\n    /// If you want to omit the current error and only use its sources,\n    /// use `skip(1)`.\n    ///\n    /// # Examples\n    ///\n    /// ```\n    /// #![feature(error_iter)]\n    /// use std::error::Error;\n    /// use std::fmt;\n    ///\n    /// #[derive(Debug)]\n    /// struct A;\n    ///\n    /// #[derive(Debug)]\n    /// struct B(Option<Box<dyn Error + 'static>>);\n    ///\n    /// impl fmt::Display for A {\n    ///     fn fmt(&self, f: &mut fmt::Formatter<'_>) -> fmt::Result {\n    ///         write!(f, \"A\")\n    ///     }\n    /// }\n    ///\n    /// impl fmt::Display for B {\n    ///     fn fmt(&self, f: &mut fmt::Formatter<'_>) -> fmt::Result {\n    ///         write!(f, \"B\")\n    ///     }\n    /// }\n    ///\n    /// impl Error for A {}\n    ///\n    /// impl Error for B {\n    ///     fn source(&self) -> Option<&(dyn Error + 'static)> {\n    ///         self.0.as_ref().map(|e| e.as_ref())\n    ///     }\n    /// }\n    ///\n    /// let b = B(Some(Box::new(A)));\n    ///\n    /// // let err : Box<Error> = b.into(); // or\n    /// let err = &b as &(dyn Error);\n    ///\n    /// let mut iter = err.chain();\n    ///\n    /// assert_eq!(\"B\".to_string(), iter.next().unwrap().to_string());\n    /// assert_eq!(\"A\".to_string(), iter.next().unwrap().to_string());\n    /// assert!(iter.next().is_none());\n    /// assert!(iter.next().is_none());\n    /// ```\n    #[unstable(feature = \"error_iter\", issue = \"58520\")]\n    #[inline]\n    pub fn chain(&self) -> Chain<'_> {\n        Chain { current: Some(self) }\n    }\n}\n\n/// An iterator over an [`Error`] and its sources.\n///\n/// If you want to omit the initial error and only process\n/// its sources, use `skip(1)`.\n#[unstable(feature = \"error_iter\", issue = \"58520\")]\n#[derive(Clone, Debug)]\npub struct Chain<'a> {\n    current: Option<&'a (dyn Error + 'static)>,\n}\n\n#[unstable(feature = \"error_iter\", issue = \"58520\")]\nimpl<'a> Iterator for Chain<'a> {\n    type Item = &'a (dyn Error + 'static);\n\n    fn next(&mut self) -> Option<Self::Item> {\n        let current = self.current;\n        self.current = self.current.and_then(Error::source);\n        current\n    }\n}\n\nimpl dyn Error + Send {\n    #[inline]\n    #[stable(feature = \"error_downcast\", since = \"1.3.0\")]\n    /// Attempts to downcast the box to a concrete type.\n    pub fn downcast<T: Error + 'static>(self: Box<Self>) -> Result<Box<T>, Box<dyn Error + Send>> {\n        let err: Box<dyn Error> = self;\n        <dyn Error>::downcast(err).map_err(|s| unsafe {\n            // Reapply the `Send` marker.\n            transmute::<Box<dyn Error>, Box<dyn Error + Send>>(s)\n        })\n    }\n}\n\nimpl dyn Error + Send + Sync {\n    #[inline]\n    #[stable(feature = \"error_downcast\", since = \"1.3.0\")]\n    /// Attempts to downcast the box to a concrete type.\n    pub fn downcast<T: Error + 'static>(self: Box<Self>) -> Result<Box<T>, Box<Self>> {\n        let err: Box<dyn Error> = self;\n        <dyn Error>::downcast(err).map_err(|s| unsafe {\n            // Reapply the `Send + Sync` marker.\n            transmute::<Box<dyn Error>, Box<dyn Error + Send + Sync>>(s)\n        })\n    }\n}\n"],[2223,"//! Lazy values and one-time initialization of static data.\n\n#[cfg(test)]\nmod tests;\n\nuse crate::{\n    cell::{Cell, UnsafeCell},\n    fmt,\n    marker::PhantomData,\n    mem::MaybeUninit,\n    ops::{Deref, Drop},\n    panic::{RefUnwindSafe, UnwindSafe},\n    pin::Pin,\n    sync::Once,\n};\n\n#[doc(inline)]\n#[unstable(feature = \"once_cell\", issue = \"74465\")]\npub use core::lazy::*;\n\n/// A synchronization primitive which can be written to only once.\n///\n/// This type is a thread-safe `OnceCell`.\n///\n/// # Examples\n///\n/// ```\n/// #![feature(once_cell)]\n///\n/// use std::lazy::SyncOnceCell;\n///\n/// static CELL: SyncOnceCell<String> = SyncOnceCell::new();\n/// assert!(CELL.get().is_none());\n///\n/// std::thread::spawn(|| {\n///     let value: &String = CELL.get_or_init(|| {\n///         \"Hello, World!\".to_string()\n///     });\n///     assert_eq!(value, \"Hello, World!\");\n/// }).join().unwrap();\n///\n/// let value: Option<&String> = CELL.get();\n/// assert!(value.is_some());\n/// assert_eq!(value.unwrap().as_str(), \"Hello, World!\");\n/// ```\n#[unstable(feature = \"once_cell\", issue = \"74465\")]\npub struct SyncOnceCell<T> {\n    once: Once,\n    // Whether or not the value is initialized is tracked by `state_and_queue`.\n    value: UnsafeCell<MaybeUninit<T>>,\n    /// `PhantomData` to make sure dropck understands we're dropping T in our Drop impl.\n    ///\n    /// ```compile_fail,E0597\n    /// #![feature(once_cell)]\n    ///\n    /// use std::lazy::SyncOnceCell;\n    ///\n    /// struct A<'a>(&'a str);\n    ///\n    /// impl<'a> Drop for A<'a> {\n    ///     fn drop(&mut self) {}\n    /// }\n    ///\n    /// let cell = SyncOnceCell::new();\n    /// {\n    ///     let s = String::new();\n    ///     let _ = cell.set(A(&s));\n    /// }\n    /// ```\n    _marker: PhantomData<T>,\n}\n\n// Why do we need `T: Send`?\n// Thread A creates a `SyncOnceCell` and shares it with\n// scoped thread B, which fills the cell, which is\n// then destroyed by A. That is, destructor observes\n// a sent value.\n#[unstable(feature = \"once_cell\", issue = \"74465\")]\nunsafe impl<T: Sync + Send> Sync for SyncOnceCell<T> {}\n#[unstable(feature = \"once_cell\", issue = \"74465\")]\nunsafe impl<T: Send> Send for SyncOnceCell<T> {}\n\n#[unstable(feature = \"once_cell\", issue = \"74465\")]\nimpl<T: RefUnwindSafe + UnwindSafe> RefUnwindSafe for SyncOnceCell<T> {}\n#[unstable(feature = \"once_cell\", issue = \"74465\")]\nimpl<T: UnwindSafe> UnwindSafe for SyncOnceCell<T> {}\n\n#[unstable(feature = \"once_cell\", issue = \"74465\")]\nimpl<T> Default for SyncOnceCell<T> {\n    fn default() -> SyncOnceCell<T> {\n        SyncOnceCell::new()\n    }\n}\n\n#[unstable(feature = \"once_cell\", issue = \"74465\")]\nimpl<T: fmt::Debug> fmt::Debug for SyncOnceCell<T> {\n    fn fmt(&self, f: &mut fmt::Formatter<'_>) -> fmt::Result {\n        match self.get() {\n            Some(v) => f.debug_tuple(\"Once\").field(v).finish(),\n            None => f.write_str(\"Once(Uninit)\"),\n        }\n    }\n}\n\n#[unstable(feature = \"once_cell\", issue = \"74465\")]\nimpl<T: Clone> Clone for SyncOnceCell<T> {\n    fn clone(&self) -> SyncOnceCell<T> {\n        let cell = Self::new();\n        if let Some(value) = self.get() {\n            match cell.set(value.clone()) {\n                Ok(()) => (),\n                Err(_) => unreachable!(),\n            }\n        }\n        cell\n    }\n}\n\n#[unstable(feature = \"once_cell\", issue = \"74465\")]\nimpl<T> From<T> for SyncOnceCell<T> {\n    fn from(value: T) -> Self {\n        let cell = Self::new();\n        match cell.set(value) {\n            Ok(()) => cell,\n            Err(_) => unreachable!(),\n        }\n    }\n}\n\n#[unstable(feature = \"once_cell\", issue = \"74465\")]\nimpl<T: PartialEq> PartialEq for SyncOnceCell<T> {\n    fn eq(&self, other: &SyncOnceCell<T>) -> bool {\n        self.get() == other.get()\n    }\n}\n\n#[unstable(feature = \"once_cell\", issue = \"74465\")]\nimpl<T: Eq> Eq for SyncOnceCell<T> {}\n\nimpl<T> SyncOnceCell<T> {\n    /// Creates a new empty cell.\n    #[unstable(feature = \"once_cell\", issue = \"74465\")]\n    pub const fn new() -> SyncOnceCell<T> {\n        SyncOnceCell {\n            once: Once::new(),\n            value: UnsafeCell::new(MaybeUninit::uninit()),\n            _marker: PhantomData,\n        }\n    }\n\n    /// Gets the reference to the underlying value.\n    ///\n    /// Returns `None` if the cell is empty, or being initialized. This\n    /// method never blocks.\n    #[unstable(feature = \"once_cell\", issue = \"74465\")]\n    pub fn get(&self) -> Option<&T> {\n        if self.is_initialized() {\n            // Safe b/c checked is_initialized\n            Some(unsafe { self.get_unchecked() })\n        } else {\n            None\n        }\n    }\n\n    /// Gets the mutable reference to the underlying value.\n    ///\n    /// Returns `None` if the cell is empty. This method never blocks.\n    #[unstable(feature = \"once_cell\", issue = \"74465\")]\n    pub fn get_mut(&mut self) -> Option<&mut T> {\n        if self.is_initialized() {\n            // Safe b/c checked is_initialized and we have a unique access\n            Some(unsafe { self.get_unchecked_mut() })\n        } else {\n            None\n        }\n    }\n\n    /// Sets the contents of this cell to `value`.\n    ///\n    /// May block if another thread is currently attempting to initialize the cell. The cell is\n    /// guaranteed to contain a value when set returns, though not necessarily the one provided.\n    ///\n    /// Returns `Ok(())` if the cell's value was set by this call.\n    ///\n    /// # Examples\n    ///\n    /// ```\n    /// #![feature(once_cell)]\n    ///\n    /// use std::lazy::SyncOnceCell;\n    ///\n    /// static CELL: SyncOnceCell<i32> = SyncOnceCell::new();\n    ///\n    /// fn main() {\n    ///     assert!(CELL.get().is_none());\n    ///\n    ///     std::thread::spawn(|| {\n    ///         assert_eq!(CELL.set(92), Ok(()));\n    ///     }).join().unwrap();\n    ///\n    ///     assert_eq!(CELL.set(62), Err(62));\n    ///     assert_eq!(CELL.get(), Some(&92));\n    /// }\n    /// ```\n    #[unstable(feature = \"once_cell\", issue = \"74465\")]\n    pub fn set(&self, value: T) -> Result<(), T> {\n        let mut value = Some(value);\n        self.get_or_init(|| value.take().unwrap());\n        match value {\n            None => Ok(()),\n            Some(value) => Err(value),\n        }\n    }\n\n    /// Gets the contents of the cell, initializing it with `f` if the cell\n    /// was empty.\n    ///\n    /// Many threads may call `get_or_init` concurrently with different\n    /// initializing functions, but it is guaranteed that only one function\n    /// will be executed.\n    ///\n    /// # Panics\n    ///\n    /// If `f` panics, the panic is propagated to the caller, and the cell\n    /// remains uninitialized.\n    ///\n    /// It is an error to reentrantly initialize the cell from `f`. The\n    /// exact outcome is unspecified. Current implementation deadlocks, but\n    /// this may be changed to a panic in the future.\n    ///\n    /// # Examples\n    ///\n    /// ```\n    /// #![feature(once_cell)]\n    ///\n    /// use std::lazy::SyncOnceCell;\n    ///\n    /// let cell = SyncOnceCell::new();\n    /// let value = cell.get_or_init(|| 92);\n    /// assert_eq!(value, &92);\n    /// let value = cell.get_or_init(|| unreachable!());\n    /// assert_eq!(value, &92);\n    /// ```\n    #[unstable(feature = \"once_cell\", issue = \"74465\")]\n    pub fn get_or_init<F>(&self, f: F) -> &T\n    where\n        F: FnOnce() -> T,\n    {\n        match self.get_or_try_init(|| Ok::<T, !>(f())) {\n            Ok(val) => val,\n        }\n    }\n\n    /// Gets the contents of the cell, initializing it with `f` if\n    /// the cell was empty. If the cell was empty and `f` failed, an\n    /// error is returned.\n    ///\n    /// # Panics\n    ///\n    /// If `f` panics, the panic is propagated to the caller, and\n    /// the cell remains uninitialized.\n    ///\n    /// It is an error to reentrantly initialize the cell from `f`.\n    /// The exact outcome is unspecified. Current implementation\n    /// deadlocks, but this may be changed to a panic in the future.\n    ///\n    /// # Examples\n    ///\n    /// ```\n    /// #![feature(once_cell)]\n    ///\n    /// use std::lazy::SyncOnceCell;\n    ///\n    /// let cell = SyncOnceCell::new();\n    /// assert_eq!(cell.get_or_try_init(|| Err(())), Err(()));\n    /// assert!(cell.get().is_none());\n    /// let value = cell.get_or_try_init(|| -> Result<i32, ()> {\n    ///     Ok(92)\n    /// });\n    /// assert_eq!(value, Ok(&92));\n    /// assert_eq!(cell.get(), Some(&92))\n    /// ```\n    #[unstable(feature = \"once_cell\", issue = \"74465\")]\n    pub fn get_or_try_init<F, E>(&self, f: F) -> Result<&T, E>\n    where\n        F: FnOnce() -> Result<T, E>,\n    {\n        // Fast path check\n        // NOTE: We need to perform an acquire on the state in this method\n        // in order to correctly synchronize `SyncLazy::force`. This is\n        // currently done by calling `self.get()`, which in turn calls\n        // `self.is_initialized()`, which in turn performs the acquire.\n        if let Some(value) = self.get() {\n            return Ok(value);\n        }\n        self.initialize(f)?;\n\n        debug_assert!(self.is_initialized());\n\n        // SAFETY: The inner value has been initialized\n        Ok(unsafe { self.get_unchecked() })\n    }\n\n    /// Internal-only API that gets the contents of the cell, initializing it\n    /// in two steps with `f` and `g` if the cell was empty.\n    ///\n    /// `f` is called to construct the value, which is then moved into the cell\n    /// and given as a (pinned) mutable reference to `g` to finish\n    /// initialization.\n    ///\n    /// This allows `g` to inspect an manipulate the value after it has been\n    /// moved into its final place in the cell, but before the cell is\n    /// considered initialized.\n    ///\n    /// # Panics\n    ///\n    /// If `f` or `g` panics, the panic is propagated to the caller, and the\n    /// cell remains uninitialized.\n    ///\n    /// With the current implementation, if `g` panics, the value from `f` will\n    /// not be dropped. This should probably be fixed if this is ever used for\n    /// a type where this matters.\n    ///\n    /// It is an error to reentrantly initialize the cell from `f`. The exact\n    /// outcome is unspecified. Current implementation deadlocks, but this may\n    /// be changed to a panic in the future.\n    pub(crate) fn get_or_init_pin<F, G>(self: Pin<&Self>, f: F, g: G) -> Pin<&T>\n    where\n        F: FnOnce() -> T,\n        G: FnOnce(Pin<&mut T>),\n    {\n        if let Some(value) = self.get_ref().get() {\n            // SAFETY: The inner value was already initialized, and will not be\n            // moved anymore.\n            return unsafe { Pin::new_unchecked(value) };\n        }\n\n        let slot = &self.value;\n\n        // Ignore poisoning from other threads\n        // If another thread panics, then we'll be able to run our closure\n        self.once.call_once_force(|_| {\n            let value = f();\n            // SAFETY: We use the Once (self.once) to guarantee unique access\n            // to the UnsafeCell (slot).\n            let value: &mut T = unsafe { (&mut *slot.get()).write(value) };\n            // SAFETY: The value has been written to its final place in\n            // self.value. We do not to move it anymore, which we promise here\n            // with a Pin<&mut T>.\n            g(unsafe { Pin::new_unchecked(value) });\n        });\n\n        // SAFETY: The inner value has been initialized, and will not be moved\n        // anymore.\n        unsafe { Pin::new_unchecked(self.get_ref().get_unchecked()) }\n    }\n\n    /// Consumes the `SyncOnceCell`, returning the wrapped value. Returns\n    /// `None` if the cell was empty.\n    ///\n    /// # Examples\n    ///\n    /// ```\n    /// #![feature(once_cell)]\n    ///\n    /// use std::lazy::SyncOnceCell;\n    ///\n    /// let cell: SyncOnceCell<String> = SyncOnceCell::new();\n    /// assert_eq!(cell.into_inner(), None);\n    ///\n    /// let cell = SyncOnceCell::new();\n    /// cell.set(\"hello\".to_string()).unwrap();\n    /// assert_eq!(cell.into_inner(), Some(\"hello\".to_string()));\n    /// ```\n    #[unstable(feature = \"once_cell\", issue = \"74465\")]\n    pub fn into_inner(mut self) -> Option<T> {\n        self.take()\n    }\n\n    /// Takes the value out of this `SyncOnceCell`, moving it back to an uninitialized state.\n    ///\n    /// Has no effect and returns `None` if the `SyncOnceCell` hasn't been initialized.\n    ///\n    /// Safety is guaranteed by requiring a mutable reference.\n    ///\n    /// # Examples\n    ///\n    /// ```\n    /// #![feature(once_cell)]\n    ///\n    /// use std::lazy::SyncOnceCell;\n    ///\n    /// let mut cell: SyncOnceCell<String> = SyncOnceCell::new();\n    /// assert_eq!(cell.take(), None);\n    ///\n    /// let mut cell = SyncOnceCell::new();\n    /// cell.set(\"hello\".to_string()).unwrap();\n    /// assert_eq!(cell.take(), Some(\"hello\".to_string()));\n    /// assert_eq!(cell.get(), None);\n    /// ```\n    #[unstable(feature = \"once_cell\", issue = \"74465\")]\n    pub fn take(&mut self) -> Option<T> {\n        if self.is_initialized() {\n            self.once = Once::new();\n            // SAFETY: `self.value` is initialized and contains a valid `T`.\n            // `self.once` is reset, so `is_initialized()` will be false again\n            // which prevents the value from being read twice.\n            unsafe { Some((&mut *self.value.get()).assume_init_read()) }\n        } else {\n            None\n        }\n    }\n\n    #[inline]\n    fn is_initialized(&self) -> bool {\n        self.once.is_completed()\n    }\n\n    #[cold]\n    fn initialize<F, E>(&self, f: F) -> Result<(), E>\n    where\n        F: FnOnce() -> Result<T, E>,\n    {\n        let mut res: Result<(), E> = Ok(());\n        let slot = &self.value;\n\n        // Ignore poisoning from other threads\n        // If another thread panics, then we'll be able to run our closure\n        self.once.call_once_force(|p| {\n            match f() {\n                Ok(value) => {\n                    unsafe { (&mut *slot.get()).write(value) };\n                }\n                Err(e) => {\n                    res = Err(e);\n\n                    // Treat the underlying `Once` as poisoned since we\n                    // failed to initialize our value. Calls\n                    p.poison();\n                }\n            }\n        });\n        res\n    }\n\n    /// # Safety\n    ///\n    /// The value must be initialized\n    unsafe fn get_unchecked(&self) -> &T {\n        debug_assert!(self.is_initialized());\n        (&*self.value.get()).assume_init_ref()\n    }\n\n    /// # Safety\n    ///\n    /// The value must be initialized\n    unsafe fn get_unchecked_mut(&mut self) -> &mut T {\n        debug_assert!(self.is_initialized());\n        (&mut *self.value.get()).assume_init_mut()\n    }\n}\n\nunsafe impl<#[may_dangle] T> Drop for SyncOnceCell<T> {\n    fn drop(&mut self) {\n        if self.is_initialized() {\n            // SAFETY: The cell is initialized and being dropped, so it can't\n            // be accessed again. We also don't touch the `T` other than\n            // dropping it, which validates our usage of #[may_dangle].\n            unsafe { (&mut *self.value.get()).assume_init_drop() };\n        }\n    }\n}\n\n/// A value which is initialized on the first access.\n///\n/// This type is a thread-safe `Lazy`, and can be used in statics.\n///\n/// # Examples\n///\n/// ```\n/// #![feature(once_cell)]\n///\n/// use std::collections::HashMap;\n///\n/// use std::lazy::SyncLazy;\n///\n/// static HASHMAP: SyncLazy<HashMap<i32, String>> = SyncLazy::new(|| {\n///     println!(\"initializing\");\n///     let mut m = HashMap::new();\n///     m.insert(13, \"Spica\".to_string());\n///     m.insert(74, \"Hoyten\".to_string());\n///     m\n/// });\n///\n/// fn main() {\n///     println!(\"ready\");\n///     std::thread::spawn(|| {\n///         println!(\"{:?}\", HASHMAP.get(&13));\n///     }).join().unwrap();\n///     println!(\"{:?}\", HASHMAP.get(&74));\n///\n///     // Prints:\n///     //   ready\n///     //   initializing\n///     //   Some(\"Spica\")\n///     //   Some(\"Hoyten\")\n/// }\n/// ```\n#[unstable(feature = \"once_cell\", issue = \"74465\")]\npub struct SyncLazy<T, F = fn() -> T> {\n    cell: SyncOnceCell<T>,\n    init: Cell<Option<F>>,\n}\n\n#[unstable(feature = \"once_cell\", issue = \"74465\")]\nimpl<T: fmt::Debug, F> fmt::Debug for SyncLazy<T, F> {\n    fn fmt(&self, f: &mut fmt::Formatter<'_>) -> fmt::Result {\n        f.debug_struct(\"Lazy\").field(\"cell\", &self.cell).finish_non_exhaustive()\n    }\n}\n\n// We never create a `&F` from a `&SyncLazy<T, F>` so it is fine\n// to not impl `Sync` for `F`\n// we do create a `&mut Option<F>` in `force`, but this is\n// properly synchronized, so it only happens once\n// so it also does not contribute to this impl.\n#[unstable(feature = \"once_cell\", issue = \"74465\")]\nunsafe impl<T, F: Send> Sync for SyncLazy<T, F> where SyncOnceCell<T>: Sync {}\n// auto-derived `Send` impl is OK.\n\n#[unstable(feature = \"once_cell\", issue = \"74465\")]\nimpl<T, F: UnwindSafe> RefUnwindSafe for SyncLazy<T, F> where SyncOnceCell<T>: RefUnwindSafe {}\n#[unstable(feature = \"once_cell\", issue = \"74465\")]\nimpl<T, F: UnwindSafe> UnwindSafe for SyncLazy<T, F> where SyncOnceCell<T>: UnwindSafe {}\n\nimpl<T, F> SyncLazy<T, F> {\n    /// Creates a new lazy value with the given initializing\n    /// function.\n    #[unstable(feature = \"once_cell\", issue = \"74465\")]\n    pub const fn new(f: F) -> SyncLazy<T, F> {\n        SyncLazy { cell: SyncOnceCell::new(), init: Cell::new(Some(f)) }\n    }\n}\n\nimpl<T, F: FnOnce() -> T> SyncLazy<T, F> {\n    /// Forces the evaluation of this lazy value and\n    /// returns a reference to result. This is equivalent\n    /// to the `Deref` impl, but is explicit.\n    ///\n    /// # Examples\n    ///\n    /// ```\n    /// #![feature(once_cell)]\n    ///\n    /// use std::lazy::SyncLazy;\n    ///\n    /// let lazy = SyncLazy::new(|| 92);\n    ///\n    /// assert_eq!(SyncLazy::force(&lazy), &92);\n    /// assert_eq!(&*lazy, &92);\n    /// ```\n    #[unstable(feature = \"once_cell\", issue = \"74465\")]\n    pub fn force(this: &SyncLazy<T, F>) -> &T {\n        this.cell.get_or_init(|| match this.init.take() {\n            Some(f) => f(),\n            None => panic!(\"Lazy instance has previously been poisoned\"),\n        })\n    }\n}\n\n#[unstable(feature = \"once_cell\", issue = \"74465\")]\nimpl<T, F: FnOnce() -> T> Deref for SyncLazy<T, F> {\n    type Target = T;\n    fn deref(&self) -> &T {\n        SyncLazy::force(self)\n    }\n}\n\n#[unstable(feature = \"once_cell\", issue = \"74465\")]\nimpl<T: Default> Default for SyncLazy<T> {\n    /// Creates a new lazy value using `Default` as the initializing function.\n    fn default() -> SyncLazy<T> {\n        SyncLazy::new(T::default)\n    }\n}\n"],[2224,"// ignore-tidy-filelength\n\n#[cfg(test)]\nmod tests;\n\nuse self::Entry::*;\n\nuse hashbrown::hash_map as base;\n\nuse crate::borrow::Borrow;\nuse crate::cell::Cell;\nuse crate::collections::TryReserveError;\nuse crate::fmt::{self, Debug};\n#[allow(deprecated)]\nuse crate::hash::{BuildHasher, Hash, Hasher, SipHasher13};\nuse crate::iter::{FromIterator, FusedIterator};\nuse crate::ops::Index;\nuse crate::sys;\n\n/// A [hash map] implemented with quadratic probing and SIMD lookup.\n///\n/// By default, `HashMap` uses a hashing algorithm selected to provide\n/// resistance against HashDoS attacks. The algorithm is randomly seeded, and a\n/// reasonable best-effort is made to generate this seed from a high quality,\n/// secure source of randomness provided by the host without blocking the\n/// program. Because of this, the randomness of the seed depends on the output\n/// quality of the system's random number generator when the seed is created.\n/// In particular, seeds generated when the system's entropy pool is abnormally\n/// low such as during system boot may be of a lower quality.\n///\n/// The default hashing algorithm is currently SipHash 1-3, though this is\n/// subject to change at any point in the future. While its performance is very\n/// competitive for medium sized keys, other hashing algorithms will outperform\n/// it for small keys such as integers as well as large keys such as long\n/// strings, though those algorithms will typically *not* protect against\n/// attacks such as HashDoS.\n///\n/// The hashing algorithm can be replaced on a per-`HashMap` basis using the\n/// [`default`], [`with_hasher`], and [`with_capacity_and_hasher`] methods.\n/// There are many alternative [hashing algorithms available on crates.io].\n///\n/// It is required that the keys implement the [`Eq`] and [`Hash`] traits, although\n/// this can frequently be achieved by using `#[derive(PartialEq, Eq, Hash)]`.\n/// If you implement these yourself, it is important that the following\n/// property holds:\n///\n/// ```text\n/// k1 == k2 -> hash(k1) == hash(k2)\n/// ```\n///\n/// In other words, if two keys are equal, their hashes must be equal.\n///\n/// It is a logic error for a key to be modified in such a way that the key's\n/// hash, as determined by the [`Hash`] trait, or its equality, as determined by\n/// the [`Eq`] trait, changes while it is in the map. This is normally only\n/// possible through [`Cell`], [`RefCell`], global state, I/O, or unsafe code.\n/// The behavior resulting from such a logic error is not specified, but will\n/// not result in undefined behavior. This could include panics, incorrect results,\n/// aborts, memory leaks, and non-termination.\n///\n/// The hash table implementation is a Rust port of Google's [SwissTable].\n/// The original C++ version of SwissTable can be found [here], and this\n/// [CppCon talk] gives an overview of how the algorithm works.\n///\n/// [hash map]: crate::collections#use-a-hashmap-when\n/// [hashing algorithms available on crates.io]: https://crates.io/keywords/hasher\n/// [SwissTable]: https://abseil.io/blog/20180927-swisstables\n/// [here]: https://github.com/abseil/abseil-cpp/blob/master/absl/container/internal/raw_hash_set.h\n/// [CppCon talk]: https://www.youtube.com/watch?v=ncHmEUmJZf4\n///\n/// # Examples\n///\n/// ```\n/// use std::collections::HashMap;\n///\n/// // Type inference lets us omit an explicit type signature (which\n/// // would be `HashMap<String, String>` in this example).\n/// let mut book_reviews = HashMap::new();\n///\n/// // Review some books.\n/// book_reviews.insert(\n///     \"Adventures of Huckleberry Finn\".to_string(),\n///     \"My favorite book.\".to_string(),\n/// );\n/// book_reviews.insert(\n///     \"Grimms' Fairy Tales\".to_string(),\n///     \"Masterpiece.\".to_string(),\n/// );\n/// book_reviews.insert(\n///     \"Pride and Prejudice\".to_string(),\n///     \"Very enjoyable.\".to_string(),\n/// );\n/// book_reviews.insert(\n///     \"The Adventures of Sherlock Holmes\".to_string(),\n///     \"Eye lyked it alot.\".to_string(),\n/// );\n///\n/// // Check for a specific one.\n/// // When collections store owned values (String), they can still be\n/// // queried using references (&str).\n/// if !book_reviews.contains_key(\"Les Misérables\") {\n///     println!(\"We've got {} reviews, but Les Misérables ain't one.\",\n///              book_reviews.len());\n/// }\n///\n/// // oops, this review has a lot of spelling mistakes, let's delete it.\n/// book_reviews.remove(\"The Adventures of Sherlock Holmes\");\n///\n/// // Look up the values associated with some keys.\n/// let to_find = [\"Pride and Prejudice\", \"Alice's Adventure in Wonderland\"];\n/// for &book in &to_find {\n///     match book_reviews.get(book) {\n///         Some(review) => println!(\"{}: {}\", book, review),\n///         None => println!(\"{} is unreviewed.\", book)\n///     }\n/// }\n///\n/// // Look up the value for a key (will panic if the key is not found).\n/// println!(\"Review for Jane: {}\", book_reviews[\"Pride and Prejudice\"]);\n///\n/// // Iterate over everything.\n/// for (book, review) in &book_reviews {\n///     println!(\"{}: \\\"{}\\\"\", book, review);\n/// }\n/// ```\n///\n/// `HashMap` also implements an [`Entry API`](#method.entry), which allows\n/// for more complex methods of getting, setting, updating and removing keys and\n/// their values:\n///\n/// ```\n/// use std::collections::HashMap;\n///\n/// // type inference lets us omit an explicit type signature (which\n/// // would be `HashMap<&str, u8>` in this example).\n/// let mut player_stats = HashMap::new();\n///\n/// fn random_stat_buff() -> u8 {\n///     // could actually return some random value here - let's just return\n///     // some fixed value for now\n///     42\n/// }\n///\n/// // insert a key only if it doesn't already exist\n/// player_stats.entry(\"health\").or_insert(100);\n///\n/// // insert a key using a function that provides a new value only if it\n/// // doesn't already exist\n/// player_stats.entry(\"defence\").or_insert_with(random_stat_buff);\n///\n/// // update a key, guarding against the key possibly not being set\n/// let stat = player_stats.entry(\"attack\").or_insert(100);\n/// *stat += random_stat_buff();\n/// ```\n///\n/// The easiest way to use `HashMap` with a custom key type is to derive [`Eq`] and [`Hash`].\n/// We must also derive [`PartialEq`].\n///\n/// [`RefCell`]: crate::cell::RefCell\n/// [`Cell`]: crate::cell::Cell\n/// [`default`]: Default::default\n/// [`with_hasher`]: Self::with_hasher\n/// [`with_capacity_and_hasher`]: Self::with_capacity_and_hasher\n///\n/// ```\n/// use std::collections::HashMap;\n///\n/// #[derive(Hash, Eq, PartialEq, Debug)]\n/// struct Viking {\n///     name: String,\n///     country: String,\n/// }\n///\n/// impl Viking {\n///     /// Creates a new Viking.\n///     fn new(name: &str, country: &str) -> Viking {\n///         Viking { name: name.to_string(), country: country.to_string() }\n///     }\n/// }\n///\n/// // Use a HashMap to store the vikings' health points.\n/// let mut vikings = HashMap::new();\n///\n/// vikings.insert(Viking::new(\"Einar\", \"Norway\"), 25);\n/// vikings.insert(Viking::new(\"Olaf\", \"Denmark\"), 24);\n/// vikings.insert(Viking::new(\"Harald\", \"Iceland\"), 12);\n///\n/// // Use derived implementation to print the status of the vikings.\n/// for (viking, health) in &vikings {\n///     println!(\"{:?} has {} hp\", viking, health);\n/// }\n/// ```\n///\n/// A `HashMap` with fixed list of elements can be initialized from an array:\n///\n/// ```\n/// use std::collections::HashMap;\n///\n/// let timber_resources: HashMap<&str, i32> = [(\"Norway\", 100), (\"Denmark\", 50), (\"Iceland\", 10)]\n///     .iter().cloned().collect();\n/// // use the values stored in map\n/// ```\n\n#[cfg_attr(not(test), rustc_diagnostic_item = \"hashmap_type\")]\n#[stable(feature = \"rust1\", since = \"1.0.0\")]\npub struct HashMap<K, V, S = RandomState> {\n    base: base::HashMap<K, V, S>,\n}\n\nimpl<K, V> HashMap<K, V, RandomState> {\n    /// Creates an empty `HashMap`.\n    ///\n    /// The hash map is initially created with a capacity of 0, so it will not allocate until it\n    /// is first inserted into.\n    ///\n    /// # Examples\n    ///\n    /// ```\n    /// use std::collections::HashMap;\n    /// let mut map: HashMap<&str, i32> = HashMap::new();\n    /// ```\n    #[inline]\n    #[stable(feature = \"rust1\", since = \"1.0.0\")]\n    pub fn new() -> HashMap<K, V, RandomState> {\n        Default::default()\n    }\n\n    /// Creates an empty `HashMap` with the specified capacity.\n    ///\n    /// The hash map will be able to hold at least `capacity` elements without\n    /// reallocating. If `capacity` is 0, the hash map will not allocate.\n    ///\n    /// # Examples\n    ///\n    /// ```\n    /// use std::collections::HashMap;\n    /// let mut map: HashMap<&str, i32> = HashMap::with_capacity(10);\n    /// ```\n    #[inline]\n    #[stable(feature = \"rust1\", since = \"1.0.0\")]\n    pub fn with_capacity(capacity: usize) -> HashMap<K, V, RandomState> {\n        HashMap::with_capacity_and_hasher(capacity, Default::default())\n    }\n}\n\nimpl<K, V, S> HashMap<K, V, S> {\n    /// Creates an empty `HashMap` which will use the given hash builder to hash\n    /// keys.\n    ///\n    /// The created map has the default initial capacity.\n    ///\n    /// Warning: `hash_builder` is normally randomly generated, and\n    /// is designed to allow HashMaps to be resistant to attacks that\n    /// cause many collisions and very poor performance. Setting it\n    /// manually using this function can expose a DoS attack vector.\n    ///\n    /// The `hash_builder` passed should implement the [`BuildHasher`] trait for\n    /// the HashMap to be useful, see its documentation for details.\n    ///\n    /// # Examples\n    ///\n    /// ```\n    /// use std::collections::HashMap;\n    /// use std::collections::hash_map::RandomState;\n    ///\n    /// let s = RandomState::new();\n    /// let mut map = HashMap::with_hasher(s);\n    /// map.insert(1, 2);\n    /// ```\n    #[inline]\n    #[stable(feature = \"hashmap_build_hasher\", since = \"1.7.0\")]\n    pub fn with_hasher(hash_builder: S) -> HashMap<K, V, S> {\n        HashMap { base: base::HashMap::with_hasher(hash_builder) }\n    }\n\n    /// Creates an empty `HashMap` with the specified capacity, using `hash_builder`\n    /// to hash the keys.\n    ///\n    /// The hash map will be able to hold at least `capacity` elements without\n    /// reallocating. If `capacity` is 0, the hash map will not allocate.\n    ///\n    /// Warning: `hash_builder` is normally randomly generated, and\n    /// is designed to allow HashMaps to be resistant to attacks that\n    /// cause many collisions and very poor performance. Setting it\n    /// manually using this function can expose a DoS attack vector.\n    ///\n    /// The `hash_builder` passed should implement the [`BuildHasher`] trait for\n    /// the HashMap to be useful, see its documentation for details.\n    ///\n    /// # Examples\n    ///\n    /// ```\n    /// use std::collections::HashMap;\n    /// use std::collections::hash_map::RandomState;\n    ///\n    /// let s = RandomState::new();\n    /// let mut map = HashMap::with_capacity_and_hasher(10, s);\n    /// map.insert(1, 2);\n    /// ```\n    #[inline]\n    #[stable(feature = \"hashmap_build_hasher\", since = \"1.7.0\")]\n    pub fn with_capacity_and_hasher(capacity: usize, hash_builder: S) -> HashMap<K, V, S> {\n        HashMap { base: base::HashMap::with_capacity_and_hasher(capacity, hash_builder) }\n    }\n\n    /// Returns the number of elements the map can hold without reallocating.\n    ///\n    /// This number is a lower bound; the `HashMap<K, V>` might be able to hold\n    /// more, but is guaranteed to be able to hold at least this many.\n    ///\n    /// # Examples\n    ///\n    /// ```\n    /// use std::collections::HashMap;\n    /// let map: HashMap<i32, i32> = HashMap::with_capacity(100);\n    /// assert!(map.capacity() >= 100);\n    /// ```\n    #[inline]\n    #[stable(feature = \"rust1\", since = \"1.0.0\")]\n    pub fn capacity(&self) -> usize {\n        self.base.capacity()\n    }\n\n    /// An iterator visiting all keys in arbitrary order.\n    /// The iterator element type is `&'a K`.\n    ///\n    /// # Examples\n    ///\n    /// ```\n    /// use std::collections::HashMap;\n    ///\n    /// let mut map = HashMap::new();\n    /// map.insert(\"a\", 1);\n    /// map.insert(\"b\", 2);\n    /// map.insert(\"c\", 3);\n    ///\n    /// for key in map.keys() {\n    ///     println!(\"{}\", key);\n    /// }\n    /// ```\n    #[stable(feature = \"rust1\", since = \"1.0.0\")]\n    pub fn keys(&self) -> Keys<'_, K, V> {\n        Keys { inner: self.iter() }\n    }\n\n    /// An iterator visiting all values in arbitrary order.\n    /// The iterator element type is `&'a V`.\n    ///\n    /// # Examples\n    ///\n    /// ```\n    /// use std::collections::HashMap;\n    ///\n    /// let mut map = HashMap::new();\n    /// map.insert(\"a\", 1);\n    /// map.insert(\"b\", 2);\n    /// map.insert(\"c\", 3);\n    ///\n    /// for val in map.values() {\n    ///     println!(\"{}\", val);\n    /// }\n    /// ```\n    #[stable(feature = \"rust1\", since = \"1.0.0\")]\n    pub fn values(&self) -> Values<'_, K, V> {\n        Values { inner: self.iter() }\n    }\n\n    /// An iterator visiting all values mutably in arbitrary order.\n    /// The iterator element type is `&'a mut V`.\n    ///\n    /// # Examples\n    ///\n    /// ```\n    /// use std::collections::HashMap;\n    ///\n    /// let mut map = HashMap::new();\n    ///\n    /// map.insert(\"a\", 1);\n    /// map.insert(\"b\", 2);\n    /// map.insert(\"c\", 3);\n    ///\n    /// for val in map.values_mut() {\n    ///     *val = *val + 10;\n    /// }\n    ///\n    /// for val in map.values() {\n    ///     println!(\"{}\", val);\n    /// }\n    /// ```\n    #[stable(feature = \"map_values_mut\", since = \"1.10.0\")]\n    pub fn values_mut(&mut self) -> ValuesMut<'_, K, V> {\n        ValuesMut { inner: self.iter_mut() }\n    }\n\n    /// An iterator visiting all key-value pairs in arbitrary order.\n    /// The iterator element type is `(&'a K, &'a V)`.\n    ///\n    /// # Examples\n    ///\n    /// ```\n    /// use std::collections::HashMap;\n    ///\n    /// let mut map = HashMap::new();\n    /// map.insert(\"a\", 1);\n    /// map.insert(\"b\", 2);\n    /// map.insert(\"c\", 3);\n    ///\n    /// for (key, val) in map.iter() {\n    ///     println!(\"key: {} val: {}\", key, val);\n    /// }\n    /// ```\n    #[stable(feature = \"rust1\", since = \"1.0.0\")]\n    pub fn iter(&self) -> Iter<'_, K, V> {\n        Iter { base: self.base.iter() }\n    }\n\n    /// An iterator visiting all key-value pairs in arbitrary order,\n    /// with mutable references to the values.\n    /// The iterator element type is `(&'a K, &'a mut V)`.\n    ///\n    /// # Examples\n    ///\n    /// ```\n    /// use std::collections::HashMap;\n    ///\n    /// let mut map = HashMap::new();\n    /// map.insert(\"a\", 1);\n    /// map.insert(\"b\", 2);\n    /// map.insert(\"c\", 3);\n    ///\n    /// // Update all values\n    /// for (_, val) in map.iter_mut() {\n    ///     *val *= 2;\n    /// }\n    ///\n    /// for (key, val) in &map {\n    ///     println!(\"key: {} val: {}\", key, val);\n    /// }\n    /// ```\n    #[stable(feature = \"rust1\", since = \"1.0.0\")]\n    pub fn iter_mut(&mut self) -> IterMut<'_, K, V> {\n        IterMut { base: self.base.iter_mut() }\n    }\n\n    /// Returns the number of elements in the map.\n    ///\n    /// # Examples\n    ///\n    /// ```\n    /// use std::collections::HashMap;\n    ///\n    /// let mut a = HashMap::new();\n    /// assert_eq!(a.len(), 0);\n    /// a.insert(1, \"a\");\n    /// assert_eq!(a.len(), 1);\n    /// ```\n    #[doc(alias = \"length\")]\n    #[stable(feature = \"rust1\", since = \"1.0.0\")]\n    pub fn len(&self) -> usize {\n        self.base.len()\n    }\n\n    /// Returns `true` if the map contains no elements.\n    ///\n    /// # Examples\n    ///\n    /// ```\n    /// use std::collections::HashMap;\n    ///\n    /// let mut a = HashMap::new();\n    /// assert!(a.is_empty());\n    /// a.insert(1, \"a\");\n    /// assert!(!a.is_empty());\n    /// ```\n    #[inline]\n    #[stable(feature = \"rust1\", since = \"1.0.0\")]\n    pub fn is_empty(&self) -> bool {\n        self.base.is_empty()\n    }\n\n    /// Clears the map, returning all key-value pairs as an iterator. Keeps the\n    /// allocated memory for reuse.\n    ///\n    /// # Examples\n    ///\n    /// ```\n    /// use std::collections::HashMap;\n    ///\n    /// let mut a = HashMap::new();\n    /// a.insert(1, \"a\");\n    /// a.insert(2, \"b\");\n    ///\n    /// for (k, v) in a.drain().take(1) {\n    ///     assert!(k == 1 || k == 2);\n    ///     assert!(v == \"a\" || v == \"b\");\n    /// }\n    ///\n    /// assert!(a.is_empty());\n    /// ```\n    #[inline]\n    #[stable(feature = \"drain\", since = \"1.6.0\")]\n    pub fn drain(&mut self) -> Drain<'_, K, V> {\n        Drain { base: self.base.drain() }\n    }\n\n    /// Creates an iterator which uses a closure to determine if an element should be removed.\n    ///\n    /// If the closure returns true, the element is removed from the map and yielded.\n    /// If the closure returns false, or panics, the element remains in the map and will not be\n    /// yielded.\n    ///\n    /// Note that `drain_filter` lets you mutate every value in the filter closure, regardless of\n    /// whether you choose to keep or remove it.\n    ///\n    /// If the iterator is only partially consumed or not consumed at all, each of the remaining\n    /// elements will still be subjected to the closure and removed and dropped if it returns true.\n    ///\n    /// It is unspecified how many more elements will be subjected to the closure\n    /// if a panic occurs in the closure, or a panic occurs while dropping an element,\n    /// or if the `DrainFilter` value is leaked.\n    ///\n    /// # Examples\n    ///\n    /// Splitting a map into even and odd keys, reusing the original map:\n    ///\n    /// ```\n    /// #![feature(hash_drain_filter)]\n    /// use std::collections::HashMap;\n    ///\n    /// let mut map: HashMap<i32, i32> = (0..8).map(|x| (x, x)).collect();\n    /// let drained: HashMap<i32, i32> = map.drain_filter(|k, _v| k % 2 == 0).collect();\n    ///\n    /// let mut evens = drained.keys().copied().collect::<Vec<_>>();\n    /// let mut odds = map.keys().copied().collect::<Vec<_>>();\n    /// evens.sort();\n    /// odds.sort();\n    ///\n    /// assert_eq!(evens, vec![0, 2, 4, 6]);\n    /// assert_eq!(odds, vec![1, 3, 5, 7]);\n    /// ```\n    #[inline]\n    #[unstable(feature = \"hash_drain_filter\", issue = \"59618\")]\n    pub fn drain_filter<F>(&mut self, pred: F) -> DrainFilter<'_, K, V, F>\n    where\n        F: FnMut(&K, &mut V) -> bool,\n    {\n        DrainFilter { base: self.base.drain_filter(pred) }\n    }\n\n    /// Clears the map, removing all key-value pairs. Keeps the allocated memory\n    /// for reuse.\n    ///\n    /// # Examples\n    ///\n    /// ```\n    /// use std::collections::HashMap;\n    ///\n    /// let mut a = HashMap::new();\n    /// a.insert(1, \"a\");\n    /// a.clear();\n    /// assert!(a.is_empty());\n    /// ```\n    #[inline]\n    #[stable(feature = \"rust1\", since = \"1.0.0\")]\n    pub fn clear(&mut self) {\n        self.base.clear();\n    }\n\n    /// Returns a reference to the map's [`BuildHasher`].\n    ///\n    /// # Examples\n    ///\n    /// ```\n    /// use std::collections::HashMap;\n    /// use std::collections::hash_map::RandomState;\n    ///\n    /// let hasher = RandomState::new();\n    /// let map: HashMap<i32, i32> = HashMap::with_hasher(hasher);\n    /// let hasher: &RandomState = map.hasher();\n    /// ```\n    #[inline]\n    #[stable(feature = \"hashmap_public_hasher\", since = \"1.9.0\")]\n    pub fn hasher(&self) -> &S {\n        self.base.hasher()\n    }\n}\n\nimpl<K, V, S> HashMap<K, V, S>\nwhere\n    K: Eq + Hash,\n    S: BuildHasher,\n{\n    /// Reserves capacity for at least `additional` more elements to be inserted\n    /// in the `HashMap`. The collection may reserve more space to avoid\n    /// frequent reallocations.\n    ///\n    /// # Panics\n    ///\n    /// Panics if the new allocation size overflows [`usize`].\n    ///\n    /// # Examples\n    ///\n    /// ```\n    /// use std::collections::HashMap;\n    /// let mut map: HashMap<&str, i32> = HashMap::new();\n    /// map.reserve(10);\n    /// ```\n    #[inline]\n    #[stable(feature = \"rust1\", since = \"1.0.0\")]\n    pub fn reserve(&mut self, additional: usize) {\n        self.base.reserve(additional)\n    }\n\n    /// Tries to reserve capacity for at least `additional` more elements to be inserted\n    /// in the given `HashMap<K, V>`. The collection may reserve more space to avoid\n    /// frequent reallocations.\n    ///\n    /// # Errors\n    ///\n    /// If the capacity overflows, or the allocator reports a failure, then an error\n    /// is returned.\n    ///\n    /// # Examples\n    ///\n    /// ```\n    /// #![feature(try_reserve)]\n    /// use std::collections::HashMap;\n    ///\n    /// let mut map: HashMap<&str, isize> = HashMap::new();\n    /// map.try_reserve(10).expect(\"why is the test harness OOMing on 10 bytes?\");\n    /// ```\n    #[inline]\n    #[unstable(feature = \"try_reserve\", reason = \"new API\", issue = \"48043\")]\n    pub fn try_reserve(&mut self, additional: usize) -> Result<(), TryReserveError> {\n        self.base.try_reserve(additional).map_err(map_try_reserve_error)\n    }\n\n    /// Shrinks the capacity of the map as much as possible. It will drop\n    /// down as much as possible while maintaining the internal rules\n    /// and possibly leaving some space in accordance with the resize policy.\n    ///\n    /// # Examples\n    ///\n    /// ```\n    /// use std::collections::HashMap;\n    ///\n    /// let mut map: HashMap<i32, i32> = HashMap::with_capacity(100);\n    /// map.insert(1, 2);\n    /// map.insert(3, 4);\n    /// assert!(map.capacity() >= 100);\n    /// map.shrink_to_fit();\n    /// assert!(map.capacity() >= 2);\n    /// ```\n    #[inline]\n    #[stable(feature = \"rust1\", since = \"1.0.0\")]\n    pub fn shrink_to_fit(&mut self) {\n        self.base.shrink_to_fit();\n    }\n\n    /// Shrinks the capacity of the map with a lower limit. It will drop\n    /// down no lower than the supplied limit while maintaining the internal rules\n    /// and possibly leaving some space in accordance with the resize policy.\n    ///\n    /// If the current capacity is less than the lower limit, this is a no-op.\n    ///\n    /// # Examples\n    ///\n    /// ```\n    /// #![feature(shrink_to)]\n    /// use std::collections::HashMap;\n    ///\n    /// let mut map: HashMap<i32, i32> = HashMap::with_capacity(100);\n    /// map.insert(1, 2);\n    /// map.insert(3, 4);\n    /// assert!(map.capacity() >= 100);\n    /// map.shrink_to(10);\n    /// assert!(map.capacity() >= 10);\n    /// map.shrink_to(0);\n    /// assert!(map.capacity() >= 2);\n    /// ```\n    #[inline]\n    #[unstable(feature = \"shrink_to\", reason = \"new API\", issue = \"56431\")]\n    pub fn shrink_to(&mut self, min_capacity: usize) {\n        self.base.shrink_to(min_capacity);\n    }\n\n    /// Gets the given key's corresponding entry in the map for in-place manipulation.\n    ///\n    /// # Examples\n    ///\n    /// ```\n    /// use std::collections::HashMap;\n    ///\n    /// let mut letters = HashMap::new();\n    ///\n    /// for ch in \"a short treatise on fungi\".chars() {\n    ///     let counter = letters.entry(ch).or_insert(0);\n    ///     *counter += 1;\n    /// }\n    ///\n    /// assert_eq!(letters[&'s'], 2);\n    /// assert_eq!(letters[&'t'], 3);\n    /// assert_eq!(letters[&'u'], 1);\n    /// assert_eq!(letters.get(&'y'), None);\n    /// ```\n    #[inline]\n    #[stable(feature = \"rust1\", since = \"1.0.0\")]\n    pub fn entry(&mut self, key: K) -> Entry<'_, K, V> {\n        map_entry(self.base.rustc_entry(key))\n    }\n\n    /// Returns a reference to the value corresponding to the key.\n    ///\n    /// The key may be any borrowed form of the map's key type, but\n    /// [`Hash`] and [`Eq`] on the borrowed form *must* match those for\n    /// the key type.\n    ///\n    /// # Examples\n    ///\n    /// ```\n    /// use std::collections::HashMap;\n    ///\n    /// let mut map = HashMap::new();\n    /// map.insert(1, \"a\");\n    /// assert_eq!(map.get(&1), Some(&\"a\"));\n    /// assert_eq!(map.get(&2), None);\n    /// ```\n    #[stable(feature = \"rust1\", since = \"1.0.0\")]\n    #[inline]\n    pub fn get<Q: ?Sized>(&self, k: &Q) -> Option<&V>\n    where\n        K: Borrow<Q>,\n        Q: Hash + Eq,\n    {\n        self.base.get(k)\n    }\n\n    /// Returns the key-value pair corresponding to the supplied key.\n    ///\n    /// The supplied key may be any borrowed form of the map's key type, but\n    /// [`Hash`] and [`Eq`] on the borrowed form *must* match those for\n    /// the key type.\n    ///\n    /// # Examples\n    ///\n    /// ```\n    /// use std::collections::HashMap;\n    ///\n    /// let mut map = HashMap::new();\n    /// map.insert(1, \"a\");\n    /// assert_eq!(map.get_key_value(&1), Some((&1, &\"a\")));\n    /// assert_eq!(map.get_key_value(&2), None);\n    /// ```\n    #[inline]\n    #[stable(feature = \"map_get_key_value\", since = \"1.40.0\")]\n    pub fn get_key_value<Q: ?Sized>(&self, k: &Q) -> Option<(&K, &V)>\n    where\n        K: Borrow<Q>,\n        Q: Hash + Eq,\n    {\n        self.base.get_key_value(k)\n    }\n\n    /// Returns `true` if the map contains a value for the specified key.\n    ///\n    /// The key may be any borrowed form of the map's key type, but\n    /// [`Hash`] and [`Eq`] on the borrowed form *must* match those for\n    /// the key type.\n    ///\n    /// # Examples\n    ///\n    /// ```\n    /// use std::collections::HashMap;\n    ///\n    /// let mut map = HashMap::new();\n    /// map.insert(1, \"a\");\n    /// assert_eq!(map.contains_key(&1), true);\n    /// assert_eq!(map.contains_key(&2), false);\n    /// ```\n    #[inline]\n    #[stable(feature = \"rust1\", since = \"1.0.0\")]\n    pub fn contains_key<Q: ?Sized>(&self, k: &Q) -> bool\n    where\n        K: Borrow<Q>,\n        Q: Hash + Eq,\n    {\n        self.base.contains_key(k)\n    }\n\n    /// Returns a mutable reference to the value corresponding to the key.\n    ///\n    /// The key may be any borrowed form of the map's key type, but\n    /// [`Hash`] and [`Eq`] on the borrowed form *must* match those for\n    /// the key type.\n    ///\n    /// # Examples\n    ///\n    /// ```\n    /// use std::collections::HashMap;\n    ///\n    /// let mut map = HashMap::new();\n    /// map.insert(1, \"a\");\n    /// if let Some(x) = map.get_mut(&1) {\n    ///     *x = \"b\";\n    /// }\n    /// assert_eq!(map[&1], \"b\");\n    /// ```\n    #[inline]\n    #[stable(feature = \"rust1\", since = \"1.0.0\")]\n    pub fn get_mut<Q: ?Sized>(&mut self, k: &Q) -> Option<&mut V>\n    where\n        K: Borrow<Q>,\n        Q: Hash + Eq,\n    {\n        self.base.get_mut(k)\n    }\n\n    /// Inserts a key-value pair into the map.\n    ///\n    /// If the map did not have this key present, [`None`] is returned.\n    ///\n    /// If the map did have this key present, the value is updated, and the old\n    /// value is returned. The key is not updated, though; this matters for\n    /// types that can be `==` without being identical. See the [module-level\n    /// documentation] for more.\n    ///\n    /// [module-level documentation]: crate::collections#insert-and-complex-keys\n    ///\n    /// # Examples\n    ///\n    /// ```\n    /// use std::collections::HashMap;\n    ///\n    /// let mut map = HashMap::new();\n    /// assert_eq!(map.insert(37, \"a\"), None);\n    /// assert_eq!(map.is_empty(), false);\n    ///\n    /// map.insert(37, \"b\");\n    /// assert_eq!(map.insert(37, \"c\"), Some(\"b\"));\n    /// assert_eq!(map[&37], \"c\");\n    /// ```\n    #[inline]\n    #[stable(feature = \"rust1\", since = \"1.0.0\")]\n    pub fn insert(&mut self, k: K, v: V) -> Option<V> {\n        self.base.insert(k, v)\n    }\n\n    /// Tries to insert a key-value pair into the map, and returns\n    /// a mutable reference to the value in the entry.\n    ///\n    /// If the map already had this key present, nothing is updated, and\n    /// an error containing the occupied entry and the value is returned.\n    ///\n    /// # Examples\n    ///\n    /// Basic usage:\n    ///\n    /// ```\n    /// #![feature(map_try_insert)]\n    ///\n    /// use std::collections::HashMap;\n    ///\n    /// let mut map = HashMap::new();\n    /// assert_eq!(map.try_insert(37, \"a\").unwrap(), &\"a\");\n    ///\n    /// let err = map.try_insert(37, \"b\").unwrap_err();\n    /// assert_eq!(err.entry.key(), &37);\n    /// assert_eq!(err.entry.get(), &\"a\");\n    /// assert_eq!(err.value, \"b\");\n    /// ```\n    #[unstable(feature = \"map_try_insert\", issue = \"82766\")]\n    pub fn try_insert(&mut self, key: K, value: V) -> Result<&mut V, OccupiedError<'_, K, V>> {\n        match self.entry(key) {\n            Occupied(entry) => Err(OccupiedError { entry, value }),\n            Vacant(entry) => Ok(entry.insert(value)),\n        }\n    }\n\n    /// Removes a key from the map, returning the value at the key if the key\n    /// was previously in the map.\n    ///\n    /// The key may be any borrowed form of the map's key type, but\n    /// [`Hash`] and [`Eq`] on the borrowed form *must* match those for\n    /// the key type.\n    ///\n    /// # Examples\n    ///\n    /// ```\n    /// use std::collections::HashMap;\n    ///\n    /// let mut map = HashMap::new();\n    /// map.insert(1, \"a\");\n    /// assert_eq!(map.remove(&1), Some(\"a\"));\n    /// assert_eq!(map.remove(&1), None);\n    /// ```\n    #[doc(alias = \"delete\")]\n    #[inline]\n    #[stable(feature = \"rust1\", since = \"1.0.0\")]\n    pub fn remove<Q: ?Sized>(&mut self, k: &Q) -> Option<V>\n    where\n        K: Borrow<Q>,\n        Q: Hash + Eq,\n    {\n        self.base.remove(k)\n    }\n\n    /// Removes a key from the map, returning the stored key and value if the\n    /// key was previously in the map.\n    ///\n    /// The key may be any borrowed form of the map's key type, but\n    /// [`Hash`] and [`Eq`] on the borrowed form *must* match those for\n    /// the key type.\n    ///\n    /// # Examples\n    ///\n    /// ```\n    /// use std::collections::HashMap;\n    ///\n    /// # fn main() {\n    /// let mut map = HashMap::new();\n    /// map.insert(1, \"a\");\n    /// assert_eq!(map.remove_entry(&1), Some((1, \"a\")));\n    /// assert_eq!(map.remove(&1), None);\n    /// # }\n    /// ```\n    #[inline]\n    #[stable(feature = \"hash_map_remove_entry\", since = \"1.27.0\")]\n    pub fn remove_entry<Q: ?Sized>(&mut self, k: &Q) -> Option<(K, V)>\n    where\n        K: Borrow<Q>,\n        Q: Hash + Eq,\n    {\n        self.base.remove_entry(k)\n    }\n\n    /// Retains only the elements specified by the predicate.\n    ///\n    /// In other words, remove all pairs `(k, v)` such that `f(&k, &mut v)` returns `false`.\n    ///\n    /// # Examples\n    ///\n    /// ```\n    /// use std::collections::HashMap;\n    ///\n    /// let mut map: HashMap<i32, i32> = (0..8).map(|x| (x, x*10)).collect();\n    /// map.retain(|&k, _| k % 2 == 0);\n    /// assert_eq!(map.len(), 4);\n    /// ```\n    #[inline]\n    #[stable(feature = \"retain_hash_collection\", since = \"1.18.0\")]\n    pub fn retain<F>(&mut self, f: F)\n    where\n        F: FnMut(&K, &mut V) -> bool,\n    {\n        self.base.retain(f)\n    }\n\n    /// Creates a consuming iterator visiting all the keys in arbitrary order.\n    /// The map cannot be used after calling this.\n    /// The iterator element type is `K`.\n    ///\n    /// # Examples\n    ///\n    /// ```\n    /// use std::collections::HashMap;\n    ///\n    /// let mut map = HashMap::new();\n    /// map.insert(\"a\", 1);\n    /// map.insert(\"b\", 2);\n    /// map.insert(\"c\", 3);\n    ///\n    /// let vec: Vec<&str> = map.into_keys().collect();\n    /// ```\n    #[inline]\n    #[stable(feature = \"map_into_keys_values\", since = \"1.54.0\")]\n    pub fn into_keys(self) -> IntoKeys<K, V> {\n        IntoKeys { inner: self.into_iter() }\n    }\n\n    /// Creates a consuming iterator visiting all the values in arbitrary order.\n    /// The map cannot be used after calling this.\n    /// The iterator element type is `V`.\n    ///\n    /// # Examples\n    ///\n    /// ```\n    /// use std::collections::HashMap;\n    ///\n    /// let mut map = HashMap::new();\n    /// map.insert(\"a\", 1);\n    /// map.insert(\"b\", 2);\n    /// map.insert(\"c\", 3);\n    ///\n    /// let vec: Vec<i32> = map.into_values().collect();\n    /// ```\n    #[inline]\n    #[stable(feature = \"map_into_keys_values\", since = \"1.54.0\")]\n    pub fn into_values(self) -> IntoValues<K, V> {\n        IntoValues { inner: self.into_iter() }\n    }\n}\n\nimpl<K, V, S> HashMap<K, V, S>\nwhere\n    S: BuildHasher,\n{\n    /// Creates a raw entry builder for the HashMap.\n    ///\n    /// Raw entries provide the lowest level of control for searching and\n    /// manipulating a map. They must be manually initialized with a hash and\n    /// then manually searched. After this, insertions into a vacant entry\n    /// still require an owned key to be provided.\n    ///\n    /// Raw entries are useful for such exotic situations as:\n    ///\n    /// * Hash memoization\n    /// * Deferring the creation of an owned key until it is known to be required\n    /// * Using a search key that doesn't work with the Borrow trait\n    /// * Using custom comparison logic without newtype wrappers\n    ///\n    /// Because raw entries provide much more low-level control, it's much easier\n    /// to put the HashMap into an inconsistent state which, while memory-safe,\n    /// will cause the map to produce seemingly random results. Higher-level and\n    /// more foolproof APIs like `entry` should be preferred when possible.\n    ///\n    /// In particular, the hash used to initialized the raw entry must still be\n    /// consistent with the hash of the key that is ultimately stored in the entry.\n    /// This is because implementations of HashMap may need to recompute hashes\n    /// when resizing, at which point only the keys are available.\n    ///\n    /// Raw entries give mutable access to the keys. This must not be used\n    /// to modify how the key would compare or hash, as the map will not re-evaluate\n    /// where the key should go, meaning the keys may become \"lost\" if their\n    /// location does not reflect their state. For instance, if you change a key\n    /// so that the map now contains keys which compare equal, search may start\n    /// acting erratically, with two keys randomly masking each other. Implementations\n    /// are free to assume this doesn't happen (within the limits of memory-safety).\n    #[inline]\n    #[unstable(feature = \"hash_raw_entry\", issue = \"56167\")]\n    pub fn raw_entry_mut(&mut self) -> RawEntryBuilderMut<'_, K, V, S> {\n        RawEntryBuilderMut { map: self }\n    }\n\n    /// Creates a raw immutable entry builder for the HashMap.\n    ///\n    /// Raw entries provide the lowest level of control for searching and\n    /// manipulating a map. They must be manually initialized with a hash and\n    /// then manually searched.\n    ///\n    /// This is useful for\n    /// * Hash memoization\n    /// * Using a search key that doesn't work with the Borrow trait\n    /// * Using custom comparison logic without newtype wrappers\n    ///\n    /// Unless you are in such a situation, higher-level and more foolproof APIs like\n    /// `get` should be preferred.\n    ///\n    /// Immutable raw entries have very limited use; you might instead want `raw_entry_mut`.\n    #[inline]\n    #[unstable(feature = \"hash_raw_entry\", issue = \"56167\")]\n    pub fn raw_entry(&self) -> RawEntryBuilder<'_, K, V, S> {\n        RawEntryBuilder { map: self }\n    }\n}\n\n#[stable(feature = \"rust1\", since = \"1.0.0\")]\nimpl<K, V, S> Clone for HashMap<K, V, S>\nwhere\n    K: Clone,\n    V: Clone,\n    S: Clone,\n{\n    #[inline]\n    fn clone(&self) -> Self {\n        Self { base: self.base.clone() }\n    }\n\n    #[inline]\n    fn clone_from(&mut self, other: &Self) {\n        self.base.clone_from(&other.base);\n    }\n}\n\n#[stable(feature = \"rust1\", since = \"1.0.0\")]\nimpl<K, V, S> PartialEq for HashMap<K, V, S>\nwhere\n    K: Eq + Hash,\n    V: PartialEq,\n    S: BuildHasher,\n{\n    fn eq(&self, other: &HashMap<K, V, S>) -> bool {\n        if self.len() != other.len() {\n            return false;\n        }\n\n        self.iter().all(|(key, value)| other.get(key).map_or(false, |v| *value == *v))\n    }\n}\n\n#[stable(feature = \"rust1\", since = \"1.0.0\")]\nimpl<K, V, S> Eq for HashMap<K, V, S>\nwhere\n    K: Eq + Hash,\n    V: Eq,\n    S: BuildHasher,\n{\n}\n\n#[stable(feature = \"rust1\", since = \"1.0.0\")]\nimpl<K, V, S> Debug for HashMap<K, V, S>\nwhere\n    K: Debug,\n    V: Debug,\n{\n    fn fmt(&self, f: &mut fmt::Formatter<'_>) -> fmt::Result {\n        f.debug_map().entries(self.iter()).finish()\n    }\n}\n\n#[stable(feature = \"rust1\", since = \"1.0.0\")]\nimpl<K, V, S> Default for HashMap<K, V, S>\nwhere\n    S: Default,\n{\n    /// Creates an empty `HashMap<K, V, S>`, with the `Default` value for the hasher.\n    #[inline]\n    fn default() -> HashMap<K, V, S> {\n        HashMap::with_hasher(Default::default())\n    }\n}\n\n#[stable(feature = \"rust1\", since = \"1.0.0\")]\nimpl<K, Q: ?Sized, V, S> Index<&Q> for HashMap<K, V, S>\nwhere\n    K: Eq + Hash + Borrow<Q>,\n    Q: Eq + Hash,\n    S: BuildHasher,\n{\n    type Output = V;\n\n    /// Returns a reference to the value corresponding to the supplied key.\n    ///\n    /// # Panics\n    ///\n    /// Panics if the key is not present in the `HashMap`.\n    #[inline]\n    fn index(&self, key: &Q) -> &V {\n        self.get(key).expect(\"no entry found for key\")\n    }\n}\n\n/// An iterator over the entries of a `HashMap`.\n///\n/// This `struct` is created by the [`iter`] method on [`HashMap`]. See its\n/// documentation for more.\n///\n/// [`iter`]: HashMap::iter\n///\n/// # Example\n///\n/// ```\n/// use std::collections::HashMap;\n///\n/// let mut map = HashMap::new();\n/// map.insert(\"a\", 1);\n/// let iter = map.iter();\n/// ```\n#[stable(feature = \"rust1\", since = \"1.0.0\")]\npub struct Iter<'a, K: 'a, V: 'a> {\n    base: base::Iter<'a, K, V>,\n}\n\n// FIXME(#26925) Remove in favor of `#[derive(Clone)]`\n#[stable(feature = \"rust1\", since = \"1.0.0\")]\nimpl<K, V> Clone for Iter<'_, K, V> {\n    #[inline]\n    fn clone(&self) -> Self {\n        Iter { base: self.base.clone() }\n    }\n}\n\n#[stable(feature = \"std_debug\", since = \"1.16.0\")]\nimpl<K: Debug, V: Debug> fmt::Debug for Iter<'_, K, V> {\n    fn fmt(&self, f: &mut fmt::Formatter<'_>) -> fmt::Result {\n        f.debug_list().entries(self.clone()).finish()\n    }\n}\n\n/// A mutable iterator over the entries of a `HashMap`.\n///\n/// This `struct` is created by the [`iter_mut`] method on [`HashMap`]. See its\n/// documentation for more.\n///\n/// [`iter_mut`]: HashMap::iter_mut\n///\n/// # Example\n///\n/// ```\n/// use std::collections::HashMap;\n///\n/// let mut map = HashMap::new();\n/// map.insert(\"a\", 1);\n/// let iter = map.iter_mut();\n/// ```\n#[stable(feature = \"rust1\", since = \"1.0.0\")]\npub struct IterMut<'a, K: 'a, V: 'a> {\n    base: base::IterMut<'a, K, V>,\n}\n\nimpl<'a, K, V> IterMut<'a, K, V> {\n    /// Returns a iterator of references over the remaining items.\n    #[inline]\n    pub(super) fn iter(&self) -> Iter<'_, K, V> {\n        Iter { base: self.base.rustc_iter() }\n    }\n}\n\n/// An owning iterator over the entries of a `HashMap`.\n///\n/// This `struct` is created by the [`into_iter`] method on [`HashMap`]\n/// (provided by the `IntoIterator` trait). See its documentation for more.\n///\n/// [`into_iter`]: IntoIterator::into_iter\n///\n/// # Example\n///\n/// ```\n/// use std::collections::HashMap;\n///\n/// let mut map = HashMap::new();\n/// map.insert(\"a\", 1);\n/// let iter = map.into_iter();\n/// ```\n#[stable(feature = \"rust1\", since = \"1.0.0\")]\npub struct IntoIter<K, V> {\n    base: base::IntoIter<K, V>,\n}\n\nimpl<K, V> IntoIter<K, V> {\n    /// Returns a iterator of references over the remaining items.\n    #[inline]\n    pub(super) fn iter(&self) -> Iter<'_, K, V> {\n        Iter { base: self.base.rustc_iter() }\n    }\n}\n\n/// An iterator over the keys of a `HashMap`.\n///\n/// This `struct` is created by the [`keys`] method on [`HashMap`]. See its\n/// documentation for more.\n///\n/// [`keys`]: HashMap::keys\n///\n/// # Example\n///\n/// ```\n/// use std::collections::HashMap;\n///\n/// let mut map = HashMap::new();\n/// map.insert(\"a\", 1);\n/// let iter_keys = map.keys();\n/// ```\n#[stable(feature = \"rust1\", since = \"1.0.0\")]\npub struct Keys<'a, K: 'a, V: 'a> {\n    inner: Iter<'a, K, V>,\n}\n\n// FIXME(#26925) Remove in favor of `#[derive(Clone)]`\n#[stable(feature = \"rust1\", since = \"1.0.0\")]\nimpl<K, V> Clone for Keys<'_, K, V> {\n    #[inline]\n    fn clone(&self) -> Self {\n        Keys { inner: self.inner.clone() }\n    }\n}\n\n#[stable(feature = \"std_debug\", since = \"1.16.0\")]\nimpl<K: Debug, V> fmt::Debug for Keys<'_, K, V> {\n    fn fmt(&self, f: &mut fmt::Formatter<'_>) -> fmt::Result {\n        f.debug_list().entries(self.clone()).finish()\n    }\n}\n\n/// An iterator over the values of a `HashMap`.\n///\n/// This `struct` is created by the [`values`] method on [`HashMap`]. See its\n/// documentation for more.\n///\n/// [`values`]: HashMap::values\n///\n/// # Example\n///\n/// ```\n/// use std::collections::HashMap;\n///\n/// let mut map = HashMap::new();\n/// map.insert(\"a\", 1);\n/// let iter_values = map.values();\n/// ```\n#[stable(feature = \"rust1\", since = \"1.0.0\")]\npub struct Values<'a, K: 'a, V: 'a> {\n    inner: Iter<'a, K, V>,\n}\n\n// FIXME(#26925) Remove in favor of `#[derive(Clone)]`\n#[stable(feature = \"rust1\", since = \"1.0.0\")]\nimpl<K, V> Clone for Values<'_, K, V> {\n    #[inline]\n    fn clone(&self) -> Self {\n        Values { inner: self.inner.clone() }\n    }\n}\n\n#[stable(feature = \"std_debug\", since = \"1.16.0\")]\nimpl<K, V: Debug> fmt::Debug for Values<'_, K, V> {\n    fn fmt(&self, f: &mut fmt::Formatter<'_>) -> fmt::Result {\n        f.debug_list().entries(self.clone()).finish()\n    }\n}\n\n/// A draining iterator over the entries of a `HashMap`.\n///\n/// This `struct` is created by the [`drain`] method on [`HashMap`]. See its\n/// documentation for more.\n///\n/// [`drain`]: HashMap::drain\n///\n/// # Example\n///\n/// ```\n/// use std::collections::HashMap;\n///\n/// let mut map = HashMap::new();\n/// map.insert(\"a\", 1);\n/// let iter = map.drain();\n/// ```\n#[stable(feature = \"drain\", since = \"1.6.0\")]\npub struct Drain<'a, K: 'a, V: 'a> {\n    base: base::Drain<'a, K, V>,\n}\n\nimpl<'a, K, V> Drain<'a, K, V> {\n    /// Returns a iterator of references over the remaining items.\n    #[inline]\n    pub(super) fn iter(&self) -> Iter<'_, K, V> {\n        Iter { base: self.base.rustc_iter() }\n    }\n}\n\n/// A draining, filtering iterator over the entries of a `HashMap`.\n///\n/// This `struct` is created by the [`drain_filter`] method on [`HashMap`].\n///\n/// [`drain_filter`]: HashMap::drain_filter\n///\n/// # Example\n///\n/// ```\n/// #![feature(hash_drain_filter)]\n///\n/// use std::collections::HashMap;\n///\n/// let mut map = HashMap::new();\n/// map.insert(\"a\", 1);\n/// let iter = map.drain_filter(|_k, v| *v % 2 == 0);\n/// ```\n#[unstable(feature = \"hash_drain_filter\", issue = \"59618\")]\npub struct DrainFilter<'a, K, V, F>\nwhere\n    F: FnMut(&K, &mut V) -> bool,\n{\n    base: base::DrainFilter<'a, K, V, F>,\n}\n\n/// A mutable iterator over the values of a `HashMap`.\n///\n/// This `struct` is created by the [`values_mut`] method on [`HashMap`]. See its\n/// documentation for more.\n///\n/// [`values_mut`]: HashMap::values_mut\n///\n/// # Example\n///\n/// ```\n/// use std::collections::HashMap;\n///\n/// let mut map = HashMap::new();\n/// map.insert(\"a\", 1);\n/// let iter_values = map.values_mut();\n/// ```\n#[stable(feature = \"map_values_mut\", since = \"1.10.0\")]\npub struct ValuesMut<'a, K: 'a, V: 'a> {\n    inner: IterMut<'a, K, V>,\n}\n\n/// An owning iterator over the keys of a `HashMap`.\n///\n/// This `struct` is created by the [`into_keys`] method on [`HashMap`].\n/// See its documentation for more.\n///\n/// [`into_keys`]: HashMap::into_keys\n///\n/// # Example\n///\n/// ```\n/// use std::collections::HashMap;\n///\n/// let mut map = HashMap::new();\n/// map.insert(\"a\", 1);\n/// let iter_keys = map.into_keys();\n/// ```\n#[stable(feature = \"map_into_keys_values\", since = \"1.54.0\")]\npub struct IntoKeys<K, V> {\n    inner: IntoIter<K, V>,\n}\n\n/// An owning iterator over the values of a `HashMap`.\n///\n/// This `struct` is created by the [`into_values`] method on [`HashMap`].\n/// See its documentation for more.\n///\n/// [`into_values`]: HashMap::into_values\n///\n/// # Example\n///\n/// ```\n/// use std::collections::HashMap;\n///\n/// let mut map = HashMap::new();\n/// map.insert(\"a\", 1);\n/// let iter_keys = map.into_values();\n/// ```\n#[stable(feature = \"map_into_keys_values\", since = \"1.54.0\")]\npub struct IntoValues<K, V> {\n    inner: IntoIter<K, V>,\n}\n\n/// A builder for computing where in a HashMap a key-value pair would be stored.\n///\n/// See the [`HashMap::raw_entry_mut`] docs for usage examples.\n#[unstable(feature = \"hash_raw_entry\", issue = \"56167\")]\npub struct RawEntryBuilderMut<'a, K: 'a, V: 'a, S: 'a> {\n    map: &'a mut HashMap<K, V, S>,\n}\n\n/// A view into a single entry in a map, which may either be vacant or occupied.\n///\n/// This is a lower-level version of [`Entry`].\n///\n/// This `enum` is constructed through the [`raw_entry_mut`] method on [`HashMap`],\n/// then calling one of the methods of that [`RawEntryBuilderMut`].\n///\n/// [`raw_entry_mut`]: HashMap::raw_entry_mut\n#[unstable(feature = \"hash_raw_entry\", issue = \"56167\")]\npub enum RawEntryMut<'a, K: 'a, V: 'a, S: 'a> {\n    /// An occupied entry.\n    Occupied(RawOccupiedEntryMut<'a, K, V, S>),\n    /// A vacant entry.\n    Vacant(RawVacantEntryMut<'a, K, V, S>),\n}\n\n/// A view into an occupied entry in a `HashMap`.\n/// It is part of the [`RawEntryMut`] enum.\n#[unstable(feature = \"hash_raw_entry\", issue = \"56167\")]\npub struct RawOccupiedEntryMut<'a, K: 'a, V: 'a, S: 'a> {\n    base: base::RawOccupiedEntryMut<'a, K, V, S>,\n}\n\n/// A view into a vacant entry in a `HashMap`.\n/// It is part of the [`RawEntryMut`] enum.\n#[unstable(feature = \"hash_raw_entry\", issue = \"56167\")]\npub struct RawVacantEntryMut<'a, K: 'a, V: 'a, S: 'a> {\n    base: base::RawVacantEntryMut<'a, K, V, S>,\n}\n\n/// A builder for computing where in a HashMap a key-value pair would be stored.\n///\n/// See the [`HashMap::raw_entry`] docs for usage examples.\n#[unstable(feature = \"hash_raw_entry\", issue = \"56167\")]\npub struct RawEntryBuilder<'a, K: 'a, V: 'a, S: 'a> {\n    map: &'a HashMap<K, V, S>,\n}\n\nimpl<'a, K, V, S> RawEntryBuilderMut<'a, K, V, S>\nwhere\n    S: BuildHasher,\n{\n    /// Creates a `RawEntryMut` from the given key.\n    #[inline]\n    #[unstable(feature = \"hash_raw_entry\", issue = \"56167\")]\n    pub fn from_key<Q: ?Sized>(self, k: &Q) -> RawEntryMut<'a, K, V, S>\n    where\n        K: Borrow<Q>,\n        Q: Hash + Eq,\n    {\n        map_raw_entry(self.map.base.raw_entry_mut().from_key(k))\n    }\n\n    /// Creates a `RawEntryMut` from the given key and its hash.\n    #[inline]\n    #[unstable(feature = \"hash_raw_entry\", issue = \"56167\")]\n    pub fn from_key_hashed_nocheck<Q: ?Sized>(self, hash: u64, k: &Q) -> RawEntryMut<'a, K, V, S>\n    where\n        K: Borrow<Q>,\n        Q: Eq,\n    {\n        map_raw_entry(self.map.base.raw_entry_mut().from_key_hashed_nocheck(hash, k))\n    }\n\n    /// Creates a `RawEntryMut` from the given hash.\n    #[inline]\n    #[unstable(feature = \"hash_raw_entry\", issue = \"56167\")]\n    pub fn from_hash<F>(self, hash: u64, is_match: F) -> RawEntryMut<'a, K, V, S>\n    where\n        for<'b> F: FnMut(&'b K) -> bool,\n    {\n        map_raw_entry(self.map.base.raw_entry_mut().from_hash(hash, is_match))\n    }\n}\n\nimpl<'a, K, V, S> RawEntryBuilder<'a, K, V, S>\nwhere\n    S: BuildHasher,\n{\n    /// Access an entry by key.\n    #[inline]\n    #[unstable(feature = \"hash_raw_entry\", issue = \"56167\")]\n    pub fn from_key<Q: ?Sized>(self, k: &Q) -> Option<(&'a K, &'a V)>\n    where\n        K: Borrow<Q>,\n        Q: Hash + Eq,\n    {\n        self.map.base.raw_entry().from_key(k)\n    }\n\n    /// Access an entry by a key and its hash.\n    #[inline]\n    #[unstable(feature = \"hash_raw_entry\", issue = \"56167\")]\n    pub fn from_key_hashed_nocheck<Q: ?Sized>(self, hash: u64, k: &Q) -> Option<(&'a K, &'a V)>\n    where\n        K: Borrow<Q>,\n        Q: Hash + Eq,\n    {\n        self.map.base.raw_entry().from_key_hashed_nocheck(hash, k)\n    }\n\n    /// Access an entry by hash.\n    #[inline]\n    #[unstable(feature = \"hash_raw_entry\", issue = \"56167\")]\n    pub fn from_hash<F>(self, hash: u64, is_match: F) -> Option<(&'a K, &'a V)>\n    where\n        F: FnMut(&K) -> bool,\n    {\n        self.map.base.raw_entry().from_hash(hash, is_match)\n    }\n}\n\nimpl<'a, K, V, S> RawEntryMut<'a, K, V, S> {\n    /// Ensures a value is in the entry by inserting the default if empty, and returns\n    /// mutable references to the key and value in the entry.\n    ///\n    /// # Examples\n    ///\n    /// ```\n    /// #![feature(hash_raw_entry)]\n    /// use std::collections::HashMap;\n    ///\n    /// let mut map: HashMap<&str, u32> = HashMap::new();\n    ///\n    /// map.raw_entry_mut().from_key(\"poneyland\").or_insert(\"poneyland\", 3);\n    /// assert_eq!(map[\"poneyland\"], 3);\n    ///\n    /// *map.raw_entry_mut().from_key(\"poneyland\").or_insert(\"poneyland\", 10).1 *= 2;\n    /// assert_eq!(map[\"poneyland\"], 6);\n    /// ```\n    #[inline]\n    #[unstable(feature = \"hash_raw_entry\", issue = \"56167\")]\n    pub fn or_insert(self, default_key: K, default_val: V) -> (&'a mut K, &'a mut V)\n    where\n        K: Hash,\n        S: BuildHasher,\n    {\n        match self {\n            RawEntryMut::Occupied(entry) => entry.into_key_value(),\n            RawEntryMut::Vacant(entry) => entry.insert(default_key, default_val),\n        }\n    }\n\n    /// Ensures a value is in the entry by inserting the result of the default function if empty,\n    /// and returns mutable references to the key and value in the entry.\n    ///\n    /// # Examples\n    ///\n    /// ```\n    /// #![feature(hash_raw_entry)]\n    /// use std::collections::HashMap;\n    ///\n    /// let mut map: HashMap<&str, String> = HashMap::new();\n    ///\n    /// map.raw_entry_mut().from_key(\"poneyland\").or_insert_with(|| {\n    ///     (\"poneyland\", \"hoho\".to_string())\n    /// });\n    ///\n    /// assert_eq!(map[\"poneyland\"], \"hoho\".to_string());\n    /// ```\n    #[inline]\n    #[unstable(feature = \"hash_raw_entry\", issue = \"56167\")]\n    pub fn or_insert_with<F>(self, default: F) -> (&'a mut K, &'a mut V)\n    where\n        F: FnOnce() -> (K, V),\n        K: Hash,\n        S: BuildHasher,\n    {\n        match self {\n            RawEntryMut::Occupied(entry) => entry.into_key_value(),\n            RawEntryMut::Vacant(entry) => {\n                let (k, v) = default();\n                entry.insert(k, v)\n            }\n        }\n    }\n\n    /// Provides in-place mutable access to an occupied entry before any\n    /// potential inserts into the map.\n    ///\n    /// # Examples\n    ///\n    /// ```\n    /// #![feature(hash_raw_entry)]\n    /// use std::collections::HashMap;\n    ///\n    /// let mut map: HashMap<&str, u32> = HashMap::new();\n    ///\n    /// map.raw_entry_mut()\n    ///    .from_key(\"poneyland\")\n    ///    .and_modify(|_k, v| { *v += 1 })\n    ///    .or_insert(\"poneyland\", 42);\n    /// assert_eq!(map[\"poneyland\"], 42);\n    ///\n    /// map.raw_entry_mut()\n    ///    .from_key(\"poneyland\")\n    ///    .and_modify(|_k, v| { *v += 1 })\n    ///    .or_insert(\"poneyland\", 0);\n    /// assert_eq!(map[\"poneyland\"], 43);\n    /// ```\n    #[inline]\n    #[unstable(feature = \"hash_raw_entry\", issue = \"56167\")]\n    pub fn and_modify<F>(self, f: F) -> Self\n    where\n        F: FnOnce(&mut K, &mut V),\n    {\n        match self {\n            RawEntryMut::Occupied(mut entry) => {\n                {\n                    let (k, v) = entry.get_key_value_mut();\n                    f(k, v);\n                }\n                RawEntryMut::Occupied(entry)\n            }\n            RawEntryMut::Vacant(entry) => RawEntryMut::Vacant(entry),\n        }\n    }\n}\n\nimpl<'a, K, V, S> RawOccupiedEntryMut<'a, K, V, S> {\n    /// Gets a reference to the key in the entry.\n    #[inline]\n    #[unstable(feature = \"hash_raw_entry\", issue = \"56167\")]\n    pub fn key(&self) -> &K {\n        self.base.key()\n    }\n\n    /// Gets a mutable reference to the key in the entry.\n    #[inline]\n    #[unstable(feature = \"hash_raw_entry\", issue = \"56167\")]\n    pub fn key_mut(&mut self) -> &mut K {\n        self.base.key_mut()\n    }\n\n    /// Converts the entry into a mutable reference to the key in the entry\n    /// with a lifetime bound to the map itself.\n    #[inline]\n    #[unstable(feature = \"hash_raw_entry\", issue = \"56167\")]\n    pub fn into_key(self) -> &'a mut K {\n        self.base.into_key()\n    }\n\n    /// Gets a reference to the value in the entry.\n    #[inline]\n    #[unstable(feature = \"hash_raw_entry\", issue = \"56167\")]\n    pub fn get(&self) -> &V {\n        self.base.get()\n    }\n\n    /// Converts the `OccupiedEntry` into a mutable reference to the value in the entry\n    /// with a lifetime bound to the map itself.\n    #[inline]\n    #[unstable(feature = \"hash_raw_entry\", issue = \"56167\")]\n    pub fn into_mut(self) -> &'a mut V {\n        self.base.into_mut()\n    }\n\n    /// Gets a mutable reference to the value in the entry.\n    #[inline]\n    #[unstable(feature = \"hash_raw_entry\", issue = \"56167\")]\n    pub fn get_mut(&mut self) -> &mut V {\n        self.base.get_mut()\n    }\n\n    /// Gets a reference to the key and value in the entry.\n    #[inline]\n    #[unstable(feature = \"hash_raw_entry\", issue = \"56167\")]\n    pub fn get_key_value(&mut self) -> (&K, &V) {\n        self.base.get_key_value()\n    }\n\n    /// Gets a mutable reference to the key and value in the entry.\n    #[inline]\n    #[unstable(feature = \"hash_raw_entry\", issue = \"56167\")]\n    pub fn get_key_value_mut(&mut self) -> (&mut K, &mut V) {\n        self.base.get_key_value_mut()\n    }\n\n    /// Converts the `OccupiedEntry` into a mutable reference to the key and value in the entry\n    /// with a lifetime bound to the map itself.\n    #[inline]\n    #[unstable(feature = \"hash_raw_entry\", issue = \"56167\")]\n    pub fn into_key_value(self) -> (&'a mut K, &'a mut V) {\n        self.base.into_key_value()\n    }\n\n    /// Sets the value of the entry, and returns the entry's old value.\n    #[inline]\n    #[unstable(feature = \"hash_raw_entry\", issue = \"56167\")]\n    pub fn insert(&mut self, value: V) -> V {\n        self.base.insert(value)\n    }\n\n    /// Sets the value of the entry, and returns the entry's old value.\n    #[inline]\n    #[unstable(feature = \"hash_raw_entry\", issue = \"56167\")]\n    pub fn insert_key(&mut self, key: K) -> K {\n        self.base.insert_key(key)\n    }\n\n    /// Takes the value out of the entry, and returns it.\n    #[inline]\n    #[unstable(feature = \"hash_raw_entry\", issue = \"56167\")]\n    pub fn remove(self) -> V {\n        self.base.remove()\n    }\n\n    /// Take the ownership of the key and value from the map.\n    #[inline]\n    #[unstable(feature = \"hash_raw_entry\", issue = \"56167\")]\n    pub fn remove_entry(self) -> (K, V) {\n        self.base.remove_entry()\n    }\n}\n\nimpl<'a, K, V, S> RawVacantEntryMut<'a, K, V, S> {\n    /// Sets the value of the entry with the `VacantEntry`'s key,\n    /// and returns a mutable reference to it.\n    #[inline]\n    #[unstable(feature = \"hash_raw_entry\", issue = \"56167\")]\n    pub fn insert(self, key: K, value: V) -> (&'a mut K, &'a mut V)\n    where\n        K: Hash,\n        S: BuildHasher,\n    {\n        self.base.insert(key, value)\n    }\n\n    /// Sets the value of the entry with the VacantEntry's key,\n    /// and returns a mutable reference to it.\n    #[inline]\n    #[unstable(feature = \"hash_raw_entry\", issue = \"56167\")]\n    pub fn insert_hashed_nocheck(self, hash: u64, key: K, value: V) -> (&'a mut K, &'a mut V)\n    where\n        K: Hash,\n        S: BuildHasher,\n    {\n        self.base.insert_hashed_nocheck(hash, key, value)\n    }\n}\n\n#[unstable(feature = \"hash_raw_entry\", issue = \"56167\")]\nimpl<K, V, S> Debug for RawEntryBuilderMut<'_, K, V, S> {\n    fn fmt(&self, f: &mut fmt::Formatter<'_>) -> fmt::Result {\n        f.debug_struct(\"RawEntryBuilder\").finish_non_exhaustive()\n    }\n}\n\n#[unstable(feature = \"hash_raw_entry\", issue = \"56167\")]\nimpl<K: Debug, V: Debug, S> Debug for RawEntryMut<'_, K, V, S> {\n    fn fmt(&self, f: &mut fmt::Formatter<'_>) -> fmt::Result {\n        match *self {\n            RawEntryMut::Vacant(ref v) => f.debug_tuple(\"RawEntry\").field(v).finish(),\n            RawEntryMut::Occupied(ref o) => f.debug_tuple(\"RawEntry\").field(o).finish(),\n        }\n    }\n}\n\n#[unstable(feature = \"hash_raw_entry\", issue = \"56167\")]\nimpl<K: Debug, V: Debug, S> Debug for RawOccupiedEntryMut<'_, K, V, S> {\n    fn fmt(&self, f: &mut fmt::Formatter<'_>) -> fmt::Result {\n        f.debug_struct(\"RawOccupiedEntryMut\")\n            .field(\"key\", self.key())\n            .field(\"value\", self.get())\n            .finish_non_exhaustive()\n    }\n}\n\n#[unstable(feature = \"hash_raw_entry\", issue = \"56167\")]\nimpl<K, V, S> Debug for RawVacantEntryMut<'_, K, V, S> {\n    fn fmt(&self, f: &mut fmt::Formatter<'_>) -> fmt::Result {\n        f.debug_struct(\"RawVacantEntryMut\").finish_non_exhaustive()\n    }\n}\n\n#[unstable(feature = \"hash_raw_entry\", issue = \"56167\")]\nimpl<K, V, S> Debug for RawEntryBuilder<'_, K, V, S> {\n    fn fmt(&self, f: &mut fmt::Formatter<'_>) -> fmt::Result {\n        f.debug_struct(\"RawEntryBuilder\").finish_non_exhaustive()\n    }\n}\n\n/// A view into a single entry in a map, which may either be vacant or occupied.\n///\n/// This `enum` is constructed from the [`entry`] method on [`HashMap`].\n///\n/// [`entry`]: HashMap::entry\n#[stable(feature = \"rust1\", since = \"1.0.0\")]\npub enum Entry<'a, K: 'a, V: 'a> {\n    /// An occupied entry.\n    #[stable(feature = \"rust1\", since = \"1.0.0\")]\n    Occupied(#[stable(feature = \"rust1\", since = \"1.0.0\")] OccupiedEntry<'a, K, V>),\n\n    /// A vacant entry.\n    #[stable(feature = \"rust1\", since = \"1.0.0\")]\n    Vacant(#[stable(feature = \"rust1\", since = \"1.0.0\")] VacantEntry<'a, K, V>),\n}\n\n#[stable(feature = \"debug_hash_map\", since = \"1.12.0\")]\nimpl<K: Debug, V: Debug> Debug for Entry<'_, K, V> {\n    fn fmt(&self, f: &mut fmt::Formatter<'_>) -> fmt::Result {\n        match *self {\n            Vacant(ref v) => f.debug_tuple(\"Entry\").field(v).finish(),\n            Occupied(ref o) => f.debug_tuple(\"Entry\").field(o).finish(),\n        }\n    }\n}\n\n/// A view into an occupied entry in a `HashMap`.\n/// It is part of the [`Entry`] enum.\n#[stable(feature = \"rust1\", since = \"1.0.0\")]\npub struct OccupiedEntry<'a, K: 'a, V: 'a> {\n    base: base::RustcOccupiedEntry<'a, K, V>,\n}\n\n#[stable(feature = \"debug_hash_map\", since = \"1.12.0\")]\nimpl<K: Debug, V: Debug> Debug for OccupiedEntry<'_, K, V> {\n    fn fmt(&self, f: &mut fmt::Formatter<'_>) -> fmt::Result {\n        f.debug_struct(\"OccupiedEntry\")\n            .field(\"key\", self.key())\n            .field(\"value\", self.get())\n            .finish_non_exhaustive()\n    }\n}\n\n/// A view into a vacant entry in a `HashMap`.\n/// It is part of the [`Entry`] enum.\n#[stable(feature = \"rust1\", since = \"1.0.0\")]\npub struct VacantEntry<'a, K: 'a, V: 'a> {\n    base: base::RustcVacantEntry<'a, K, V>,\n}\n\n#[stable(feature = \"debug_hash_map\", since = \"1.12.0\")]\nimpl<K: Debug, V> Debug for VacantEntry<'_, K, V> {\n    fn fmt(&self, f: &mut fmt::Formatter<'_>) -> fmt::Result {\n        f.debug_tuple(\"VacantEntry\").field(self.key()).finish()\n    }\n}\n\n/// The error returned by [`try_insert`](HashMap::try_insert) when the key already exists.\n///\n/// Contains the occupied entry, and the value that was not inserted.\n#[unstable(feature = \"map_try_insert\", issue = \"82766\")]\npub struct OccupiedError<'a, K: 'a, V: 'a> {\n    /// The entry in the map that was already occupied.\n    pub entry: OccupiedEntry<'a, K, V>,\n    /// The value which was not inserted, because the entry was already occupied.\n    pub value: V,\n}\n\n#[unstable(feature = \"map_try_insert\", issue = \"82766\")]\nimpl<K: Debug, V: Debug> Debug for OccupiedError<'_, K, V> {\n    fn fmt(&self, f: &mut fmt::Formatter<'_>) -> fmt::Result {\n        f.debug_struct(\"OccupiedError\")\n            .field(\"key\", self.entry.key())\n            .field(\"old_value\", self.entry.get())\n            .field(\"new_value\", &self.value)\n            .finish_non_exhaustive()\n    }\n}\n\n#[unstable(feature = \"map_try_insert\", issue = \"82766\")]\nimpl<'a, K: Debug, V: Debug> fmt::Display for OccupiedError<'a, K, V> {\n    fn fmt(&self, f: &mut fmt::Formatter<'_>) -> fmt::Result {\n        write!(\n            f,\n            \"failed to insert {:?}, key {:?} already exists with value {:?}\",\n            self.value,\n            self.entry.key(),\n            self.entry.get(),\n        )\n    }\n}\n\n#[stable(feature = \"rust1\", since = \"1.0.0\")]\nimpl<'a, K, V, S> IntoIterator for &'a HashMap<K, V, S> {\n    type Item = (&'a K, &'a V);\n    type IntoIter = Iter<'a, K, V>;\n\n    #[inline]\n    fn into_iter(self) -> Iter<'a, K, V> {\n        self.iter()\n    }\n}\n\n#[stable(feature = \"rust1\", since = \"1.0.0\")]\nimpl<'a, K, V, S> IntoIterator for &'a mut HashMap<K, V, S> {\n    type Item = (&'a K, &'a mut V);\n    type IntoIter = IterMut<'a, K, V>;\n\n    #[inline]\n    fn into_iter(self) -> IterMut<'a, K, V> {\n        self.iter_mut()\n    }\n}\n\n#[stable(feature = \"rust1\", since = \"1.0.0\")]\nimpl<K, V, S> IntoIterator for HashMap<K, V, S> {\n    type Item = (K, V);\n    type IntoIter = IntoIter<K, V>;\n\n    /// Creates a consuming iterator, that is, one that moves each key-value\n    /// pair out of the map in arbitrary order. The map cannot be used after\n    /// calling this.\n    ///\n    /// # Examples\n    ///\n    /// ```\n    /// use std::collections::HashMap;\n    ///\n    /// let mut map = HashMap::new();\n    /// map.insert(\"a\", 1);\n    /// map.insert(\"b\", 2);\n    /// map.insert(\"c\", 3);\n    ///\n    /// // Not possible with .iter()\n    /// let vec: Vec<(&str, i32)> = map.into_iter().collect();\n    /// ```\n    #[inline]\n    fn into_iter(self) -> IntoIter<K, V> {\n        IntoIter { base: self.base.into_iter() }\n    }\n}\n\n#[stable(feature = \"rust1\", since = \"1.0.0\")]\nimpl<'a, K, V> Iterator for Iter<'a, K, V> {\n    type Item = (&'a K, &'a V);\n\n    #[inline]\n    fn next(&mut self) -> Option<(&'a K, &'a V)> {\n        self.base.next()\n    }\n    #[inline]\n    fn size_hint(&self) -> (usize, Option<usize>) {\n        self.base.size_hint()\n    }\n}\n#[stable(feature = \"rust1\", since = \"1.0.0\")]\nimpl<K, V> ExactSizeIterator for Iter<'_, K, V> {\n    #[inline]\n    fn len(&self) -> usize {\n        self.base.len()\n    }\n}\n\n#[stable(feature = \"fused\", since = \"1.26.0\")]\nimpl<K, V> FusedIterator for Iter<'_, K, V> {}\n\n#[stable(feature = \"rust1\", since = \"1.0.0\")]\nimpl<'a, K, V> Iterator for IterMut<'a, K, V> {\n    type Item = (&'a K, &'a mut V);\n\n    #[inline]\n    fn next(&mut self) -> Option<(&'a K, &'a mut V)> {\n        self.base.next()\n    }\n    #[inline]\n    fn size_hint(&self) -> (usize, Option<usize>) {\n        self.base.size_hint()\n    }\n}\n#[stable(feature = \"rust1\", since = \"1.0.0\")]\nimpl<K, V> ExactSizeIterator for IterMut<'_, K, V> {\n    #[inline]\n    fn len(&self) -> usize {\n        self.base.len()\n    }\n}\n#[stable(feature = \"fused\", since = \"1.26.0\")]\nimpl<K, V> FusedIterator for IterMut<'_, K, V> {}\n\n#[stable(feature = \"std_debug\", since = \"1.16.0\")]\nimpl<K, V> fmt::Debug for IterMut<'_, K, V>\nwhere\n    K: fmt::Debug,\n    V: fmt::Debug,\n{\n    fn fmt(&self, f: &mut fmt::Formatter<'_>) -> fmt::Result {\n        f.debug_list().entries(self.iter()).finish()\n    }\n}\n\n#[stable(feature = \"rust1\", since = \"1.0.0\")]\nimpl<K, V> Iterator for IntoIter<K, V> {\n    type Item = (K, V);\n\n    #[inline]\n    fn next(&mut self) -> Option<(K, V)> {\n        self.base.next()\n    }\n    #[inline]\n    fn size_hint(&self) -> (usize, Option<usize>) {\n        self.base.size_hint()\n    }\n}\n#[stable(feature = \"rust1\", since = \"1.0.0\")]\nimpl<K, V> ExactSizeIterator for IntoIter<K, V> {\n    #[inline]\n    fn len(&self) -> usize {\n        self.base.len()\n    }\n}\n#[stable(feature = \"fused\", since = \"1.26.0\")]\nimpl<K, V> FusedIterator for IntoIter<K, V> {}\n\n#[stable(feature = \"std_debug\", since = \"1.16.0\")]\nimpl<K: Debug, V: Debug> fmt::Debug for IntoIter<K, V> {\n    fn fmt(&self, f: &mut fmt::Formatter<'_>) -> fmt::Result {\n        f.debug_list().entries(self.iter()).finish()\n    }\n}\n\n#[stable(feature = \"rust1\", since = \"1.0.0\")]\nimpl<'a, K, V> Iterator for Keys<'a, K, V> {\n    type Item = &'a K;\n\n    #[inline]\n    fn next(&mut self) -> Option<&'a K> {\n        self.inner.next().map(|(k, _)| k)\n    }\n    #[inline]\n    fn size_hint(&self) -> (usize, Option<usize>) {\n        self.inner.size_hint()\n    }\n}\n#[stable(feature = \"rust1\", since = \"1.0.0\")]\nimpl<K, V> ExactSizeIterator for Keys<'_, K, V> {\n    #[inline]\n    fn len(&self) -> usize {\n        self.inner.len()\n    }\n}\n#[stable(feature = \"fused\", since = \"1.26.0\")]\nimpl<K, V> FusedIterator for Keys<'_, K, V> {}\n\n#[stable(feature = \"rust1\", since = \"1.0.0\")]\nimpl<'a, K, V> Iterator for Values<'a, K, V> {\n    type Item = &'a V;\n\n    #[inline]\n    fn next(&mut self) -> Option<&'a V> {\n        self.inner.next().map(|(_, v)| v)\n    }\n    #[inline]\n    fn size_hint(&self) -> (usize, Option<usize>) {\n        self.inner.size_hint()\n    }\n}\n#[stable(feature = \"rust1\", since = \"1.0.0\")]\nimpl<K, V> ExactSizeIterator for Values<'_, K, V> {\n    #[inline]\n    fn len(&self) -> usize {\n        self.inner.len()\n    }\n}\n#[stable(feature = \"fused\", since = \"1.26.0\")]\nimpl<K, V> FusedIterator for Values<'_, K, V> {}\n\n#[stable(feature = \"map_values_mut\", since = \"1.10.0\")]\nimpl<'a, K, V> Iterator for ValuesMut<'a, K, V> {\n    type Item = &'a mut V;\n\n    #[inline]\n    fn next(&mut self) -> Option<&'a mut V> {\n        self.inner.next().map(|(_, v)| v)\n    }\n    #[inline]\n    fn size_hint(&self) -> (usize, Option<usize>) {\n        self.inner.size_hint()\n    }\n}\n#[stable(feature = \"map_values_mut\", since = \"1.10.0\")]\nimpl<K, V> ExactSizeIterator for ValuesMut<'_, K, V> {\n    #[inline]\n    fn len(&self) -> usize {\n        self.inner.len()\n    }\n}\n#[stable(feature = \"fused\", since = \"1.26.0\")]\nimpl<K, V> FusedIterator for ValuesMut<'_, K, V> {}\n\n#[stable(feature = \"std_debug\", since = \"1.16.0\")]\nimpl<K, V: fmt::Debug> fmt::Debug for ValuesMut<'_, K, V> {\n    fn fmt(&self, f: &mut fmt::Formatter<'_>) -> fmt::Result {\n        f.debug_list().entries(self.inner.iter().map(|(_, val)| val)).finish()\n    }\n}\n\n#[stable(feature = \"map_into_keys_values\", since = \"1.54.0\")]\nimpl<K, V> Iterator for IntoKeys<K, V> {\n    type Item = K;\n\n    #[inline]\n    fn next(&mut self) -> Option<K> {\n        self.inner.next().map(|(k, _)| k)\n    }\n    #[inline]\n    fn size_hint(&self) -> (usize, Option<usize>) {\n        self.inner.size_hint()\n    }\n}\n#[stable(feature = \"map_into_keys_values\", since = \"1.54.0\")]\nimpl<K, V> ExactSizeIterator for IntoKeys<K, V> {\n    #[inline]\n    fn len(&self) -> usize {\n        self.inner.len()\n    }\n}\n#[stable(feature = \"map_into_keys_values\", since = \"1.54.0\")]\nimpl<K, V> FusedIterator for IntoKeys<K, V> {}\n\n#[stable(feature = \"map_into_keys_values\", since = \"1.54.0\")]\nimpl<K: Debug, V> fmt::Debug for IntoKeys<K, V> {\n    fn fmt(&self, f: &mut fmt::Formatter<'_>) -> fmt::Result {\n        f.debug_list().entries(self.inner.iter().map(|(k, _)| k)).finish()\n    }\n}\n\n#[stable(feature = \"map_into_keys_values\", since = \"1.54.0\")]\nimpl<K, V> Iterator for IntoValues<K, V> {\n    type Item = V;\n\n    #[inline]\n    fn next(&mut self) -> Option<V> {\n        self.inner.next().map(|(_, v)| v)\n    }\n    #[inline]\n    fn size_hint(&self) -> (usize, Option<usize>) {\n        self.inner.size_hint()\n    }\n}\n#[stable(feature = \"map_into_keys_values\", since = \"1.54.0\")]\nimpl<K, V> ExactSizeIterator for IntoValues<K, V> {\n    #[inline]\n    fn len(&self) -> usize {\n        self.inner.len()\n    }\n}\n#[stable(feature = \"map_into_keys_values\", since = \"1.54.0\")]\nimpl<K, V> FusedIterator for IntoValues<K, V> {}\n\n#[stable(feature = \"map_into_keys_values\", since = \"1.54.0\")]\nimpl<K, V: Debug> fmt::Debug for IntoValues<K, V> {\n    fn fmt(&self, f: &mut fmt::Formatter<'_>) -> fmt::Result {\n        f.debug_list().entries(self.inner.iter().map(|(_, v)| v)).finish()\n    }\n}\n\n#[stable(feature = \"drain\", since = \"1.6.0\")]\nimpl<'a, K, V> Iterator for Drain<'a, K, V> {\n    type Item = (K, V);\n\n    #[inline]\n    fn next(&mut self) -> Option<(K, V)> {\n        self.base.next()\n    }\n    #[inline]\n    fn size_hint(&self) -> (usize, Option<usize>) {\n        self.base.size_hint()\n    }\n}\n#[stable(feature = \"drain\", since = \"1.6.0\")]\nimpl<K, V> ExactSizeIterator for Drain<'_, K, V> {\n    #[inline]\n    fn len(&self) -> usize {\n        self.base.len()\n    }\n}\n#[stable(feature = \"fused\", since = \"1.26.0\")]\nimpl<K, V> FusedIterator for Drain<'_, K, V> {}\n\n#[stable(feature = \"std_debug\", since = \"1.16.0\")]\nimpl<K, V> fmt::Debug for Drain<'_, K, V>\nwhere\n    K: fmt::Debug,\n    V: fmt::Debug,\n{\n    fn fmt(&self, f: &mut fmt::Formatter<'_>) -> fmt::Result {\n        f.debug_list().entries(self.iter()).finish()\n    }\n}\n\n#[unstable(feature = \"hash_drain_filter\", issue = \"59618\")]\nimpl<K, V, F> Iterator for DrainFilter<'_, K, V, F>\nwhere\n    F: FnMut(&K, &mut V) -> bool,\n{\n    type Item = (K, V);\n\n    #[inline]\n    fn next(&mut self) -> Option<(K, V)> {\n        self.base.next()\n    }\n    #[inline]\n    fn size_hint(&self) -> (usize, Option<usize>) {\n        self.base.size_hint()\n    }\n}\n\n#[unstable(feature = \"hash_drain_filter\", issue = \"59618\")]\nimpl<K, V, F> FusedIterator for DrainFilter<'_, K, V, F> where F: FnMut(&K, &mut V) -> bool {}\n\n#[unstable(feature = \"hash_drain_filter\", issue = \"59618\")]\nimpl<'a, K, V, F> fmt::Debug for DrainFilter<'a, K, V, F>\nwhere\n    F: FnMut(&K, &mut V) -> bool,\n{\n    fn fmt(&self, f: &mut fmt::Formatter<'_>) -> fmt::Result {\n        f.debug_struct(\"DrainFilter\").finish_non_exhaustive()\n    }\n}\n\nimpl<'a, K, V> Entry<'a, K, V> {\n    /// Ensures a value is in the entry by inserting the default if empty, and returns\n    /// a mutable reference to the value in the entry.\n    ///\n    /// # Examples\n    ///\n    /// ```\n    /// use std::collections::HashMap;\n    ///\n    /// let mut map: HashMap<&str, u32> = HashMap::new();\n    ///\n    /// map.entry(\"poneyland\").or_insert(3);\n    /// assert_eq!(map[\"poneyland\"], 3);\n    ///\n    /// *map.entry(\"poneyland\").or_insert(10) *= 2;\n    /// assert_eq!(map[\"poneyland\"], 6);\n    /// ```\n    #[inline]\n    #[stable(feature = \"rust1\", since = \"1.0.0\")]\n    pub fn or_insert(self, default: V) -> &'a mut V {\n        match self {\n            Occupied(entry) => entry.into_mut(),\n            Vacant(entry) => entry.insert(default),\n        }\n    }\n\n    /// Ensures a value is in the entry by inserting the result of the default function if empty,\n    /// and returns a mutable reference to the value in the entry.\n    ///\n    /// # Examples\n    ///\n    /// ```\n    /// use std::collections::HashMap;\n    ///\n    /// let mut map: HashMap<&str, String> = HashMap::new();\n    /// let s = \"hoho\".to_string();\n    ///\n    /// map.entry(\"poneyland\").or_insert_with(|| s);\n    ///\n    /// assert_eq!(map[\"poneyland\"], \"hoho\".to_string());\n    /// ```\n    #[inline]\n    #[stable(feature = \"rust1\", since = \"1.0.0\")]\n    pub fn or_insert_with<F: FnOnce() -> V>(self, default: F) -> &'a mut V {\n        match self {\n            Occupied(entry) => entry.into_mut(),\n            Vacant(entry) => entry.insert(default()),\n        }\n    }\n\n    /// Ensures a value is in the entry by inserting, if empty, the result of the default function.\n    /// This method allows for generating key-derived values for insertion by providing the default\n    /// function a reference to the key that was moved during the `.entry(key)` method call.\n    ///\n    /// The reference to the moved key is provided so that cloning or copying the key is\n    /// unnecessary, unlike with `.or_insert_with(|| ... )`.\n    ///\n    /// # Examples\n    ///\n    /// ```\n    /// use std::collections::HashMap;\n    ///\n    /// let mut map: HashMap<&str, usize> = HashMap::new();\n    ///\n    /// map.entry(\"poneyland\").or_insert_with_key(|key| key.chars().count());\n    ///\n    /// assert_eq!(map[\"poneyland\"], 9);\n    /// ```\n    #[inline]\n    #[stable(feature = \"or_insert_with_key\", since = \"1.50.0\")]\n    pub fn or_insert_with_key<F: FnOnce(&K) -> V>(self, default: F) -> &'a mut V {\n        match self {\n            Occupied(entry) => entry.into_mut(),\n            Vacant(entry) => {\n                let value = default(entry.key());\n                entry.insert(value)\n            }\n        }\n    }\n\n    /// Returns a reference to this entry's key.\n    ///\n    /// # Examples\n    ///\n    /// ```\n    /// use std::collections::HashMap;\n    ///\n    /// let mut map: HashMap<&str, u32> = HashMap::new();\n    /// assert_eq!(map.entry(\"poneyland\").key(), &\"poneyland\");\n    /// ```\n    #[inline]\n    #[stable(feature = \"map_entry_keys\", since = \"1.10.0\")]\n    pub fn key(&self) -> &K {\n        match *self {\n            Occupied(ref entry) => entry.key(),\n            Vacant(ref entry) => entry.key(),\n        }\n    }\n\n    /// Provides in-place mutable access to an occupied entry before any\n    /// potential inserts into the map.\n    ///\n    /// # Examples\n    ///\n    /// ```\n    /// use std::collections::HashMap;\n    ///\n    /// let mut map: HashMap<&str, u32> = HashMap::new();\n    ///\n    /// map.entry(\"poneyland\")\n    ///    .and_modify(|e| { *e += 1 })\n    ///    .or_insert(42);\n    /// assert_eq!(map[\"poneyland\"], 42);\n    ///\n    /// map.entry(\"poneyland\")\n    ///    .and_modify(|e| { *e += 1 })\n    ///    .or_insert(42);\n    /// assert_eq!(map[\"poneyland\"], 43);\n    /// ```\n    #[inline]\n    #[stable(feature = \"entry_and_modify\", since = \"1.26.0\")]\n    pub fn and_modify<F>(self, f: F) -> Self\n    where\n        F: FnOnce(&mut V),\n    {\n        match self {\n            Occupied(mut entry) => {\n                f(entry.get_mut());\n                Occupied(entry)\n            }\n            Vacant(entry) => Vacant(entry),\n        }\n    }\n\n    /// Sets the value of the entry, and returns an `OccupiedEntry`.\n    ///\n    /// # Examples\n    ///\n    /// ```\n    /// #![feature(entry_insert)]\n    /// use std::collections::HashMap;\n    ///\n    /// let mut map: HashMap<&str, String> = HashMap::new();\n    /// let entry = map.entry(\"poneyland\").insert(\"hoho\".to_string());\n    ///\n    /// assert_eq!(entry.key(), &\"poneyland\");\n    /// ```\n    #[inline]\n    #[unstable(feature = \"entry_insert\", issue = \"65225\")]\n    pub fn insert(self, value: V) -> OccupiedEntry<'a, K, V> {\n        match self {\n            Occupied(mut entry) => {\n                entry.insert(value);\n                entry\n            }\n            Vacant(entry) => entry.insert_entry(value),\n        }\n    }\n}\n\nimpl<'a, K, V: Default> Entry<'a, K, V> {\n    /// Ensures a value is in the entry by inserting the default value if empty,\n    /// and returns a mutable reference to the value in the entry.\n    ///\n    /// # Examples\n    ///\n    /// ```\n    /// # fn main() {\n    /// use std::collections::HashMap;\n    ///\n    /// let mut map: HashMap<&str, Option<u32>> = HashMap::new();\n    /// map.entry(\"poneyland\").or_default();\n    ///\n    /// assert_eq!(map[\"poneyland\"], None);\n    /// # }\n    /// ```\n    #[inline]\n    #[stable(feature = \"entry_or_default\", since = \"1.28.0\")]\n    pub fn or_default(self) -> &'a mut V {\n        match self {\n            Occupied(entry) => entry.into_mut(),\n            Vacant(entry) => entry.insert(Default::default()),\n        }\n    }\n}\n\nimpl<'a, K, V> OccupiedEntry<'a, K, V> {\n    /// Gets a reference to the key in the entry.\n    ///\n    /// # Examples\n    ///\n    /// ```\n    /// use std::collections::HashMap;\n    ///\n    /// let mut map: HashMap<&str, u32> = HashMap::new();\n    /// map.entry(\"poneyland\").or_insert(12);\n    /// assert_eq!(map.entry(\"poneyland\").key(), &\"poneyland\");\n    /// ```\n    #[inline]\n    #[stable(feature = \"map_entry_keys\", since = \"1.10.0\")]\n    pub fn key(&self) -> &K {\n        self.base.key()\n    }\n\n    /// Take the ownership of the key and value from the map.\n    ///\n    /// # Examples\n    ///\n    /// ```\n    /// use std::collections::HashMap;\n    /// use std::collections::hash_map::Entry;\n    ///\n    /// let mut map: HashMap<&str, u32> = HashMap::new();\n    /// map.entry(\"poneyland\").or_insert(12);\n    ///\n    /// if let Entry::Occupied(o) = map.entry(\"poneyland\") {\n    ///     // We delete the entry from the map.\n    ///     o.remove_entry();\n    /// }\n    ///\n    /// assert_eq!(map.contains_key(\"poneyland\"), false);\n    /// ```\n    #[inline]\n    #[stable(feature = \"map_entry_recover_keys2\", since = \"1.12.0\")]\n    pub fn remove_entry(self) -> (K, V) {\n        self.base.remove_entry()\n    }\n\n    /// Gets a reference to the value in the entry.\n    ///\n    /// # Examples\n    ///\n    /// ```\n    /// use std::collections::HashMap;\n    /// use std::collections::hash_map::Entry;\n    ///\n    /// let mut map: HashMap<&str, u32> = HashMap::new();\n    /// map.entry(\"poneyland\").or_insert(12);\n    ///\n    /// if let Entry::Occupied(o) = map.entry(\"poneyland\") {\n    ///     assert_eq!(o.get(), &12);\n    /// }\n    /// ```\n    #[inline]\n    #[stable(feature = \"rust1\", since = \"1.0.0\")]\n    pub fn get(&self) -> &V {\n        self.base.get()\n    }\n\n    /// Gets a mutable reference to the value in the entry.\n    ///\n    /// If you need a reference to the `OccupiedEntry` which may outlive the\n    /// destruction of the `Entry` value, see [`into_mut`].\n    ///\n    /// [`into_mut`]: Self::into_mut\n    ///\n    /// # Examples\n    ///\n    /// ```\n    /// use std::collections::HashMap;\n    /// use std::collections::hash_map::Entry;\n    ///\n    /// let mut map: HashMap<&str, u32> = HashMap::new();\n    /// map.entry(\"poneyland\").or_insert(12);\n    ///\n    /// assert_eq!(map[\"poneyland\"], 12);\n    /// if let Entry::Occupied(mut o) = map.entry(\"poneyland\") {\n    ///     *o.get_mut() += 10;\n    ///     assert_eq!(*o.get(), 22);\n    ///\n    ///     // We can use the same Entry multiple times.\n    ///     *o.get_mut() += 2;\n    /// }\n    ///\n    /// assert_eq!(map[\"poneyland\"], 24);\n    /// ```\n    #[inline]\n    #[stable(feature = \"rust1\", since = \"1.0.0\")]\n    pub fn get_mut(&mut self) -> &mut V {\n        self.base.get_mut()\n    }\n\n    /// Converts the `OccupiedEntry` into a mutable reference to the value in the entry\n    /// with a lifetime bound to the map itself.\n    ///\n    /// If you need multiple references to the `OccupiedEntry`, see [`get_mut`].\n    ///\n    /// [`get_mut`]: Self::get_mut\n    ///\n    /// # Examples\n    ///\n    /// ```\n    /// use std::collections::HashMap;\n    /// use std::collections::hash_map::Entry;\n    ///\n    /// let mut map: HashMap<&str, u32> = HashMap::new();\n    /// map.entry(\"poneyland\").or_insert(12);\n    ///\n    /// assert_eq!(map[\"poneyland\"], 12);\n    /// if let Entry::Occupied(o) = map.entry(\"poneyland\") {\n    ///     *o.into_mut() += 10;\n    /// }\n    ///\n    /// assert_eq!(map[\"poneyland\"], 22);\n    /// ```\n    #[inline]\n    #[stable(feature = \"rust1\", since = \"1.0.0\")]\n    pub fn into_mut(self) -> &'a mut V {\n        self.base.into_mut()\n    }\n\n    /// Sets the value of the entry, and returns the entry's old value.\n    ///\n    /// # Examples\n    ///\n    /// ```\n    /// use std::collections::HashMap;\n    /// use std::collections::hash_map::Entry;\n    ///\n    /// let mut map: HashMap<&str, u32> = HashMap::new();\n    /// map.entry(\"poneyland\").or_insert(12);\n    ///\n    /// if let Entry::Occupied(mut o) = map.entry(\"poneyland\") {\n    ///     assert_eq!(o.insert(15), 12);\n    /// }\n    ///\n    /// assert_eq!(map[\"poneyland\"], 15);\n    /// ```\n    #[inline]\n    #[stable(feature = \"rust1\", since = \"1.0.0\")]\n    pub fn insert(&mut self, value: V) -> V {\n        self.base.insert(value)\n    }\n\n    /// Takes the value out of the entry, and returns it.\n    ///\n    /// # Examples\n    ///\n    /// ```\n    /// use std::collections::HashMap;\n    /// use std::collections::hash_map::Entry;\n    ///\n    /// let mut map: HashMap<&str, u32> = HashMap::new();\n    /// map.entry(\"poneyland\").or_insert(12);\n    ///\n    /// if let Entry::Occupied(o) = map.entry(\"poneyland\") {\n    ///     assert_eq!(o.remove(), 12);\n    /// }\n    ///\n    /// assert_eq!(map.contains_key(\"poneyland\"), false);\n    /// ```\n    #[inline]\n    #[stable(feature = \"rust1\", since = \"1.0.0\")]\n    pub fn remove(self) -> V {\n        self.base.remove()\n    }\n\n    /// Replaces the entry, returning the old key and value. The new key in the hash map will be\n    /// the key used to create this entry.\n    ///\n    /// # Examples\n    ///\n    /// ```\n    /// #![feature(map_entry_replace)]\n    /// use std::collections::hash_map::{Entry, HashMap};\n    /// use std::rc::Rc;\n    ///\n    /// let mut map: HashMap<Rc<String>, u32> = HashMap::new();\n    /// map.insert(Rc::new(\"Stringthing\".to_string()), 15);\n    ///\n    /// let my_key = Rc::new(\"Stringthing\".to_string());\n    ///\n    /// if let Entry::Occupied(entry) = map.entry(my_key) {\n    ///     // Also replace the key with a handle to our other key.\n    ///     let (old_key, old_value): (Rc<String>, u32) = entry.replace_entry(16);\n    /// }\n    ///\n    /// ```\n    #[inline]\n    #[unstable(feature = \"map_entry_replace\", issue = \"44286\")]\n    pub fn replace_entry(self, value: V) -> (K, V) {\n        self.base.replace_entry(value)\n    }\n\n    /// Replaces the key in the hash map with the key used to create this entry.\n    ///\n    /// # Examples\n    ///\n    /// ```\n    /// #![feature(map_entry_replace)]\n    /// use std::collections::hash_map::{Entry, HashMap};\n    /// use std::rc::Rc;\n    ///\n    /// let mut map: HashMap<Rc<String>, u32> = HashMap::new();\n    /// let known_strings: Vec<Rc<String>> = Vec::new();\n    ///\n    /// // Initialise known strings, run program, etc.\n    ///\n    /// reclaim_memory(&mut map, &known_strings);\n    ///\n    /// fn reclaim_memory(map: &mut HashMap<Rc<String>, u32>, known_strings: &[Rc<String>] ) {\n    ///     for s in known_strings {\n    ///         if let Entry::Occupied(entry) = map.entry(Rc::clone(s)) {\n    ///             // Replaces the entry's key with our version of it in `known_strings`.\n    ///             entry.replace_key();\n    ///         }\n    ///     }\n    /// }\n    /// ```\n    #[inline]\n    #[unstable(feature = \"map_entry_replace\", issue = \"44286\")]\n    pub fn replace_key(self) -> K {\n        self.base.replace_key()\n    }\n}\n\nimpl<'a, K: 'a, V: 'a> VacantEntry<'a, K, V> {\n    /// Gets a reference to the key that would be used when inserting a value\n    /// through the `VacantEntry`.\n    ///\n    /// # Examples\n    ///\n    /// ```\n    /// use std::collections::HashMap;\n    ///\n    /// let mut map: HashMap<&str, u32> = HashMap::new();\n    /// assert_eq!(map.entry(\"poneyland\").key(), &\"poneyland\");\n    /// ```\n    #[inline]\n    #[stable(feature = \"map_entry_keys\", since = \"1.10.0\")]\n    pub fn key(&self) -> &K {\n        self.base.key()\n    }\n\n    /// Take ownership of the key.\n    ///\n    /// # Examples\n    ///\n    /// ```\n    /// use std::collections::HashMap;\n    /// use std::collections::hash_map::Entry;\n    ///\n    /// let mut map: HashMap<&str, u32> = HashMap::new();\n    ///\n    /// if let Entry::Vacant(v) = map.entry(\"poneyland\") {\n    ///     v.into_key();\n    /// }\n    /// ```\n    #[inline]\n    #[stable(feature = \"map_entry_recover_keys2\", since = \"1.12.0\")]\n    pub fn into_key(self) -> K {\n        self.base.into_key()\n    }\n\n    /// Sets the value of the entry with the `VacantEntry`'s key,\n    /// and returns a mutable reference to it.\n    ///\n    /// # Examples\n    ///\n    /// ```\n    /// use std::collections::HashMap;\n    /// use std::collections::hash_map::Entry;\n    ///\n    /// let mut map: HashMap<&str, u32> = HashMap::new();\n    ///\n    /// if let Entry::Vacant(o) = map.entry(\"poneyland\") {\n    ///     o.insert(37);\n    /// }\n    /// assert_eq!(map[\"poneyland\"], 37);\n    /// ```\n    #[inline]\n    #[stable(feature = \"rust1\", since = \"1.0.0\")]\n    pub fn insert(self, value: V) -> &'a mut V {\n        self.base.insert(value)\n    }\n\n    /// Sets the value of the entry with the `VacantEntry`'s key,\n    /// and returns an `OccupiedEntry`.\n    ///\n    /// # Examples\n    ///\n    /// ```\n    /// use std::collections::HashMap;\n    /// use std::collections::hash_map::Entry;\n    ///\n    /// let mut map: HashMap<&str, u32> = HashMap::new();\n    ///\n    /// if let Entry::Vacant(o) = map.entry(\"poneyland\") {\n    ///     o.insert(37);\n    /// }\n    /// assert_eq!(map[\"poneyland\"], 37);\n    /// ```\n    #[inline]\n    fn insert_entry(self, value: V) -> OccupiedEntry<'a, K, V> {\n        let base = self.base.insert_entry(value);\n        OccupiedEntry { base }\n    }\n}\n\n#[stable(feature = \"rust1\", since = \"1.0.0\")]\nimpl<K, V, S> FromIterator<(K, V)> for HashMap<K, V, S>\nwhere\n    K: Eq + Hash,\n    S: BuildHasher + Default,\n{\n    fn from_iter<T: IntoIterator<Item = (K, V)>>(iter: T) -> HashMap<K, V, S> {\n        let mut map = HashMap::with_hasher(Default::default());\n        map.extend(iter);\n        map\n    }\n}\n\n/// Inserts all new key-values from the iterator and replaces values with existing\n/// keys with new values returned from the iterator.\n#[stable(feature = \"rust1\", since = \"1.0.0\")]\nimpl<K, V, S> Extend<(K, V)> for HashMap<K, V, S>\nwhere\n    K: Eq + Hash,\n    S: BuildHasher,\n{\n    #[inline]\n    fn extend<T: IntoIterator<Item = (K, V)>>(&mut self, iter: T) {\n        self.base.extend(iter)\n    }\n\n    #[inline]\n    fn extend_one(&mut self, (k, v): (K, V)) {\n        self.base.insert(k, v);\n    }\n\n    #[inline]\n    fn extend_reserve(&mut self, additional: usize) {\n        // self.base.extend_reserve(additional);\n        // FIXME: hashbrown should implement this method.\n        // But until then, use the same reservation logic:\n\n        // Reserve the entire hint lower bound if the map is empty.\n        // Otherwise reserve half the hint (rounded up), so the map\n        // will only resize twice in the worst case.\n        let reserve = if self.is_empty() { additional } else { (additional + 1) / 2 };\n        self.base.reserve(reserve);\n    }\n}\n\n#[stable(feature = \"hash_extend_copy\", since = \"1.4.0\")]\nimpl<'a, K, V, S> Extend<(&'a K, &'a V)> for HashMap<K, V, S>\nwhere\n    K: Eq + Hash + Copy,\n    V: Copy,\n    S: BuildHasher,\n{\n    #[inline]\n    fn extend<T: IntoIterator<Item = (&'a K, &'a V)>>(&mut self, iter: T) {\n        self.base.extend(iter)\n    }\n\n    #[inline]\n    fn extend_one(&mut self, (&k, &v): (&'a K, &'a V)) {\n        self.base.insert(k, v);\n    }\n\n    #[inline]\n    fn extend_reserve(&mut self, additional: usize) {\n        Extend::<(K, V)>::extend_reserve(self, additional)\n    }\n}\n\n/// `RandomState` is the default state for [`HashMap`] types.\n///\n/// A particular instance `RandomState` will create the same instances of\n/// [`Hasher`], but the hashers created by two different `RandomState`\n/// instances are unlikely to produce the same result for the same values.\n///\n/// # Examples\n///\n/// ```\n/// use std::collections::HashMap;\n/// use std::collections::hash_map::RandomState;\n///\n/// let s = RandomState::new();\n/// let mut map = HashMap::with_hasher(s);\n/// map.insert(1, 2);\n/// ```\n#[derive(Clone)]\n#[stable(feature = \"hashmap_build_hasher\", since = \"1.7.0\")]\npub struct RandomState {\n    k0: u64,\n    k1: u64,\n}\n\nimpl RandomState {\n    /// Constructs a new `RandomState` that is initialized with random keys.\n    ///\n    /// # Examples\n    ///\n    /// ```\n    /// use std::collections::hash_map::RandomState;\n    ///\n    /// let s = RandomState::new();\n    /// ```\n    #[inline]\n    #[allow(deprecated)]\n    // rand\n    #[stable(feature = \"hashmap_build_hasher\", since = \"1.7.0\")]\n    pub fn new() -> RandomState {\n        // Historically this function did not cache keys from the OS and instead\n        // simply always called `rand::thread_rng().gen()` twice. In #31356 it\n        // was discovered, however, that because we re-seed the thread-local RNG\n        // from the OS periodically that this can cause excessive slowdown when\n        // many hash maps are created on a thread. To solve this performance\n        // trap we cache the first set of randomly generated keys per-thread.\n        //\n        // Later in #36481 it was discovered that exposing a deterministic\n        // iteration order allows a form of DOS attack. To counter that we\n        // increment one of the seeds on every RandomState creation, giving\n        // every corresponding HashMap a different iteration order.\n        thread_local!(static KEYS: Cell<(u64, u64)> = {\n            Cell::new(sys::hashmap_random_keys())\n        });\n\n        KEYS.with(|keys| {\n            let (k0, k1) = keys.get();\n            keys.set((k0.wrapping_add(1), k1));\n            RandomState { k0, k1 }\n        })\n    }\n}\n\n#[stable(feature = \"hashmap_build_hasher\", since = \"1.7.0\")]\nimpl BuildHasher for RandomState {\n    type Hasher = DefaultHasher;\n    #[inline]\n    #[allow(deprecated)]\n    fn build_hasher(&self) -> DefaultHasher {\n        DefaultHasher(SipHasher13::new_with_keys(self.k0, self.k1))\n    }\n}\n\n/// The default [`Hasher`] used by [`RandomState`].\n///\n/// The internal algorithm is not specified, and so it and its hashes should\n/// not be relied upon over releases.\n#[stable(feature = \"hashmap_default_hasher\", since = \"1.13.0\")]\n#[allow(deprecated)]\n#[derive(Clone, Debug)]\npub struct DefaultHasher(SipHasher13);\n\nimpl DefaultHasher {\n    /// Creates a new `DefaultHasher`.\n    ///\n    /// This hasher is not guaranteed to be the same as all other\n    /// `DefaultHasher` instances, but is the same as all other `DefaultHasher`\n    /// instances created through `new` or `default`.\n    #[stable(feature = \"hashmap_default_hasher\", since = \"1.13.0\")]\n    #[allow(deprecated)]\n    pub fn new() -> DefaultHasher {\n        DefaultHasher(SipHasher13::new_with_keys(0, 0))\n    }\n}\n\n#[stable(feature = \"hashmap_default_hasher\", since = \"1.13.0\")]\nimpl Default for DefaultHasher {\n    /// Creates a new `DefaultHasher` using [`new`].\n    /// See its documentation for more.\n    ///\n    /// [`new`]: DefaultHasher::new\n    fn default() -> DefaultHasher {\n        DefaultHasher::new()\n    }\n}\n\n#[stable(feature = \"hashmap_default_hasher\", since = \"1.13.0\")]\nimpl Hasher for DefaultHasher {\n    #[inline]\n    fn write(&mut self, msg: &[u8]) {\n        self.0.write(msg)\n    }\n\n    #[inline]\n    fn finish(&self) -> u64 {\n        self.0.finish()\n    }\n}\n\n#[stable(feature = \"hashmap_build_hasher\", since = \"1.7.0\")]\nimpl Default for RandomState {\n    /// Constructs a new `RandomState`.\n    #[inline]\n    fn default() -> RandomState {\n        RandomState::new()\n    }\n}\n\n#[stable(feature = \"std_debug\", since = \"1.16.0\")]\nimpl fmt::Debug for RandomState {\n    fn fmt(&self, f: &mut fmt::Formatter<'_>) -> fmt::Result {\n        f.debug_struct(\"RandomState\").finish_non_exhaustive()\n    }\n}\n\n#[inline]\nfn map_entry<'a, K: 'a, V: 'a>(raw: base::RustcEntry<'a, K, V>) -> Entry<'a, K, V> {\n    match raw {\n        base::RustcEntry::Occupied(base) => Entry::Occupied(OccupiedEntry { base }),\n        base::RustcEntry::Vacant(base) => Entry::Vacant(VacantEntry { base }),\n    }\n}\n\n#[inline]\npub(super) fn map_try_reserve_error(err: hashbrown::TryReserveError) -> TryReserveError {\n    match err {\n        hashbrown::TryReserveError::CapacityOverflow => TryReserveError::CapacityOverflow,\n        hashbrown::TryReserveError::AllocError { layout } => {\n            TryReserveError::AllocError { layout, non_exhaustive: () }\n        }\n    }\n}\n\n#[inline]\nfn map_raw_entry<'a, K: 'a, V: 'a, S: 'a>(\n    raw: base::RawEntryMut<'a, K, V, S>,\n) -> RawEntryMut<'a, K, V, S> {\n    match raw {\n        base::RawEntryMut::Occupied(base) => RawEntryMut::Occupied(RawOccupiedEntryMut { base }),\n        base::RawEntryMut::Vacant(base) => RawEntryMut::Vacant(RawVacantEntryMut { base }),\n    }\n}\n\n#[allow(dead_code)]\nfn assert_covariance() {\n    fn map_key<'new>(v: HashMap<&'static str, u8>) -> HashMap<&'new str, u8> {\n        v\n    }\n    fn map_val<'new>(v: HashMap<u8, &'static str>) -> HashMap<u8, &'new str> {\n        v\n    }\n    fn iter_key<'a, 'new>(v: Iter<'a, &'static str, u8>) -> Iter<'a, &'new str, u8> {\n        v\n    }\n    fn iter_val<'a, 'new>(v: Iter<'a, u8, &'static str>) -> Iter<'a, u8, &'new str> {\n        v\n    }\n    fn into_iter_key<'new>(v: IntoIter<&'static str, u8>) -> IntoIter<&'new str, u8> {\n        v\n    }\n    fn into_iter_val<'new>(v: IntoIter<u8, &'static str>) -> IntoIter<u8, &'new str> {\n        v\n    }\n    fn keys_key<'a, 'new>(v: Keys<'a, &'static str, u8>) -> Keys<'a, &'new str, u8> {\n        v\n    }\n    fn keys_val<'a, 'new>(v: Keys<'a, u8, &'static str>) -> Keys<'a, u8, &'new str> {\n        v\n    }\n    fn values_key<'a, 'new>(v: Values<'a, &'static str, u8>) -> Values<'a, &'new str, u8> {\n        v\n    }\n    fn values_val<'a, 'new>(v: Values<'a, u8, &'static str>) -> Values<'a, u8, &'new str> {\n        v\n    }\n    fn drain<'new>(\n        d: Drain<'static, &'static str, &'static str>,\n    ) -> Drain<'new, &'new str, &'new str> {\n        d\n    }\n}\n"],[2225,"use super::Entry::{Occupied, Vacant};\nuse super::HashMap;\nuse super::RandomState;\nuse crate::cell::RefCell;\nuse rand::{thread_rng, Rng};\nuse realstd::collections::TryReserveError::*;\n\n// https://github.com/rust-lang/rust/issues/62301\nfn _assert_hashmap_is_unwind_safe() {\n    fn assert_unwind_safe<T: crate::panic::UnwindSafe>() {}\n    assert_unwind_safe::<HashMap<(), crate::cell::UnsafeCell<()>>>();\n}\n\n#[test]\nfn test_zero_capacities() {\n    type HM = HashMap<i32, i32>;\n\n    let m = HM::new();\n    assert_eq!(m.capacity(), 0);\n\n    let m = HM::default();\n    assert_eq!(m.capacity(), 0);\n\n    let m = HM::with_hasher(RandomState::new());\n    assert_eq!(m.capacity(), 0);\n\n    let m = HM::with_capacity(0);\n    assert_eq!(m.capacity(), 0);\n\n    let m = HM::with_capacity_and_hasher(0, RandomState::new());\n    assert_eq!(m.capacity(), 0);\n\n    let mut m = HM::new();\n    m.insert(1, 1);\n    m.insert(2, 2);\n    m.remove(&1);\n    m.remove(&2);\n    m.shrink_to_fit();\n    assert_eq!(m.capacity(), 0);\n\n    let mut m = HM::new();\n    m.reserve(0);\n    assert_eq!(m.capacity(), 0);\n}\n\n#[test]\nfn test_create_capacity_zero() {\n    let mut m = HashMap::with_capacity(0);\n\n    assert!(m.insert(1, 1).is_none());\n\n    assert!(m.contains_key(&1));\n    assert!(!m.contains_key(&0));\n}\n\n#[test]\nfn test_insert() {\n    let mut m = HashMap::new();\n    assert_eq!(m.len(), 0);\n    assert!(m.insert(1, 2).is_none());\n    assert_eq!(m.len(), 1);\n    assert!(m.insert(2, 4).is_none());\n    assert_eq!(m.len(), 2);\n    assert_eq!(*m.get(&1).unwrap(), 2);\n    assert_eq!(*m.get(&2).unwrap(), 4);\n}\n\n#[test]\nfn test_clone() {\n    let mut m = HashMap::new();\n    assert_eq!(m.len(), 0);\n    assert!(m.insert(1, 2).is_none());\n    assert_eq!(m.len(), 1);\n    assert!(m.insert(2, 4).is_none());\n    assert_eq!(m.len(), 2);\n    let m2 = m.clone();\n    assert_eq!(*m2.get(&1).unwrap(), 2);\n    assert_eq!(*m2.get(&2).unwrap(), 4);\n    assert_eq!(m2.len(), 2);\n}\n\nthread_local! { static DROP_VECTOR: RefCell<Vec<i32>> = RefCell::new(Vec::new()) }\n\n#[derive(Hash, PartialEq, Eq)]\nstruct Droppable {\n    k: usize,\n}\n\nimpl Droppable {\n    fn new(k: usize) -> Droppable {\n        DROP_VECTOR.with(|slot| {\n            slot.borrow_mut()[k] += 1;\n        });\n\n        Droppable { k }\n    }\n}\n\nimpl Drop for Droppable {\n    fn drop(&mut self) {\n        DROP_VECTOR.with(|slot| {\n            slot.borrow_mut()[self.k] -= 1;\n        });\n    }\n}\n\nimpl Clone for Droppable {\n    fn clone(&self) -> Droppable {\n        Droppable::new(self.k)\n    }\n}\n\n#[test]\nfn test_drops() {\n    DROP_VECTOR.with(|slot| {\n        *slot.borrow_mut() = vec![0; 200];\n    });\n\n    {\n        let mut m = HashMap::new();\n\n        DROP_VECTOR.with(|v| {\n            for i in 0..200 {\n                assert_eq!(v.borrow()[i], 0);\n            }\n        });\n\n        for i in 0..100 {\n            let d1 = Droppable::new(i);\n            let d2 = Droppable::new(i + 100);\n            m.insert(d1, d2);\n        }\n\n        DROP_VECTOR.with(|v| {\n            for i in 0..200 {\n                assert_eq!(v.borrow()[i], 1);\n            }\n        });\n\n        for i in 0..50 {\n            let k = Droppable::new(i);\n            let v = m.remove(&k);\n\n            assert!(v.is_some());\n\n            DROP_VECTOR.with(|v| {\n                assert_eq!(v.borrow()[i], 1);\n                assert_eq!(v.borrow()[i + 100], 1);\n            });\n        }\n\n        DROP_VECTOR.with(|v| {\n            for i in 0..50 {\n                assert_eq!(v.borrow()[i], 0);\n                assert_eq!(v.borrow()[i + 100], 0);\n            }\n\n            for i in 50..100 {\n                assert_eq!(v.borrow()[i], 1);\n                assert_eq!(v.borrow()[i + 100], 1);\n            }\n        });\n    }\n\n    DROP_VECTOR.with(|v| {\n        for i in 0..200 {\n            assert_eq!(v.borrow()[i], 0);\n        }\n    });\n}\n\n#[test]\nfn test_into_iter_drops() {\n    DROP_VECTOR.with(|v| {\n        *v.borrow_mut() = vec![0; 200];\n    });\n\n    let hm = {\n        let mut hm = HashMap::new();\n\n        DROP_VECTOR.with(|v| {\n            for i in 0..200 {\n                assert_eq!(v.borrow()[i], 0);\n            }\n        });\n\n        for i in 0..100 {\n            let d1 = Droppable::new(i);\n            let d2 = Droppable::new(i + 100);\n            hm.insert(d1, d2);\n        }\n\n        DROP_VECTOR.with(|v| {\n            for i in 0..200 {\n                assert_eq!(v.borrow()[i], 1);\n            }\n        });\n\n        hm\n    };\n\n    // By the way, ensure that cloning doesn't screw up the dropping.\n    drop(hm.clone());\n\n    {\n        let mut half = hm.into_iter().take(50);\n\n        DROP_VECTOR.with(|v| {\n            for i in 0..200 {\n                assert_eq!(v.borrow()[i], 1);\n            }\n        });\n\n        for _ in half.by_ref() {}\n\n        DROP_VECTOR.with(|v| {\n            let nk = (0..100).filter(|&i| v.borrow()[i] == 1).count();\n\n            let nv = (0..100).filter(|&i| v.borrow()[i + 100] == 1).count();\n\n            assert_eq!(nk, 50);\n            assert_eq!(nv, 50);\n        });\n    };\n\n    DROP_VECTOR.with(|v| {\n        for i in 0..200 {\n            assert_eq!(v.borrow()[i], 0);\n        }\n    });\n}\n\n#[test]\nfn test_empty_remove() {\n    let mut m: HashMap<i32, bool> = HashMap::new();\n    assert_eq!(m.remove(&0), None);\n}\n\n#[test]\nfn test_empty_entry() {\n    let mut m: HashMap<i32, bool> = HashMap::new();\n    match m.entry(0) {\n        Occupied(_) => panic!(),\n        Vacant(_) => {}\n    }\n    assert!(*m.entry(0).or_insert(true));\n    assert_eq!(m.len(), 1);\n}\n\n#[test]\nfn test_empty_iter() {\n    let mut m: HashMap<i32, bool> = HashMap::new();\n    assert_eq!(m.drain().next(), None);\n    assert_eq!(m.keys().next(), None);\n    assert_eq!(m.values().next(), None);\n    assert_eq!(m.values_mut().next(), None);\n    assert_eq!(m.iter().next(), None);\n    assert_eq!(m.iter_mut().next(), None);\n    assert_eq!(m.len(), 0);\n    assert!(m.is_empty());\n    assert_eq!(m.into_iter().next(), None);\n}\n\n#[test]\nfn test_lots_of_insertions() {\n    let mut m = HashMap::new();\n\n    // Try this a few times to make sure we never screw up the hashmap's\n    // internal state.\n    for _ in 0..10 {\n        assert!(m.is_empty());\n\n        for i in 1..1001 {\n            assert!(m.insert(i, i).is_none());\n\n            for j in 1..=i {\n                let r = m.get(&j);\n                assert_eq!(r, Some(&j));\n            }\n\n            for j in i + 1..1001 {\n                let r = m.get(&j);\n                assert_eq!(r, None);\n            }\n        }\n\n        for i in 1001..2001 {\n            assert!(!m.contains_key(&i));\n        }\n\n        // remove forwards\n        for i in 1..1001 {\n            assert!(m.remove(&i).is_some());\n\n            for j in 1..=i {\n                assert!(!m.contains_key(&j));\n            }\n\n            for j in i + 1..1001 {\n                assert!(m.contains_key(&j));\n            }\n        }\n\n        for i in 1..1001 {\n            assert!(!m.contains_key(&i));\n        }\n\n        for i in 1..1001 {\n            assert!(m.insert(i, i).is_none());\n        }\n\n        // remove backwards\n        for i in (1..1001).rev() {\n            assert!(m.remove(&i).is_some());\n\n            for j in i..1001 {\n                assert!(!m.contains_key(&j));\n            }\n\n            for j in 1..i {\n                assert!(m.contains_key(&j));\n            }\n        }\n    }\n}\n\n#[test]\nfn test_find_mut() {\n    let mut m = HashMap::new();\n    assert!(m.insert(1, 12).is_none());\n    assert!(m.insert(2, 8).is_none());\n    assert!(m.insert(5, 14).is_none());\n    let new = 100;\n    match m.get_mut(&5) {\n        None => panic!(),\n        Some(x) => *x = new,\n    }\n    assert_eq!(m.get(&5), Some(&new));\n}\n\n#[test]\nfn test_insert_overwrite() {\n    let mut m = HashMap::new();\n    assert!(m.insert(1, 2).is_none());\n    assert_eq!(*m.get(&1).unwrap(), 2);\n    assert!(!m.insert(1, 3).is_none());\n    assert_eq!(*m.get(&1).unwrap(), 3);\n}\n\n#[test]\nfn test_insert_conflicts() {\n    let mut m = HashMap::with_capacity(4);\n    assert!(m.insert(1, 2).is_none());\n    assert!(m.insert(5, 3).is_none());\n    assert!(m.insert(9, 4).is_none());\n    assert_eq!(*m.get(&9).unwrap(), 4);\n    assert_eq!(*m.get(&5).unwrap(), 3);\n    assert_eq!(*m.get(&1).unwrap(), 2);\n}\n\n#[test]\nfn test_conflict_remove() {\n    let mut m = HashMap::with_capacity(4);\n    assert!(m.insert(1, 2).is_none());\n    assert_eq!(*m.get(&1).unwrap(), 2);\n    assert!(m.insert(5, 3).is_none());\n    assert_eq!(*m.get(&1).unwrap(), 2);\n    assert_eq!(*m.get(&5).unwrap(), 3);\n    assert!(m.insert(9, 4).is_none());\n    assert_eq!(*m.get(&1).unwrap(), 2);\n    assert_eq!(*m.get(&5).unwrap(), 3);\n    assert_eq!(*m.get(&9).unwrap(), 4);\n    assert!(m.remove(&1).is_some());\n    assert_eq!(*m.get(&9).unwrap(), 4);\n    assert_eq!(*m.get(&5).unwrap(), 3);\n}\n\n#[test]\nfn test_is_empty() {\n    let mut m = HashMap::with_capacity(4);\n    assert!(m.insert(1, 2).is_none());\n    assert!(!m.is_empty());\n    assert!(m.remove(&1).is_some());\n    assert!(m.is_empty());\n}\n\n#[test]\nfn test_remove() {\n    let mut m = HashMap::new();\n    m.insert(1, 2);\n    assert_eq!(m.remove(&1), Some(2));\n    assert_eq!(m.remove(&1), None);\n}\n\n#[test]\nfn test_remove_entry() {\n    let mut m = HashMap::new();\n    m.insert(1, 2);\n    assert_eq!(m.remove_entry(&1), Some((1, 2)));\n    assert_eq!(m.remove(&1), None);\n}\n\n#[test]\nfn test_iterate() {\n    let mut m = HashMap::with_capacity(4);\n    for i in 0..32 {\n        assert!(m.insert(i, i * 2).is_none());\n    }\n    assert_eq!(m.len(), 32);\n\n    let mut observed: u32 = 0;\n\n    for (k, v) in &m {\n        assert_eq!(*v, *k * 2);\n        observed |= 1 << *k;\n    }\n    assert_eq!(observed, 0xFFFF_FFFF);\n}\n\n#[test]\nfn test_keys() {\n    let vec = vec![(1, 'a'), (2, 'b'), (3, 'c')];\n    let map: HashMap<_, _> = vec.into_iter().collect();\n    let keys: Vec<_> = map.keys().cloned().collect();\n    assert_eq!(keys.len(), 3);\n    assert!(keys.contains(&1));\n    assert!(keys.contains(&2));\n    assert!(keys.contains(&3));\n}\n\n#[test]\nfn test_values() {\n    let vec = vec![(1, 'a'), (2, 'b'), (3, 'c')];\n    let map: HashMap<_, _> = vec.into_iter().collect();\n    let values: Vec<_> = map.values().cloned().collect();\n    assert_eq!(values.len(), 3);\n    assert!(values.contains(&'a'));\n    assert!(values.contains(&'b'));\n    assert!(values.contains(&'c'));\n}\n\n#[test]\nfn test_values_mut() {\n    let vec = vec![(1, 1), (2, 2), (3, 3)];\n    let mut map: HashMap<_, _> = vec.into_iter().collect();\n    for value in map.values_mut() {\n        *value = (*value) * 2\n    }\n    let values: Vec<_> = map.values().cloned().collect();\n    assert_eq!(values.len(), 3);\n    assert!(values.contains(&2));\n    assert!(values.contains(&4));\n    assert!(values.contains(&6));\n}\n\n#[test]\nfn test_into_keys() {\n    let vec = vec![(1, 'a'), (2, 'b'), (3, 'c')];\n    let map: HashMap<_, _> = vec.into_iter().collect();\n    let keys: Vec<_> = map.into_keys().collect();\n\n    assert_eq!(keys.len(), 3);\n    assert!(keys.contains(&1));\n    assert!(keys.contains(&2));\n    assert!(keys.contains(&3));\n}\n\n#[test]\nfn test_into_values() {\n    let vec = vec![(1, 'a'), (2, 'b'), (3, 'c')];\n    let map: HashMap<_, _> = vec.into_iter().collect();\n    let values: Vec<_> = map.into_values().collect();\n\n    assert_eq!(values.len(), 3);\n    assert!(values.contains(&'a'));\n    assert!(values.contains(&'b'));\n    assert!(values.contains(&'c'));\n}\n\n#[test]\nfn test_find() {\n    let mut m = HashMap::new();\n    assert!(m.get(&1).is_none());\n    m.insert(1, 2);\n    match m.get(&1) {\n        None => panic!(),\n        Some(v) => assert_eq!(*v, 2),\n    }\n}\n\n#[test]\nfn test_eq() {\n    let mut m1 = HashMap::new();\n    m1.insert(1, 2);\n    m1.insert(2, 3);\n    m1.insert(3, 4);\n\n    let mut m2 = HashMap::new();\n    m2.insert(1, 2);\n    m2.insert(2, 3);\n\n    assert!(m1 != m2);\n\n    m2.insert(3, 4);\n\n    assert_eq!(m1, m2);\n}\n\n#[test]\nfn test_show() {\n    let mut map = HashMap::new();\n    let empty: HashMap<i32, i32> = HashMap::new();\n\n    map.insert(1, 2);\n    map.insert(3, 4);\n\n    let map_str = format!(\"{:?}\", map);\n\n    assert!(map_str == \"{1: 2, 3: 4}\" || map_str == \"{3: 4, 1: 2}\");\n    assert_eq!(format!(\"{:?}\", empty), \"{}\");\n}\n\n#[test]\nfn test_reserve_shrink_to_fit() {\n    let mut m = HashMap::new();\n    m.insert(0, 0);\n    m.remove(&0);\n    assert!(m.capacity() >= m.len());\n    for i in 0..128 {\n        m.insert(i, i);\n    }\n    m.reserve(256);\n\n    let usable_cap = m.capacity();\n    for i in 128..(128 + 256) {\n        m.insert(i, i);\n        assert_eq!(m.capacity(), usable_cap);\n    }\n\n    for i in 100..(128 + 256) {\n        assert_eq!(m.remove(&i), Some(i));\n    }\n    m.shrink_to_fit();\n\n    assert_eq!(m.len(), 100);\n    assert!(!m.is_empty());\n    assert!(m.capacity() >= m.len());\n\n    for i in 0..100 {\n        assert_eq!(m.remove(&i), Some(i));\n    }\n    m.shrink_to_fit();\n    m.insert(0, 0);\n\n    assert_eq!(m.len(), 1);\n    assert!(m.capacity() >= m.len());\n    assert_eq!(m.remove(&0), Some(0));\n}\n\n#[test]\nfn test_from_iter() {\n    let xs = [(1, 1), (2, 2), (2, 2), (3, 3), (4, 4), (5, 5), (6, 6)];\n\n    let map: HashMap<_, _> = xs.iter().cloned().collect();\n\n    for &(k, v) in &xs {\n        assert_eq!(map.get(&k), Some(&v));\n    }\n\n    assert_eq!(map.iter().len(), xs.len() - 1);\n}\n\n#[test]\nfn test_size_hint() {\n    let xs = [(1, 1), (2, 2), (3, 3), (4, 4), (5, 5), (6, 6)];\n\n    let map: HashMap<_, _> = xs.iter().cloned().collect();\n\n    let mut iter = map.iter();\n\n    for _ in iter.by_ref().take(3) {}\n\n    assert_eq!(iter.size_hint(), (3, Some(3)));\n}\n\n#[test]\nfn test_iter_len() {\n    let xs = [(1, 1), (2, 2), (3, 3), (4, 4), (5, 5), (6, 6)];\n\n    let map: HashMap<_, _> = xs.iter().cloned().collect();\n\n    let mut iter = map.iter();\n\n    for _ in iter.by_ref().take(3) {}\n\n    assert_eq!(iter.len(), 3);\n}\n\n#[test]\nfn test_mut_size_hint() {\n    let xs = [(1, 1), (2, 2), (3, 3), (4, 4), (5, 5), (6, 6)];\n\n    let mut map: HashMap<_, _> = xs.iter().cloned().collect();\n\n    let mut iter = map.iter_mut();\n\n    for _ in iter.by_ref().take(3) {}\n\n    assert_eq!(iter.size_hint(), (3, Some(3)));\n}\n\n#[test]\nfn test_iter_mut_len() {\n    let xs = [(1, 1), (2, 2), (3, 3), (4, 4), (5, 5), (6, 6)];\n\n    let mut map: HashMap<_, _> = xs.iter().cloned().collect();\n\n    let mut iter = map.iter_mut();\n\n    for _ in iter.by_ref().take(3) {}\n\n    assert_eq!(iter.len(), 3);\n}\n\n#[test]\nfn test_index() {\n    let mut map = HashMap::new();\n\n    map.insert(1, 2);\n    map.insert(2, 1);\n    map.insert(3, 4);\n\n    assert_eq!(map[&2], 1);\n}\n\n#[test]\n#[should_panic]\nfn test_index_nonexistent() {\n    let mut map = HashMap::new();\n\n    map.insert(1, 2);\n    map.insert(2, 1);\n    map.insert(3, 4);\n\n    map[&4];\n}\n\n#[test]\nfn test_entry() {\n    let xs = [(1, 10), (2, 20), (3, 30), (4, 40), (5, 50), (6, 60)];\n\n    let mut map: HashMap<_, _> = xs.iter().cloned().collect();\n\n    // Existing key (insert)\n    match map.entry(1) {\n        Vacant(_) => unreachable!(),\n        Occupied(mut view) => {\n            assert_eq!(view.get(), &10);\n            assert_eq!(view.insert(100), 10);\n        }\n    }\n    assert_eq!(map.get(&1).unwrap(), &100);\n    assert_eq!(map.len(), 6);\n\n    // Existing key (update)\n    match map.entry(2) {\n        Vacant(_) => unreachable!(),\n        Occupied(mut view) => {\n            let v = view.get_mut();\n            let new_v = (*v) * 10;\n            *v = new_v;\n        }\n    }\n    assert_eq!(map.get(&2).unwrap(), &200);\n    assert_eq!(map.len(), 6);\n\n    // Existing key (take)\n    match map.entry(3) {\n        Vacant(_) => unreachable!(),\n        Occupied(view) => {\n            assert_eq!(view.remove(), 30);\n        }\n    }\n    assert_eq!(map.get(&3), None);\n    assert_eq!(map.len(), 5);\n\n    // Inexistent key (insert)\n    match map.entry(10) {\n        Occupied(_) => unreachable!(),\n        Vacant(view) => {\n            assert_eq!(*view.insert(1000), 1000);\n        }\n    }\n    assert_eq!(map.get(&10).unwrap(), &1000);\n    assert_eq!(map.len(), 6);\n}\n\n#[test]\nfn test_entry_take_doesnt_corrupt() {\n    #![allow(deprecated)] //rand\n    // Test for #19292\n    fn check(m: &HashMap<i32, ()>) {\n        for k in m.keys() {\n            assert!(m.contains_key(k), \"{} is in keys() but not in the map?\", k);\n        }\n    }\n\n    let mut m = HashMap::new();\n    let mut rng = thread_rng();\n\n    // Populate the map with some items.\n    for _ in 0..50 {\n        let x = rng.gen_range(-10, 10);\n        m.insert(x, ());\n    }\n\n    for _ in 0..1000 {\n        let x = rng.gen_range(-10, 10);\n        match m.entry(x) {\n            Vacant(_) => {}\n            Occupied(e) => {\n                e.remove();\n            }\n        }\n\n        check(&m);\n    }\n}\n\n#[test]\nfn test_extend_ref() {\n    let mut a = HashMap::new();\n    a.insert(1, \"one\");\n    let mut b = HashMap::new();\n    b.insert(2, \"two\");\n    b.insert(3, \"three\");\n\n    a.extend(&b);\n\n    assert_eq!(a.len(), 3);\n    assert_eq!(a[&1], \"one\");\n    assert_eq!(a[&2], \"two\");\n    assert_eq!(a[&3], \"three\");\n}\n\n#[test]\nfn test_capacity_not_less_than_len() {\n    let mut a = HashMap::new();\n    let mut item = 0;\n\n    for _ in 0..116 {\n        a.insert(item, 0);\n        item += 1;\n    }\n\n    assert!(a.capacity() > a.len());\n\n    let free = a.capacity() - a.len();\n    for _ in 0..free {\n        a.insert(item, 0);\n        item += 1;\n    }\n\n    assert_eq!(a.len(), a.capacity());\n\n    // Insert at capacity should cause allocation.\n    a.insert(item, 0);\n    assert!(a.capacity() > a.len());\n}\n\n#[test]\nfn test_occupied_entry_key() {\n    let mut a = HashMap::new();\n    let key = \"hello there\";\n    let value = \"value goes here\";\n    assert!(a.is_empty());\n    a.insert(key, value);\n    assert_eq!(a.len(), 1);\n    assert_eq!(a[key], value);\n\n    match a.entry(key) {\n        Vacant(_) => panic!(),\n        Occupied(e) => assert_eq!(key, *e.key()),\n    }\n    assert_eq!(a.len(), 1);\n    assert_eq!(a[key], value);\n}\n\n#[test]\nfn test_vacant_entry_key() {\n    let mut a = HashMap::new();\n    let key = \"hello there\";\n    let value = \"value goes here\";\n\n    assert!(a.is_empty());\n    match a.entry(key) {\n        Occupied(_) => panic!(),\n        Vacant(e) => {\n            assert_eq!(key, *e.key());\n            e.insert(value);\n        }\n    }\n    assert_eq!(a.len(), 1);\n    assert_eq!(a[key], value);\n}\n\n#[test]\nfn test_retain() {\n    let mut map: HashMap<i32, i32> = (0..100).map(|x| (x, x * 10)).collect();\n\n    map.retain(|&k, _| k % 2 == 0);\n    assert_eq!(map.len(), 50);\n    assert_eq!(map[&2], 20);\n    assert_eq!(map[&4], 40);\n    assert_eq!(map[&6], 60);\n}\n\n#[test]\nfn test_try_reserve() {\n    let mut empty_bytes: HashMap<u8, u8> = HashMap::new();\n\n    const MAX_USIZE: usize = usize::MAX;\n\n    if let Err(CapacityOverflow) = empty_bytes.try_reserve(MAX_USIZE) {\n    } else {\n        panic!(\"usize::MAX should trigger an overflow!\");\n    }\n\n    if let Err(AllocError { .. }) = empty_bytes.try_reserve(MAX_USIZE / 8) {\n    } else {\n        panic!(\"usize::MAX / 8 should trigger an OOM!\")\n    }\n}\n\n#[test]\nfn test_raw_entry() {\n    use super::RawEntryMut::{Occupied, Vacant};\n\n    let xs = [(1i32, 10i32), (2, 20), (3, 30), (4, 40), (5, 50), (6, 60)];\n\n    let mut map: HashMap<_, _> = xs.iter().cloned().collect();\n\n    let compute_hash = |map: &HashMap<i32, i32>, k: i32| -> u64 {\n        use core::hash::{BuildHasher, Hash, Hasher};\n\n        let mut hasher = map.hasher().build_hasher();\n        k.hash(&mut hasher);\n        hasher.finish()\n    };\n\n    // Existing key (insert)\n    match map.raw_entry_mut().from_key(&1) {\n        Vacant(_) => unreachable!(),\n        Occupied(mut view) => {\n            assert_eq!(view.get(), &10);\n            assert_eq!(view.insert(100), 10);\n        }\n    }\n    let hash1 = compute_hash(&map, 1);\n    assert_eq!(map.raw_entry().from_key(&1).unwrap(), (&1, &100));\n    assert_eq!(map.raw_entry().from_hash(hash1, |k| *k == 1).unwrap(), (&1, &100));\n    assert_eq!(map.raw_entry().from_key_hashed_nocheck(hash1, &1).unwrap(), (&1, &100));\n    assert_eq!(map.len(), 6);\n\n    // Existing key (update)\n    match map.raw_entry_mut().from_key(&2) {\n        Vacant(_) => unreachable!(),\n        Occupied(mut view) => {\n            let v = view.get_mut();\n            let new_v = (*v) * 10;\n            *v = new_v;\n        }\n    }\n    let hash2 = compute_hash(&map, 2);\n    assert_eq!(map.raw_entry().from_key(&2).unwrap(), (&2, &200));\n    assert_eq!(map.raw_entry().from_hash(hash2, |k| *k == 2).unwrap(), (&2, &200));\n    assert_eq!(map.raw_entry().from_key_hashed_nocheck(hash2, &2).unwrap(), (&2, &200));\n    assert_eq!(map.len(), 6);\n\n    // Existing key (take)\n    let hash3 = compute_hash(&map, 3);\n    match map.raw_entry_mut().from_key_hashed_nocheck(hash3, &3) {\n        Vacant(_) => unreachable!(),\n        Occupied(view) => {\n            assert_eq!(view.remove_entry(), (3, 30));\n        }\n    }\n    assert_eq!(map.raw_entry().from_key(&3), None);\n    assert_eq!(map.raw_entry().from_hash(hash3, |k| *k == 3), None);\n    assert_eq!(map.raw_entry().from_key_hashed_nocheck(hash3, &3), None);\n    assert_eq!(map.len(), 5);\n\n    // Nonexistent key (insert)\n    match map.raw_entry_mut().from_key(&10) {\n        Occupied(_) => unreachable!(),\n        Vacant(view) => {\n            assert_eq!(view.insert(10, 1000), (&mut 10, &mut 1000));\n        }\n    }\n    assert_eq!(map.raw_entry().from_key(&10).unwrap(), (&10, &1000));\n    assert_eq!(map.len(), 6);\n\n    // Ensure all lookup methods produce equivalent results.\n    for k in 0..12 {\n        let hash = compute_hash(&map, k);\n        let v = map.get(&k).cloned();\n        let kv = v.as_ref().map(|v| (&k, v));\n\n        assert_eq!(map.raw_entry().from_key(&k), kv);\n        assert_eq!(map.raw_entry().from_hash(hash, |q| *q == k), kv);\n        assert_eq!(map.raw_entry().from_key_hashed_nocheck(hash, &k), kv);\n\n        match map.raw_entry_mut().from_key(&k) {\n            Occupied(mut o) => assert_eq!(Some(o.get_key_value()), kv),\n            Vacant(_) => assert_eq!(v, None),\n        }\n        match map.raw_entry_mut().from_key_hashed_nocheck(hash, &k) {\n            Occupied(mut o) => assert_eq!(Some(o.get_key_value()), kv),\n            Vacant(_) => assert_eq!(v, None),\n        }\n        match map.raw_entry_mut().from_hash(hash, |q| *q == k) {\n            Occupied(mut o) => assert_eq!(Some(o.get_key_value()), kv),\n            Vacant(_) => assert_eq!(v, None),\n        }\n    }\n}\n\nmod test_drain_filter {\n    use super::*;\n\n    use crate::panic::{catch_unwind, AssertUnwindSafe};\n    use crate::sync::atomic::{AtomicUsize, Ordering};\n\n    trait EqSorted: Iterator {\n        fn eq_sorted<I: IntoIterator<Item = Self::Item>>(self, other: I) -> bool;\n    }\n\n    impl<T: Iterator> EqSorted for T\n    where\n        T::Item: Eq + Ord,\n    {\n        fn eq_sorted<I: IntoIterator<Item = Self::Item>>(self, other: I) -> bool {\n            let mut v: Vec<_> = self.collect();\n            v.sort_unstable();\n            v.into_iter().eq(other)\n        }\n    }\n\n    #[test]\n    fn empty() {\n        let mut map: HashMap<i32, i32> = HashMap::new();\n        map.drain_filter(|_, _| unreachable!(\"there's nothing to decide on\"));\n        assert!(map.is_empty());\n    }\n\n    #[test]\n    fn consuming_nothing() {\n        let pairs = (0..3).map(|i| (i, i));\n        let mut map: HashMap<_, _> = pairs.collect();\n        assert!(map.drain_filter(|_, _| false).eq_sorted(crate::iter::empty()));\n        assert_eq!(map.len(), 3);\n    }\n\n    #[test]\n    fn consuming_all() {\n        let pairs = (0..3).map(|i| (i, i));\n        let mut map: HashMap<_, _> = pairs.clone().collect();\n        assert!(map.drain_filter(|_, _| true).eq_sorted(pairs));\n        assert!(map.is_empty());\n    }\n\n    #[test]\n    fn mutating_and_keeping() {\n        let pairs = (0..3).map(|i| (i, i));\n        let mut map: HashMap<_, _> = pairs.collect();\n        assert!(\n            map.drain_filter(|_, v| {\n                *v += 6;\n                false\n            })\n            .eq_sorted(crate::iter::empty())\n        );\n        assert!(map.keys().copied().eq_sorted(0..3));\n        assert!(map.values().copied().eq_sorted(6..9));\n    }\n\n    #[test]\n    fn mutating_and_removing() {\n        let pairs = (0..3).map(|i| (i, i));\n        let mut map: HashMap<_, _> = pairs.collect();\n        assert!(\n            map.drain_filter(|_, v| {\n                *v += 6;\n                true\n            })\n            .eq_sorted((0..3).map(|i| (i, i + 6)))\n        );\n        assert!(map.is_empty());\n    }\n\n    #[test]\n    fn drop_panic_leak() {\n        static PREDS: AtomicUsize = AtomicUsize::new(0);\n        static DROPS: AtomicUsize = AtomicUsize::new(0);\n\n        struct D;\n        impl Drop for D {\n            fn drop(&mut self) {\n                if DROPS.fetch_add(1, Ordering::SeqCst) == 1 {\n                    panic!(\"panic in `drop`\");\n                }\n            }\n        }\n\n        let mut map = (0..3).map(|i| (i, D)).collect::<HashMap<_, _>>();\n\n        catch_unwind(move || {\n            drop(map.drain_filter(|_, _| {\n                PREDS.fetch_add(1, Ordering::SeqCst);\n                true\n            }))\n        })\n        .unwrap_err();\n\n        assert_eq!(PREDS.load(Ordering::SeqCst), 3);\n        assert_eq!(DROPS.load(Ordering::SeqCst), 3);\n    }\n\n    #[test]\n    fn pred_panic_leak() {\n        static PREDS: AtomicUsize = AtomicUsize::new(0);\n        static DROPS: AtomicUsize = AtomicUsize::new(0);\n\n        struct D;\n        impl Drop for D {\n            fn drop(&mut self) {\n                DROPS.fetch_add(1, Ordering::SeqCst);\n            }\n        }\n\n        let mut map = (0..3).map(|i| (i, D)).collect::<HashMap<_, _>>();\n\n        catch_unwind(AssertUnwindSafe(|| {\n            drop(map.drain_filter(|_, _| match PREDS.fetch_add(1, Ordering::SeqCst) {\n                0 => true,\n                _ => panic!(),\n            }))\n        }))\n        .unwrap_err();\n\n        assert_eq!(PREDS.load(Ordering::SeqCst), 2);\n        assert_eq!(DROPS.load(Ordering::SeqCst), 1);\n        assert_eq!(map.len(), 2);\n    }\n\n    // Same as above, but attempt to use the iterator again after the panic in the predicate\n    #[test]\n    fn pred_panic_reuse() {\n        static PREDS: AtomicUsize = AtomicUsize::new(0);\n        static DROPS: AtomicUsize = AtomicUsize::new(0);\n\n        struct D;\n        impl Drop for D {\n            fn drop(&mut self) {\n                DROPS.fetch_add(1, Ordering::SeqCst);\n            }\n        }\n\n        let mut map = (0..3).map(|i| (i, D)).collect::<HashMap<_, _>>();\n\n        {\n            let mut it = map.drain_filter(|_, _| match PREDS.fetch_add(1, Ordering::SeqCst) {\n                0 => true,\n                _ => panic!(),\n            });\n            catch_unwind(AssertUnwindSafe(|| while it.next().is_some() {})).unwrap_err();\n            // Iterator behaviour after a panic is explicitly unspecified,\n            // so this is just the current implementation:\n            let result = catch_unwind(AssertUnwindSafe(|| it.next()));\n            assert!(result.is_err());\n        }\n\n        assert_eq!(PREDS.load(Ordering::SeqCst), 3);\n        assert_eq!(DROPS.load(Ordering::SeqCst), 1);\n        assert_eq!(map.len(), 2);\n    }\n}\n"],[2226,"//! Unordered containers, implemented as hash-tables\n\npub mod map;\npub mod set;\n"],[2227,"#[cfg(test)]\nmod tests;\n\nuse hashbrown::hash_set as base;\n\nuse crate::borrow::Borrow;\nuse crate::collections::TryReserveError;\nuse crate::fmt;\nuse crate::hash::{BuildHasher, Hash};\nuse crate::iter::{Chain, FromIterator, FusedIterator};\nuse crate::ops::{BitAnd, BitOr, BitXor, Sub};\n\nuse super::map::{map_try_reserve_error, RandomState};\n\n// Future Optimization (FIXME!)\n// ============================\n//\n// Iteration over zero sized values is a noop. There is no need\n// for `bucket.val` in the case of HashSet. I suppose we would need HKT\n// to get rid of it properly.\n\n/// A [hash set] implemented as a `HashMap` where the value is `()`.\n///\n/// As with the [`HashMap`] type, a `HashSet` requires that the elements\n/// implement the [`Eq`] and [`Hash`] traits. This can frequently be achieved by\n/// using `#[derive(PartialEq, Eq, Hash)]`. If you implement these yourself,\n/// it is important that the following property holds:\n///\n/// ```text\n/// k1 == k2 -> hash(k1) == hash(k2)\n/// ```\n///\n/// In other words, if two keys are equal, their hashes must be equal.\n///\n///\n/// It is a logic error for an item to be modified in such a way that the\n/// item's hash, as determined by the [`Hash`] trait, or its equality, as\n/// determined by the [`Eq`] trait, changes while it is in the set. This is\n/// normally only possible through [`Cell`], [`RefCell`], global state, I/O, or\n/// unsafe code. The behavior resulting from such a logic error is not\n/// specified, but will not result in undefined behavior. This could include\n/// panics, incorrect results, aborts, memory leaks, and non-termination.\n///\n/// # Examples\n///\n/// ```\n/// use std::collections::HashSet;\n/// // Type inference lets us omit an explicit type signature (which\n/// // would be `HashSet<String>` in this example).\n/// let mut books = HashSet::new();\n///\n/// // Add some books.\n/// books.insert(\"A Dance With Dragons\".to_string());\n/// books.insert(\"To Kill a Mockingbird\".to_string());\n/// books.insert(\"The Odyssey\".to_string());\n/// books.insert(\"The Great Gatsby\".to_string());\n///\n/// // Check for a specific one.\n/// if !books.contains(\"The Winds of Winter\") {\n///     println!(\"We have {} books, but The Winds of Winter ain't one.\",\n///              books.len());\n/// }\n///\n/// // Remove a book.\n/// books.remove(\"The Odyssey\");\n///\n/// // Iterate over everything.\n/// for book in &books {\n///     println!(\"{}\", book);\n/// }\n/// ```\n///\n/// The easiest way to use `HashSet` with a custom type is to derive\n/// [`Eq`] and [`Hash`]. We must also derive [`PartialEq`], this will in the\n/// future be implied by [`Eq`].\n///\n/// ```\n/// use std::collections::HashSet;\n/// #[derive(Hash, Eq, PartialEq, Debug)]\n/// struct Viking {\n///     name: String,\n///     power: usize,\n/// }\n///\n/// let mut vikings = HashSet::new();\n///\n/// vikings.insert(Viking { name: \"Einar\".to_string(), power: 9 });\n/// vikings.insert(Viking { name: \"Einar\".to_string(), power: 9 });\n/// vikings.insert(Viking { name: \"Olaf\".to_string(), power: 4 });\n/// vikings.insert(Viking { name: \"Harald\".to_string(), power: 8 });\n///\n/// // Use derived implementation to print the vikings.\n/// for x in &vikings {\n///     println!(\"{:?}\", x);\n/// }\n/// ```\n///\n/// A `HashSet` with fixed list of elements can be initialized from an array:\n///\n/// ```\n/// use std::collections::HashSet;\n///\n/// let viking_names: HashSet<&'static str> =\n///     [ \"Einar\", \"Olaf\", \"Harald\" ].iter().cloned().collect();\n/// // use the values stored in the set\n/// ```\n///\n/// [hash set]: crate::collections#use-the-set-variant-of-any-of-these-maps-when\n/// [`HashMap`]: crate::collections::HashMap\n/// [`RefCell`]: crate::cell::RefCell\n/// [`Cell`]: crate::cell::Cell\n#[cfg_attr(not(test), rustc_diagnostic_item = \"hashset_type\")]\n#[stable(feature = \"rust1\", since = \"1.0.0\")]\npub struct HashSet<T, S = RandomState> {\n    base: base::HashSet<T, S>,\n}\n\nimpl<T> HashSet<T, RandomState> {\n    /// Creates an empty `HashSet`.\n    ///\n    /// The hash set is initially created with a capacity of 0, so it will not allocate until it\n    /// is first inserted into.\n    ///\n    /// # Examples\n    ///\n    /// ```\n    /// use std::collections::HashSet;\n    /// let set: HashSet<i32> = HashSet::new();\n    /// ```\n    #[inline]\n    #[stable(feature = \"rust1\", since = \"1.0.0\")]\n    pub fn new() -> HashSet<T, RandomState> {\n        Default::default()\n    }\n\n    /// Creates an empty `HashSet` with the specified capacity.\n    ///\n    /// The hash set will be able to hold at least `capacity` elements without\n    /// reallocating. If `capacity` is 0, the hash set will not allocate.\n    ///\n    /// # Examples\n    ///\n    /// ```\n    /// use std::collections::HashSet;\n    /// let set: HashSet<i32> = HashSet::with_capacity(10);\n    /// assert!(set.capacity() >= 10);\n    /// ```\n    #[inline]\n    #[stable(feature = \"rust1\", since = \"1.0.0\")]\n    pub fn with_capacity(capacity: usize) -> HashSet<T, RandomState> {\n        HashSet { base: base::HashSet::with_capacity_and_hasher(capacity, Default::default()) }\n    }\n}\n\nimpl<T, S> HashSet<T, S> {\n    /// Returns the number of elements the set can hold without reallocating.\n    ///\n    /// # Examples\n    ///\n    /// ```\n    /// use std::collections::HashSet;\n    /// let set: HashSet<i32> = HashSet::with_capacity(100);\n    /// assert!(set.capacity() >= 100);\n    /// ```\n    #[inline]\n    #[stable(feature = \"rust1\", since = \"1.0.0\")]\n    pub fn capacity(&self) -> usize {\n        self.base.capacity()\n    }\n\n    /// An iterator visiting all elements in arbitrary order.\n    /// The iterator element type is `&'a T`.\n    ///\n    /// # Examples\n    ///\n    /// ```\n    /// use std::collections::HashSet;\n    /// let mut set = HashSet::new();\n    /// set.insert(\"a\");\n    /// set.insert(\"b\");\n    ///\n    /// // Will print in an arbitrary order.\n    /// for x in set.iter() {\n    ///     println!(\"{}\", x);\n    /// }\n    /// ```\n    #[inline]\n    #[stable(feature = \"rust1\", since = \"1.0.0\")]\n    pub fn iter(&self) -> Iter<'_, T> {\n        Iter { base: self.base.iter() }\n    }\n\n    /// Returns the number of elements in the set.\n    ///\n    /// # Examples\n    ///\n    /// ```\n    /// use std::collections::HashSet;\n    ///\n    /// let mut v = HashSet::new();\n    /// assert_eq!(v.len(), 0);\n    /// v.insert(1);\n    /// assert_eq!(v.len(), 1);\n    /// ```\n    #[doc(alias = \"length\")]\n    #[inline]\n    #[stable(feature = \"rust1\", since = \"1.0.0\")]\n    pub fn len(&self) -> usize {\n        self.base.len()\n    }\n\n    /// Returns `true` if the set contains no elements.\n    ///\n    /// # Examples\n    ///\n    /// ```\n    /// use std::collections::HashSet;\n    ///\n    /// let mut v = HashSet::new();\n    /// assert!(v.is_empty());\n    /// v.insert(1);\n    /// assert!(!v.is_empty());\n    /// ```\n    #[inline]\n    #[stable(feature = \"rust1\", since = \"1.0.0\")]\n    pub fn is_empty(&self) -> bool {\n        self.base.is_empty()\n    }\n\n    /// Clears the set, returning all elements in an iterator.\n    ///\n    /// # Examples\n    ///\n    /// ```\n    /// use std::collections::HashSet;\n    ///\n    /// let mut set: HashSet<_> = [1, 2, 3].iter().cloned().collect();\n    /// assert!(!set.is_empty());\n    ///\n    /// // print 1, 2, 3 in an arbitrary order\n    /// for i in set.drain() {\n    ///     println!(\"{}\", i);\n    /// }\n    ///\n    /// assert!(set.is_empty());\n    /// ```\n    #[inline]\n    #[stable(feature = \"drain\", since = \"1.6.0\")]\n    pub fn drain(&mut self) -> Drain<'_, T> {\n        Drain { base: self.base.drain() }\n    }\n\n    /// Creates an iterator which uses a closure to determine if a value should be removed.\n    ///\n    /// If the closure returns true, then the value is removed and yielded.\n    /// If the closure returns false, the value will remain in the list and will not be yielded\n    /// by the iterator.\n    ///\n    /// If the iterator is only partially consumed or not consumed at all, each of the remaining\n    /// values will still be subjected to the closure and removed and dropped if it returns true.\n    ///\n    /// It is unspecified how many more values will be subjected to the closure\n    /// if a panic occurs in the closure, or if a panic occurs while dropping a value, or if the\n    /// `DrainFilter` itself is leaked.\n    ///\n    /// # Examples\n    ///\n    /// Splitting a set into even and odd values, reusing the original set:\n    ///\n    /// ```\n    /// #![feature(hash_drain_filter)]\n    /// use std::collections::HashSet;\n    ///\n    /// let mut set: HashSet<i32> = (0..8).collect();\n    /// let drained: HashSet<i32> = set.drain_filter(|v| v % 2 == 0).collect();\n    ///\n    /// let mut evens = drained.into_iter().collect::<Vec<_>>();\n    /// let mut odds = set.into_iter().collect::<Vec<_>>();\n    /// evens.sort();\n    /// odds.sort();\n    ///\n    /// assert_eq!(evens, vec![0, 2, 4, 6]);\n    /// assert_eq!(odds, vec![1, 3, 5, 7]);\n    /// ```\n    #[inline]\n    #[unstable(feature = \"hash_drain_filter\", issue = \"59618\")]\n    pub fn drain_filter<F>(&mut self, pred: F) -> DrainFilter<'_, T, F>\n    where\n        F: FnMut(&T) -> bool,\n    {\n        DrainFilter { base: self.base.drain_filter(pred) }\n    }\n\n    /// Clears the set, removing all values.\n    ///\n    /// # Examples\n    ///\n    /// ```\n    /// use std::collections::HashSet;\n    ///\n    /// let mut v = HashSet::new();\n    /// v.insert(1);\n    /// v.clear();\n    /// assert!(v.is_empty());\n    /// ```\n    #[inline]\n    #[stable(feature = \"rust1\", since = \"1.0.0\")]\n    pub fn clear(&mut self) {\n        self.base.clear()\n    }\n\n    /// Creates a new empty hash set which will use the given hasher to hash\n    /// keys.\n    ///\n    /// The hash set is also created with the default initial capacity.\n    ///\n    /// Warning: `hasher` is normally randomly generated, and\n    /// is designed to allow `HashSet`s to be resistant to attacks that\n    /// cause many collisions and very poor performance. Setting it\n    /// manually using this function can expose a DoS attack vector.\n    ///\n    /// The `hash_builder` passed should implement the [`BuildHasher`] trait for\n    /// the HashMap to be useful, see its documentation for details.\n    ///\n    /// # Examples\n    ///\n    /// ```\n    /// use std::collections::HashSet;\n    /// use std::collections::hash_map::RandomState;\n    ///\n    /// let s = RandomState::new();\n    /// let mut set = HashSet::with_hasher(s);\n    /// set.insert(2);\n    /// ```\n    #[inline]\n    #[stable(feature = \"hashmap_build_hasher\", since = \"1.7.0\")]\n    pub fn with_hasher(hasher: S) -> HashSet<T, S> {\n        HashSet { base: base::HashSet::with_hasher(hasher) }\n    }\n\n    /// Creates an empty `HashSet` with the specified capacity, using\n    /// `hasher` to hash the keys.\n    ///\n    /// The hash set will be able to hold at least `capacity` elements without\n    /// reallocating. If `capacity` is 0, the hash set will not allocate.\n    ///\n    /// Warning: `hasher` is normally randomly generated, and\n    /// is designed to allow `HashSet`s to be resistant to attacks that\n    /// cause many collisions and very poor performance. Setting it\n    /// manually using this function can expose a DoS attack vector.\n    ///\n    /// The `hash_builder` passed should implement the [`BuildHasher`] trait for\n    /// the HashMap to be useful, see its documentation for details.\n    ///\n    /// # Examples\n    ///\n    /// ```\n    /// use std::collections::HashSet;\n    /// use std::collections::hash_map::RandomState;\n    ///\n    /// let s = RandomState::new();\n    /// let mut set = HashSet::with_capacity_and_hasher(10, s);\n    /// set.insert(1);\n    /// ```\n    #[inline]\n    #[stable(feature = \"hashmap_build_hasher\", since = \"1.7.0\")]\n    pub fn with_capacity_and_hasher(capacity: usize, hasher: S) -> HashSet<T, S> {\n        HashSet { base: base::HashSet::with_capacity_and_hasher(capacity, hasher) }\n    }\n\n    /// Returns a reference to the set's [`BuildHasher`].\n    ///\n    /// # Examples\n    ///\n    /// ```\n    /// use std::collections::HashSet;\n    /// use std::collections::hash_map::RandomState;\n    ///\n    /// let hasher = RandomState::new();\n    /// let set: HashSet<i32> = HashSet::with_hasher(hasher);\n    /// let hasher: &RandomState = set.hasher();\n    /// ```\n    #[inline]\n    #[stable(feature = \"hashmap_public_hasher\", since = \"1.9.0\")]\n    pub fn hasher(&self) -> &S {\n        self.base.hasher()\n    }\n}\n\nimpl<T, S> HashSet<T, S>\nwhere\n    T: Eq + Hash,\n    S: BuildHasher,\n{\n    /// Reserves capacity for at least `additional` more elements to be inserted\n    /// in the `HashSet`. The collection may reserve more space to avoid\n    /// frequent reallocations.\n    ///\n    /// # Panics\n    ///\n    /// Panics if the new allocation size overflows `usize`.\n    ///\n    /// # Examples\n    ///\n    /// ```\n    /// use std::collections::HashSet;\n    /// let mut set: HashSet<i32> = HashSet::new();\n    /// set.reserve(10);\n    /// assert!(set.capacity() >= 10);\n    /// ```\n    #[inline]\n    #[stable(feature = \"rust1\", since = \"1.0.0\")]\n    pub fn reserve(&mut self, additional: usize) {\n        self.base.reserve(additional)\n    }\n\n    /// Tries to reserve capacity for at least `additional` more elements to be inserted\n    /// in the given `HashSet<K, V>`. The collection may reserve more space to avoid\n    /// frequent reallocations.\n    ///\n    /// # Errors\n    ///\n    /// If the capacity overflows, or the allocator reports a failure, then an error\n    /// is returned.\n    ///\n    /// # Examples\n    ///\n    /// ```\n    /// #![feature(try_reserve)]\n    /// use std::collections::HashSet;\n    /// let mut set: HashSet<i32> = HashSet::new();\n    /// set.try_reserve(10).expect(\"why is the test harness OOMing on 10 bytes?\");\n    /// ```\n    #[inline]\n    #[unstable(feature = \"try_reserve\", reason = \"new API\", issue = \"48043\")]\n    pub fn try_reserve(&mut self, additional: usize) -> Result<(), TryReserveError> {\n        self.base.try_reserve(additional).map_err(map_try_reserve_error)\n    }\n\n    /// Shrinks the capacity of the set as much as possible. It will drop\n    /// down as much as possible while maintaining the internal rules\n    /// and possibly leaving some space in accordance with the resize policy.\n    ///\n    /// # Examples\n    ///\n    /// ```\n    /// use std::collections::HashSet;\n    ///\n    /// let mut set = HashSet::with_capacity(100);\n    /// set.insert(1);\n    /// set.insert(2);\n    /// assert!(set.capacity() >= 100);\n    /// set.shrink_to_fit();\n    /// assert!(set.capacity() >= 2);\n    /// ```\n    #[inline]\n    #[stable(feature = \"rust1\", since = \"1.0.0\")]\n    pub fn shrink_to_fit(&mut self) {\n        self.base.shrink_to_fit()\n    }\n\n    /// Shrinks the capacity of the set with a lower limit. It will drop\n    /// down no lower than the supplied limit while maintaining the internal rules\n    /// and possibly leaving some space in accordance with the resize policy.\n    ///\n    /// If the current capacity is less than the lower limit, this is a no-op.\n    /// # Examples\n    ///\n    /// ```\n    /// #![feature(shrink_to)]\n    /// use std::collections::HashSet;\n    ///\n    /// let mut set = HashSet::with_capacity(100);\n    /// set.insert(1);\n    /// set.insert(2);\n    /// assert!(set.capacity() >= 100);\n    /// set.shrink_to(10);\n    /// assert!(set.capacity() >= 10);\n    /// set.shrink_to(0);\n    /// assert!(set.capacity() >= 2);\n    /// ```\n    #[inline]\n    #[unstable(feature = \"shrink_to\", reason = \"new API\", issue = \"56431\")]\n    pub fn shrink_to(&mut self, min_capacity: usize) {\n        self.base.shrink_to(min_capacity)\n    }\n\n    /// Visits the values representing the difference,\n    /// i.e., the values that are in `self` but not in `other`.\n    ///\n    /// # Examples\n    ///\n    /// ```\n    /// use std::collections::HashSet;\n    /// let a: HashSet<_> = [1, 2, 3].iter().cloned().collect();\n    /// let b: HashSet<_> = [4, 2, 3, 4].iter().cloned().collect();\n    ///\n    /// // Can be seen as `a - b`.\n    /// for x in a.difference(&b) {\n    ///     println!(\"{}\", x); // Print 1\n    /// }\n    ///\n    /// let diff: HashSet<_> = a.difference(&b).collect();\n    /// assert_eq!(diff, [1].iter().collect());\n    ///\n    /// // Note that difference is not symmetric,\n    /// // and `b - a` means something else:\n    /// let diff: HashSet<_> = b.difference(&a).collect();\n    /// assert_eq!(diff, [4].iter().collect());\n    /// ```\n    #[inline]\n    #[stable(feature = \"rust1\", since = \"1.0.0\")]\n    pub fn difference<'a>(&'a self, other: &'a HashSet<T, S>) -> Difference<'a, T, S> {\n        Difference { iter: self.iter(), other }\n    }\n\n    /// Visits the values representing the symmetric difference,\n    /// i.e., the values that are in `self` or in `other` but not in both.\n    ///\n    /// # Examples\n    ///\n    /// ```\n    /// use std::collections::HashSet;\n    /// let a: HashSet<_> = [1, 2, 3].iter().cloned().collect();\n    /// let b: HashSet<_> = [4, 2, 3, 4].iter().cloned().collect();\n    ///\n    /// // Print 1, 4 in arbitrary order.\n    /// for x in a.symmetric_difference(&b) {\n    ///     println!(\"{}\", x);\n    /// }\n    ///\n    /// let diff1: HashSet<_> = a.symmetric_difference(&b).collect();\n    /// let diff2: HashSet<_> = b.symmetric_difference(&a).collect();\n    ///\n    /// assert_eq!(diff1, diff2);\n    /// assert_eq!(diff1, [1, 4].iter().collect());\n    /// ```\n    #[inline]\n    #[stable(feature = \"rust1\", since = \"1.0.0\")]\n    pub fn symmetric_difference<'a>(\n        &'a self,\n        other: &'a HashSet<T, S>,\n    ) -> SymmetricDifference<'a, T, S> {\n        SymmetricDifference { iter: self.difference(other).chain(other.difference(self)) }\n    }\n\n    /// Visits the values representing the intersection,\n    /// i.e., the values that are both in `self` and `other`.\n    ///\n    /// # Examples\n    ///\n    /// ```\n    /// use std::collections::HashSet;\n    /// let a: HashSet<_> = [1, 2, 3].iter().cloned().collect();\n    /// let b: HashSet<_> = [4, 2, 3, 4].iter().cloned().collect();\n    ///\n    /// // Print 2, 3 in arbitrary order.\n    /// for x in a.intersection(&b) {\n    ///     println!(\"{}\", x);\n    /// }\n    ///\n    /// let intersection: HashSet<_> = a.intersection(&b).collect();\n    /// assert_eq!(intersection, [2, 3].iter().collect());\n    /// ```\n    #[inline]\n    #[stable(feature = \"rust1\", since = \"1.0.0\")]\n    pub fn intersection<'a>(&'a self, other: &'a HashSet<T, S>) -> Intersection<'a, T, S> {\n        if self.len() <= other.len() {\n            Intersection { iter: self.iter(), other }\n        } else {\n            Intersection { iter: other.iter(), other: self }\n        }\n    }\n\n    /// Visits the values representing the union,\n    /// i.e., all the values in `self` or `other`, without duplicates.\n    ///\n    /// # Examples\n    ///\n    /// ```\n    /// use std::collections::HashSet;\n    /// let a: HashSet<_> = [1, 2, 3].iter().cloned().collect();\n    /// let b: HashSet<_> = [4, 2, 3, 4].iter().cloned().collect();\n    ///\n    /// // Print 1, 2, 3, 4 in arbitrary order.\n    /// for x in a.union(&b) {\n    ///     println!(\"{}\", x);\n    /// }\n    ///\n    /// let union: HashSet<_> = a.union(&b).collect();\n    /// assert_eq!(union, [1, 2, 3, 4].iter().collect());\n    /// ```\n    #[inline]\n    #[stable(feature = \"rust1\", since = \"1.0.0\")]\n    pub fn union<'a>(&'a self, other: &'a HashSet<T, S>) -> Union<'a, T, S> {\n        if self.len() >= other.len() {\n            Union { iter: self.iter().chain(other.difference(self)) }\n        } else {\n            Union { iter: other.iter().chain(self.difference(other)) }\n        }\n    }\n\n    /// Returns `true` if the set contains a value.\n    ///\n    /// The value may be any borrowed form of the set's value type, but\n    /// [`Hash`] and [`Eq`] on the borrowed form *must* match those for\n    /// the value type.\n    ///\n    /// # Examples\n    ///\n    /// ```\n    /// use std::collections::HashSet;\n    ///\n    /// let set: HashSet<_> = [1, 2, 3].iter().cloned().collect();\n    /// assert_eq!(set.contains(&1), true);\n    /// assert_eq!(set.contains(&4), false);\n    /// ```\n    #[inline]\n    #[stable(feature = \"rust1\", since = \"1.0.0\")]\n    pub fn contains<Q: ?Sized>(&self, value: &Q) -> bool\n    where\n        T: Borrow<Q>,\n        Q: Hash + Eq,\n    {\n        self.base.contains(value)\n    }\n\n    /// Returns a reference to the value in the set, if any, that is equal to the given value.\n    ///\n    /// The value may be any borrowed form of the set's value type, but\n    /// [`Hash`] and [`Eq`] on the borrowed form *must* match those for\n    /// the value type.\n    ///\n    /// # Examples\n    ///\n    /// ```\n    /// use std::collections::HashSet;\n    ///\n    /// let set: HashSet<_> = [1, 2, 3].iter().cloned().collect();\n    /// assert_eq!(set.get(&2), Some(&2));\n    /// assert_eq!(set.get(&4), None);\n    /// ```\n    #[inline]\n    #[stable(feature = \"set_recovery\", since = \"1.9.0\")]\n    pub fn get<Q: ?Sized>(&self, value: &Q) -> Option<&T>\n    where\n        T: Borrow<Q>,\n        Q: Hash + Eq,\n    {\n        self.base.get(value)\n    }\n\n    /// Inserts the given `value` into the set if it is not present, then\n    /// returns a reference to the value in the set.\n    ///\n    /// # Examples\n    ///\n    /// ```\n    /// #![feature(hash_set_entry)]\n    ///\n    /// use std::collections::HashSet;\n    ///\n    /// let mut set: HashSet<_> = [1, 2, 3].iter().cloned().collect();\n    /// assert_eq!(set.len(), 3);\n    /// assert_eq!(set.get_or_insert(2), &2);\n    /// assert_eq!(set.get_or_insert(100), &100);\n    /// assert_eq!(set.len(), 4); // 100 was inserted\n    /// ```\n    #[inline]\n    #[unstable(feature = \"hash_set_entry\", issue = \"60896\")]\n    pub fn get_or_insert(&mut self, value: T) -> &T {\n        // Although the raw entry gives us `&mut T`, we only return `&T` to be consistent with\n        // `get`. Key mutation is \"raw\" because you're not supposed to affect `Eq` or `Hash`.\n        self.base.get_or_insert(value)\n    }\n\n    /// Inserts an owned copy of the given `value` into the set if it is not\n    /// present, then returns a reference to the value in the set.\n    ///\n    /// # Examples\n    ///\n    /// ```\n    /// #![feature(hash_set_entry)]\n    ///\n    /// use std::collections::HashSet;\n    ///\n    /// let mut set: HashSet<String> = [\"cat\", \"dog\", \"horse\"]\n    ///     .iter().map(|&pet| pet.to_owned()).collect();\n    ///\n    /// assert_eq!(set.len(), 3);\n    /// for &pet in &[\"cat\", \"dog\", \"fish\"] {\n    ///     let value = set.get_or_insert_owned(pet);\n    ///     assert_eq!(value, pet);\n    /// }\n    /// assert_eq!(set.len(), 4); // a new \"fish\" was inserted\n    /// ```\n    #[inline]\n    #[unstable(feature = \"hash_set_entry\", issue = \"60896\")]\n    pub fn get_or_insert_owned<Q: ?Sized>(&mut self, value: &Q) -> &T\n    where\n        T: Borrow<Q>,\n        Q: Hash + Eq + ToOwned<Owned = T>,\n    {\n        // Although the raw entry gives us `&mut T`, we only return `&T` to be consistent with\n        // `get`. Key mutation is \"raw\" because you're not supposed to affect `Eq` or `Hash`.\n        self.base.get_or_insert_owned(value)\n    }\n\n    /// Inserts a value computed from `f` into the set if the given `value` is\n    /// not present, then returns a reference to the value in the set.\n    ///\n    /// # Examples\n    ///\n    /// ```\n    /// #![feature(hash_set_entry)]\n    ///\n    /// use std::collections::HashSet;\n    ///\n    /// let mut set: HashSet<String> = [\"cat\", \"dog\", \"horse\"]\n    ///     .iter().map(|&pet| pet.to_owned()).collect();\n    ///\n    /// assert_eq!(set.len(), 3);\n    /// for &pet in &[\"cat\", \"dog\", \"fish\"] {\n    ///     let value = set.get_or_insert_with(pet, str::to_owned);\n    ///     assert_eq!(value, pet);\n    /// }\n    /// assert_eq!(set.len(), 4); // a new \"fish\" was inserted\n    /// ```\n    #[inline]\n    #[unstable(feature = \"hash_set_entry\", issue = \"60896\")]\n    pub fn get_or_insert_with<Q: ?Sized, F>(&mut self, value: &Q, f: F) -> &T\n    where\n        T: Borrow<Q>,\n        Q: Hash + Eq,\n        F: FnOnce(&Q) -> T,\n    {\n        // Although the raw entry gives us `&mut T`, we only return `&T` to be consistent with\n        // `get`. Key mutation is \"raw\" because you're not supposed to affect `Eq` or `Hash`.\n        self.base.get_or_insert_with(value, f)\n    }\n\n    /// Returns `true` if `self` has no elements in common with `other`.\n    /// This is equivalent to checking for an empty intersection.\n    ///\n    /// # Examples\n    ///\n    /// ```\n    /// use std::collections::HashSet;\n    ///\n    /// let a: HashSet<_> = [1, 2, 3].iter().cloned().collect();\n    /// let mut b = HashSet::new();\n    ///\n    /// assert_eq!(a.is_disjoint(&b), true);\n    /// b.insert(4);\n    /// assert_eq!(a.is_disjoint(&b), true);\n    /// b.insert(1);\n    /// assert_eq!(a.is_disjoint(&b), false);\n    /// ```\n    #[stable(feature = \"rust1\", since = \"1.0.0\")]\n    pub fn is_disjoint(&self, other: &HashSet<T, S>) -> bool {\n        if self.len() <= other.len() {\n            self.iter().all(|v| !other.contains(v))\n        } else {\n            other.iter().all(|v| !self.contains(v))\n        }\n    }\n\n    /// Returns `true` if the set is a subset of another,\n    /// i.e., `other` contains at least all the values in `self`.\n    ///\n    /// # Examples\n    ///\n    /// ```\n    /// use std::collections::HashSet;\n    ///\n    /// let sup: HashSet<_> = [1, 2, 3].iter().cloned().collect();\n    /// let mut set = HashSet::new();\n    ///\n    /// assert_eq!(set.is_subset(&sup), true);\n    /// set.insert(2);\n    /// assert_eq!(set.is_subset(&sup), true);\n    /// set.insert(4);\n    /// assert_eq!(set.is_subset(&sup), false);\n    /// ```\n    #[stable(feature = \"rust1\", since = \"1.0.0\")]\n    pub fn is_subset(&self, other: &HashSet<T, S>) -> bool {\n        if self.len() <= other.len() { self.iter().all(|v| other.contains(v)) } else { false }\n    }\n\n    /// Returns `true` if the set is a superset of another,\n    /// i.e., `self` contains at least all the values in `other`.\n    ///\n    /// # Examples\n    ///\n    /// ```\n    /// use std::collections::HashSet;\n    ///\n    /// let sub: HashSet<_> = [1, 2].iter().cloned().collect();\n    /// let mut set = HashSet::new();\n    ///\n    /// assert_eq!(set.is_superset(&sub), false);\n    ///\n    /// set.insert(0);\n    /// set.insert(1);\n    /// assert_eq!(set.is_superset(&sub), false);\n    ///\n    /// set.insert(2);\n    /// assert_eq!(set.is_superset(&sub), true);\n    /// ```\n    #[inline]\n    #[stable(feature = \"rust1\", since = \"1.0.0\")]\n    pub fn is_superset(&self, other: &HashSet<T, S>) -> bool {\n        other.is_subset(self)\n    }\n\n    /// Adds a value to the set.\n    ///\n    /// If the set did not have this value present, `true` is returned.\n    ///\n    /// If the set did have this value present, `false` is returned.\n    ///\n    /// # Examples\n    ///\n    /// ```\n    /// use std::collections::HashSet;\n    ///\n    /// let mut set = HashSet::new();\n    ///\n    /// assert_eq!(set.insert(2), true);\n    /// assert_eq!(set.insert(2), false);\n    /// assert_eq!(set.len(), 1);\n    /// ```\n    #[inline]\n    #[stable(feature = \"rust1\", since = \"1.0.0\")]\n    pub fn insert(&mut self, value: T) -> bool {\n        self.base.insert(value)\n    }\n\n    /// Adds a value to the set, replacing the existing value, if any, that is equal to the given\n    /// one. Returns the replaced value.\n    ///\n    /// # Examples\n    ///\n    /// ```\n    /// use std::collections::HashSet;\n    ///\n    /// let mut set = HashSet::new();\n    /// set.insert(Vec::<i32>::new());\n    ///\n    /// assert_eq!(set.get(&[][..]).unwrap().capacity(), 0);\n    /// set.replace(Vec::with_capacity(10));\n    /// assert_eq!(set.get(&[][..]).unwrap().capacity(), 10);\n    /// ```\n    #[inline]\n    #[stable(feature = \"set_recovery\", since = \"1.9.0\")]\n    pub fn replace(&mut self, value: T) -> Option<T> {\n        self.base.replace(value)\n    }\n\n    /// Removes a value from the set. Returns whether the value was\n    /// present in the set.\n    ///\n    /// The value may be any borrowed form of the set's value type, but\n    /// [`Hash`] and [`Eq`] on the borrowed form *must* match those for\n    /// the value type.\n    ///\n    /// # Examples\n    ///\n    /// ```\n    /// use std::collections::HashSet;\n    ///\n    /// let mut set = HashSet::new();\n    ///\n    /// set.insert(2);\n    /// assert_eq!(set.remove(&2), true);\n    /// assert_eq!(set.remove(&2), false);\n    /// ```\n    #[doc(alias = \"delete\")]\n    #[inline]\n    #[stable(feature = \"rust1\", since = \"1.0.0\")]\n    pub fn remove<Q: ?Sized>(&mut self, value: &Q) -> bool\n    where\n        T: Borrow<Q>,\n        Q: Hash + Eq,\n    {\n        self.base.remove(value)\n    }\n\n    /// Removes and returns the value in the set, if any, that is equal to the given one.\n    ///\n    /// The value may be any borrowed form of the set's value type, but\n    /// [`Hash`] and [`Eq`] on the borrowed form *must* match those for\n    /// the value type.\n    ///\n    /// # Examples\n    ///\n    /// ```\n    /// use std::collections::HashSet;\n    ///\n    /// let mut set: HashSet<_> = [1, 2, 3].iter().cloned().collect();\n    /// assert_eq!(set.take(&2), Some(2));\n    /// assert_eq!(set.take(&2), None);\n    /// ```\n    #[inline]\n    #[stable(feature = \"set_recovery\", since = \"1.9.0\")]\n    pub fn take<Q: ?Sized>(&mut self, value: &Q) -> Option<T>\n    where\n        T: Borrow<Q>,\n        Q: Hash + Eq,\n    {\n        self.base.take(value)\n    }\n\n    /// Retains only the elements specified by the predicate.\n    ///\n    /// In other words, remove all elements `e` such that `f(&e)` returns `false`.\n    ///\n    /// # Examples\n    ///\n    /// ```\n    /// use std::collections::HashSet;\n    ///\n    /// let xs = [1, 2, 3, 4, 5, 6];\n    /// let mut set: HashSet<i32> = xs.iter().cloned().collect();\n    /// set.retain(|&k| k % 2 == 0);\n    /// assert_eq!(set.len(), 3);\n    /// ```\n    #[stable(feature = \"retain_hash_collection\", since = \"1.18.0\")]\n    pub fn retain<F>(&mut self, f: F)\n    where\n        F: FnMut(&T) -> bool,\n    {\n        self.base.retain(f)\n    }\n}\n\n#[stable(feature = \"rust1\", since = \"1.0.0\")]\nimpl<T, S> Clone for HashSet<T, S>\nwhere\n    T: Clone,\n    S: Clone,\n{\n    #[inline]\n    fn clone(&self) -> Self {\n        Self { base: self.base.clone() }\n    }\n\n    #[inline]\n    fn clone_from(&mut self, other: &Self) {\n        self.base.clone_from(&other.base);\n    }\n}\n\n#[stable(feature = \"rust1\", since = \"1.0.0\")]\nimpl<T, S> PartialEq for HashSet<T, S>\nwhere\n    T: Eq + Hash,\n    S: BuildHasher,\n{\n    fn eq(&self, other: &HashSet<T, S>) -> bool {\n        if self.len() != other.len() {\n            return false;\n        }\n\n        self.iter().all(|key| other.contains(key))\n    }\n}\n\n#[stable(feature = \"rust1\", since = \"1.0.0\")]\nimpl<T, S> Eq for HashSet<T, S>\nwhere\n    T: Eq + Hash,\n    S: BuildHasher,\n{\n}\n\n#[stable(feature = \"rust1\", since = \"1.0.0\")]\nimpl<T, S> fmt::Debug for HashSet<T, S>\nwhere\n    T: fmt::Debug,\n{\n    fn fmt(&self, f: &mut fmt::Formatter<'_>) -> fmt::Result {\n        f.debug_set().entries(self.iter()).finish()\n    }\n}\n\n#[stable(feature = \"rust1\", since = \"1.0.0\")]\nimpl<T, S> FromIterator<T> for HashSet<T, S>\nwhere\n    T: Eq + Hash,\n    S: BuildHasher + Default,\n{\n    #[inline]\n    fn from_iter<I: IntoIterator<Item = T>>(iter: I) -> HashSet<T, S> {\n        let mut set = HashSet::with_hasher(Default::default());\n        set.extend(iter);\n        set\n    }\n}\n\n#[stable(feature = \"rust1\", since = \"1.0.0\")]\nimpl<T, S> Extend<T> for HashSet<T, S>\nwhere\n    T: Eq + Hash,\n    S: BuildHasher,\n{\n    #[inline]\n    fn extend<I: IntoIterator<Item = T>>(&mut self, iter: I) {\n        self.base.extend(iter);\n    }\n\n    #[inline]\n    fn extend_one(&mut self, item: T) {\n        self.base.insert(item);\n    }\n\n    #[inline]\n    fn extend_reserve(&mut self, additional: usize) {\n        self.base.extend_reserve(additional);\n    }\n}\n\n#[stable(feature = \"hash_extend_copy\", since = \"1.4.0\")]\nimpl<'a, T, S> Extend<&'a T> for HashSet<T, S>\nwhere\n    T: 'a + Eq + Hash + Copy,\n    S: BuildHasher,\n{\n    #[inline]\n    fn extend<I: IntoIterator<Item = &'a T>>(&mut self, iter: I) {\n        self.extend(iter.into_iter().cloned());\n    }\n\n    #[inline]\n    fn extend_one(&mut self, &item: &'a T) {\n        self.base.insert(item);\n    }\n\n    #[inline]\n    fn extend_reserve(&mut self, additional: usize) {\n        Extend::<T>::extend_reserve(self, additional)\n    }\n}\n\n#[stable(feature = \"rust1\", since = \"1.0.0\")]\nimpl<T, S> Default for HashSet<T, S>\nwhere\n    S: Default,\n{\n    /// Creates an empty `HashSet<T, S>` with the `Default` value for the hasher.\n    #[inline]\n    fn default() -> HashSet<T, S> {\n        HashSet { base: Default::default() }\n    }\n}\n\n#[stable(feature = \"rust1\", since = \"1.0.0\")]\nimpl<T, S> BitOr<&HashSet<T, S>> for &HashSet<T, S>\nwhere\n    T: Eq + Hash + Clone,\n    S: BuildHasher + Default,\n{\n    type Output = HashSet<T, S>;\n\n    /// Returns the union of `self` and `rhs` as a new `HashSet<T, S>`.\n    ///\n    /// # Examples\n    ///\n    /// ```\n    /// use std::collections::HashSet;\n    ///\n    /// let a: HashSet<_> = vec![1, 2, 3].into_iter().collect();\n    /// let b: HashSet<_> = vec![3, 4, 5].into_iter().collect();\n    ///\n    /// let set = &a | &b;\n    ///\n    /// let mut i = 0;\n    /// let expected = [1, 2, 3, 4, 5];\n    /// for x in &set {\n    ///     assert!(expected.contains(x));\n    ///     i += 1;\n    /// }\n    /// assert_eq!(i, expected.len());\n    /// ```\n    fn bitor(self, rhs: &HashSet<T, S>) -> HashSet<T, S> {\n        self.union(rhs).cloned().collect()\n    }\n}\n\n#[stable(feature = \"rust1\", since = \"1.0.0\")]\nimpl<T, S> BitAnd<&HashSet<T, S>> for &HashSet<T, S>\nwhere\n    T: Eq + Hash + Clone,\n    S: BuildHasher + Default,\n{\n    type Output = HashSet<T, S>;\n\n    /// Returns the intersection of `self` and `rhs` as a new `HashSet<T, S>`.\n    ///\n    /// # Examples\n    ///\n    /// ```\n    /// use std::collections::HashSet;\n    ///\n    /// let a: HashSet<_> = vec![1, 2, 3].into_iter().collect();\n    /// let b: HashSet<_> = vec![2, 3, 4].into_iter().collect();\n    ///\n    /// let set = &a & &b;\n    ///\n    /// let mut i = 0;\n    /// let expected = [2, 3];\n    /// for x in &set {\n    ///     assert!(expected.contains(x));\n    ///     i += 1;\n    /// }\n    /// assert_eq!(i, expected.len());\n    /// ```\n    fn bitand(self, rhs: &HashSet<T, S>) -> HashSet<T, S> {\n        self.intersection(rhs).cloned().collect()\n    }\n}\n\n#[stable(feature = \"rust1\", since = \"1.0.0\")]\nimpl<T, S> BitXor<&HashSet<T, S>> for &HashSet<T, S>\nwhere\n    T: Eq + Hash + Clone,\n    S: BuildHasher + Default,\n{\n    type Output = HashSet<T, S>;\n\n    /// Returns the symmetric difference of `self` and `rhs` as a new `HashSet<T, S>`.\n    ///\n    /// # Examples\n    ///\n    /// ```\n    /// use std::collections::HashSet;\n    ///\n    /// let a: HashSet<_> = vec![1, 2, 3].into_iter().collect();\n    /// let b: HashSet<_> = vec![3, 4, 5].into_iter().collect();\n    ///\n    /// let set = &a ^ &b;\n    ///\n    /// let mut i = 0;\n    /// let expected = [1, 2, 4, 5];\n    /// for x in &set {\n    ///     assert!(expected.contains(x));\n    ///     i += 1;\n    /// }\n    /// assert_eq!(i, expected.len());\n    /// ```\n    fn bitxor(self, rhs: &HashSet<T, S>) -> HashSet<T, S> {\n        self.symmetric_difference(rhs).cloned().collect()\n    }\n}\n\n#[stable(feature = \"rust1\", since = \"1.0.0\")]\nimpl<T, S> Sub<&HashSet<T, S>> for &HashSet<T, S>\nwhere\n    T: Eq + Hash + Clone,\n    S: BuildHasher + Default,\n{\n    type Output = HashSet<T, S>;\n\n    /// Returns the difference of `self` and `rhs` as a new `HashSet<T, S>`.\n    ///\n    /// # Examples\n    ///\n    /// ```\n    /// use std::collections::HashSet;\n    ///\n    /// let a: HashSet<_> = vec![1, 2, 3].into_iter().collect();\n    /// let b: HashSet<_> = vec![3, 4, 5].into_iter().collect();\n    ///\n    /// let set = &a - &b;\n    ///\n    /// let mut i = 0;\n    /// let expected = [1, 2];\n    /// for x in &set {\n    ///     assert!(expected.contains(x));\n    ///     i += 1;\n    /// }\n    /// assert_eq!(i, expected.len());\n    /// ```\n    fn sub(self, rhs: &HashSet<T, S>) -> HashSet<T, S> {\n        self.difference(rhs).cloned().collect()\n    }\n}\n\n/// An iterator over the items of a `HashSet`.\n///\n/// This `struct` is created by the [`iter`] method on [`HashSet`].\n/// See its documentation for more.\n///\n/// [`iter`]: HashSet::iter\n///\n/// # Examples\n///\n/// ```\n/// use std::collections::HashSet;\n///\n/// let a: HashSet<u32> = vec![1, 2, 3].into_iter().collect();\n///\n/// let mut iter = a.iter();\n/// ```\n#[stable(feature = \"rust1\", since = \"1.0.0\")]\npub struct Iter<'a, K: 'a> {\n    base: base::Iter<'a, K>,\n}\n\n/// An owning iterator over the items of a `HashSet`.\n///\n/// This `struct` is created by the [`into_iter`] method on [`HashSet`]\n/// (provided by the `IntoIterator` trait). See its documentation for more.\n///\n/// [`into_iter`]: IntoIterator::into_iter\n///\n/// # Examples\n///\n/// ```\n/// use std::collections::HashSet;\n///\n/// let a: HashSet<u32> = vec![1, 2, 3].into_iter().collect();\n///\n/// let mut iter = a.into_iter();\n/// ```\n#[stable(feature = \"rust1\", since = \"1.0.0\")]\npub struct IntoIter<K> {\n    base: base::IntoIter<K>,\n}\n\n/// A draining iterator over the items of a `HashSet`.\n///\n/// This `struct` is created by the [`drain`] method on [`HashSet`].\n/// See its documentation for more.\n///\n/// [`drain`]: HashSet::drain\n///\n/// # Examples\n///\n/// ```\n/// use std::collections::HashSet;\n///\n/// let mut a: HashSet<u32> = vec![1, 2, 3].into_iter().collect();\n///\n/// let mut drain = a.drain();\n/// ```\n#[stable(feature = \"rust1\", since = \"1.0.0\")]\npub struct Drain<'a, K: 'a> {\n    base: base::Drain<'a, K>,\n}\n\n/// A draining, filtering iterator over the items of a `HashSet`.\n///\n/// This `struct` is created by the [`drain_filter`] method on [`HashSet`].\n///\n/// [`drain_filter`]: HashSet::drain_filter\n///\n/// # Examples\n///\n/// ```\n/// #![feature(hash_drain_filter)]\n///\n/// use std::collections::HashSet;\n///\n/// let mut a: HashSet<u32> = vec![1, 2, 3].into_iter().collect();\n///\n/// let mut drain_filtered = a.drain_filter(|v| v % 2 == 0);\n/// ```\n#[unstable(feature = \"hash_drain_filter\", issue = \"59618\")]\npub struct DrainFilter<'a, K, F>\nwhere\n    F: FnMut(&K) -> bool,\n{\n    base: base::DrainFilter<'a, K, F>,\n}\n\n/// A lazy iterator producing elements in the intersection of `HashSet`s.\n///\n/// This `struct` is created by the [`intersection`] method on [`HashSet`].\n/// See its documentation for more.\n///\n/// [`intersection`]: HashSet::intersection\n///\n/// # Examples\n///\n/// ```\n/// use std::collections::HashSet;\n///\n/// let a: HashSet<u32> = vec![1, 2, 3].into_iter().collect();\n/// let b: HashSet<_> = [4, 2, 3, 4].iter().cloned().collect();\n///\n/// let mut intersection = a.intersection(&b);\n/// ```\n#[stable(feature = \"rust1\", since = \"1.0.0\")]\npub struct Intersection<'a, T: 'a, S: 'a> {\n    // iterator of the first set\n    iter: Iter<'a, T>,\n    // the second set\n    other: &'a HashSet<T, S>,\n}\n\n/// A lazy iterator producing elements in the difference of `HashSet`s.\n///\n/// This `struct` is created by the [`difference`] method on [`HashSet`].\n/// See its documentation for more.\n///\n/// [`difference`]: HashSet::difference\n///\n/// # Examples\n///\n/// ```\n/// use std::collections::HashSet;\n///\n/// let a: HashSet<u32> = vec![1, 2, 3].into_iter().collect();\n/// let b: HashSet<_> = [4, 2, 3, 4].iter().cloned().collect();\n///\n/// let mut difference = a.difference(&b);\n/// ```\n#[stable(feature = \"rust1\", since = \"1.0.0\")]\npub struct Difference<'a, T: 'a, S: 'a> {\n    // iterator of the first set\n    iter: Iter<'a, T>,\n    // the second set\n    other: &'a HashSet<T, S>,\n}\n\n/// A lazy iterator producing elements in the symmetric difference of `HashSet`s.\n///\n/// This `struct` is created by the [`symmetric_difference`] method on\n/// [`HashSet`]. See its documentation for more.\n///\n/// [`symmetric_difference`]: HashSet::symmetric_difference\n///\n/// # Examples\n///\n/// ```\n/// use std::collections::HashSet;\n///\n/// let a: HashSet<u32> = vec![1, 2, 3].into_iter().collect();\n/// let b: HashSet<_> = [4, 2, 3, 4].iter().cloned().collect();\n///\n/// let mut intersection = a.symmetric_difference(&b);\n/// ```\n#[stable(feature = \"rust1\", since = \"1.0.0\")]\npub struct SymmetricDifference<'a, T: 'a, S: 'a> {\n    iter: Chain<Difference<'a, T, S>, Difference<'a, T, S>>,\n}\n\n/// A lazy iterator producing elements in the union of `HashSet`s.\n///\n/// This `struct` is created by the [`union`] method on [`HashSet`].\n/// See its documentation for more.\n///\n/// [`union`]: HashSet::union\n///\n/// # Examples\n///\n/// ```\n/// use std::collections::HashSet;\n///\n/// let a: HashSet<u32> = vec![1, 2, 3].into_iter().collect();\n/// let b: HashSet<_> = [4, 2, 3, 4].iter().cloned().collect();\n///\n/// let mut union_iter = a.union(&b);\n/// ```\n#[stable(feature = \"rust1\", since = \"1.0.0\")]\npub struct Union<'a, T: 'a, S: 'a> {\n    iter: Chain<Iter<'a, T>, Difference<'a, T, S>>,\n}\n\n#[stable(feature = \"rust1\", since = \"1.0.0\")]\nimpl<'a, T, S> IntoIterator for &'a HashSet<T, S> {\n    type Item = &'a T;\n    type IntoIter = Iter<'a, T>;\n\n    #[inline]\n    fn into_iter(self) -> Iter<'a, T> {\n        self.iter()\n    }\n}\n\n#[stable(feature = \"rust1\", since = \"1.0.0\")]\nimpl<T, S> IntoIterator for HashSet<T, S> {\n    type Item = T;\n    type IntoIter = IntoIter<T>;\n\n    /// Creates a consuming iterator, that is, one that moves each value out\n    /// of the set in arbitrary order. The set cannot be used after calling\n    /// this.\n    ///\n    /// # Examples\n    ///\n    /// ```\n    /// use std::collections::HashSet;\n    /// let mut set = HashSet::new();\n    /// set.insert(\"a\".to_string());\n    /// set.insert(\"b\".to_string());\n    ///\n    /// // Not possible to collect to a Vec<String> with a regular `.iter()`.\n    /// let v: Vec<String> = set.into_iter().collect();\n    ///\n    /// // Will print in an arbitrary order.\n    /// for x in &v {\n    ///     println!(\"{}\", x);\n    /// }\n    /// ```\n    #[inline]\n    fn into_iter(self) -> IntoIter<T> {\n        IntoIter { base: self.base.into_iter() }\n    }\n}\n\n#[stable(feature = \"rust1\", since = \"1.0.0\")]\nimpl<K> Clone for Iter<'_, K> {\n    #[inline]\n    fn clone(&self) -> Self {\n        Iter { base: self.base.clone() }\n    }\n}\n#[stable(feature = \"rust1\", since = \"1.0.0\")]\nimpl<'a, K> Iterator for Iter<'a, K> {\n    type Item = &'a K;\n\n    #[inline]\n    fn next(&mut self) -> Option<&'a K> {\n        self.base.next()\n    }\n    #[inline]\n    fn size_hint(&self) -> (usize, Option<usize>) {\n        self.base.size_hint()\n    }\n}\n#[stable(feature = \"rust1\", since = \"1.0.0\")]\nimpl<K> ExactSizeIterator for Iter<'_, K> {\n    #[inline]\n    fn len(&self) -> usize {\n        self.base.len()\n    }\n}\n#[stable(feature = \"fused\", since = \"1.26.0\")]\nimpl<K> FusedIterator for Iter<'_, K> {}\n\n#[stable(feature = \"std_debug\", since = \"1.16.0\")]\nimpl<K: fmt::Debug> fmt::Debug for Iter<'_, K> {\n    fn fmt(&self, f: &mut fmt::Formatter<'_>) -> fmt::Result {\n        f.debug_list().entries(self.clone()).finish()\n    }\n}\n\n#[stable(feature = \"rust1\", since = \"1.0.0\")]\nimpl<K> Iterator for IntoIter<K> {\n    type Item = K;\n\n    #[inline]\n    fn next(&mut self) -> Option<K> {\n        self.base.next()\n    }\n    #[inline]\n    fn size_hint(&self) -> (usize, Option<usize>) {\n        self.base.size_hint()\n    }\n}\n#[stable(feature = \"rust1\", since = \"1.0.0\")]\nimpl<K> ExactSizeIterator for IntoIter<K> {\n    #[inline]\n    fn len(&self) -> usize {\n        self.base.len()\n    }\n}\n#[stable(feature = \"fused\", since = \"1.26.0\")]\nimpl<K> FusedIterator for IntoIter<K> {}\n\n#[stable(feature = \"std_debug\", since = \"1.16.0\")]\nimpl<K: fmt::Debug> fmt::Debug for IntoIter<K> {\n    fn fmt(&self, f: &mut fmt::Formatter<'_>) -> fmt::Result {\n        fmt::Debug::fmt(&self.base, f)\n    }\n}\n\n#[stable(feature = \"rust1\", since = \"1.0.0\")]\nimpl<'a, K> Iterator for Drain<'a, K> {\n    type Item = K;\n\n    #[inline]\n    fn next(&mut self) -> Option<K> {\n        self.base.next()\n    }\n    #[inline]\n    fn size_hint(&self) -> (usize, Option<usize>) {\n        self.base.size_hint()\n    }\n}\n#[stable(feature = \"rust1\", since = \"1.0.0\")]\nimpl<K> ExactSizeIterator for Drain<'_, K> {\n    #[inline]\n    fn len(&self) -> usize {\n        self.base.len()\n    }\n}\n#[stable(feature = \"fused\", since = \"1.26.0\")]\nimpl<K> FusedIterator for Drain<'_, K> {}\n\n#[stable(feature = \"std_debug\", since = \"1.16.0\")]\nimpl<K: fmt::Debug> fmt::Debug for Drain<'_, K> {\n    fn fmt(&self, f: &mut fmt::Formatter<'_>) -> fmt::Result {\n        fmt::Debug::fmt(&self.base, f)\n    }\n}\n\n#[unstable(feature = \"hash_drain_filter\", issue = \"59618\")]\nimpl<K, F> Iterator for DrainFilter<'_, K, F>\nwhere\n    F: FnMut(&K) -> bool,\n{\n    type Item = K;\n\n    #[inline]\n    fn next(&mut self) -> Option<K> {\n        self.base.next()\n    }\n    #[inline]\n    fn size_hint(&self) -> (usize, Option<usize>) {\n        self.base.size_hint()\n    }\n}\n\n#[unstable(feature = \"hash_drain_filter\", issue = \"59618\")]\nimpl<K, F> FusedIterator for DrainFilter<'_, K, F> where F: FnMut(&K) -> bool {}\n\n#[unstable(feature = \"hash_drain_filter\", issue = \"59618\")]\nimpl<'a, K, F> fmt::Debug for DrainFilter<'a, K, F>\nwhere\n    F: FnMut(&K) -> bool,\n{\n    fn fmt(&self, f: &mut fmt::Formatter<'_>) -> fmt::Result {\n        f.debug_struct(\"DrainFilter\").finish_non_exhaustive()\n    }\n}\n\n#[stable(feature = \"rust1\", since = \"1.0.0\")]\nimpl<T, S> Clone for Intersection<'_, T, S> {\n    #[inline]\n    fn clone(&self) -> Self {\n        Intersection { iter: self.iter.clone(), ..*self }\n    }\n}\n\n#[stable(feature = \"rust1\", since = \"1.0.0\")]\nimpl<'a, T, S> Iterator for Intersection<'a, T, S>\nwhere\n    T: Eq + Hash,\n    S: BuildHasher,\n{\n    type Item = &'a T;\n\n    #[inline]\n    fn next(&mut self) -> Option<&'a T> {\n        loop {\n            let elt = self.iter.next()?;\n            if self.other.contains(elt) {\n                return Some(elt);\n            }\n        }\n    }\n\n    #[inline]\n    fn size_hint(&self) -> (usize, Option<usize>) {\n        let (_, upper) = self.iter.size_hint();\n        (0, upper)\n    }\n}\n\n#[stable(feature = \"std_debug\", since = \"1.16.0\")]\nimpl<T, S> fmt::Debug for Intersection<'_, T, S>\nwhere\n    T: fmt::Debug + Eq + Hash,\n    S: BuildHasher,\n{\n    fn fmt(&self, f: &mut fmt::Formatter<'_>) -> fmt::Result {\n        f.debug_list().entries(self.clone()).finish()\n    }\n}\n\n#[stable(feature = \"fused\", since = \"1.26.0\")]\nimpl<T, S> FusedIterator for Intersection<'_, T, S>\nwhere\n    T: Eq + Hash,\n    S: BuildHasher,\n{\n}\n\n#[stable(feature = \"rust1\", since = \"1.0.0\")]\nimpl<T, S> Clone for Difference<'_, T, S> {\n    #[inline]\n    fn clone(&self) -> Self {\n        Difference { iter: self.iter.clone(), ..*self }\n    }\n}\n\n#[stable(feature = \"rust1\", since = \"1.0.0\")]\nimpl<'a, T, S> Iterator for Difference<'a, T, S>\nwhere\n    T: Eq + Hash,\n    S: BuildHasher,\n{\n    type Item = &'a T;\n\n    #[inline]\n    fn next(&mut self) -> Option<&'a T> {\n        loop {\n            let elt = self.iter.next()?;\n            if !self.other.contains(elt) {\n                return Some(elt);\n            }\n        }\n    }\n\n    #[inline]\n    fn size_hint(&self) -> (usize, Option<usize>) {\n        let (_, upper) = self.iter.size_hint();\n        (0, upper)\n    }\n}\n\n#[stable(feature = \"fused\", since = \"1.26.0\")]\nimpl<T, S> FusedIterator for Difference<'_, T, S>\nwhere\n    T: Eq + Hash,\n    S: BuildHasher,\n{\n}\n\n#[stable(feature = \"std_debug\", since = \"1.16.0\")]\nimpl<T, S> fmt::Debug for Difference<'_, T, S>\nwhere\n    T: fmt::Debug + Eq + Hash,\n    S: BuildHasher,\n{\n    fn fmt(&self, f: &mut fmt::Formatter<'_>) -> fmt::Result {\n        f.debug_list().entries(self.clone()).finish()\n    }\n}\n\n#[stable(feature = \"rust1\", since = \"1.0.0\")]\nimpl<T, S> Clone for SymmetricDifference<'_, T, S> {\n    #[inline]\n    fn clone(&self) -> Self {\n        SymmetricDifference { iter: self.iter.clone() }\n    }\n}\n\n#[stable(feature = \"rust1\", since = \"1.0.0\")]\nimpl<'a, T, S> Iterator for SymmetricDifference<'a, T, S>\nwhere\n    T: Eq + Hash,\n    S: BuildHasher,\n{\n    type Item = &'a T;\n\n    #[inline]\n    fn next(&mut self) -> Option<&'a T> {\n        self.iter.next()\n    }\n    #[inline]\n    fn size_hint(&self) -> (usize, Option<usize>) {\n        self.iter.size_hint()\n    }\n}\n\n#[stable(feature = \"fused\", since = \"1.26.0\")]\nimpl<T, S> FusedIterator for SymmetricDifference<'_, T, S>\nwhere\n    T: Eq + Hash,\n    S: BuildHasher,\n{\n}\n\n#[stable(feature = \"std_debug\", since = \"1.16.0\")]\nimpl<T, S> fmt::Debug for SymmetricDifference<'_, T, S>\nwhere\n    T: fmt::Debug + Eq + Hash,\n    S: BuildHasher,\n{\n    fn fmt(&self, f: &mut fmt::Formatter<'_>) -> fmt::Result {\n        f.debug_list().entries(self.clone()).finish()\n    }\n}\n\n#[stable(feature = \"rust1\", since = \"1.0.0\")]\nimpl<T, S> Clone for Union<'_, T, S> {\n    #[inline]\n    fn clone(&self) -> Self {\n        Union { iter: self.iter.clone() }\n    }\n}\n\n#[stable(feature = \"fused\", since = \"1.26.0\")]\nimpl<T, S> FusedIterator for Union<'_, T, S>\nwhere\n    T: Eq + Hash,\n    S: BuildHasher,\n{\n}\n\n#[stable(feature = \"std_debug\", since = \"1.16.0\")]\nimpl<T, S> fmt::Debug for Union<'_, T, S>\nwhere\n    T: fmt::Debug + Eq + Hash,\n    S: BuildHasher,\n{\n    fn fmt(&self, f: &mut fmt::Formatter<'_>) -> fmt::Result {\n        f.debug_list().entries(self.clone()).finish()\n    }\n}\n\n#[stable(feature = \"rust1\", since = \"1.0.0\")]\nimpl<'a, T, S> Iterator for Union<'a, T, S>\nwhere\n    T: Eq + Hash,\n    S: BuildHasher,\n{\n    type Item = &'a T;\n\n    #[inline]\n    fn next(&mut self) -> Option<&'a T> {\n        self.iter.next()\n    }\n    #[inline]\n    fn size_hint(&self) -> (usize, Option<usize>) {\n        self.iter.size_hint()\n    }\n}\n\n#[allow(dead_code)]\nfn assert_covariance() {\n    fn set<'new>(v: HashSet<&'static str>) -> HashSet<&'new str> {\n        v\n    }\n    fn iter<'a, 'new>(v: Iter<'a, &'static str>) -> Iter<'a, &'new str> {\n        v\n    }\n    fn into_iter<'new>(v: IntoIter<&'static str>) -> IntoIter<&'new str> {\n        v\n    }\n    fn difference<'a, 'new>(\n        v: Difference<'a, &'static str, RandomState>,\n    ) -> Difference<'a, &'new str, RandomState> {\n        v\n    }\n    fn symmetric_difference<'a, 'new>(\n        v: SymmetricDifference<'a, &'static str, RandomState>,\n    ) -> SymmetricDifference<'a, &'new str, RandomState> {\n        v\n    }\n    fn intersection<'a, 'new>(\n        v: Intersection<'a, &'static str, RandomState>,\n    ) -> Intersection<'a, &'new str, RandomState> {\n        v\n    }\n    fn union<'a, 'new>(\n        v: Union<'a, &'static str, RandomState>,\n    ) -> Union<'a, &'new str, RandomState> {\n        v\n    }\n    fn drain<'new>(d: Drain<'static, &'static str>) -> Drain<'new, &'new str> {\n        d\n    }\n}\n"],[2228,"use super::super::map::RandomState;\nuse super::HashSet;\n\nuse crate::panic::{catch_unwind, AssertUnwindSafe};\nuse crate::sync::atomic::{AtomicU32, Ordering};\n\n#[test]\nfn test_zero_capacities() {\n    type HS = HashSet<i32>;\n\n    let s = HS::new();\n    assert_eq!(s.capacity(), 0);\n\n    let s = HS::default();\n    assert_eq!(s.capacity(), 0);\n\n    let s = HS::with_hasher(RandomState::new());\n    assert_eq!(s.capacity(), 0);\n\n    let s = HS::with_capacity(0);\n    assert_eq!(s.capacity(), 0);\n\n    let s = HS::with_capacity_and_hasher(0, RandomState::new());\n    assert_eq!(s.capacity(), 0);\n\n    let mut s = HS::new();\n    s.insert(1);\n    s.insert(2);\n    s.remove(&1);\n    s.remove(&2);\n    s.shrink_to_fit();\n    assert_eq!(s.capacity(), 0);\n\n    let mut s = HS::new();\n    s.reserve(0);\n    assert_eq!(s.capacity(), 0);\n}\n\n#[test]\nfn test_disjoint() {\n    let mut xs = HashSet::new();\n    let mut ys = HashSet::new();\n    assert!(xs.is_disjoint(&ys));\n    assert!(ys.is_disjoint(&xs));\n    assert!(xs.insert(5));\n    assert!(ys.insert(11));\n    assert!(xs.is_disjoint(&ys));\n    assert!(ys.is_disjoint(&xs));\n    assert!(xs.insert(7));\n    assert!(xs.insert(19));\n    assert!(xs.insert(4));\n    assert!(ys.insert(2));\n    assert!(ys.insert(-11));\n    assert!(xs.is_disjoint(&ys));\n    assert!(ys.is_disjoint(&xs));\n    assert!(ys.insert(7));\n    assert!(!xs.is_disjoint(&ys));\n    assert!(!ys.is_disjoint(&xs));\n}\n\n#[test]\nfn test_subset_and_superset() {\n    let mut a = HashSet::new();\n    assert!(a.insert(0));\n    assert!(a.insert(5));\n    assert!(a.insert(11));\n    assert!(a.insert(7));\n\n    let mut b = HashSet::new();\n    assert!(b.insert(0));\n    assert!(b.insert(7));\n    assert!(b.insert(19));\n    assert!(b.insert(250));\n    assert!(b.insert(11));\n    assert!(b.insert(200));\n\n    assert!(!a.is_subset(&b));\n    assert!(!a.is_superset(&b));\n    assert!(!b.is_subset(&a));\n    assert!(!b.is_superset(&a));\n\n    assert!(b.insert(5));\n\n    assert!(a.is_subset(&b));\n    assert!(!a.is_superset(&b));\n    assert!(!b.is_subset(&a));\n    assert!(b.is_superset(&a));\n}\n\n#[test]\nfn test_iterate() {\n    let mut a = HashSet::new();\n    for i in 0..32 {\n        assert!(a.insert(i));\n    }\n    let mut observed: u32 = 0;\n    for k in &a {\n        observed |= 1 << *k;\n    }\n    assert_eq!(observed, 0xFFFF_FFFF);\n}\n\n#[test]\nfn test_intersection() {\n    let mut a = HashSet::new();\n    let mut b = HashSet::new();\n    assert!(a.intersection(&b).next().is_none());\n\n    assert!(a.insert(11));\n    assert!(a.insert(1));\n    assert!(a.insert(3));\n    assert!(a.insert(77));\n    assert!(a.insert(103));\n    assert!(a.insert(5));\n    assert!(a.insert(-5));\n\n    assert!(b.insert(2));\n    assert!(b.insert(11));\n    assert!(b.insert(77));\n    assert!(b.insert(-9));\n    assert!(b.insert(-42));\n    assert!(b.insert(5));\n    assert!(b.insert(3));\n\n    let mut i = 0;\n    let expected = [3, 5, 11, 77];\n    for x in a.intersection(&b) {\n        assert!(expected.contains(x));\n        i += 1\n    }\n    assert_eq!(i, expected.len());\n\n    assert!(a.insert(9)); // make a bigger than b\n\n    i = 0;\n    for x in a.intersection(&b) {\n        assert!(expected.contains(x));\n        i += 1\n    }\n    assert_eq!(i, expected.len());\n\n    i = 0;\n    for x in b.intersection(&a) {\n        assert!(expected.contains(x));\n        i += 1\n    }\n    assert_eq!(i, expected.len());\n}\n\n#[test]\nfn test_difference() {\n    let mut a = HashSet::new();\n    let mut b = HashSet::new();\n\n    assert!(a.insert(1));\n    assert!(a.insert(3));\n    assert!(a.insert(5));\n    assert!(a.insert(9));\n    assert!(a.insert(11));\n\n    assert!(b.insert(3));\n    assert!(b.insert(9));\n\n    let mut i = 0;\n    let expected = [1, 5, 11];\n    for x in a.difference(&b) {\n        assert!(expected.contains(x));\n        i += 1\n    }\n    assert_eq!(i, expected.len());\n}\n\n#[test]\nfn test_symmetric_difference() {\n    let mut a = HashSet::new();\n    let mut b = HashSet::new();\n\n    assert!(a.insert(1));\n    assert!(a.insert(3));\n    assert!(a.insert(5));\n    assert!(a.insert(9));\n    assert!(a.insert(11));\n\n    assert!(b.insert(-2));\n    assert!(b.insert(3));\n    assert!(b.insert(9));\n    assert!(b.insert(14));\n    assert!(b.insert(22));\n\n    let mut i = 0;\n    let expected = [-2, 1, 5, 11, 14, 22];\n    for x in a.symmetric_difference(&b) {\n        assert!(expected.contains(x));\n        i += 1\n    }\n    assert_eq!(i, expected.len());\n}\n\n#[test]\nfn test_union() {\n    let mut a = HashSet::new();\n    let mut b = HashSet::new();\n    assert!(a.union(&b).next().is_none());\n    assert!(b.union(&a).next().is_none());\n\n    assert!(a.insert(1));\n    assert!(a.insert(3));\n    assert!(a.insert(11));\n    assert!(a.insert(16));\n    assert!(a.insert(19));\n    assert!(a.insert(24));\n\n    assert!(b.insert(-2));\n    assert!(b.insert(1));\n    assert!(b.insert(5));\n    assert!(b.insert(9));\n    assert!(b.insert(13));\n    assert!(b.insert(19));\n\n    let mut i = 0;\n    let expected = [-2, 1, 3, 5, 9, 11, 13, 16, 19, 24];\n    for x in a.union(&b) {\n        assert!(expected.contains(x));\n        i += 1\n    }\n    assert_eq!(i, expected.len());\n\n    assert!(a.insert(9)); // make a bigger than b\n    assert!(a.insert(5));\n\n    i = 0;\n    for x in a.union(&b) {\n        assert!(expected.contains(x));\n        i += 1\n    }\n    assert_eq!(i, expected.len());\n\n    i = 0;\n    for x in b.union(&a) {\n        assert!(expected.contains(x));\n        i += 1\n    }\n    assert_eq!(i, expected.len());\n}\n\n#[test]\nfn test_from_iter() {\n    let xs = [1, 2, 2, 3, 4, 5, 6, 7, 8, 9];\n\n    let set: HashSet<_> = xs.iter().cloned().collect();\n\n    for x in &xs {\n        assert!(set.contains(x));\n    }\n\n    assert_eq!(set.iter().len(), xs.len() - 1);\n}\n\n#[test]\nfn test_move_iter() {\n    let hs = {\n        let mut hs = HashSet::new();\n\n        hs.insert('a');\n        hs.insert('b');\n\n        hs\n    };\n\n    let v = hs.into_iter().collect::<Vec<char>>();\n    assert!(v == ['a', 'b'] || v == ['b', 'a']);\n}\n\n#[test]\nfn test_eq() {\n    // These constants once happened to expose a bug in insert().\n    // I'm keeping them around to prevent a regression.\n    let mut s1 = HashSet::new();\n\n    s1.insert(1);\n    s1.insert(2);\n    s1.insert(3);\n\n    let mut s2 = HashSet::new();\n\n    s2.insert(1);\n    s2.insert(2);\n\n    assert!(s1 != s2);\n\n    s2.insert(3);\n\n    assert_eq!(s1, s2);\n}\n\n#[test]\nfn test_show() {\n    let mut set = HashSet::new();\n    let empty = HashSet::<i32>::new();\n\n    set.insert(1);\n    set.insert(2);\n\n    let set_str = format!(\"{:?}\", set);\n\n    assert!(set_str == \"{1, 2}\" || set_str == \"{2, 1}\");\n    assert_eq!(format!(\"{:?}\", empty), \"{}\");\n}\n\n#[test]\nfn test_trivial_drain() {\n    let mut s = HashSet::<i32>::new();\n    for _ in s.drain() {}\n    assert!(s.is_empty());\n    drop(s);\n\n    let mut s = HashSet::<i32>::new();\n    drop(s.drain());\n    assert!(s.is_empty());\n}\n\n#[test]\nfn test_drain() {\n    let mut s: HashSet<_> = (1..100).collect();\n\n    // try this a bunch of times to make sure we don't screw up internal state.\n    for _ in 0..20 {\n        assert_eq!(s.len(), 99);\n\n        {\n            let mut last_i = 0;\n            let mut d = s.drain();\n            for (i, x) in d.by_ref().take(50).enumerate() {\n                last_i = i;\n                assert!(x != 0);\n            }\n            assert_eq!(last_i, 49);\n        }\n\n        for _ in &s {\n            panic!(\"s should be empty!\");\n        }\n\n        // reset to try again.\n        s.extend(1..100);\n    }\n}\n\n#[test]\nfn test_replace() {\n    use crate::hash;\n\n    #[derive(Debug)]\n    struct Foo(&'static str, i32);\n\n    impl PartialEq for Foo {\n        fn eq(&self, other: &Self) -> bool {\n            self.0 == other.0\n        }\n    }\n\n    impl Eq for Foo {}\n\n    impl hash::Hash for Foo {\n        fn hash<H: hash::Hasher>(&self, h: &mut H) {\n            self.0.hash(h);\n        }\n    }\n\n    let mut s = HashSet::new();\n    assert_eq!(s.replace(Foo(\"a\", 1)), None);\n    assert_eq!(s.len(), 1);\n    assert_eq!(s.replace(Foo(\"a\", 2)), Some(Foo(\"a\", 1)));\n    assert_eq!(s.len(), 1);\n\n    let mut it = s.iter();\n    assert_eq!(it.next(), Some(&Foo(\"a\", 2)));\n    assert_eq!(it.next(), None);\n}\n\n#[test]\nfn test_extend_ref() {\n    let mut a = HashSet::new();\n    a.insert(1);\n\n    a.extend(&[2, 3, 4]);\n\n    assert_eq!(a.len(), 4);\n    assert!(a.contains(&1));\n    assert!(a.contains(&2));\n    assert!(a.contains(&3));\n    assert!(a.contains(&4));\n\n    let mut b = HashSet::new();\n    b.insert(5);\n    b.insert(6);\n\n    a.extend(&b);\n\n    assert_eq!(a.len(), 6);\n    assert!(a.contains(&1));\n    assert!(a.contains(&2));\n    assert!(a.contains(&3));\n    assert!(a.contains(&4));\n    assert!(a.contains(&5));\n    assert!(a.contains(&6));\n}\n\n#[test]\nfn test_retain() {\n    let xs = [1, 2, 3, 4, 5, 6];\n    let mut set: HashSet<i32> = xs.iter().cloned().collect();\n    set.retain(|&k| k % 2 == 0);\n    assert_eq!(set.len(), 3);\n    assert!(set.contains(&2));\n    assert!(set.contains(&4));\n    assert!(set.contains(&6));\n}\n\n#[test]\nfn test_drain_filter() {\n    let mut x: HashSet<_> = [1].iter().copied().collect();\n    let mut y: HashSet<_> = [1].iter().copied().collect();\n\n    x.drain_filter(|_| true);\n    y.drain_filter(|_| false);\n    assert_eq!(x.len(), 0);\n    assert_eq!(y.len(), 1);\n}\n\n#[test]\nfn test_drain_filter_drop_panic_leak() {\n    static PREDS: AtomicU32 = AtomicU32::new(0);\n    static DROPS: AtomicU32 = AtomicU32::new(0);\n\n    #[derive(PartialEq, Eq, PartialOrd, Hash)]\n    struct D(i32);\n    impl Drop for D {\n        fn drop(&mut self) {\n            if DROPS.fetch_add(1, Ordering::SeqCst) == 1 {\n                panic!(\"panic in `drop`\");\n            }\n        }\n    }\n\n    let mut set = (0..3).map(|i| D(i)).collect::<HashSet<_>>();\n\n    catch_unwind(move || {\n        drop(set.drain_filter(|_| {\n            PREDS.fetch_add(1, Ordering::SeqCst);\n            true\n        }))\n    })\n    .ok();\n\n    assert_eq!(PREDS.load(Ordering::SeqCst), 3);\n    assert_eq!(DROPS.load(Ordering::SeqCst), 3);\n}\n\n#[test]\nfn test_drain_filter_pred_panic_leak() {\n    static PREDS: AtomicU32 = AtomicU32::new(0);\n    static DROPS: AtomicU32 = AtomicU32::new(0);\n\n    #[derive(PartialEq, Eq, PartialOrd, Hash)]\n    struct D;\n    impl Drop for D {\n        fn drop(&mut self) {\n            DROPS.fetch_add(1, Ordering::SeqCst);\n        }\n    }\n\n    let mut set: HashSet<_> = (0..3).map(|_| D).collect();\n\n    catch_unwind(AssertUnwindSafe(|| {\n        drop(set.drain_filter(|_| match PREDS.fetch_add(1, Ordering::SeqCst) {\n            0 => true,\n            _ => panic!(),\n        }))\n    }))\n    .ok();\n\n    assert_eq!(PREDS.load(Ordering::SeqCst), 1);\n    assert_eq!(DROPS.load(Ordering::SeqCst), 3);\n    assert_eq!(set.len(), 0);\n}\n"],[2229,"//! Collection types.\n//!\n//! Rust's standard collection library provides efficient implementations of the\n//! most common general purpose programming data structures. By using the\n//! standard implementations, it should be possible for two libraries to\n//! communicate without significant data conversion.\n//!\n//! To get this out of the way: you should probably just use [`Vec`] or [`HashMap`].\n//! These two collections cover most use cases for generic data storage and\n//! processing. They are exceptionally good at doing what they do. All the other\n//! collections in the standard library have specific use cases where they are\n//! the optimal choice, but these cases are borderline *niche* in comparison.\n//! Even when `Vec` and `HashMap` are technically suboptimal, they're probably a\n//! good enough choice to get started.\n//!\n//! Rust's collections can be grouped into four major categories:\n//!\n//! * Sequences: [`Vec`], [`VecDeque`], [`LinkedList`]\n//! * Maps: [`HashMap`], [`BTreeMap`]\n//! * Sets: [`HashSet`], [`BTreeSet`]\n//! * Misc: [`BinaryHeap`]\n//!\n//! # When Should You Use Which Collection?\n//!\n//! These are fairly high-level and quick break-downs of when each collection\n//! should be considered. Detailed discussions of strengths and weaknesses of\n//! individual collections can be found on their own documentation pages.\n//!\n//! ### Use a `Vec` when:\n//! * You want to collect items up to be processed or sent elsewhere later, and\n//!   don't care about any properties of the actual values being stored.\n//! * You want a sequence of elements in a particular order, and will only be\n//!   appending to (or near) the end.\n//! * You want a stack.\n//! * You want a resizable array.\n//! * You want a heap-allocated array.\n//!\n//! ### Use a `VecDeque` when:\n//! * You want a [`Vec`] that supports efficient insertion at both ends of the\n//!   sequence.\n//! * You want a queue.\n//! * You want a double-ended queue (deque).\n//!\n//! ### Use a `LinkedList` when:\n//! * You want a [`Vec`] or [`VecDeque`] of unknown size, and can't tolerate\n//!   amortization.\n//! * You want to efficiently split and append lists.\n//! * You are *absolutely* certain you *really*, *truly*, want a doubly linked\n//!   list.\n//!\n//! ### Use a `HashMap` when:\n//! * You want to associate arbitrary keys with an arbitrary value.\n//! * You want a cache.\n//! * You want a map, with no extra functionality.\n//!\n//! ### Use a `BTreeMap` when:\n//! * You want a map sorted by its keys.\n//! * You want to be able to get a range of entries on-demand.\n//! * You're interested in what the smallest or largest key-value pair is.\n//! * You want to find the largest or smallest key that is smaller or larger\n//!   than something.\n//!\n//! ### Use the `Set` variant of any of these `Map`s when:\n//! * You just want to remember which keys you've seen.\n//! * There is no meaningful value to associate with your keys.\n//! * You just want a set.\n//!\n//! ### Use a `BinaryHeap` when:\n//!\n//! * You want to store a bunch of elements, but only ever want to process the\n//!   \"biggest\" or \"most important\" one at any given time.\n//! * You want a priority queue.\n//!\n//! # Performance\n//!\n//! Choosing the right collection for the job requires an understanding of what\n//! each collection is good at. Here we briefly summarize the performance of\n//! different collections for certain important operations. For further details,\n//! see each type's documentation, and note that the names of actual methods may\n//! differ from the tables below on certain collections.\n//!\n//! Throughout the documentation, we will follow a few conventions. For all\n//! operations, the collection's size is denoted by n. If another collection is\n//! involved in the operation, it contains m elements. Operations which have an\n//! *amortized* cost are suffixed with a `*`. Operations with an *expected*\n//! cost are suffixed with a `~`.\n//!\n//! All amortized costs are for the potential need to resize when capacity is\n//! exhausted. If a resize occurs it will take *O*(*n*) time. Our collections never\n//! automatically shrink, so removal operations aren't amortized. Over a\n//! sufficiently large series of operations, the average cost per operation will\n//! deterministically equal the given cost.\n//!\n//! Only [`HashMap`] has expected costs, due to the probabilistic nature of hashing.\n//! It is theoretically possible, though very unlikely, for [`HashMap`] to\n//! experience worse performance.\n//!\n//! ## Sequences\n//!\n//! |                | get(i)         | insert(i)       | remove(i)      | append | split_off(i)   |\n//! |----------------|----------------|-----------------|----------------|--------|----------------|\n//! | [`Vec`]        | O(1)           | O(n-i)*         | O(n-i)         | O(m)*  | O(n-i)         |\n//! | [`VecDeque`]   | O(1)           | O(min(i, n-i))* | O(min(i, n-i)) | O(m)*  | O(min(i, n-i)) |\n//! | [`LinkedList`] | O(min(i, n-i)) | O(min(i, n-i))  | O(min(i, n-i)) | O(1)   | O(min(i, n-i)) |\n//!\n//! Note that where ties occur, [`Vec`] is generally going to be faster than [`VecDeque`], and\n//! [`VecDeque`] is generally going to be faster than [`LinkedList`].\n//!\n//! ## Maps\n//!\n//! For Sets, all operations have the cost of the equivalent Map operation.\n//!\n//! |              | get       | insert    | remove    | range     | append |\n//! |--------------|-----------|-----------|-----------|-----------|--------|\n//! | [`HashMap`]  | O(1)~     | O(1)~*    | O(1)~     | N/A       | N/A    |\n//! | [`BTreeMap`] | O(log(n)) | O(log(n)) | O(log(n)) | O(log(n)) | O(n+m) |\n//!\n//! # Correct and Efficient Usage of Collections\n//!\n//! Of course, knowing which collection is the right one for the job doesn't\n//! instantly permit you to use it correctly. Here are some quick tips for\n//! efficient and correct usage of the standard collections in general. If\n//! you're interested in how to use a specific collection in particular, consult\n//! its documentation for detailed discussion and code examples.\n//!\n//! ## Capacity Management\n//!\n//! Many collections provide several constructors and methods that refer to\n//! \"capacity\". These collections are generally built on top of an array.\n//! Optimally, this array would be exactly the right size to fit only the\n//! elements stored in the collection, but for the collection to do this would\n//! be very inefficient. If the backing array was exactly the right size at all\n//! times, then every time an element is inserted, the collection would have to\n//! grow the array to fit it. Due to the way memory is allocated and managed on\n//! most computers, this would almost surely require allocating an entirely new\n//! array and copying every single element from the old one into the new one.\n//! Hopefully you can see that this wouldn't be very efficient to do on every\n//! operation.\n//!\n//! Most collections therefore use an *amortized* allocation strategy. They\n//! generally let themselves have a fair amount of unoccupied space so that they\n//! only have to grow on occasion. When they do grow, they allocate a\n//! substantially larger array to move the elements into so that it will take a\n//! while for another grow to be required. While this strategy is great in\n//! general, it would be even better if the collection *never* had to resize its\n//! backing array. Unfortunately, the collection itself doesn't have enough\n//! information to do this itself. Therefore, it is up to us programmers to give\n//! it hints.\n//!\n//! Any `with_capacity` constructor will instruct the collection to allocate\n//! enough space for the specified number of elements. Ideally this will be for\n//! exactly that many elements, but some implementation details may prevent\n//! this. See collection-specific documentation for details. In general, use\n//! `with_capacity` when you know exactly how many elements will be inserted, or\n//! at least have a reasonable upper-bound on that number.\n//!\n//! When anticipating a large influx of elements, the `reserve` family of\n//! methods can be used to hint to the collection how much room it should make\n//! for the coming items. As with `with_capacity`, the precise behavior of\n//! these methods will be specific to the collection of interest.\n//!\n//! For optimal performance, collections will generally avoid shrinking\n//! themselves. If you believe that a collection will not soon contain any more\n//! elements, or just really need the memory, the `shrink_to_fit` method prompts\n//! the collection to shrink the backing array to the minimum size capable of\n//! holding its elements.\n//!\n//! Finally, if ever you're interested in what the actual capacity of the\n//! collection is, most collections provide a `capacity` method to query this\n//! information on demand. This can be useful for debugging purposes, or for\n//! use with the `reserve` methods.\n//!\n//! ## Iterators\n//!\n//! Iterators are a powerful and robust mechanism used throughout Rust's\n//! standard libraries. Iterators provide a sequence of values in a generic,\n//! safe, efficient and convenient way. The contents of an iterator are usually\n//! *lazily* evaluated, so that only the values that are actually needed are\n//! ever actually produced, and no allocation need be done to temporarily store\n//! them. Iterators are primarily consumed using a `for` loop, although many\n//! functions also take iterators where a collection or sequence of values is\n//! desired.\n//!\n//! All of the standard collections provide several iterators for performing\n//! bulk manipulation of their contents. The three primary iterators almost\n//! every collection should provide are `iter`, `iter_mut`, and `into_iter`.\n//! Some of these are not provided on collections where it would be unsound or\n//! unreasonable to provide them.\n//!\n//! `iter` provides an iterator of immutable references to all the contents of a\n//! collection in the most \"natural\" order. For sequence collections like [`Vec`],\n//! this means the items will be yielded in increasing order of index starting\n//! at 0. For ordered collections like [`BTreeMap`], this means that the items\n//! will be yielded in sorted order. For unordered collections like [`HashMap`],\n//! the items will be yielded in whatever order the internal representation made\n//! most convenient. This is great for reading through all the contents of the\n//! collection.\n//!\n//! ```\n//! let vec = vec![1, 2, 3, 4];\n//! for x in vec.iter() {\n//!    println!(\"vec contained {}\", x);\n//! }\n//! ```\n//!\n//! `iter_mut` provides an iterator of *mutable* references in the same order as\n//! `iter`. This is great for mutating all the contents of the collection.\n//!\n//! ```\n//! let mut vec = vec![1, 2, 3, 4];\n//! for x in vec.iter_mut() {\n//!    *x += 1;\n//! }\n//! ```\n//!\n//! `into_iter` transforms the actual collection into an iterator over its\n//! contents by-value. This is great when the collection itself is no longer\n//! needed, and the values are needed elsewhere. Using `extend` with `into_iter`\n//! is the main way that contents of one collection are moved into another.\n//! `extend` automatically calls `into_iter`, and takes any `T: `[`IntoIterator`].\n//! Calling `collect` on an iterator itself is also a great way to convert one\n//! collection into another. Both of these methods should internally use the\n//! capacity management tools discussed in the previous section to do this as\n//! efficiently as possible.\n//!\n//! ```\n//! let mut vec1 = vec![1, 2, 3, 4];\n//! let vec2 = vec![10, 20, 30, 40];\n//! vec1.extend(vec2);\n//! ```\n//!\n//! ```\n//! use std::collections::VecDeque;\n//!\n//! let vec = vec![1, 2, 3, 4];\n//! let buf: VecDeque<_> = vec.into_iter().collect();\n//! ```\n//!\n//! Iterators also provide a series of *adapter* methods for performing common\n//! threads to sequences. Among the adapters are functional favorites like `map`,\n//! `fold`, `skip` and `take`. Of particular interest to collections is the\n//! `rev` adapter, that reverses any iterator that supports this operation. Most\n//! collections provide reversible iterators as the way to iterate over them in\n//! reverse order.\n//!\n//! ```\n//! let vec = vec![1, 2, 3, 4];\n//! for x in vec.iter().rev() {\n//!    println!(\"vec contained {}\", x);\n//! }\n//! ```\n//!\n//! Several other collection methods also return iterators to yield a sequence\n//! of results but avoid allocating an entire collection to store the result in.\n//! This provides maximum flexibility as `collect` or `extend` can be called to\n//! \"pipe\" the sequence into any collection if desired. Otherwise, the sequence\n//! can be looped over with a `for` loop. The iterator can also be discarded\n//! after partial use, preventing the computation of the unused items.\n//!\n//! ## Entries\n//!\n//! The `entry` API is intended to provide an efficient mechanism for\n//! manipulating the contents of a map conditionally on the presence of a key or\n//! not. The primary motivating use case for this is to provide efficient\n//! accumulator maps. For instance, if one wishes to maintain a count of the\n//! number of times each key has been seen, they will have to perform some\n//! conditional logic on whether this is the first time the key has been seen or\n//! not. Normally, this would require a `find` followed by an `insert`,\n//! effectively duplicating the search effort on each insertion.\n//!\n//! When a user calls `map.entry(&key)`, the map will search for the key and\n//! then yield a variant of the `Entry` enum.\n//!\n//! If a `Vacant(entry)` is yielded, then the key *was not* found. In this case\n//! the only valid operation is to `insert` a value into the entry. When this is\n//! done, the vacant entry is consumed and converted into a mutable reference to\n//! the value that was inserted. This allows for further manipulation of the\n//! value beyond the lifetime of the search itself. This is useful if complex\n//! logic needs to be performed on the value regardless of whether the value was\n//! just inserted.\n//!\n//! If an `Occupied(entry)` is yielded, then the key *was* found. In this case,\n//! the user has several options: they can `get`, `insert` or `remove` the\n//! value of the occupied entry. Additionally, they can convert the occupied\n//! entry into a mutable reference to its value, providing symmetry to the\n//! vacant `insert` case.\n//!\n//! ### Examples\n//!\n//! Here are the two primary ways in which `entry` is used. First, a simple\n//! example where the logic performed on the values is trivial.\n//!\n//! #### Counting the number of times each character in a string occurs\n//!\n//! ```\n//! use std::collections::btree_map::BTreeMap;\n//!\n//! let mut count = BTreeMap::new();\n//! let message = \"she sells sea shells by the sea shore\";\n//!\n//! for c in message.chars() {\n//!     *count.entry(c).or_insert(0) += 1;\n//! }\n//!\n//! assert_eq!(count.get(&'s'), Some(&8));\n//!\n//! println!(\"Number of occurrences of each character\");\n//! for (char, count) in &count {\n//!     println!(\"{}: {}\", char, count);\n//! }\n//! ```\n//!\n//! When the logic to be performed on the value is more complex, we may simply\n//! use the `entry` API to ensure that the value is initialized and perform the\n//! logic afterwards.\n//!\n//! #### Tracking the inebriation of customers at a bar\n//!\n//! ```\n//! use std::collections::btree_map::BTreeMap;\n//!\n//! // A client of the bar. They have a blood alcohol level.\n//! struct Person { blood_alcohol: f32 }\n//!\n//! // All the orders made to the bar, by client ID.\n//! let orders = vec![1, 2, 1, 2, 3, 4, 1, 2, 2, 3, 4, 1, 1, 1];\n//!\n//! // Our clients.\n//! let mut blood_alcohol = BTreeMap::new();\n//!\n//! for id in orders {\n//!     // If this is the first time we've seen this customer, initialize them\n//!     // with no blood alcohol. Otherwise, just retrieve them.\n//!     let person = blood_alcohol.entry(id).or_insert(Person { blood_alcohol: 0.0 });\n//!\n//!     // Reduce their blood alcohol level. It takes time to order and drink a beer!\n//!     person.blood_alcohol *= 0.9;\n//!\n//!     // Check if they're sober enough to have another beer.\n//!     if person.blood_alcohol > 0.3 {\n//!         // Too drunk... for now.\n//!         println!(\"Sorry {}, I have to cut you off\", id);\n//!     } else {\n//!         // Have another!\n//!         person.blood_alcohol += 0.1;\n//!     }\n//! }\n//! ```\n//!\n//! # Insert and complex keys\n//!\n//! If we have a more complex key, calls to `insert` will\n//! not update the value of the key. For example:\n//!\n//! ```\n//! use std::cmp::Ordering;\n//! use std::collections::BTreeMap;\n//! use std::hash::{Hash, Hasher};\n//!\n//! #[derive(Debug)]\n//! struct Foo {\n//!     a: u32,\n//!     b: &'static str,\n//! }\n//!\n//! // we will compare `Foo`s by their `a` value only.\n//! impl PartialEq for Foo {\n//!     fn eq(&self, other: &Self) -> bool { self.a == other.a }\n//! }\n//!\n//! impl Eq for Foo {}\n//!\n//! // we will hash `Foo`s by their `a` value only.\n//! impl Hash for Foo {\n//!     fn hash<H: Hasher>(&self, h: &mut H) { self.a.hash(h); }\n//! }\n//!\n//! impl PartialOrd for Foo {\n//!     fn partial_cmp(&self, other: &Self) -> Option<Ordering> { self.a.partial_cmp(&other.a) }\n//! }\n//!\n//! impl Ord for Foo {\n//!     fn cmp(&self, other: &Self) -> Ordering { self.a.cmp(&other.a) }\n//! }\n//!\n//! let mut map = BTreeMap::new();\n//! map.insert(Foo { a: 1, b: \"baz\" }, 99);\n//!\n//! // We already have a Foo with an a of 1, so this will be updating the value.\n//! map.insert(Foo { a: 1, b: \"xyz\" }, 100);\n//!\n//! // The value has been updated...\n//! assert_eq!(map.values().next().unwrap(), &100);\n//!\n//! // ...but the key hasn't changed. b is still \"baz\", not \"xyz\".\n//! assert_eq!(map.keys().next().unwrap().b, \"baz\");\n//! ```\n//!\n//! [`IntoIterator`]: crate::iter::IntoIterator\n\n#![stable(feature = \"rust1\", since = \"1.0.0\")]\n\n#[stable(feature = \"rust1\", since = \"1.0.0\")]\n// FIXME(#82080) The deprecation here is only theoretical, and does not actually produce a warning.\n#[rustc_deprecated(reason = \"moved to `std::ops::Bound`\", since = \"1.26.0\")]\n#[doc(hidden)]\npub use crate::ops::Bound;\n\n#[stable(feature = \"rust1\", since = \"1.0.0\")]\npub use alloc_crate::collections::{binary_heap, btree_map, btree_set};\n#[stable(feature = \"rust1\", since = \"1.0.0\")]\npub use alloc_crate::collections::{linked_list, vec_deque};\n#[stable(feature = \"rust1\", since = \"1.0.0\")]\npub use alloc_crate::collections::{BTreeMap, BTreeSet, BinaryHeap};\n#[stable(feature = \"rust1\", since = \"1.0.0\")]\npub use alloc_crate::collections::{LinkedList, VecDeque};\n\n#[stable(feature = \"rust1\", since = \"1.0.0\")]\npub use self::hash_map::HashMap;\n#[stable(feature = \"rust1\", since = \"1.0.0\")]\npub use self::hash_set::HashSet;\n\n#[unstable(feature = \"try_reserve\", reason = \"new API\", issue = \"48043\")]\npub use alloc_crate::collections::TryReserveError;\n\nmod hash;\n\n#[stable(feature = \"rust1\", since = \"1.0.0\")]\npub mod hash_map {\n    //! A hash map implemented with quadratic probing and SIMD lookup.\n    #[stable(feature = \"rust1\", since = \"1.0.0\")]\n    pub use super::hash::map::*;\n}\n\n#[stable(feature = \"rust1\", since = \"1.0.0\")]\npub mod hash_set {\n    //! A hash set implemented as a `HashMap` where the value is `()`.\n    #[stable(feature = \"rust1\", since = \"1.0.0\")]\n    pub use super::hash::set::*;\n}\n"],[2230,"//! Platform-dependent platform abstraction.\n//!\n//! The `std::sys` module is the abstracted interface through which\n//! `std` talks to the underlying operating system. It has different\n//! implementations for different operating system families, today\n//! just Unix and Windows, and initial support for Redox.\n//!\n//! The centralization of platform-specific code in this module is\n//! enforced by the \"platform abstraction layer\" tidy script in\n//! `tools/tidy/src/pal.rs`.\n//!\n//! This module is closely related to the platform-independent system\n//! integration code in `std::sys_common`. See that module's\n//! documentation for details.\n//!\n//! In the future it would be desirable for the independent\n//! implementations of this module to be extracted to their own crates\n//! that `std` can link to, thus enabling their implementation\n//! out-of-tree via crate replacement. Though due to the complex\n//! inter-dependencies within `std` that will be a challenging goal to\n//! achieve.\n\n#![allow(missing_debug_implementations)]\n\nmod common;\n\ncfg_if::cfg_if! {\n    if #[cfg(unix)] {\n        mod unix;\n        pub use self::unix::*;\n    } else if #[cfg(windows)] {\n        mod windows;\n        pub use self::windows::*;\n    } else if #[cfg(target_os = \"hermit\")] {\n        mod hermit;\n        pub use self::hermit::*;\n    } else if #[cfg(target_os = \"wasi\")] {\n        mod wasi;\n        pub use self::wasi::*;\n    } else if #[cfg(target_arch = \"wasm32\")] {\n        mod wasm;\n        pub use self::wasm::*;\n    } else if #[cfg(all(target_vendor = \"fortanix\", target_env = \"sgx\"))] {\n        mod sgx;\n        pub use self::sgx::*;\n    } else {\n        mod unsupported;\n        pub use self::unsupported::*;\n    }\n}\n\n// Import essential modules from platforms used in `std::os` when documenting.\n//\n// Note that on some platforms those modules don't compile\n// (missing things in `libc` which is empty), so they are not included in `std::os` and can be\n// omitted here as well.\n\n#[cfg(doc)]\n#[cfg(not(any(\n    all(target_arch = \"wasm32\", not(target_os = \"wasi\")),\n    all(target_vendor = \"fortanix\", target_env = \"sgx\")\n)))]\ncfg_if::cfg_if! {\n    if #[cfg(not(windows))] {\n        // On non-Windows platforms (aka linux/osx/etc) pull in a \"minimal\"\n        // amount of windows goop which ends up compiling\n\n        #[macro_use]\n        #[path = \"windows/compat.rs\"]\n        pub mod compat;\n\n        #[path = \"windows/c.rs\"]\n        pub mod c;\n    }\n}\n"],[2231,"#![deny(unsafe_op_in_unsafe_fn)]\n#![allow(dead_code)]\n\nuse super::err2io;\nuse crate::io::{self, IoSlice, IoSliceMut, SeekFrom};\nuse crate::mem;\nuse crate::net::Shutdown;\n\n#[derive(Debug)]\npub struct WasiFd {\n    fd: wasi::Fd,\n}\n\nfn iovec<'a>(a: &'a mut [IoSliceMut<'_>]) -> &'a [wasi::Iovec] {\n    assert_eq!(mem::size_of::<IoSliceMut<'_>>(), mem::size_of::<wasi::Iovec>());\n    assert_eq!(mem::align_of::<IoSliceMut<'_>>(), mem::align_of::<wasi::Iovec>());\n    // SAFETY: `IoSliceMut` and `IoVec` have exactly the same memory layout\n    unsafe { mem::transmute(a) }\n}\n\nfn ciovec<'a>(a: &'a [IoSlice<'_>]) -> &'a [wasi::Ciovec] {\n    assert_eq!(mem::size_of::<IoSlice<'_>>(), mem::size_of::<wasi::Ciovec>());\n    assert_eq!(mem::align_of::<IoSlice<'_>>(), mem::align_of::<wasi::Ciovec>());\n    // SAFETY: `IoSlice` and `CIoVec` have exactly the same memory layout\n    unsafe { mem::transmute(a) }\n}\n\nimpl WasiFd {\n    pub unsafe fn from_raw(fd: wasi::Fd) -> WasiFd {\n        WasiFd { fd }\n    }\n\n    pub fn into_raw(self) -> wasi::Fd {\n        let ret = self.fd;\n        mem::forget(self);\n        ret\n    }\n\n    pub fn as_raw(&self) -> wasi::Fd {\n        self.fd\n    }\n\n    pub fn datasync(&self) -> io::Result<()> {\n        unsafe { wasi::fd_datasync(self.fd).map_err(err2io) }\n    }\n\n    pub fn pread(&self, bufs: &mut [IoSliceMut<'_>], offset: u64) -> io::Result<usize> {\n        unsafe { wasi::fd_pread(self.fd, iovec(bufs), offset).map_err(err2io) }\n    }\n\n    pub fn pwrite(&self, bufs: &[IoSlice<'_>], offset: u64) -> io::Result<usize> {\n        unsafe { wasi::fd_pwrite(self.fd, ciovec(bufs), offset).map_err(err2io) }\n    }\n\n    pub fn read(&self, bufs: &mut [IoSliceMut<'_>]) -> io::Result<usize> {\n        unsafe { wasi::fd_read(self.fd, iovec(bufs)).map_err(err2io) }\n    }\n\n    pub fn write(&self, bufs: &[IoSlice<'_>]) -> io::Result<usize> {\n        unsafe { wasi::fd_write(self.fd, ciovec(bufs)).map_err(err2io) }\n    }\n\n    pub fn seek(&self, pos: SeekFrom) -> io::Result<u64> {\n        let (whence, offset) = match pos {\n            SeekFrom::Start(pos) => (wasi::WHENCE_SET, pos as i64),\n            SeekFrom::End(pos) => (wasi::WHENCE_END, pos),\n            SeekFrom::Current(pos) => (wasi::WHENCE_CUR, pos),\n        };\n        unsafe { wasi::fd_seek(self.fd, offset, whence).map_err(err2io) }\n    }\n\n    pub fn tell(&self) -> io::Result<u64> {\n        unsafe { wasi::fd_tell(self.fd).map_err(err2io) }\n    }\n\n    // FIXME: __wasi_fd_fdstat_get\n\n    pub fn set_flags(&self, flags: wasi::Fdflags) -> io::Result<()> {\n        unsafe { wasi::fd_fdstat_set_flags(self.fd, flags).map_err(err2io) }\n    }\n\n    pub fn set_rights(&self, base: wasi::Rights, inheriting: wasi::Rights) -> io::Result<()> {\n        unsafe { wasi::fd_fdstat_set_rights(self.fd, base, inheriting).map_err(err2io) }\n    }\n\n    pub fn sync(&self) -> io::Result<()> {\n        unsafe { wasi::fd_sync(self.fd).map_err(err2io) }\n    }\n\n    pub fn advise(&self, offset: u64, len: u64, advice: wasi::Advice) -> io::Result<()> {\n        unsafe { wasi::fd_advise(self.fd, offset, len, advice).map_err(err2io) }\n    }\n\n    pub fn allocate(&self, offset: u64, len: u64) -> io::Result<()> {\n        unsafe { wasi::fd_allocate(self.fd, offset, len).map_err(err2io) }\n    }\n\n    pub fn create_directory(&self, path: &str) -> io::Result<()> {\n        unsafe { wasi::path_create_directory(self.fd, path).map_err(err2io) }\n    }\n\n    pub fn link(\n        &self,\n        old_flags: wasi::Lookupflags,\n        old_path: &str,\n        new_fd: &WasiFd,\n        new_path: &str,\n    ) -> io::Result<()> {\n        unsafe {\n            wasi::path_link(self.fd, old_flags, old_path, new_fd.fd, new_path).map_err(err2io)\n        }\n    }\n\n    pub fn open(\n        &self,\n        dirflags: wasi::Lookupflags,\n        path: &str,\n        oflags: wasi::Oflags,\n        fs_rights_base: wasi::Rights,\n        fs_rights_inheriting: wasi::Rights,\n        fs_flags: wasi::Fdflags,\n    ) -> io::Result<WasiFd> {\n        unsafe {\n            wasi::path_open(\n                self.fd,\n                dirflags,\n                path,\n                oflags,\n                fs_rights_base,\n                fs_rights_inheriting,\n                fs_flags,\n            )\n            .map(|fd| WasiFd::from_raw(fd))\n            .map_err(err2io)\n        }\n    }\n\n    pub fn readdir(&self, buf: &mut [u8], cookie: wasi::Dircookie) -> io::Result<usize> {\n        unsafe { wasi::fd_readdir(self.fd, buf.as_mut_ptr(), buf.len(), cookie).map_err(err2io) }\n    }\n\n    pub fn readlink(&self, path: &str, buf: &mut [u8]) -> io::Result<usize> {\n        unsafe { wasi::path_readlink(self.fd, path, buf.as_mut_ptr(), buf.len()).map_err(err2io) }\n    }\n\n    pub fn rename(&self, old_path: &str, new_fd: &WasiFd, new_path: &str) -> io::Result<()> {\n        unsafe { wasi::path_rename(self.fd, old_path, new_fd.fd, new_path).map_err(err2io) }\n    }\n\n    pub fn filestat_get(&self) -> io::Result<wasi::Filestat> {\n        unsafe { wasi::fd_filestat_get(self.fd).map_err(err2io) }\n    }\n\n    pub fn filestat_set_times(\n        &self,\n        atim: wasi::Timestamp,\n        mtim: wasi::Timestamp,\n        fstflags: wasi::Fstflags,\n    ) -> io::Result<()> {\n        unsafe { wasi::fd_filestat_set_times(self.fd, atim, mtim, fstflags).map_err(err2io) }\n    }\n\n    pub fn filestat_set_size(&self, size: u64) -> io::Result<()> {\n        unsafe { wasi::fd_filestat_set_size(self.fd, size).map_err(err2io) }\n    }\n\n    pub fn path_filestat_get(\n        &self,\n        flags: wasi::Lookupflags,\n        path: &str,\n    ) -> io::Result<wasi::Filestat> {\n        unsafe { wasi::path_filestat_get(self.fd, flags, path).map_err(err2io) }\n    }\n\n    pub fn path_filestat_set_times(\n        &self,\n        flags: wasi::Lookupflags,\n        path: &str,\n        atim: wasi::Timestamp,\n        mtim: wasi::Timestamp,\n        fstflags: wasi::Fstflags,\n    ) -> io::Result<()> {\n        unsafe {\n            wasi::path_filestat_set_times(self.fd, flags, path, atim, mtim, fstflags)\n                .map_err(err2io)\n        }\n    }\n\n    pub fn symlink(&self, old_path: &str, new_path: &str) -> io::Result<()> {\n        unsafe { wasi::path_symlink(old_path, self.fd, new_path).map_err(err2io) }\n    }\n\n    pub fn unlink_file(&self, path: &str) -> io::Result<()> {\n        unsafe { wasi::path_unlink_file(self.fd, path).map_err(err2io) }\n    }\n\n    pub fn remove_directory(&self, path: &str) -> io::Result<()> {\n        unsafe { wasi::path_remove_directory(self.fd, path).map_err(err2io) }\n    }\n\n    pub fn sock_recv(\n        &self,\n        ri_data: &mut [IoSliceMut<'_>],\n        ri_flags: wasi::Riflags,\n    ) -> io::Result<(usize, wasi::Roflags)> {\n        unsafe { wasi::sock_recv(self.fd, iovec(ri_data), ri_flags).map_err(err2io) }\n    }\n\n    pub fn sock_send(&self, si_data: &[IoSlice<'_>], si_flags: wasi::Siflags) -> io::Result<usize> {\n        unsafe { wasi::sock_send(self.fd, ciovec(si_data), si_flags).map_err(err2io) }\n    }\n\n    pub fn sock_shutdown(&self, how: Shutdown) -> io::Result<()> {\n        let how = match how {\n            Shutdown::Read => wasi::SDFLAGS_RD,\n            Shutdown::Write => wasi::SDFLAGS_WR,\n            Shutdown::Both => wasi::SDFLAGS_WR | wasi::SDFLAGS_RD,\n        };\n        unsafe { wasi::sock_shutdown(self.fd, how).map_err(err2io) }\n    }\n}\n\nimpl Drop for WasiFd {\n    fn drop(&mut self) {\n        // FIXME: can we handle the return code here even though we can't on\n        // unix?\n        let _ = unsafe { wasi::fd_close(self.fd) };\n    }\n}\n"],[2232,"#![deny(unsafe_op_in_unsafe_fn)]\n\nuse crate::any::Any;\nuse crate::error::Error as StdError;\nuse crate::ffi::{CStr, CString, OsStr, OsString};\nuse crate::fmt;\nuse crate::io;\nuse crate::marker::PhantomData;\nuse crate::os::wasi::prelude::*;\nuse crate::path::{self, PathBuf};\nuse crate::str;\nuse crate::sys::memchr;\nuse crate::sys::unsupported;\nuse crate::vec;\n\n// Add a few symbols not in upstream `libc` just yet.\nmod libc {\n    pub use libc::*;\n\n    extern \"C\" {\n        pub fn getcwd(buf: *mut c_char, size: size_t) -> *mut c_char;\n        pub fn chdir(dir: *const c_char) -> c_int;\n    }\n}\n\n#[cfg(not(target_feature = \"atomics\"))]\npub unsafe fn env_lock() -> impl Any {\n    // No need for a lock if we're single-threaded, but this function will need\n    // to get implemented for multi-threaded scenarios\n}\n\npub fn errno() -> i32 {\n    extern \"C\" {\n        #[thread_local]\n        static errno: libc::c_int;\n    }\n\n    unsafe { errno as i32 }\n}\n\npub fn error_string(errno: i32) -> String {\n    let mut buf = [0 as libc::c_char; 1024];\n\n    let p = buf.as_mut_ptr();\n    unsafe {\n        if libc::strerror_r(errno as libc::c_int, p, buf.len()) < 0 {\n            panic!(\"strerror_r failure\");\n        }\n        str::from_utf8(CStr::from_ptr(p).to_bytes()).unwrap().to_owned()\n    }\n}\n\npub fn getcwd() -> io::Result<PathBuf> {\n    let mut buf = Vec::with_capacity(512);\n    loop {\n        unsafe {\n            let ptr = buf.as_mut_ptr() as *mut libc::c_char;\n            if !libc::getcwd(ptr, buf.capacity()).is_null() {\n                let len = CStr::from_ptr(buf.as_ptr() as *const libc::c_char).to_bytes().len();\n                buf.set_len(len);\n                buf.shrink_to_fit();\n                return Ok(PathBuf::from(OsString::from_vec(buf)));\n            } else {\n                let error = io::Error::last_os_error();\n                if error.raw_os_error() != Some(libc::ERANGE) {\n                    return Err(error);\n                }\n            }\n\n            // Trigger the internal buffer resizing logic of `Vec` by requiring\n            // more space than the current capacity.\n            let cap = buf.capacity();\n            buf.set_len(cap);\n            buf.reserve(1);\n        }\n    }\n}\n\npub fn chdir(p: &path::Path) -> io::Result<()> {\n    let p: &OsStr = p.as_ref();\n    let p = CString::new(p.as_bytes())?;\n    unsafe {\n        match libc::chdir(p.as_ptr()) == (0 as libc::c_int) {\n            true => Ok(()),\n            false => Err(io::Error::last_os_error()),\n        }\n    }\n}\n\npub struct SplitPaths<'a>(!, PhantomData<&'a ()>);\n\npub fn split_paths(_unparsed: &OsStr) -> SplitPaths<'_> {\n    panic!(\"unsupported\")\n}\n\nimpl<'a> Iterator for SplitPaths<'a> {\n    type Item = PathBuf;\n    fn next(&mut self) -> Option<PathBuf> {\n        self.0\n    }\n}\n\n#[derive(Debug)]\npub struct JoinPathsError;\n\npub fn join_paths<I, T>(_paths: I) -> Result<OsString, JoinPathsError>\nwhere\n    I: Iterator<Item = T>,\n    T: AsRef<OsStr>,\n{\n    Err(JoinPathsError)\n}\n\nimpl fmt::Display for JoinPathsError {\n    fn fmt(&self, f: &mut fmt::Formatter<'_>) -> fmt::Result {\n        \"not supported on wasm yet\".fmt(f)\n    }\n}\n\nimpl StdError for JoinPathsError {\n    #[allow(deprecated)]\n    fn description(&self) -> &str {\n        \"not supported on wasm yet\"\n    }\n}\n\npub fn current_exe() -> io::Result<PathBuf> {\n    unsupported()\n}\npub struct Env {\n    iter: vec::IntoIter<(OsString, OsString)>,\n}\n\nimpl !Send for Env {}\nimpl !Sync for Env {}\n\nimpl Iterator for Env {\n    type Item = (OsString, OsString);\n    fn next(&mut self) -> Option<(OsString, OsString)> {\n        self.iter.next()\n    }\n    fn size_hint(&self) -> (usize, Option<usize>) {\n        self.iter.size_hint()\n    }\n}\n\npub fn env() -> Env {\n    unsafe {\n        let _guard = env_lock();\n        let mut environ = libc::environ;\n        let mut result = Vec::new();\n        if !environ.is_null() {\n            while !(*environ).is_null() {\n                if let Some(key_value) = parse(CStr::from_ptr(*environ).to_bytes()) {\n                    result.push(key_value);\n                }\n                environ = environ.add(1);\n            }\n        }\n        return Env { iter: result.into_iter() };\n    }\n\n    // See src/libstd/sys/unix/os.rs, same as that\n    fn parse(input: &[u8]) -> Option<(OsString, OsString)> {\n        if input.is_empty() {\n            return None;\n        }\n        let pos = memchr::memchr(b'=', &input[1..]).map(|p| p + 1);\n        pos.map(|p| {\n            (\n                OsStringExt::from_vec(input[..p].to_vec()),\n                OsStringExt::from_vec(input[p + 1..].to_vec()),\n            )\n        })\n    }\n}\n\npub fn getenv(k: &OsStr) -> io::Result<Option<OsString>> {\n    let k = CString::new(k.as_bytes())?;\n    unsafe {\n        let _guard = env_lock();\n        let s = libc::getenv(k.as_ptr()) as *const libc::c_char;\n        let ret = if s.is_null() {\n            None\n        } else {\n            Some(OsStringExt::from_vec(CStr::from_ptr(s).to_bytes().to_vec()))\n        };\n        Ok(ret)\n    }\n}\n\npub fn setenv(k: &OsStr, v: &OsStr) -> io::Result<()> {\n    let k = CString::new(k.as_bytes())?;\n    let v = CString::new(v.as_bytes())?;\n\n    unsafe {\n        let _guard = env_lock();\n        cvt(libc::setenv(k.as_ptr(), v.as_ptr(), 1)).map(drop)\n    }\n}\n\npub fn unsetenv(n: &OsStr) -> io::Result<()> {\n    let nbuf = CString::new(n.as_bytes())?;\n\n    unsafe {\n        let _guard = env_lock();\n        cvt(libc::unsetenv(nbuf.as_ptr())).map(drop)\n    }\n}\n\npub fn temp_dir() -> PathBuf {\n    panic!(\"no filesystem on wasm\")\n}\n\npub fn home_dir() -> Option<PathBuf> {\n    None\n}\n\npub fn exit(code: i32) -> ! {\n    unsafe { libc::exit(code) }\n}\n\npub fn getpid() -> u32 {\n    panic!(\"unsupported\");\n}\n\n#[doc(hidden)]\npub trait IsMinusOne {\n    fn is_minus_one(&self) -> bool;\n}\n\nmacro_rules! impl_is_minus_one {\n    ($($t:ident)*) => ($(impl IsMinusOne for $t {\n        fn is_minus_one(&self) -> bool {\n            *self == -1\n        }\n    })*)\n}\n\nimpl_is_minus_one! { i8 i16 i32 i64 isize }\n\nfn cvt<T: IsMinusOne>(t: T) -> io::Result<T> {\n    if t.is_minus_one() { Err(io::Error::last_os_error()) } else { Ok(t) }\n}\n"],[2233,"#![deny(unsafe_op_in_unsafe_fn)]\n\nuse super::fd::WasiFd;\nuse crate::io::{self, IoSlice, IoSliceMut};\nuse crate::mem::ManuallyDrop;\n\npub struct Stdin;\npub struct Stdout;\npub struct Stderr;\n\nimpl Stdin {\n    pub const fn new() -> Stdin {\n        Stdin\n    }\n\n    #[inline]\n    pub fn as_raw_fd(&self) -> u32 {\n        0\n    }\n}\n\nimpl io::Read for Stdin {\n    fn read(&mut self, data: &mut [u8]) -> io::Result<usize> {\n        self.read_vectored(&mut [IoSliceMut::new(data)])\n    }\n\n    fn read_vectored(&mut self, data: &mut [IoSliceMut<'_>]) -> io::Result<usize> {\n        ManuallyDrop::new(unsafe { WasiFd::from_raw(self.as_raw_fd()) }).read(data)\n    }\n\n    #[inline]\n    fn is_read_vectored(&self) -> bool {\n        true\n    }\n}\n\nimpl Stdout {\n    pub const fn new() -> Stdout {\n        Stdout\n    }\n\n    #[inline]\n    pub fn as_raw_fd(&self) -> u32 {\n        1\n    }\n}\n\nimpl io::Write for Stdout {\n    fn write(&mut self, data: &[u8]) -> io::Result<usize> {\n        self.write_vectored(&[IoSlice::new(data)])\n    }\n\n    fn write_vectored(&mut self, data: &[IoSlice<'_>]) -> io::Result<usize> {\n        ManuallyDrop::new(unsafe { WasiFd::from_raw(self.as_raw_fd()) }).write(data)\n    }\n\n    #[inline]\n    fn is_write_vectored(&self) -> bool {\n        true\n    }\n    fn flush(&mut self) -> io::Result<()> {\n        Ok(())\n    }\n}\n\nimpl Stderr {\n    pub const fn new() -> Stderr {\n        Stderr\n    }\n\n    #[inline]\n    pub fn as_raw_fd(&self) -> u32 {\n        2\n    }\n}\n\nimpl io::Write for Stderr {\n    fn write(&mut self, data: &[u8]) -> io::Result<usize> {\n        self.write_vectored(&[IoSlice::new(data)])\n    }\n\n    fn write_vectored(&mut self, data: &[IoSlice<'_>]) -> io::Result<usize> {\n        ManuallyDrop::new(unsafe { WasiFd::from_raw(self.as_raw_fd()) }).write(data)\n    }\n\n    #[inline]\n    fn is_write_vectored(&self) -> bool {\n        true\n    }\n\n    fn flush(&mut self) -> io::Result<()> {\n        Ok(())\n    }\n}\n\npub const STDIN_BUF_SIZE: usize = crate::sys_common::io::DEFAULT_BUF_SIZE;\n\npub fn is_ebadf(err: &io::Error) -> bool {\n    err.raw_os_error() == Some(wasi::ERRNO_BADF.into())\n}\n\npub fn panic_output() -> Option<impl io::Write> {\n    Some(Stderr::new())\n}\n"],[2234,"#![deny(unsafe_op_in_unsafe_fn)]\n\nuse super::fd::WasiFd;\nuse crate::ffi::{CStr, CString, OsStr, OsString};\nuse crate::fmt;\nuse crate::io::{self, IoSlice, IoSliceMut, SeekFrom};\nuse crate::iter;\nuse crate::mem::{self, ManuallyDrop};\nuse crate::os::wasi::ffi::{OsStrExt, OsStringExt};\nuse crate::path::{Path, PathBuf};\nuse crate::ptr;\nuse crate::sync::Arc;\nuse crate::sys::time::SystemTime;\nuse crate::sys::unsupported;\nuse crate::sys_common::FromInner;\n\npub use crate::sys_common::fs::{remove_dir_all, try_exists};\n\npub struct File {\n    fd: WasiFd,\n}\n\n#[derive(Clone)]\npub struct FileAttr {\n    meta: wasi::Filestat,\n}\n\npub struct ReadDir {\n    inner: Arc<ReadDirInner>,\n    cookie: Option<wasi::Dircookie>,\n    buf: Vec<u8>,\n    offset: usize,\n    cap: usize,\n}\n\nstruct ReadDirInner {\n    root: PathBuf,\n    dir: File,\n}\n\npub struct DirEntry {\n    meta: wasi::Dirent,\n    name: Vec<u8>,\n    inner: Arc<ReadDirInner>,\n}\n\n#[derive(Clone, Debug, Default)]\npub struct OpenOptions {\n    read: bool,\n    write: bool,\n    append: bool,\n    dirflags: wasi::Lookupflags,\n    fdflags: wasi::Fdflags,\n    oflags: wasi::Oflags,\n    rights_base: Option<wasi::Rights>,\n    rights_inheriting: Option<wasi::Rights>,\n}\n\n#[derive(Clone, PartialEq, Eq, Debug)]\npub struct FilePermissions {\n    readonly: bool,\n}\n\n#[derive(PartialEq, Eq, Hash, Debug, Copy, Clone)]\npub struct FileType {\n    bits: wasi::Filetype,\n}\n\n#[derive(Debug)]\npub struct DirBuilder {}\n\nimpl FileAttr {\n    pub fn size(&self) -> u64 {\n        self.meta.size\n    }\n\n    pub fn perm(&self) -> FilePermissions {\n        // not currently implemented in wasi yet\n        FilePermissions { readonly: false }\n    }\n\n    pub fn file_type(&self) -> FileType {\n        FileType { bits: self.meta.filetype }\n    }\n\n    pub fn modified(&self) -> io::Result<SystemTime> {\n        Ok(SystemTime::from_wasi_timestamp(self.meta.mtim))\n    }\n\n    pub fn accessed(&self) -> io::Result<SystemTime> {\n        Ok(SystemTime::from_wasi_timestamp(self.meta.atim))\n    }\n\n    pub fn created(&self) -> io::Result<SystemTime> {\n        Ok(SystemTime::from_wasi_timestamp(self.meta.ctim))\n    }\n\n    pub fn as_wasi(&self) -> &wasi::Filestat {\n        &self.meta\n    }\n}\n\nimpl FilePermissions {\n    pub fn readonly(&self) -> bool {\n        self.readonly\n    }\n\n    pub fn set_readonly(&mut self, readonly: bool) {\n        self.readonly = readonly;\n    }\n}\n\nimpl FileType {\n    pub fn is_dir(&self) -> bool {\n        self.bits == wasi::FILETYPE_DIRECTORY\n    }\n\n    pub fn is_file(&self) -> bool {\n        self.bits == wasi::FILETYPE_REGULAR_FILE\n    }\n\n    pub fn is_symlink(&self) -> bool {\n        self.bits == wasi::FILETYPE_SYMBOLIC_LINK\n    }\n\n    pub fn bits(&self) -> wasi::Filetype {\n        self.bits\n    }\n}\n\nimpl fmt::Debug for ReadDir {\n    fn fmt(&self, f: &mut fmt::Formatter<'_>) -> fmt::Result {\n        f.debug_struct(\"ReadDir\").finish_non_exhaustive()\n    }\n}\n\nimpl Iterator for ReadDir {\n    type Item = io::Result<DirEntry>;\n\n    fn next(&mut self) -> Option<io::Result<DirEntry>> {\n        loop {\n            // If we've reached the capacity of our buffer then we need to read\n            // some more from the OS, otherwise we pick up at our old offset.\n            let offset = if self.offset == self.cap {\n                let cookie = self.cookie.take()?;\n                match self.inner.dir.fd.readdir(&mut self.buf, cookie) {\n                    Ok(bytes) => self.cap = bytes,\n                    Err(e) => return Some(Err(e)),\n                }\n                self.offset = 0;\n                self.cookie = Some(cookie);\n\n                // If we didn't actually read anything, this is in theory the\n                // end of the directory.\n                if self.cap == 0 {\n                    self.cookie = None;\n                    return None;\n                }\n\n                0\n            } else {\n                self.offset\n            };\n            let data = &self.buf[offset..self.cap];\n\n            // If we're not able to read a directory entry then that means it\n            // must have been truncated at the end of the buffer, so reset our\n            // offset so we can go back and reread into the buffer, picking up\n            // where we last left off.\n            let dirent_size = mem::size_of::<wasi::Dirent>();\n            if data.len() < dirent_size {\n                assert!(self.cookie.is_some());\n                assert!(self.buf.len() >= dirent_size);\n                self.offset = self.cap;\n                continue;\n            }\n            let (dirent, data) = data.split_at(dirent_size);\n            let dirent = unsafe { ptr::read_unaligned(dirent.as_ptr() as *const wasi::Dirent) };\n\n            // If the file name was truncated, then we need to reinvoke\n            // `readdir` so we truncate our buffer to start over and reread this\n            // descriptor. Note that if our offset is 0 that means the file name\n            // is massive and we need a bigger buffer.\n            if data.len() < dirent.d_namlen as usize {\n                if offset == 0 {\n                    let amt_to_add = self.buf.capacity();\n                    self.buf.extend(iter::repeat(0).take(amt_to_add));\n                }\n                assert!(self.cookie.is_some());\n                self.offset = self.cap;\n                continue;\n            }\n            self.cookie = Some(dirent.d_next);\n            self.offset = offset + dirent_size + dirent.d_namlen as usize;\n\n            let name = &data[..(dirent.d_namlen as usize)];\n\n            // These names are skipped on all other platforms, so let's skip\n            // them here too\n            if name == b\".\" || name == b\"..\" {\n                continue;\n            }\n\n            return Some(Ok(DirEntry {\n                meta: dirent,\n                name: name.to_vec(),\n                inner: self.inner.clone(),\n            }));\n        }\n    }\n}\n\nimpl DirEntry {\n    pub fn path(&self) -> PathBuf {\n        let name = OsStr::from_bytes(&self.name);\n        self.inner.root.join(name)\n    }\n\n    pub fn file_name(&self) -> OsString {\n        OsString::from_vec(self.name.clone())\n    }\n\n    pub fn metadata(&self) -> io::Result<FileAttr> {\n        metadata_at(&self.inner.dir.fd, 0, OsStr::from_bytes(&self.name).as_ref())\n    }\n\n    pub fn file_type(&self) -> io::Result<FileType> {\n        Ok(FileType { bits: self.meta.d_type })\n    }\n\n    pub fn ino(&self) -> wasi::Inode {\n        self.meta.d_ino\n    }\n}\n\nimpl OpenOptions {\n    pub fn new() -> OpenOptions {\n        let mut base = OpenOptions::default();\n        base.dirflags = wasi::LOOKUPFLAGS_SYMLINK_FOLLOW;\n        return base;\n    }\n\n    pub fn read(&mut self, read: bool) {\n        self.read = read;\n    }\n\n    pub fn write(&mut self, write: bool) {\n        self.write = write;\n    }\n\n    pub fn truncate(&mut self, truncate: bool) {\n        self.oflag(wasi::OFLAGS_TRUNC, truncate);\n    }\n\n    pub fn create(&mut self, create: bool) {\n        self.oflag(wasi::OFLAGS_CREAT, create);\n    }\n\n    pub fn create_new(&mut self, create_new: bool) {\n        self.oflag(wasi::OFLAGS_EXCL, create_new);\n        self.oflag(wasi::OFLAGS_CREAT, create_new);\n    }\n\n    pub fn directory(&mut self, directory: bool) {\n        self.oflag(wasi::OFLAGS_DIRECTORY, directory);\n    }\n\n    fn oflag(&mut self, bit: wasi::Oflags, set: bool) {\n        if set {\n            self.oflags |= bit;\n        } else {\n            self.oflags &= !bit;\n        }\n    }\n\n    pub fn append(&mut self, append: bool) {\n        self.append = append;\n        self.fdflag(wasi::FDFLAGS_APPEND, append);\n    }\n\n    pub fn dsync(&mut self, set: bool) {\n        self.fdflag(wasi::FDFLAGS_DSYNC, set);\n    }\n\n    pub fn nonblock(&mut self, set: bool) {\n        self.fdflag(wasi::FDFLAGS_NONBLOCK, set);\n    }\n\n    pub fn rsync(&mut self, set: bool) {\n        self.fdflag(wasi::FDFLAGS_RSYNC, set);\n    }\n\n    pub fn sync(&mut self, set: bool) {\n        self.fdflag(wasi::FDFLAGS_SYNC, set);\n    }\n\n    fn fdflag(&mut self, bit: wasi::Fdflags, set: bool) {\n        if set {\n            self.fdflags |= bit;\n        } else {\n            self.fdflags &= !bit;\n        }\n    }\n\n    pub fn fs_rights_base(&mut self, rights: wasi::Rights) {\n        self.rights_base = Some(rights);\n    }\n\n    pub fn fs_rights_inheriting(&mut self, rights: wasi::Rights) {\n        self.rights_inheriting = Some(rights);\n    }\n\n    fn rights_base(&self) -> wasi::Rights {\n        if let Some(rights) = self.rights_base {\n            return rights;\n        }\n\n        // If rights haven't otherwise been specified try to pick a reasonable\n        // set. This can always be overridden by users via extension traits, and\n        // implementations may give us fewer rights silently than we ask for. So\n        // given that, just look at `read` and `write` and bucket permissions\n        // based on that.\n        let mut base = 0;\n        if self.read {\n            base |= wasi::RIGHTS_FD_READ;\n            base |= wasi::RIGHTS_FD_READDIR;\n        }\n        if self.write || self.append {\n            base |= wasi::RIGHTS_FD_WRITE;\n            base |= wasi::RIGHTS_FD_DATASYNC;\n            base |= wasi::RIGHTS_FD_ALLOCATE;\n            base |= wasi::RIGHTS_FD_FILESTAT_SET_SIZE;\n        }\n\n        // FIXME: some of these should probably be read-only or write-only...\n        base |= wasi::RIGHTS_FD_ADVISE;\n        base |= wasi::RIGHTS_FD_FDSTAT_SET_FLAGS;\n        base |= wasi::RIGHTS_FD_FILESTAT_GET;\n        base |= wasi::RIGHTS_FD_FILESTAT_SET_TIMES;\n        base |= wasi::RIGHTS_FD_SEEK;\n        base |= wasi::RIGHTS_FD_SYNC;\n        base |= wasi::RIGHTS_FD_TELL;\n        base |= wasi::RIGHTS_PATH_CREATE_DIRECTORY;\n        base |= wasi::RIGHTS_PATH_CREATE_FILE;\n        base |= wasi::RIGHTS_PATH_FILESTAT_GET;\n        base |= wasi::RIGHTS_PATH_LINK_SOURCE;\n        base |= wasi::RIGHTS_PATH_LINK_TARGET;\n        base |= wasi::RIGHTS_PATH_OPEN;\n        base |= wasi::RIGHTS_PATH_READLINK;\n        base |= wasi::RIGHTS_PATH_REMOVE_DIRECTORY;\n        base |= wasi::RIGHTS_PATH_RENAME_SOURCE;\n        base |= wasi::RIGHTS_PATH_RENAME_TARGET;\n        base |= wasi::RIGHTS_PATH_SYMLINK;\n        base |= wasi::RIGHTS_PATH_UNLINK_FILE;\n        base |= wasi::RIGHTS_POLL_FD_READWRITE;\n\n        return base;\n    }\n\n    fn rights_inheriting(&self) -> wasi::Rights {\n        self.rights_inheriting.unwrap_or_else(|| self.rights_base())\n    }\n\n    pub fn lookup_flags(&mut self, flags: wasi::Lookupflags) {\n        self.dirflags = flags;\n    }\n}\n\nimpl File {\n    pub fn open(path: &Path, opts: &OpenOptions) -> io::Result<File> {\n        let (dir, file) = open_parent(path)?;\n        open_at(&dir, &file, opts)\n    }\n\n    pub fn open_at(&self, path: &Path, opts: &OpenOptions) -> io::Result<File> {\n        open_at(&self.fd, path, opts)\n    }\n\n    pub fn file_attr(&self) -> io::Result<FileAttr> {\n        self.fd.filestat_get().map(|meta| FileAttr { meta })\n    }\n\n    pub fn metadata_at(&self, flags: wasi::Lookupflags, path: &Path) -> io::Result<FileAttr> {\n        metadata_at(&self.fd, flags, path)\n    }\n\n    pub fn fsync(&self) -> io::Result<()> {\n        self.fd.sync()\n    }\n\n    pub fn datasync(&self) -> io::Result<()> {\n        self.fd.datasync()\n    }\n\n    pub fn truncate(&self, size: u64) -> io::Result<()> {\n        self.fd.filestat_set_size(size)\n    }\n\n    pub fn read(&self, buf: &mut [u8]) -> io::Result<usize> {\n        self.read_vectored(&mut [IoSliceMut::new(buf)])\n    }\n\n    pub fn read_vectored(&self, bufs: &mut [IoSliceMut<'_>]) -> io::Result<usize> {\n        self.fd.read(bufs)\n    }\n\n    #[inline]\n    pub fn is_read_vectored(&self) -> bool {\n        true\n    }\n\n    pub fn write(&self, buf: &[u8]) -> io::Result<usize> {\n        self.write_vectored(&[IoSlice::new(buf)])\n    }\n\n    pub fn write_vectored(&self, bufs: &[IoSlice<'_>]) -> io::Result<usize> {\n        self.fd.write(bufs)\n    }\n\n    #[inline]\n    pub fn is_write_vectored(&self) -> bool {\n        true\n    }\n\n    pub fn flush(&self) -> io::Result<()> {\n        Ok(())\n    }\n\n    pub fn seek(&self, pos: SeekFrom) -> io::Result<u64> {\n        self.fd.seek(pos)\n    }\n\n    pub fn duplicate(&self) -> io::Result<File> {\n        // https://github.com/CraneStation/wasmtime/blob/master/docs/WASI-rationale.md#why-no-dup\n        unsupported()\n    }\n\n    pub fn set_permissions(&self, _perm: FilePermissions) -> io::Result<()> {\n        // Permissions haven't been fully figured out in wasi yet, so this is\n        // likely temporary\n        unsupported()\n    }\n\n    pub fn fd(&self) -> &WasiFd {\n        &self.fd\n    }\n\n    pub fn into_fd(self) -> WasiFd {\n        self.fd\n    }\n\n    pub fn read_link(&self, file: &Path) -> io::Result<PathBuf> {\n        read_link(&self.fd, file)\n    }\n}\n\nimpl FromInner<u32> for File {\n    fn from_inner(fd: u32) -> File {\n        unsafe { File { fd: WasiFd::from_raw(fd) } }\n    }\n}\n\nimpl DirBuilder {\n    pub fn new() -> DirBuilder {\n        DirBuilder {}\n    }\n\n    pub fn mkdir(&self, p: &Path) -> io::Result<()> {\n        let (dir, file) = open_parent(p)?;\n        dir.create_directory(osstr2str(file.as_ref())?)\n    }\n}\n\nimpl fmt::Debug for File {\n    fn fmt(&self, f: &mut fmt::Formatter<'_>) -> fmt::Result {\n        f.debug_struct(\"File\").field(\"fd\", &self.fd.as_raw()).finish()\n    }\n}\n\npub fn readdir(p: &Path) -> io::Result<ReadDir> {\n    let mut opts = OpenOptions::new();\n    opts.directory(true);\n    opts.read(true);\n    let dir = File::open(p, &opts)?;\n    Ok(ReadDir {\n        cookie: Some(0),\n        buf: vec![0; 128],\n        offset: 0,\n        cap: 0,\n        inner: Arc::new(ReadDirInner { dir, root: p.to_path_buf() }),\n    })\n}\n\npub fn unlink(p: &Path) -> io::Result<()> {\n    let (dir, file) = open_parent(p)?;\n    dir.unlink_file(osstr2str(file.as_ref())?)\n}\n\npub fn rename(old: &Path, new: &Path) -> io::Result<()> {\n    let (old, old_file) = open_parent(old)?;\n    let (new, new_file) = open_parent(new)?;\n    old.rename(osstr2str(old_file.as_ref())?, &new, osstr2str(new_file.as_ref())?)\n}\n\npub fn set_perm(_p: &Path, _perm: FilePermissions) -> io::Result<()> {\n    // Permissions haven't been fully figured out in wasi yet, so this is\n    // likely temporary\n    unsupported()\n}\n\npub fn rmdir(p: &Path) -> io::Result<()> {\n    let (dir, file) = open_parent(p)?;\n    dir.remove_directory(osstr2str(file.as_ref())?)\n}\n\npub fn readlink(p: &Path) -> io::Result<PathBuf> {\n    let (dir, file) = open_parent(p)?;\n    read_link(&dir, &file)\n}\n\nfn read_link(fd: &WasiFd, file: &Path) -> io::Result<PathBuf> {\n    // Try to get a best effort initial capacity for the vector we're going to\n    // fill. Note that if it's not a symlink we don't use a file to avoid\n    // allocating gigabytes if you read_link a huge movie file by accident.\n    // Additionally we add 1 to the initial size so if it doesn't change until\n    // when we call `readlink` the returned length will be less than the\n    // capacity, guaranteeing that we got all the data.\n    let meta = metadata_at(fd, 0, file)?;\n    let initial_size = if meta.file_type().is_symlink() {\n        (meta.size() as usize).saturating_add(1)\n    } else {\n        1 // this'll fail in just a moment\n    };\n\n    // Now that we have an initial guess of how big to make our buffer, call\n    // `readlink` in a loop until it fails or reports it filled fewer bytes than\n    // we asked for, indicating we got everything.\n    let file = osstr2str(file.as_ref())?;\n    let mut destination = vec![0u8; initial_size];\n    loop {\n        let len = fd.readlink(file, &mut destination)?;\n        if len < destination.len() {\n            destination.truncate(len);\n            destination.shrink_to_fit();\n            return Ok(PathBuf::from(OsString::from_vec(destination)));\n        }\n        let amt_to_add = destination.len();\n        destination.extend(iter::repeat(0).take(amt_to_add));\n    }\n}\n\npub fn symlink(original: &Path, link: &Path) -> io::Result<()> {\n    let (link, link_file) = open_parent(link)?;\n    link.symlink(osstr2str(original.as_ref())?, osstr2str(link_file.as_ref())?)\n}\n\npub fn link(original: &Path, link: &Path) -> io::Result<()> {\n    let (original, original_file) = open_parent(original)?;\n    let (link, link_file) = open_parent(link)?;\n    // Pass 0 as the flags argument, meaning don't follow symlinks.\n    original.link(0, osstr2str(original_file.as_ref())?, &link, osstr2str(link_file.as_ref())?)\n}\n\npub fn stat(p: &Path) -> io::Result<FileAttr> {\n    let (dir, file) = open_parent(p)?;\n    metadata_at(&dir, wasi::LOOKUPFLAGS_SYMLINK_FOLLOW, &file)\n}\n\npub fn lstat(p: &Path) -> io::Result<FileAttr> {\n    let (dir, file) = open_parent(p)?;\n    metadata_at(&dir, 0, &file)\n}\n\nfn metadata_at(fd: &WasiFd, flags: wasi::Lookupflags, path: &Path) -> io::Result<FileAttr> {\n    let meta = fd.path_filestat_get(flags, osstr2str(path.as_ref())?)?;\n    Ok(FileAttr { meta })\n}\n\npub fn canonicalize(_p: &Path) -> io::Result<PathBuf> {\n    // This seems to not be in wasi's API yet, and we may need to end up\n    // emulating it ourselves. For now just return an error.\n    unsupported()\n}\n\nfn open_at(fd: &WasiFd, path: &Path, opts: &OpenOptions) -> io::Result<File> {\n    let fd = fd.open(\n        opts.dirflags,\n        osstr2str(path.as_ref())?,\n        opts.oflags,\n        opts.rights_base(),\n        opts.rights_inheriting(),\n        opts.fdflags,\n    )?;\n    Ok(File { fd })\n}\n\n/// Attempts to open a bare path `p`.\n///\n/// WASI has no fundamental capability to do this. All syscalls and operations\n/// are relative to already-open file descriptors. The C library, however,\n/// manages a map of pre-opened file descriptors to their path, and then the C\n/// library provides an API to look at this. In other words, when you want to\n/// open a path `p`, you have to find a previously opened file descriptor in a\n/// global table and then see if `p` is relative to that file descriptor.\n///\n/// This function, if successful, will return two items:\n///\n/// * The first is a `ManuallyDrop<WasiFd>`. This represents a pre-opened file\n///   descriptor which we don't have ownership of, but we can use. You shouldn't\n///   actually drop the `fd`.\n///\n/// * The second is a path that should be a part of `p` and represents a\n///   relative traversal from the file descriptor specified to the desired\n///   location `p`.\n///\n/// If successful you can use the returned file descriptor to perform\n/// file-descriptor-relative operations on the path returned as well. The\n/// `rights` argument indicates what operations are desired on the returned file\n/// descriptor, and if successful the returned file descriptor should have the\n/// appropriate rights for performing `rights` actions.\n///\n/// Note that this can fail if `p` doesn't look like it can be opened relative\n/// to any pre-opened file descriptor.\nfn open_parent(p: &Path) -> io::Result<(ManuallyDrop<WasiFd>, PathBuf)> {\n    let p = CString::new(p.as_os_str().as_bytes())?;\n    let mut buf = Vec::<u8>::with_capacity(512);\n    loop {\n        unsafe {\n            let mut relative_path = buf.as_ptr().cast();\n            let mut abs_prefix = ptr::null();\n            let fd = __wasilibc_find_relpath(\n                p.as_ptr(),\n                &mut abs_prefix,\n                &mut relative_path,\n                buf.capacity(),\n            );\n            if fd == -1 {\n                if io::Error::last_os_error().raw_os_error() == Some(libc::ENOMEM) {\n                    // Trigger the internal buffer resizing logic of `Vec` by requiring\n                    // more space than the current capacity.\n                    let cap = buf.capacity();\n                    buf.set_len(cap);\n                    buf.reserve(1);\n                    continue;\n                }\n                let msg = format!(\n                    \"failed to find a pre-opened file descriptor \\\n                     through which {:?} could be opened\",\n                    p\n                );\n                return Err(io::Error::new(io::ErrorKind::Other, msg));\n            }\n            let relative = CStr::from_ptr(relative_path).to_bytes().to_vec();\n\n            return Ok((\n                ManuallyDrop::new(WasiFd::from_raw(fd as u32)),\n                PathBuf::from(OsString::from_vec(relative)),\n            ));\n        }\n    }\n\n    extern \"C\" {\n        pub fn __wasilibc_find_relpath(\n            path: *const libc::c_char,\n            abs_prefix: *mut *const libc::c_char,\n            relative_path: *mut *const libc::c_char,\n            relative_path_len: libc::size_t,\n        ) -> libc::c_int;\n    }\n}\n\npub fn osstr2str(f: &OsStr) -> io::Result<&str> {\n    f.to_str().ok_or_else(|| io::Error::new_const(io::ErrorKind::Other, &\"input must be utf-8\"))\n}\n\npub fn copy(from: &Path, to: &Path) -> io::Result<u64> {\n    use crate::fs::File;\n\n    let mut reader = File::open(from)?;\n    let mut writer = File::create(to)?;\n\n    io::copy(&mut reader, &mut writer)\n}\n"],[2235,"#![deny(unsafe_op_in_unsafe_fn)]\n\nuse crate::ffi::{CStr, OsStr, OsString};\nuse crate::fmt;\nuse crate::os::wasi::ffi::OsStrExt;\nuse crate::vec;\n\npub struct Args {\n    iter: vec::IntoIter<OsString>,\n}\n\nimpl !Send for Args {}\nimpl !Sync for Args {}\n\n/// Returns the command line arguments\npub fn args() -> Args {\n    Args { iter: maybe_args().unwrap_or(Vec::new()).into_iter() }\n}\n\nfn maybe_args() -> Option<Vec<OsString>> {\n    unsafe {\n        let (argc, buf_size) = wasi::args_sizes_get().ok()?;\n        let mut argv = Vec::with_capacity(argc);\n        let mut buf = Vec::with_capacity(buf_size);\n        wasi::args_get(argv.as_mut_ptr(), buf.as_mut_ptr()).ok()?;\n        argv.set_len(argc);\n        let mut ret = Vec::with_capacity(argc);\n        for ptr in argv {\n            let s = CStr::from_ptr(ptr.cast());\n            ret.push(OsStr::from_bytes(s.to_bytes()).to_owned());\n        }\n        Some(ret)\n    }\n}\n\nimpl fmt::Debug for Args {\n    fn fmt(&self, f: &mut fmt::Formatter<'_>) -> fmt::Result {\n        self.iter.as_slice().fmt(f)\n    }\n}\n\nimpl Iterator for Args {\n    type Item = OsString;\n    fn next(&mut self) -> Option<OsString> {\n        self.iter.next()\n    }\n    fn size_hint(&self) -> (usize, Option<usize>) {\n        self.iter.size_hint()\n    }\n}\n\nimpl ExactSizeIterator for Args {\n    fn len(&self) -> usize {\n        self.iter.len()\n    }\n}\n\nimpl DoubleEndedIterator for Args {\n    fn next_back(&mut self) -> Option<OsString> {\n        self.iter.next_back()\n    }\n}\n"],[2236,"#![deny(unsafe_op_in_unsafe_fn)]\n\nuse crate::time::Duration;\n\n#[derive(Copy, Clone, PartialEq, Eq, PartialOrd, Ord, Debug, Hash)]\npub struct Instant(Duration);\n\n#[derive(Copy, Clone, PartialEq, Eq, PartialOrd, Ord, Debug, Hash)]\npub struct SystemTime(Duration);\n\npub const UNIX_EPOCH: SystemTime = SystemTime(Duration::from_secs(0));\n\nfn current_time(clock: u32) -> Duration {\n    let ts = unsafe {\n        wasi::clock_time_get(\n            clock, 1, // precision... seems ignored though?\n        )\n        .unwrap()\n    };\n    Duration::new((ts / 1_000_000_000) as u64, (ts % 1_000_000_000) as u32)\n}\n\nimpl Instant {\n    pub fn now() -> Instant {\n        Instant(current_time(wasi::CLOCKID_MONOTONIC))\n    }\n\n    pub const fn zero() -> Instant {\n        Instant(Duration::from_secs(0))\n    }\n\n    pub fn actually_monotonic() -> bool {\n        true\n    }\n\n    pub fn checked_sub_instant(&self, other: &Instant) -> Option<Duration> {\n        self.0.checked_sub(other.0)\n    }\n\n    pub fn checked_add_duration(&self, other: &Duration) -> Option<Instant> {\n        Some(Instant(self.0.checked_add(*other)?))\n    }\n\n    pub fn checked_sub_duration(&self, other: &Duration) -> Option<Instant> {\n        Some(Instant(self.0.checked_sub(*other)?))\n    }\n}\n\nimpl SystemTime {\n    pub fn now() -> SystemTime {\n        SystemTime(current_time(wasi::CLOCKID_REALTIME))\n    }\n\n    pub fn from_wasi_timestamp(ts: wasi::Timestamp) -> SystemTime {\n        SystemTime(Duration::from_nanos(ts))\n    }\n\n    pub fn sub_time(&self, other: &SystemTime) -> Result<Duration, Duration> {\n        self.0.checked_sub(other.0).ok_or_else(|| other.0 - self.0)\n    }\n\n    pub fn checked_add_duration(&self, other: &Duration) -> Option<SystemTime> {\n        Some(SystemTime(self.0.checked_add(*other)?))\n    }\n\n    pub fn checked_sub_duration(&self, other: &Duration) -> Option<SystemTime> {\n        Some(SystemTime(self.0.checked_sub(*other)?))\n    }\n}\n"],[2237,"pub mod os {\n    pub const FAMILY: &str = \"\";\n    pub const OS: &str = \"\";\n    pub const DLL_PREFIX: &str = \"\";\n    pub const DLL_SUFFIX: &str = \".wasm\";\n    pub const DLL_EXTENSION: &str = \"wasm\";\n    pub const EXE_SUFFIX: &str = \".wasm\";\n    pub const EXE_EXTENSION: &str = \"wasm\";\n}\n"],[2238,"//! System bindings for the wasm/web platform\n//!\n//! This module contains the facade (aka platform-specific) implementations of\n//! OS level functionality for wasm. Note that this wasm is *not* the emscripten\n//! wasm, so we have no runtime here.\n//!\n//! This is all super highly experimental and not actually intended for\n//! wide/production use yet, it's still all in the experimental category. This\n//! will likely change over time.\n//!\n//! Currently all functions here are basically stubs that immediately return\n//! errors. The hope is that with a portability lint we can turn actually just\n//! remove all this and just omit parts of the standard library if we're\n//! compiling for wasm. That way it's a compile time error for something that's\n//! guaranteed to be a runtime error!\n\nuse crate::io as std_io;\nuse crate::mem;\n\n#[path = \"../unix/alloc.rs\"]\npub mod alloc;\npub mod args;\n#[path = \"../unix/cmath.rs\"]\npub mod cmath;\n#[path = \"../unsupported/condvar.rs\"]\npub mod condvar;\npub mod env;\npub mod fd;\npub mod fs;\npub mod io;\n#[path = \"../unsupported/mutex.rs\"]\npub mod mutex;\npub mod net;\npub mod os;\npub use crate::sys_common::os_str_bytes as os_str;\n#[path = \"../unix/path.rs\"]\npub mod path;\n#[path = \"../unsupported/pipe.rs\"]\npub mod pipe;\n#[path = \"../unsupported/process.rs\"]\npub mod process;\n#[path = \"../unsupported/rwlock.rs\"]\npub mod rwlock;\npub mod stdio;\npub mod thread;\n#[path = \"../unsupported/thread_local_dtor.rs\"]\npub mod thread_local_dtor;\n#[path = \"../unsupported/thread_local_key.rs\"]\npub mod thread_local_key;\npub mod time;\n\n#[path = \"../unsupported/common.rs\"]\n#[deny(unsafe_op_in_unsafe_fn)]\n#[allow(unused)]\nmod common;\npub use common::*;\n\npub fn decode_error_kind(errno: i32) -> std_io::ErrorKind {\n    use std_io::ErrorKind::*;\n    if errno > u16::MAX as i32 || errno < 0 {\n        return Other;\n    }\n    match errno as u16 {\n        wasi::ERRNO_CONNREFUSED => ConnectionRefused,\n        wasi::ERRNO_CONNRESET => ConnectionReset,\n        wasi::ERRNO_PERM | wasi::ERRNO_ACCES => PermissionDenied,\n        wasi::ERRNO_PIPE => BrokenPipe,\n        wasi::ERRNO_NOTCONN => NotConnected,\n        wasi::ERRNO_CONNABORTED => ConnectionAborted,\n        wasi::ERRNO_ADDRNOTAVAIL => AddrNotAvailable,\n        wasi::ERRNO_ADDRINUSE => AddrInUse,\n        wasi::ERRNO_NOENT => NotFound,\n        wasi::ERRNO_INTR => Interrupted,\n        wasi::ERRNO_INVAL => InvalidInput,\n        wasi::ERRNO_TIMEDOUT => TimedOut,\n        wasi::ERRNO_EXIST => AlreadyExists,\n        wasi::ERRNO_AGAIN => WouldBlock,\n        wasi::ERRNO_NOSYS => Unsupported,\n        wasi::ERRNO_NOMEM => OutOfMemory,\n        _ => Other,\n    }\n}\n\npub fn abort_internal() -> ! {\n    unsafe { libc::abort() }\n}\n\npub fn hashmap_random_keys() -> (u64, u64) {\n    let mut ret = (0u64, 0u64);\n    unsafe {\n        let base = &mut ret as *mut (u64, u64) as *mut u8;\n        let len = mem::size_of_val(&ret);\n        wasi::random_get(base, len).expect(\"random_get failure\");\n    }\n    return ret;\n}\n\nfn err2io(err: wasi::Error) -> std_io::Error {\n    std_io::Error::from_raw_os_error(err.raw_error().into())\n}\n"],[2239,"#![deny(unsafe_op_in_unsafe_fn)]\n\nuse super::fd::WasiFd;\nuse crate::convert::TryFrom;\nuse crate::fmt;\nuse crate::io::{self, IoSlice, IoSliceMut};\nuse crate::net::{Ipv4Addr, Ipv6Addr, Shutdown, SocketAddr};\nuse crate::sys::unsupported;\nuse crate::sys_common::FromInner;\nuse crate::time::Duration;\n\npub struct TcpStream {\n    fd: WasiFd,\n}\n\nimpl TcpStream {\n    pub fn connect(_: io::Result<&SocketAddr>) -> io::Result<TcpStream> {\n        unsupported()\n    }\n\n    pub fn connect_timeout(_: &SocketAddr, _: Duration) -> io::Result<TcpStream> {\n        unsupported()\n    }\n\n    pub fn set_read_timeout(&self, _: Option<Duration>) -> io::Result<()> {\n        unsupported()\n    }\n\n    pub fn set_write_timeout(&self, _: Option<Duration>) -> io::Result<()> {\n        unsupported()\n    }\n\n    pub fn read_timeout(&self) -> io::Result<Option<Duration>> {\n        unsupported()\n    }\n\n    pub fn write_timeout(&self) -> io::Result<Option<Duration>> {\n        unsupported()\n    }\n\n    pub fn peek(&self, _: &mut [u8]) -> io::Result<usize> {\n        unsupported()\n    }\n\n    pub fn read(&self, _: &mut [u8]) -> io::Result<usize> {\n        unsupported()\n    }\n\n    pub fn read_vectored(&self, _: &mut [IoSliceMut<'_>]) -> io::Result<usize> {\n        unsupported()\n    }\n\n    pub fn is_read_vectored(&self) -> bool {\n        true\n    }\n\n    pub fn write(&self, _: &[u8]) -> io::Result<usize> {\n        unsupported()\n    }\n\n    pub fn write_vectored(&self, _: &[IoSlice<'_>]) -> io::Result<usize> {\n        unsupported()\n    }\n\n    pub fn is_write_vectored(&self) -> bool {\n        true\n    }\n\n    pub fn peer_addr(&self) -> io::Result<SocketAddr> {\n        unsupported()\n    }\n\n    pub fn socket_addr(&self) -> io::Result<SocketAddr> {\n        unsupported()\n    }\n\n    pub fn shutdown(&self, _: Shutdown) -> io::Result<()> {\n        unsupported()\n    }\n\n    pub fn duplicate(&self) -> io::Result<TcpStream> {\n        unsupported()\n    }\n\n    pub fn set_nodelay(&self, _: bool) -> io::Result<()> {\n        unsupported()\n    }\n\n    pub fn nodelay(&self) -> io::Result<bool> {\n        unsupported()\n    }\n\n    pub fn set_ttl(&self, _: u32) -> io::Result<()> {\n        unsupported()\n    }\n\n    pub fn ttl(&self) -> io::Result<u32> {\n        unsupported()\n    }\n\n    pub fn take_error(&self) -> io::Result<Option<io::Error>> {\n        unsupported()\n    }\n\n    pub fn set_nonblocking(&self, _: bool) -> io::Result<()> {\n        unsupported()\n    }\n\n    pub fn fd(&self) -> &WasiFd {\n        &self.fd\n    }\n\n    pub fn into_fd(self) -> WasiFd {\n        self.fd\n    }\n}\n\nimpl FromInner<u32> for TcpStream {\n    fn from_inner(fd: u32) -> TcpStream {\n        unsafe { TcpStream { fd: WasiFd::from_raw(fd) } }\n    }\n}\n\nimpl fmt::Debug for TcpStream {\n    fn fmt(&self, f: &mut fmt::Formatter<'_>) -> fmt::Result {\n        f.debug_struct(\"TcpStream\").field(\"fd\", &self.fd.as_raw()).finish()\n    }\n}\n\npub struct TcpListener {\n    fd: WasiFd,\n}\n\nimpl TcpListener {\n    pub fn bind(_: io::Result<&SocketAddr>) -> io::Result<TcpListener> {\n        unsupported()\n    }\n\n    pub fn socket_addr(&self) -> io::Result<SocketAddr> {\n        unsupported()\n    }\n\n    pub fn accept(&self) -> io::Result<(TcpStream, SocketAddr)> {\n        unsupported()\n    }\n\n    pub fn duplicate(&self) -> io::Result<TcpListener> {\n        unsupported()\n    }\n\n    pub fn set_ttl(&self, _: u32) -> io::Result<()> {\n        unsupported()\n    }\n\n    pub fn ttl(&self) -> io::Result<u32> {\n        unsupported()\n    }\n\n    pub fn set_only_v6(&self, _: bool) -> io::Result<()> {\n        unsupported()\n    }\n\n    pub fn only_v6(&self) -> io::Result<bool> {\n        unsupported()\n    }\n\n    pub fn take_error(&self) -> io::Result<Option<io::Error>> {\n        unsupported()\n    }\n\n    pub fn set_nonblocking(&self, _: bool) -> io::Result<()> {\n        unsupported()\n    }\n\n    pub fn fd(&self) -> &WasiFd {\n        &self.fd\n    }\n\n    pub fn into_fd(self) -> WasiFd {\n        self.fd\n    }\n}\n\nimpl FromInner<u32> for TcpListener {\n    fn from_inner(fd: u32) -> TcpListener {\n        unsafe { TcpListener { fd: WasiFd::from_raw(fd) } }\n    }\n}\n\nimpl fmt::Debug for TcpListener {\n    fn fmt(&self, f: &mut fmt::Formatter<'_>) -> fmt::Result {\n        f.debug_struct(\"TcpListener\").field(\"fd\", &self.fd.as_raw()).finish()\n    }\n}\n\npub struct UdpSocket {\n    fd: WasiFd,\n}\n\nimpl UdpSocket {\n    pub fn bind(_: io::Result<&SocketAddr>) -> io::Result<UdpSocket> {\n        unsupported()\n    }\n\n    pub fn peer_addr(&self) -> io::Result<SocketAddr> {\n        unsupported()\n    }\n\n    pub fn socket_addr(&self) -> io::Result<SocketAddr> {\n        unsupported()\n    }\n\n    pub fn recv_from(&self, _: &mut [u8]) -> io::Result<(usize, SocketAddr)> {\n        unsupported()\n    }\n\n    pub fn peek_from(&self, _: &mut [u8]) -> io::Result<(usize, SocketAddr)> {\n        unsupported()\n    }\n\n    pub fn send_to(&self, _: &[u8], _: &SocketAddr) -> io::Result<usize> {\n        unsupported()\n    }\n\n    pub fn duplicate(&self) -> io::Result<UdpSocket> {\n        unsupported()\n    }\n\n    pub fn set_read_timeout(&self, _: Option<Duration>) -> io::Result<()> {\n        unsupported()\n    }\n\n    pub fn set_write_timeout(&self, _: Option<Duration>) -> io::Result<()> {\n        unsupported()\n    }\n\n    pub fn read_timeout(&self) -> io::Result<Option<Duration>> {\n        unsupported()\n    }\n\n    pub fn write_timeout(&self) -> io::Result<Option<Duration>> {\n        unsupported()\n    }\n\n    pub fn set_broadcast(&self, _: bool) -> io::Result<()> {\n        unsupported()\n    }\n\n    pub fn broadcast(&self) -> io::Result<bool> {\n        unsupported()\n    }\n\n    pub fn set_multicast_loop_v4(&self, _: bool) -> io::Result<()> {\n        unsupported()\n    }\n\n    pub fn multicast_loop_v4(&self) -> io::Result<bool> {\n        unsupported()\n    }\n\n    pub fn set_multicast_ttl_v4(&self, _: u32) -> io::Result<()> {\n        unsupported()\n    }\n\n    pub fn multicast_ttl_v4(&self) -> io::Result<u32> {\n        unsupported()\n    }\n\n    pub fn set_multicast_loop_v6(&self, _: bool) -> io::Result<()> {\n        unsupported()\n    }\n\n    pub fn multicast_loop_v6(&self) -> io::Result<bool> {\n        unsupported()\n    }\n\n    pub fn join_multicast_v4(&self, _: &Ipv4Addr, _: &Ipv4Addr) -> io::Result<()> {\n        unsupported()\n    }\n\n    pub fn join_multicast_v6(&self, _: &Ipv6Addr, _: u32) -> io::Result<()> {\n        unsupported()\n    }\n\n    pub fn leave_multicast_v4(&self, _: &Ipv4Addr, _: &Ipv4Addr) -> io::Result<()> {\n        unsupported()\n    }\n\n    pub fn leave_multicast_v6(&self, _: &Ipv6Addr, _: u32) -> io::Result<()> {\n        unsupported()\n    }\n\n    pub fn set_ttl(&self, _: u32) -> io::Result<()> {\n        unsupported()\n    }\n\n    pub fn ttl(&self) -> io::Result<u32> {\n        unsupported()\n    }\n\n    pub fn take_error(&self) -> io::Result<Option<io::Error>> {\n        unsupported()\n    }\n\n    pub fn set_nonblocking(&self, _: bool) -> io::Result<()> {\n        unsupported()\n    }\n\n    pub fn recv(&self, _: &mut [u8]) -> io::Result<usize> {\n        unsupported()\n    }\n\n    pub fn peek(&self, _: &mut [u8]) -> io::Result<usize> {\n        unsupported()\n    }\n\n    pub fn send(&self, _: &[u8]) -> io::Result<usize> {\n        unsupported()\n    }\n\n    pub fn connect(&self, _: io::Result<&SocketAddr>) -> io::Result<()> {\n        unsupported()\n    }\n\n    pub fn fd(&self) -> &WasiFd {\n        &self.fd\n    }\n\n    pub fn into_fd(self) -> WasiFd {\n        self.fd\n    }\n}\n\nimpl FromInner<u32> for UdpSocket {\n    fn from_inner(fd: u32) -> UdpSocket {\n        unsafe { UdpSocket { fd: WasiFd::from_raw(fd) } }\n    }\n}\n\nimpl fmt::Debug for UdpSocket {\n    fn fmt(&self, f: &mut fmt::Formatter<'_>) -> fmt::Result {\n        f.debug_struct(\"UdpSocket\").field(\"fd\", &self.fd.as_raw()).finish()\n    }\n}\n\npub struct LookupHost(!);\n\nimpl LookupHost {\n    pub fn port(&self) -> u16 {\n        self.0\n    }\n}\n\nimpl Iterator for LookupHost {\n    type Item = SocketAddr;\n    fn next(&mut self) -> Option<SocketAddr> {\n        self.0\n    }\n}\n\nimpl<'a> TryFrom<&'a str> for LookupHost {\n    type Error = io::Error;\n\n    fn try_from(_v: &'a str) -> io::Result<LookupHost> {\n        unsupported()\n    }\n}\n\nimpl<'a> TryFrom<(&'a str, u16)> for LookupHost {\n    type Error = io::Error;\n\n    fn try_from(_v: (&'a str, u16)) -> io::Result<LookupHost> {\n        unsupported()\n    }\n}\n\n#[allow(nonstandard_style)]\npub mod netc {\n    pub const AF_INET: u8 = 0;\n    pub const AF_INET6: u8 = 1;\n    pub type sa_family_t = u8;\n\n    #[derive(Copy, Clone)]\n    pub struct in_addr {\n        pub s_addr: u32,\n    }\n\n    #[derive(Copy, Clone)]\n    pub struct sockaddr_in {\n        pub sin_family: sa_family_t,\n        pub sin_port: u16,\n        pub sin_addr: in_addr,\n    }\n\n    #[derive(Copy, Clone)]\n    pub struct in6_addr {\n        pub s6_addr: [u8; 16],\n    }\n\n    #[derive(Copy, Clone)]\n    pub struct sockaddr_in6 {\n        pub sin6_family: sa_family_t,\n        pub sin6_port: u16,\n        pub sin6_addr: in6_addr,\n        pub sin6_flowinfo: u32,\n        pub sin6_scope_id: u32,\n    }\n\n    #[derive(Copy, Clone)]\n    pub struct sockaddr {}\n\n    pub type socklen_t = usize;\n}\n"],[2240,"#![deny(unsafe_op_in_unsafe_fn)]\n\nuse crate::marker::PhantomData;\nuse crate::slice;\n\n#[derive(Copy, Clone)]\n#[repr(transparent)]\npub struct IoSlice<'a> {\n    vec: wasi::Ciovec,\n    _p: PhantomData<&'a [u8]>,\n}\n\nimpl<'a> IoSlice<'a> {\n    #[inline]\n    pub fn new(buf: &'a [u8]) -> IoSlice<'a> {\n        IoSlice { vec: wasi::Ciovec { buf: buf.as_ptr(), buf_len: buf.len() }, _p: PhantomData }\n    }\n\n    #[inline]\n    pub fn advance(&mut self, n: usize) {\n        if self.vec.buf_len < n {\n            panic!(\"advancing IoSlice beyond its length\");\n        }\n\n        unsafe {\n            self.vec.buf_len -= n;\n            self.vec.buf = self.vec.buf.add(n);\n        }\n    }\n\n    #[inline]\n    pub fn as_slice(&self) -> &[u8] {\n        unsafe { slice::from_raw_parts(self.vec.buf as *const u8, self.vec.buf_len) }\n    }\n}\n\n#[repr(transparent)]\npub struct IoSliceMut<'a> {\n    vec: wasi::Iovec,\n    _p: PhantomData<&'a mut [u8]>,\n}\n\nimpl<'a> IoSliceMut<'a> {\n    #[inline]\n    pub fn new(buf: &'a mut [u8]) -> IoSliceMut<'a> {\n        IoSliceMut {\n            vec: wasi::Iovec { buf: buf.as_mut_ptr(), buf_len: buf.len() },\n            _p: PhantomData,\n        }\n    }\n\n    #[inline]\n    pub fn advance(&mut self, n: usize) {\n        if self.vec.buf_len < n {\n            panic!(\"advancing IoSlice beyond its length\");\n        }\n\n        unsafe {\n            self.vec.buf_len -= n;\n            self.vec.buf = self.vec.buf.add(n);\n        }\n    }\n\n    #[inline]\n    pub fn as_slice(&self) -> &[u8] {\n        unsafe { slice::from_raw_parts(self.vec.buf as *const u8, self.vec.buf_len) }\n    }\n\n    #[inline]\n    pub fn as_mut_slice(&mut self) -> &mut [u8] {\n        unsafe { slice::from_raw_parts_mut(self.vec.buf as *mut u8, self.vec.buf_len) }\n    }\n}\n"],[2241,"#![deny(unsafe_op_in_unsafe_fn)]\n\nuse crate::ffi::CStr;\nuse crate::io;\nuse crate::mem;\nuse crate::num::NonZeroUsize;\nuse crate::sys::unsupported;\nuse crate::time::Duration;\n\npub struct Thread(!);\n\npub const DEFAULT_MIN_STACK_SIZE: usize = 4096;\n\nimpl Thread {\n    // unsafe: see thread::Builder::spawn_unchecked for safety requirements\n    pub unsafe fn new(_stack: usize, _p: Box<dyn FnOnce()>) -> io::Result<Thread> {\n        unsupported()\n    }\n\n    pub fn yield_now() {\n        let ret = unsafe { wasi::sched_yield() };\n        debug_assert_eq!(ret, Ok(()));\n    }\n\n    pub fn set_name(_name: &CStr) {\n        // nope\n    }\n\n    pub fn sleep(dur: Duration) {\n        let nanos = dur.as_nanos();\n        assert!(nanos <= u64::MAX as u128);\n\n        const USERDATA: wasi::Userdata = 0x0123_45678;\n\n        let clock = wasi::SubscriptionClock {\n            id: wasi::CLOCKID_MONOTONIC,\n            timeout: nanos as u64,\n            precision: 0,\n            flags: 0,\n        };\n\n        let in_ = wasi::Subscription {\n            userdata: USERDATA,\n            r#type: wasi::EVENTTYPE_CLOCK,\n            u: wasi::SubscriptionU { clock },\n        };\n        unsafe {\n            let mut event: wasi::Event = mem::zeroed();\n            let res = wasi::poll_oneoff(&in_, &mut event, 1);\n            match (res, event) {\n                (\n                    Ok(1),\n                    wasi::Event {\n                        userdata: USERDATA, error: 0, r#type: wasi::EVENTTYPE_CLOCK, ..\n                    },\n                ) => {}\n                _ => panic!(\"thread::sleep(): unexpected result of poll_oneoff\"),\n            }\n        }\n    }\n\n    pub fn join(self) {\n        self.0\n    }\n}\n\npub fn available_concurrency() -> io::Result<NonZeroUsize> {\n    unsupported()\n}\n\npub mod guard {\n    pub type Guard = !;\n    pub unsafe fn current() -> Option<Guard> {\n        None\n    }\n    pub unsafe fn init() -> Option<Guard> {\n        None\n    }\n}\n"],[2242,"//! System bindings for the wasm/web platform\n//!\n//! This module contains the facade (aka platform-specific) implementations of\n//! OS level functionality for wasm. Note that this wasm is *not* the emscripten\n//! wasm, so we have no runtime here.\n//!\n//! This is all super highly experimental and not actually intended for\n//! wide/production use yet, it's still all in the experimental category. This\n//! will likely change over time.\n//!\n//! Currently all functions here are basically stubs that immediately return\n//! errors. The hope is that with a portability lint we can turn actually just\n//! remove all this and just omit parts of the standard library if we're\n//! compiling for wasm. That way it's a compile time error for something that's\n//! guaranteed to be a runtime error!\n\n#![deny(unsafe_op_in_unsafe_fn)]\n\npub mod alloc;\n#[path = \"../unsupported/args.rs\"]\npub mod args;\n#[path = \"../unix/cmath.rs\"]\npub mod cmath;\npub mod env;\n#[path = \"../unsupported/fs.rs\"]\npub mod fs;\n#[path = \"../unsupported/io.rs\"]\npub mod io;\n#[path = \"../unsupported/net.rs\"]\npub mod net;\n#[path = \"../unsupported/os.rs\"]\npub mod os;\n#[path = \"../unix/path.rs\"]\npub mod path;\n#[path = \"../unsupported/pipe.rs\"]\npub mod pipe;\n#[path = \"../unsupported/process.rs\"]\npub mod process;\n#[path = \"../unsupported/stdio.rs\"]\npub mod stdio;\n#[path = \"../unsupported/thread_local_dtor.rs\"]\npub mod thread_local_dtor;\n#[path = \"../unsupported/thread_local_key.rs\"]\npub mod thread_local_key;\n#[path = \"../unsupported/time.rs\"]\npub mod time;\n\npub use crate::sys_common::os_str_bytes as os_str;\n\ncfg_if::cfg_if! {\n    if #[cfg(target_feature = \"atomics\")] {\n        #[path = \"atomics/condvar.rs\"]\n        pub mod condvar;\n        #[path = \"atomics/mutex.rs\"]\n        pub mod mutex;\n        #[path = \"atomics/rwlock.rs\"]\n        pub mod rwlock;\n        #[path = \"atomics/futex.rs\"]\n        pub mod futex;\n        #[path = \"atomics/thread.rs\"]\n        pub mod thread;\n    } else {\n        #[path = \"../unsupported/condvar.rs\"]\n        pub mod condvar;\n        #[path = \"../unsupported/mutex.rs\"]\n        pub mod mutex;\n        #[path = \"../unsupported/rwlock.rs\"]\n        pub mod rwlock;\n        #[path = \"../unsupported/thread.rs\"]\n        pub mod thread;\n    }\n}\n\n#[path = \"../unsupported/common.rs\"]\n#[deny(unsafe_op_in_unsafe_fn)]\nmod common;\npub use common::*;\n"],[2243,"pub mod os {\n    pub const FAMILY: &str = \"\";\n    pub const OS: &str = \"\";\n    pub const DLL_PREFIX: &str = \"\";\n    pub const DLL_SUFFIX: &str = \".wasm\";\n    pub const DLL_EXTENSION: &str = \"wasm\";\n    pub const EXE_SUFFIX: &str = \".wasm\";\n    pub const EXE_EXTENSION: &str = \"wasm\";\n}\n"],[2244,"//! This is an implementation of a global allocator on the wasm32 platform when\n//! emscripten is not in use. In that situation there's no actual runtime for us\n//! to lean on for allocation, so instead we provide our own!\n//!\n//! The wasm32 instruction set has two instructions for getting the current\n//! amount of memory and growing the amount of memory. These instructions are the\n//! foundation on which we're able to build an allocator, so we do so! Note that\n//! the instructions are also pretty \"global\" and this is the \"global\" allocator\n//! after all!\n//!\n//! The current allocator here is the `dlmalloc` crate which we've got included\n//! in the rust-lang/rust repository as a submodule. The crate is a port of\n//! dlmalloc.c from C to Rust and is basically just so we can have \"pure Rust\"\n//! for now which is currently technically required (can't link with C yet).\n//!\n//! The crate itself provides a global allocator which on wasm has no\n//! synchronization as there are no threads!\n\nuse crate::alloc::{GlobalAlloc, Layout, System};\n\nstatic mut DLMALLOC: dlmalloc::Dlmalloc = dlmalloc::Dlmalloc::new();\n\n#[stable(feature = \"alloc_system_type\", since = \"1.28.0\")]\nunsafe impl GlobalAlloc for System {\n    #[inline]\n    unsafe fn alloc(&self, layout: Layout) -> *mut u8 {\n        // SAFETY: DLMALLOC access is guranteed to be safe because the lock gives us unique and non-reentrant access.\n        // Calling malloc() is safe because preconditions on this function match the trait method preconditions.\n        let _lock = lock::lock();\n        unsafe { DLMALLOC.malloc(layout.size(), layout.align()) }\n    }\n\n    #[inline]\n    unsafe fn alloc_zeroed(&self, layout: Layout) -> *mut u8 {\n        // SAFETY: DLMALLOC access is guranteed to be safe because the lock gives us unique and non-reentrant access.\n        // Calling calloc() is safe because preconditions on this function match the trait method preconditions.\n        let _lock = lock::lock();\n        unsafe { DLMALLOC.calloc(layout.size(), layout.align()) }\n    }\n\n    #[inline]\n    unsafe fn dealloc(&self, ptr: *mut u8, layout: Layout) {\n        // SAFETY: DLMALLOC access is guranteed to be safe because the lock gives us unique and non-reentrant access.\n        // Calling free() is safe because preconditions on this function match the trait method preconditions.\n        let _lock = lock::lock();\n        unsafe { DLMALLOC.free(ptr, layout.size(), layout.align()) }\n    }\n\n    #[inline]\n    unsafe fn realloc(&self, ptr: *mut u8, layout: Layout, new_size: usize) -> *mut u8 {\n        // SAFETY: DLMALLOC access is guranteed to be safe because the lock gives us unique and non-reentrant access.\n        // Calling realloc() is safe because preconditions on this function match the trait method preconditions.\n        let _lock = lock::lock();\n        unsafe { DLMALLOC.realloc(ptr, layout.size(), layout.align(), new_size) }\n    }\n}\n\n#[cfg(target_feature = \"atomics\")]\nmod lock {\n    use crate::sync::atomic::{AtomicI32, Ordering::SeqCst};\n\n    static LOCKED: AtomicI32 = AtomicI32::new(0);\n\n    pub struct DropLock;\n\n    pub fn lock() -> DropLock {\n        loop {\n            if LOCKED.swap(1, SeqCst) == 0 {\n                return DropLock;\n            }\n            // Ok so here's where things get a little depressing. At this point\n            // in time we need to synchronously acquire a lock, but we're\n            // contending with some other thread. Typically we'd execute some\n            // form of `i32.atomic.wait` like so:\n            //\n            //     unsafe {\n            //         let r = core::arch::wasm32::i32_atomic_wait(\n            //             LOCKED.as_mut_ptr(),\n            //             1,  //     expected value\n            //             -1, //     timeout\n            //         );\n            //         debug_assert!(r == 0 || r == 1);\n            //     }\n            //\n            // Unfortunately though in doing so we would cause issues for the\n            // main thread. The main thread in a web browser *cannot ever\n            // block*, no exceptions. This means that the main thread can't\n            // actually execute the `i32.atomic.wait` instruction.\n            //\n            // As a result if we want to work within the context of browsers we\n            // need to figure out some sort of allocation scheme for the main\n            // thread where when there's contention on the global malloc lock we\n            // do... something.\n            //\n            // Possible ideas include:\n            //\n            // 1. Attempt to acquire the global lock. If it fails, fall back to\n            //    memory allocation via `memory.grow`. Later just ... somehow\n            //    ... inject this raw page back into the main allocator as it\n            //    gets sliced up over time. This strategy has the downside of\n            //    forcing allocation of a page to happen whenever the main\n            //    thread contents with other threads, which is unfortunate.\n            //\n            // 2. Maintain a form of \"two level\" allocator scheme where the main\n            //    thread has its own allocator. Somehow this allocator would\n            //    also be balanced with a global allocator, not only to have\n            //    allocations cross between threads but also to ensure that the\n            //    two allocators stay \"balanced\" in terms of free'd memory and\n            //    such. This, however, seems significantly complicated.\n            //\n            // Out of a lack of other ideas, the current strategy implemented\n            // here is to simply spin. Typical spin loop algorithms have some\n            // form of \"hint\" here to the CPU that it's what we're doing to\n            // ensure that the CPU doesn't get too hot, but wasm doesn't have\n            // such an instruction.\n            //\n            // To be clear, spinning here is not a great solution.\n            // Another thread with the lock may take quite a long time to wake\n            // up. For example it could be in `memory.grow` or it could be\n            // evicted from the CPU for a timeslice like 10ms. For these periods\n            // of time our thread will \"helpfully\" sit here and eat CPU time\n            // until it itself is evicted or the lock holder finishes. This\n            // means we're just burning and wasting CPU time to no one's\n            // benefit.\n            //\n            // Spinning does have the nice properties, though, of being\n            // semantically correct, being fair to all threads for memory\n            // allocation, and being simple enough to implement.\n            //\n            // This will surely (hopefully) be replaced in the future with a\n            // real memory allocator that can handle the restriction of the main\n            // thread.\n            //\n            //\n            // FIXME: We can also possibly add an optimization here to detect\n            // when a thread is the main thread or not and block on all\n            // non-main-thread threads. Currently, however, we have no way\n            // of knowing which wasm thread is on the browser main thread, but\n            // if we could figure out we could at least somewhat mitigate the\n            // cost of this spinning.\n        }\n    }\n\n    impl Drop for DropLock {\n        fn drop(&mut self) {\n            let r = LOCKED.swap(0, SeqCst);\n            debug_assert_eq!(r, 1);\n\n            // Note that due to the above logic we don't actually need to wake\n            // anyone up, but if we did it'd likely look something like this:\n            //\n            //     unsafe {\n            //         core::arch::wasm32::atomic_notify(\n            //             LOCKED.as_mut_ptr(),\n            //             1, //     only one thread\n            //         );\n            //     }\n        }\n    }\n}\n\n#[cfg(not(target_feature = \"atomics\"))]\nmod lock {\n    #[inline]\n    pub fn lock() {} // no atomics, no threads, that's easy!\n}\n"],[2245,"use crate::arch::wasm32;\nuse crate::cell::UnsafeCell;\nuse crate::mem;\nuse crate::sync::atomic::{AtomicU32, AtomicUsize, Ordering::SeqCst};\nuse crate::sys::thread;\n\npub struct Mutex {\n    locked: AtomicUsize,\n}\n\npub type MovableMutex = Mutex;\n\n// Mutexes have a pretty simple implementation where they contain an `i32`\n// internally that is 0 when unlocked and 1 when the mutex is locked.\n// Acquisition has a fast path where it attempts to cmpxchg the 0 to a 1, and\n// if it fails it then waits for a notification. Releasing a lock is then done\n// by swapping in 0 and then notifying any waiters, if present.\n\nimpl Mutex {\n    pub const fn new() -> Mutex {\n        Mutex { locked: AtomicUsize::new(0) }\n    }\n\n    #[inline]\n    pub unsafe fn init(&mut self) {\n        // nothing to do\n    }\n\n    pub unsafe fn lock(&self) {\n        while !self.try_lock() {\n            // SAFETY: the caller must uphold the safety contract for `memory_atomic_wait32`.\n            let val = unsafe {\n                wasm32::memory_atomic_wait32(\n                    self.ptr(),\n                    1,  // we expect our mutex is locked\n                    -1, // wait infinitely\n                )\n            };\n            // we should have either woke up (0) or got a not-equal due to a\n            // race (1). We should never time out (2)\n            debug_assert!(val == 0 || val == 1);\n        }\n    }\n\n    pub unsafe fn unlock(&self) {\n        let prev = self.locked.swap(0, SeqCst);\n        debug_assert_eq!(prev, 1);\n        wasm32::memory_atomic_notify(self.ptr(), 1); // wake up one waiter, if any\n    }\n\n    #[inline]\n    pub unsafe fn try_lock(&self) -> bool {\n        self.locked.compare_exchange(0, 1, SeqCst, SeqCst).is_ok()\n    }\n\n    #[inline]\n    pub unsafe fn destroy(&self) {\n        // nothing to do\n    }\n\n    #[inline]\n    fn ptr(&self) -> *mut i32 {\n        assert_eq!(mem::size_of::<usize>(), mem::size_of::<i32>());\n        self.locked.as_mut_ptr() as *mut i32\n    }\n}\n\npub struct ReentrantMutex {\n    owner: AtomicU32,\n    recursions: UnsafeCell<u32>,\n}\n\nunsafe impl Send for ReentrantMutex {}\nunsafe impl Sync for ReentrantMutex {}\n\n// Reentrant mutexes are similarly implemented to mutexs above except that\n// instead of \"1\" meaning unlocked we use the id of a thread to represent\n// whether it has locked a mutex. That way we have an atomic counter which\n// always holds the id of the thread that currently holds the lock (or 0 if the\n// lock is unlocked).\n//\n// Once a thread acquires a lock recursively, which it detects by looking at\n// the value that's already there, it will update a local `recursions` counter\n// in a nonatomic fashion (as we hold the lock). The lock is then fully\n// released when this recursion counter reaches 0.\n\nimpl ReentrantMutex {\n    pub const unsafe fn uninitialized() -> ReentrantMutex {\n        ReentrantMutex { owner: AtomicU32::new(0), recursions: UnsafeCell::new(0) }\n    }\n\n    pub unsafe fn init(&self) {\n        // nothing to do...\n    }\n\n    pub unsafe fn lock(&self) {\n        let me = thread::my_id();\n        while let Err(owner) = self._try_lock(me) {\n            // SAFETY: the caller must gurantee that `self.ptr()` and `owner` are valid i32.\n            let val = unsafe { wasm32::memory_atomic_wait32(self.ptr(), owner as i32, -1) };\n            debug_assert!(val == 0 || val == 1);\n        }\n    }\n\n    #[inline]\n    pub unsafe fn try_lock(&self) -> bool {\n        unsafe { self._try_lock(thread::my_id()).is_ok() }\n    }\n\n    #[inline]\n    unsafe fn _try_lock(&self, id: u32) -> Result<(), u32> {\n        let id = id.checked_add(1).unwrap();\n        match self.owner.compare_exchange(0, id, SeqCst, SeqCst) {\n            // we transitioned from unlocked to locked\n            Ok(_) => {\n                debug_assert_eq!(*self.recursions.get(), 0);\n                Ok(())\n            }\n\n            // we currently own this lock, so let's update our count and return\n            // true.\n            Err(n) if n == id => {\n                *self.recursions.get() += 1;\n                Ok(())\n            }\n\n            // Someone else owns the lock, let our caller take care of it\n            Err(other) => Err(other),\n        }\n    }\n\n    pub unsafe fn unlock(&self) {\n        // If we didn't ever recursively lock the lock then we fully unlock the\n        // mutex and wake up a waiter, if any. Otherwise we decrement our\n        // recursive counter and let some one else take care of the zero.\n        match *self.recursions.get() {\n            0 => {\n                self.owner.swap(0, SeqCst);\n                // SAFETY: the caller must gurantee that `self.ptr()` is valid i32.\n                unsafe {\n                    wasm32::memory_atomic_notify(self.ptr() as *mut i32, 1);\n                } // wake up one waiter, if any\n            }\n            ref mut n => *n -= 1,\n        }\n    }\n\n    pub unsafe fn destroy(&self) {\n        // nothing to do...\n    }\n\n    #[inline]\n    fn ptr(&self) -> *mut i32 {\n        self.owner.as_mut_ptr() as *mut i32\n    }\n}\n"],[2246,"use super::unsupported;\nuse crate::ffi::CStr;\nuse crate::io;\nuse crate::num::NonZeroUsize;\nuse crate::sys::unsupported;\nuse crate::time::Duration;\n\npub struct Thread(!);\n\npub const DEFAULT_MIN_STACK_SIZE: usize = 4096;\n\nimpl Thread {\n    // unsafe: see thread::Builder::spawn_unchecked for safety requirements\n    pub unsafe fn new(_stack: usize, _p: Box<dyn FnOnce()>) -> io::Result<Thread> {\n        unsupported()\n    }\n\n    pub fn yield_now() {}\n\n    pub fn set_name(_name: &CStr) {}\n\n    pub fn sleep(dur: Duration) {\n        use crate::arch::wasm32;\n        use crate::cmp;\n\n        // Use an atomic wait to block the current thread artificially with a\n        // timeout listed. Note that we should never be notified (return value\n        // of 0) or our comparison should never fail (return value of 1) so we\n        // should always only resume execution through a timeout (return value\n        // 2).\n        let mut nanos = dur.as_nanos();\n        while nanos > 0 {\n            let amt = cmp::min(i64::MAX as u128, nanos);\n            let mut x = 0;\n            let val = unsafe { wasm32::memory_atomic_wait32(&mut x, 0, amt as i64) };\n            debug_assert_eq!(val, 2);\n            nanos -= amt;\n        }\n    }\n\n    pub fn join(self) {}\n}\n\npub fn available_concurrency() -> io::Result<NonZeroUsize> {\n    unsupported()\n}\n\npub mod guard {\n    pub type Guard = !;\n    pub unsafe fn current() -> Option<Guard> {\n        None\n    }\n    pub unsafe fn init() -> Option<Guard> {\n        None\n    }\n}\n\n// We currently just use our own thread-local to store our\n// current thread's ID, and then we lazily initialize it to something allocated\n// from a global counter.\npub fn my_id() -> u32 {\n    use crate::sync::atomic::{AtomicU32, Ordering::SeqCst};\n\n    static NEXT_ID: AtomicU32 = AtomicU32::new(0);\n\n    #[thread_local]\n    static mut MY_ID: u32 = 0;\n\n    unsafe {\n        // If our thread ID isn't set yet then we need to allocate one. Do so\n        // with with a simple \"atomically add to a global counter\" strategy.\n        // This strategy doesn't handled what happens when the counter\n        // overflows, however, so just abort everything once the counter\n        // overflows and eventually we could have some sort of recycling scheme\n        // (or maybe this is all totally irrelevant by that point!). In any case\n        // though we're using a CAS loop instead of a `fetch_add` to ensure that\n        // the global counter never overflows.\n        if MY_ID == 0 {\n            let mut cur = NEXT_ID.load(SeqCst);\n            MY_ID = loop {\n                let next = cur.checked_add(1).unwrap_or_else(|| crate::process::abort());\n                match NEXT_ID.compare_exchange(cur, next, SeqCst, SeqCst) {\n                    Ok(_) => break next,\n                    Err(i) => cur = i,\n                }\n            };\n        }\n        MY_ID\n    }\n}\n"],[2247,"use crate::cell::UnsafeCell;\nuse crate::sys::condvar::Condvar;\nuse crate::sys::mutex::Mutex;\n\npub struct RWLock {\n    lock: Mutex,\n    cond: Condvar,\n    state: UnsafeCell<State>,\n}\n\npub type MovableRWLock = RWLock;\n\nenum State {\n    Unlocked,\n    Reading(usize),\n    Writing,\n}\n\nunsafe impl Send for RWLock {}\nunsafe impl Sync for RWLock {}\n\n// This rwlock implementation is a relatively simple implementation which has a\n// condition variable for readers/writers as well as a mutex protecting the\n// internal state of the lock. A current downside of the implementation is that\n// unlocking the lock will notify *all* waiters rather than just readers or just\n// writers. This can cause lots of \"thundering stampede\" problems. While\n// hopefully correct this implementation is very likely to want to be changed in\n// the future.\n\nimpl RWLock {\n    pub const fn new() -> RWLock {\n        RWLock { lock: Mutex::new(), cond: Condvar::new(), state: UnsafeCell::new(State::Unlocked) }\n    }\n\n    #[inline]\n    pub unsafe fn read(&self) {\n        self.lock.lock();\n        while !(*self.state.get()).inc_readers() {\n            self.cond.wait(&self.lock);\n        }\n        self.lock.unlock();\n    }\n\n    #[inline]\n    pub unsafe fn try_read(&self) -> bool {\n        self.lock.lock();\n        let ok = (*self.state.get()).inc_readers();\n        self.lock.unlock();\n        return ok;\n    }\n\n    #[inline]\n    pub unsafe fn write(&self) {\n        self.lock.lock();\n        while !(*self.state.get()).inc_writers() {\n            self.cond.wait(&self.lock);\n        }\n        self.lock.unlock();\n    }\n\n    #[inline]\n    pub unsafe fn try_write(&self) -> bool {\n        self.lock.lock();\n        let ok = (*self.state.get()).inc_writers();\n        self.lock.unlock();\n        return ok;\n    }\n\n    #[inline]\n    pub unsafe fn read_unlock(&self) {\n        self.lock.lock();\n        let notify = (*self.state.get()).dec_readers();\n        self.lock.unlock();\n        if notify {\n            // FIXME: should only wake up one of these some of the time\n            self.cond.notify_all();\n        }\n    }\n\n    #[inline]\n    pub unsafe fn write_unlock(&self) {\n        self.lock.lock();\n        (*self.state.get()).dec_writers();\n        self.lock.unlock();\n        // FIXME: should only wake up one of these some of the time\n        self.cond.notify_all();\n    }\n\n    #[inline]\n    pub unsafe fn destroy(&self) {\n        self.lock.destroy();\n        self.cond.destroy();\n    }\n}\n\nimpl State {\n    fn inc_readers(&mut self) -> bool {\n        match *self {\n            State::Unlocked => {\n                *self = State::Reading(1);\n                true\n            }\n            State::Reading(ref mut cnt) => {\n                *cnt += 1;\n                true\n            }\n            State::Writing => false,\n        }\n    }\n\n    fn inc_writers(&mut self) -> bool {\n        match *self {\n            State::Unlocked => {\n                *self = State::Writing;\n                true\n            }\n            State::Reading(_) | State::Writing => false,\n        }\n    }\n\n    fn dec_readers(&mut self) -> bool {\n        let zero = match *self {\n            State::Reading(ref mut cnt) => {\n                *cnt -= 1;\n                *cnt == 0\n            }\n            State::Unlocked | State::Writing => invalid(),\n        };\n        if zero {\n            *self = State::Unlocked;\n        }\n        zero\n    }\n\n    fn dec_writers(&mut self) {\n        match *self {\n            State::Writing => {}\n            State::Unlocked | State::Reading(_) => invalid(),\n        }\n        *self = State::Unlocked;\n    }\n}\n\nfn invalid() -> ! {\n    panic!(\"inconsistent rwlock\");\n}\n"],[2248,"use crate::arch::wasm32;\nuse crate::convert::TryInto;\nuse crate::sync::atomic::AtomicI32;\nuse crate::time::Duration;\n\npub fn futex_wait(futex: &AtomicI32, expected: i32, timeout: Option<Duration>) {\n    let timeout = timeout.and_then(|t| t.as_nanos().try_into().ok()).unwrap_or(-1);\n    unsafe {\n        wasm32::memory_atomic_wait32(futex as *const AtomicI32 as *mut i32, expected, timeout);\n    }\n}\n\npub fn futex_wake(futex: &AtomicI32) {\n    unsafe {\n        wasm32::memory_atomic_notify(futex as *const AtomicI32 as *mut i32, 1);\n    }\n}\n"],[2249,"use crate::arch::wasm32;\nuse crate::cmp;\nuse crate::mem;\nuse crate::sync::atomic::{AtomicUsize, Ordering::SeqCst};\nuse crate::sys::mutex::Mutex;\nuse crate::time::Duration;\n\npub struct Condvar {\n    cnt: AtomicUsize,\n}\n\npub type MovableCondvar = Condvar;\n\n// Condition variables are implemented with a simple counter internally that is\n// likely to cause spurious wakeups. Blocking on a condition variable will first\n// read the value of the internal counter, unlock the given mutex, and then\n// block if and only if the counter's value is still the same. Notifying a\n// condition variable will modify the counter (add one for now) and then wake up\n// a thread waiting on the address of the counter.\n//\n// A thread waiting on the condition variable will as a result avoid going to\n// sleep if it's notified after the lock is unlocked but before it fully goes to\n// sleep. A sleeping thread is guaranteed to be woken up at some point as it can\n// only be woken up with a call to `wake`.\n//\n// Note that it's possible for 2 or more threads to be woken up by a call to\n// `notify_one` with this implementation. That can happen where the modification\n// of `cnt` causes any threads in the middle of `wait` to avoid going to sleep,\n// and the subsequent `wake` may wake up a thread that's actually blocking. We\n// consider this a spurious wakeup, though, which all users of condition\n// variables must already be prepared to handle. As a result, this source of\n// spurious wakeups is currently though to be ok, although it may be problematic\n// later on if it causes too many spurious wakeups.\n\nimpl Condvar {\n    pub const fn new() -> Condvar {\n        Condvar { cnt: AtomicUsize::new(0) }\n    }\n\n    #[inline]\n    pub unsafe fn init(&mut self) {\n        // nothing to do\n    }\n\n    pub unsafe fn notify_one(&self) {\n        self.cnt.fetch_add(1, SeqCst);\n        // SAFETY: ptr() is always valid\n        unsafe {\n            wasm32::memory_atomic_notify(self.ptr(), 1);\n        }\n    }\n\n    #[inline]\n    pub unsafe fn notify_all(&self) {\n        self.cnt.fetch_add(1, SeqCst);\n        // SAFETY: ptr() is always valid\n        unsafe {\n            wasm32::memory_atomic_notify(self.ptr(), u32::MAX); // -1 == \"wake everyone\"\n        }\n    }\n\n    pub unsafe fn wait(&self, mutex: &Mutex) {\n        // \"atomically block and unlock\" implemented by loading our current\n        // counter's value, unlocking the mutex, and blocking if the counter\n        // still has the same value.\n        //\n        // Notifications happen by incrementing the counter and then waking a\n        // thread. Incrementing the counter after we unlock the mutex will\n        // prevent us from sleeping and otherwise the call to `wake` will\n        // wake us up once we're asleep.\n        let ticket = self.cnt.load(SeqCst) as i32;\n        mutex.unlock();\n        let val = wasm32::memory_atomic_wait32(self.ptr(), ticket, -1);\n        // 0 == woken, 1 == not equal to `ticket`, 2 == timeout (shouldn't happen)\n        debug_assert!(val == 0 || val == 1);\n        mutex.lock();\n    }\n\n    pub unsafe fn wait_timeout(&self, mutex: &Mutex, dur: Duration) -> bool {\n        let ticket = self.cnt.load(SeqCst) as i32;\n        mutex.unlock();\n        let nanos = dur.as_nanos();\n        let nanos = cmp::min(i64::MAX as u128, nanos);\n\n        // If the return value is 2 then a timeout happened, so we return\n        // `false` as we weren't actually notified.\n        let ret = wasm32::memory_atomic_wait32(self.ptr(), ticket, nanos as i64) != 2;\n        mutex.lock();\n        return ret;\n    }\n\n    #[inline]\n    pub unsafe fn destroy(&self) {\n        // nothing to do\n    }\n\n    #[inline]\n    fn ptr(&self) -> *mut i32 {\n        assert_eq!(mem::size_of::<usize>(), mem::size_of::<i32>());\n        self.cnt.as_mut_ptr() as *mut i32\n    }\n}\n"],[2250,"use super::*;\n\n// Verify that the byte pattern libunwind uses to initialize an RWLock is\n// equivalent to the value of RWLock::new(). If the value changes,\n// `src/UnwindRustSgx.h` in libunwind needs to be changed too.\n#[test]\nfn test_c_rwlock_initializer() {\n    #[rustfmt::skip]\n    const C_RWLOCK_INIT: &[u8] = &[\n        /* 0x00 */ 0x1, 0x0, 0x0, 0x0, 0x0, 0x0, 0x0, 0x0, 0x0, 0x0, 0x0, 0x0, 0x0, 0x0, 0x0, 0x0,\n        /* 0x10 */ 0x0, 0x0, 0x0, 0x0, 0x0, 0x0, 0x0, 0x0, 0x2, 0x0, 0x0, 0x0, 0x0, 0x0, 0x0, 0x0,\n        /* 0x20 */ 0x0, 0x0, 0x0, 0x0, 0x0, 0x0, 0x0, 0x0, 0x0, 0x0, 0x0, 0x0, 0x0, 0x0, 0x0, 0x0,\n        /* 0x30 */ 0x0, 0x0, 0x0, 0x0, 0x0, 0x0, 0x0, 0x0, 0x0, 0x0, 0x0, 0x0, 0x0, 0x0, 0x0, 0x0,\n        /* 0x40 */ 0x0, 0x0, 0x0, 0x0, 0x0, 0x0, 0x0, 0x0, 0x1, 0x0, 0x0, 0x0, 0x0, 0x0, 0x0, 0x0,\n        /* 0x50 */ 0x0, 0x0, 0x0, 0x0, 0x0, 0x0, 0x0, 0x0, 0x0, 0x0, 0x0, 0x0, 0x0, 0x0, 0x0, 0x0,\n        /* 0x60 */ 0x2, 0x0, 0x0, 0x0, 0x0, 0x0, 0x0, 0x0, 0x0, 0x0, 0x0, 0x0, 0x0, 0x0, 0x0, 0x0,\n        /* 0x70 */ 0x0, 0x0, 0x0, 0x0, 0x0, 0x0, 0x0, 0x0, 0x0, 0x0, 0x0, 0x0, 0x0, 0x0, 0x0, 0x0,\n        /* 0x80 */ 0x0, 0x0, 0x0, 0x0, 0x0, 0x0, 0x0, 0x0, 0x0, 0x0, 0x0, 0x0, 0x0, 0x0, 0x0, 0x0,\n    ];\n\n    // For the test to work, we need the padding/unused bytes in RWLock to be\n    // initialized as 0. In practice, this is the case with statics.\n    static RUST_RWLOCK_INIT: RWLock = RWLock::new();\n\n    unsafe {\n        // If the assertion fails, that not necessarily an issue with the value\n        // of C_RWLOCK_INIT. It might just be an issue with the way padding\n        // bytes are initialized in the test code.\n        assert_eq!(&crate::mem::transmute_copy::<_, [u8; 144]>(&RUST_RWLOCK_INIT), C_RWLOCK_INIT);\n    };\n}\n"],[2251,"#![cfg_attr(test, allow(dead_code))] // why is this necessary?\nuse super::unsupported;\nuse crate::ffi::CStr;\nuse crate::io;\nuse crate::num::NonZeroUsize;\nuse crate::time::Duration;\n\nuse super::abi::usercalls;\n\npub struct Thread(task_queue::JoinHandle);\n\npub const DEFAULT_MIN_STACK_SIZE: usize = 4096;\n\npub use self::task_queue::JoinNotifier;\n\nmod task_queue {\n    use super::wait_notify;\n    use crate::sync::{Mutex, MutexGuard, Once};\n\n    pub type JoinHandle = wait_notify::Waiter;\n\n    pub struct JoinNotifier(Option<wait_notify::Notifier>);\n\n    impl Drop for JoinNotifier {\n        fn drop(&mut self) {\n            self.0.take().unwrap().notify();\n        }\n    }\n\n    pub(super) struct Task {\n        p: Box<dyn FnOnce()>,\n        done: JoinNotifier,\n    }\n\n    impl Task {\n        pub(super) fn new(p: Box<dyn FnOnce()>) -> (Task, JoinHandle) {\n            let (done, recv) = wait_notify::new();\n            let done = JoinNotifier(Some(done));\n            (Task { p, done }, recv)\n        }\n\n        pub(super) fn run(self) -> JoinNotifier {\n            (self.p)();\n            self.done\n        }\n    }\n\n    #[cfg_attr(test, linkage = \"available_externally\")]\n    #[export_name = \"_ZN16__rust_internals3std3sys3sgx6thread15TASK_QUEUE_INITE\"]\n    static TASK_QUEUE_INIT: Once = Once::new();\n    #[cfg_attr(test, linkage = \"available_externally\")]\n    #[export_name = \"_ZN16__rust_internals3std3sys3sgx6thread10TASK_QUEUEE\"]\n    static mut TASK_QUEUE: Option<Mutex<Vec<Task>>> = None;\n\n    pub(super) fn lock() -> MutexGuard<'static, Vec<Task>> {\n        unsafe {\n            TASK_QUEUE_INIT.call_once(|| TASK_QUEUE = Some(Default::default()));\n            TASK_QUEUE.as_ref().unwrap().lock().unwrap()\n        }\n    }\n}\n\n/// This module provides a synchronization primitive that does not use thread\n/// local variables. This is needed for signaling that a thread has finished\n/// execution. The signal is sent once all TLS destructors have finished at\n/// which point no new thread locals should be created.\npub mod wait_notify {\n    use super::super::waitqueue::{SpinMutex, WaitQueue, WaitVariable};\n    use crate::sync::Arc;\n\n    pub struct Notifier(Arc<SpinMutex<WaitVariable<bool>>>);\n\n    impl Notifier {\n        /// Notify the waiter. The waiter is either notified right away (if\n        /// currently blocked in `Waiter::wait()`) or later when it calls the\n        /// `Waiter::wait()` method.\n        pub fn notify(self) {\n            let mut guard = self.0.lock();\n            *guard.lock_var_mut() = true;\n            let _ = WaitQueue::notify_one(guard);\n        }\n    }\n\n    pub struct Waiter(Arc<SpinMutex<WaitVariable<bool>>>);\n\n    impl Waiter {\n        /// Wait for a notification. If `Notifier::notify()` has already been\n        /// called, this will return immediately, otherwise the current thread\n        /// is blocked until notified.\n        pub fn wait(self) {\n            let guard = self.0.lock();\n            if *guard.lock_var() {\n                return;\n            }\n            WaitQueue::wait(guard, || {});\n        }\n    }\n\n    pub fn new() -> (Notifier, Waiter) {\n        let inner = Arc::new(SpinMutex::new(WaitVariable::new(false)));\n        (Notifier(inner.clone()), Waiter(inner))\n    }\n}\n\nimpl Thread {\n    // unsafe: see thread::Builder::spawn_unchecked for safety requirements\n    pub unsafe fn new(_stack: usize, p: Box<dyn FnOnce()>) -> io::Result<Thread> {\n        let mut queue_lock = task_queue::lock();\n        unsafe { usercalls::launch_thread()? };\n        let (task, handle) = task_queue::Task::new(p);\n        queue_lock.push(task);\n        Ok(Thread(handle))\n    }\n\n    pub(super) fn entry() -> JoinNotifier {\n        let mut pending_tasks = task_queue::lock();\n        let task = rtunwrap!(Some, pending_tasks.pop());\n        drop(pending_tasks); // make sure to not hold the task queue lock longer than necessary\n        task.run()\n    }\n\n    pub fn yield_now() {\n        let wait_error = rtunwrap!(Err, usercalls::wait(0, usercalls::raw::WAIT_NO));\n        rtassert!(wait_error.kind() == io::ErrorKind::WouldBlock);\n    }\n\n    pub fn set_name(_name: &CStr) {\n        // FIXME: could store this pointer in TLS somewhere\n    }\n\n    pub fn sleep(dur: Duration) {\n        usercalls::wait_timeout(0, dur, || true);\n    }\n\n    pub fn join(self) {\n        self.0.wait();\n    }\n}\n\npub fn available_concurrency() -> io::Result<NonZeroUsize> {\n    unsupported()\n}\n\npub mod guard {\n    pub type Guard = !;\n    pub unsafe fn current() -> Option<Guard> {\n        None\n    }\n    pub unsafe fn init() -> Option<Guard> {\n        None\n    }\n}\n"],[2252,"#[cfg(test)]\nmod tests;\n\nuse crate::num::NonZeroUsize;\n\nuse super::waitqueue::{\n    try_lock_or_false, NotifiedTcs, SpinMutex, SpinMutexGuard, WaitQueue, WaitVariable,\n};\nuse crate::mem;\n\npub struct RWLock {\n    readers: SpinMutex<WaitVariable<Option<NonZeroUsize>>>,\n    writer: SpinMutex<WaitVariable<bool>>,\n}\n\npub type MovableRWLock = Box<RWLock>;\n\n// Check at compile time that RWLock size matches C definition (see test_c_rwlock_initializer below)\n//\n// # Safety\n// Never called, as it is a compile time check.\n#[allow(dead_code)]\nunsafe fn rw_lock_size_assert(r: RWLock) {\n    unsafe { mem::transmute::<RWLock, [u8; 144]>(r) };\n}\n\nimpl RWLock {\n    pub const fn new() -> RWLock {\n        RWLock {\n            readers: SpinMutex::new(WaitVariable::new(None)),\n            writer: SpinMutex::new(WaitVariable::new(false)),\n        }\n    }\n\n    #[inline]\n    pub unsafe fn read(&self) {\n        let mut rguard = self.readers.lock();\n        let wguard = self.writer.lock();\n        if *wguard.lock_var() || !wguard.queue_empty() {\n            // Another thread has or is waiting for the write lock, wait\n            drop(wguard);\n            WaitQueue::wait(rguard, || {});\n        // Another thread has passed the lock to us\n        } else {\n            // No waiting writers, acquire the read lock\n            *rguard.lock_var_mut() =\n                NonZeroUsize::new(rguard.lock_var().map_or(0, |n| n.get()) + 1);\n        }\n    }\n\n    #[inline]\n    pub unsafe fn try_read(&self) -> bool {\n        let mut rguard = try_lock_or_false!(self.readers);\n        let wguard = try_lock_or_false!(self.writer);\n        if *wguard.lock_var() || !wguard.queue_empty() {\n            // Another thread has or is waiting for the write lock\n            false\n        } else {\n            // No waiting writers, acquire the read lock\n            *rguard.lock_var_mut() =\n                NonZeroUsize::new(rguard.lock_var().map_or(0, |n| n.get()) + 1);\n            true\n        }\n    }\n\n    #[inline]\n    pub unsafe fn write(&self) {\n        let rguard = self.readers.lock();\n        let mut wguard = self.writer.lock();\n        if *wguard.lock_var() || rguard.lock_var().is_some() {\n            // Another thread has the lock, wait\n            drop(rguard);\n            WaitQueue::wait(wguard, || {});\n        // Another thread has passed the lock to us\n        } else {\n            // We are just now obtaining the lock\n            *wguard.lock_var_mut() = true;\n        }\n    }\n\n    #[inline]\n    pub unsafe fn try_write(&self) -> bool {\n        let rguard = try_lock_or_false!(self.readers);\n        let mut wguard = try_lock_or_false!(self.writer);\n        if *wguard.lock_var() || rguard.lock_var().is_some() {\n            // Another thread has the lock\n            false\n        } else {\n            // We are just now obtaining the lock\n            *wguard.lock_var_mut() = true;\n            true\n        }\n    }\n\n    #[inline]\n    unsafe fn __read_unlock(\n        &self,\n        mut rguard: SpinMutexGuard<'_, WaitVariable<Option<NonZeroUsize>>>,\n        wguard: SpinMutexGuard<'_, WaitVariable<bool>>,\n    ) {\n        *rguard.lock_var_mut() = NonZeroUsize::new(rguard.lock_var().unwrap().get() - 1);\n        if rguard.lock_var().is_some() {\n            // There are other active readers\n        } else {\n            if let Ok(mut wguard) = WaitQueue::notify_one(wguard) {\n                // A writer was waiting, pass the lock\n                *wguard.lock_var_mut() = true;\n                wguard.drop_after(rguard);\n            } else {\n                // No writers were waiting, the lock is released\n                rtassert!(rguard.queue_empty());\n            }\n        }\n    }\n\n    #[inline]\n    pub unsafe fn read_unlock(&self) {\n        let rguard = self.readers.lock();\n        let wguard = self.writer.lock();\n        unsafe { self.__read_unlock(rguard, wguard) };\n    }\n\n    #[inline]\n    unsafe fn __write_unlock(\n        &self,\n        rguard: SpinMutexGuard<'_, WaitVariable<Option<NonZeroUsize>>>,\n        wguard: SpinMutexGuard<'_, WaitVariable<bool>>,\n    ) {\n        match WaitQueue::notify_one(wguard) {\n            Err(mut wguard) => {\n                // No writers waiting, release the write lock\n                *wguard.lock_var_mut() = false;\n                if let Ok(mut rguard) = WaitQueue::notify_all(rguard) {\n                    // One or more readers were waiting, pass the lock to them\n                    if let NotifiedTcs::All { count } = rguard.notified_tcs() {\n                        *rguard.lock_var_mut() = Some(count)\n                    } else {\n                        unreachable!() // called notify_all\n                    }\n                    rguard.drop_after(wguard);\n                } else {\n                    // No readers waiting, the lock is released\n                }\n            }\n            Ok(wguard) => {\n                // There was a thread waiting for write, just pass the lock\n                wguard.drop_after(rguard);\n            }\n        }\n    }\n\n    #[inline]\n    pub unsafe fn write_unlock(&self) {\n        let rguard = self.readers.lock();\n        let wguard = self.writer.lock();\n        unsafe { self.__write_unlock(rguard, wguard) };\n    }\n\n    // only used by __rust_rwlock_unlock below\n    #[inline]\n    #[cfg_attr(test, allow(dead_code))]\n    unsafe fn unlock(&self) {\n        let rguard = self.readers.lock();\n        let wguard = self.writer.lock();\n        if *wguard.lock_var() == true {\n            unsafe { self.__write_unlock(rguard, wguard) };\n        } else {\n            unsafe { self.__read_unlock(rguard, wguard) };\n        }\n    }\n\n    #[inline]\n    pub unsafe fn destroy(&self) {}\n}\n\n// The following functions are needed by libunwind. These symbols are named\n// in pre-link args for the target specification, so keep that in sync.\n#[cfg(not(test))]\nconst EINVAL: i32 = 22;\n\n#[cfg(not(test))]\n#[no_mangle]\npub unsafe extern \"C\" fn __rust_rwlock_rdlock(p: *mut RWLock) -> i32 {\n    if p.is_null() {\n        return EINVAL;\n    }\n    unsafe { (*p).read() };\n    return 0;\n}\n\n#[cfg(not(test))]\n#[no_mangle]\npub unsafe extern \"C\" fn __rust_rwlock_wrlock(p: *mut RWLock) -> i32 {\n    if p.is_null() {\n        return EINVAL;\n    }\n    unsafe { (*p).write() };\n    return 0;\n}\n#[cfg(not(test))]\n#[no_mangle]\npub unsafe extern \"C\" fn __rust_rwlock_unlock(p: *mut RWLock) -> i32 {\n    if p.is_null() {\n        return EINVAL;\n    }\n    unsafe { (*p).unlock() };\n    return 0;\n}\n"],[2253,"use super::abi::usercalls::{alloc, raw::ByteBuffer};\nuse crate::ffi::OsString;\nuse crate::fmt;\nuse crate::slice;\nuse crate::sync::atomic::{AtomicUsize, Ordering};\nuse crate::sys::os_str::Buf;\nuse crate::sys_common::FromInner;\n\n#[cfg_attr(test, linkage = \"available_externally\")]\n#[export_name = \"_ZN16__rust_internals3std3sys3sgx4args4ARGSE\"]\nstatic ARGS: AtomicUsize = AtomicUsize::new(0);\ntype ArgsStore = Vec<OsString>;\n\n#[cfg_attr(test, allow(dead_code))]\npub unsafe fn init(argc: isize, argv: *const *const u8) {\n    if argc != 0 {\n        let args = unsafe { alloc::User::<[ByteBuffer]>::from_raw_parts(argv as _, argc as _) };\n        let args = args\n            .iter()\n            .map(|a| OsString::from_inner(Buf { inner: a.copy_user_buffer() }))\n            .collect::<ArgsStore>();\n        ARGS.store(Box::into_raw(Box::new(args)) as _, Ordering::Relaxed);\n    }\n}\n\npub fn args() -> Args {\n    let args = unsafe { (ARGS.load(Ordering::Relaxed) as *const ArgsStore).as_ref() };\n    if let Some(args) = args { Args(args.iter()) } else { Args([].iter()) }\n}\n\npub struct Args(slice::Iter<'static, OsString>);\n\nimpl fmt::Debug for Args {\n    fn fmt(&self, f: &mut fmt::Formatter<'_>) -> fmt::Result {\n        self.0.as_slice().fmt(f)\n    }\n}\n\nimpl Iterator for Args {\n    type Item = OsString;\n    fn next(&mut self) -> Option<OsString> {\n        self.0.next().cloned()\n    }\n    fn size_hint(&self) -> (usize, Option<usize>) {\n        self.0.size_hint()\n    }\n}\n\nimpl ExactSizeIterator for Args {\n    fn len(&self) -> usize {\n        self.0.len()\n    }\n}\n\nimpl DoubleEndedIterator for Args {\n    fn next_back(&mut self) -> Option<OsString> {\n        self.0.next_back().cloned()\n    }\n}\n"],[2254,"use super::abi::usercalls;\nuse crate::time::Duration;\n\n#[derive(Copy, Clone, PartialEq, Eq, PartialOrd, Ord, Debug, Hash)]\npub struct Instant(Duration);\n\n#[derive(Copy, Clone, PartialEq, Eq, PartialOrd, Ord, Debug, Hash)]\npub struct SystemTime(Duration);\n\npub const UNIX_EPOCH: SystemTime = SystemTime(Duration::from_secs(0));\n\nimpl Instant {\n    pub fn now() -> Instant {\n        Instant(usercalls::insecure_time())\n    }\n\n    pub fn checked_sub_instant(&self, other: &Instant) -> Option<Duration> {\n        self.0.checked_sub(other.0)\n    }\n\n    pub fn checked_add_duration(&self, other: &Duration) -> Option<Instant> {\n        Some(Instant(self.0.checked_add(*other)?))\n    }\n\n    pub fn checked_sub_duration(&self, other: &Duration) -> Option<Instant> {\n        Some(Instant(self.0.checked_sub(*other)?))\n    }\n\n    pub fn actually_monotonic() -> bool {\n        false\n    }\n\n    pub const fn zero() -> Instant {\n        Instant(Duration::from_secs(0))\n    }\n}\n\nimpl SystemTime {\n    pub fn now() -> SystemTime {\n        SystemTime(usercalls::insecure_time())\n    }\n\n    pub fn sub_time(&self, other: &SystemTime) -> Result<Duration, Duration> {\n        self.0.checked_sub(other.0).ok_or_else(|| other.0 - self.0)\n    }\n\n    pub fn checked_add_duration(&self, other: &Duration) -> Option<SystemTime> {\n        Some(SystemTime(self.0.checked_add(*other)?))\n    }\n\n    pub fn checked_sub_duration(&self, other: &Duration) -> Option<SystemTime> {\n        Some(SystemTime(self.0.checked_sub(*other)?))\n    }\n}\n"],[2255,"//! System bindings for the Fortanix SGX platform\n//!\n//! This module contains the facade (aka platform-specific) implementations of\n//! OS level functionality for Fortanix SGX.\n#![deny(unsafe_op_in_unsafe_fn)]\n\nuse crate::io::ErrorKind;\nuse crate::os::raw::c_char;\nuse crate::sync::atomic::{AtomicBool, Ordering};\n\npub mod abi;\nmod waitqueue;\n\npub mod alloc;\npub mod args;\n#[path = \"../unix/cmath.rs\"]\npub mod cmath;\npub mod condvar;\npub mod env;\npub mod fd;\n#[path = \"../unsupported/fs.rs\"]\npub mod fs;\n#[path = \"../unsupported/io.rs\"]\npub mod io;\npub mod memchr;\npub mod mutex;\npub mod net;\npub mod os;\npub mod path;\n#[path = \"../unsupported/pipe.rs\"]\npub mod pipe;\n#[path = \"../unsupported/process.rs\"]\npub mod process;\npub mod rwlock;\npub mod stdio;\npub mod thread;\npub mod thread_local_key;\npub mod time;\n\npub use crate::sys_common::os_str_bytes as os_str;\n\n// SAFETY: must be called only once during runtime initialization.\n// NOTE: this is not guaranteed to run, for example when Rust code is called externally.\npub unsafe fn init(argc: isize, argv: *const *const u8) {\n    unsafe {\n        args::init(argc, argv);\n    }\n}\n\n// SAFETY: must be called only once during runtime cleanup.\n// NOTE: this is not guaranteed to run, for example when the program aborts.\npub unsafe fn cleanup() {}\n\n/// This function is used to implement functionality that simply doesn't exist.\n/// Programs relying on this functionality will need to deal with the error.\npub fn unsupported<T>() -> crate::io::Result<T> {\n    Err(unsupported_err())\n}\n\npub fn unsupported_err() -> crate::io::Error {\n    crate::io::Error::new_const(ErrorKind::Unsupported, &\"operation not supported on SGX yet\")\n}\n\n/// This function is used to implement various functions that doesn't exist,\n/// but the lack of which might not be reason for error. If no error is\n/// returned, the program might very well be able to function normally. This is\n/// what happens when `SGX_INEFFECTIVE_ERROR` is set to `true`. If it is\n/// `false`, the behavior is the same as `unsupported`.\npub fn sgx_ineffective<T>(v: T) -> crate::io::Result<T> {\n    static SGX_INEFFECTIVE_ERROR: AtomicBool = AtomicBool::new(false);\n    if SGX_INEFFECTIVE_ERROR.load(Ordering::Relaxed) {\n        Err(crate::io::Error::new_const(\n            ErrorKind::Other,\n            &\"operation can't be trusted to have any effect on SGX\",\n        ))\n    } else {\n        Ok(v)\n    }\n}\n\npub fn decode_error_kind(code: i32) -> ErrorKind {\n    use fortanix_sgx_abi::Error;\n\n    // FIXME: not sure how to make sure all variants of Error are covered\n    if code == Error::NotFound as _ {\n        ErrorKind::NotFound\n    } else if code == Error::PermissionDenied as _ {\n        ErrorKind::PermissionDenied\n    } else if code == Error::ConnectionRefused as _ {\n        ErrorKind::ConnectionRefused\n    } else if code == Error::ConnectionReset as _ {\n        ErrorKind::ConnectionReset\n    } else if code == Error::ConnectionAborted as _ {\n        ErrorKind::ConnectionAborted\n    } else if code == Error::NotConnected as _ {\n        ErrorKind::NotConnected\n    } else if code == Error::AddrInUse as _ {\n        ErrorKind::AddrInUse\n    } else if code == Error::AddrNotAvailable as _ {\n        ErrorKind::AddrNotAvailable\n    } else if code == Error::BrokenPipe as _ {\n        ErrorKind::BrokenPipe\n    } else if code == Error::AlreadyExists as _ {\n        ErrorKind::AlreadyExists\n    } else if code == Error::WouldBlock as _ {\n        ErrorKind::WouldBlock\n    } else if code == Error::InvalidInput as _ {\n        ErrorKind::InvalidInput\n    } else if code == Error::InvalidData as _ {\n        ErrorKind::InvalidData\n    } else if code == Error::TimedOut as _ {\n        ErrorKind::TimedOut\n    } else if code == Error::WriteZero as _ {\n        ErrorKind::WriteZero\n    } else if code == Error::Interrupted as _ {\n        ErrorKind::Interrupted\n    } else if code == Error::Other as _ {\n        ErrorKind::Other\n    } else if code == Error::UnexpectedEof as _ {\n        ErrorKind::UnexpectedEof\n    } else {\n        ErrorKind::Other\n    }\n}\n\npub unsafe fn strlen(mut s: *const c_char) -> usize {\n    let mut n = 0;\n    while unsafe { *s } != 0 {\n        n += 1;\n        s = unsafe { s.offset(1) };\n    }\n    return n;\n}\n\npub fn abort_internal() -> ! {\n    abi::usercalls::exit(true)\n}\n\n// This function is needed by the panic runtime. The symbol is named in\n// pre-link args for the target specification, so keep that in sync.\n#[cfg(not(test))]\n#[no_mangle]\n// NB. used by both libunwind and libpanic_abort\npub extern \"C\" fn __rust_abort() {\n    abort_internal();\n}\n\npub mod rand {\n    pub fn rdrand64() -> u64 {\n        unsafe {\n            let mut ret: u64 = 0;\n            for _ in 0..10 {\n                if crate::arch::x86_64::_rdrand64_step(&mut ret) == 1 {\n                    return ret;\n                }\n            }\n            rtabort!(\"Failed to obtain random data\");\n        }\n    }\n}\n\npub fn hashmap_random_keys() -> (u64, u64) {\n    (self::rand::rdrand64(), self::rand::rdrand64())\n}\n\npub use crate::sys_common::{AsInner, FromInner, IntoInner};\n\npub trait TryIntoInner<Inner>: Sized {\n    fn try_into_inner(self) -> Result<Inner, Self>;\n}\n"],[2256,"use crate::convert::TryFrom;\nuse crate::error;\nuse crate::fmt;\nuse crate::io::{self, IoSlice, IoSliceMut};\nuse crate::net::{Ipv4Addr, Ipv6Addr, Shutdown, SocketAddr, ToSocketAddrs};\nuse crate::sync::Arc;\nuse crate::sys::fd::FileDesc;\nuse crate::sys::{sgx_ineffective, unsupported, AsInner, FromInner, IntoInner, TryIntoInner};\nuse crate::time::Duration;\n\nuse super::abi::usercalls;\n\nconst DEFAULT_FAKE_TTL: u32 = 64;\n\n#[derive(Debug, Clone)]\npub struct Socket {\n    inner: Arc<FileDesc>,\n    local_addr: Option<String>,\n}\n\nimpl Socket {\n    fn new(fd: usercalls::raw::Fd, local_addr: String) -> Socket {\n        Socket { inner: Arc::new(FileDesc::new(fd)), local_addr: Some(local_addr) }\n    }\n}\n\nimpl AsInner<FileDesc> for Socket {\n    fn as_inner(&self) -> &FileDesc {\n        &self.inner\n    }\n}\n\nimpl TryIntoInner<FileDesc> for Socket {\n    fn try_into_inner(self) -> Result<FileDesc, Socket> {\n        let Socket { inner, local_addr } = self;\n        Arc::try_unwrap(inner).map_err(|inner| Socket { inner, local_addr })\n    }\n}\n\nimpl FromInner<(FileDesc, Option<String>)> for Socket {\n    fn from_inner((inner, local_addr): (FileDesc, Option<String>)) -> Socket {\n        Socket { inner: Arc::new(inner), local_addr }\n    }\n}\n\n#[derive(Clone)]\npub struct TcpStream {\n    inner: Socket,\n    peer_addr: Option<String>,\n}\n\nimpl fmt::Debug for TcpStream {\n    fn fmt(&self, f: &mut fmt::Formatter<'_>) -> fmt::Result {\n        let mut res = f.debug_struct(\"TcpStream\");\n\n        if let Some(ref addr) = self.inner.local_addr {\n            res.field(\"addr\", addr);\n        }\n\n        if let Some(ref peer) = self.peer_addr {\n            res.field(\"peer\", peer);\n        }\n\n        res.field(\"fd\", &self.inner.inner.as_inner()).finish()\n    }\n}\n\nfn io_err_to_addr(result: io::Result<&SocketAddr>) -> io::Result<String> {\n    match result {\n        Ok(saddr) => Ok(saddr.to_string()),\n        // need to downcast twice because io::Error::into_inner doesn't return the original\n        // value if the conversion fails\n        Err(e) => {\n            if e.get_ref().and_then(|e| e.downcast_ref::<NonIpSockAddr>()).is_some() {\n                Ok(e.into_inner().unwrap().downcast::<NonIpSockAddr>().unwrap().host)\n            } else {\n                Err(e)\n            }\n        }\n    }\n}\n\nfn addr_to_sockaddr(addr: &Option<String>) -> io::Result<SocketAddr> {\n    addr.as_ref()\n        .ok_or(io::ErrorKind::AddrNotAvailable)?\n        .to_socket_addrs()\n        // unwrap OK: if an iterator is returned, we're guaranteed to get exactly one entry\n        .map(|mut it| it.next().unwrap())\n}\n\nimpl TcpStream {\n    pub fn connect(addr: io::Result<&SocketAddr>) -> io::Result<TcpStream> {\n        let addr = io_err_to_addr(addr)?;\n        let (fd, local_addr, peer_addr) = usercalls::connect_stream(&addr)?;\n        Ok(TcpStream { inner: Socket::new(fd, local_addr), peer_addr: Some(peer_addr) })\n    }\n\n    pub fn connect_timeout(addr: &SocketAddr, dur: Duration) -> io::Result<TcpStream> {\n        if dur == Duration::default() {\n            return Err(io::Error::new_const(\n                io::ErrorKind::InvalidInput,\n                &\"cannot set a 0 duration timeout\",\n            ));\n        }\n        Self::connect(Ok(addr)) // FIXME: ignoring timeout\n    }\n\n    pub fn set_read_timeout(&self, dur: Option<Duration>) -> io::Result<()> {\n        match dur {\n            Some(dur) if dur == Duration::default() => {\n                return Err(io::Error::new_const(\n                    io::ErrorKind::InvalidInput,\n                    &\"cannot set a 0 duration timeout\",\n                ));\n            }\n            _ => sgx_ineffective(()),\n        }\n    }\n\n    pub fn set_write_timeout(&self, dur: Option<Duration>) -> io::Result<()> {\n        match dur {\n            Some(dur) if dur == Duration::default() => {\n                return Err(io::Error::new_const(\n                    io::ErrorKind::InvalidInput,\n                    &\"cannot set a 0 duration timeout\",\n                ));\n            }\n            _ => sgx_ineffective(()),\n        }\n    }\n\n    pub fn read_timeout(&self) -> io::Result<Option<Duration>> {\n        sgx_ineffective(None)\n    }\n\n    pub fn write_timeout(&self) -> io::Result<Option<Duration>> {\n        sgx_ineffective(None)\n    }\n\n    pub fn peek(&self, _: &mut [u8]) -> io::Result<usize> {\n        Ok(0)\n    }\n\n    pub fn read(&self, buf: &mut [u8]) -> io::Result<usize> {\n        self.inner.inner.read(buf)\n    }\n\n    pub fn read_vectored(&self, bufs: &mut [IoSliceMut<'_>]) -> io::Result<usize> {\n        self.inner.inner.read_vectored(bufs)\n    }\n\n    #[inline]\n    pub fn is_read_vectored(&self) -> bool {\n        self.inner.inner.is_read_vectored()\n    }\n\n    pub fn write(&self, buf: &[u8]) -> io::Result<usize> {\n        self.inner.inner.write(buf)\n    }\n\n    pub fn write_vectored(&self, bufs: &[IoSlice<'_>]) -> io::Result<usize> {\n        self.inner.inner.write_vectored(bufs)\n    }\n\n    #[inline]\n    pub fn is_write_vectored(&self) -> bool {\n        self.inner.inner.is_write_vectored()\n    }\n\n    pub fn peer_addr(&self) -> io::Result<SocketAddr> {\n        addr_to_sockaddr(&self.peer_addr)\n    }\n\n    pub fn socket_addr(&self) -> io::Result<SocketAddr> {\n        addr_to_sockaddr(&self.inner.local_addr)\n    }\n\n    pub fn shutdown(&self, _: Shutdown) -> io::Result<()> {\n        sgx_ineffective(())\n    }\n\n    pub fn duplicate(&self) -> io::Result<TcpStream> {\n        Ok(self.clone())\n    }\n\n    pub fn set_nodelay(&self, _: bool) -> io::Result<()> {\n        sgx_ineffective(())\n    }\n\n    pub fn nodelay(&self) -> io::Result<bool> {\n        sgx_ineffective(false)\n    }\n\n    pub fn set_ttl(&self, _: u32) -> io::Result<()> {\n        sgx_ineffective(())\n    }\n\n    pub fn ttl(&self) -> io::Result<u32> {\n        sgx_ineffective(DEFAULT_FAKE_TTL)\n    }\n\n    pub fn take_error(&self) -> io::Result<Option<io::Error>> {\n        Ok(None)\n    }\n\n    pub fn set_nonblocking(&self, _: bool) -> io::Result<()> {\n        sgx_ineffective(())\n    }\n}\n\nimpl AsInner<Socket> for TcpStream {\n    fn as_inner(&self) -> &Socket {\n        &self.inner\n    }\n}\n\n// `Inner` includes `peer_addr` so that a `TcpStream` maybe correctly\n// reconstructed if `Socket::try_into_inner` fails.\nimpl IntoInner<(Socket, Option<String>)> for TcpStream {\n    fn into_inner(self) -> (Socket, Option<String>) {\n        (self.inner, self.peer_addr)\n    }\n}\n\nimpl FromInner<(Socket, Option<String>)> for TcpStream {\n    fn from_inner((inner, peer_addr): (Socket, Option<String>)) -> TcpStream {\n        TcpStream { inner, peer_addr }\n    }\n}\n\n#[derive(Clone)]\npub struct TcpListener {\n    inner: Socket,\n}\n\nimpl fmt::Debug for TcpListener {\n    fn fmt(&self, f: &mut fmt::Formatter<'_>) -> fmt::Result {\n        let mut res = f.debug_struct(\"TcpListener\");\n\n        if let Some(ref addr) = self.inner.local_addr {\n            res.field(\"addr\", addr);\n        }\n\n        res.field(\"fd\", &self.inner.inner.as_inner()).finish()\n    }\n}\n\nimpl TcpListener {\n    pub fn bind(addr: io::Result<&SocketAddr>) -> io::Result<TcpListener> {\n        let addr = io_err_to_addr(addr)?;\n        let (fd, local_addr) = usercalls::bind_stream(&addr)?;\n        Ok(TcpListener { inner: Socket::new(fd, local_addr) })\n    }\n\n    pub fn socket_addr(&self) -> io::Result<SocketAddr> {\n        addr_to_sockaddr(&self.inner.local_addr)\n    }\n\n    pub fn accept(&self) -> io::Result<(TcpStream, SocketAddr)> {\n        let (fd, local_addr, peer_addr) = usercalls::accept_stream(self.inner.inner.raw())?;\n        let peer_addr = Some(peer_addr);\n        let ret_peer = addr_to_sockaddr(&peer_addr).unwrap_or_else(|_| ([0; 4], 0).into());\n        Ok((TcpStream { inner: Socket::new(fd, local_addr), peer_addr }, ret_peer))\n    }\n\n    pub fn duplicate(&self) -> io::Result<TcpListener> {\n        Ok(self.clone())\n    }\n\n    pub fn set_ttl(&self, _: u32) -> io::Result<()> {\n        sgx_ineffective(())\n    }\n\n    pub fn ttl(&self) -> io::Result<u32> {\n        sgx_ineffective(DEFAULT_FAKE_TTL)\n    }\n\n    pub fn set_only_v6(&self, _: bool) -> io::Result<()> {\n        sgx_ineffective(())\n    }\n\n    pub fn only_v6(&self) -> io::Result<bool> {\n        sgx_ineffective(false)\n    }\n\n    pub fn take_error(&self) -> io::Result<Option<io::Error>> {\n        Ok(None)\n    }\n\n    pub fn set_nonblocking(&self, _: bool) -> io::Result<()> {\n        sgx_ineffective(())\n    }\n}\n\nimpl AsInner<Socket> for TcpListener {\n    fn as_inner(&self) -> &Socket {\n        &self.inner\n    }\n}\n\nimpl IntoInner<Socket> for TcpListener {\n    fn into_inner(self) -> Socket {\n        self.inner\n    }\n}\n\nimpl FromInner<Socket> for TcpListener {\n    fn from_inner(inner: Socket) -> TcpListener {\n        TcpListener { inner }\n    }\n}\n\npub struct UdpSocket(!);\n\nimpl UdpSocket {\n    pub fn bind(_: io::Result<&SocketAddr>) -> io::Result<UdpSocket> {\n        unsupported()\n    }\n\n    pub fn peer_addr(&self) -> io::Result<SocketAddr> {\n        self.0\n    }\n\n    pub fn socket_addr(&self) -> io::Result<SocketAddr> {\n        self.0\n    }\n\n    pub fn recv_from(&self, _: &mut [u8]) -> io::Result<(usize, SocketAddr)> {\n        self.0\n    }\n\n    pub fn peek_from(&self, _: &mut [u8]) -> io::Result<(usize, SocketAddr)> {\n        self.0\n    }\n\n    pub fn send_to(&self, _: &[u8], _: &SocketAddr) -> io::Result<usize> {\n        self.0\n    }\n\n    pub fn duplicate(&self) -> io::Result<UdpSocket> {\n        self.0\n    }\n\n    pub fn set_read_timeout(&self, _: Option<Duration>) -> io::Result<()> {\n        self.0\n    }\n\n    pub fn set_write_timeout(&self, _: Option<Duration>) -> io::Result<()> {\n        self.0\n    }\n\n    pub fn read_timeout(&self) -> io::Result<Option<Duration>> {\n        self.0\n    }\n\n    pub fn write_timeout(&self) -> io::Result<Option<Duration>> {\n        self.0\n    }\n\n    pub fn set_broadcast(&self, _: bool) -> io::Result<()> {\n        self.0\n    }\n\n    pub fn broadcast(&self) -> io::Result<bool> {\n        self.0\n    }\n\n    pub fn set_multicast_loop_v4(&self, _: bool) -> io::Result<()> {\n        self.0\n    }\n\n    pub fn multicast_loop_v4(&self) -> io::Result<bool> {\n        self.0\n    }\n\n    pub fn set_multicast_ttl_v4(&self, _: u32) -> io::Result<()> {\n        self.0\n    }\n\n    pub fn multicast_ttl_v4(&self) -> io::Result<u32> {\n        self.0\n    }\n\n    pub fn set_multicast_loop_v6(&self, _: bool) -> io::Result<()> {\n        self.0\n    }\n\n    pub fn multicast_loop_v6(&self) -> io::Result<bool> {\n        self.0\n    }\n\n    pub fn join_multicast_v4(&self, _: &Ipv4Addr, _: &Ipv4Addr) -> io::Result<()> {\n        self.0\n    }\n\n    pub fn join_multicast_v6(&self, _: &Ipv6Addr, _: u32) -> io::Result<()> {\n        self.0\n    }\n\n    pub fn leave_multicast_v4(&self, _: &Ipv4Addr, _: &Ipv4Addr) -> io::Result<()> {\n        self.0\n    }\n\n    pub fn leave_multicast_v6(&self, _: &Ipv6Addr, _: u32) -> io::Result<()> {\n        self.0\n    }\n\n    pub fn set_ttl(&self, _: u32) -> io::Result<()> {\n        self.0\n    }\n\n    pub fn ttl(&self) -> io::Result<u32> {\n        self.0\n    }\n\n    pub fn take_error(&self) -> io::Result<Option<io::Error>> {\n        self.0\n    }\n\n    pub fn set_nonblocking(&self, _: bool) -> io::Result<()> {\n        self.0\n    }\n\n    pub fn recv(&self, _: &mut [u8]) -> io::Result<usize> {\n        self.0\n    }\n\n    pub fn peek(&self, _: &mut [u8]) -> io::Result<usize> {\n        self.0\n    }\n\n    pub fn send(&self, _: &[u8]) -> io::Result<usize> {\n        self.0\n    }\n\n    pub fn connect(&self, _: io::Result<&SocketAddr>) -> io::Result<()> {\n        self.0\n    }\n}\n\nimpl fmt::Debug for UdpSocket {\n    fn fmt(&self, _f: &mut fmt::Formatter<'_>) -> fmt::Result {\n        self.0\n    }\n}\n\n#[derive(Debug)]\npub struct NonIpSockAddr {\n    host: String,\n}\n\nimpl error::Error for NonIpSockAddr {\n    #[allow(deprecated)]\n    fn description(&self) -> &str {\n        \"Failed to convert address to SocketAddr\"\n    }\n}\n\nimpl fmt::Display for NonIpSockAddr {\n    fn fmt(&self, f: &mut fmt::Formatter<'_>) -> fmt::Result {\n        write!(f, \"Failed to convert address to SocketAddr: {}\", self.host)\n    }\n}\n\npub struct LookupHost(!);\n\nimpl LookupHost {\n    fn new(host: String) -> io::Result<LookupHost> {\n        Err(io::Error::new(io::ErrorKind::Other, NonIpSockAddr { host }))\n    }\n\n    pub fn port(&self) -> u16 {\n        self.0\n    }\n}\n\nimpl Iterator for LookupHost {\n    type Item = SocketAddr;\n    fn next(&mut self) -> Option<SocketAddr> {\n        self.0\n    }\n}\n\nimpl TryFrom<&str> for LookupHost {\n    type Error = io::Error;\n\n    fn try_from(v: &str) -> io::Result<LookupHost> {\n        LookupHost::new(v.to_owned())\n    }\n}\n\nimpl<'a> TryFrom<(&'a str, u16)> for LookupHost {\n    type Error = io::Error;\n\n    fn try_from((host, port): (&'a str, u16)) -> io::Result<LookupHost> {\n        LookupHost::new(format!(\"{}:{}\", host, port))\n    }\n}\n\n#[allow(bad_style)]\npub mod netc {\n    pub const AF_INET: u8 = 0;\n    pub const AF_INET6: u8 = 1;\n    pub type sa_family_t = u8;\n\n    #[derive(Copy, Clone)]\n    pub struct in_addr {\n        pub s_addr: u32,\n    }\n\n    #[derive(Copy, Clone)]\n    pub struct sockaddr_in {\n        pub sin_family: sa_family_t,\n        pub sin_port: u16,\n        pub sin_addr: in_addr,\n    }\n\n    #[derive(Copy, Clone)]\n    pub struct in6_addr {\n        pub s6_addr: [u8; 16],\n    }\n\n    #[derive(Copy, Clone)]\n    pub struct sockaddr_in6 {\n        pub sin6_family: sa_family_t,\n        pub sin6_port: u16,\n        pub sin6_addr: in6_addr,\n        pub sin6_flowinfo: u32,\n        pub sin6_scope_id: u32,\n    }\n\n    #[derive(Copy, Clone)]\n    pub struct sockaddr {}\n\n    pub type socklen_t = usize;\n}\n"],[2257,"pub mod os {\n    pub const FAMILY: &str = \"\";\n    pub const OS: &str = \"\";\n    pub const DLL_PREFIX: &str = \"\";\n    pub const DLL_SUFFIX: &str = \".sgxs\";\n    pub const DLL_EXTENSION: &str = \"sgxs\";\n    pub const EXE_SUFFIX: &str = \".sgxs\";\n    pub const EXE_EXTENSION: &str = \"sgxs\";\n}\n"],[2258,"use fortanix_sgx_abi::Tcs;\n\nuse super::abi::thread;\n\nuse super::waitqueue::{try_lock_or_false, NotifiedTcs, SpinMutex, WaitQueue, WaitVariable};\n\npub struct Mutex {\n    inner: SpinMutex<WaitVariable<bool>>,\n}\n\npub type MovableMutex = Mutex;\n\n// Implementation according to “Operating Systems: Three Easy Pieces”, chapter 28\nimpl Mutex {\n    pub const fn new() -> Mutex {\n        Mutex { inner: SpinMutex::new(WaitVariable::new(false)) }\n    }\n\n    #[inline]\n    pub unsafe fn init(&mut self) {}\n\n    #[inline]\n    pub unsafe fn lock(&self) {\n        let mut guard = self.inner.lock();\n        if *guard.lock_var() {\n            // Another thread has the lock, wait\n            WaitQueue::wait(guard, || {})\n        // Another thread has passed the lock to us\n        } else {\n            // We are just now obtaining the lock\n            *guard.lock_var_mut() = true;\n        }\n    }\n\n    #[inline]\n    pub unsafe fn unlock(&self) {\n        let guard = self.inner.lock();\n        if let Err(mut guard) = WaitQueue::notify_one(guard) {\n            // No other waiters, unlock\n            *guard.lock_var_mut() = false;\n        } else {\n            // There was a thread waiting, just pass the lock\n        }\n    }\n\n    #[inline]\n    pub unsafe fn try_lock(&self) -> bool {\n        let mut guard = try_lock_or_false!(self.inner);\n        if *guard.lock_var() {\n            // Another thread has the lock\n            false\n        } else {\n            // We are just now obtaining the lock\n            *guard.lock_var_mut() = true;\n            true\n        }\n    }\n\n    #[inline]\n    pub unsafe fn destroy(&self) {}\n}\n\nstruct ReentrantLock {\n    owner: Option<Tcs>,\n    count: usize,\n}\n\npub struct ReentrantMutex {\n    inner: SpinMutex<WaitVariable<ReentrantLock>>,\n}\n\nimpl ReentrantMutex {\n    pub const fn uninitialized() -> ReentrantMutex {\n        ReentrantMutex {\n            inner: SpinMutex::new(WaitVariable::new(ReentrantLock { owner: None, count: 0 })),\n        }\n    }\n\n    #[inline]\n    pub unsafe fn init(&self) {}\n\n    #[inline]\n    pub unsafe fn lock(&self) {\n        let mut guard = self.inner.lock();\n        match guard.lock_var().owner {\n            Some(tcs) if tcs != thread::current() => {\n                // Another thread has the lock, wait\n                WaitQueue::wait(guard, || {});\n                // Another thread has passed the lock to us\n            }\n            _ => {\n                // We are just now obtaining the lock\n                guard.lock_var_mut().owner = Some(thread::current());\n                guard.lock_var_mut().count += 1;\n            }\n        }\n    }\n\n    #[inline]\n    pub unsafe fn unlock(&self) {\n        let mut guard = self.inner.lock();\n        if guard.lock_var().count > 1 {\n            guard.lock_var_mut().count -= 1;\n        } else {\n            match WaitQueue::notify_one(guard) {\n                Err(mut guard) => {\n                    // No other waiters, unlock\n                    guard.lock_var_mut().count = 0;\n                    guard.lock_var_mut().owner = None;\n                }\n                Ok(mut guard) => {\n                    // There was a thread waiting, just pass the lock\n                    if let NotifiedTcs::Single(tcs) = guard.notified_tcs() {\n                        guard.lock_var_mut().owner = Some(tcs)\n                    } else {\n                        unreachable!() // called notify_one\n                    }\n                }\n            }\n        }\n    }\n\n    #[inline]\n    pub unsafe fn try_lock(&self) -> bool {\n        let mut guard = try_lock_or_false!(self.inner);\n        match guard.lock_var().owner {\n            Some(tcs) if tcs != thread::current() => {\n                // Another thread has the lock\n                false\n            }\n            _ => {\n                // We are just now obtaining the lock\n                guard.lock_var_mut().owner = Some(thread::current());\n                guard.lock_var_mut().count += 1;\n                true\n            }\n        }\n    }\n\n    #[inline]\n    pub unsafe fn destroy(&self) {}\n}\n"],[2259,"pub use core::slice::memchr::{memchr, memrchr};\n"],[2260,"use crate::sys::mutex::Mutex;\nuse crate::time::Duration;\n\nuse super::waitqueue::{SpinMutex, WaitQueue, WaitVariable};\n\npub struct Condvar {\n    inner: SpinMutex<WaitVariable<()>>,\n}\n\npub type MovableCondvar = Box<Condvar>;\n\nimpl Condvar {\n    pub const fn new() -> Condvar {\n        Condvar { inner: SpinMutex::new(WaitVariable::new(())) }\n    }\n\n    #[inline]\n    pub unsafe fn init(&mut self) {}\n\n    #[inline]\n    pub unsafe fn notify_one(&self) {\n        let _ = WaitQueue::notify_one(self.inner.lock());\n    }\n\n    #[inline]\n    pub unsafe fn notify_all(&self) {\n        let _ = WaitQueue::notify_all(self.inner.lock());\n    }\n\n    pub unsafe fn wait(&self, mutex: &Mutex) {\n        let guard = self.inner.lock();\n        WaitQueue::wait(guard, || unsafe { mutex.unlock() });\n        unsafe { mutex.lock() }\n    }\n\n    pub unsafe fn wait_timeout(&self, mutex: &Mutex, dur: Duration) -> bool {\n        let success = WaitQueue::wait_timeout(&self.inner, dur, || unsafe { mutex.unlock() });\n        unsafe { mutex.lock() };\n        success\n    }\n\n    #[inline]\n    pub unsafe fn destroy(&self) {}\n}\n"],[2261,"use crate::alloc::{GlobalAlloc, Layout, System};\nuse crate::ptr;\nuse crate::sys::sgx::abi::mem as sgx_mem;\nuse core::sync::atomic::{AtomicBool, Ordering};\n\nuse super::waitqueue::SpinMutex;\n\n// Using a SpinMutex because we never want to exit the enclave waiting for the\n// allocator.\n//\n// The current allocator here is the `dlmalloc` crate which we've got included\n// in the rust-lang/rust repository as a submodule. The crate is a port of\n// dlmalloc.c from C to Rust.\n#[cfg_attr(test, linkage = \"available_externally\")]\n#[export_name = \"_ZN16__rust_internals3std3sys3sgx5alloc8DLMALLOCE\"]\nstatic DLMALLOC: SpinMutex<dlmalloc::Dlmalloc<Sgx>> =\n    SpinMutex::new(dlmalloc::Dlmalloc::new_with_allocator(Sgx {}));\n\nstruct Sgx;\n\nunsafe impl dlmalloc::Allocator for Sgx {\n    /// Allocs system resources\n    fn alloc(&self, _size: usize) -> (*mut u8, usize, u32) {\n        static INIT: AtomicBool = AtomicBool::new(false);\n\n        // No ordering requirement since this function is protected by the global lock.\n        if !INIT.swap(true, Ordering::Relaxed) {\n            (sgx_mem::heap_base() as _, sgx_mem::heap_size(), 0)\n        } else {\n            (ptr::null_mut(), 0, 0)\n        }\n    }\n\n    fn remap(&self, _ptr: *mut u8, _oldsize: usize, _newsize: usize, _can_move: bool) -> *mut u8 {\n        ptr::null_mut()\n    }\n\n    fn free_part(&self, _ptr: *mut u8, _oldsize: usize, _newsize: usize) -> bool {\n        false\n    }\n\n    fn free(&self, _ptr: *mut u8, _size: usize) -> bool {\n        return false;\n    }\n\n    fn can_release_part(&self, _flags: u32) -> bool {\n        false\n    }\n\n    fn allocates_zeros(&self) -> bool {\n        false\n    }\n\n    fn page_size(&self) -> usize {\n        0x1000\n    }\n}\n\n#[stable(feature = \"alloc_system_type\", since = \"1.28.0\")]\nunsafe impl GlobalAlloc for System {\n    #[inline]\n    unsafe fn alloc(&self, layout: Layout) -> *mut u8 {\n        // SAFETY: the caller must uphold the safety contract for `malloc`\n        unsafe { DLMALLOC.lock().malloc(layout.size(), layout.align()) }\n    }\n\n    #[inline]\n    unsafe fn alloc_zeroed(&self, layout: Layout) -> *mut u8 {\n        // SAFETY: the caller must uphold the safety contract for `malloc`\n        unsafe { DLMALLOC.lock().calloc(layout.size(), layout.align()) }\n    }\n\n    #[inline]\n    unsafe fn dealloc(&self, ptr: *mut u8, layout: Layout) {\n        // SAFETY: the caller must uphold the safety contract for `malloc`\n        unsafe { DLMALLOC.lock().free(ptr, layout.size(), layout.align()) }\n    }\n\n    #[inline]\n    unsafe fn realloc(&self, ptr: *mut u8, layout: Layout, new_size: usize) -> *mut u8 {\n        // SAFETY: the caller must uphold the safety contract for `malloc`\n        unsafe { DLMALLOC.lock().realloc(ptr, layout.size(), layout.align(), new_size) }\n    }\n}\n\n// The following functions are needed by libunwind. These symbols are named\n// in pre-link args for the target specification, so keep that in sync.\n#[cfg(not(test))]\n#[no_mangle]\npub unsafe extern \"C\" fn __rust_c_alloc(size: usize, align: usize) -> *mut u8 {\n    unsafe { crate::alloc::alloc(Layout::from_size_align_unchecked(size, align)) }\n}\n\n#[cfg(not(test))]\n#[no_mangle]\npub unsafe extern \"C\" fn __rust_c_dealloc(ptr: *mut u8, size: usize, align: usize) {\n    unsafe { crate::alloc::dealloc(ptr, Layout::from_size_align_unchecked(size, align)) }\n}\n"],[2262,"// Do not remove inline: will result in relocation failure\n#[inline(always)]\npub(crate) unsafe fn rel_ptr<T>(offset: u64) -> *const T {\n    (image_base() + offset) as *const T\n}\n\n// Do not remove inline: will result in relocation failure\n#[inline(always)]\npub(crate) unsafe fn rel_ptr_mut<T>(offset: u64) -> *mut T {\n    (image_base() + offset) as *mut T\n}\n\nextern \"C\" {\n    static ENCLAVE_SIZE: usize;\n    static HEAP_BASE: u64;\n    static HEAP_SIZE: usize;\n}\n\n/// Returns the base memory address of the heap\npub(crate) fn heap_base() -> *const u8 {\n    unsafe { rel_ptr_mut(HEAP_BASE) }\n}\n\n/// Returns the size of the heap\npub(crate) fn heap_size() -> usize {\n    unsafe { HEAP_SIZE }\n}\n\n// Do not remove inline: will result in relocation failure\n// For the same reason we use inline ASM here instead of an extern static to\n// locate the base\n/// Returns address at which current enclave is loaded.\n#[inline(always)]\n#[unstable(feature = \"sgx_platform\", issue = \"56975\")]\npub fn image_base() -> u64 {\n    let base: u64;\n    unsafe {\n        asm!(\n            \"lea IMAGE_BASE(%rip), {}\",\n            lateout(reg) base,\n            options(att_syntax, nostack, preserves_flags, nomem, pure),\n        )\n    };\n    base\n}\n\n/// Returns `true` if the specified memory range is in the enclave.\n///\n/// For safety, this function also checks whether the range given overflows,\n/// returning `false` if so.\n#[unstable(feature = \"sgx_platform\", issue = \"56975\")]\npub fn is_enclave_range(p: *const u8, len: usize) -> bool {\n    let start = p as usize;\n\n    // Subtract one from `len` when calculating `end` in case `p + len` is\n    // exactly at the end of addressable memory (`p + len` would overflow, but\n    // the range is still valid).\n    let end = if len == 0 {\n        start\n    } else if let Some(end) = start.checked_add(len - 1) {\n        end\n    } else {\n        return false;\n    };\n\n    let base = image_base() as usize;\n    start >= base && end <= base + (unsafe { ENCLAVE_SIZE } - 1) // unsafe ok: link-time constant\n}\n\n/// Returns `true` if the specified memory range is in userspace.\n///\n/// For safety, this function also checks whether the range given overflows,\n/// returning `false` if so.\n#[unstable(feature = \"sgx_platform\", issue = \"56975\")]\npub fn is_user_range(p: *const u8, len: usize) -> bool {\n    let start = p as usize;\n\n    // Subtract one from `len` when calculating `end` in case `p + len` is\n    // exactly at the end of addressable memory (`p + len` would overflow, but\n    // the range is still valid).\n    let end = if len == 0 {\n        start\n    } else if let Some(end) = start.checked_add(len - 1) {\n        end\n    } else {\n        return false;\n    };\n\n    let base = image_base() as usize;\n    end < base || start > base + (unsafe { ENCLAVE_SIZE } - 1) // unsafe ok: link-time constant\n}\n"],[2263,"#![cfg_attr(test, allow(unused))] // RT initialization logic is not compiled for test\n\nuse crate::io::Write;\nuse core::sync::atomic::{AtomicUsize, Ordering};\n\n// runtime features\npub(super) mod panic;\nmod reloc;\n\n// library features\npub mod mem;\npub mod thread;\npub mod tls;\n#[macro_use]\npub mod usercalls;\n\n#[cfg(not(test))]\nglobal_asm!(include_str!(\"entry.S\"), options(att_syntax));\n\n#[repr(C)]\nstruct EntryReturn(u64, u64);\n\n#[cfg(not(test))]\n#[no_mangle]\nunsafe extern \"C\" fn tcs_init(secondary: bool) {\n    // Be very careful when changing this code: it runs before the binary has been\n    // relocated. Any indirect accesses to symbols will likely fail.\n    const UNINIT: usize = 0;\n    const BUSY: usize = 1;\n    const DONE: usize = 2;\n    // Three-state spin-lock\n    static RELOC_STATE: AtomicUsize = AtomicUsize::new(UNINIT);\n\n    if secondary && RELOC_STATE.load(Ordering::Relaxed) != DONE {\n        rtabort!(\"Entered secondary TCS before main TCS!\")\n    }\n\n    // Try to atomically swap UNINIT with BUSY. The returned state can be:\n    match RELOC_STATE.compare_exchange(UNINIT, BUSY, Ordering::Acquire, Ordering::Acquire) {\n        // This thread just obtained the lock and other threads will observe BUSY\n        Ok(_) => {\n            reloc::relocate_elf_rela();\n            RELOC_STATE.store(DONE, Ordering::Release);\n        }\n        // We need to wait until the initialization is done.\n        Err(BUSY) => {\n            while RELOC_STATE.load(Ordering::Acquire) == BUSY {\n                core::hint::spin_loop();\n            }\n        }\n        // Initialization is done.\n        Err(DONE) => {}\n        _ => unreachable!(),\n    }\n}\n\n// FIXME: this item should only exist if this is linked into an executable\n// (main function exists). If this is a library, the crate author should be\n// able to specify this\n#[cfg(not(test))]\n#[no_mangle]\nextern \"C\" fn entry(p1: u64, p2: u64, p3: u64, secondary: bool, p4: u64, p5: u64) -> EntryReturn {\n    // FIXME: how to support TLS in library mode?\n    let tls = Box::new(tls::Tls::new());\n    let tls_guard = unsafe { tls.activate() };\n\n    if secondary {\n        let join_notifier = super::thread::Thread::entry();\n        drop(tls_guard);\n        drop(join_notifier);\n\n        EntryReturn(0, 0)\n    } else {\n        extern \"C\" {\n            fn main(argc: isize, argv: *const *const u8) -> isize;\n        }\n\n        // check entry is being called according to ABI\n        rtassert!(p3 == 0);\n        rtassert!(p4 == 0);\n        rtassert!(p5 == 0);\n\n        unsafe {\n            // The actual types of these arguments are `p1: *const Arg, p2:\n            // usize`. We can't currently customize the argument list of Rust's\n            // main function, so we pass these in as the standard pointer-sized\n            // values in `argc` and `argv`.\n            let ret = main(p2 as _, p1 as _);\n            exit_with_code(ret)\n        }\n    }\n}\n\npub(super) fn exit_with_code(code: isize) -> ! {\n    if code != 0 {\n        if let Some(mut out) = panic::SgxPanicOutput::new() {\n            let _ = write!(out, \"Exited with status code {}\", code);\n        }\n    }\n    usercalls::exit(code != 0);\n}\n\n#[cfg(not(test))]\n#[no_mangle]\nextern \"C\" fn abort_reentry() -> ! {\n    usercalls::exit(false)\n}\n"],[2264,"mod sync_bitset;\n\nuse self::sync_bitset::*;\nuse crate::cell::Cell;\nuse crate::mem;\nuse crate::num::NonZeroUsize;\nuse crate::ptr;\nuse crate::sync::atomic::{AtomicUsize, Ordering};\n\n#[cfg(target_pointer_width = \"64\")]\nconst USIZE_BITS: usize = 64;\nconst TLS_KEYS: usize = 128; // Same as POSIX minimum\nconst TLS_KEYS_BITSET_SIZE: usize = (TLS_KEYS + (USIZE_BITS - 1)) / USIZE_BITS;\n\n#[cfg_attr(test, linkage = \"available_externally\")]\n#[export_name = \"_ZN16__rust_internals3std3sys3sgx3abi3tls14TLS_KEY_IN_USEE\"]\nstatic TLS_KEY_IN_USE: SyncBitset = SYNC_BITSET_INIT;\nmacro_rules! dup {\n    ((* $($exp:tt)*) $($val:tt)*) => (dup!( ($($exp)*) $($val)* $($val)* ));\n    (() $($val:tt)*) => ([$($val),*])\n}\n#[cfg_attr(test, linkage = \"available_externally\")]\n#[export_name = \"_ZN16__rust_internals3std3sys3sgx3abi3tls14TLS_DESTRUCTORE\"]\nstatic TLS_DESTRUCTOR: [AtomicUsize; TLS_KEYS] = dup!((* * * * * * *) (AtomicUsize::new(0)));\n\nextern \"C\" {\n    fn get_tls_ptr() -> *const u8;\n    fn set_tls_ptr(tls: *const u8);\n}\n\n#[derive(Copy, Clone)]\n#[repr(C)]\npub struct Key(NonZeroUsize);\n\nimpl Key {\n    fn to_index(self) -> usize {\n        self.0.get() - 1\n    }\n\n    fn from_index(index: usize) -> Self {\n        Key(NonZeroUsize::new(index + 1).unwrap())\n    }\n\n    pub fn as_usize(self) -> usize {\n        self.0.get()\n    }\n\n    pub fn from_usize(index: usize) -> Self {\n        Key(NonZeroUsize::new(index).unwrap())\n    }\n}\n\n#[repr(C)]\npub struct Tls {\n    data: [Cell<*mut u8>; TLS_KEYS],\n}\n\npub struct ActiveTls<'a> {\n    tls: &'a Tls,\n}\n\nimpl<'a> Drop for ActiveTls<'a> {\n    fn drop(&mut self) {\n        let value_with_destructor = |key: usize| {\n            let ptr = TLS_DESTRUCTOR[key].load(Ordering::Relaxed);\n            unsafe { mem::transmute::<_, Option<unsafe extern \"C\" fn(*mut u8)>>(ptr) }\n                .map(|dtor| (&self.tls.data[key], dtor))\n        };\n\n        let mut any_non_null_dtor = true;\n        while any_non_null_dtor {\n            any_non_null_dtor = false;\n            for (value, dtor) in TLS_KEY_IN_USE.iter().filter_map(&value_with_destructor) {\n                let value = value.replace(ptr::null_mut());\n                if !value.is_null() {\n                    any_non_null_dtor = true;\n                    unsafe { dtor(value) }\n                }\n            }\n        }\n    }\n}\n\nimpl Tls {\n    pub fn new() -> Tls {\n        Tls { data: dup!((* * * * * * *) (Cell::new(ptr::null_mut()))) }\n    }\n\n    pub unsafe fn activate(&self) -> ActiveTls<'_> {\n        // FIXME: Needs safety information. See entry.S for `set_tls_ptr` definition.\n        unsafe { set_tls_ptr(self as *const Tls as _) };\n        ActiveTls { tls: self }\n    }\n\n    #[allow(unused)]\n    pub unsafe fn activate_persistent(self: Box<Self>) {\n        // FIXME: Needs safety information. See entry.S for `set_tls_ptr` definition.\n        unsafe { set_tls_ptr((&*self) as *const Tls as _) };\n        mem::forget(self);\n    }\n\n    unsafe fn current<'a>() -> &'a Tls {\n        // FIXME: Needs safety information. See entry.S for `set_tls_ptr` definition.\n        unsafe { &*(get_tls_ptr() as *const Tls) }\n    }\n\n    pub fn create(dtor: Option<unsafe extern \"C\" fn(*mut u8)>) -> Key {\n        let index = if let Some(index) = TLS_KEY_IN_USE.set() {\n            index\n        } else {\n            rtabort!(\"TLS limit exceeded\")\n        };\n        TLS_DESTRUCTOR[index].store(dtor.map_or(0, |f| f as usize), Ordering::Relaxed);\n        Key::from_index(index)\n    }\n\n    pub fn set(key: Key, value: *mut u8) {\n        let index = key.to_index();\n        rtassert!(TLS_KEY_IN_USE.get(index));\n        unsafe { Self::current() }.data[index].set(value);\n    }\n\n    pub fn get(key: Key) -> *mut u8 {\n        let index = key.to_index();\n        rtassert!(TLS_KEY_IN_USE.get(index));\n        unsafe { Self::current() }.data[index].get()\n    }\n\n    pub fn destroy(key: Key) {\n        TLS_KEY_IN_USE.clear(key.to_index());\n    }\n}\n"],[2265,"use super::*;\n\nfn test_data(bitset: [usize; 2], bit_indices: &[usize]) {\n    let set = SyncBitset([AtomicUsize::new(bitset[0]), AtomicUsize::new(bitset[1])]);\n    assert_eq!(set.iter().collect::<Vec<_>>(), bit_indices);\n    for &i in bit_indices {\n        assert!(set.get(i));\n    }\n}\n\n#[test]\nfn iter() {\n    test_data([0b0110_1001, 0], &[0, 3, 5, 6]);\n    test_data([0x8000_0000_0000_0000, 0x8000_0000_0000_0001], &[63, 64, 127]);\n    test_data([0, 0], &[]);\n}\n\n#[test]\nfn set_get_clear() {\n    let set = SYNC_BITSET_INIT;\n    let key = set.set().unwrap();\n    assert!(set.get(key));\n    set.clear(key);\n    assert!(!set.get(key));\n}\n"],[2266,"#[cfg(test)]\nmod tests;\n\nuse super::{TLS_KEYS_BITSET_SIZE, USIZE_BITS};\nuse crate::iter::{Enumerate, Peekable};\nuse crate::slice::Iter;\nuse crate::sync::atomic::{AtomicUsize, Ordering};\n\n/// A bitset that can be used synchronously.\npub(super) struct SyncBitset([AtomicUsize; TLS_KEYS_BITSET_SIZE]);\n\npub(super) const SYNC_BITSET_INIT: SyncBitset =\n    SyncBitset([AtomicUsize::new(0), AtomicUsize::new(0)]);\n\nimpl SyncBitset {\n    pub fn get(&self, index: usize) -> bool {\n        let (hi, lo) = Self::split(index);\n        (self.0[hi].load(Ordering::Relaxed) & lo) != 0\n    }\n\n    /// Not atomic.\n    pub fn iter(&self) -> SyncBitsetIter<'_> {\n        SyncBitsetIter { iter: self.0.iter().enumerate().peekable(), elem_idx: 0 }\n    }\n\n    pub fn clear(&self, index: usize) {\n        let (hi, lo) = Self::split(index);\n        self.0[hi].fetch_and(!lo, Ordering::Relaxed);\n    }\n\n    /// Sets any unset bit. Not atomic. Returns `None` if all bits were\n    /// observed to be set.\n    pub fn set(&self) -> Option<usize> {\n        'elems: for (idx, elem) in self.0.iter().enumerate() {\n            let mut current = elem.load(Ordering::Relaxed);\n            loop {\n                if 0 == !current {\n                    continue 'elems;\n                }\n                let trailing_ones = (!current).trailing_zeros() as usize;\n                match elem.compare_exchange(\n                    current,\n                    current | (1 << trailing_ones),\n                    Ordering::AcqRel,\n                    Ordering::Relaxed,\n                ) {\n                    Ok(_) => return Some(idx * USIZE_BITS + trailing_ones),\n                    Err(previous) => current = previous,\n                }\n            }\n        }\n        None\n    }\n\n    fn split(index: usize) -> (usize, usize) {\n        (index / USIZE_BITS, 1 << (index % USIZE_BITS))\n    }\n}\n\npub(super) struct SyncBitsetIter<'a> {\n    iter: Peekable<Enumerate<Iter<'a, AtomicUsize>>>,\n    elem_idx: usize,\n}\n\nimpl<'a> Iterator for SyncBitsetIter<'a> {\n    type Item = usize;\n\n    fn next(&mut self) -> Option<usize> {\n        self.iter.peek().cloned().and_then(|(idx, elem)| {\n            let elem = elem.load(Ordering::Relaxed);\n            let low_mask = (1 << self.elem_idx) - 1;\n            let next = elem & !low_mask;\n            let next_idx = next.trailing_zeros() as usize;\n            self.elem_idx = next_idx + 1;\n            if self.elem_idx >= 64 {\n                self.elem_idx = 0;\n                self.iter.next();\n            }\n            match next_idx {\n                64 => self.next(),\n                _ => Some(idx * USIZE_BITS + next_idx),\n            }\n        })\n    }\n}\n"],[2267,"#![allow(unused)]\n\n#[unstable(feature = \"sgx_platform\", issue = \"56975\")]\npub use fortanix_sgx_abi::*;\n\nuse crate::num::NonZeroU64;\nuse crate::ptr::NonNull;\n\n#[repr(C)]\nstruct UsercallReturn(u64, u64);\n\nextern \"C\" {\n    fn usercall(nr: NonZeroU64, p1: u64, p2: u64, abort: u64, p3: u64, p4: u64) -> UsercallReturn;\n}\n\n/// Performs the raw usercall operation as defined in the ABI calling convention.\n///\n/// # Safety\n///\n/// The caller must ensure to pass parameters appropriate for the usercall `nr`\n/// and to observe all requirements specified in the ABI.\n///\n/// # Panics\n///\n/// Panics if `nr` is `0`.\n#[unstable(feature = \"sgx_platform\", issue = \"56975\")]\n#[inline]\npub unsafe fn do_usercall(\n    nr: NonZeroU64,\n    p1: u64,\n    p2: u64,\n    p3: u64,\n    p4: u64,\n    abort: bool,\n) -> (u64, u64) {\n    let UsercallReturn(a, b) = unsafe { usercall(nr, p1, p2, abort as _, p3, p4) };\n    (a, b)\n}\n\ntype Register = u64;\n\ntrait RegisterArgument {\n    fn from_register(_: Register) -> Self;\n    fn into_register(self) -> Register;\n}\n\ntrait ReturnValue {\n    fn from_registers(call: &'static str, regs: (Register, Register)) -> Self;\n}\n\nmacro_rules! define_usercalls {\n    ($(fn $f:ident($($n:ident: $t:ty),*) $(-> $r:tt)*; )*) => {\n        /// Usercall numbers as per the ABI.\n        #[repr(u64)]\n        #[unstable(feature = \"sgx_platform\", issue = \"56975\")]\n        #[derive(Copy, Clone, Hash, PartialEq, Eq, Debug)]\n        #[allow(missing_docs, non_camel_case_types)]\n        #[non_exhaustive]\n        pub enum Usercalls {\n            #[doc(hidden)]\n            __enclave_usercalls_invalid = 0,\n            $($f,)*\n        }\n\n        $(enclave_usercalls_internal_define_usercalls!(def fn $f($($n: $t),*) $(-> $r)*);)*\n    };\n}\n\nmacro_rules! define_ra {\n    (< $i:ident > $t:ty) => {\n        impl<$i> RegisterArgument for $t {\n            fn from_register(a: Register) -> Self {\n                a as _\n            }\n            fn into_register(self) -> Register {\n                self as _\n            }\n        }\n    };\n    ($i:ty as $t:ty) => {\n        impl RegisterArgument for $t {\n            fn from_register(a: Register) -> Self {\n                a as $i as _\n            }\n            fn into_register(self) -> Register {\n                self as $i as _\n            }\n        }\n    };\n    ($t:ty) => {\n        impl RegisterArgument for $t {\n            fn from_register(a: Register) -> Self {\n                a as _\n            }\n            fn into_register(self) -> Register {\n                self as _\n            }\n        }\n    };\n}\n\ndefine_ra!(Register);\ndefine_ra!(i64);\ndefine_ra!(u32);\ndefine_ra!(u32 as i32);\ndefine_ra!(u16);\ndefine_ra!(u16 as i16);\ndefine_ra!(u8);\ndefine_ra!(u8 as i8);\ndefine_ra!(usize);\ndefine_ra!(usize as isize);\ndefine_ra!(<T> *const T);\ndefine_ra!(<T> *mut T);\n\nimpl RegisterArgument for bool {\n    fn from_register(a: Register) -> bool {\n        if a != 0 { true } else { false }\n    }\n    fn into_register(self) -> Register {\n        self as _\n    }\n}\n\nimpl<T: RegisterArgument> RegisterArgument for Option<NonNull<T>> {\n    fn from_register(a: Register) -> Option<NonNull<T>> {\n        NonNull::new(a as _)\n    }\n    fn into_register(self) -> Register {\n        self.map_or(0 as _, NonNull::as_ptr) as _\n    }\n}\n\nimpl ReturnValue for ! {\n    fn from_registers(call: &'static str, _regs: (Register, Register)) -> Self {\n        rtabort!(\"Usercall {}: did not expect to be re-entered\", call);\n    }\n}\n\nimpl ReturnValue for () {\n    fn from_registers(call: &'static str, usercall_retval: (Register, Register)) -> Self {\n        rtassert!(usercall_retval.0 == 0);\n        rtassert!(usercall_retval.1 == 0);\n        ()\n    }\n}\n\nimpl<T: RegisterArgument> ReturnValue for T {\n    fn from_registers(call: &'static str, usercall_retval: (Register, Register)) -> Self {\n        rtassert!(usercall_retval.1 == 0);\n        T::from_register(usercall_retval.0)\n    }\n}\n\nimpl<T: RegisterArgument, U: RegisterArgument> ReturnValue for (T, U) {\n    fn from_registers(_call: &'static str, regs: (Register, Register)) -> Self {\n        (T::from_register(regs.0), U::from_register(regs.1))\n    }\n}\n\nmacro_rules! return_type_is_abort {\n    (!) => {\n        true\n    };\n    ($r:ty) => {\n        false\n    };\n}\n\n// In this macro: using `$r:tt` because `$r:ty` doesn't match ! in `return_type_is_abort`\nmacro_rules! enclave_usercalls_internal_define_usercalls {\n    (def fn $f:ident($n1:ident: $t1:ty, $n2:ident: $t2:ty,\n                     $n3:ident: $t3:ty, $n4:ident: $t4:ty) -> $r:tt) => (\n        /// This is the raw function definition, see the ABI documentation for\n        /// more information.\n        #[unstable(feature = \"sgx_platform\", issue = \"56975\")]\n        #[inline(always)]\n        pub unsafe fn $f($n1: $t1, $n2: $t2, $n3: $t3, $n4: $t4) -> $r {\n            ReturnValue::from_registers(stringify!($f), unsafe { do_usercall(\n                    rtunwrap!(Some, NonZeroU64::new(Usercalls::$f as Register)),\n                    RegisterArgument::into_register($n1),\n                    RegisterArgument::into_register($n2),\n                    RegisterArgument::into_register($n3),\n                    RegisterArgument::into_register($n4),\n                    return_type_is_abort!($r)\n            ) })\n        }\n    );\n    (def fn $f:ident($n1:ident: $t1:ty, $n2:ident: $t2:ty, $n3:ident: $t3:ty) -> $r:tt) => (\n        /// This is the raw function definition, see the ABI documentation for\n        /// more information.\n        #[unstable(feature = \"sgx_platform\", issue = \"56975\")]\n        #[inline(always)]\n        pub unsafe fn $f($n1: $t1, $n2: $t2, $n3: $t3) -> $r {\n            ReturnValue::from_registers(stringify!($f), unsafe { do_usercall(\n                    rtunwrap!(Some, NonZeroU64::new(Usercalls::$f as Register)),\n                    RegisterArgument::into_register($n1),\n                    RegisterArgument::into_register($n2),\n                    RegisterArgument::into_register($n3),\n                    0,\n                    return_type_is_abort!($r)\n            ) })\n        }\n    );\n    (def fn $f:ident($n1:ident: $t1:ty, $n2:ident: $t2:ty) -> $r:tt) => (\n        /// This is the raw function definition, see the ABI documentation for\n        /// more information.\n        #[unstable(feature = \"sgx_platform\", issue = \"56975\")]\n        #[inline(always)]\n        pub unsafe fn $f($n1: $t1, $n2: $t2) -> $r {\n            ReturnValue::from_registers(stringify!($f), unsafe { do_usercall(\n                    rtunwrap!(Some, NonZeroU64::new(Usercalls::$f as Register)),\n                    RegisterArgument::into_register($n1),\n                    RegisterArgument::into_register($n2),\n                    0,0,\n                    return_type_is_abort!($r)\n            ) })\n        }\n    );\n    (def fn $f:ident($n1:ident: $t1:ty) -> $r:tt) => (\n        /// This is the raw function definition, see the ABI documentation for\n        /// more information.\n        #[unstable(feature = \"sgx_platform\", issue = \"56975\")]\n        #[inline(always)]\n        pub unsafe fn $f($n1: $t1) -> $r {\n            ReturnValue::from_registers(stringify!($f), unsafe { do_usercall(\n                    rtunwrap!(Some, NonZeroU64::new(Usercalls::$f as Register)),\n                    RegisterArgument::into_register($n1),\n                    0,0,0,\n                    return_type_is_abort!($r)\n            ) })\n        }\n    );\n    (def fn $f:ident() -> $r:tt) => (\n        /// This is the raw function definition, see the ABI documentation for\n        /// more information.\n        #[unstable(feature = \"sgx_platform\", issue = \"56975\")]\n        #[inline(always)]\n        pub unsafe fn $f() -> $r {\n            ReturnValue::from_registers(stringify!($f), unsafe { do_usercall(\n                    rtunwrap!(Some, NonZeroU64::new(Usercalls::$f as Register)),\n                    0,0,0,0,\n                    return_type_is_abort!($r)\n            ) })\n        }\n    );\n    (def fn $f:ident($($n:ident: $t:ty),*)) => (\n        enclave_usercalls_internal_define_usercalls!(def fn $f($($n: $t),*) -> ());\n    );\n}\n\ninvoke_with_usercalls!(define_usercalls);\n"],[2268,"#![allow(unused)]\n\nuse crate::cell::UnsafeCell;\nuse crate::mem;\nuse crate::ops::{CoerceUnsized, Deref, DerefMut, Index, IndexMut};\nuse crate::ptr::{self, NonNull};\nuse crate::slice;\nuse crate::slice::SliceIndex;\n\nuse super::super::mem::is_user_range;\nuse fortanix_sgx_abi::*;\n\n/// A type that can be safely read from or written to userspace.\n///\n/// Non-exhaustive list of specific requirements for reading and writing:\n/// * **Type is `Copy`** (and therefore also not `Drop`). Copies will be\n///   created when copying from/to userspace. Destructors will not be called.\n/// * **No references or Rust-style owned pointers** (`Vec`, `Arc`, etc.). When\n///   reading from userspace, references into enclave memory must not be\n///   created. Also, only enclave memory is considered managed by the Rust\n///   compiler's static analysis. When reading from userspace, there can be no\n///   guarantee that the value correctly adheres to the expectations of the\n///   type. When writing to userspace, memory addresses of data in enclave\n///   memory must not be leaked for confidentiality reasons. `User` and\n///   `UserRef` are also not allowed for the same reasons.\n/// * **No fat pointers.** When reading from userspace, the size or vtable\n///   pointer could be automatically interpreted and used by the code. When\n///   writing to userspace, memory addresses of data in enclave memory (such\n///   as vtable pointers) must not be leaked for confidentiality reasons.\n///\n/// Non-exhaustive list of specific requirements for reading from userspace:\n/// * **Any bit pattern is valid** for this type (no `enum`s). There can be no\n///   guarantee that the value correctly adheres to the expectations of the\n///   type, so any value must be valid for this type.\n///\n/// Non-exhaustive list of specific requirements for writing to userspace:\n/// * **No pointers to enclave memory.** Memory addresses of data in enclave\n///   memory must not be leaked for confidentiality reasons.\n/// * **No internal padding.** Padding might contain previously-initialized\n///   secret data stored at that memory location and must not be leaked for\n///   confidentiality reasons.\n#[unstable(feature = \"sgx_platform\", issue = \"56975\")]\npub unsafe trait UserSafeSized: Copy + Sized {}\n\n#[unstable(feature = \"sgx_platform\", issue = \"56975\")]\nunsafe impl UserSafeSized for u8 {}\n#[unstable(feature = \"sgx_platform\", issue = \"56975\")]\nunsafe impl<T> UserSafeSized for FifoDescriptor<T> {}\n#[unstable(feature = \"sgx_platform\", issue = \"56975\")]\nunsafe impl UserSafeSized for ByteBuffer {}\n#[unstable(feature = \"sgx_platform\", issue = \"56975\")]\nunsafe impl UserSafeSized for Usercall {}\n#[unstable(feature = \"sgx_platform\", issue = \"56975\")]\nunsafe impl UserSafeSized for Return {}\n#[unstable(feature = \"sgx_platform\", issue = \"56975\")]\nunsafe impl<T: UserSafeSized> UserSafeSized for [T; 2] {}\n\n/// A type that can be represented in memory as one or more `UserSafeSized`s.\n#[unstable(feature = \"sgx_platform\", issue = \"56975\")]\npub unsafe trait UserSafe {\n    /// Equivalent to `mem::align_of::<Self>`.\n    fn align_of() -> usize;\n\n    /// Construct a pointer to `Self` given a memory range in user space.\n    ///\n    /// N.B., this takes a size, not a length!\n    ///\n    /// # Safety\n    ///\n    /// The caller must ensure the memory range is in user memory, is the\n    /// correct size and is correctly aligned and points to the right type.\n    unsafe fn from_raw_sized_unchecked(ptr: *mut u8, size: usize) -> *mut Self;\n\n    /// Construct a pointer to `Self` given a memory range.\n    ///\n    /// N.B., this takes a size, not a length!\n    ///\n    /// # Safety\n    ///\n    /// The caller must ensure the memory range points to the correct type.\n    ///\n    /// # Panics\n    ///\n    /// This function panics if:\n    ///\n    /// * the pointer is not aligned.\n    /// * the pointer is null.\n    /// * the pointed-to range does not fit in the address space.\n    /// * the pointed-to range is not in user memory.\n    unsafe fn from_raw_sized(ptr: *mut u8, size: usize) -> NonNull<Self> {\n        assert!(ptr.wrapping_add(size) >= ptr);\n        // SAFETY: The caller has guaranteed the pointer is valid\n        let ret = unsafe { Self::from_raw_sized_unchecked(ptr, size) };\n        unsafe {\n            Self::check_ptr(ret);\n            NonNull::new_unchecked(ret as _)\n        }\n    }\n\n    /// Checks if a pointer may point to `Self` in user memory.\n    ///\n    /// # Safety\n    ///\n    /// The caller must ensure the memory range points to the correct type and\n    /// length (if this is a slice).\n    ///\n    /// # Panics\n    ///\n    /// This function panics if:\n    ///\n    /// * the pointer is not aligned.\n    /// * the pointer is null.\n    /// * the pointed-to range is not in user memory.\n    unsafe fn check_ptr(ptr: *const Self) {\n        let is_aligned = |p| -> bool { 0 == (p as usize) & (Self::align_of() - 1) };\n\n        assert!(is_aligned(ptr as *const u8));\n        assert!(is_user_range(ptr as _, mem::size_of_val(unsafe { &*ptr })));\n        assert!(!ptr.is_null());\n    }\n}\n\n#[unstable(feature = \"sgx_platform\", issue = \"56975\")]\nunsafe impl<T: UserSafeSized> UserSafe for T {\n    fn align_of() -> usize {\n        mem::align_of::<T>()\n    }\n\n    unsafe fn from_raw_sized_unchecked(ptr: *mut u8, size: usize) -> *mut Self {\n        assert_eq!(size, mem::size_of::<T>());\n        ptr as _\n    }\n}\n\n#[unstable(feature = \"sgx_platform\", issue = \"56975\")]\nunsafe impl<T: UserSafeSized> UserSafe for [T] {\n    fn align_of() -> usize {\n        mem::align_of::<T>()\n    }\n\n    /// # Safety\n    /// Behavior is undefined if any of these conditions are violated:\n    /// * `ptr` must be [valid] for writes of `size` many bytes, and it must be\n    ///   properly aligned.\n    ///\n    /// [valid]: core::ptr#safety\n    /// # Panics\n    ///\n    /// This function panics if:\n    ///\n    /// * the element size is not a factor of the size\n    unsafe fn from_raw_sized_unchecked(ptr: *mut u8, size: usize) -> *mut Self {\n        let elem_size = mem::size_of::<T>();\n        assert_eq!(size % elem_size, 0);\n        let len = size / elem_size;\n        // SAFETY: The caller must uphold the safety contract for `from_raw_sized_unchecked`\n        unsafe { slice::from_raw_parts_mut(ptr as _, len) }\n    }\n}\n\n/// A reference to some type in userspace memory. `&UserRef<T>` is equivalent\n/// to `&T` in enclave memory. Access to the memory is only allowed by copying\n/// to avoid TOCTTOU issues. After copying, code should make sure to completely\n/// check the value before use.\n///\n/// It is also possible to obtain a mutable reference `&mut UserRef<T>`. Unlike\n/// regular mutable references, these are not exclusive. Userspace may always\n/// write to the backing memory at any time, so it can't be assumed that there\n/// the pointed-to memory is uniquely borrowed. The two different reference types\n/// are used solely to indicate intent: a mutable reference is for writing to\n/// user memory, an immutable reference for reading from user memory.\n#[unstable(feature = \"sgx_platform\", issue = \"56975\")]\npub struct UserRef<T: ?Sized>(UnsafeCell<T>);\n/// An owned type in userspace memory. `User<T>` is equivalent to `Box<T>` in\n/// enclave memory. Access to the memory is only allowed by copying to avoid\n/// TOCTTOU issues. The user memory will be freed when the value is dropped.\n/// After copying, code should make sure to completely check the value before\n/// use.\n#[unstable(feature = \"sgx_platform\", issue = \"56975\")]\npub struct User<T: UserSafe + ?Sized>(NonNull<UserRef<T>>);\n\ntrait NewUserRef<T: ?Sized> {\n    unsafe fn new_userref(v: T) -> Self;\n}\n\nimpl<T: ?Sized> NewUserRef<*mut T> for NonNull<UserRef<T>> {\n    unsafe fn new_userref(v: *mut T) -> Self {\n        // SAFETY: The caller has guaranteed the pointer is valid\n        unsafe { NonNull::new_unchecked(v as _) }\n    }\n}\n\nimpl<T: ?Sized> NewUserRef<NonNull<T>> for NonNull<UserRef<T>> {\n    unsafe fn new_userref(v: NonNull<T>) -> Self {\n        // SAFETY: The caller has guaranteed the pointer is valid\n        unsafe { NonNull::new_userref(v.as_ptr()) }\n    }\n}\n\n#[unstable(feature = \"sgx_platform\", issue = \"56975\")]\nimpl<T: ?Sized> User<T>\nwhere\n    T: UserSafe,\n{\n    // This function returns memory that is practically uninitialized, but is\n    // not considered \"unspecified\" or \"undefined\" for purposes of an\n    // optimizing compiler. This is achieved by returning a pointer from\n    // from outside as obtained by `super::alloc`.\n    fn new_uninit_bytes(size: usize) -> Self {\n        unsafe {\n            // Mustn't call alloc with size 0.\n            let ptr = if size > 0 {\n                rtunwrap!(Ok, super::alloc(size, T::align_of())) as _\n            } else {\n                T::align_of() as _ // dangling pointer ok for size 0\n            };\n            if let Ok(v) = crate::panic::catch_unwind(|| T::from_raw_sized(ptr, size)) {\n                User(NonNull::new_userref(v))\n            } else {\n                rtabort!(\"Got invalid pointer from alloc() usercall\")\n            }\n        }\n    }\n\n    /// Copies `val` into freshly allocated space in user memory.\n    pub fn new_from_enclave(val: &T) -> Self {\n        unsafe {\n            let ret = Self::new_uninit_bytes(mem::size_of_val(val));\n            ptr::copy(\n                val as *const T as *const u8,\n                ret.0.as_ptr() as *mut u8,\n                mem::size_of_val(val),\n            );\n            ret\n        }\n    }\n\n    /// Creates an owned `User<T>` from a raw pointer.\n    ///\n    /// # Safety\n    /// The caller must ensure `ptr` points to `T`, is freeable with the `free`\n    /// usercall and the alignment of `T`, and is uniquely owned.\n    ///\n    /// # Panics\n    /// This function panics if:\n    ///\n    /// * The pointer is not aligned\n    /// * The pointer is null\n    /// * The pointed-to range is not in user memory\n    pub unsafe fn from_raw(ptr: *mut T) -> Self {\n        // SAFETY: the caller must uphold the safety contract for `from_raw`.\n        unsafe { T::check_ptr(ptr) };\n        User(unsafe { NonNull::new_userref(ptr) })\n    }\n\n    /// Converts this value into a raw pointer. The value will no longer be\n    /// automatically freed.\n    pub fn into_raw(self) -> *mut T {\n        let ret = self.0;\n        mem::forget(self);\n        ret.as_ptr() as _\n    }\n}\n\n#[unstable(feature = \"sgx_platform\", issue = \"56975\")]\nimpl<T> User<T>\nwhere\n    T: UserSafe,\n{\n    /// Allocate space for `T` in user memory.\n    pub fn uninitialized() -> Self {\n        Self::new_uninit_bytes(mem::size_of::<T>())\n    }\n}\n\n#[unstable(feature = \"sgx_platform\", issue = \"56975\")]\nimpl<T> User<[T]>\nwhere\n    [T]: UserSafe,\n{\n    /// Allocate space for a `[T]` of `n` elements in user memory.\n    pub fn uninitialized(n: usize) -> Self {\n        Self::new_uninit_bytes(n * mem::size_of::<T>())\n    }\n\n    /// Creates an owned `User<[T]>` from a raw thin pointer and a slice length.\n    ///\n    /// # Safety\n    /// The caller must ensure `ptr` points to `len` elements of `T`, is\n    /// freeable with the `free` usercall and the alignment of `T`, and is\n    /// uniquely owned.\n    ///\n    /// # Panics\n    /// This function panics if:\n    ///\n    /// * The pointer is not aligned\n    /// * The pointer is null\n    /// * The pointed-to range does not fit in the address space\n    /// * The pointed-to range is not in user memory\n    pub unsafe fn from_raw_parts(ptr: *mut T, len: usize) -> Self {\n        User(unsafe {\n            NonNull::new_userref(<[T]>::from_raw_sized(ptr as _, len * mem::size_of::<T>()))\n        })\n    }\n}\n\n#[unstable(feature = \"sgx_platform\", issue = \"56975\")]\nimpl<T: ?Sized> UserRef<T>\nwhere\n    T: UserSafe,\n{\n    /// Creates a `&UserRef<[T]>` from a raw pointer.\n    ///\n    /// # Safety\n    /// The caller must ensure `ptr` points to `T`.\n    ///\n    /// # Panics\n    /// This function panics if:\n    ///\n    /// * The pointer is not aligned\n    /// * The pointer is null\n    /// * The pointed-to range is not in user memory\n    pub unsafe fn from_ptr<'a>(ptr: *const T) -> &'a Self {\n        // SAFETY: The caller must uphold the safety contract for `from_ptr`.\n        unsafe { T::check_ptr(ptr) };\n        unsafe { &*(ptr as *const Self) }\n    }\n\n    /// Creates a `&mut UserRef<[T]>` from a raw pointer. See the struct\n    /// documentation for the nuances regarding a `&mut UserRef<T>`.\n    ///\n    /// # Safety\n    /// The caller must ensure `ptr` points to `T`.\n    ///\n    /// # Panics\n    /// This function panics if:\n    ///\n    /// * The pointer is not aligned\n    /// * The pointer is null\n    /// * The pointed-to range is not in user memory\n    pub unsafe fn from_mut_ptr<'a>(ptr: *mut T) -> &'a mut Self {\n        // SAFETY: The caller must uphold the safety contract for `from_mut_ptr`.\n        unsafe { T::check_ptr(ptr) };\n        unsafe { &mut *(ptr as *mut Self) }\n    }\n\n    /// Copies `val` into user memory.\n    ///\n    /// # Panics\n    /// This function panics if the destination doesn't have the same size as\n    /// the source. This can happen for dynamically-sized types such as slices.\n    pub fn copy_from_enclave(&mut self, val: &T) {\n        unsafe {\n            assert_eq!(mem::size_of_val(val), mem::size_of_val(&*self.0.get()));\n            ptr::copy(\n                val as *const T as *const u8,\n                self.0.get() as *mut T as *mut u8,\n                mem::size_of_val(val),\n            );\n        }\n    }\n\n    /// Copies the value from user memory and place it into `dest`.\n    ///\n    /// # Panics\n    /// This function panics if the destination doesn't have the same size as\n    /// the source. This can happen for dynamically-sized types such as slices.\n    pub fn copy_to_enclave(&self, dest: &mut T) {\n        unsafe {\n            assert_eq!(mem::size_of_val(dest), mem::size_of_val(&*self.0.get()));\n            ptr::copy(\n                self.0.get() as *const T as *const u8,\n                dest as *mut T as *mut u8,\n                mem::size_of_val(dest),\n            );\n        }\n    }\n\n    /// Obtain a raw pointer from this reference.\n    pub fn as_raw_ptr(&self) -> *const T {\n        self as *const _ as _\n    }\n\n    /// Obtain a raw pointer from this reference.\n    pub fn as_raw_mut_ptr(&mut self) -> *mut T {\n        self as *mut _ as _\n    }\n}\n\n#[unstable(feature = \"sgx_platform\", issue = \"56975\")]\nimpl<T> UserRef<T>\nwhere\n    T: UserSafe,\n{\n    /// Copies the value from user memory into enclave memory.\n    pub fn to_enclave(&self) -> T {\n        unsafe { ptr::read(self.0.get()) }\n    }\n}\n\n#[unstable(feature = \"sgx_platform\", issue = \"56975\")]\nimpl<T> UserRef<[T]>\nwhere\n    [T]: UserSafe,\n{\n    /// Creates a `&UserRef<[T]>` from a raw thin pointer and a slice length.\n    ///\n    /// # Safety\n    /// The caller must ensure `ptr` points to `n` elements of `T`.\n    ///\n    /// # Panics\n    /// This function panics if:\n    ///\n    /// * The pointer is not aligned\n    /// * The pointer is null\n    /// * The pointed-to range does not fit in the address space\n    /// * The pointed-to range is not in user memory\n    pub unsafe fn from_raw_parts<'a>(ptr: *const T, len: usize) -> &'a Self {\n        // SAFETY: The caller must uphold the safety contract for `from_raw_parts`.\n        unsafe {\n            &*(<[T]>::from_raw_sized(ptr as _, len * mem::size_of::<T>()).as_ptr() as *const Self)\n        }\n    }\n\n    /// Creates a `&mut UserRef<[T]>` from a raw thin pointer and a slice length.\n    /// See the struct documentation for the nuances regarding a\n    /// `&mut UserRef<T>`.\n    ///\n    /// # Safety\n    /// The caller must ensure `ptr` points to `n` elements of `T`.\n    ///\n    /// # Panics\n    /// This function panics if:\n    ///\n    /// * The pointer is not aligned\n    /// * The pointer is null\n    /// * The pointed-to range does not fit in the address space\n    /// * The pointed-to range is not in user memory\n    pub unsafe fn from_raw_parts_mut<'a>(ptr: *mut T, len: usize) -> &'a mut Self {\n        // SAFETY: The caller must uphold the safety contract for `from_raw_parts_mut`.\n        unsafe {\n            &mut *(<[T]>::from_raw_sized(ptr as _, len * mem::size_of::<T>()).as_ptr() as *mut Self)\n        }\n    }\n\n    /// Obtain a raw pointer to the first element of this user slice.\n    pub fn as_ptr(&self) -> *const T {\n        self.0.get() as _\n    }\n\n    /// Obtain a raw pointer to the first element of this user slice.\n    pub fn as_mut_ptr(&mut self) -> *mut T {\n        self.0.get() as _\n    }\n\n    /// Obtain the number of elements in this user slice.\n    pub fn len(&self) -> usize {\n        unsafe { (*self.0.get()).len() }\n    }\n\n    /// Copies the value from user memory and place it into `dest`. Afterwards,\n    /// `dest` will contain exactly `self.len()` elements.\n    ///\n    /// # Panics\n    /// This function panics if the destination doesn't have the same size as\n    /// the source. This can happen for dynamically-sized types such as slices.\n    pub fn copy_to_enclave_vec(&self, dest: &mut Vec<T>) {\n        if let Some(missing) = self.len().checked_sub(dest.capacity()) {\n            dest.reserve(missing)\n        }\n        // SAFETY: We reserve enough space above.\n        unsafe { dest.set_len(self.len()) };\n        self.copy_to_enclave(&mut dest[..]);\n    }\n\n    /// Copies the value from user memory into a vector in enclave memory.\n    pub fn to_enclave(&self) -> Vec<T> {\n        let mut ret = Vec::with_capacity(self.len());\n        self.copy_to_enclave_vec(&mut ret);\n        ret\n    }\n\n    /// Returns an iterator over the slice.\n    pub fn iter(&self) -> Iter<'_, T>\n    where\n        T: UserSafe, // FIXME: should be implied by [T]: UserSafe?\n    {\n        unsafe { Iter((&*self.as_raw_ptr()).iter()) }\n    }\n\n    /// Returns an iterator that allows modifying each value.\n    pub fn iter_mut(&mut self) -> IterMut<'_, T>\n    where\n        T: UserSafe, // FIXME: should be implied by [T]: UserSafe?\n    {\n        unsafe { IterMut((&mut *self.as_raw_mut_ptr()).iter_mut()) }\n    }\n}\n\n/// Immutable user slice iterator\n///\n/// This struct is created by the `iter` method on `UserRef<[T]>`.\n#[unstable(feature = \"sgx_platform\", issue = \"56975\")]\npub struct Iter<'a, T: 'a + UserSafe>(slice::Iter<'a, T>);\n\n#[unstable(feature = \"sgx_platform\", issue = \"56975\")]\nimpl<'a, T: UserSafe> Iterator for Iter<'a, T> {\n    type Item = &'a UserRef<T>;\n\n    #[inline]\n    fn next(&mut self) -> Option<Self::Item> {\n        unsafe { self.0.next().map(|e| UserRef::from_ptr(e)) }\n    }\n}\n\n/// Mutable user slice iterator\n///\n/// This struct is created by the `iter_mut` method on `UserRef<[T]>`.\n#[unstable(feature = \"sgx_platform\", issue = \"56975\")]\npub struct IterMut<'a, T: 'a + UserSafe>(slice::IterMut<'a, T>);\n\n#[unstable(feature = \"sgx_platform\", issue = \"56975\")]\nimpl<'a, T: UserSafe> Iterator for IterMut<'a, T> {\n    type Item = &'a mut UserRef<T>;\n\n    #[inline]\n    fn next(&mut self) -> Option<Self::Item> {\n        unsafe { self.0.next().map(|e| UserRef::from_mut_ptr(e)) }\n    }\n}\n\n#[unstable(feature = \"sgx_platform\", issue = \"56975\")]\nimpl<T: ?Sized> Deref for User<T>\nwhere\n    T: UserSafe,\n{\n    type Target = UserRef<T>;\n\n    fn deref(&self) -> &Self::Target {\n        unsafe { &*self.0.as_ptr() }\n    }\n}\n\n#[unstable(feature = \"sgx_platform\", issue = \"56975\")]\nimpl<T: ?Sized> DerefMut for User<T>\nwhere\n    T: UserSafe,\n{\n    fn deref_mut(&mut self) -> &mut Self::Target {\n        unsafe { &mut *self.0.as_ptr() }\n    }\n}\n\n#[unstable(feature = \"sgx_platform\", issue = \"56975\")]\nimpl<T: ?Sized> Drop for User<T>\nwhere\n    T: UserSafe,\n{\n    fn drop(&mut self) {\n        unsafe {\n            let ptr = (*self.0.as_ptr()).0.get();\n            super::free(ptr as _, mem::size_of_val(&mut *ptr), T::align_of());\n        }\n    }\n}\n\n#[unstable(feature = \"sgx_platform\", issue = \"56975\")]\nimpl<T: CoerceUnsized<U>, U> CoerceUnsized<UserRef<U>> for UserRef<T> {}\n\n#[unstable(feature = \"sgx_platform\", issue = \"56975\")]\nimpl<T, I> Index<I> for UserRef<[T]>\nwhere\n    [T]: UserSafe,\n    I: SliceIndex<[T], Output: UserSafe>,\n{\n    type Output = UserRef<I::Output>;\n\n    #[inline]\n    fn index(&self, index: I) -> &UserRef<I::Output> {\n        unsafe {\n            if let Some(slice) = index.get(&*self.as_raw_ptr()) {\n                UserRef::from_ptr(slice)\n            } else {\n                rtabort!(\"index out of range for user slice\");\n            }\n        }\n    }\n}\n\n#[unstable(feature = \"sgx_platform\", issue = \"56975\")]\nimpl<T, I> IndexMut<I> for UserRef<[T]>\nwhere\n    [T]: UserSafe,\n    I: SliceIndex<[T], Output: UserSafe>,\n{\n    #[inline]\n    fn index_mut(&mut self, index: I) -> &mut UserRef<I::Output> {\n        unsafe {\n            if let Some(slice) = index.get_mut(&mut *self.as_raw_mut_ptr()) {\n                UserRef::from_mut_ptr(slice)\n            } else {\n                rtabort!(\"index out of range for user slice\");\n            }\n        }\n    }\n}\n\n#[unstable(feature = \"sgx_platform\", issue = \"56975\")]\nimpl UserRef<super::raw::ByteBuffer> {\n    /// Copies the user memory range pointed to by the user `ByteBuffer` to\n    /// enclave memory.\n    ///\n    /// # Panics\n    /// This function panics if, in the user `ByteBuffer`:\n    ///\n    /// * The pointer is null\n    /// * The pointed-to range does not fit in the address space\n    /// * The pointed-to range is not in user memory\n    pub fn copy_user_buffer(&self) -> Vec<u8> {\n        unsafe {\n            let buf = self.to_enclave();\n            if buf.len > 0 {\n                User::from_raw_parts(buf.data as _, buf.len).to_enclave()\n            } else {\n                // Mustn't look at `data` or call `free` if `len` is `0`.\n                Vec::with_capacity(0)\n            }\n        }\n    }\n}\n"],[2269,"use crate::cmp;\nuse crate::convert::TryFrom;\nuse crate::io::{Error as IoError, ErrorKind, IoSlice, IoSliceMut, Result as IoResult};\nuse crate::sys::rand::rdrand64;\nuse crate::time::{Duration, Instant};\n\npub(crate) mod alloc;\n#[macro_use]\npub(crate) mod raw;\n\nuse self::raw::*;\n\n/// Usercall `read`. See the ABI documentation for more information.\n///\n/// This will do a single `read` usercall and scatter the read data among\n/// `bufs`. To read to a single buffer, just pass a slice of length one.\n#[unstable(feature = \"sgx_platform\", issue = \"56975\")]\npub fn read(fd: Fd, bufs: &mut [IoSliceMut<'_>]) -> IoResult<usize> {\n    unsafe {\n        let total_len = bufs.iter().fold(0usize, |sum, buf| sum.saturating_add(buf.len()));\n        let mut userbuf = alloc::User::<[u8]>::uninitialized(total_len);\n        let ret_len = raw::read(fd, userbuf.as_mut_ptr(), userbuf.len()).from_sgx_result()?;\n        let userbuf = &userbuf[..ret_len];\n        let mut index = 0;\n        for buf in bufs {\n            let end = cmp::min(index + buf.len(), userbuf.len());\n            if let Some(buflen) = end.checked_sub(index) {\n                userbuf[index..end].copy_to_enclave(&mut buf[..buflen]);\n                index += buf.len();\n            } else {\n                break;\n            }\n        }\n        Ok(userbuf.len())\n    }\n}\n\n/// Usercall `read_alloc`. See the ABI documentation for more information.\n#[unstable(feature = \"sgx_platform\", issue = \"56975\")]\npub fn read_alloc(fd: Fd) -> IoResult<Vec<u8>> {\n    unsafe {\n        let userbuf = ByteBuffer { data: crate::ptr::null_mut(), len: 0 };\n        let mut userbuf = alloc::User::new_from_enclave(&userbuf);\n        raw::read_alloc(fd, userbuf.as_raw_mut_ptr()).from_sgx_result()?;\n        Ok(userbuf.copy_user_buffer())\n    }\n}\n\n/// Usercall `write`. See the ABI documentation for more information.\n///\n/// This will do a single `write` usercall and gather the written data from\n/// `bufs`. To write from a single buffer, just pass a slice of length one.\n#[unstable(feature = \"sgx_platform\", issue = \"56975\")]\npub fn write(fd: Fd, bufs: &[IoSlice<'_>]) -> IoResult<usize> {\n    unsafe {\n        let total_len = bufs.iter().fold(0usize, |sum, buf| sum.saturating_add(buf.len()));\n        let mut userbuf = alloc::User::<[u8]>::uninitialized(total_len);\n        let mut index = 0;\n        for buf in bufs {\n            let end = cmp::min(index + buf.len(), userbuf.len());\n            if let Some(buflen) = end.checked_sub(index) {\n                userbuf[index..end].copy_from_enclave(&buf[..buflen]);\n                index += buf.len();\n            } else {\n                break;\n            }\n        }\n        raw::write(fd, userbuf.as_ptr(), userbuf.len()).from_sgx_result()\n    }\n}\n\n/// Usercall `flush`. See the ABI documentation for more information.\n#[unstable(feature = \"sgx_platform\", issue = \"56975\")]\npub fn flush(fd: Fd) -> IoResult<()> {\n    unsafe { raw::flush(fd).from_sgx_result() }\n}\n\n/// Usercall `close`. See the ABI documentation for more information.\n#[unstable(feature = \"sgx_platform\", issue = \"56975\")]\npub fn close(fd: Fd) {\n    unsafe { raw::close(fd) }\n}\n\nfn string_from_bytebuffer(buf: &alloc::UserRef<ByteBuffer>, usercall: &str, arg: &str) -> String {\n    String::from_utf8(buf.copy_user_buffer())\n        .unwrap_or_else(|_| rtabort!(\"Usercall {}: expected {} to be valid UTF-8\", usercall, arg))\n}\n\n/// Usercall `bind_stream`. See the ABI documentation for more information.\n#[unstable(feature = \"sgx_platform\", issue = \"56975\")]\npub fn bind_stream(addr: &str) -> IoResult<(Fd, String)> {\n    unsafe {\n        let addr_user = alloc::User::new_from_enclave(addr.as_bytes());\n        let mut local = alloc::User::<ByteBuffer>::uninitialized();\n        let fd = raw::bind_stream(addr_user.as_ptr(), addr_user.len(), local.as_raw_mut_ptr())\n            .from_sgx_result()?;\n        let local = string_from_bytebuffer(&local, \"bind_stream\", \"local_addr\");\n        Ok((fd, local))\n    }\n}\n\n/// Usercall `accept_stream`. See the ABI documentation for more information.\n#[unstable(feature = \"sgx_platform\", issue = \"56975\")]\npub fn accept_stream(fd: Fd) -> IoResult<(Fd, String, String)> {\n    unsafe {\n        let mut bufs = alloc::User::<[ByteBuffer; 2]>::uninitialized();\n        let mut buf_it = alloc::UserRef::iter_mut(&mut *bufs); // FIXME: can this be done\n        // without forcing coercion?\n        let (local, peer) = (buf_it.next().unwrap(), buf_it.next().unwrap());\n        let fd = raw::accept_stream(fd, local.as_raw_mut_ptr(), peer.as_raw_mut_ptr())\n            .from_sgx_result()?;\n        let local = string_from_bytebuffer(&local, \"accept_stream\", \"local_addr\");\n        let peer = string_from_bytebuffer(&peer, \"accept_stream\", \"peer_addr\");\n        Ok((fd, local, peer))\n    }\n}\n\n/// Usercall `connect_stream`. See the ABI documentation for more information.\n#[unstable(feature = \"sgx_platform\", issue = \"56975\")]\npub fn connect_stream(addr: &str) -> IoResult<(Fd, String, String)> {\n    unsafe {\n        let addr_user = alloc::User::new_from_enclave(addr.as_bytes());\n        let mut bufs = alloc::User::<[ByteBuffer; 2]>::uninitialized();\n        let mut buf_it = alloc::UserRef::iter_mut(&mut *bufs); // FIXME: can this be done\n        // without forcing coercion?\n        let (local, peer) = (buf_it.next().unwrap(), buf_it.next().unwrap());\n        let fd = raw::connect_stream(\n            addr_user.as_ptr(),\n            addr_user.len(),\n            local.as_raw_mut_ptr(),\n            peer.as_raw_mut_ptr(),\n        )\n        .from_sgx_result()?;\n        let local = string_from_bytebuffer(&local, \"connect_stream\", \"local_addr\");\n        let peer = string_from_bytebuffer(&peer, \"connect_stream\", \"peer_addr\");\n        Ok((fd, local, peer))\n    }\n}\n\n/// Usercall `launch_thread`. See the ABI documentation for more information.\n#[unstable(feature = \"sgx_platform\", issue = \"56975\")]\npub unsafe fn launch_thread() -> IoResult<()> {\n    // SAFETY: The caller must uphold the safety contract for `launch_thread`.\n    unsafe { raw::launch_thread().from_sgx_result() }\n}\n\n/// Usercall `exit`. See the ABI documentation for more information.\n#[unstable(feature = \"sgx_platform\", issue = \"56975\")]\npub fn exit(panic: bool) -> ! {\n    unsafe { raw::exit(panic) }\n}\n\n/// Usercall `wait`. See the ABI documentation for more information.\n#[unstable(feature = \"sgx_platform\", issue = \"56975\")]\npub fn wait(event_mask: u64, mut timeout: u64) -> IoResult<u64> {\n    if timeout != WAIT_NO && timeout != WAIT_INDEFINITE {\n        // We don't want people to rely on accuracy of timeouts to make\n        // security decisions in an SGX enclave. That's why we add a random\n        // amount not exceeding +/- 10% to the timeout value to discourage\n        // people from relying on accuracy of timeouts while providing a way\n        // to make things work in other cases. Note that in the SGX threat\n        // model the enclave runner which is serving the wait usercall is not\n        // trusted to ensure accurate timeouts.\n        if let Ok(timeout_signed) = i64::try_from(timeout) {\n            let tenth = timeout_signed / 10;\n            let deviation = (rdrand64() as i64).checked_rem(tenth).unwrap_or(0);\n            timeout = timeout_signed.saturating_add(deviation) as _;\n        }\n    }\n    unsafe { raw::wait(event_mask, timeout).from_sgx_result() }\n}\n\n/// This function makes an effort to wait for a non-spurious event at least as\n/// long as `duration`. Note that in general there is no guarantee about accuracy\n/// of time and timeouts in SGX model. The enclave runner serving usercalls may\n/// lie about current time and/or ignore timeout values.\n///\n/// Once the event is observed, `should_wake_up` will be used to determine\n/// whether or not the event was spurious.\n#[unstable(feature = \"sgx_platform\", issue = \"56975\")]\npub fn wait_timeout<F>(event_mask: u64, duration: Duration, should_wake_up: F)\nwhere\n    F: Fn() -> bool,\n{\n    // Calls the wait usercall and checks the result. Returns true if event was\n    // returned, and false if WouldBlock/TimedOut was returned.\n    // If duration is None, it will use WAIT_NO.\n    fn wait_checked(event_mask: u64, duration: Option<Duration>) -> bool {\n        let timeout = duration.map_or(raw::WAIT_NO, |duration| {\n            cmp::min((u64::MAX - 1) as u128, duration.as_nanos()) as u64\n        });\n        match wait(event_mask, timeout) {\n            Ok(eventset) => {\n                if event_mask == 0 {\n                    rtabort!(\"expected wait() to return Err, found Ok.\");\n                }\n                rtassert!(eventset != 0 && eventset & !event_mask == 0);\n                true\n            }\n            Err(e) => {\n                rtassert!(e.kind() == ErrorKind::TimedOut || e.kind() == ErrorKind::WouldBlock);\n                false\n            }\n        }\n    }\n\n    match wait_checked(event_mask, Some(duration)) {\n        false => return,                    // timed out\n        true if should_wake_up() => return, // woken up\n        true => {}                          // spurious event\n    }\n\n    // Drain all cached events.\n    // Note that `event_mask != 0` is implied if we get here.\n    loop {\n        match wait_checked(event_mask, None) {\n            false => break,                     // no more cached events\n            true if should_wake_up() => return, // woken up\n            true => {}                          // spurious event\n        }\n    }\n\n    // Continue waiting, but take note of time spent waiting so we don't wait\n    // forever. We intentionally don't call `Instant::now()` before this point\n    // to avoid the cost of the `insecure_time` usercall in case there are no\n    // spurious wakeups.\n\n    let start = Instant::now();\n    let mut remaining = duration;\n    loop {\n        match wait_checked(event_mask, Some(remaining)) {\n            false => return,                    // timed out\n            true if should_wake_up() => return, // woken up\n            true => {}                          // spurious event\n        }\n        remaining = match duration.checked_sub(start.elapsed()) {\n            Some(remaining) => remaining,\n            None => break,\n        }\n    }\n}\n\n/// Usercall `send`. See the ABI documentation for more information.\n#[unstable(feature = \"sgx_platform\", issue = \"56975\")]\npub fn send(event_set: u64, tcs: Option<Tcs>) -> IoResult<()> {\n    unsafe { raw::send(event_set, tcs).from_sgx_result() }\n}\n\n/// Usercall `insecure_time`. See the ABI documentation for more information.\n#[unstable(feature = \"sgx_platform\", issue = \"56975\")]\npub fn insecure_time() -> Duration {\n    let t = unsafe { raw::insecure_time() };\n    Duration::new(t / 1_000_000_000, (t % 1_000_000_000) as _)\n}\n\n/// Usercall `alloc`. See the ABI documentation for more information.\n#[unstable(feature = \"sgx_platform\", issue = \"56975\")]\npub fn alloc(size: usize, alignment: usize) -> IoResult<*mut u8> {\n    unsafe { raw::alloc(size, alignment).from_sgx_result() }\n}\n\n#[unstable(feature = \"sgx_platform\", issue = \"56975\")]\n#[doc(inline)]\npub use self::raw::free;\n\nfn check_os_error(err: Result) -> i32 {\n    // FIXME: not sure how to make sure all variants of Error are covered\n    if err == Error::NotFound as _\n        || err == Error::PermissionDenied as _\n        || err == Error::ConnectionRefused as _\n        || err == Error::ConnectionReset as _\n        || err == Error::ConnectionAborted as _\n        || err == Error::NotConnected as _\n        || err == Error::AddrInUse as _\n        || err == Error::AddrNotAvailable as _\n        || err == Error::BrokenPipe as _\n        || err == Error::AlreadyExists as _\n        || err == Error::WouldBlock as _\n        || err == Error::InvalidInput as _\n        || err == Error::InvalidData as _\n        || err == Error::TimedOut as _\n        || err == Error::WriteZero as _\n        || err == Error::Interrupted as _\n        || err == Error::Other as _\n        || err == Error::UnexpectedEof as _\n        || ((Error::UserRangeStart as _)..=(Error::UserRangeEnd as _)).contains(&err)\n    {\n        err\n    } else {\n        rtabort!(\"Usercall: returned invalid error value {}\", err)\n    }\n}\n\ntrait FromSgxResult {\n    type Return;\n\n    fn from_sgx_result(self) -> IoResult<Self::Return>;\n}\n\nimpl<T> FromSgxResult for (Result, T) {\n    type Return = T;\n\n    fn from_sgx_result(self) -> IoResult<Self::Return> {\n        if self.0 == RESULT_SUCCESS {\n            Ok(self.1)\n        } else {\n            Err(IoError::from_raw_os_error(check_os_error(self.0)))\n        }\n    }\n}\n\nimpl FromSgxResult for Result {\n    type Return = ();\n\n    fn from_sgx_result(self) -> IoResult<Self::Return> {\n        if self == RESULT_SUCCESS {\n            Ok(())\n        } else {\n            Err(IoError::from_raw_os_error(check_os_error(self)))\n        }\n    }\n}\n"],[2270,"use super::usercalls::alloc::UserRef;\nuse crate::cmp;\nuse crate::io::{self, Write};\nuse crate::mem;\n\nextern \"C\" {\n    fn take_debug_panic_buf_ptr() -> *mut u8;\n    static DEBUG: u8;\n}\n\npub(crate) struct SgxPanicOutput(Option<&'static mut UserRef<[u8]>>);\n\nfn empty_user_slice() -> &'static mut UserRef<[u8]> {\n    unsafe { UserRef::from_raw_parts_mut(1 as *mut u8, 0) }\n}\n\nimpl SgxPanicOutput {\n    pub(crate) fn new() -> Option<Self> {\n        if unsafe { DEBUG == 0 } { None } else { Some(SgxPanicOutput(None)) }\n    }\n\n    fn init(&mut self) -> &mut &'static mut UserRef<[u8]> {\n        self.0.get_or_insert_with(|| unsafe {\n            let ptr = take_debug_panic_buf_ptr();\n            if ptr.is_null() { empty_user_slice() } else { UserRef::from_raw_parts_mut(ptr, 1024) }\n        })\n    }\n}\n\nimpl Write for SgxPanicOutput {\n    fn write(&mut self, src: &[u8]) -> io::Result<usize> {\n        let dst = mem::replace(self.init(), empty_user_slice());\n        let written = cmp::min(src.len(), dst.len());\n        dst[..written].copy_from_enclave(&src[..written]);\n        self.0 = Some(&mut dst[written..]);\n        Ok(written)\n    }\n\n    fn flush(&mut self) -> io::Result<()> {\n        Ok(())\n    }\n}\n"],[2271,"use fortanix_sgx_abi::Tcs;\n\n/// Gets the ID for the current thread. The ID is guaranteed to be unique among\n/// all currently running threads in the enclave, and it is guaranteed to be\n/// constant for the lifetime of the thread. More specifically for SGX, there\n/// is a one-to-one correspondence of the ID to the address of the TCS.\n#[unstable(feature = \"sgx_platform\", issue = \"56975\")]\npub fn current() -> Tcs {\n    extern \"C\" {\n        fn get_tcs_addr() -> Tcs;\n    }\n    unsafe { get_tcs_addr() }\n}\n"],[2272,"use super::mem;\nuse crate::slice::from_raw_parts;\n\nconst R_X86_64_RELATIVE: u32 = 8;\n\n#[repr(packed)]\nstruct Rela<T> {\n    offset: T,\n    info: T,\n    addend: T,\n}\n\npub fn relocate_elf_rela() {\n    extern \"C\" {\n        static RELA: u64;\n        static RELACOUNT: usize;\n    }\n\n    if unsafe { RELACOUNT } == 0 {\n        return;\n    } // unsafe ok: link-time constant\n\n    let relas = unsafe {\n        from_raw_parts::<Rela<u64>>(mem::rel_ptr(RELA), RELACOUNT) // unsafe ok: link-time constant\n    };\n    for rela in relas {\n        if rela.info != (/*0 << 32 |*/R_X86_64_RELATIVE as u64) {\n            rtabort!(\"Invalid relocation\");\n        }\n        unsafe { *mem::rel_ptr_mut::<*const ()>(rela.offset) = mem::rel_ptr(rela.addend) };\n    }\n}\n"],[2273,"use fortanix_sgx_abi::{Error, RESULT_SUCCESS};\n\nuse crate::collections::HashMap;\nuse crate::error::Error as StdError;\nuse crate::ffi::{OsStr, OsString};\nuse crate::fmt;\nuse crate::io;\nuse crate::marker::PhantomData;\nuse crate::path::{self, PathBuf};\nuse crate::str;\nuse crate::sync::atomic::{AtomicUsize, Ordering};\nuse crate::sync::Mutex;\nuse crate::sync::Once;\nuse crate::sys::{decode_error_kind, sgx_ineffective, unsupported};\nuse crate::vec;\n\npub fn errno() -> i32 {\n    RESULT_SUCCESS\n}\n\npub fn error_string(errno: i32) -> String {\n    if errno == RESULT_SUCCESS {\n        \"operation successful\".into()\n    } else if ((Error::UserRangeStart as _)..=(Error::UserRangeEnd as _)).contains(&errno) {\n        format!(\"user-specified error {:08x}\", errno)\n    } else {\n        decode_error_kind(errno).as_str().into()\n    }\n}\n\npub fn getcwd() -> io::Result<PathBuf> {\n    unsupported()\n}\n\npub fn chdir(_: &path::Path) -> io::Result<()> {\n    sgx_ineffective(())\n}\n\npub struct SplitPaths<'a>(!, PhantomData<&'a ()>);\n\npub fn split_paths(_unparsed: &OsStr) -> SplitPaths<'_> {\n    panic!(\"unsupported\")\n}\n\nimpl<'a> Iterator for SplitPaths<'a> {\n    type Item = PathBuf;\n    fn next(&mut self) -> Option<PathBuf> {\n        self.0\n    }\n}\n\n#[derive(Debug)]\npub struct JoinPathsError;\n\npub fn join_paths<I, T>(_paths: I) -> Result<OsString, JoinPathsError>\nwhere\n    I: Iterator<Item = T>,\n    T: AsRef<OsStr>,\n{\n    Err(JoinPathsError)\n}\n\nimpl fmt::Display for JoinPathsError {\n    fn fmt(&self, f: &mut fmt::Formatter<'_>) -> fmt::Result {\n        \"not supported in SGX yet\".fmt(f)\n    }\n}\n\nimpl StdError for JoinPathsError {\n    #[allow(deprecated)]\n    fn description(&self) -> &str {\n        \"not supported in SGX yet\"\n    }\n}\n\npub fn current_exe() -> io::Result<PathBuf> {\n    unsupported()\n}\n\n#[cfg_attr(test, linkage = \"available_externally\")]\n#[export_name = \"_ZN16__rust_internals3std3sys3sgx2os3ENVE\"]\nstatic ENV: AtomicUsize = AtomicUsize::new(0);\n#[cfg_attr(test, linkage = \"available_externally\")]\n#[export_name = \"_ZN16__rust_internals3std3sys3sgx2os8ENV_INITE\"]\nstatic ENV_INIT: Once = Once::new();\ntype EnvStore = Mutex<HashMap<OsString, OsString>>;\n\nfn get_env_store() -> Option<&'static EnvStore> {\n    unsafe { (ENV.load(Ordering::Relaxed) as *const EnvStore).as_ref() }\n}\n\nfn create_env_store() -> &'static EnvStore {\n    ENV_INIT.call_once(|| {\n        ENV.store(Box::into_raw(Box::new(EnvStore::default())) as _, Ordering::Relaxed)\n    });\n    unsafe { &*(ENV.load(Ordering::Relaxed) as *const EnvStore) }\n}\n\npub type Env = vec::IntoIter<(OsString, OsString)>;\n\npub fn env() -> Env {\n    let clone_to_vec = |map: &HashMap<OsString, OsString>| -> Vec<_> {\n        map.iter().map(|(k, v)| (k.clone(), v.clone())).collect()\n    };\n\n    get_env_store().map(|env| clone_to_vec(&env.lock().unwrap())).unwrap_or_default().into_iter()\n}\n\npub fn getenv(k: &OsStr) -> io::Result<Option<OsString>> {\n    Ok(get_env_store().and_then(|s| s.lock().unwrap().get(k).cloned()))\n}\n\npub fn setenv(k: &OsStr, v: &OsStr) -> io::Result<()> {\n    let (k, v) = (k.to_owned(), v.to_owned());\n    create_env_store().lock().unwrap().insert(k, v);\n    Ok(())\n}\n\npub fn unsetenv(k: &OsStr) -> io::Result<()> {\n    if let Some(env) = get_env_store() {\n        env.lock().unwrap().remove(k);\n    }\n    Ok(())\n}\n\npub fn temp_dir() -> PathBuf {\n    panic!(\"no filesystem in SGX\")\n}\n\npub fn home_dir() -> Option<PathBuf> {\n    None\n}\n\npub fn exit(code: i32) -> ! {\n    super::abi::exit_with_code(code as _)\n}\n\npub fn getpid() -> u32 {\n    panic!(\"no pids in SGX\")\n}\n"],[2274,"use fortanix_sgx_abi::Fd;\n\nuse super::abi::usercalls;\nuse crate::io::{self, IoSlice, IoSliceMut};\nuse crate::mem;\nuse crate::sys::{AsInner, FromInner, IntoInner};\n\n#[derive(Debug)]\npub struct FileDesc {\n    fd: Fd,\n}\n\nimpl FileDesc {\n    pub fn new(fd: Fd) -> FileDesc {\n        FileDesc { fd: fd }\n    }\n\n    pub fn raw(&self) -> Fd {\n        self.fd\n    }\n\n    /// Extracts the actual file descriptor without closing it.\n    pub fn into_raw(self) -> Fd {\n        let fd = self.fd;\n        mem::forget(self);\n        fd\n    }\n\n    pub fn read(&self, buf: &mut [u8]) -> io::Result<usize> {\n        usercalls::read(self.fd, &mut [IoSliceMut::new(buf)])\n    }\n\n    pub fn read_vectored(&self, bufs: &mut [IoSliceMut<'_>]) -> io::Result<usize> {\n        usercalls::read(self.fd, bufs)\n    }\n\n    #[inline]\n    pub fn is_read_vectored(&self) -> bool {\n        true\n    }\n\n    pub fn write(&self, buf: &[u8]) -> io::Result<usize> {\n        usercalls::write(self.fd, &[IoSlice::new(buf)])\n    }\n\n    pub fn write_vectored(&self, bufs: &[IoSlice<'_>]) -> io::Result<usize> {\n        usercalls::write(self.fd, bufs)\n    }\n\n    #[inline]\n    pub fn is_write_vectored(&self) -> bool {\n        true\n    }\n\n    pub fn flush(&self) -> io::Result<()> {\n        usercalls::flush(self.fd)\n    }\n}\n\nimpl AsInner<Fd> for FileDesc {\n    fn as_inner(&self) -> &Fd {\n        &self.fd\n    }\n}\n\nimpl IntoInner<Fd> for FileDesc {\n    fn into_inner(self) -> Fd {\n        let fd = self.fd;\n        mem::forget(self);\n        fd\n    }\n}\n\nimpl FromInner<Fd> for FileDesc {\n    fn from_inner(fd: Fd) -> FileDesc {\n        FileDesc { fd }\n    }\n}\n\nimpl Drop for FileDesc {\n    fn drop(&mut self) {\n        usercalls::close(self.fd)\n    }\n}\n"],[2275,"use crate::ffi::OsStr;\nuse crate::path::Prefix;\n\n#[inline]\npub fn is_sep_byte(b: u8) -> bool {\n    b == b'/'\n}\n\n#[inline]\npub fn is_verbatim_sep(b: u8) -> bool {\n    b == b'/'\n}\n\npub fn parse_prefix(_: &OsStr) -> Option<Prefix<'_>> {\n    None\n}\n\npub const MAIN_SEP_STR: &str = \"/\";\npub const MAIN_SEP: char = '/';\n"],[2276,"use fortanix_sgx_abi as abi;\n\nuse crate::io;\n#[cfg(not(test))]\nuse crate::slice;\n#[cfg(not(test))]\nuse crate::str;\nuse crate::sys::fd::FileDesc;\n\npub struct Stdin(());\npub struct Stdout(());\npub struct Stderr(());\n\nfn with_std_fd<F: FnOnce(&FileDesc) -> R, R>(fd: abi::Fd, f: F) -> R {\n    let fd = FileDesc::new(fd);\n    let ret = f(&fd);\n    fd.into_raw();\n    ret\n}\n\nimpl Stdin {\n    pub const fn new() -> Stdin {\n        Stdin(())\n    }\n}\n\nimpl io::Read for Stdin {\n    fn read(&mut self, buf: &mut [u8]) -> io::Result<usize> {\n        with_std_fd(abi::FD_STDIN, |fd| fd.read(buf))\n    }\n}\n\nimpl Stdout {\n    pub const fn new() -> Stdout {\n        Stdout(())\n    }\n}\n\nimpl io::Write for Stdout {\n    fn write(&mut self, buf: &[u8]) -> io::Result<usize> {\n        with_std_fd(abi::FD_STDOUT, |fd| fd.write(buf))\n    }\n\n    fn flush(&mut self) -> io::Result<()> {\n        with_std_fd(abi::FD_STDOUT, |fd| fd.flush())\n    }\n}\n\nimpl Stderr {\n    pub const fn new() -> Stderr {\n        Stderr(())\n    }\n}\n\nimpl io::Write for Stderr {\n    fn write(&mut self, buf: &[u8]) -> io::Result<usize> {\n        with_std_fd(abi::FD_STDERR, |fd| fd.write(buf))\n    }\n\n    fn flush(&mut self) -> io::Result<()> {\n        with_std_fd(abi::FD_STDERR, |fd| fd.flush())\n    }\n}\n\npub const STDIN_BUF_SIZE: usize = crate::sys_common::io::DEFAULT_BUF_SIZE;\n\npub fn is_ebadf(err: &io::Error) -> bool {\n    // FIXME: Rust normally maps Unix EBADF to `Other`\n    err.raw_os_error() == Some(abi::Error::BrokenPipe as _)\n}\n\npub fn panic_output() -> Option<impl io::Write> {\n    super::abi::panic::SgxPanicOutput::new()\n}\n\n// This function is needed by libunwind. The symbol is named in pre-link args\n// for the target specification, so keep that in sync.\n#[cfg(not(test))]\n#[no_mangle]\npub unsafe extern \"C\" fn __rust_print_err(m: *mut u8, s: i32) {\n    if s < 0 {\n        return;\n    }\n    let buf = unsafe { slice::from_raw_parts(m as *const u8, s as _) };\n    if let Ok(s) = str::from_utf8(&buf[..buf.iter().position(|&b| b == 0).unwrap_or(buf.len())]) {\n        eprint!(\"{}\", s);\n    }\n}\n"],[2277,"use super::abi::tls::{Key as AbiKey, Tls};\n\npub type Key = usize;\n\n#[inline]\npub unsafe fn create(dtor: Option<unsafe extern \"C\" fn(*mut u8)>) -> Key {\n    Tls::create(dtor).as_usize()\n}\n\n#[inline]\npub unsafe fn set(key: Key, value: *mut u8) {\n    Tls::set(AbiKey::from_usize(key), value)\n}\n\n#[inline]\npub unsafe fn get(key: Key) -> *mut u8 {\n    Tls::get(AbiKey::from_usize(key))\n}\n\n#[inline]\npub unsafe fn destroy(key: Key) {\n    Tls::destroy(AbiKey::from_usize(key))\n}\n\n#[inline]\npub fn requires_synchronized_create() -> bool {\n    false\n}\n"],[2278,"//! A simple queue implementation for synchronization primitives.\n//!\n//! This queue is used to implement condition variable and mutexes.\n//!\n//! Users of this API are expected to use the `WaitVariable<T>` type. Since\n//! that type is not `Sync`, it needs to be protected by e.g., a `SpinMutex` to\n//! allow shared access.\n//!\n//! Since userspace may send spurious wake-ups, the wakeup event state is\n//! recorded in the enclave. The wakeup event state is protected by a spinlock.\n//! The queue and associated wait state are stored in a `WaitVariable`.\n\n#[cfg(test)]\nmod tests;\n\nmod spin_mutex;\nmod unsafe_list;\n\nuse crate::num::NonZeroUsize;\nuse crate::ops::{Deref, DerefMut};\nuse crate::time::Duration;\n\nuse super::abi::thread;\nuse super::abi::usercalls;\nuse fortanix_sgx_abi::{Tcs, EV_UNPARK, WAIT_INDEFINITE};\n\npub use self::spin_mutex::{try_lock_or_false, SpinMutex, SpinMutexGuard};\nuse self::unsafe_list::{UnsafeList, UnsafeListEntry};\n\n/// An queue entry in a `WaitQueue`.\nstruct WaitEntry {\n    /// TCS address of the thread that is waiting\n    tcs: Tcs,\n    /// Whether this thread has been notified to be awoken\n    wake: bool,\n}\n\n/// Data stored with a `WaitQueue` alongside it. This ensures accesses to the\n/// queue and the data are synchronized, since the type itself is not `Sync`.\n///\n/// Consumers of this API should use a synchronization primitive for shared\n/// access, such as `SpinMutex`.\n#[derive(Default)]\npub struct WaitVariable<T> {\n    queue: WaitQueue,\n    lock: T,\n}\n\nimpl<T> WaitVariable<T> {\n    pub const fn new(var: T) -> Self {\n        WaitVariable { queue: WaitQueue::new(), lock: var }\n    }\n\n    pub fn queue_empty(&self) -> bool {\n        self.queue.is_empty()\n    }\n\n    pub fn lock_var(&self) -> &T {\n        &self.lock\n    }\n\n    pub fn lock_var_mut(&mut self) -> &mut T {\n        &mut self.lock\n    }\n}\n\n#[derive(Copy, Clone)]\npub enum NotifiedTcs {\n    Single(Tcs),\n    All { count: NonZeroUsize },\n}\n\n/// An RAII guard that will notify a set of target threads as well as unlock\n/// a mutex on drop.\npub struct WaitGuard<'a, T: 'a> {\n    mutex_guard: Option<SpinMutexGuard<'a, WaitVariable<T>>>,\n    notified_tcs: NotifiedTcs,\n}\n\n/// A queue of threads that are waiting on some synchronization primitive.\n///\n/// `UnsafeList` entries are allocated on the waiting thread's stack. This\n/// avoids any global locking that might happen in the heap allocator. This is\n/// safe because the waiting thread will not return from that stack frame until\n/// after it is notified. The notifying thread ensures to clean up any\n/// references to the list entries before sending the wakeup event.\npub struct WaitQueue {\n    // We use an inner Mutex here to protect the data in the face of spurious\n    // wakeups.\n    inner: UnsafeList<SpinMutex<WaitEntry>>,\n}\nunsafe impl Send for WaitQueue {}\n\nimpl Default for WaitQueue {\n    fn default() -> Self {\n        Self::new()\n    }\n}\n\nimpl<'a, T> WaitGuard<'a, T> {\n    /// Returns which TCSes will be notified when this guard drops.\n    pub fn notified_tcs(&self) -> NotifiedTcs {\n        self.notified_tcs\n    }\n\n    /// Drop this `WaitGuard`, after dropping another `guard`.\n    pub fn drop_after<U>(self, guard: U) {\n        drop(guard);\n        drop(self);\n    }\n}\n\nimpl<'a, T> Deref for WaitGuard<'a, T> {\n    type Target = SpinMutexGuard<'a, WaitVariable<T>>;\n\n    fn deref(&self) -> &Self::Target {\n        self.mutex_guard.as_ref().unwrap()\n    }\n}\n\nimpl<'a, T> DerefMut for WaitGuard<'a, T> {\n    fn deref_mut(&mut self) -> &mut Self::Target {\n        self.mutex_guard.as_mut().unwrap()\n    }\n}\n\nimpl<'a, T> Drop for WaitGuard<'a, T> {\n    fn drop(&mut self) {\n        drop(self.mutex_guard.take());\n        let target_tcs = match self.notified_tcs {\n            NotifiedTcs::Single(tcs) => Some(tcs),\n            NotifiedTcs::All { .. } => None,\n        };\n        rtunwrap!(Ok, usercalls::send(EV_UNPARK, target_tcs));\n    }\n}\n\nimpl WaitQueue {\n    pub const fn new() -> Self {\n        WaitQueue { inner: UnsafeList::new() }\n    }\n\n    pub fn is_empty(&self) -> bool {\n        self.inner.is_empty()\n    }\n\n    /// Adds the calling thread to the `WaitVariable`'s wait queue, then wait\n    /// until a wakeup event.\n    ///\n    /// This function does not return until this thread has been awoken.\n    pub fn wait<T, F: FnOnce()>(mut guard: SpinMutexGuard<'_, WaitVariable<T>>, before_wait: F) {\n        // very unsafe: check requirements of UnsafeList::push\n        unsafe {\n            let mut entry = UnsafeListEntry::new(SpinMutex::new(WaitEntry {\n                tcs: thread::current(),\n                wake: false,\n            }));\n            let entry = guard.queue.inner.push(&mut entry);\n            drop(guard);\n            before_wait();\n            while !entry.lock().wake {\n                // don't panic, this would invalidate `entry` during unwinding\n                let eventset = rtunwrap!(Ok, usercalls::wait(EV_UNPARK, WAIT_INDEFINITE));\n                rtassert!(eventset & EV_UNPARK == EV_UNPARK);\n            }\n        }\n    }\n\n    /// Adds the calling thread to the `WaitVariable`'s wait queue, then wait\n    /// until a wakeup event or timeout. If event was observed, returns true.\n    /// If not, it will remove the calling thread from the wait queue.\n    pub fn wait_timeout<T, F: FnOnce()>(\n        lock: &SpinMutex<WaitVariable<T>>,\n        timeout: Duration,\n        before_wait: F,\n    ) -> bool {\n        // very unsafe: check requirements of UnsafeList::push\n        unsafe {\n            let mut entry = UnsafeListEntry::new(SpinMutex::new(WaitEntry {\n                tcs: thread::current(),\n                wake: false,\n            }));\n            let entry_lock = lock.lock().queue.inner.push(&mut entry);\n            before_wait();\n            usercalls::wait_timeout(EV_UNPARK, timeout, || entry_lock.lock().wake);\n            // acquire the wait queue's lock first to avoid deadlock.\n            let mut guard = lock.lock();\n            let success = entry_lock.lock().wake;\n            if !success {\n                // nobody is waking us up, so remove our entry from the wait queue.\n                guard.queue.inner.remove(&mut entry);\n            }\n            success\n        }\n    }\n\n    /// Either find the next waiter on the wait queue, or return the mutex\n    /// guard unchanged.\n    ///\n    /// If a waiter is found, a `WaitGuard` is returned which will notify the\n    /// waiter when it is dropped.\n    pub fn notify_one<T>(\n        mut guard: SpinMutexGuard<'_, WaitVariable<T>>,\n    ) -> Result<WaitGuard<'_, T>, SpinMutexGuard<'_, WaitVariable<T>>> {\n        unsafe {\n            if let Some(entry) = guard.queue.inner.pop() {\n                let mut entry_guard = entry.lock();\n                let tcs = entry_guard.tcs;\n                entry_guard.wake = true;\n                drop(entry);\n                Ok(WaitGuard { mutex_guard: Some(guard), notified_tcs: NotifiedTcs::Single(tcs) })\n            } else {\n                Err(guard)\n            }\n        }\n    }\n\n    /// Either find any and all waiters on the wait queue, or return the mutex\n    /// guard unchanged.\n    ///\n    /// If at least one waiter is found, a `WaitGuard` is returned which will\n    /// notify all waiters when it is dropped.\n    pub fn notify_all<T>(\n        mut guard: SpinMutexGuard<'_, WaitVariable<T>>,\n    ) -> Result<WaitGuard<'_, T>, SpinMutexGuard<'_, WaitVariable<T>>> {\n        unsafe {\n            let mut count = 0;\n            while let Some(entry) = guard.queue.inner.pop() {\n                count += 1;\n                let mut entry_guard = entry.lock();\n                entry_guard.wake = true;\n            }\n            if let Some(count) = NonZeroUsize::new(count) {\n                Ok(WaitGuard { mutex_guard: Some(guard), notified_tcs: NotifiedTcs::All { count } })\n            } else {\n                Err(guard)\n            }\n        }\n    }\n}\n"],[2279,"#![allow(deprecated)]\n\nuse super::*;\nuse crate::sync::Arc;\nuse crate::thread;\nuse crate::time::Duration;\n\n#[test]\nfn sleep() {\n    let mutex = Arc::new(SpinMutex::<i32>::default());\n    let mutex2 = mutex.clone();\n    let guard = mutex.lock();\n    let t1 = thread::spawn(move || {\n        *mutex2.lock() = 1;\n    });\n\n    thread::sleep(Duration::from_millis(50));\n\n    assert_eq!(*guard, 0);\n    drop(guard);\n    t1.join().unwrap();\n    assert_eq!(*mutex.lock(), 1);\n}\n"],[2280,"use super::*;\nuse crate::sync::Arc;\nuse crate::thread;\n\n#[test]\nfn queue() {\n    let wq = Arc::new(SpinMutex::<WaitVariable<()>>::default());\n    let wq2 = wq.clone();\n\n    let locked = wq.lock();\n\n    let t1 = thread::spawn(move || {\n        // if we obtain the lock, the main thread should be waiting\n        assert!(WaitQueue::notify_one(wq2.lock()).is_ok());\n    });\n\n    WaitQueue::wait(locked, || {});\n\n    t1.join().unwrap();\n}\n"],[2281,"//! Trivial spinlock-based implementation of `sync::Mutex`.\n// FIXME: Perhaps use Intel TSX to avoid locking?\n\n#[cfg(test)]\nmod tests;\n\nuse crate::cell::UnsafeCell;\nuse crate::hint;\nuse crate::ops::{Deref, DerefMut};\nuse crate::sync::atomic::{AtomicBool, Ordering};\n\n#[derive(Default)]\npub struct SpinMutex<T> {\n    value: UnsafeCell<T>,\n    lock: AtomicBool,\n}\n\nunsafe impl<T: Send> Send for SpinMutex<T> {}\nunsafe impl<T: Send> Sync for SpinMutex<T> {}\n\npub struct SpinMutexGuard<'a, T: 'a> {\n    mutex: &'a SpinMutex<T>,\n}\n\nimpl<'a, T> !Send for SpinMutexGuard<'a, T> {}\nunsafe impl<'a, T: Sync> Sync for SpinMutexGuard<'a, T> {}\n\nimpl<T> SpinMutex<T> {\n    pub const fn new(value: T) -> Self {\n        SpinMutex { value: UnsafeCell::new(value), lock: AtomicBool::new(false) }\n    }\n\n    #[inline(always)]\n    pub fn lock(&self) -> SpinMutexGuard<'_, T> {\n        loop {\n            match self.try_lock() {\n                None => {\n                    while self.lock.load(Ordering::Relaxed) {\n                        hint::spin_loop()\n                    }\n                }\n                Some(guard) => return guard,\n            }\n        }\n    }\n\n    #[inline(always)]\n    pub fn try_lock(&self) -> Option<SpinMutexGuard<'_, T>> {\n        if self.lock.compare_exchange(false, true, Ordering::Acquire, Ordering::Acquire).is_ok() {\n            Some(SpinMutexGuard { mutex: self })\n        } else {\n            None\n        }\n    }\n}\n\n/// Lock the Mutex or return false.\npub macro try_lock_or_false($e:expr) {\n    if let Some(v) = $e.try_lock() { v } else { return false }\n}\n\nimpl<'a, T> Deref for SpinMutexGuard<'a, T> {\n    type Target = T;\n\n    fn deref(&self) -> &T {\n        unsafe { &*self.mutex.value.get() }\n    }\n}\n\nimpl<'a, T> DerefMut for SpinMutexGuard<'a, T> {\n    fn deref_mut(&mut self) -> &mut T {\n        unsafe { &mut *self.mutex.value.get() }\n    }\n}\n\nimpl<'a, T> Drop for SpinMutexGuard<'a, T> {\n    fn drop(&mut self) {\n        self.mutex.lock.store(false, Ordering::Release)\n    }\n}\n"],[2282,"//! A doubly-linked list where callers are in charge of memory allocation\n//! of the nodes in the list.\n\n#[cfg(test)]\nmod tests;\n\nuse crate::mem;\nuse crate::ptr::NonNull;\n\npub struct UnsafeListEntry<T> {\n    next: NonNull<UnsafeListEntry<T>>,\n    prev: NonNull<UnsafeListEntry<T>>,\n    value: Option<T>,\n}\n\nimpl<T> UnsafeListEntry<T> {\n    fn dummy() -> Self {\n        UnsafeListEntry { next: NonNull::dangling(), prev: NonNull::dangling(), value: None }\n    }\n\n    pub fn new(value: T) -> Self {\n        UnsafeListEntry { value: Some(value), ..Self::dummy() }\n    }\n}\n\npub struct UnsafeList<T> {\n    head_tail: NonNull<UnsafeListEntry<T>>,\n    head_tail_entry: Option<UnsafeListEntry<T>>,\n}\n\nimpl<T> UnsafeList<T> {\n    pub const fn new() -> Self {\n        unsafe { UnsafeList { head_tail: NonNull::new_unchecked(1 as _), head_tail_entry: None } }\n    }\n\n    /// # Safety\n    unsafe fn init(&mut self) {\n        if self.head_tail_entry.is_none() {\n            self.head_tail_entry = Some(UnsafeListEntry::dummy());\n            // SAFETY: `head_tail_entry` must be non-null, which it is because we assign it above.\n            self.head_tail =\n                unsafe { NonNull::new_unchecked(self.head_tail_entry.as_mut().unwrap()) };\n            // SAFETY: `self.head_tail` must meet all requirements for a mutable reference.\n            unsafe { self.head_tail.as_mut() }.next = self.head_tail;\n            unsafe { self.head_tail.as_mut() }.prev = self.head_tail;\n        }\n    }\n\n    pub fn is_empty(&self) -> bool {\n        if self.head_tail_entry.is_some() {\n            let first = unsafe { self.head_tail.as_ref() }.next;\n            if first == self.head_tail {\n                // ,-------> /---------\\ next ---,\n                // |         |head_tail|         |\n                // `--- prev \\---------/ <-------`\n                // SAFETY: `self.head_tail` must meet all requirements for a reference.\n                unsafe { rtassert!(self.head_tail.as_ref().prev == first) };\n                true\n            } else {\n                false\n            }\n        } else {\n            true\n        }\n    }\n\n    /// Pushes an entry onto the back of the list.\n    ///\n    /// # Safety\n    ///\n    /// The entry must remain allocated until the entry is removed from the\n    /// list AND the caller who popped is done using the entry. Special\n    /// care must be taken in the caller of `push` to ensure unwinding does\n    /// not destroy the stack frame containing the entry.\n    pub unsafe fn push<'a>(&mut self, entry: &'a mut UnsafeListEntry<T>) -> &'a T {\n        unsafe { self.init() };\n\n        // BEFORE:\n        //     /---------\\ next ---> /---------\\\n        // ... |prev_tail|           |head_tail| ...\n        //     \\---------/ <--- prev \\---------/\n        //\n        // AFTER:\n        //     /---------\\ next ---> /-----\\ next ---> /---------\\\n        // ... |prev_tail|           |entry|           |head_tail| ...\n        //     \\---------/ <--- prev \\-----/ <--- prev \\---------/\n        let mut entry = unsafe { NonNull::new_unchecked(entry) };\n        let mut prev_tail = mem::replace(&mut unsafe { self.head_tail.as_mut() }.prev, entry);\n        // SAFETY: `entry` must meet all requirements for a mutable reference.\n        unsafe { entry.as_mut() }.prev = prev_tail;\n        unsafe { entry.as_mut() }.next = self.head_tail;\n        // SAFETY: `prev_tail` must meet all requirements for a mutable reference.\n        unsafe { prev_tail.as_mut() }.next = entry;\n        // unwrap ok: always `Some` on non-dummy entries\n        unsafe { (*entry.as_ptr()).value.as_ref() }.unwrap()\n    }\n\n    /// Pops an entry from the front of the list.\n    ///\n    /// # Safety\n    ///\n    /// The caller must make sure to synchronize ending the borrow of the\n    /// return value and deallocation of the containing entry.\n    pub unsafe fn pop<'a>(&mut self) -> Option<&'a T> {\n        unsafe { self.init() };\n\n        if self.is_empty() {\n            None\n        } else {\n            // BEFORE:\n            //     /---------\\ next ---> /-----\\ next ---> /------\\\n            // ... |head_tail|           |first|           |second| ...\n            //     \\---------/ <--- prev \\-----/ <--- prev \\------/\n            //\n            // AFTER:\n            //     /---------\\ next ---> /------\\\n            // ... |head_tail|           |second| ...\n            //     \\---------/ <--- prev \\------/\n            let mut first = unsafe { self.head_tail.as_mut() }.next;\n            let mut second = unsafe { first.as_mut() }.next;\n            unsafe { self.head_tail.as_mut() }.next = second;\n            unsafe { second.as_mut() }.prev = self.head_tail;\n            unsafe { first.as_mut() }.next = NonNull::dangling();\n            unsafe { first.as_mut() }.prev = NonNull::dangling();\n            // unwrap ok: always `Some` on non-dummy entries\n            Some(unsafe { (*first.as_ptr()).value.as_ref() }.unwrap())\n        }\n    }\n\n    /// Removes an entry from the list.\n    ///\n    /// # Safety\n    ///\n    /// The caller must ensure that `entry` has been pushed onto `self`\n    /// prior to this call and has not moved since then.\n    pub unsafe fn remove(&mut self, entry: &mut UnsafeListEntry<T>) {\n        rtassert!(!self.is_empty());\n        // BEFORE:\n        //     /----\\ next ---> /-----\\ next ---> /----\\\n        // ... |prev|           |entry|           |next| ...\n        //     \\----/ <--- prev \\-----/ <--- prev \\----/\n        //\n        // AFTER:\n        //     /----\\ next ---> /----\\\n        // ... |prev|           |next| ...\n        //     \\----/ <--- prev \\----/\n        let mut prev = entry.prev;\n        let mut next = entry.next;\n        // SAFETY: `prev` and `next` must meet all requirements for a mutable reference.entry\n        unsafe { prev.as_mut() }.next = next;\n        unsafe { next.as_mut() }.prev = prev;\n        entry.next = NonNull::dangling();\n        entry.prev = NonNull::dangling();\n    }\n}\n"],[2283,"use super::*;\nuse crate::cell::Cell;\n\n/// # Safety\n/// List must be valid.\nunsafe fn assert_empty<T>(list: &mut UnsafeList<T>) {\n    assert!(unsafe { list.pop() }.is_none(), \"assertion failed: list is not empty\");\n}\n\n#[test]\nfn init_empty() {\n    unsafe {\n        assert_empty(&mut UnsafeList::<i32>::new());\n    }\n}\n\n#[test]\nfn push_pop() {\n    unsafe {\n        let mut node = UnsafeListEntry::new(1234);\n        let mut list = UnsafeList::new();\n        assert_eq!(list.push(&mut node), &1234);\n        assert_eq!(list.pop().unwrap(), &1234);\n        assert_empty(&mut list);\n    }\n}\n\n#[test]\nfn push_remove() {\n    unsafe {\n        let mut node = UnsafeListEntry::new(1234);\n        let mut list = UnsafeList::new();\n        assert_eq!(list.push(&mut node), &1234);\n        list.remove(&mut node);\n        assert_empty(&mut list);\n    }\n}\n\n#[test]\nfn push_remove_pop() {\n    unsafe {\n        let mut node1 = UnsafeListEntry::new(11);\n        let mut node2 = UnsafeListEntry::new(12);\n        let mut node3 = UnsafeListEntry::new(13);\n        let mut node4 = UnsafeListEntry::new(14);\n        let mut node5 = UnsafeListEntry::new(15);\n        let mut list = UnsafeList::new();\n        assert_eq!(list.push(&mut node1), &11);\n        assert_eq!(list.push(&mut node2), &12);\n        assert_eq!(list.push(&mut node3), &13);\n        assert_eq!(list.push(&mut node4), &14);\n        assert_eq!(list.push(&mut node5), &15);\n\n        list.remove(&mut node1);\n        assert_eq!(list.pop().unwrap(), &12);\n        list.remove(&mut node3);\n        assert_eq!(list.pop().unwrap(), &14);\n        list.remove(&mut node5);\n        assert_empty(&mut list);\n\n        assert_eq!(list.push(&mut node1), &11);\n        assert_eq!(list.pop().unwrap(), &11);\n        assert_empty(&mut list);\n\n        assert_eq!(list.push(&mut node3), &13);\n        assert_eq!(list.push(&mut node4), &14);\n        list.remove(&mut node3);\n        list.remove(&mut node4);\n        assert_empty(&mut list);\n    }\n}\n\n#[test]\nfn complex_pushes_pops() {\n    unsafe {\n        let mut node1 = UnsafeListEntry::new(1234);\n        let mut node2 = UnsafeListEntry::new(4567);\n        let mut node3 = UnsafeListEntry::new(9999);\n        let mut node4 = UnsafeListEntry::new(8642);\n        let mut list = UnsafeList::new();\n        list.push(&mut node1);\n        list.push(&mut node2);\n        assert_eq!(list.pop().unwrap(), &1234);\n        list.push(&mut node3);\n        assert_eq!(list.pop().unwrap(), &4567);\n        assert_eq!(list.pop().unwrap(), &9999);\n        assert_empty(&mut list);\n        list.push(&mut node4);\n        assert_eq!(list.pop().unwrap(), &8642);\n        assert_empty(&mut list);\n    }\n}\n\n#[test]\nfn cell() {\n    unsafe {\n        let mut node = UnsafeListEntry::new(Cell::new(0));\n        let mut list = UnsafeList::new();\n        let noderef = list.push(&mut node);\n        assert_eq!(noderef.get(), 0);\n        list.pop().unwrap().set(1);\n        assert_empty(&mut list);\n        assert_eq!(noderef.get(), 1);\n    }\n}\n"],[2284,"use crate::convert::TryFrom;\nuse crate::fmt;\nuse crate::io::{self, IoSlice, IoSliceMut};\nuse crate::net::{Ipv4Addr, Ipv6Addr, Shutdown, SocketAddr};\nuse crate::sys::unsupported;\nuse crate::time::Duration;\n\npub struct TcpStream(!);\n\nimpl TcpStream {\n    pub fn connect(_: io::Result<&SocketAddr>) -> io::Result<TcpStream> {\n        unsupported()\n    }\n\n    pub fn connect_timeout(_: &SocketAddr, _: Duration) -> io::Result<TcpStream> {\n        unsupported()\n    }\n\n    pub fn set_read_timeout(&self, _: Option<Duration>) -> io::Result<()> {\n        self.0\n    }\n\n    pub fn set_write_timeout(&self, _: Option<Duration>) -> io::Result<()> {\n        self.0\n    }\n\n    pub fn read_timeout(&self) -> io::Result<Option<Duration>> {\n        self.0\n    }\n\n    pub fn write_timeout(&self) -> io::Result<Option<Duration>> {\n        self.0\n    }\n\n    pub fn peek(&self, _: &mut [u8]) -> io::Result<usize> {\n        self.0\n    }\n\n    pub fn read(&self, _: &mut [u8]) -> io::Result<usize> {\n        self.0\n    }\n\n    pub fn read_vectored(&self, _: &mut [IoSliceMut<'_>]) -> io::Result<usize> {\n        self.0\n    }\n\n    pub fn is_read_vectored(&self) -> bool {\n        self.0\n    }\n\n    pub fn write(&self, _: &[u8]) -> io::Result<usize> {\n        self.0\n    }\n\n    pub fn write_vectored(&self, _: &[IoSlice<'_>]) -> io::Result<usize> {\n        self.0\n    }\n\n    pub fn is_write_vectored(&self) -> bool {\n        self.0\n    }\n\n    pub fn peer_addr(&self) -> io::Result<SocketAddr> {\n        self.0\n    }\n\n    pub fn socket_addr(&self) -> io::Result<SocketAddr> {\n        self.0\n    }\n\n    pub fn shutdown(&self, _: Shutdown) -> io::Result<()> {\n        self.0\n    }\n\n    pub fn duplicate(&self) -> io::Result<TcpStream> {\n        self.0\n    }\n\n    pub fn set_nodelay(&self, _: bool) -> io::Result<()> {\n        self.0\n    }\n\n    pub fn nodelay(&self) -> io::Result<bool> {\n        self.0\n    }\n\n    pub fn set_ttl(&self, _: u32) -> io::Result<()> {\n        self.0\n    }\n\n    pub fn ttl(&self) -> io::Result<u32> {\n        self.0\n    }\n\n    pub fn take_error(&self) -> io::Result<Option<io::Error>> {\n        self.0\n    }\n\n    pub fn set_nonblocking(&self, _: bool) -> io::Result<()> {\n        self.0\n    }\n}\n\nimpl fmt::Debug for TcpStream {\n    fn fmt(&self, _f: &mut fmt::Formatter<'_>) -> fmt::Result {\n        self.0\n    }\n}\n\npub struct TcpListener(!);\n\nimpl TcpListener {\n    pub fn bind(_: io::Result<&SocketAddr>) -> io::Result<TcpListener> {\n        unsupported()\n    }\n\n    pub fn socket_addr(&self) -> io::Result<SocketAddr> {\n        self.0\n    }\n\n    pub fn accept(&self) -> io::Result<(TcpStream, SocketAddr)> {\n        self.0\n    }\n\n    pub fn duplicate(&self) -> io::Result<TcpListener> {\n        self.0\n    }\n\n    pub fn set_ttl(&self, _: u32) -> io::Result<()> {\n        self.0\n    }\n\n    pub fn ttl(&self) -> io::Result<u32> {\n        self.0\n    }\n\n    pub fn set_only_v6(&self, _: bool) -> io::Result<()> {\n        self.0\n    }\n\n    pub fn only_v6(&self) -> io::Result<bool> {\n        self.0\n    }\n\n    pub fn take_error(&self) -> io::Result<Option<io::Error>> {\n        self.0\n    }\n\n    pub fn set_nonblocking(&self, _: bool) -> io::Result<()> {\n        self.0\n    }\n}\n\nimpl fmt::Debug for TcpListener {\n    fn fmt(&self, _f: &mut fmt::Formatter<'_>) -> fmt::Result {\n        self.0\n    }\n}\n\npub struct UdpSocket(!);\n\nimpl UdpSocket {\n    pub fn bind(_: io::Result<&SocketAddr>) -> io::Result<UdpSocket> {\n        unsupported()\n    }\n\n    pub fn peer_addr(&self) -> io::Result<SocketAddr> {\n        self.0\n    }\n\n    pub fn socket_addr(&self) -> io::Result<SocketAddr> {\n        self.0\n    }\n\n    pub fn recv_from(&self, _: &mut [u8]) -> io::Result<(usize, SocketAddr)> {\n        self.0\n    }\n\n    pub fn peek_from(&self, _: &mut [u8]) -> io::Result<(usize, SocketAddr)> {\n        self.0\n    }\n\n    pub fn send_to(&self, _: &[u8], _: &SocketAddr) -> io::Result<usize> {\n        self.0\n    }\n\n    pub fn duplicate(&self) -> io::Result<UdpSocket> {\n        self.0\n    }\n\n    pub fn set_read_timeout(&self, _: Option<Duration>) -> io::Result<()> {\n        self.0\n    }\n\n    pub fn set_write_timeout(&self, _: Option<Duration>) -> io::Result<()> {\n        self.0\n    }\n\n    pub fn read_timeout(&self) -> io::Result<Option<Duration>> {\n        self.0\n    }\n\n    pub fn write_timeout(&self) -> io::Result<Option<Duration>> {\n        self.0\n    }\n\n    pub fn set_broadcast(&self, _: bool) -> io::Result<()> {\n        self.0\n    }\n\n    pub fn broadcast(&self) -> io::Result<bool> {\n        self.0\n    }\n\n    pub fn set_multicast_loop_v4(&self, _: bool) -> io::Result<()> {\n        self.0\n    }\n\n    pub fn multicast_loop_v4(&self) -> io::Result<bool> {\n        self.0\n    }\n\n    pub fn set_multicast_ttl_v4(&self, _: u32) -> io::Result<()> {\n        self.0\n    }\n\n    pub fn multicast_ttl_v4(&self) -> io::Result<u32> {\n        self.0\n    }\n\n    pub fn set_multicast_loop_v6(&self, _: bool) -> io::Result<()> {\n        self.0\n    }\n\n    pub fn multicast_loop_v6(&self) -> io::Result<bool> {\n        self.0\n    }\n\n    pub fn join_multicast_v4(&self, _: &Ipv4Addr, _: &Ipv4Addr) -> io::Result<()> {\n        self.0\n    }\n\n    pub fn join_multicast_v6(&self, _: &Ipv6Addr, _: u32) -> io::Result<()> {\n        self.0\n    }\n\n    pub fn leave_multicast_v4(&self, _: &Ipv4Addr, _: &Ipv4Addr) -> io::Result<()> {\n        self.0\n    }\n\n    pub fn leave_multicast_v6(&self, _: &Ipv6Addr, _: u32) -> io::Result<()> {\n        self.0\n    }\n\n    pub fn set_ttl(&self, _: u32) -> io::Result<()> {\n        self.0\n    }\n\n    pub fn ttl(&self) -> io::Result<u32> {\n        self.0\n    }\n\n    pub fn take_error(&self) -> io::Result<Option<io::Error>> {\n        self.0\n    }\n\n    pub fn set_nonblocking(&self, _: bool) -> io::Result<()> {\n        self.0\n    }\n\n    pub fn recv(&self, _: &mut [u8]) -> io::Result<usize> {\n        self.0\n    }\n\n    pub fn peek(&self, _: &mut [u8]) -> io::Result<usize> {\n        self.0\n    }\n\n    pub fn send(&self, _: &[u8]) -> io::Result<usize> {\n        self.0\n    }\n\n    pub fn connect(&self, _: io::Result<&SocketAddr>) -> io::Result<()> {\n        self.0\n    }\n}\n\nimpl fmt::Debug for UdpSocket {\n    fn fmt(&self, _f: &mut fmt::Formatter<'_>) -> fmt::Result {\n        self.0\n    }\n}\n\npub struct LookupHost(!);\n\nimpl LookupHost {\n    pub fn port(&self) -> u16 {\n        self.0\n    }\n}\n\nimpl Iterator for LookupHost {\n    type Item = SocketAddr;\n    fn next(&mut self) -> Option<SocketAddr> {\n        self.0\n    }\n}\n\nimpl TryFrom<&str> for LookupHost {\n    type Error = io::Error;\n\n    fn try_from(_v: &str) -> io::Result<LookupHost> {\n        unsupported()\n    }\n}\n\nimpl<'a> TryFrom<(&'a str, u16)> for LookupHost {\n    type Error = io::Error;\n\n    fn try_from(_v: (&'a str, u16)) -> io::Result<LookupHost> {\n        unsupported()\n    }\n}\n\n#[allow(nonstandard_style)]\npub mod netc {\n    pub const AF_INET: u8 = 0;\n    pub const AF_INET6: u8 = 1;\n    pub type sa_family_t = u8;\n\n    #[derive(Copy, Clone)]\n    pub struct in_addr {\n        pub s_addr: u32,\n    }\n\n    #[derive(Copy, Clone)]\n    pub struct sockaddr_in {\n        pub sin_family: sa_family_t,\n        pub sin_port: u16,\n        pub sin_addr: in_addr,\n    }\n\n    #[derive(Copy, Clone)]\n    pub struct in6_addr {\n        pub s6_addr: [u8; 16],\n    }\n\n    #[derive(Copy, Clone)]\n    pub struct sockaddr_in6 {\n        pub sin6_family: sa_family_t,\n        pub sin6_port: u16,\n        pub sin6_addr: in6_addr,\n        pub sin6_flowinfo: u32,\n        pub sin6_scope_id: u32,\n    }\n\n    #[derive(Copy, Clone)]\n    pub struct sockaddr {}\n\n    pub type socklen_t = usize;\n}\n"],[2285,"#![deny(unsafe_op_in_unsafe_fn)]\n\npub mod alloc;\npub mod args;\n#[path = \"../unix/cmath.rs\"]\npub mod cmath;\npub mod condvar;\npub mod env;\npub mod fs;\npub mod io;\npub mod mutex;\npub mod net;\npub mod os;\n#[path = \"../unix/path.rs\"]\npub mod path;\npub mod pipe;\npub mod process;\npub mod rwlock;\npub mod stdio;\npub mod thread;\n#[cfg(target_thread_local)]\npub mod thread_local_dtor;\npub mod thread_local_key;\npub mod time;\n\nmod common;\npub use common::*;\n"],[2286,"use crate::cell::Cell;\n\npub struct Mutex {\n    // This platform has no threads, so we can use a Cell here.\n    locked: Cell<bool>,\n}\n\npub type MovableMutex = Mutex;\n\nunsafe impl Send for Mutex {}\nunsafe impl Sync for Mutex {} // no threads on this platform\n\nimpl Mutex {\n    pub const fn new() -> Mutex {\n        Mutex { locked: Cell::new(false) }\n    }\n\n    #[inline]\n    pub unsafe fn init(&mut self) {}\n\n    #[inline]\n    pub unsafe fn lock(&self) {\n        assert_eq!(self.locked.replace(true), false, \"cannot recursively acquire mutex\");\n    }\n\n    #[inline]\n    pub unsafe fn unlock(&self) {\n        self.locked.set(false);\n    }\n\n    #[inline]\n    pub unsafe fn try_lock(&self) -> bool {\n        self.locked.replace(true) == false\n    }\n\n    #[inline]\n    pub unsafe fn destroy(&self) {}\n}\n\n// All empty stubs because this platform does not yet support threads, so lock\n// acquisition always succeeds.\npub struct ReentrantMutex {}\n\nimpl ReentrantMutex {\n    pub const unsafe fn uninitialized() -> ReentrantMutex {\n        ReentrantMutex {}\n    }\n\n    pub unsafe fn init(&self) {}\n\n    pub unsafe fn lock(&self) {}\n\n    #[inline]\n    pub unsafe fn try_lock(&self) -> bool {\n        true\n    }\n\n    pub unsafe fn unlock(&self) {}\n\n    pub unsafe fn destroy(&self) {}\n}\n"],[2287,"use super::unsupported;\nuse crate::error::Error as StdError;\nuse crate::ffi::{OsStr, OsString};\nuse crate::fmt;\nuse crate::io;\nuse crate::marker::PhantomData;\nuse crate::path::{self, PathBuf};\n\npub fn errno() -> i32 {\n    0\n}\n\npub fn error_string(_errno: i32) -> String {\n    \"operation successful\".to_string()\n}\n\npub fn getcwd() -> io::Result<PathBuf> {\n    unsupported()\n}\n\npub fn chdir(_: &path::Path) -> io::Result<()> {\n    unsupported()\n}\n\npub struct SplitPaths<'a>(!, PhantomData<&'a ()>);\n\npub fn split_paths(_unparsed: &OsStr) -> SplitPaths<'_> {\n    panic!(\"unsupported\")\n}\n\nimpl<'a> Iterator for SplitPaths<'a> {\n    type Item = PathBuf;\n    fn next(&mut self) -> Option<PathBuf> {\n        self.0\n    }\n}\n\n#[derive(Debug)]\npub struct JoinPathsError;\n\npub fn join_paths<I, T>(_paths: I) -> Result<OsString, JoinPathsError>\nwhere\n    I: Iterator<Item = T>,\n    T: AsRef<OsStr>,\n{\n    Err(JoinPathsError)\n}\n\nimpl fmt::Display for JoinPathsError {\n    fn fmt(&self, f: &mut fmt::Formatter<'_>) -> fmt::Result {\n        \"not supported on this platform yet\".fmt(f)\n    }\n}\n\nimpl StdError for JoinPathsError {\n    #[allow(deprecated)]\n    fn description(&self) -> &str {\n        \"not supported on this platform yet\"\n    }\n}\n\npub fn current_exe() -> io::Result<PathBuf> {\n    unsupported()\n}\n\npub struct Env(!);\n\nimpl Iterator for Env {\n    type Item = (OsString, OsString);\n    fn next(&mut self) -> Option<(OsString, OsString)> {\n        self.0\n    }\n}\n\npub fn env() -> Env {\n    panic!(\"not supported on this platform\")\n}\n\npub fn getenv(_: &OsStr) -> io::Result<Option<OsString>> {\n    Ok(None)\n}\n\npub fn setenv(_: &OsStr, _: &OsStr) -> io::Result<()> {\n    Err(io::Error::new_const(io::ErrorKind::Unsupported, &\"cannot set env vars on this platform\"))\n}\n\npub fn unsetenv(_: &OsStr) -> io::Result<()> {\n    Err(io::Error::new_const(io::ErrorKind::Unsupported, &\"cannot unset env vars on this platform\"))\n}\n\npub fn temp_dir() -> PathBuf {\n    panic!(\"no filesystem on this platform\")\n}\n\npub fn home_dir() -> Option<PathBuf> {\n    None\n}\n\npub fn exit(_code: i32) -> ! {\n    crate::intrinsics::abort()\n}\n\npub fn getpid() -> u32 {\n    panic!(\"no pids on this platform\")\n}\n"],[2288,"pub mod os {\n    pub const FAMILY: &str = \"\";\n    pub const OS: &str = \"\";\n    pub const DLL_PREFIX: &str = \"\";\n    pub const DLL_SUFFIX: &str = \"\";\n    pub const DLL_EXTENSION: &str = \"\";\n    pub const EXE_SUFFIX: &str = \"\";\n    pub const EXE_EXTENSION: &str = \"\";\n}\n"],[2289,"use crate::ffi::OsString;\nuse crate::fmt;\nuse crate::hash::{Hash, Hasher};\nuse crate::io::{self, IoSlice, IoSliceMut, SeekFrom};\nuse crate::path::{Path, PathBuf};\nuse crate::sys::time::SystemTime;\nuse crate::sys::unsupported;\n\npub struct File(!);\n\npub struct FileAttr(!);\n\npub struct ReadDir(!);\n\npub struct DirEntry(!);\n\n#[derive(Clone, Debug)]\npub struct OpenOptions {}\n\npub struct FilePermissions(!);\n\npub struct FileType(!);\n\n#[derive(Debug)]\npub struct DirBuilder {}\n\nimpl FileAttr {\n    pub fn size(&self) -> u64 {\n        self.0\n    }\n\n    pub fn perm(&self) -> FilePermissions {\n        self.0\n    }\n\n    pub fn file_type(&self) -> FileType {\n        self.0\n    }\n\n    pub fn modified(&self) -> io::Result<SystemTime> {\n        self.0\n    }\n\n    pub fn accessed(&self) -> io::Result<SystemTime> {\n        self.0\n    }\n\n    pub fn created(&self) -> io::Result<SystemTime> {\n        self.0\n    }\n}\n\nimpl Clone for FileAttr {\n    fn clone(&self) -> FileAttr {\n        self.0\n    }\n}\n\nimpl FilePermissions {\n    pub fn readonly(&self) -> bool {\n        self.0\n    }\n\n    pub fn set_readonly(&mut self, _readonly: bool) {\n        self.0\n    }\n}\n\nimpl Clone for FilePermissions {\n    fn clone(&self) -> FilePermissions {\n        self.0\n    }\n}\n\nimpl PartialEq for FilePermissions {\n    fn eq(&self, _other: &FilePermissions) -> bool {\n        self.0\n    }\n}\n\nimpl Eq for FilePermissions {}\n\nimpl fmt::Debug for FilePermissions {\n    fn fmt(&self, _f: &mut fmt::Formatter<'_>) -> fmt::Result {\n        self.0\n    }\n}\n\nimpl FileType {\n    pub fn is_dir(&self) -> bool {\n        self.0\n    }\n\n    pub fn is_file(&self) -> bool {\n        self.0\n    }\n\n    pub fn is_symlink(&self) -> bool {\n        self.0\n    }\n}\n\nimpl Clone for FileType {\n    fn clone(&self) -> FileType {\n        self.0\n    }\n}\n\nimpl Copy for FileType {}\n\nimpl PartialEq for FileType {\n    fn eq(&self, _other: &FileType) -> bool {\n        self.0\n    }\n}\n\nimpl Eq for FileType {}\n\nimpl Hash for FileType {\n    fn hash<H: Hasher>(&self, _h: &mut H) {\n        self.0\n    }\n}\n\nimpl fmt::Debug for FileType {\n    fn fmt(&self, _f: &mut fmt::Formatter<'_>) -> fmt::Result {\n        self.0\n    }\n}\n\nimpl fmt::Debug for ReadDir {\n    fn fmt(&self, _f: &mut fmt::Formatter<'_>) -> fmt::Result {\n        self.0\n    }\n}\n\nimpl Iterator for ReadDir {\n    type Item = io::Result<DirEntry>;\n\n    fn next(&mut self) -> Option<io::Result<DirEntry>> {\n        self.0\n    }\n}\n\nimpl DirEntry {\n    pub fn path(&self) -> PathBuf {\n        self.0\n    }\n\n    pub fn file_name(&self) -> OsString {\n        self.0\n    }\n\n    pub fn metadata(&self) -> io::Result<FileAttr> {\n        self.0\n    }\n\n    pub fn file_type(&self) -> io::Result<FileType> {\n        self.0\n    }\n}\n\nimpl OpenOptions {\n    pub fn new() -> OpenOptions {\n        OpenOptions {}\n    }\n\n    pub fn read(&mut self, _read: bool) {}\n    pub fn write(&mut self, _write: bool) {}\n    pub fn append(&mut self, _append: bool) {}\n    pub fn truncate(&mut self, _truncate: bool) {}\n    pub fn create(&mut self, _create: bool) {}\n    pub fn create_new(&mut self, _create_new: bool) {}\n}\n\nimpl File {\n    pub fn open(_path: &Path, _opts: &OpenOptions) -> io::Result<File> {\n        unsupported()\n    }\n\n    pub fn file_attr(&self) -> io::Result<FileAttr> {\n        self.0\n    }\n\n    pub fn fsync(&self) -> io::Result<()> {\n        self.0\n    }\n\n    pub fn datasync(&self) -> io::Result<()> {\n        self.0\n    }\n\n    pub fn truncate(&self, _size: u64) -> io::Result<()> {\n        self.0\n    }\n\n    pub fn read(&self, _buf: &mut [u8]) -> io::Result<usize> {\n        self.0\n    }\n\n    pub fn read_vectored(&self, _bufs: &mut [IoSliceMut<'_>]) -> io::Result<usize> {\n        self.0\n    }\n\n    pub fn is_read_vectored(&self) -> bool {\n        self.0\n    }\n\n    pub fn write(&self, _buf: &[u8]) -> io::Result<usize> {\n        self.0\n    }\n\n    pub fn write_vectored(&self, _bufs: &[IoSlice<'_>]) -> io::Result<usize> {\n        self.0\n    }\n\n    pub fn is_write_vectored(&self) -> bool {\n        self.0\n    }\n\n    pub fn flush(&self) -> io::Result<()> {\n        self.0\n    }\n\n    pub fn seek(&self, _pos: SeekFrom) -> io::Result<u64> {\n        self.0\n    }\n\n    pub fn duplicate(&self) -> io::Result<File> {\n        self.0\n    }\n\n    pub fn set_permissions(&self, _perm: FilePermissions) -> io::Result<()> {\n        self.0\n    }\n}\n\nimpl DirBuilder {\n    pub fn new() -> DirBuilder {\n        DirBuilder {}\n    }\n\n    pub fn mkdir(&self, _p: &Path) -> io::Result<()> {\n        unsupported()\n    }\n}\n\nimpl fmt::Debug for File {\n    fn fmt(&self, _f: &mut fmt::Formatter<'_>) -> fmt::Result {\n        self.0\n    }\n}\n\npub fn readdir(_p: &Path) -> io::Result<ReadDir> {\n    unsupported()\n}\n\npub fn unlink(_p: &Path) -> io::Result<()> {\n    unsupported()\n}\n\npub fn rename(_old: &Path, _new: &Path) -> io::Result<()> {\n    unsupported()\n}\n\npub fn set_perm(_p: &Path, perm: FilePermissions) -> io::Result<()> {\n    match perm.0 {}\n}\n\npub fn rmdir(_p: &Path) -> io::Result<()> {\n    unsupported()\n}\n\npub fn remove_dir_all(_path: &Path) -> io::Result<()> {\n    unsupported()\n}\n\npub fn try_exists(_path: &Path) -> io::Result<bool> {\n    unsupported()\n}\n\npub fn readlink(_p: &Path) -> io::Result<PathBuf> {\n    unsupported()\n}\n\npub fn symlink(_original: &Path, _link: &Path) -> io::Result<()> {\n    unsupported()\n}\n\npub fn link(_src: &Path, _dst: &Path) -> io::Result<()> {\n    unsupported()\n}\n\npub fn stat(_p: &Path) -> io::Result<FileAttr> {\n    unsupported()\n}\n\npub fn lstat(_p: &Path) -> io::Result<FileAttr> {\n    unsupported()\n}\n\npub fn canonicalize(_p: &Path) -> io::Result<PathBuf> {\n    unsupported()\n}\n\npub fn copy(_from: &Path, _to: &Path) -> io::Result<u64> {\n    unsupported()\n}\n"],[2290,"use crate::ffi::OsStr;\nuse crate::fmt;\nuse crate::io;\nuse crate::marker::PhantomData;\nuse crate::num::NonZeroI32;\nuse crate::path::Path;\nuse crate::sys::fs::File;\nuse crate::sys::pipe::AnonPipe;\nuse crate::sys::unsupported;\nuse crate::sys_common::process::{CommandEnv, CommandEnvs};\n\npub use crate::ffi::OsString as EnvKey;\n\n////////////////////////////////////////////////////////////////////////////////\n// Command\n////////////////////////////////////////////////////////////////////////////////\n\npub struct Command {\n    env: CommandEnv,\n}\n\n// passed back to std::process with the pipes connected to the child, if any\n// were requested\npub struct StdioPipes {\n    pub stdin: Option<AnonPipe>,\n    pub stdout: Option<AnonPipe>,\n    pub stderr: Option<AnonPipe>,\n}\n\npub enum Stdio {\n    Inherit,\n    Null,\n    MakePipe,\n}\n\nimpl Command {\n    pub fn new(_program: &OsStr) -> Command {\n        Command { env: Default::default() }\n    }\n\n    pub fn arg(&mut self, _arg: &OsStr) {}\n\n    pub fn env_mut(&mut self) -> &mut CommandEnv {\n        &mut self.env\n    }\n\n    pub fn cwd(&mut self, _dir: &OsStr) {}\n\n    pub fn stdin(&mut self, _stdin: Stdio) {}\n\n    pub fn stdout(&mut self, _stdout: Stdio) {}\n\n    pub fn stderr(&mut self, _stderr: Stdio) {}\n\n    pub fn get_program(&self) -> &OsStr {\n        panic!(\"unsupported\")\n    }\n\n    pub fn get_args(&self) -> CommandArgs<'_> {\n        CommandArgs { _p: PhantomData }\n    }\n\n    pub fn get_envs(&self) -> CommandEnvs<'_> {\n        self.env.iter()\n    }\n\n    pub fn get_current_dir(&self) -> Option<&Path> {\n        None\n    }\n\n    pub fn spawn(\n        &mut self,\n        _default: Stdio,\n        _needs_stdin: bool,\n    ) -> io::Result<(Process, StdioPipes)> {\n        unsupported()\n    }\n}\n\nimpl From<AnonPipe> for Stdio {\n    fn from(pipe: AnonPipe) -> Stdio {\n        pipe.diverge()\n    }\n}\n\nimpl From<File> for Stdio {\n    fn from(_file: File) -> Stdio {\n        panic!(\"unsupported\")\n    }\n}\n\nimpl fmt::Debug for Command {\n    fn fmt(&self, _f: &mut fmt::Formatter<'_>) -> fmt::Result {\n        Ok(())\n    }\n}\n\npub struct ExitStatus(!);\n\nimpl ExitStatus {\n    pub fn exit_ok(&self) -> Result<(), ExitStatusError> {\n        self.0\n    }\n\n    pub fn code(&self) -> Option<i32> {\n        self.0\n    }\n}\n\nimpl Clone for ExitStatus {\n    fn clone(&self) -> ExitStatus {\n        self.0\n    }\n}\n\nimpl Copy for ExitStatus {}\n\nimpl PartialEq for ExitStatus {\n    fn eq(&self, _other: &ExitStatus) -> bool {\n        self.0\n    }\n}\n\nimpl Eq for ExitStatus {}\n\nimpl fmt::Debug for ExitStatus {\n    fn fmt(&self, _f: &mut fmt::Formatter<'_>) -> fmt::Result {\n        self.0\n    }\n}\n\nimpl fmt::Display for ExitStatus {\n    fn fmt(&self, _f: &mut fmt::Formatter<'_>) -> fmt::Result {\n        self.0\n    }\n}\n\n#[derive(PartialEq, Eq, Clone, Copy, Debug)]\npub struct ExitStatusError(ExitStatus);\n\nimpl Into<ExitStatus> for ExitStatusError {\n    fn into(self) -> ExitStatus {\n        self.0.0\n    }\n}\n\nimpl ExitStatusError {\n    pub fn code(self) -> Option<NonZeroI32> {\n        self.0.0\n    }\n}\n\n#[derive(PartialEq, Eq, Clone, Copy, Debug)]\npub struct ExitCode(bool);\n\nimpl ExitCode {\n    pub const SUCCESS: ExitCode = ExitCode(false);\n    pub const FAILURE: ExitCode = ExitCode(true);\n\n    pub fn as_i32(&self) -> i32 {\n        self.0 as i32\n    }\n}\n\npub struct Process(!);\n\nimpl Process {\n    pub fn id(&self) -> u32 {\n        self.0\n    }\n\n    pub fn kill(&mut self) -> io::Result<()> {\n        self.0\n    }\n\n    pub fn wait(&mut self) -> io::Result<ExitStatus> {\n        self.0\n    }\n\n    pub fn try_wait(&mut self) -> io::Result<Option<ExitStatus>> {\n        self.0\n    }\n}\n\npub struct CommandArgs<'a> {\n    _p: PhantomData<&'a ()>,\n}\n\nimpl<'a> Iterator for CommandArgs<'a> {\n    type Item = &'a OsStr;\n    fn next(&mut self) -> Option<&'a OsStr> {\n        None\n    }\n}\n\nimpl<'a> ExactSizeIterator for CommandArgs<'a> {}\n\nimpl<'a> fmt::Debug for CommandArgs<'a> {\n    fn fmt(&self, f: &mut fmt::Formatter<'_>) -> fmt::Result {\n        f.debug_list().finish()\n    }\n}\n"],[2291,"use crate::sys::mutex::Mutex;\nuse crate::time::Duration;\n\npub struct Condvar {}\n\npub type MovableCondvar = Condvar;\n\nimpl Condvar {\n    pub const fn new() -> Condvar {\n        Condvar {}\n    }\n\n    #[inline]\n    pub unsafe fn init(&mut self) {}\n\n    #[inline]\n    pub unsafe fn notify_one(&self) {}\n\n    #[inline]\n    pub unsafe fn notify_all(&self) {}\n\n    pub unsafe fn wait(&self, _mutex: &Mutex) {\n        panic!(\"condvar wait not supported\")\n    }\n\n    pub unsafe fn wait_timeout(&self, _mutex: &Mutex, _dur: Duration) -> bool {\n        panic!(\"condvar wait not supported\");\n    }\n\n    #[inline]\n    pub unsafe fn destroy(&self) {}\n}\n"],[2292,"use crate::io::{self, IoSlice, IoSliceMut};\n\npub struct AnonPipe(!);\n\nimpl AnonPipe {\n    pub fn read(&self, _buf: &mut [u8]) -> io::Result<usize> {\n        self.0\n    }\n\n    pub fn read_vectored(&self, _bufs: &mut [IoSliceMut<'_>]) -> io::Result<usize> {\n        self.0\n    }\n\n    pub fn is_read_vectored(&self) -> bool {\n        self.0\n    }\n\n    pub fn write(&self, _buf: &[u8]) -> io::Result<usize> {\n        self.0\n    }\n\n    pub fn write_vectored(&self, _bufs: &[IoSlice<'_>]) -> io::Result<usize> {\n        self.0\n    }\n\n    pub fn is_write_vectored(&self) -> bool {\n        self.0\n    }\n\n    pub fn diverge(&self) -> ! {\n        self.0\n    }\n}\n\npub fn read2(p1: AnonPipe, _v1: &mut Vec<u8>, _p2: AnonPipe, _v2: &mut Vec<u8>) -> io::Result<()> {\n    match p1.0 {}\n}\n"],[2293,"pub type Key = usize;\n\n#[inline]\npub unsafe fn create(_dtor: Option<unsafe extern \"C\" fn(*mut u8)>) -> Key {\n    panic!(\"should not be used on this target\");\n}\n\n#[inline]\npub unsafe fn set(_key: Key, _value: *mut u8) {\n    panic!(\"should not be used on this target\");\n}\n\n#[inline]\npub unsafe fn get(_key: Key) -> *mut u8 {\n    panic!(\"should not be used on this target\");\n}\n\n#[inline]\npub unsafe fn destroy(_key: Key) {\n    panic!(\"should not be used on this target\");\n}\n\n#[inline]\npub fn requires_synchronized_create() -> bool {\n    panic!(\"should not be used on this target\");\n}\n"],[2294,"use crate::io as std_io;\n\npub mod memchr {\n    pub use core::slice::memchr::{memchr, memrchr};\n}\n\npub use crate::sys_common::os_str_bytes as os_str;\n\n// This is not necessarily correct. May want to consider making it part of the\n// spec definition?\nuse crate::os::raw::c_char;\n\n// SAFETY: must be called only once during runtime initialization.\n// NOTE: this is not guaranteed to run, for example when Rust code is called externally.\npub unsafe fn init(_argc: isize, _argv: *const *const u8) {}\n\n// SAFETY: must be called only once during runtime cleanup.\n// NOTE: this is not guaranteed to run, for example when the program aborts.\npub unsafe fn cleanup() {}\n\npub fn unsupported<T>() -> std_io::Result<T> {\n    Err(unsupported_err())\n}\n\npub fn unsupported_err() -> std_io::Error {\n    std_io::Error::new_const(\n        std_io::ErrorKind::Unsupported,\n        &\"operation not supported on this platform\",\n    )\n}\n\npub fn decode_error_kind(_code: i32) -> crate::io::ErrorKind {\n    crate::io::ErrorKind::Other\n}\n\npub fn abort_internal() -> ! {\n    core::intrinsics::abort();\n}\n\npub fn hashmap_random_keys() -> (u64, u64) {\n    (1, 2)\n}\n\npub unsafe fn strlen(mut s: *const c_char) -> usize {\n    // SAFETY: The caller must guarantee `s` points to a valid 0-terminated string.\n    unsafe {\n        let mut n = 0;\n        while *s != 0 {\n            n += 1;\n            s = s.offset(1);\n        }\n        n\n    }\n}\n"],[2295,"use super::unsupported;\nuse crate::ffi::CStr;\nuse crate::io;\nuse crate::num::NonZeroUsize;\nuse crate::time::Duration;\n\npub struct Thread(!);\n\npub const DEFAULT_MIN_STACK_SIZE: usize = 4096;\n\nimpl Thread {\n    // unsafe: see thread::Builder::spawn_unchecked for safety requirements\n    pub unsafe fn new(_stack: usize, _p: Box<dyn FnOnce()>) -> io::Result<Thread> {\n        unsupported()\n    }\n\n    pub fn yield_now() {\n        // do nothing\n    }\n\n    pub fn set_name(_name: &CStr) {\n        // nope\n    }\n\n    pub fn sleep(_dur: Duration) {\n        panic!(\"can't sleep\");\n    }\n\n    pub fn join(self) {\n        self.0\n    }\n}\n\npub fn available_concurrency() -> io::Result<NonZeroUsize> {\n    unsupported()\n}\n\npub mod guard {\n    pub type Guard = !;\n    pub unsafe fn current() -> Option<Guard> {\n        None\n    }\n    pub unsafe fn init() -> Option<Guard> {\n        None\n    }\n}\n"],[2296,"use crate::ffi::OsString;\nuse crate::fmt;\n\npub struct Args {}\n\npub fn args() -> Args {\n    Args {}\n}\n\nimpl fmt::Debug for Args {\n    fn fmt(&self, f: &mut fmt::Formatter<'_>) -> fmt::Result {\n        f.debug_list().finish()\n    }\n}\n\nimpl Iterator for Args {\n    type Item = OsString;\n    fn next(&mut self) -> Option<OsString> {\n        None\n    }\n    fn size_hint(&self) -> (usize, Option<usize>) {\n        (0, Some(0))\n    }\n}\n\nimpl ExactSizeIterator for Args {\n    fn len(&self) -> usize {\n        0\n    }\n}\n\nimpl DoubleEndedIterator for Args {\n    fn next_back(&mut self) -> Option<OsString> {\n        None\n    }\n}\n"],[2297,"use crate::time::Duration;\n\n#[derive(Copy, Clone, PartialEq, Eq, PartialOrd, Ord, Debug, Hash)]\npub struct Instant(Duration);\n\n#[derive(Copy, Clone, PartialEq, Eq, PartialOrd, Ord, Debug, Hash)]\npub struct SystemTime(Duration);\n\npub const UNIX_EPOCH: SystemTime = SystemTime(Duration::from_secs(0));\n\nimpl Instant {\n    pub fn now() -> Instant {\n        panic!(\"time not implemented on this platform\")\n    }\n\n    pub const fn zero() -> Instant {\n        Instant(Duration::from_secs(0))\n    }\n\n    pub fn actually_monotonic() -> bool {\n        false\n    }\n\n    pub fn checked_sub_instant(&self, other: &Instant) -> Option<Duration> {\n        self.0.checked_sub(other.0)\n    }\n\n    pub fn checked_add_duration(&self, other: &Duration) -> Option<Instant> {\n        Some(Instant(self.0.checked_add(*other)?))\n    }\n\n    pub fn checked_sub_duration(&self, other: &Duration) -> Option<Instant> {\n        Some(Instant(self.0.checked_sub(*other)?))\n    }\n}\n\nimpl SystemTime {\n    pub fn now() -> SystemTime {\n        panic!(\"time not implemented on this platform\")\n    }\n\n    pub fn sub_time(&self, other: &SystemTime) -> Result<Duration, Duration> {\n        self.0.checked_sub(other.0).ok_or_else(|| other.0 - self.0)\n    }\n\n    pub fn checked_add_duration(&self, other: &Duration) -> Option<SystemTime> {\n        Some(SystemTime(self.0.checked_add(*other)?))\n    }\n\n    pub fn checked_sub_duration(&self, other: &Duration) -> Option<SystemTime> {\n        Some(SystemTime(self.0.checked_sub(*other)?))\n    }\n}\n"],[2298,"use crate::io;\n\npub struct Stdin;\npub struct Stdout;\npub struct Stderr;\n\nimpl Stdin {\n    pub const fn new() -> Stdin {\n        Stdin\n    }\n}\n\nimpl io::Read for Stdin {\n    fn read(&mut self, _buf: &mut [u8]) -> io::Result<usize> {\n        Ok(0)\n    }\n}\n\nimpl Stdout {\n    pub const fn new() -> Stdout {\n        Stdout\n    }\n}\n\nimpl io::Write for Stdout {\n    fn write(&mut self, buf: &[u8]) -> io::Result<usize> {\n        Ok(buf.len())\n    }\n\n    fn flush(&mut self) -> io::Result<()> {\n        Ok(())\n    }\n}\n\nimpl Stderr {\n    pub const fn new() -> Stderr {\n        Stderr\n    }\n}\n\nimpl io::Write for Stderr {\n    fn write(&mut self, buf: &[u8]) -> io::Result<usize> {\n        Ok(buf.len())\n    }\n\n    fn flush(&mut self) -> io::Result<()> {\n        Ok(())\n    }\n}\n\npub const STDIN_BUF_SIZE: usize = 0;\n\npub fn is_ebadf(_err: &io::Error) -> bool {\n    true\n}\n\npub fn panic_output() -> Option<Vec<u8>> {\n    None\n}\n"],[2299,"use crate::mem;\n\n#[derive(Copy, Clone)]\npub struct IoSlice<'a>(&'a [u8]);\n\nimpl<'a> IoSlice<'a> {\n    #[inline]\n    pub fn new(buf: &'a [u8]) -> IoSlice<'a> {\n        IoSlice(buf)\n    }\n\n    #[inline]\n    pub fn advance(&mut self, n: usize) {\n        self.0 = &self.0[n..]\n    }\n\n    #[inline]\n    pub fn as_slice(&self) -> &[u8] {\n        self.0\n    }\n}\n\npub struct IoSliceMut<'a>(&'a mut [u8]);\n\nimpl<'a> IoSliceMut<'a> {\n    #[inline]\n    pub fn new(buf: &'a mut [u8]) -> IoSliceMut<'a> {\n        IoSliceMut(buf)\n    }\n\n    #[inline]\n    pub fn advance(&mut self, n: usize) {\n        let slice = mem::replace(&mut self.0, &mut []);\n        let (_, remaining) = slice.split_at_mut(n);\n        self.0 = remaining;\n    }\n\n    #[inline]\n    pub fn as_slice(&self) -> &[u8] {\n        self.0\n    }\n\n    #[inline]\n    pub fn as_mut_slice(&mut self) -> &mut [u8] {\n        self.0\n    }\n}\n"],[2300,"#![unstable(feature = \"thread_local_internals\", issue = \"none\")]\n\npub unsafe fn register_dtor(_t: *mut u8, _dtor: unsafe extern \"C\" fn(*mut u8)) {\n    // FIXME: right now there is no concept of \"thread exit\", but this is likely\n    // going to show up at some point in the form of an exported symbol that the\n    // wasm runtime is going to be expected to call. For now we basically just\n    // ignore the arguments, but if such a function starts to exist it will\n    // likely look like the OSX implementation in `unix/fast_thread_local.rs`\n}\n"],[2301,"use crate::alloc::{GlobalAlloc, Layout, System};\n\n#[stable(feature = \"alloc_system_type\", since = \"1.28.0\")]\nunsafe impl GlobalAlloc for System {\n    #[inline]\n    unsafe fn alloc(&self, _layout: Layout) -> *mut u8 {\n        0 as *mut u8\n    }\n\n    #[inline]\n    unsafe fn alloc_zeroed(&self, _layout: Layout) -> *mut u8 {\n        0 as *mut u8\n    }\n\n    #[inline]\n    unsafe fn dealloc(&self, _ptr: *mut u8, _layout: Layout) {}\n\n    #[inline]\n    unsafe fn realloc(&self, _ptr: *mut u8, _layout: Layout, _new_size: usize) -> *mut u8 {\n        0 as *mut u8\n    }\n}\n"],[2302,"use crate::cell::Cell;\n\npub struct RWLock {\n    // This platform has no threads, so we can use a Cell here.\n    mode: Cell<isize>,\n}\n\npub type MovableRWLock = RWLock;\n\nunsafe impl Send for RWLock {}\nunsafe impl Sync for RWLock {} // no threads on this platform\n\nimpl RWLock {\n    pub const fn new() -> RWLock {\n        RWLock { mode: Cell::new(0) }\n    }\n\n    #[inline]\n    pub unsafe fn read(&self) {\n        let m = self.mode.get();\n        if m >= 0 {\n            self.mode.set(m + 1);\n        } else {\n            rtabort!(\"rwlock locked for writing\");\n        }\n    }\n\n    #[inline]\n    pub unsafe fn try_read(&self) -> bool {\n        let m = self.mode.get();\n        if m >= 0 {\n            self.mode.set(m + 1);\n            true\n        } else {\n            false\n        }\n    }\n\n    #[inline]\n    pub unsafe fn write(&self) {\n        if self.mode.replace(-1) != 0 {\n            rtabort!(\"rwlock locked for reading\")\n        }\n    }\n\n    #[inline]\n    pub unsafe fn try_write(&self) -> bool {\n        if self.mode.get() == 0 {\n            self.mode.set(-1);\n            true\n        } else {\n            false\n        }\n    }\n\n    #[inline]\n    pub unsafe fn read_unlock(&self) {\n        self.mode.set(self.mode.get() - 1);\n    }\n\n    #[inline]\n    pub unsafe fn write_unlock(&self) {\n        assert_eq!(self.mode.replace(0), -1);\n    }\n\n    #[inline]\n    pub unsafe fn destroy(&self) {}\n}\n"],[2303,"#![allow(dead_code)]\n\nuse super::unsupported;\nuse crate::ffi::CStr;\nuse crate::io;\nuse crate::mem;\nuse crate::num::NonZeroUsize;\nuse crate::sys::hermit::abi;\nuse crate::sys::hermit::thread_local_dtor::run_dtors;\nuse crate::time::Duration;\n\npub type Tid = abi::Tid;\n\npub struct Thread {\n    tid: Tid,\n}\n\nunsafe impl Send for Thread {}\nunsafe impl Sync for Thread {}\n\npub const DEFAULT_MIN_STACK_SIZE: usize = 1 << 20;\n\nimpl Thread {\n    pub unsafe fn new_with_coreid(\n        stack: usize,\n        p: Box<dyn FnOnce()>,\n        core_id: isize,\n    ) -> io::Result<Thread> {\n        let p = Box::into_raw(box p);\n        let tid = abi::spawn2(\n            thread_start,\n            p as usize,\n            abi::Priority::into(abi::NORMAL_PRIO),\n            stack,\n            core_id,\n        );\n\n        return if tid == 0 {\n            // The thread failed to start and as a result p was not consumed. Therefore, it is\n            // safe to reconstruct the box so that it gets deallocated.\n            drop(Box::from_raw(p));\n            Err(io::Error::new_const(io::ErrorKind::Other, &\"Unable to create thread!\"))\n        } else {\n            Ok(Thread { tid: tid })\n        };\n\n        extern \"C\" fn thread_start(main: usize) {\n            unsafe {\n                // Finally, let's run some code.\n                Box::from_raw(main as *mut Box<dyn FnOnce()>)();\n\n                // run all destructors\n                run_dtors();\n            }\n        }\n    }\n\n    pub unsafe fn new(stack: usize, p: Box<dyn FnOnce()>) -> io::Result<Thread> {\n        Thread::new_with_coreid(stack, p, -1 /* = no specific core */)\n    }\n\n    #[inline]\n    pub fn yield_now() {\n        unsafe {\n            abi::yield_now();\n        }\n    }\n\n    #[inline]\n    pub fn set_name(_name: &CStr) {\n        // nope\n    }\n\n    #[inline]\n    pub fn sleep(dur: Duration) {\n        unsafe {\n            abi::usleep(dur.as_micros() as u64);\n        }\n    }\n\n    pub fn join(self) {\n        unsafe {\n            let _ = abi::join(self.tid);\n        }\n    }\n\n    #[inline]\n    pub fn id(&self) -> Tid {\n        self.tid\n    }\n\n    #[inline]\n    pub fn into_id(self) -> Tid {\n        let id = self.tid;\n        mem::forget(self);\n        id\n    }\n}\n\npub fn available_concurrency() -> io::Result<NonZeroUsize> {\n    unsupported()\n}\n\npub mod guard {\n    pub type Guard = !;\n    pub unsafe fn current() -> Option<Guard> {\n        None\n    }\n    pub unsafe fn init() -> Option<Guard> {\n        None\n    }\n}\n"],[2304,"use crate::alloc::{GlobalAlloc, Layout, System};\nuse crate::ptr;\nuse crate::sys::hermit::abi;\n\n#[stable(feature = \"alloc_system_type\", since = \"1.28.0\")]\nunsafe impl GlobalAlloc for System {\n    #[inline]\n    unsafe fn alloc(&self, layout: Layout) -> *mut u8 {\n        abi::malloc(layout.size(), layout.align())\n    }\n\n    unsafe fn alloc_zeroed(&self, layout: Layout) -> *mut u8 {\n        let addr = abi::malloc(layout.size(), layout.align());\n\n        if !addr.is_null() {\n            ptr::write_bytes(addr, 0x00, layout.size());\n        }\n\n        addr\n    }\n\n    #[inline]\n    unsafe fn dealloc(&self, ptr: *mut u8, layout: Layout) {\n        abi::free(ptr, layout.size(), layout.align())\n    }\n\n    #[inline]\n    unsafe fn realloc(&self, ptr: *mut u8, layout: Layout, new_size: usize) -> *mut u8 {\n        abi::realloc(ptr, layout.size(), layout.align(), new_size)\n    }\n}\n"],[2305,"use crate::ffi::OsString;\nuse crate::fmt;\nuse crate::vec;\n\n/// One-time global initialization.\npub unsafe fn init(argc: isize, argv: *const *const u8) {\n    imp::init(argc, argv)\n}\n\n/// One-time global cleanup.\npub unsafe fn cleanup() {\n    imp::cleanup()\n}\n\n/// Returns the command line arguments\npub fn args() -> Args {\n    imp::args()\n}\n\npub struct Args {\n    iter: vec::IntoIter<OsString>,\n}\n\nimpl fmt::Debug for Args {\n    fn fmt(&self, f: &mut fmt::Formatter<'_>) -> fmt::Result {\n        self.iter.as_slice().fmt(f)\n    }\n}\n\nimpl !Send for Args {}\nimpl !Sync for Args {}\n\nimpl Iterator for Args {\n    type Item = OsString;\n    fn next(&mut self) -> Option<OsString> {\n        self.iter.next()\n    }\n    fn size_hint(&self) -> (usize, Option<usize>) {\n        self.iter.size_hint()\n    }\n}\n\nimpl ExactSizeIterator for Args {\n    fn len(&self) -> usize {\n        self.iter.len()\n    }\n}\n\nimpl DoubleEndedIterator for Args {\n    fn next_back(&mut self) -> Option<OsString> {\n        self.iter.next_back()\n    }\n}\n\nmod imp {\n    use super::Args;\n    use crate::ffi::{CStr, OsString};\n    use crate::os::unix::ffi::OsStringExt;\n    use crate::ptr;\n\n    use crate::sys_common::mutex::StaticMutex;\n\n    static mut ARGC: isize = 0;\n    static mut ARGV: *const *const u8 = ptr::null();\n    static LOCK: StaticMutex = StaticMutex::new();\n\n    pub unsafe fn init(argc: isize, argv: *const *const u8) {\n        let _guard = LOCK.lock();\n        ARGC = argc;\n        ARGV = argv;\n    }\n\n    pub unsafe fn cleanup() {\n        let _guard = LOCK.lock();\n        ARGC = 0;\n        ARGV = ptr::null();\n    }\n\n    pub fn args() -> Args {\n        Args { iter: clone().into_iter() }\n    }\n\n    fn clone() -> Vec<OsString> {\n        unsafe {\n            let _guard = LOCK.lock();\n            (0..ARGC)\n                .map(|i| {\n                    let cstr = CStr::from_ptr(*ARGV.offset(i) as *const i8);\n                    OsStringExt::from_vec(cstr.to_bytes().to_vec())\n                })\n                .collect()\n        }\n    }\n}\n"],[2306,"#![allow(dead_code)]\n\nuse crate::cmp::Ordering;\nuse crate::convert::TryInto;\nuse crate::sys::hermit::abi;\nuse crate::sys::hermit::abi::timespec;\nuse crate::sys::hermit::abi::{CLOCK_MONOTONIC, CLOCK_REALTIME, NSEC_PER_SEC};\nuse crate::time::Duration;\nuse core::hash::{Hash, Hasher};\n\n#[derive(Copy, Clone, Debug)]\nstruct Timespec {\n    t: timespec,\n}\n\nimpl Timespec {\n    const fn zero() -> Timespec {\n        Timespec { t: timespec { tv_sec: 0, tv_nsec: 0 } }\n    }\n\n    fn sub_timespec(&self, other: &Timespec) -> Result<Duration, Duration> {\n        if self >= other {\n            Ok(if self.t.tv_nsec >= other.t.tv_nsec {\n                Duration::new(\n                    (self.t.tv_sec - other.t.tv_sec) as u64,\n                    (self.t.tv_nsec - other.t.tv_nsec) as u32,\n                )\n            } else {\n                Duration::new(\n                    (self.t.tv_sec - 1 - other.t.tv_sec) as u64,\n                    self.t.tv_nsec as u32 + (NSEC_PER_SEC as u32) - other.t.tv_nsec as u32,\n                )\n            })\n        } else {\n            match other.sub_timespec(self) {\n                Ok(d) => Err(d),\n                Err(d) => Ok(d),\n            }\n        }\n    }\n\n    fn checked_add_duration(&self, other: &Duration) -> Option<Timespec> {\n        let mut secs = other\n            .as_secs()\n            .try_into() // <- target type would be `libc::time_t`\n            .ok()\n            .and_then(|secs| self.t.tv_sec.checked_add(secs))?;\n\n        // Nano calculations can't overflow because nanos are <1B which fit\n        // in a u32.\n        let mut nsec = other.subsec_nanos() + self.t.tv_nsec as u32;\n        if nsec >= NSEC_PER_SEC as u32 {\n            nsec -= NSEC_PER_SEC as u32;\n            secs = secs.checked_add(1)?;\n        }\n        Some(Timespec { t: timespec { tv_sec: secs, tv_nsec: nsec as _ } })\n    }\n\n    fn checked_sub_duration(&self, other: &Duration) -> Option<Timespec> {\n        let mut secs = other\n            .as_secs()\n            .try_into() // <- target type would be `libc::time_t`\n            .ok()\n            .and_then(|secs| self.t.tv_sec.checked_sub(secs))?;\n\n        // Similar to above, nanos can't overflow.\n        let mut nsec = self.t.tv_nsec as i32 - other.subsec_nanos() as i32;\n        if nsec < 0 {\n            nsec += NSEC_PER_SEC as i32;\n            secs = secs.checked_sub(1)?;\n        }\n        Some(Timespec { t: timespec { tv_sec: secs, tv_nsec: nsec as _ } })\n    }\n}\n\nimpl PartialEq for Timespec {\n    fn eq(&self, other: &Timespec) -> bool {\n        self.t.tv_sec == other.t.tv_sec && self.t.tv_nsec == other.t.tv_nsec\n    }\n}\n\nimpl Eq for Timespec {}\n\nimpl PartialOrd for Timespec {\n    fn partial_cmp(&self, other: &Timespec) -> Option<Ordering> {\n        Some(self.cmp(other))\n    }\n}\n\nimpl Ord for Timespec {\n    fn cmp(&self, other: &Timespec) -> Ordering {\n        let me = (self.t.tv_sec, self.t.tv_nsec);\n        let other = (other.t.tv_sec, other.t.tv_nsec);\n        me.cmp(&other)\n    }\n}\n\nimpl Hash for Timespec {\n    fn hash<H: Hasher>(&self, state: &mut H) {\n        self.t.tv_sec.hash(state);\n        self.t.tv_nsec.hash(state);\n    }\n}\n\n#[derive(Copy, Clone, PartialEq, Eq, PartialOrd, Ord, Debug, Hash)]\npub struct Instant {\n    t: Timespec,\n}\n\nimpl Instant {\n    pub fn now() -> Instant {\n        let mut time: Timespec = Timespec::zero();\n        let _ = unsafe { abi::clock_gettime(CLOCK_MONOTONIC, &mut time.t as *mut timespec) };\n\n        Instant { t: time }\n    }\n\n    pub const fn zero() -> Instant {\n        Instant { t: Timespec::zero() }\n    }\n\n    pub fn actually_monotonic() -> bool {\n        true\n    }\n\n    pub fn checked_sub_instant(&self, other: &Instant) -> Option<Duration> {\n        self.t.sub_timespec(&other.t).ok()\n    }\n\n    pub fn checked_add_duration(&self, other: &Duration) -> Option<Instant> {\n        Some(Instant { t: self.t.checked_add_duration(other)? })\n    }\n\n    pub fn checked_sub_duration(&self, other: &Duration) -> Option<Instant> {\n        Some(Instant { t: self.t.checked_sub_duration(other)? })\n    }\n}\n\n#[derive(Copy, Clone, PartialEq, Eq, PartialOrd, Ord, Hash, Debug)]\npub struct SystemTime {\n    t: Timespec,\n}\n\npub const UNIX_EPOCH: SystemTime = SystemTime { t: Timespec::zero() };\n\nimpl SystemTime {\n    pub fn now() -> SystemTime {\n        let mut time: Timespec = Timespec::zero();\n        let _ = unsafe { abi::clock_gettime(CLOCK_REALTIME, &mut time.t as *mut timespec) };\n\n        SystemTime { t: time }\n    }\n\n    pub fn sub_time(&self, other: &SystemTime) -> Result<Duration, Duration> {\n        self.t.sub_timespec(&other.t)\n    }\n\n    pub fn checked_add_duration(&self, other: &Duration) -> Option<SystemTime> {\n        Some(SystemTime { t: self.t.checked_add_duration(other)? })\n    }\n\n    pub fn checked_sub_duration(&self, other: &Duration) -> Option<SystemTime> {\n        Some(SystemTime { t: self.t.checked_sub_duration(other)? })\n    }\n}\n"],[2307,"pub use core::slice::memchr::{memchr, memrchr};\n"],[2308,"#![cfg(target_thread_local)]\n#![unstable(feature = \"thread_local_internals\", issue = \"none\")]\n\n// Simplify dtor registration by using a list of destructors.\n// The this solution works like the implementation of macOS and\n// doesn't additional OS support\n\nuse crate::cell::Cell;\nuse crate::ptr;\n\n#[thread_local]\nstatic DTORS: Cell<*mut List> = Cell::new(ptr::null_mut());\n\ntype List = Vec<(*mut u8, unsafe extern \"C\" fn(*mut u8))>;\n\npub unsafe fn register_dtor(t: *mut u8, dtor: unsafe extern \"C\" fn(*mut u8)) {\n    if DTORS.get().is_null() {\n        let v: Box<List> = box Vec::new();\n        DTORS.set(Box::into_raw(v));\n    }\n\n    let list: &mut List = &mut *DTORS.get();\n    list.push((t, dtor));\n}\n\n// every thread call this function to run through all possible destructors\npub unsafe fn run_dtors() {\n    let mut ptr = DTORS.replace(ptr::null_mut());\n    while !ptr.is_null() {\n        let list = Box::from_raw(ptr);\n        for (ptr, dtor) in list.into_iter() {\n            dtor(ptr);\n        }\n        ptr = DTORS.replace(ptr::null_mut());\n    }\n}\n"],[2309,"pub mod os {\n    pub const FAMILY: &str = \"\";\n    pub const OS: &str = \"hermit\";\n    pub const DLL_PREFIX: &str = \"\";\n    pub const DLL_SUFFIX: &str = \"\";\n    pub const DLL_EXTENSION: &str = \"\";\n    pub const EXE_SUFFIX: &str = \"\";\n    pub const EXE_EXTENSION: &str = \"\";\n}\n"],[2310,"//! System bindings for HermitCore\n//!\n//! This module contains the facade (aka platform-specific) implementations of\n//! OS level functionality for HermitCore.\n//!\n//! This is all super highly experimental and not actually intended for\n//! wide/production use yet, it's still all in the experimental category. This\n//! will likely change over time.\n//!\n//! Currently all functions here are basically stubs that immediately return\n//! errors. The hope is that with a portability lint we can turn actually just\n//! remove all this and just omit parts of the standard library if we're\n//! compiling for wasm. That way it's a compile time error for something that's\n//! guaranteed to be a runtime error!\n\n#![allow(unsafe_op_in_unsafe_fn)]\n\nuse crate::intrinsics;\nuse crate::os::raw::c_char;\n\npub mod alloc;\npub mod args;\n#[path = \"../unix/cmath.rs\"]\npub mod cmath;\npub mod condvar;\npub mod env;\npub mod fd;\npub mod fs;\n#[path = \"../unsupported/io.rs\"]\npub mod io;\npub mod memchr;\npub mod mutex;\npub mod net;\npub mod os;\n#[path = \"../unix/path.rs\"]\npub mod path;\n#[path = \"../unsupported/pipe.rs\"]\npub mod pipe;\n#[path = \"../unsupported/process.rs\"]\npub mod process;\npub mod rwlock;\npub mod stdio;\npub mod thread;\npub mod thread_local_dtor;\n#[path = \"../unsupported/thread_local_key.rs\"]\npub mod thread_local_key;\npub mod time;\n\nuse crate::io::ErrorKind;\npub use crate::sys_common::os_str_bytes as os_str;\n\n#[allow(unused_extern_crates)]\npub extern crate hermit_abi as abi;\n\npub fn unsupported<T>() -> crate::io::Result<T> {\n    Err(unsupported_err())\n}\n\npub fn unsupported_err() -> crate::io::Error {\n    crate::io::Error::new_const(\n        crate::io::ErrorKind::Unsupported,\n        &\"operation not supported on HermitCore yet\",\n    )\n}\n\npub unsafe fn strlen(start: *const c_char) -> usize {\n    let mut str = start;\n\n    while *str != 0 {\n        str = str.offset(1);\n    }\n\n    (str as usize) - (start as usize)\n}\n\n#[no_mangle]\npub extern \"C\" fn floor(x: f64) -> f64 {\n    unsafe { intrinsics::floorf64(x) }\n}\n\npub fn abort_internal() -> ! {\n    unsafe {\n        abi::abort();\n    }\n}\n\n// FIXME: just a workaround to test the system\npub fn hashmap_random_keys() -> (u64, u64) {\n    (1, 2)\n}\n\n// This function is needed by the panic runtime. The symbol is named in\n// pre-link args for the target specification, so keep that in sync.\n#[cfg(not(test))]\n#[no_mangle]\n// NB. used by both libunwind and libpanic_abort\npub extern \"C\" fn __rust_abort() {\n    abort_internal();\n}\n\n// SAFETY: must be called only once during runtime initialization.\n// NOTE: this is not guaranteed to run, for example when Rust code is called externally.\npub unsafe fn init(argc: isize, argv: *const *const u8) {\n    let _ = net::init();\n    args::init(argc, argv);\n}\n\n// SAFETY: must be called only once during runtime cleanup.\n// NOTE: this is not guaranteed to run, for example when the program aborts.\npub unsafe fn cleanup() {\n    args::cleanup();\n}\n\n#[cfg(not(test))]\n#[no_mangle]\npub unsafe extern \"C\" fn runtime_entry(\n    argc: i32,\n    argv: *const *const c_char,\n    env: *const *const c_char,\n) -> ! {\n    use crate::sys::hermit::thread_local_dtor::run_dtors;\n    extern \"C\" {\n        fn main(argc: isize, argv: *const *const c_char) -> i32;\n    }\n\n    // initialize environment\n    os::init_environment(env as *const *const i8);\n\n    let result = main(argc as isize, argv);\n\n    run_dtors();\n    abi::exit(result);\n}\n\npub fn decode_error_kind(errno: i32) -> ErrorKind {\n    match errno {\n        x if x == 13 as i32 => ErrorKind::PermissionDenied,\n        x if x == 98 as i32 => ErrorKind::AddrInUse,\n        x if x == 99 as i32 => ErrorKind::AddrNotAvailable,\n        x if x == 11 as i32 => ErrorKind::WouldBlock,\n        x if x == 103 as i32 => ErrorKind::ConnectionAborted,\n        x if x == 111 as i32 => ErrorKind::ConnectionRefused,\n        x if x == 104 as i32 => ErrorKind::ConnectionReset,\n        x if x == 17 as i32 => ErrorKind::AlreadyExists,\n        x if x == 4 as i32 => ErrorKind::Interrupted,\n        x if x == 22 as i32 => ErrorKind::InvalidInput,\n        x if x == 2 as i32 => ErrorKind::NotFound,\n        x if x == 107 as i32 => ErrorKind::NotConnected,\n        x if x == 1 as i32 => ErrorKind::PermissionDenied,\n        x if x == 32 as i32 => ErrorKind::BrokenPipe,\n        x if x == 110 as i32 => ErrorKind::TimedOut,\n        _ => ErrorKind::Other,\n    }\n}\n\npub fn cvt(result: i32) -> crate::io::Result<usize> {\n    if result < 0 { Err(crate::io::Error::from_raw_os_error(-result)) } else { Ok(result as usize) }\n}\n"],[2311,"use crate::convert::TryFrom;\nuse crate::fmt;\nuse crate::io::{self, ErrorKind, IoSlice, IoSliceMut};\nuse crate::net::{IpAddr, Ipv4Addr, Ipv6Addr, Shutdown, SocketAddr};\nuse crate::str;\nuse crate::sync::Arc;\nuse crate::sys::hermit::abi;\nuse crate::sys::hermit::abi::IpAddress::{Ipv4, Ipv6};\nuse crate::sys::unsupported;\nuse crate::sys_common::AsInner;\nuse crate::time::Duration;\n\n/// Checks whether the HermitCore's socket interface has been started already, and\n/// if not, starts it.\npub fn init() -> io::Result<()> {\n    if abi::network_init() < 0 {\n        return Err(io::Error::new_const(\n            ErrorKind::Other,\n            &\"Unable to initialize network interface\",\n        ));\n    }\n\n    Ok(())\n}\n\n#[derive(Debug, Clone)]\npub struct Socket(abi::Handle);\n\nimpl AsInner<abi::Handle> for Socket {\n    fn as_inner(&self) -> &abi::Handle {\n        &self.0\n    }\n}\n\nimpl Drop for Socket {\n    fn drop(&mut self) {\n        let _ = abi::tcpstream::close(self.0);\n    }\n}\n\n// Arc is used to count the number of used sockets.\n// Only if all sockets are released, the drop\n// method will close the socket.\n#[derive(Clone)]\npub struct TcpStream(Arc<Socket>);\n\nimpl TcpStream {\n    pub fn connect(addr: io::Result<&SocketAddr>) -> io::Result<TcpStream> {\n        let addr = addr?;\n\n        match abi::tcpstream::connect(addr.ip().to_string().as_bytes(), addr.port(), None) {\n            Ok(handle) => Ok(TcpStream(Arc::new(Socket(handle)))),\n            _ => Err(io::Error::new_const(\n                ErrorKind::Other,\n                &\"Unable to initiate a connection on a socket\",\n            )),\n        }\n    }\n\n    pub fn connect_timeout(saddr: &SocketAddr, duration: Duration) -> io::Result<TcpStream> {\n        match abi::tcpstream::connect(\n            saddr.ip().to_string().as_bytes(),\n            saddr.port(),\n            Some(duration.as_millis() as u64),\n        ) {\n            Ok(handle) => Ok(TcpStream(Arc::new(Socket(handle)))),\n            _ => Err(io::Error::new_const(\n                ErrorKind::Other,\n                &\"Unable to initiate a connection on a socket\",\n            )),\n        }\n    }\n\n    pub fn set_read_timeout(&self, duration: Option<Duration>) -> io::Result<()> {\n        abi::tcpstream::set_read_timeout(*self.0.as_inner(), duration.map(|d| d.as_millis() as u64))\n            .map_err(|_| io::Error::new_const(ErrorKind::Other, &\"Unable to set timeout value\"))\n    }\n\n    pub fn set_write_timeout(&self, duration: Option<Duration>) -> io::Result<()> {\n        abi::tcpstream::set_write_timeout(\n            *self.0.as_inner(),\n            duration.map(|d| d.as_millis() as u64),\n        )\n        .map_err(|_| io::Error::new_const(ErrorKind::Other, &\"Unable to set timeout value\"))\n    }\n\n    pub fn read_timeout(&self) -> io::Result<Option<Duration>> {\n        let duration = abi::tcpstream::get_read_timeout(*self.0.as_inner()).map_err(|_| {\n            io::Error::new_const(ErrorKind::Other, &\"Unable to determine timeout value\")\n        })?;\n\n        Ok(duration.map(|d| Duration::from_millis(d)))\n    }\n\n    pub fn write_timeout(&self) -> io::Result<Option<Duration>> {\n        let duration = abi::tcpstream::get_write_timeout(*self.0.as_inner()).map_err(|_| {\n            io::Error::new_const(ErrorKind::Other, &\"Unable to determine timeout value\")\n        })?;\n\n        Ok(duration.map(|d| Duration::from_millis(d)))\n    }\n\n    pub fn peek(&self, buf: &mut [u8]) -> io::Result<usize> {\n        abi::tcpstream::peek(*self.0.as_inner(), buf)\n            .map_err(|_| io::Error::new_const(ErrorKind::Other, &\"set_nodelay failed\"))\n    }\n\n    pub fn read(&self, buffer: &mut [u8]) -> io::Result<usize> {\n        self.read_vectored(&mut [IoSliceMut::new(buffer)])\n    }\n\n    pub fn read_vectored(&self, ioslice: &mut [IoSliceMut<'_>]) -> io::Result<usize> {\n        let mut size: usize = 0;\n\n        for i in ioslice.iter_mut() {\n            let ret = abi::tcpstream::read(*self.0.as_inner(), &mut i[0..])\n                .map_err(|_| io::Error::new_const(ErrorKind::Other, &\"Unable to read on socket\"))?;\n\n            if ret != 0 {\n                size += ret;\n            }\n        }\n\n        Ok(size)\n    }\n\n    #[inline]\n    pub fn is_read_vectored(&self) -> bool {\n        true\n    }\n\n    pub fn write(&self, buffer: &[u8]) -> io::Result<usize> {\n        self.write_vectored(&[IoSlice::new(buffer)])\n    }\n\n    pub fn write_vectored(&self, ioslice: &[IoSlice<'_>]) -> io::Result<usize> {\n        let mut size: usize = 0;\n\n        for i in ioslice.iter() {\n            size += abi::tcpstream::write(*self.0.as_inner(), i).map_err(|_| {\n                io::Error::new_const(ErrorKind::Other, &\"Unable to write on socket\")\n            })?;\n        }\n\n        Ok(size)\n    }\n\n    #[inline]\n    pub fn is_write_vectored(&self) -> bool {\n        true\n    }\n\n    pub fn peer_addr(&self) -> io::Result<SocketAddr> {\n        let (ipaddr, port) = abi::tcpstream::peer_addr(*self.0.as_inner())\n            .map_err(|_| io::Error::new_const(ErrorKind::Other, &\"peer_addr failed\"))?;\n\n        let saddr = match ipaddr {\n            Ipv4(ref addr) => SocketAddr::new(IpAddr::V4(Ipv4Addr::from(addr.0)), port),\n            Ipv6(ref addr) => SocketAddr::new(IpAddr::V6(Ipv6Addr::from(addr.0)), port),\n            _ => {\n                return Err(io::Error::new_const(ErrorKind::Other, &\"peer_addr failed\"));\n            }\n        };\n\n        Ok(saddr)\n    }\n\n    pub fn socket_addr(&self) -> io::Result<SocketAddr> {\n        unsupported()\n    }\n\n    pub fn shutdown(&self, how: Shutdown) -> io::Result<()> {\n        abi::tcpstream::shutdown(*self.0.as_inner(), how as i32)\n            .map_err(|_| io::Error::new_const(ErrorKind::Other, &\"unable to shutdown socket\"))\n    }\n\n    pub fn duplicate(&self) -> io::Result<TcpStream> {\n        Ok(self.clone())\n    }\n\n    pub fn set_nodelay(&self, mode: bool) -> io::Result<()> {\n        abi::tcpstream::set_nodelay(*self.0.as_inner(), mode)\n            .map_err(|_| io::Error::new_const(ErrorKind::Other, &\"set_nodelay failed\"))\n    }\n\n    pub fn nodelay(&self) -> io::Result<bool> {\n        abi::tcpstream::nodelay(*self.0.as_inner())\n            .map_err(|_| io::Error::new_const(ErrorKind::Other, &\"nodelay failed\"))\n    }\n\n    pub fn set_ttl(&self, tll: u32) -> io::Result<()> {\n        abi::tcpstream::set_tll(*self.0.as_inner(), tll)\n            .map_err(|_| io::Error::new_const(ErrorKind::Other, &\"unable to set TTL\"))\n    }\n\n    pub fn ttl(&self) -> io::Result<u32> {\n        abi::tcpstream::get_tll(*self.0.as_inner())\n            .map_err(|_| io::Error::new_const(ErrorKind::Other, &\"unable to get TTL\"))\n    }\n\n    pub fn take_error(&self) -> io::Result<Option<io::Error>> {\n        unsupported()\n    }\n\n    pub fn set_nonblocking(&self, mode: bool) -> io::Result<()> {\n        abi::tcpstream::set_nonblocking(*self.0.as_inner(), mode)\n            .map_err(|_| io::Error::new_const(ErrorKind::Other, &\"unable to set blocking mode\"))\n    }\n}\n\nimpl fmt::Debug for TcpStream {\n    fn fmt(&self, _f: &mut fmt::Formatter<'_>) -> fmt::Result {\n        Ok(())\n    }\n}\n\n#[derive(Clone)]\npub struct TcpListener(SocketAddr);\n\nimpl TcpListener {\n    pub fn bind(addr: io::Result<&SocketAddr>) -> io::Result<TcpListener> {\n        let addr = addr?;\n\n        Ok(TcpListener(*addr))\n    }\n\n    pub fn socket_addr(&self) -> io::Result<SocketAddr> {\n        Ok(self.0)\n    }\n\n    pub fn accept(&self) -> io::Result<(TcpStream, SocketAddr)> {\n        let (handle, ipaddr, port) = abi::tcplistener::accept(self.0.port())\n            .map_err(|_| io::Error::new_const(ErrorKind::Other, &\"accept failed\"))?;\n        let saddr = match ipaddr {\n            Ipv4(ref addr) => SocketAddr::new(IpAddr::V4(Ipv4Addr::from(addr.0)), port),\n            Ipv6(ref addr) => SocketAddr::new(IpAddr::V6(Ipv6Addr::from(addr.0)), port),\n            _ => {\n                return Err(io::Error::new_const(ErrorKind::Other, &\"accept failed\"));\n            }\n        };\n\n        Ok((TcpStream(Arc::new(Socket(handle))), saddr))\n    }\n\n    pub fn duplicate(&self) -> io::Result<TcpListener> {\n        Ok(self.clone())\n    }\n\n    pub fn set_ttl(&self, _: u32) -> io::Result<()> {\n        unsupported()\n    }\n\n    pub fn ttl(&self) -> io::Result<u32> {\n        unsupported()\n    }\n\n    pub fn set_only_v6(&self, _: bool) -> io::Result<()> {\n        unsupported()\n    }\n\n    pub fn only_v6(&self) -> io::Result<bool> {\n        unsupported()\n    }\n\n    pub fn take_error(&self) -> io::Result<Option<io::Error>> {\n        unsupported()\n    }\n\n    pub fn set_nonblocking(&self, _: bool) -> io::Result<()> {\n        unsupported()\n    }\n}\n\nimpl fmt::Debug for TcpListener {\n    fn fmt(&self, _f: &mut fmt::Formatter<'_>) -> fmt::Result {\n        Ok(())\n    }\n}\n\npub struct UdpSocket(abi::Handle);\n\nimpl UdpSocket {\n    pub fn bind(_: io::Result<&SocketAddr>) -> io::Result<UdpSocket> {\n        unsupported()\n    }\n\n    pub fn peer_addr(&self) -> io::Result<SocketAddr> {\n        unsupported()\n    }\n\n    pub fn socket_addr(&self) -> io::Result<SocketAddr> {\n        unsupported()\n    }\n\n    pub fn recv_from(&self, _: &mut [u8]) -> io::Result<(usize, SocketAddr)> {\n        unsupported()\n    }\n\n    pub fn peek_from(&self, _: &mut [u8]) -> io::Result<(usize, SocketAddr)> {\n        unsupported()\n    }\n\n    pub fn send_to(&self, _: &[u8], _: &SocketAddr) -> io::Result<usize> {\n        unsupported()\n    }\n\n    pub fn duplicate(&self) -> io::Result<UdpSocket> {\n        unsupported()\n    }\n\n    pub fn set_read_timeout(&self, _: Option<Duration>) -> io::Result<()> {\n        unsupported()\n    }\n\n    pub fn set_write_timeout(&self, _: Option<Duration>) -> io::Result<()> {\n        unsupported()\n    }\n\n    pub fn read_timeout(&self) -> io::Result<Option<Duration>> {\n        unsupported()\n    }\n\n    pub fn write_timeout(&self) -> io::Result<Option<Duration>> {\n        unsupported()\n    }\n\n    pub fn set_broadcast(&self, _: bool) -> io::Result<()> {\n        unsupported()\n    }\n\n    pub fn broadcast(&self) -> io::Result<bool> {\n        unsupported()\n    }\n\n    pub fn set_multicast_loop_v4(&self, _: bool) -> io::Result<()> {\n        unsupported()\n    }\n\n    pub fn multicast_loop_v4(&self) -> io::Result<bool> {\n        unsupported()\n    }\n\n    pub fn set_multicast_ttl_v4(&self, _: u32) -> io::Result<()> {\n        unsupported()\n    }\n\n    pub fn multicast_ttl_v4(&self) -> io::Result<u32> {\n        unsupported()\n    }\n\n    pub fn set_multicast_loop_v6(&self, _: bool) -> io::Result<()> {\n        unsupported()\n    }\n\n    pub fn multicast_loop_v6(&self) -> io::Result<bool> {\n        unsupported()\n    }\n\n    pub fn join_multicast_v4(&self, _: &Ipv4Addr, _: &Ipv4Addr) -> io::Result<()> {\n        unsupported()\n    }\n\n    pub fn join_multicast_v6(&self, _: &Ipv6Addr, _: u32) -> io::Result<()> {\n        unsupported()\n    }\n\n    pub fn leave_multicast_v4(&self, _: &Ipv4Addr, _: &Ipv4Addr) -> io::Result<()> {\n        unsupported()\n    }\n\n    pub fn leave_multicast_v6(&self, _: &Ipv6Addr, _: u32) -> io::Result<()> {\n        unsupported()\n    }\n\n    pub fn set_ttl(&self, _: u32) -> io::Result<()> {\n        unsupported()\n    }\n\n    pub fn ttl(&self) -> io::Result<u32> {\n        unsupported()\n    }\n\n    pub fn take_error(&self) -> io::Result<Option<io::Error>> {\n        unsupported()\n    }\n\n    pub fn set_nonblocking(&self, _: bool) -> io::Result<()> {\n        unsupported()\n    }\n\n    pub fn recv(&self, _: &mut [u8]) -> io::Result<usize> {\n        unsupported()\n    }\n\n    pub fn peek(&self, _: &mut [u8]) -> io::Result<usize> {\n        unsupported()\n    }\n\n    pub fn send(&self, _: &[u8]) -> io::Result<usize> {\n        unsupported()\n    }\n\n    pub fn connect(&self, _: io::Result<&SocketAddr>) -> io::Result<()> {\n        unsupported()\n    }\n}\n\nimpl fmt::Debug for UdpSocket {\n    fn fmt(&self, _f: &mut fmt::Formatter<'_>) -> fmt::Result {\n        Ok(())\n    }\n}\n\npub struct LookupHost(!);\n\nimpl LookupHost {\n    pub fn port(&self) -> u16 {\n        self.0\n    }\n}\n\nimpl Iterator for LookupHost {\n    type Item = SocketAddr;\n    fn next(&mut self) -> Option<SocketAddr> {\n        self.0\n    }\n}\n\nimpl TryFrom<&str> for LookupHost {\n    type Error = io::Error;\n\n    fn try_from(_v: &str) -> io::Result<LookupHost> {\n        unsupported()\n    }\n}\n\nimpl<'a> TryFrom<(&'a str, u16)> for LookupHost {\n    type Error = io::Error;\n\n    fn try_from(_v: (&'a str, u16)) -> io::Result<LookupHost> {\n        unsupported()\n    }\n}\n\n#[allow(nonstandard_style)]\npub mod netc {\n    pub const AF_INET: u8 = 0;\n    pub const AF_INET6: u8 = 1;\n    pub type sa_family_t = u8;\n\n    #[derive(Copy, Clone)]\n    pub struct in_addr {\n        pub s_addr: u32,\n    }\n\n    #[derive(Copy, Clone)]\n    pub struct sockaddr_in {\n        pub sin_family: sa_family_t,\n        pub sin_port: u16,\n        pub sin_addr: in_addr,\n    }\n\n    #[derive(Copy, Clone)]\n    pub struct in6_addr {\n        pub s6_addr: [u8; 16],\n    }\n\n    #[derive(Copy, Clone)]\n    pub struct sockaddr_in6 {\n        pub sin6_family: sa_family_t,\n        pub sin6_port: u16,\n        pub sin6_addr: in6_addr,\n        pub sin6_flowinfo: u32,\n        pub sin6_scope_id: u32,\n    }\n\n    #[derive(Copy, Clone)]\n    pub struct sockaddr {}\n\n    pub type socklen_t = usize;\n}\n"],[2312,"use crate::cell::UnsafeCell;\nuse crate::sys::condvar::Condvar;\nuse crate::sys::mutex::Mutex;\n\npub struct RWLock {\n    lock: Mutex,\n    cond: Condvar,\n    state: UnsafeCell<State>,\n}\n\npub type MovableRWLock = Box<RWLock>;\n\nenum State {\n    Unlocked,\n    Reading(usize),\n    Writing,\n}\n\nunsafe impl Send for RWLock {}\nunsafe impl Sync for RWLock {}\n\n// This rwlock implementation is a relatively simple implementation which has a\n// condition variable for readers/writers as well as a mutex protecting the\n// internal state of the lock. A current downside of the implementation is that\n// unlocking the lock will notify *all* waiters rather than just readers or just\n// writers. This can cause lots of \"thundering stampede\" problems. While\n// hopefully correct this implementation is very likely to want to be changed in\n// the future.\n\nimpl RWLock {\n    pub const fn new() -> RWLock {\n        RWLock { lock: Mutex::new(), cond: Condvar::new(), state: UnsafeCell::new(State::Unlocked) }\n    }\n\n    #[inline]\n    pub unsafe fn read(&self) {\n        self.lock.lock();\n        while !(*self.state.get()).inc_readers() {\n            self.cond.wait(&self.lock);\n        }\n        self.lock.unlock();\n    }\n\n    #[inline]\n    pub unsafe fn try_read(&self) -> bool {\n        self.lock.lock();\n        let ok = (*self.state.get()).inc_readers();\n        self.lock.unlock();\n        return ok;\n    }\n\n    #[inline]\n    pub unsafe fn write(&self) {\n        self.lock.lock();\n        while !(*self.state.get()).inc_writers() {\n            self.cond.wait(&self.lock);\n        }\n        self.lock.unlock();\n    }\n\n    #[inline]\n    pub unsafe fn try_write(&self) -> bool {\n        self.lock.lock();\n        let ok = (*self.state.get()).inc_writers();\n        self.lock.unlock();\n        return ok;\n    }\n\n    #[inline]\n    pub unsafe fn read_unlock(&self) {\n        self.lock.lock();\n        let notify = (*self.state.get()).dec_readers();\n        self.lock.unlock();\n        if notify {\n            // FIXME: should only wake up one of these some of the time\n            self.cond.notify_all();\n        }\n    }\n\n    #[inline]\n    pub unsafe fn write_unlock(&self) {\n        self.lock.lock();\n        (*self.state.get()).dec_writers();\n        self.lock.unlock();\n        // FIXME: should only wake up one of these some of the time\n        self.cond.notify_all();\n    }\n\n    #[inline]\n    pub unsafe fn destroy(&self) {\n        self.lock.destroy();\n        self.cond.destroy();\n    }\n}\n\nimpl State {\n    fn inc_readers(&mut self) -> bool {\n        match *self {\n            State::Unlocked => {\n                *self = State::Reading(1);\n                true\n            }\n            State::Reading(ref mut cnt) => {\n                *cnt += 1;\n                true\n            }\n            State::Writing => false,\n        }\n    }\n\n    fn inc_writers(&mut self) -> bool {\n        match *self {\n            State::Unlocked => {\n                *self = State::Writing;\n                true\n            }\n            State::Reading(_) | State::Writing => false,\n        }\n    }\n\n    fn dec_readers(&mut self) -> bool {\n        let zero = match *self {\n            State::Reading(ref mut cnt) => {\n                *cnt -= 1;\n                *cnt == 0\n            }\n            State::Unlocked | State::Writing => invalid(),\n        };\n        if zero {\n            *self = State::Unlocked;\n        }\n        zero\n    }\n\n    fn dec_writers(&mut self) {\n        match *self {\n            State::Writing => {}\n            State::Unlocked | State::Reading(_) => invalid(),\n        }\n        *self = State::Unlocked;\n    }\n}\n\nfn invalid() -> ! {\n    panic!(\"inconsistent rwlock\");\n}\n"],[2313,"use crate::io;\nuse crate::io::{IoSlice, IoSliceMut};\nuse crate::sys::hermit::abi;\n\npub struct Stdin;\npub struct Stdout;\npub struct Stderr;\n\nimpl Stdin {\n    pub const fn new() -> Stdin {\n        Stdin\n    }\n}\n\nimpl io::Read for Stdin {\n    fn read(&mut self, data: &mut [u8]) -> io::Result<usize> {\n        self.read_vectored(&mut [IoSliceMut::new(data)])\n    }\n\n    fn read_vectored(&mut self, _data: &mut [IoSliceMut<'_>]) -> io::Result<usize> {\n        Ok(0)\n    }\n\n    #[inline]\n    fn is_read_vectored(&self) -> bool {\n        true\n    }\n}\n\nimpl Stdout {\n    pub const fn new() -> Stdout {\n        Stdout\n    }\n}\n\nimpl io::Write for Stdout {\n    fn write(&mut self, data: &[u8]) -> io::Result<usize> {\n        let len;\n\n        unsafe { len = abi::write(1, data.as_ptr() as *const u8, data.len()) }\n\n        if len < 0 {\n            Err(io::Error::new_const(io::ErrorKind::Other, &\"Stdout is not able to print\"))\n        } else {\n            Ok(len as usize)\n        }\n    }\n\n    fn write_vectored(&mut self, data: &[IoSlice<'_>]) -> io::Result<usize> {\n        let len;\n\n        unsafe { len = abi::write(1, data.as_ptr() as *const u8, data.len()) }\n\n        if len < 0 {\n            Err(io::Error::new_const(io::ErrorKind::Other, &\"Stdout is not able to print\"))\n        } else {\n            Ok(len as usize)\n        }\n    }\n\n    #[inline]\n    fn is_write_vectored(&self) -> bool {\n        true\n    }\n\n    fn flush(&mut self) -> io::Result<()> {\n        Ok(())\n    }\n}\n\nimpl Stderr {\n    pub const fn new() -> Stderr {\n        Stderr\n    }\n}\n\nimpl io::Write for Stderr {\n    fn write(&mut self, data: &[u8]) -> io::Result<usize> {\n        let len;\n\n        unsafe { len = abi::write(2, data.as_ptr() as *const u8, data.len()) }\n\n        if len < 0 {\n            Err(io::Error::new_const(io::ErrorKind::Other, &\"Stderr is not able to print\"))\n        } else {\n            Ok(len as usize)\n        }\n    }\n\n    fn write_vectored(&mut self, data: &[IoSlice<'_>]) -> io::Result<usize> {\n        let len;\n\n        unsafe { len = abi::write(2, data.as_ptr() as *const u8, data.len()) }\n\n        if len < 0 {\n            Err(io::Error::new_const(io::ErrorKind::Other, &\"Stderr is not able to print\"))\n        } else {\n            Ok(len as usize)\n        }\n    }\n\n    #[inline]\n    fn is_write_vectored(&self) -> bool {\n        true\n    }\n\n    fn flush(&mut self) -> io::Result<()> {\n        Ok(())\n    }\n}\n\npub const STDIN_BUF_SIZE: usize = 0;\n\npub fn is_ebadf(_err: &io::Error) -> bool {\n    true\n}\n\npub fn panic_output() -> Option<impl io::Write> {\n    Some(Stderr::new())\n}\n"],[2314,"use crate::ffi::c_void;\nuse crate::ptr;\nuse crate::sync::atomic::{AtomicUsize, Ordering::SeqCst};\nuse crate::sys::hermit::abi;\nuse crate::sys::mutex::Mutex;\nuse crate::time::Duration;\n\n// The implementation is inspired by Andrew D. Birrell's paper\n// \"Implementing Condition Variables with Semaphores\"\n\npub struct Condvar {\n    counter: AtomicUsize,\n    sem1: *const c_void,\n    sem2: *const c_void,\n}\n\npub type MovableCondvar = Box<Condvar>;\n\nunsafe impl Send for Condvar {}\nunsafe impl Sync for Condvar {}\n\nimpl Condvar {\n    pub const fn new() -> Condvar {\n        Condvar { counter: AtomicUsize::new(0), sem1: ptr::null(), sem2: ptr::null() }\n    }\n\n    pub unsafe fn init(&mut self) {\n        let _ = abi::sem_init(&mut self.sem1 as *mut *const c_void, 0);\n        let _ = abi::sem_init(&mut self.sem2 as *mut *const c_void, 0);\n    }\n\n    pub unsafe fn notify_one(&self) {\n        if self.counter.load(SeqCst) > 0 {\n            self.counter.fetch_sub(1, SeqCst);\n            abi::sem_post(self.sem1);\n            abi::sem_timedwait(self.sem2, 0);\n        }\n    }\n\n    pub unsafe fn notify_all(&self) {\n        let counter = self.counter.swap(0, SeqCst);\n        for _ in 0..counter {\n            abi::sem_post(self.sem1);\n        }\n        for _ in 0..counter {\n            abi::sem_timedwait(self.sem2, 0);\n        }\n    }\n\n    pub unsafe fn wait(&self, mutex: &Mutex) {\n        self.counter.fetch_add(1, SeqCst);\n        mutex.unlock();\n        abi::sem_timedwait(self.sem1, 0);\n        abi::sem_post(self.sem2);\n        mutex.lock();\n    }\n\n    pub unsafe fn wait_timeout(&self, _mutex: &Mutex, _dur: Duration) -> bool {\n        panic!(\"wait_timeout not supported on hermit\");\n    }\n\n    pub unsafe fn destroy(&self) {\n        let _ = abi::sem_destroy(self.sem1);\n        let _ = abi::sem_destroy(self.sem2);\n    }\n}\n"],[2315,"#![unstable(reason = \"not public\", issue = \"none\", feature = \"fd\")]\n\nuse crate::io::{self, Read};\nuse crate::mem;\nuse crate::sys::cvt;\nuse crate::sys::hermit::abi;\nuse crate::sys::unsupported;\nuse crate::sys_common::AsInner;\n\n#[derive(Debug)]\npub struct FileDesc {\n    fd: i32,\n}\n\nimpl FileDesc {\n    pub fn new(fd: i32) -> FileDesc {\n        FileDesc { fd }\n    }\n\n    pub fn raw(&self) -> i32 {\n        self.fd\n    }\n\n    /// Extracts the actual file descriptor without closing it.\n    pub fn into_raw(self) -> i32 {\n        let fd = self.fd;\n        mem::forget(self);\n        fd\n    }\n\n    pub fn read(&self, buf: &mut [u8]) -> io::Result<usize> {\n        let result = unsafe { abi::read(self.fd, buf.as_mut_ptr(), buf.len()) };\n        cvt(result as i32)\n    }\n\n    pub fn read_to_end(&self, buf: &mut Vec<u8>) -> io::Result<usize> {\n        let mut me = self;\n        (&mut me).read_to_end(buf)\n    }\n\n    pub fn write(&self, buf: &[u8]) -> io::Result<usize> {\n        let result = unsafe { abi::write(self.fd, buf.as_ptr(), buf.len()) };\n        cvt(result as i32)\n    }\n\n    pub fn duplicate(&self) -> io::Result<FileDesc> {\n        self.duplicate_path(&[])\n    }\n    pub fn duplicate_path(&self, _path: &[u8]) -> io::Result<FileDesc> {\n        unsupported()\n    }\n\n    pub fn nonblocking(&self) -> io::Result<bool> {\n        Ok(false)\n    }\n\n    pub fn set_cloexec(&self) -> io::Result<()> {\n        unsupported()\n    }\n\n    pub fn set_nonblocking(&self, _nonblocking: bool) -> io::Result<()> {\n        unsupported()\n    }\n}\n\nimpl<'a> Read for &'a FileDesc {\n    fn read(&mut self, buf: &mut [u8]) -> io::Result<usize> {\n        (**self).read(buf)\n    }\n}\n\nimpl AsInner<i32> for FileDesc {\n    fn as_inner(&self) -> &i32 {\n        &self.fd\n    }\n}\n\nimpl Drop for FileDesc {\n    fn drop(&mut self) {\n        // Note that errors are ignored when closing a file descriptor. The\n        // reason for this is that if an error occurs we don't actually know if\n        // the file descriptor was closed or not, and if we retried (for\n        // something like EINTR), we might close another valid file descriptor\n        // (opened after we closed ours.\n        let _ = unsafe { abi::close(self.fd) };\n    }\n}\n"],[2316,"use crate::collections::HashMap;\nuse crate::error::Error as StdError;\nuse crate::ffi::{CStr, OsStr, OsString};\nuse crate::fmt;\nuse crate::io;\nuse crate::marker::PhantomData;\nuse crate::os::unix::ffi::OsStringExt;\nuse crate::path::{self, PathBuf};\nuse crate::str;\nuse crate::sync::Mutex;\nuse crate::sys::hermit::abi;\nuse crate::sys::memchr;\nuse crate::sys::unsupported;\nuse crate::vec;\n\npub fn errno() -> i32 {\n    0\n}\n\npub fn error_string(_errno: i32) -> String {\n    \"operation successful\".to_string()\n}\n\npub fn getcwd() -> io::Result<PathBuf> {\n    unsupported()\n}\n\npub fn chdir(_: &path::Path) -> io::Result<()> {\n    unsupported()\n}\n\npub struct SplitPaths<'a>(!, PhantomData<&'a ()>);\n\npub fn split_paths(_unparsed: &OsStr) -> SplitPaths<'_> {\n    panic!(\"unsupported\")\n}\n\nimpl<'a> Iterator for SplitPaths<'a> {\n    type Item = PathBuf;\n    fn next(&mut self) -> Option<PathBuf> {\n        self.0\n    }\n}\n\n#[derive(Debug)]\npub struct JoinPathsError;\n\npub fn join_paths<I, T>(_paths: I) -> Result<OsString, JoinPathsError>\nwhere\n    I: Iterator<Item = T>,\n    T: AsRef<OsStr>,\n{\n    Err(JoinPathsError)\n}\n\nimpl fmt::Display for JoinPathsError {\n    fn fmt(&self, f: &mut fmt::Formatter<'_>) -> fmt::Result {\n        \"not supported on hermit yet\".fmt(f)\n    }\n}\n\nimpl StdError for JoinPathsError {\n    #[allow(deprecated)]\n    fn description(&self) -> &str {\n        \"not supported on hermit yet\"\n    }\n}\n\npub fn current_exe() -> io::Result<PathBuf> {\n    unsupported()\n}\n\nstatic mut ENV: Option<Mutex<HashMap<OsString, OsString>>> = None;\n\npub fn init_environment(env: *const *const i8) {\n    unsafe {\n        ENV = Some(Mutex::new(HashMap::new()));\n\n        if env.is_null() {\n            return;\n        }\n\n        let mut guard = ENV.as_ref().unwrap().lock().unwrap();\n        let mut environ = env;\n        while !(*environ).is_null() {\n            if let Some((key, value)) = parse(CStr::from_ptr(*environ).to_bytes()) {\n                guard.insert(key, value);\n            }\n            environ = environ.add(1);\n        }\n    }\n\n    fn parse(input: &[u8]) -> Option<(OsString, OsString)> {\n        // Strategy (copied from glibc): Variable name and value are separated\n        // by an ASCII equals sign '='. Since a variable name must not be\n        // empty, allow variable names starting with an equals sign. Skip all\n        // malformed lines.\n        if input.is_empty() {\n            return None;\n        }\n        let pos = memchr::memchr(b'=', &input[1..]).map(|p| p + 1);\n        pos.map(|p| {\n            (\n                OsStringExt::from_vec(input[..p].to_vec()),\n                OsStringExt::from_vec(input[p + 1..].to_vec()),\n            )\n        })\n    }\n}\n\npub struct Env {\n    iter: vec::IntoIter<(OsString, OsString)>,\n}\n\nimpl !Send for Env {}\nimpl !Sync for Env {}\n\nimpl Iterator for Env {\n    type Item = (OsString, OsString);\n    fn next(&mut self) -> Option<(OsString, OsString)> {\n        self.iter.next()\n    }\n    fn size_hint(&self) -> (usize, Option<usize>) {\n        self.iter.size_hint()\n    }\n}\n\n/// Returns a vector of (variable, value) byte-vector pairs for all the\n/// environment variables of the current process.\npub fn env() -> Env {\n    unsafe {\n        let guard = ENV.as_ref().unwrap().lock().unwrap();\n        let mut result = Vec::new();\n\n        for (key, value) in guard.iter() {\n            result.push((key.clone(), value.clone()));\n        }\n\n        return Env { iter: result.into_iter() };\n    }\n}\n\npub fn getenv(k: &OsStr) -> io::Result<Option<OsString>> {\n    unsafe {\n        match ENV.as_ref().unwrap().lock().unwrap().get_mut(k) {\n            Some(value) => Ok(Some(value.clone())),\n            None => Ok(None),\n        }\n    }\n}\n\npub fn setenv(k: &OsStr, v: &OsStr) -> io::Result<()> {\n    unsafe {\n        let (k, v) = (k.to_owned(), v.to_owned());\n        ENV.as_ref().unwrap().lock().unwrap().insert(k, v);\n    }\n    Ok(())\n}\n\npub fn unsetenv(k: &OsStr) -> io::Result<()> {\n    unsafe {\n        ENV.as_ref().unwrap().lock().unwrap().remove(k);\n    }\n    Ok(())\n}\n\npub fn temp_dir() -> PathBuf {\n    panic!(\"no filesystem on hermit\")\n}\n\npub fn home_dir() -> Option<PathBuf> {\n    None\n}\n\npub fn exit(code: i32) -> ! {\n    unsafe {\n        abi::exit(code);\n    }\n}\n\npub fn getpid() -> u32 {\n    unsafe { abi::getpid() }\n}\n"],[2317,"use crate::ffi::{CStr, CString, OsString};\nuse crate::fmt;\nuse crate::hash::{Hash, Hasher};\nuse crate::io::{self, Error, ErrorKind};\nuse crate::io::{IoSlice, IoSliceMut, SeekFrom};\nuse crate::os::unix::ffi::OsStrExt;\nuse crate::path::{Path, PathBuf};\nuse crate::sys::cvt;\nuse crate::sys::hermit::abi;\nuse crate::sys::hermit::abi::{O_APPEND, O_CREAT, O_EXCL, O_RDONLY, O_RDWR, O_TRUNC, O_WRONLY};\nuse crate::sys::hermit::fd::FileDesc;\nuse crate::sys::time::SystemTime;\nuse crate::sys::unsupported;\n\npub use crate::sys_common::fs::{copy, try_exists};\n//pub use crate::sys_common::fs::remove_dir_all;\n\nfn cstr(path: &Path) -> io::Result<CString> {\n    Ok(CString::new(path.as_os_str().as_bytes())?)\n}\n\n#[derive(Debug)]\npub struct File(FileDesc);\n\npub struct FileAttr(!);\n\npub struct ReadDir(!);\n\npub struct DirEntry(!);\n\n#[derive(Clone, Debug)]\npub struct OpenOptions {\n    // generic\n    read: bool,\n    write: bool,\n    append: bool,\n    truncate: bool,\n    create: bool,\n    create_new: bool,\n    // system-specific\n    mode: i32,\n}\n\npub struct FilePermissions(!);\n\npub struct FileType(!);\n\n#[derive(Debug)]\npub struct DirBuilder {}\n\nimpl FileAttr {\n    pub fn size(&self) -> u64 {\n        self.0\n    }\n\n    pub fn perm(&self) -> FilePermissions {\n        self.0\n    }\n\n    pub fn file_type(&self) -> FileType {\n        self.0\n    }\n\n    pub fn modified(&self) -> io::Result<SystemTime> {\n        self.0\n    }\n\n    pub fn accessed(&self) -> io::Result<SystemTime> {\n        self.0\n    }\n\n    pub fn created(&self) -> io::Result<SystemTime> {\n        self.0\n    }\n}\n\nimpl Clone for FileAttr {\n    fn clone(&self) -> FileAttr {\n        self.0\n    }\n}\n\nimpl FilePermissions {\n    pub fn readonly(&self) -> bool {\n        self.0\n    }\n\n    pub fn set_readonly(&mut self, _readonly: bool) {\n        self.0\n    }\n}\n\nimpl Clone for FilePermissions {\n    fn clone(&self) -> FilePermissions {\n        self.0\n    }\n}\n\nimpl PartialEq for FilePermissions {\n    fn eq(&self, _other: &FilePermissions) -> bool {\n        self.0\n    }\n}\n\nimpl Eq for FilePermissions {}\n\nimpl fmt::Debug for FilePermissions {\n    fn fmt(&self, _f: &mut fmt::Formatter<'_>) -> fmt::Result {\n        self.0\n    }\n}\n\nimpl FileType {\n    pub fn is_dir(&self) -> bool {\n        self.0\n    }\n\n    pub fn is_file(&self) -> bool {\n        self.0\n    }\n\n    pub fn is_symlink(&self) -> bool {\n        self.0\n    }\n}\n\nimpl Clone for FileType {\n    fn clone(&self) -> FileType {\n        self.0\n    }\n}\n\nimpl Copy for FileType {}\n\nimpl PartialEq for FileType {\n    fn eq(&self, _other: &FileType) -> bool {\n        self.0\n    }\n}\n\nimpl Eq for FileType {}\n\nimpl Hash for FileType {\n    fn hash<H: Hasher>(&self, _h: &mut H) {\n        self.0\n    }\n}\n\nimpl fmt::Debug for FileType {\n    fn fmt(&self, _f: &mut fmt::Formatter<'_>) -> fmt::Result {\n        self.0\n    }\n}\n\nimpl fmt::Debug for ReadDir {\n    fn fmt(&self, _f: &mut fmt::Formatter<'_>) -> fmt::Result {\n        self.0\n    }\n}\n\nimpl Iterator for ReadDir {\n    type Item = io::Result<DirEntry>;\n\n    fn next(&mut self) -> Option<io::Result<DirEntry>> {\n        self.0\n    }\n}\n\nimpl DirEntry {\n    pub fn path(&self) -> PathBuf {\n        self.0\n    }\n\n    pub fn file_name(&self) -> OsString {\n        self.0\n    }\n\n    pub fn metadata(&self) -> io::Result<FileAttr> {\n        self.0\n    }\n\n    pub fn file_type(&self) -> io::Result<FileType> {\n        self.0\n    }\n}\n\nimpl OpenOptions {\n    pub fn new() -> OpenOptions {\n        OpenOptions {\n            // generic\n            read: false,\n            write: false,\n            append: false,\n            truncate: false,\n            create: false,\n            create_new: false,\n            // system-specific\n            mode: 0x777,\n        }\n    }\n\n    pub fn read(&mut self, read: bool) {\n        self.read = read;\n    }\n    pub fn write(&mut self, write: bool) {\n        self.write = write;\n    }\n    pub fn append(&mut self, append: bool) {\n        self.append = append;\n    }\n    pub fn truncate(&mut self, truncate: bool) {\n        self.truncate = truncate;\n    }\n    pub fn create(&mut self, create: bool) {\n        self.create = create;\n    }\n    pub fn create_new(&mut self, create_new: bool) {\n        self.create_new = create_new;\n    }\n\n    fn get_access_mode(&self) -> io::Result<i32> {\n        match (self.read, self.write, self.append) {\n            (true, false, false) => Ok(O_RDONLY),\n            (false, true, false) => Ok(O_WRONLY),\n            (true, true, false) => Ok(O_RDWR),\n            (false, _, true) => Ok(O_WRONLY | O_APPEND),\n            (true, _, true) => Ok(O_RDWR | O_APPEND),\n            (false, false, false) => {\n                Err(io::Error::new_const(ErrorKind::InvalidInput, &\"invalid access mode\"))\n            }\n        }\n    }\n\n    fn get_creation_mode(&self) -> io::Result<i32> {\n        match (self.write, self.append) {\n            (true, false) => {}\n            (false, false) => {\n                if self.truncate || self.create || self.create_new {\n                    return Err(io::Error::new_const(\n                        ErrorKind::InvalidInput,\n                        &\"invalid creation mode\",\n                    ));\n                }\n            }\n            (_, true) => {\n                if self.truncate && !self.create_new {\n                    return Err(io::Error::new_const(\n                        ErrorKind::InvalidInput,\n                        &\"invalid creation mode\",\n                    ));\n                }\n            }\n        }\n\n        Ok(match (self.create, self.truncate, self.create_new) {\n            (false, false, false) => 0,\n            (true, false, false) => O_CREAT,\n            (false, true, false) => O_TRUNC,\n            (true, true, false) => O_CREAT | O_TRUNC,\n            (_, _, true) => O_CREAT | O_EXCL,\n        })\n    }\n}\n\nimpl File {\n    pub fn open(path: &Path, opts: &OpenOptions) -> io::Result<File> {\n        let path = cstr(path)?;\n        File::open_c(&path, opts)\n    }\n\n    pub fn open_c(path: &CStr, opts: &OpenOptions) -> io::Result<File> {\n        let mut flags = opts.get_access_mode()?;\n        flags = flags | opts.get_creation_mode()?;\n\n        let mode;\n        if flags & O_CREAT == O_CREAT {\n            mode = opts.mode;\n        } else {\n            mode = 0;\n        }\n\n        let fd = unsafe { cvt(abi::open(path.as_ptr(), flags, mode))? };\n        Ok(File(FileDesc::new(fd as i32)))\n    }\n\n    pub fn file_attr(&self) -> io::Result<FileAttr> {\n        Err(Error::from_raw_os_error(22))\n    }\n\n    pub fn fsync(&self) -> io::Result<()> {\n        Err(Error::from_raw_os_error(22))\n    }\n\n    pub fn datasync(&self) -> io::Result<()> {\n        self.fsync()\n    }\n\n    pub fn truncate(&self, _size: u64) -> io::Result<()> {\n        Err(Error::from_raw_os_error(22))\n    }\n\n    pub fn read(&self, buf: &mut [u8]) -> io::Result<usize> {\n        self.0.read(buf)\n    }\n\n    pub fn read_vectored(&self, bufs: &mut [IoSliceMut<'_>]) -> io::Result<usize> {\n        crate::io::default_read_vectored(|buf| self.read(buf), bufs)\n    }\n\n    #[inline]\n    pub fn is_read_vectored(&self) -> bool {\n        false\n    }\n\n    pub fn write(&self, buf: &[u8]) -> io::Result<usize> {\n        self.0.write(buf)\n    }\n\n    pub fn write_vectored(&self, bufs: &[IoSlice<'_>]) -> io::Result<usize> {\n        crate::io::default_write_vectored(|buf| self.write(buf), bufs)\n    }\n\n    #[inline]\n    pub fn is_write_vectored(&self) -> bool {\n        false\n    }\n\n    pub fn flush(&self) -> io::Result<()> {\n        Ok(())\n    }\n\n    pub fn seek(&self, _pos: SeekFrom) -> io::Result<u64> {\n        Err(Error::from_raw_os_error(22))\n    }\n\n    pub fn duplicate(&self) -> io::Result<File> {\n        Err(Error::from_raw_os_error(22))\n    }\n\n    pub fn set_permissions(&self, _perm: FilePermissions) -> io::Result<()> {\n        Err(Error::from_raw_os_error(22))\n    }\n}\n\nimpl DirBuilder {\n    pub fn new() -> DirBuilder {\n        DirBuilder {}\n    }\n\n    pub fn mkdir(&self, _p: &Path) -> io::Result<()> {\n        unsupported()\n    }\n}\n\npub fn readdir(_p: &Path) -> io::Result<ReadDir> {\n    unsupported()\n}\n\npub fn unlink(path: &Path) -> io::Result<()> {\n    let name = cstr(path)?;\n    let _ = unsafe { cvt(abi::unlink(name.as_ptr()))? };\n    Ok(())\n}\n\npub fn rename(_old: &Path, _new: &Path) -> io::Result<()> {\n    unsupported()\n}\n\npub fn set_perm(_p: &Path, perm: FilePermissions) -> io::Result<()> {\n    match perm.0 {}\n}\n\npub fn rmdir(_p: &Path) -> io::Result<()> {\n    unsupported()\n}\n\npub fn remove_dir_all(_path: &Path) -> io::Result<()> {\n    //unsupported()\n    Ok(())\n}\n\npub fn readlink(_p: &Path) -> io::Result<PathBuf> {\n    unsupported()\n}\n\npub fn symlink(_original: &Path, _link: &Path) -> io::Result<()> {\n    unsupported()\n}\n\npub fn link(_original: &Path, _link: &Path) -> io::Result<()> {\n    unsupported()\n}\n\npub fn stat(_p: &Path) -> io::Result<FileAttr> {\n    unsupported()\n}\n\npub fn lstat(_p: &Path) -> io::Result<FileAttr> {\n    unsupported()\n}\n\npub fn canonicalize(_p: &Path) -> io::Result<PathBuf> {\n    unsupported()\n}\n"],[2318,"use crate::cell::UnsafeCell;\nuse crate::collections::VecDeque;\nuse crate::ffi::c_void;\nuse crate::hint;\nuse crate::ops::{Deref, DerefMut, Drop};\nuse crate::ptr;\nuse crate::sync::atomic::{AtomicUsize, Ordering};\nuse crate::sys::hermit::abi;\n\n/// This type provides a lock based on busy waiting to realize mutual exclusion\n///\n/// # Description\n///\n/// This structure behaves a lot like a common mutex. There are some differences:\n///\n/// - By using busy waiting, it can be used outside the runtime.\n/// - It is a so called ticket lock and is completely fair.\n#[cfg_attr(target_arch = \"x86_64\", repr(align(128)))]\n#[cfg_attr(not(target_arch = \"x86_64\"), repr(align(64)))]\nstruct Spinlock<T: ?Sized> {\n    queue: AtomicUsize,\n    dequeue: AtomicUsize,\n    data: UnsafeCell<T>,\n}\n\nunsafe impl<T: ?Sized + Send> Sync for Spinlock<T> {}\nunsafe impl<T: ?Sized + Send> Send for Spinlock<T> {}\n\n/// A guard to which the protected data can be accessed\n///\n/// When the guard falls out of scope it will release the lock.\nstruct SpinlockGuard<'a, T: ?Sized + 'a> {\n    dequeue: &'a AtomicUsize,\n    data: &'a mut T,\n}\n\nimpl<T> Spinlock<T> {\n    pub const fn new(user_data: T) -> Spinlock<T> {\n        Spinlock {\n            queue: AtomicUsize::new(0),\n            dequeue: AtomicUsize::new(1),\n            data: UnsafeCell::new(user_data),\n        }\n    }\n\n    #[inline]\n    fn obtain_lock(&self) {\n        let ticket = self.queue.fetch_add(1, Ordering::SeqCst) + 1;\n        while self.dequeue.load(Ordering::SeqCst) != ticket {\n            hint::spin_loop();\n        }\n    }\n\n    #[inline]\n    pub unsafe fn lock(&self) -> SpinlockGuard<'_, T> {\n        self.obtain_lock();\n        SpinlockGuard { dequeue: &self.dequeue, data: &mut *self.data.get() }\n    }\n}\n\nimpl<T: ?Sized + Default> Default for Spinlock<T> {\n    fn default() -> Spinlock<T> {\n        Spinlock::new(Default::default())\n    }\n}\n\nimpl<'a, T: ?Sized> Deref for SpinlockGuard<'a, T> {\n    type Target = T;\n    fn deref(&self) -> &T {\n        &*self.data\n    }\n}\n\nimpl<'a, T: ?Sized> DerefMut for SpinlockGuard<'a, T> {\n    fn deref_mut(&mut self) -> &mut T {\n        &mut *self.data\n    }\n}\n\nimpl<'a, T: ?Sized> Drop for SpinlockGuard<'a, T> {\n    /// The dropping of the SpinlockGuard will release the lock it was created from.\n    fn drop(&mut self) {\n        self.dequeue.fetch_add(1, Ordering::SeqCst);\n    }\n}\n\n/// Realize a priority queue for tasks\nstruct PriorityQueue {\n    queues: [Option<VecDeque<abi::Tid>>; abi::NO_PRIORITIES],\n    prio_bitmap: u64,\n}\n\nimpl PriorityQueue {\n    pub const fn new() -> PriorityQueue {\n        PriorityQueue {\n            queues: [\n                None, None, None, None, None, None, None, None, None, None, None, None, None, None,\n                None, None, None, None, None, None, None, None, None, None, None, None, None, None,\n                None, None, None,\n            ],\n            prio_bitmap: 0,\n        }\n    }\n\n    /// Add a task id by its priority to the queue\n    pub fn push(&mut self, prio: abi::Priority, id: abi::Tid) {\n        let i: usize = prio.into().into();\n        self.prio_bitmap |= (1 << i) as u64;\n        if let Some(queue) = &mut self.queues[i] {\n            queue.push_back(id);\n        } else {\n            let mut queue = VecDeque::new();\n            queue.push_back(id);\n            self.queues[i] = Some(queue);\n        }\n    }\n\n    fn pop_from_queue(&mut self, queue_index: usize) -> Option<abi::Tid> {\n        if let Some(queue) = &mut self.queues[queue_index] {\n            let id = queue.pop_front();\n\n            if queue.is_empty() {\n                self.prio_bitmap &= !(1 << queue_index as u64);\n            }\n\n            id\n        } else {\n            None\n        }\n    }\n\n    /// Pop the task handle with the highest priority from the queue\n    pub fn pop(&mut self) -> Option<abi::Tid> {\n        for i in 0..abi::NO_PRIORITIES {\n            if self.prio_bitmap & (1 << i) != 0 {\n                return self.pop_from_queue(i);\n            }\n        }\n\n        None\n    }\n}\n\nstruct MutexInner {\n    locked: bool,\n    blocked_task: PriorityQueue,\n}\n\nimpl MutexInner {\n    pub const fn new() -> MutexInner {\n        MutexInner { locked: false, blocked_task: PriorityQueue::new() }\n    }\n}\n\npub struct Mutex {\n    inner: Spinlock<MutexInner>,\n}\n\npub type MovableMutex = Box<Mutex>;\n\nunsafe impl Send for Mutex {}\nunsafe impl Sync for Mutex {}\n\nimpl Mutex {\n    pub const fn new() -> Mutex {\n        Mutex { inner: Spinlock::new(MutexInner::new()) }\n    }\n\n    #[inline]\n    pub unsafe fn init(&mut self) {\n        self.inner = Spinlock::new(MutexInner::new());\n    }\n\n    #[inline]\n    pub unsafe fn lock(&self) {\n        loop {\n            let mut guard = self.inner.lock();\n            if guard.locked == false {\n                guard.locked = true;\n                return;\n            } else {\n                let prio = abi::get_priority();\n                let id = abi::getpid();\n\n                guard.blocked_task.push(prio, id);\n                abi::block_current_task();\n                drop(guard);\n                abi::yield_now();\n            }\n        }\n    }\n\n    #[inline]\n    pub unsafe fn unlock(&self) {\n        let mut guard = self.inner.lock();\n        guard.locked = false;\n        if let Some(tid) = guard.blocked_task.pop() {\n            abi::wakeup_task(tid);\n        }\n    }\n\n    #[inline]\n    pub unsafe fn try_lock(&self) -> bool {\n        let mut guard = self.inner.lock();\n        if guard.locked == false {\n            guard.locked = true;\n        }\n        guard.locked\n    }\n\n    #[inline]\n    pub unsafe fn destroy(&self) {}\n}\n\npub struct ReentrantMutex {\n    inner: *const c_void,\n}\n\nimpl ReentrantMutex {\n    pub const unsafe fn uninitialized() -> ReentrantMutex {\n        ReentrantMutex { inner: ptr::null() }\n    }\n\n    #[inline]\n    pub unsafe fn init(&self) {\n        let _ = abi::recmutex_init(&self.inner as *const *const c_void as *mut _);\n    }\n\n    #[inline]\n    pub unsafe fn lock(&self) {\n        let _ = abi::recmutex_lock(self.inner);\n    }\n\n    #[inline]\n    pub unsafe fn try_lock(&self) -> bool {\n        true\n    }\n\n    #[inline]\n    pub unsafe fn unlock(&self) {\n        let _ = abi::recmutex_unlock(self.inner);\n    }\n\n    #[inline]\n    pub unsafe fn destroy(&self) {\n        let _ = abi::recmutex_destroy(self.inner);\n    }\n}\n"],[2319,"use crate::marker::PhantomData;\nuse crate::slice;\n\nuse libc::{c_void, iovec};\n\n#[derive(Copy, Clone)]\n#[repr(transparent)]\npub struct IoSlice<'a> {\n    vec: iovec,\n    _p: PhantomData<&'a [u8]>,\n}\n\nimpl<'a> IoSlice<'a> {\n    #[inline]\n    pub fn new(buf: &'a [u8]) -> IoSlice<'a> {\n        IoSlice {\n            vec: iovec { iov_base: buf.as_ptr() as *mut u8 as *mut c_void, iov_len: buf.len() },\n            _p: PhantomData,\n        }\n    }\n\n    #[inline]\n    pub fn advance(&mut self, n: usize) {\n        if self.vec.iov_len < n {\n            panic!(\"advancing IoSlice beyond its length\");\n        }\n\n        unsafe {\n            self.vec.iov_len -= n;\n            self.vec.iov_base = self.vec.iov_base.add(n);\n        }\n    }\n\n    #[inline]\n    pub fn as_slice(&self) -> &[u8] {\n        unsafe { slice::from_raw_parts(self.vec.iov_base as *mut u8, self.vec.iov_len) }\n    }\n}\n\n#[repr(transparent)]\npub struct IoSliceMut<'a> {\n    vec: iovec,\n    _p: PhantomData<&'a mut [u8]>,\n}\n\nimpl<'a> IoSliceMut<'a> {\n    #[inline]\n    pub fn new(buf: &'a mut [u8]) -> IoSliceMut<'a> {\n        IoSliceMut {\n            vec: iovec { iov_base: buf.as_mut_ptr() as *mut c_void, iov_len: buf.len() },\n            _p: PhantomData,\n        }\n    }\n\n    #[inline]\n    pub fn advance(&mut self, n: usize) {\n        if self.vec.iov_len < n {\n            panic!(\"advancing IoSliceMut beyond its length\");\n        }\n\n        unsafe {\n            self.vec.iov_len -= n;\n            self.vec.iov_base = self.vec.iov_base.add(n);\n        }\n    }\n\n    #[inline]\n    pub fn as_slice(&self) -> &[u8] {\n        unsafe { slice::from_raw_parts(self.vec.iov_base as *mut u8, self.vec.iov_len) }\n    }\n\n    #[inline]\n    pub fn as_mut_slice(&mut self) -> &mut [u8] {\n        unsafe { slice::from_raw_parts_mut(self.vec.iov_base as *mut u8, self.vec.iov_len) }\n    }\n}\n"],[2320,"use crate::cell::UnsafeCell;\nuse crate::sys::mutex::{self, Mutex};\nuse crate::time::Duration;\n\npub struct Condvar {\n    inner: UnsafeCell<libc::pthread_cond_t>,\n}\n\npub type MovableCondvar = Box<Condvar>;\n\nunsafe impl Send for Condvar {}\nunsafe impl Sync for Condvar {}\n\nconst TIMESPEC_MAX: libc::timespec =\n    libc::timespec { tv_sec: <libc::time_t>::MAX, tv_nsec: 1_000_000_000 - 1 };\n\nfn saturating_cast_to_time_t(value: u64) -> libc::time_t {\n    if value > <libc::time_t>::MAX as u64 { <libc::time_t>::MAX } else { value as libc::time_t }\n}\n\nimpl Condvar {\n    pub const fn new() -> Condvar {\n        // Might be moved and address is changing it is better to avoid\n        // initialization of potentially opaque OS data before it landed\n        Condvar { inner: UnsafeCell::new(libc::PTHREAD_COND_INITIALIZER) }\n    }\n\n    #[cfg(any(\n        target_os = \"macos\",\n        target_os = \"ios\",\n        target_os = \"l4re\",\n        target_os = \"android\",\n        target_os = \"redox\"\n    ))]\n    pub unsafe fn init(&mut self) {}\n\n    #[cfg(not(any(\n        target_os = \"macos\",\n        target_os = \"ios\",\n        target_os = \"l4re\",\n        target_os = \"android\",\n        target_os = \"redox\"\n    )))]\n    pub unsafe fn init(&mut self) {\n        use crate::mem::MaybeUninit;\n        let mut attr = MaybeUninit::<libc::pthread_condattr_t>::uninit();\n        let r = libc::pthread_condattr_init(attr.as_mut_ptr());\n        assert_eq!(r, 0);\n        let r = libc::pthread_condattr_setclock(attr.as_mut_ptr(), libc::CLOCK_MONOTONIC);\n        assert_eq!(r, 0);\n        let r = libc::pthread_cond_init(self.inner.get(), attr.as_ptr());\n        assert_eq!(r, 0);\n        let r = libc::pthread_condattr_destroy(attr.as_mut_ptr());\n        assert_eq!(r, 0);\n    }\n\n    #[inline]\n    pub unsafe fn notify_one(&self) {\n        let r = libc::pthread_cond_signal(self.inner.get());\n        debug_assert_eq!(r, 0);\n    }\n\n    #[inline]\n    pub unsafe fn notify_all(&self) {\n        let r = libc::pthread_cond_broadcast(self.inner.get());\n        debug_assert_eq!(r, 0);\n    }\n\n    #[inline]\n    pub unsafe fn wait(&self, mutex: &Mutex) {\n        let r = libc::pthread_cond_wait(self.inner.get(), mutex::raw(mutex));\n        debug_assert_eq!(r, 0);\n    }\n\n    // This implementation is used on systems that support pthread_condattr_setclock\n    // where we configure condition variable to use monotonic clock (instead of\n    // default system clock). This approach avoids all problems that result\n    // from changes made to the system time.\n    #[cfg(not(any(target_os = \"macos\", target_os = \"ios\", target_os = \"android\")))]\n    pub unsafe fn wait_timeout(&self, mutex: &Mutex, dur: Duration) -> bool {\n        use crate::mem;\n\n        let mut now: libc::timespec = mem::zeroed();\n        let r = libc::clock_gettime(libc::CLOCK_MONOTONIC, &mut now);\n        assert_eq!(r, 0);\n\n        // Nanosecond calculations can't overflow because both values are below 1e9.\n        let nsec = dur.subsec_nanos() + now.tv_nsec as u32;\n\n        let sec = saturating_cast_to_time_t(dur.as_secs())\n            .checked_add((nsec / 1_000_000_000) as libc::time_t)\n            .and_then(|s| s.checked_add(now.tv_sec));\n        let nsec = nsec % 1_000_000_000;\n\n        let timeout =\n            sec.map(|s| libc::timespec { tv_sec: s, tv_nsec: nsec as _ }).unwrap_or(TIMESPEC_MAX);\n\n        let r = libc::pthread_cond_timedwait(self.inner.get(), mutex::raw(mutex), &timeout);\n        assert!(r == libc::ETIMEDOUT || r == 0);\n        r == 0\n    }\n\n    // This implementation is modeled after libcxx's condition_variable\n    // https://github.com/llvm-mirror/libcxx/blob/release_35/src/condition_variable.cpp#L46\n    // https://github.com/llvm-mirror/libcxx/blob/release_35/include/__mutex_base#L367\n    #[cfg(any(target_os = \"macos\", target_os = \"ios\", target_os = \"android\"))]\n    pub unsafe fn wait_timeout(&self, mutex: &Mutex, mut dur: Duration) -> bool {\n        use crate::ptr;\n        use crate::time::Instant;\n\n        // 1000 years\n        let max_dur = Duration::from_secs(1000 * 365 * 86400);\n\n        if dur > max_dur {\n            // OSX implementation of `pthread_cond_timedwait` is buggy\n            // with super long durations. When duration is greater than\n            // 0x100_0000_0000_0000 seconds, `pthread_cond_timedwait`\n            // in macOS Sierra return error 316.\n            //\n            // This program demonstrates the issue:\n            // https://gist.github.com/stepancheg/198db4623a20aad2ad7cddb8fda4a63c\n            //\n            // To work around this issue, and possible bugs of other OSes, timeout\n            // is clamped to 1000 years, which is allowable per the API of `wait_timeout`\n            // because of spurious wakeups.\n\n            dur = max_dur;\n        }\n\n        // First, figure out what time it currently is, in both system and\n        // stable time.  pthread_cond_timedwait uses system time, but we want to\n        // report timeout based on stable time.\n        let mut sys_now = libc::timeval { tv_sec: 0, tv_usec: 0 };\n        let stable_now = Instant::now();\n        let r = libc::gettimeofday(&mut sys_now, ptr::null_mut());\n        debug_assert_eq!(r, 0);\n\n        let nsec = dur.subsec_nanos() as libc::c_long + (sys_now.tv_usec * 1000) as libc::c_long;\n        let extra = (nsec / 1_000_000_000) as libc::time_t;\n        let nsec = nsec % 1_000_000_000;\n        let seconds = saturating_cast_to_time_t(dur.as_secs());\n\n        let timeout = sys_now\n            .tv_sec\n            .checked_add(extra)\n            .and_then(|s| s.checked_add(seconds))\n            .map(|s| libc::timespec { tv_sec: s, tv_nsec: nsec })\n            .unwrap_or(TIMESPEC_MAX);\n\n        // And wait!\n        let r = libc::pthread_cond_timedwait(self.inner.get(), mutex::raw(mutex), &timeout);\n        debug_assert!(r == libc::ETIMEDOUT || r == 0);\n\n        // ETIMEDOUT is not a totally reliable method of determining timeout due\n        // to clock shifts, so do the check ourselves\n        stable_now.elapsed() < dur\n    }\n\n    #[inline]\n    #[cfg(not(target_os = \"dragonfly\"))]\n    pub unsafe fn destroy(&self) {\n        let r = libc::pthread_cond_destroy(self.inner.get());\n        debug_assert_eq!(r, 0);\n    }\n\n    #[inline]\n    #[cfg(target_os = \"dragonfly\")]\n    pub unsafe fn destroy(&self) {\n        let r = libc::pthread_cond_destroy(self.inner.get());\n        // On DragonFly pthread_cond_destroy() returns EINVAL if called on\n        // a condvar that was just initialized with\n        // libc::PTHREAD_COND_INITIALIZER. Once it is used or\n        // pthread_cond_init() is called, this behaviour no longer occurs.\n        debug_assert!(r == 0 || r == libc::EINVAL);\n    }\n}\n"],[2321,"use crate::io::{self, IoSlice, IoSliceMut};\nuse crate::mem::ManuallyDrop;\nuse crate::sys::fd::FileDesc;\n\npub struct Stdin(());\npub struct Stdout(());\npub struct Stderr(());\n\nimpl Stdin {\n    pub const fn new() -> Stdin {\n        Stdin(())\n    }\n}\n\nimpl io::Read for Stdin {\n    fn read(&mut self, buf: &mut [u8]) -> io::Result<usize> {\n        ManuallyDrop::new(FileDesc::new(libc::STDIN_FILENO)).read(buf)\n    }\n\n    fn read_vectored(&mut self, bufs: &mut [IoSliceMut<'_>]) -> io::Result<usize> {\n        ManuallyDrop::new(FileDesc::new(libc::STDIN_FILENO)).read_vectored(bufs)\n    }\n\n    #[inline]\n    fn is_read_vectored(&self) -> bool {\n        true\n    }\n}\n\nimpl Stdout {\n    pub const fn new() -> Stdout {\n        Stdout(())\n    }\n}\n\nimpl io::Write for Stdout {\n    fn write(&mut self, buf: &[u8]) -> io::Result<usize> {\n        ManuallyDrop::new(FileDesc::new(libc::STDOUT_FILENO)).write(buf)\n    }\n\n    fn write_vectored(&mut self, bufs: &[IoSlice<'_>]) -> io::Result<usize> {\n        ManuallyDrop::new(FileDesc::new(libc::STDOUT_FILENO)).write_vectored(bufs)\n    }\n\n    #[inline]\n    fn is_write_vectored(&self) -> bool {\n        true\n    }\n\n    fn flush(&mut self) -> io::Result<()> {\n        Ok(())\n    }\n}\n\nimpl Stderr {\n    pub const fn new() -> Stderr {\n        Stderr(())\n    }\n}\n\nimpl io::Write for Stderr {\n    fn write(&mut self, buf: &[u8]) -> io::Result<usize> {\n        ManuallyDrop::new(FileDesc::new(libc::STDERR_FILENO)).write(buf)\n    }\n\n    fn write_vectored(&mut self, bufs: &[IoSlice<'_>]) -> io::Result<usize> {\n        ManuallyDrop::new(FileDesc::new(libc::STDERR_FILENO)).write_vectored(bufs)\n    }\n\n    #[inline]\n    fn is_write_vectored(&self) -> bool {\n        true\n    }\n\n    fn flush(&mut self) -> io::Result<()> {\n        Ok(())\n    }\n}\n\npub fn is_ebadf(err: &io::Error) -> bool {\n    err.raw_os_error() == Some(libc::EBADF as i32)\n}\n\npub const STDIN_BUF_SIZE: usize = crate::sys_common::io::DEFAULT_BUF_SIZE;\n\npub fn panic_output() -> Option<impl io::Write> {\n    Some(Stderr::new())\n}\n"],[2322,"use crate::io::{self, IoSlice, IoSliceMut};\nuse crate::mem;\nuse crate::sys::fd::FileDesc;\nuse crate::sys::{cvt, cvt_r};\n\n////////////////////////////////////////////////////////////////////////////////\n// Anonymous pipes\n////////////////////////////////////////////////////////////////////////////////\n\npub struct AnonPipe(FileDesc);\n\npub fn anon_pipe() -> io::Result<(AnonPipe, AnonPipe)> {\n    let mut fds = [0; 2];\n\n    // The only known way right now to create atomically set the CLOEXEC flag is\n    // to use the `pipe2` syscall. This was added to Linux in 2.6.27, glibc 2.9\n    // and musl 0.9.3, and some other targets also have it.\n    cfg_if::cfg_if! {\n        if #[cfg(any(\n            target_os = \"dragonfly\",\n            target_os = \"freebsd\",\n            target_os = \"linux\",\n            target_os = \"netbsd\",\n            target_os = \"openbsd\",\n            target_os = \"redox\"\n        ))] {\n            cvt(unsafe { libc::pipe2(fds.as_mut_ptr(), libc::O_CLOEXEC) })?;\n            Ok((AnonPipe(FileDesc::new(fds[0])), AnonPipe(FileDesc::new(fds[1]))))\n        } else {\n            cvt(unsafe { libc::pipe(fds.as_mut_ptr()) })?;\n\n            let fd0 = FileDesc::new(fds[0]);\n            let fd1 = FileDesc::new(fds[1]);\n            fd0.set_cloexec()?;\n            fd1.set_cloexec()?;\n            Ok((AnonPipe(fd0), AnonPipe(fd1)))\n        }\n    }\n}\n\nimpl AnonPipe {\n    pub fn read(&self, buf: &mut [u8]) -> io::Result<usize> {\n        self.0.read(buf)\n    }\n\n    pub fn read_vectored(&self, bufs: &mut [IoSliceMut<'_>]) -> io::Result<usize> {\n        self.0.read_vectored(bufs)\n    }\n\n    #[inline]\n    pub fn is_read_vectored(&self) -> bool {\n        self.0.is_read_vectored()\n    }\n\n    pub fn write(&self, buf: &[u8]) -> io::Result<usize> {\n        self.0.write(buf)\n    }\n\n    pub fn write_vectored(&self, bufs: &[IoSlice<'_>]) -> io::Result<usize> {\n        self.0.write_vectored(bufs)\n    }\n\n    #[inline]\n    pub fn is_write_vectored(&self) -> bool {\n        self.0.is_write_vectored()\n    }\n\n    pub fn fd(&self) -> &FileDesc {\n        &self.0\n    }\n    pub fn into_fd(self) -> FileDesc {\n        self.0\n    }\n}\n\npub fn read2(p1: AnonPipe, v1: &mut Vec<u8>, p2: AnonPipe, v2: &mut Vec<u8>) -> io::Result<()> {\n    // Set both pipes into nonblocking mode as we're gonna be reading from both\n    // in the `select` loop below, and we wouldn't want one to block the other!\n    let p1 = p1.into_fd();\n    let p2 = p2.into_fd();\n    p1.set_nonblocking(true)?;\n    p2.set_nonblocking(true)?;\n\n    let mut fds: [libc::pollfd; 2] = unsafe { mem::zeroed() };\n    fds[0].fd = p1.raw();\n    fds[0].events = libc::POLLIN;\n    fds[1].fd = p2.raw();\n    fds[1].events = libc::POLLIN;\n    loop {\n        // wait for either pipe to become readable using `poll`\n        cvt_r(|| unsafe { libc::poll(fds.as_mut_ptr(), 2, -1) })?;\n\n        if fds[0].revents != 0 && read(&p1, v1)? {\n            p2.set_nonblocking(false)?;\n            return p2.read_to_end(v2).map(drop);\n        }\n        if fds[1].revents != 0 && read(&p2, v2)? {\n            p1.set_nonblocking(false)?;\n            return p1.read_to_end(v1).map(drop);\n        }\n    }\n\n    // Read as much as we can from each pipe, ignoring EWOULDBLOCK or\n    // EAGAIN. If we hit EOF, then this will happen because the underlying\n    // reader will return Ok(0), in which case we'll see `Ok` ourselves. In\n    // this case we flip the other fd back into blocking mode and read\n    // whatever's leftover on that file descriptor.\n    fn read(fd: &FileDesc, dst: &mut Vec<u8>) -> Result<bool, io::Error> {\n        match fd.read_to_end(dst) {\n            Ok(_) => Ok(true),\n            Err(e) => {\n                if e.raw_os_error() == Some(libc::EWOULDBLOCK)\n                    || e.raw_os_error() == Some(libc::EAGAIN)\n                {\n                    Ok(false)\n                } else {\n                    Err(e)\n                }\n            }\n        }\n    }\n}\n"],[2323,"//! Android ABI-compatibility module\n//!\n//! The ABI of Android has changed quite a bit over time, and libstd attempts to\n//! be both forwards and backwards compatible as much as possible. We want to\n//! always work with the most recent version of Android, but we also want to\n//! work with older versions of Android for whenever projects need to.\n//!\n//! Our current minimum supported Android version is `android-9`, e.g., Android\n//! with API level 9. We then in theory want to work on that and all future\n//! versions of Android!\n//!\n//! Some of the detection here is done at runtime via `dlopen` and\n//! introspection. Other times no detection is performed at all and we just\n//! provide a fallback implementation as some versions of Android we support\n//! don't have the function.\n//!\n//! You'll find more details below about why each compatibility shim is needed.\n\n#![cfg(target_os = \"android\")]\n\nuse libc::{c_int, c_void, sighandler_t, size_t, ssize_t};\nuse libc::{ftruncate, pread, pwrite};\n\nuse super::{cvt, cvt_r};\nuse crate::io;\n\n// The `log2` and `log2f` functions apparently appeared in android-18, or at\n// least you can see they're not present in the android-17 header [1] and they\n// are present in android-18 [2].\n//\n// [1]: https://chromium.googlesource.com/android_tools/+/20ee6d20/ndk/platforms\n//                                       /android-17/arch-arm/usr/include/math.h\n// [2]: https://chromium.googlesource.com/android_tools/+/20ee6d20/ndk/platforms\n//                                       /android-18/arch-arm/usr/include/math.h\n//\n// Note that these shims are likely less precise than directly calling `log2`,\n// but hopefully that should be enough for now...\n//\n// Note that mathematically, for any arbitrary `y`:\n//\n//      log_2(x) = log_y(x) / log_y(2)\n//               = log_y(x) / (1 / log_2(y))\n//               = log_y(x) * log_2(y)\n//\n// Hence because `ln` (log_e) is available on all Android we just choose `y = e`\n// and get:\n//\n//      log_2(x) = ln(x) * log_2(e)\n\n#[cfg(not(test))]\npub fn log2f32(f: f32) -> f32 {\n    f.ln() * crate::f32::consts::LOG2_E\n}\n\n#[cfg(not(test))]\npub fn log2f64(f: f64) -> f64 {\n    f.ln() * crate::f64::consts::LOG2_E\n}\n\n// Back in the day [1] the `signal` function was just an inline wrapper\n// around `bsd_signal`, but starting in API level android-20 the `signal`\n// symbols was introduced [2]. Finally, in android-21 the API `bsd_signal` was\n// removed [3].\n//\n// Basically this means that if we want to be binary compatible with multiple\n// Android releases (oldest being 9 and newest being 21) then we need to check\n// for both symbols and not actually link against either.\n//\n// [1]: https://chromium.googlesource.com/android_tools/+/20ee6d20/ndk/platforms\n//                                       /android-18/arch-arm/usr/include/signal.h\n// [2]: https://chromium.googlesource.com/android_tools/+/fbd420/ndk_experimental\n//                                       /platforms/android-20/arch-arm\n//                                       /usr/include/signal.h\n// [3]: https://chromium.googlesource.com/android_tools/+/20ee6d/ndk/platforms\n//                                       /android-21/arch-arm/usr/include/signal.h\npub unsafe fn signal(signum: c_int, handler: sighandler_t) -> sighandler_t {\n    weak!(fn signal(c_int, sighandler_t) -> sighandler_t);\n    weak!(fn bsd_signal(c_int, sighandler_t) -> sighandler_t);\n\n    let f = signal.get().or_else(|| bsd_signal.get());\n    let f = f.expect(\"neither `signal` nor `bsd_signal` symbols found\");\n    f(signum, handler)\n}\n\n// The `ftruncate64` symbol apparently appeared in android-12, so we do some\n// dynamic detection to see if we can figure out whether `ftruncate64` exists.\n//\n// If it doesn't we just fall back to `ftruncate`, generating an error for\n// too-large values.\n#[cfg(target_pointer_width = \"32\")]\npub fn ftruncate64(fd: c_int, size: u64) -> io::Result<()> {\n    weak!(fn ftruncate64(c_int, i64) -> c_int);\n\n    unsafe {\n        match ftruncate64.get() {\n            Some(f) => cvt_r(|| f(fd, size as i64)).map(drop),\n            None => {\n                if size > i32::MAX as u64 {\n                    Err(io::Error::new_const(io::ErrorKind::InvalidInput, &\"cannot truncate >2GB\"))\n                } else {\n                    cvt_r(|| ftruncate(fd, size as i32)).map(drop)\n                }\n            }\n        }\n    }\n}\n\n#[cfg(target_pointer_width = \"64\")]\npub fn ftruncate64(fd: c_int, size: u64) -> io::Result<()> {\n    unsafe { cvt_r(|| ftruncate(fd, size as i64)).map(drop) }\n}\n\n#[cfg(target_pointer_width = \"32\")]\npub unsafe fn cvt_pread64(\n    fd: c_int,\n    buf: *mut c_void,\n    count: size_t,\n    offset: i64,\n) -> io::Result<ssize_t> {\n    use crate::convert::TryInto;\n    weak!(fn pread64(c_int, *mut c_void, size_t, i64) -> ssize_t);\n    pread64.get().map(|f| cvt(f(fd, buf, count, offset))).unwrap_or_else(|| {\n        if let Ok(o) = offset.try_into() {\n            cvt(pread(fd, buf, count, o))\n        } else {\n            Err(io::Error::new_const(io::ErrorKind::InvalidInput, &\"cannot pread >2GB\"))\n        }\n    })\n}\n\n#[cfg(target_pointer_width = \"32\")]\npub unsafe fn cvt_pwrite64(\n    fd: c_int,\n    buf: *const c_void,\n    count: size_t,\n    offset: i64,\n) -> io::Result<ssize_t> {\n    use crate::convert::TryInto;\n    weak!(fn pwrite64(c_int, *const c_void, size_t, i64) -> ssize_t);\n    pwrite64.get().map(|f| cvt(f(fd, buf, count, offset))).unwrap_or_else(|| {\n        if let Ok(o) = offset.try_into() {\n            cvt(pwrite(fd, buf, count, o))\n        } else {\n            Err(io::Error::new_const(io::ErrorKind::InvalidInput, &\"cannot pwrite >2GB\"))\n        }\n    })\n}\n\n#[cfg(target_pointer_width = \"64\")]\npub unsafe fn cvt_pread64(\n    fd: c_int,\n    buf: *mut c_void,\n    count: size_t,\n    offset: i64,\n) -> io::Result<ssize_t> {\n    cvt(pread(fd, buf, count, offset))\n}\n\n#[cfg(target_pointer_width = \"64\")]\npub unsafe fn cvt_pwrite64(\n    fd: c_int,\n    buf: *const c_void,\n    count: size_t,\n    offset: i64,\n) -> io::Result<ssize_t> {\n    cvt(pwrite(fd, buf, count, offset))\n}\n"],[2324,"//! This module contains specializations that can offload `io::copy()` operations on file descriptor\n//! containing types (`File`, `TcpStream`, etc.) to more efficient syscalls than `read(2)` and `write(2)`.\n//!\n//! Specialization is only applied to wholly std-owned types so that user code can't observe\n//! that the `Read` and `Write` traits are not used.\n//!\n//! Since a copy operation involves a reader and writer side where each can consist of different types\n//! and also involve generic wrappers (e.g. `Take`, `BufReader`) it is not practical to specialize\n//! a single method on all possible combinations.\n//!\n//! Instead readers and writers are handled separately by the `CopyRead` and `CopyWrite` specialization\n//! traits and then specialized on by the `Copier::copy` method.\n//!\n//! `Copier` uses the specialization traits to unpack the underlying file descriptors and\n//! additional prerequisites and constraints imposed by the wrapper types.\n//!\n//! Once it has obtained all necessary pieces and brought any wrapper types into a state where they\n//! can be safely bypassed it will attempt to use the `copy_file_range(2)`,\n//! `sendfile(2)` or `splice(2)` syscalls to move data directly between file descriptors.\n//! Since those syscalls have requirements that cannot be fully checked in advance and\n//! gathering additional information about file descriptors would require additional syscalls\n//! anyway it simply attempts to use them one after another (guided by inaccurate hints) to\n//! figure out which one works and and falls back to the generic read-write copy loop if none of them\n//! does.\n//! Once a working syscall is found for a pair of file descriptors it will be called in a loop\n//! until the copy operation is completed.\n//!\n//! Advantages of using these syscalls:\n//!\n//! * fewer context switches since reads and writes are coalesced into a single syscall\n//!   and more bytes are transferred per syscall. This translates to higher throughput\n//!   and fewer CPU cycles, at least for sufficiently large transfers to amortize the initial probing.\n//! * `copy_file_range` creates reflink copies on CoW filesystems, thus moving less data and\n//!   consuming less disk space\n//! * `sendfile` and `splice` can perform zero-copy IO under some circumstances while\n//!   a naive copy loop would move every byte through the CPU.\n//!\n//! Drawbacks:\n//!\n//! * copy operations smaller than the default buffer size can under some circumstances, especially\n//!   on older kernels, incur more syscalls than the naive approach would. As mentioned above\n//!   the syscall selection is guided by hints to minimize this possibility but they are not perfect.\n//! * optimizations only apply to std types. If a user adds a custom wrapper type, e.g. to report\n//!   progress, they can hit a performance cliff.\n//! * complexity\n\nuse crate::cmp::min;\nuse crate::convert::TryInto;\nuse crate::fs::{File, Metadata};\nuse crate::io::copy::generic_copy;\nuse crate::io::{\n    BufRead, BufReader, BufWriter, Error, Read, Result, StderrLock, StdinLock, StdoutLock, Take,\n    Write,\n};\nuse crate::mem::ManuallyDrop;\nuse crate::net::TcpStream;\nuse crate::os::unix::fs::FileTypeExt;\nuse crate::os::unix::io::{AsRawFd, FromRawFd, RawFd};\nuse crate::os::unix::net::UnixStream;\nuse crate::process::{ChildStderr, ChildStdin, ChildStdout};\nuse crate::ptr;\nuse crate::sync::atomic::{AtomicBool, AtomicU8, Ordering};\nuse crate::sys::cvt;\nuse libc::{EBADF, EINVAL, ENOSYS, EOPNOTSUPP, EOVERFLOW, EPERM, EXDEV};\n\n#[cfg(test)]\nmod tests;\n\npub(crate) fn copy_spec<R: Read + ?Sized, W: Write + ?Sized>(\n    read: &mut R,\n    write: &mut W,\n) -> Result<u64> {\n    let copier = Copier { read, write };\n    SpecCopy::copy(copier)\n}\n\n/// This type represents either the inferred `FileType` of a `RawFd` based on the source\n/// type from which it was extracted or the actual metadata\n///\n/// The methods on this type only provide hints, due to `AsRawFd` and `FromRawFd` the inferred\n/// type may be wrong.\nenum FdMeta {\n    /// We obtained the FD from a type that can contain any type of `FileType` and queried the metadata\n    /// because it is cheaper than probing all possible syscalls (reader side)\n    Metadata(Metadata),\n    Socket,\n    Pipe,\n    /// We don't have any metadata, e.g. because the original type was `File` which can represent\n    /// any `FileType` and we did not query the metadata either since it did not seem beneficial\n    /// (writer side)\n    NoneObtained,\n}\n\nimpl FdMeta {\n    fn maybe_fifo(&self) -> bool {\n        match self {\n            FdMeta::Metadata(meta) => meta.file_type().is_fifo(),\n            FdMeta::Socket => false,\n            FdMeta::Pipe => true,\n            FdMeta::NoneObtained => true,\n        }\n    }\n\n    fn potential_sendfile_source(&self) -> bool {\n        match self {\n            // procfs erronously shows 0 length on non-empty readable files.\n            // and if a file is truly empty then a `read` syscall will determine that and skip the write syscall\n            // thus there would be benefit from attempting sendfile\n            FdMeta::Metadata(meta)\n                if meta.file_type().is_file() && meta.len() > 0\n                    || meta.file_type().is_block_device() =>\n            {\n                true\n            }\n            _ => false,\n        }\n    }\n\n    fn copy_file_range_candidate(&self) -> bool {\n        match self {\n            // copy_file_range will fail on empty procfs files. `read` can determine whether EOF has been reached\n            // without extra cost and skip the write, thus there is no benefit in attempting copy_file_range\n            FdMeta::Metadata(meta) if meta.is_file() && meta.len() > 0 => true,\n            FdMeta::NoneObtained => true,\n            _ => false,\n        }\n    }\n}\n\nstruct CopyParams(FdMeta, Option<RawFd>);\n\nstruct Copier<'a, 'b, R: Read + ?Sized, W: Write + ?Sized> {\n    read: &'a mut R,\n    write: &'b mut W,\n}\n\ntrait SpecCopy {\n    fn copy(self) -> Result<u64>;\n}\n\nimpl<R: Read + ?Sized, W: Write + ?Sized> SpecCopy for Copier<'_, '_, R, W> {\n    default fn copy(self) -> Result<u64> {\n        generic_copy(self.read, self.write)\n    }\n}\n\nimpl<R: CopyRead, W: CopyWrite> SpecCopy for Copier<'_, '_, R, W> {\n    fn copy(self) -> Result<u64> {\n        let (reader, writer) = (self.read, self.write);\n        let r_cfg = reader.properties();\n        let w_cfg = writer.properties();\n\n        // before direct operations on file descriptors ensure that all source and sink buffers are empty\n        let mut flush = || -> crate::io::Result<u64> {\n            let bytes = reader.drain_to(writer, u64::MAX)?;\n            // BufWriter buffered bytes have already been accounted for in earlier write() calls\n            writer.flush()?;\n            Ok(bytes)\n        };\n\n        let mut written = 0u64;\n\n        if let (CopyParams(input_meta, Some(readfd)), CopyParams(output_meta, Some(writefd))) =\n            (r_cfg, w_cfg)\n        {\n            written += flush()?;\n            let max_write = reader.min_limit();\n\n            if input_meta.copy_file_range_candidate() && output_meta.copy_file_range_candidate() {\n                let result = copy_regular_files(readfd, writefd, max_write);\n                result.update_take(reader);\n\n                match result {\n                    CopyResult::Ended(bytes_copied) => return Ok(bytes_copied + written),\n                    CopyResult::Error(e, _) => return Err(e),\n                    CopyResult::Fallback(bytes) => written += bytes,\n                }\n            }\n\n            // on modern kernels sendfile can copy from any mmapable type (some but not all regular files and block devices)\n            // to any writable file descriptor. On older kernels the writer side can only be a socket.\n            // So we just try and fallback if needed.\n            // If current file offsets + write sizes overflow it may also fail, we do not try to fix that and instead\n            // fall back to the generic copy loop.\n            if input_meta.potential_sendfile_source() {\n                let result = sendfile_splice(SpliceMode::Sendfile, readfd, writefd, max_write);\n                result.update_take(reader);\n\n                match result {\n                    CopyResult::Ended(bytes_copied) => return Ok(bytes_copied + written),\n                    CopyResult::Error(e, _) => return Err(e),\n                    CopyResult::Fallback(bytes) => written += bytes,\n                }\n            }\n\n            if input_meta.maybe_fifo() || output_meta.maybe_fifo() {\n                let result = sendfile_splice(SpliceMode::Splice, readfd, writefd, max_write);\n                result.update_take(reader);\n\n                match result {\n                    CopyResult::Ended(bytes_copied) => return Ok(bytes_copied + written),\n                    CopyResult::Error(e, _) => return Err(e),\n                    CopyResult::Fallback(0) => { /* use the fallback below */ }\n                    CopyResult::Fallback(_) => {\n                        unreachable!(\"splice should not return > 0 bytes on the fallback path\")\n                    }\n                }\n            }\n        }\n\n        // fallback if none of the more specialized syscalls wants to work with these file descriptors\n        match generic_copy(reader, writer) {\n            Ok(bytes) => Ok(bytes + written),\n            err => err,\n        }\n    }\n}\n\n#[rustc_specialization_trait]\ntrait CopyRead: Read {\n    /// Implementations that contain buffers (i.e. `BufReader`) must transfer data from their internal\n    /// buffers into `writer` until either the buffers are emptied or `limit` bytes have been\n    /// transferred, whichever occurs sooner.\n    /// If nested buffers are present the outer buffers must be drained first.\n    ///\n    /// This is necessary to directly bypass the wrapper types while preserving the data order\n    /// when operating directly on the underlying file descriptors.\n    fn drain_to<W: Write>(&mut self, _writer: &mut W, _limit: u64) -> Result<u64> {\n        Ok(0)\n    }\n\n    /// Updates `Take` wrappers to remove the number of bytes copied.\n    fn taken(&mut self, _bytes: u64) {}\n\n    /// The minimum of the limit of all `Take<_>` wrappers, `u64::MAX` otherwise.\n    /// This method does not account for data `BufReader` buffers and would underreport\n    /// the limit of a `Take<BufReader<Take<_>>>` type. Thus its result is only valid\n    /// after draining the buffers via `drain_to`.\n    fn min_limit(&self) -> u64 {\n        u64::MAX\n    }\n\n    /// Extracts the file descriptor and hints/metadata, delegating through wrappers if necessary.\n    fn properties(&self) -> CopyParams;\n}\n\n#[rustc_specialization_trait]\ntrait CopyWrite: Write {\n    /// Extracts the file descriptor and hints/metadata, delegating through wrappers if necessary.\n    fn properties(&self) -> CopyParams;\n}\n\nimpl<T> CopyRead for &mut T\nwhere\n    T: CopyRead,\n{\n    fn drain_to<W: Write>(&mut self, writer: &mut W, limit: u64) -> Result<u64> {\n        (**self).drain_to(writer, limit)\n    }\n\n    fn taken(&mut self, bytes: u64) {\n        (**self).taken(bytes);\n    }\n\n    fn min_limit(&self) -> u64 {\n        (**self).min_limit()\n    }\n\n    fn properties(&self) -> CopyParams {\n        (**self).properties()\n    }\n}\n\nimpl<T> CopyWrite for &mut T\nwhere\n    T: CopyWrite,\n{\n    fn properties(&self) -> CopyParams {\n        (**self).properties()\n    }\n}\n\nimpl CopyRead for File {\n    fn properties(&self) -> CopyParams {\n        CopyParams(fd_to_meta(self), Some(self.as_raw_fd()))\n    }\n}\n\nimpl CopyRead for &File {\n    fn properties(&self) -> CopyParams {\n        CopyParams(fd_to_meta(*self), Some(self.as_raw_fd()))\n    }\n}\n\nimpl CopyWrite for File {\n    fn properties(&self) -> CopyParams {\n        CopyParams(FdMeta::NoneObtained, Some(self.as_raw_fd()))\n    }\n}\n\nimpl CopyWrite for &File {\n    fn properties(&self) -> CopyParams {\n        CopyParams(FdMeta::NoneObtained, Some(self.as_raw_fd()))\n    }\n}\n\nimpl CopyRead for TcpStream {\n    fn properties(&self) -> CopyParams {\n        // avoid the stat syscall since we can be fairly sure it's a socket\n        CopyParams(FdMeta::Socket, Some(self.as_raw_fd()))\n    }\n}\n\nimpl CopyRead for &TcpStream {\n    fn properties(&self) -> CopyParams {\n        // avoid the stat syscall since we can be fairly sure it's a socket\n        CopyParams(FdMeta::Socket, Some(self.as_raw_fd()))\n    }\n}\n\nimpl CopyWrite for TcpStream {\n    fn properties(&self) -> CopyParams {\n        // avoid the stat syscall since we can be fairly sure it's a socket\n        CopyParams(FdMeta::Socket, Some(self.as_raw_fd()))\n    }\n}\n\nimpl CopyWrite for &TcpStream {\n    fn properties(&self) -> CopyParams {\n        // avoid the stat syscall since we can be fairly sure it's a socket\n        CopyParams(FdMeta::Socket, Some(self.as_raw_fd()))\n    }\n}\n\nimpl CopyRead for UnixStream {\n    fn properties(&self) -> CopyParams {\n        // avoid the stat syscall since we can be fairly sure it's a socket\n        CopyParams(FdMeta::Socket, Some(self.as_raw_fd()))\n    }\n}\n\nimpl CopyRead for &UnixStream {\n    fn properties(&self) -> CopyParams {\n        // avoid the stat syscall since we can be fairly sure it's a socket\n        CopyParams(FdMeta::Socket, Some(self.as_raw_fd()))\n    }\n}\n\nimpl CopyWrite for UnixStream {\n    fn properties(&self) -> CopyParams {\n        // avoid the stat syscall since we can be fairly sure it's a socket\n        CopyParams(FdMeta::Socket, Some(self.as_raw_fd()))\n    }\n}\n\nimpl CopyWrite for &UnixStream {\n    fn properties(&self) -> CopyParams {\n        // avoid the stat syscall since we can be fairly sure it's a socket\n        CopyParams(FdMeta::Socket, Some(self.as_raw_fd()))\n    }\n}\n\nimpl CopyWrite for ChildStdin {\n    fn properties(&self) -> CopyParams {\n        CopyParams(FdMeta::Pipe, Some(self.as_raw_fd()))\n    }\n}\n\nimpl CopyRead for ChildStdout {\n    fn properties(&self) -> CopyParams {\n        CopyParams(FdMeta::Pipe, Some(self.as_raw_fd()))\n    }\n}\n\nimpl CopyRead for ChildStderr {\n    fn properties(&self) -> CopyParams {\n        CopyParams(FdMeta::Pipe, Some(self.as_raw_fd()))\n    }\n}\n\nimpl CopyRead for StdinLock<'_> {\n    fn drain_to<W: Write>(&mut self, writer: &mut W, outer_limit: u64) -> Result<u64> {\n        let buf_reader = self.as_mut_buf();\n        let buf = buf_reader.buffer();\n        let buf = &buf[0..min(buf.len(), outer_limit.try_into().unwrap_or(usize::MAX))];\n        let bytes_drained = buf.len();\n        writer.write_all(buf)?;\n        buf_reader.consume(bytes_drained);\n\n        Ok(bytes_drained as u64)\n    }\n\n    fn properties(&self) -> CopyParams {\n        CopyParams(fd_to_meta(self), Some(self.as_raw_fd()))\n    }\n}\n\nimpl CopyWrite for StdoutLock<'_> {\n    fn properties(&self) -> CopyParams {\n        CopyParams(FdMeta::NoneObtained, Some(self.as_raw_fd()))\n    }\n}\n\nimpl CopyWrite for StderrLock<'_> {\n    fn properties(&self) -> CopyParams {\n        CopyParams(FdMeta::NoneObtained, Some(self.as_raw_fd()))\n    }\n}\n\nimpl<T: CopyRead> CopyRead for Take<T> {\n    fn drain_to<W: Write>(&mut self, writer: &mut W, outer_limit: u64) -> Result<u64> {\n        let local_limit = self.limit();\n        let combined_limit = min(outer_limit, local_limit);\n        let bytes_drained = self.get_mut().drain_to(writer, combined_limit)?;\n        // update limit since read() was bypassed\n        self.set_limit(local_limit - bytes_drained);\n\n        Ok(bytes_drained)\n    }\n\n    fn taken(&mut self, bytes: u64) {\n        self.set_limit(self.limit() - bytes);\n        self.get_mut().taken(bytes);\n    }\n\n    fn min_limit(&self) -> u64 {\n        min(Take::limit(self), self.get_ref().min_limit())\n    }\n\n    fn properties(&self) -> CopyParams {\n        self.get_ref().properties()\n    }\n}\n\nimpl<T: CopyRead> CopyRead for BufReader<T> {\n    fn drain_to<W: Write>(&mut self, writer: &mut W, outer_limit: u64) -> Result<u64> {\n        let buf = self.buffer();\n        let buf = &buf[0..min(buf.len(), outer_limit.try_into().unwrap_or(usize::MAX))];\n        let bytes = buf.len();\n        writer.write_all(buf)?;\n        self.consume(bytes);\n\n        let remaining = outer_limit - bytes as u64;\n\n        // in case of nested bufreaders we also need to drain the ones closer to the source\n        let inner_bytes = self.get_mut().drain_to(writer, remaining)?;\n\n        Ok(bytes as u64 + inner_bytes)\n    }\n\n    fn taken(&mut self, bytes: u64) {\n        self.get_mut().taken(bytes);\n    }\n\n    fn min_limit(&self) -> u64 {\n        self.get_ref().min_limit()\n    }\n\n    fn properties(&self) -> CopyParams {\n        self.get_ref().properties()\n    }\n}\n\nimpl<T: CopyWrite> CopyWrite for BufWriter<T> {\n    fn properties(&self) -> CopyParams {\n        self.get_ref().properties()\n    }\n}\n\nfn fd_to_meta<T: AsRawFd>(fd: &T) -> FdMeta {\n    let fd = fd.as_raw_fd();\n    let file: ManuallyDrop<File> = ManuallyDrop::new(unsafe { File::from_raw_fd(fd) });\n    match file.metadata() {\n        Ok(meta) => FdMeta::Metadata(meta),\n        Err(_) => FdMeta::NoneObtained,\n    }\n}\n\npub(super) enum CopyResult {\n    Ended(u64),\n    Error(Error, u64),\n    Fallback(u64),\n}\n\nimpl CopyResult {\n    fn update_take(&self, reader: &mut impl CopyRead) {\n        match *self {\n            CopyResult::Fallback(bytes)\n            | CopyResult::Ended(bytes)\n            | CopyResult::Error(_, bytes) => reader.taken(bytes),\n        }\n    }\n}\n\n/// Invalid file descriptor.\n///\n/// Valid file descriptors are guaranteed to be positive numbers (see `open()` manpage)\n/// while negative values are used to indicate errors.\n/// Thus -1 will never be overlap with a valid open file.\nconst INVALID_FD: RawFd = -1;\n\n/// Linux-specific implementation that will attempt to use copy_file_range for copy offloading.\n/// As the name says, it only works on regular files.\n///\n/// Callers must handle fallback to a generic copy loop.\n/// `Fallback` may indicate non-zero number of bytes already written\n/// if one of the files' cursor +`max_len` would exceed u64::MAX (`EOVERFLOW`).\npub(super) fn copy_regular_files(reader: RawFd, writer: RawFd, max_len: u64) -> CopyResult {\n    use crate::cmp;\n\n    const NOT_PROBED: u8 = 0;\n    const UNAVAILABLE: u8 = 1;\n    const AVAILABLE: u8 = 2;\n\n    // Kernel prior to 4.5 don't have copy_file_range\n    // We store the availability in a global to avoid unnecessary syscalls\n    static HAS_COPY_FILE_RANGE: AtomicU8 = AtomicU8::new(NOT_PROBED);\n\n    syscall! {\n        fn copy_file_range(\n            fd_in: libc::c_int,\n            off_in: *mut libc::loff_t,\n            fd_out: libc::c_int,\n            off_out: *mut libc::loff_t,\n            len: libc::size_t,\n            flags: libc::c_uint\n        ) -> libc::ssize_t\n    }\n\n    match HAS_COPY_FILE_RANGE.load(Ordering::Relaxed) {\n        NOT_PROBED => {\n            // EPERM can indicate seccomp filters or an immutable file.\n            // To distinguish these cases we probe with invalid file descriptors which should result in EBADF if the syscall is supported\n            // and some other error (ENOSYS or EPERM) if it's not available\n            let result = unsafe {\n                cvt(copy_file_range(INVALID_FD, ptr::null_mut(), INVALID_FD, ptr::null_mut(), 1, 0))\n            };\n\n            if matches!(result.map_err(|e| e.raw_os_error()), Err(Some(EBADF))) {\n                HAS_COPY_FILE_RANGE.store(AVAILABLE, Ordering::Relaxed);\n            } else {\n                HAS_COPY_FILE_RANGE.store(UNAVAILABLE, Ordering::Relaxed);\n                return CopyResult::Fallback(0);\n            }\n        }\n        UNAVAILABLE => return CopyResult::Fallback(0),\n        _ => {}\n    };\n\n    let mut written = 0u64;\n    while written < max_len {\n        let bytes_to_copy = cmp::min(max_len - written, usize::MAX as u64);\n        // cap to 1GB chunks in case u64::MAX is passed as max_len and the file has a non-zero seek position\n        // this allows us to copy large chunks without hitting EOVERFLOW,\n        // unless someone sets a file offset close to u64::MAX - 1GB, in which case a fallback would be required\n        let bytes_to_copy = cmp::min(bytes_to_copy as usize, 0x4000_0000usize);\n        let copy_result = unsafe {\n            // We actually don't have to adjust the offsets,\n            // because copy_file_range adjusts the file offset automatically\n            cvt(copy_file_range(reader, ptr::null_mut(), writer, ptr::null_mut(), bytes_to_copy, 0))\n        };\n\n        match copy_result {\n            Ok(0) if written == 0 => {\n                // fallback to work around several kernel bugs where copy_file_range will fail to\n                // copy any bytes and return 0 instead of an error if\n                // - reading virtual files from the proc filesystem which appear to have 0 size\n                //   but are not empty. noted in coreutils to affect kernels at least up to 5.6.19.\n                // - copying from an overlay filesystem in docker. reported to occur on fedora 32.\n                return CopyResult::Fallback(0);\n            }\n            Ok(0) => return CopyResult::Ended(written), // reached EOF\n            Ok(ret) => written += ret as u64,\n            Err(err) => {\n                return match err.raw_os_error() {\n                    // when file offset + max_length > u64::MAX\n                    Some(EOVERFLOW) => CopyResult::Fallback(written),\n                    Some(ENOSYS | EXDEV | EINVAL | EPERM | EOPNOTSUPP | EBADF) => {\n                        // Try fallback io::copy if either:\n                        // - Kernel version is < 4.5 (ENOSYS¹)\n                        // - Files are mounted on different fs (EXDEV)\n                        // - copy_file_range is broken in various ways on RHEL/CentOS 7 (EOPNOTSUPP)\n                        // - copy_file_range file is immutable or syscall is blocked by seccomp¹ (EPERM)\n                        // - copy_file_range cannot be used with pipes or device nodes (EINVAL)\n                        // - the writer fd was opened with O_APPEND (EBADF²)\n                        //\n                        // ¹ these cases should be detected by the initial probe but we handle them here\n                        //   anyway in case syscall interception changes during runtime\n                        // ² actually invalid file descriptors would cause this too, but in that case\n                        //   the fallback code path is expected to encounter the same error again\n                        assert_eq!(written, 0);\n                        CopyResult::Fallback(0)\n                    }\n                    _ => CopyResult::Error(err, written),\n                };\n            }\n        }\n    }\n    CopyResult::Ended(written)\n}\n\n#[derive(PartialEq)]\nenum SpliceMode {\n    Sendfile,\n    Splice,\n}\n\n/// performs splice or sendfile between file descriptors\n/// Does _not_ fall back to a generic copy loop.\nfn sendfile_splice(mode: SpliceMode, reader: RawFd, writer: RawFd, len: u64) -> CopyResult {\n    static HAS_SENDFILE: AtomicBool = AtomicBool::new(true);\n    static HAS_SPLICE: AtomicBool = AtomicBool::new(true);\n\n    syscall! {\n        fn splice(\n            srcfd: libc::c_int,\n            src_offset: *const i64,\n            dstfd: libc::c_int,\n            dst_offset: *const i64,\n            len: libc::size_t,\n            flags: libc::c_int\n        ) -> libc::ssize_t\n    }\n\n    match mode {\n        SpliceMode::Sendfile if !HAS_SENDFILE.load(Ordering::Relaxed) => {\n            return CopyResult::Fallback(0);\n        }\n        SpliceMode::Splice if !HAS_SPLICE.load(Ordering::Relaxed) => {\n            return CopyResult::Fallback(0);\n        }\n        _ => (),\n    }\n\n    let mut written = 0u64;\n    while written < len {\n        // according to its manpage that's the maximum size sendfile() will copy per invocation\n        let chunk_size = crate::cmp::min(len - written, 0x7ffff000_u64) as usize;\n\n        let result = match mode {\n            SpliceMode::Sendfile => {\n                cvt(unsafe { libc::sendfile(writer, reader, ptr::null_mut(), chunk_size) })\n            }\n            SpliceMode::Splice => cvt(unsafe {\n                splice(reader, ptr::null_mut(), writer, ptr::null_mut(), chunk_size, 0)\n            }),\n        };\n\n        match result {\n            Ok(0) => break, // EOF\n            Ok(ret) => written += ret as u64,\n            Err(err) => {\n                return match err.raw_os_error() {\n                    Some(ENOSYS | EPERM) => {\n                        // syscall not supported (ENOSYS)\n                        // syscall is disallowed, e.g. by seccomp (EPERM)\n                        match mode {\n                            SpliceMode::Sendfile => HAS_SENDFILE.store(false, Ordering::Relaxed),\n                            SpliceMode::Splice => HAS_SPLICE.store(false, Ordering::Relaxed),\n                        }\n                        assert_eq!(written, 0);\n                        CopyResult::Fallback(0)\n                    }\n                    Some(EINVAL) => {\n                        // splice/sendfile do not support this particular file descriptor (EINVAL)\n                        assert_eq!(written, 0);\n                        CopyResult::Fallback(0)\n                    }\n                    Some(os_err) if mode == SpliceMode::Sendfile && os_err == EOVERFLOW => {\n                        CopyResult::Fallback(written)\n                    }\n                    _ => CopyResult::Error(err, written),\n                };\n            }\n        }\n    }\n    CopyResult::Ended(written)\n}\n"],[2325,"#![cfg_attr(test, allow(dead_code))]\n\nuse self::imp::{drop_handler, make_handler};\n\npub use self::imp::cleanup;\npub use self::imp::init;\n\npub struct Handler {\n    _data: *mut libc::c_void,\n}\n\nimpl Handler {\n    pub unsafe fn new() -> Handler {\n        make_handler()\n    }\n\n    fn null() -> Handler {\n        Handler { _data: crate::ptr::null_mut() }\n    }\n}\n\nimpl Drop for Handler {\n    fn drop(&mut self) {\n        unsafe {\n            drop_handler(self);\n        }\n    }\n}\n\n#[cfg(any(\n    target_os = \"linux\",\n    target_os = \"macos\",\n    target_os = \"dragonfly\",\n    target_os = \"freebsd\",\n    target_os = \"solaris\",\n    target_os = \"illumos\",\n    target_os = \"netbsd\",\n    target_os = \"openbsd\"\n))]\nmod imp {\n    use super::Handler;\n    use crate::io;\n    use crate::mem;\n    use crate::ptr;\n    use crate::thread;\n\n    use libc::MAP_FAILED;\n    use libc::{mmap, munmap};\n    use libc::{sigaction, sighandler_t, SA_ONSTACK, SA_SIGINFO, SIGBUS, SIG_DFL};\n    use libc::{sigaltstack, SIGSTKSZ, SS_DISABLE};\n    use libc::{MAP_ANON, MAP_PRIVATE, PROT_NONE, PROT_READ, PROT_WRITE, SIGSEGV};\n\n    use crate::sync::atomic::{AtomicBool, AtomicPtr, Ordering};\n    use crate::sys::unix::os::page_size;\n    use crate::sys_common::thread_info;\n\n    #[cfg(any(target_os = \"linux\", target_os = \"android\"))]\n    unsafe fn siginfo_si_addr(info: *mut libc::siginfo_t) -> usize {\n        #[repr(C)]\n        struct siginfo_t {\n            a: [libc::c_int; 3], // si_signo, si_errno, si_code\n            si_addr: *mut libc::c_void,\n        }\n\n        (*(info as *const siginfo_t)).si_addr as usize\n    }\n\n    #[cfg(not(any(target_os = \"linux\", target_os = \"android\")))]\n    unsafe fn siginfo_si_addr(info: *mut libc::siginfo_t) -> usize {\n        (*info).si_addr as usize\n    }\n\n    // Signal handler for the SIGSEGV and SIGBUS handlers. We've got guard pages\n    // (unmapped pages) at the end of every thread's stack, so if a thread ends\n    // up running into the guard page it'll trigger this handler. We want to\n    // detect these cases and print out a helpful error saying that the stack\n    // has overflowed. All other signals, however, should go back to what they\n    // were originally supposed to do.\n    //\n    // This handler currently exists purely to print an informative message\n    // whenever a thread overflows its stack. We then abort to exit and\n    // indicate a crash, but to avoid a misleading SIGSEGV that might lead\n    // users to believe that unsafe code has accessed an invalid pointer; the\n    // SIGSEGV encountered when overflowing the stack is expected and\n    // well-defined.\n    //\n    // If this is not a stack overflow, the handler un-registers itself and\n    // then returns (to allow the original signal to be delivered again).\n    // Returning from this kind of signal handler is technically not defined\n    // to work when reading the POSIX spec strictly, but in practice it turns\n    // out many large systems and all implementations allow returning from a\n    // signal handler to work. For a more detailed explanation see the\n    // comments on #26458.\n    unsafe extern \"C\" fn signal_handler(\n        signum: libc::c_int,\n        info: *mut libc::siginfo_t,\n        _data: *mut libc::c_void,\n    ) {\n        let guard = thread_info::stack_guard().unwrap_or(0..0);\n        let addr = siginfo_si_addr(info);\n\n        // If the faulting address is within the guard page, then we print a\n        // message saying so and abort.\n        if guard.start <= addr && addr < guard.end {\n            rtprintpanic!(\n                \"\\nthread '{}' has overflowed its stack\\n\",\n                thread::current().name().unwrap_or(\"<unknown>\")\n            );\n            rtabort!(\"stack overflow\");\n        } else {\n            // Unregister ourselves by reverting back to the default behavior.\n            let mut action: sigaction = mem::zeroed();\n            action.sa_sigaction = SIG_DFL;\n            sigaction(signum, &action, ptr::null_mut());\n\n            // See comment above for why this function returns.\n        }\n    }\n\n    static MAIN_ALTSTACK: AtomicPtr<libc::c_void> = AtomicPtr::new(ptr::null_mut());\n    static NEED_ALTSTACK: AtomicBool = AtomicBool::new(false);\n\n    pub unsafe fn init() {\n        let mut action: sigaction = mem::zeroed();\n        for &signal in &[SIGSEGV, SIGBUS] {\n            sigaction(signal, ptr::null_mut(), &mut action);\n            // Configure our signal handler if one is not already set.\n            if action.sa_sigaction == SIG_DFL {\n                action.sa_flags = SA_SIGINFO | SA_ONSTACK;\n                action.sa_sigaction = signal_handler as sighandler_t;\n                sigaction(signal, &action, ptr::null_mut());\n                NEED_ALTSTACK.store(true, Ordering::Relaxed);\n            }\n        }\n\n        let handler = make_handler();\n        MAIN_ALTSTACK.store(handler._data, Ordering::Relaxed);\n        mem::forget(handler);\n    }\n\n    pub unsafe fn cleanup() {\n        Handler { _data: MAIN_ALTSTACK.load(Ordering::Relaxed) };\n    }\n\n    unsafe fn get_stackp() -> *mut libc::c_void {\n        let stackp = mmap(\n            ptr::null_mut(),\n            SIGSTKSZ + page_size(),\n            PROT_READ | PROT_WRITE,\n            MAP_PRIVATE | MAP_ANON,\n            -1,\n            0,\n        );\n        if stackp == MAP_FAILED {\n            panic!(\"failed to allocate an alternative stack: {}\", io::Error::last_os_error());\n        }\n        let guard_result = libc::mprotect(stackp, page_size(), PROT_NONE);\n        if guard_result != 0 {\n            panic!(\"failed to set up alternative stack guard page: {}\", io::Error::last_os_error());\n        }\n        stackp.add(page_size())\n    }\n\n    #[cfg(any(\n        target_os = \"linux\",\n        target_os = \"macos\",\n        target_os = \"freebsd\",\n        target_os = \"netbsd\",\n        target_os = \"openbsd\",\n        target_os = \"solaris\",\n        target_os = \"illumos\"\n    ))]\n    unsafe fn get_stack() -> libc::stack_t {\n        libc::stack_t { ss_sp: get_stackp(), ss_flags: 0, ss_size: SIGSTKSZ }\n    }\n\n    #[cfg(target_os = \"dragonfly\")]\n    unsafe fn get_stack() -> libc::stack_t {\n        libc::stack_t { ss_sp: get_stackp() as *mut i8, ss_flags: 0, ss_size: SIGSTKSZ }\n    }\n\n    pub unsafe fn make_handler() -> Handler {\n        if !NEED_ALTSTACK.load(Ordering::Relaxed) {\n            return Handler::null();\n        }\n        let mut stack = mem::zeroed();\n        sigaltstack(ptr::null(), &mut stack);\n        // Configure alternate signal stack, if one is not already set.\n        if stack.ss_flags & SS_DISABLE != 0 {\n            stack = get_stack();\n            sigaltstack(&stack, ptr::null_mut());\n            Handler { _data: stack.ss_sp as *mut libc::c_void }\n        } else {\n            Handler::null()\n        }\n    }\n\n    pub unsafe fn drop_handler(handler: &mut Handler) {\n        if !handler._data.is_null() {\n            let stack = libc::stack_t {\n                ss_sp: ptr::null_mut(),\n                ss_flags: SS_DISABLE,\n                // Workaround for bug in macOS implementation of sigaltstack\n                // UNIX2003 which returns ENOMEM when disabling a stack while\n                // passing ss_size smaller than MINSIGSTKSZ. According to POSIX\n                // both ss_sp and ss_size should be ignored in this case.\n                ss_size: SIGSTKSZ,\n            };\n            sigaltstack(&stack, ptr::null_mut());\n            // We know from `get_stackp` that the alternate stack we installed is part of a mapping\n            // that started one page earlier, so walk back a page and unmap from there.\n            munmap(handler._data.sub(page_size()), SIGSTKSZ + page_size());\n        }\n    }\n}\n\n#[cfg(not(any(\n    target_os = \"linux\",\n    target_os = \"macos\",\n    target_os = \"dragonfly\",\n    target_os = \"freebsd\",\n    target_os = \"solaris\",\n    target_os = \"illumos\",\n    target_os = \"netbsd\",\n    target_os = \"openbsd\",\n)))]\nmod imp {\n    pub unsafe fn init() {}\n\n    pub unsafe fn cleanup() {}\n\n    pub unsafe fn make_handler() -> super::Handler {\n        super::Handler::null()\n    }\n\n    pub unsafe fn drop_handler(_handler: &mut super::Handler) {}\n}\n"],[2326,"use crate::alloc::{GlobalAlloc, Layout, System};\nuse crate::ptr;\nuse crate::sys::common::alloc::{realloc_fallback, MIN_ALIGN};\n\n#[stable(feature = \"alloc_system_type\", since = \"1.28.0\")]\nunsafe impl GlobalAlloc for System {\n    #[inline]\n    unsafe fn alloc(&self, layout: Layout) -> *mut u8 {\n        // jemalloc provides alignment less than MIN_ALIGN for small allocations.\n        // So only rely on MIN_ALIGN if size >= align.\n        // Also see <https://github.com/rust-lang/rust/issues/45955> and\n        // <https://github.com/rust-lang/rust/issues/62251#issuecomment-507580914>.\n        if layout.align() <= MIN_ALIGN && layout.align() <= layout.size() {\n            libc::malloc(layout.size()) as *mut u8\n        } else {\n            #[cfg(target_os = \"macos\")]\n            {\n                if layout.align() > (1 << 31) {\n                    return ptr::null_mut();\n                }\n            }\n            aligned_malloc(&layout)\n        }\n    }\n\n    #[inline]\n    unsafe fn alloc_zeroed(&self, layout: Layout) -> *mut u8 {\n        // See the comment above in `alloc` for why this check looks the way it does.\n        if layout.align() <= MIN_ALIGN && layout.align() <= layout.size() {\n            libc::calloc(layout.size(), 1) as *mut u8\n        } else {\n            let ptr = self.alloc(layout);\n            if !ptr.is_null() {\n                ptr::write_bytes(ptr, 0, layout.size());\n            }\n            ptr\n        }\n    }\n\n    #[inline]\n    unsafe fn dealloc(&self, ptr: *mut u8, _layout: Layout) {\n        libc::free(ptr as *mut libc::c_void)\n    }\n\n    #[inline]\n    unsafe fn realloc(&self, ptr: *mut u8, layout: Layout, new_size: usize) -> *mut u8 {\n        if layout.align() <= MIN_ALIGN && layout.align() <= new_size {\n            libc::realloc(ptr as *mut libc::c_void, new_size) as *mut u8\n        } else {\n            realloc_fallback(self, ptr, layout, new_size)\n        }\n    }\n}\n\ncfg_if::cfg_if! {\n    if #[cfg(any(\n        target_os = \"android\",\n        target_os = \"illumos\",\n        target_os = \"redox\",\n        target_os = \"solaris\"\n    ))] {\n        #[inline]\n        unsafe fn aligned_malloc(layout: &Layout) -> *mut u8 {\n            // On android we currently target API level 9 which unfortunately\n            // doesn't have the `posix_memalign` API used below. Instead we use\n            // `memalign`, but this unfortunately has the property on some systems\n            // where the memory returned cannot be deallocated by `free`!\n            //\n            // Upon closer inspection, however, this appears to work just fine with\n            // Android, so for this platform we should be fine to call `memalign`\n            // (which is present in API level 9). Some helpful references could\n            // possibly be chromium using memalign [1], attempts at documenting that\n            // memalign + free is ok [2] [3], or the current source of chromium\n            // which still uses memalign on android [4].\n            //\n            // [1]: https://codereview.chromium.org/10796020/\n            // [2]: https://code.google.com/p/android/issues/detail?id=35391\n            // [3]: https://bugs.chromium.org/p/chromium/issues/detail?id=138579\n            // [4]: https://chromium.googlesource.com/chromium/src/base/+/master/\n            //                                       /memory/aligned_memory.cc\n            libc::memalign(layout.align(), layout.size()) as *mut u8\n        }\n    } else if #[cfg(target_os = \"wasi\")] {\n        #[inline]\n        unsafe fn aligned_malloc(layout: &Layout) -> *mut u8 {\n            libc::aligned_alloc(layout.align(), layout.size()) as *mut u8\n        }\n    } else {\n        #[inline]\n        unsafe fn aligned_malloc(layout: &Layout) -> *mut u8 {\n            let mut out = ptr::null_mut();\n            // posix_memalign requires that the alignment be a multiple of `sizeof(void*)`.\n            // Since these are all powers of 2, we can just use max.\n            let align = layout.align().max(crate::mem::size_of::<usize>());\n            let ret = libc::posix_memalign(&mut out, align, layout.size());\n            if ret != 0 { ptr::null_mut() } else { out as *mut u8 }\n        }\n    }\n}\n"],[2327,"#![allow(non_camel_case_types, unused)]\n\nuse crate::convert::TryInto;\nuse crate::io;\nuse crate::mem::MaybeUninit;\nuse crate::os::raw::c_char;\n\nuse libc::{c_int, c_void, size_t};\n\npub type zx_handle_t = u32;\npub type zx_vaddr_t = usize;\npub type zx_rights_t = u32;\npub type zx_status_t = i32;\n\npub const ZX_HANDLE_INVALID: zx_handle_t = 0;\n\npub type zx_time_t = i64;\npub const ZX_TIME_INFINITE: zx_time_t = i64::MAX;\n\npub type zx_signals_t = u32;\n\npub const ZX_OBJECT_SIGNAL_3: zx_signals_t = 1 << 3;\n\npub const ZX_TASK_TERMINATED: zx_signals_t = ZX_OBJECT_SIGNAL_3;\n\npub const ZX_RIGHT_SAME_RIGHTS: zx_rights_t = 1 << 31;\n\npub type zx_object_info_topic_t = u32;\n\npub const ZX_INFO_PROCESS: zx_object_info_topic_t = 3;\n\npub fn zx_cvt<T>(t: T) -> io::Result<T>\nwhere\n    T: TryInto<zx_status_t> + Copy,\n{\n    if let Ok(status) = TryInto::try_into(t) {\n        if status < 0 { Err(io::Error::from_raw_os_error(status)) } else { Ok(t) }\n    } else {\n        Err(io::Error::last_os_error())\n    }\n}\n\n// Safe wrapper around zx_handle_t\npub struct Handle {\n    raw: zx_handle_t,\n}\n\nimpl Handle {\n    pub fn new(raw: zx_handle_t) -> Handle {\n        Handle { raw }\n    }\n\n    pub fn raw(&self) -> zx_handle_t {\n        self.raw\n    }\n}\n\nimpl Drop for Handle {\n    fn drop(&mut self) {\n        unsafe {\n            zx_cvt(zx_handle_close(self.raw)).expect(\"Failed to close zx_handle_t\");\n        }\n    }\n}\n\n// Returned for topic ZX_INFO_PROCESS\n#[derive(Default)]\n#[repr(C)]\npub struct zx_info_process_t {\n    pub return_code: i64,\n    pub started: bool,\n    pub exited: bool,\n    pub debugger_attached: bool,\n}\n\nextern \"C\" {\n    pub fn zx_job_default() -> zx_handle_t;\n\n    pub fn zx_task_kill(handle: zx_handle_t) -> zx_status_t;\n\n    pub fn zx_handle_close(handle: zx_handle_t) -> zx_status_t;\n\n    pub fn zx_handle_duplicate(\n        handle: zx_handle_t,\n        rights: zx_rights_t,\n        out: *const zx_handle_t,\n    ) -> zx_handle_t;\n\n    pub fn zx_object_wait_one(\n        handle: zx_handle_t,\n        signals: zx_signals_t,\n        timeout: zx_time_t,\n        pending: *mut zx_signals_t,\n    ) -> zx_status_t;\n\n    pub fn zx_object_get_info(\n        handle: zx_handle_t,\n        topic: u32,\n        buffer: *mut c_void,\n        buffer_size: size_t,\n        actual_size: *mut size_t,\n        avail: *mut size_t,\n    ) -> zx_status_t;\n}\n\n#[derive(Default)]\n#[repr(C)]\npub struct fdio_spawn_action_t {\n    pub action: u32,\n    pub reserved0: u32,\n    pub local_fd: i32,\n    pub target_fd: i32,\n    pub reserved1: u64,\n}\n\nextern \"C\" {\n    pub fn fdio_spawn_etc(\n        job: zx_handle_t,\n        flags: u32,\n        path: *const c_char,\n        argv: *const *const c_char,\n        envp: *const *const c_char,\n        action_count: size_t,\n        actions: *const fdio_spawn_action_t,\n        process: *mut zx_handle_t,\n        err_msg: *mut c_char,\n    ) -> zx_status_t;\n\n    pub fn fdio_fd_clone(fd: c_int, out_handle: *mut zx_handle_t) -> zx_status_t;\n    pub fn fdio_fd_create(handle: zx_handle_t, fd: *mut c_int) -> zx_status_t;\n}\n\n// fdio_spawn_etc flags\n\npub const FDIO_SPAWN_CLONE_JOB: u32 = 0x0001;\npub const FDIO_SPAWN_CLONE_LDSVC: u32 = 0x0002;\npub const FDIO_SPAWN_CLONE_NAMESPACE: u32 = 0x0004;\npub const FDIO_SPAWN_CLONE_STDIO: u32 = 0x0008;\npub const FDIO_SPAWN_CLONE_ENVIRON: u32 = 0x0010;\npub const FDIO_SPAWN_CLONE_UTC_CLOCK: u32 = 0x0020;\npub const FDIO_SPAWN_CLONE_ALL: u32 = 0xFFFF;\n\n// fdio_spawn_etc actions\n\npub const FDIO_SPAWN_ACTION_CLONE_FD: u32 = 0x0001;\npub const FDIO_SPAWN_ACTION_TRANSFER_FD: u32 = 0x0002;\n\n// Errors\n\n#[allow(unused)]\npub const ERR_INTERNAL: zx_status_t = -1;\n\n// ERR_NOT_SUPPORTED: The operation is not implemented, supported,\n// or enabled.\n#[allow(unused)]\npub const ERR_NOT_SUPPORTED: zx_status_t = -2;\n\n// ERR_NO_RESOURCES: The system was not able to allocate some resource\n// needed for the operation.\n#[allow(unused)]\npub const ERR_NO_RESOURCES: zx_status_t = -3;\n\n// ERR_NO_MEMORY: The system was not able to allocate memory needed\n// for the operation.\n#[allow(unused)]\npub const ERR_NO_MEMORY: zx_status_t = -4;\n\n// ERR_CALL_FAILED: The second phase of zx_channel_call(; did not complete\n// successfully.\n#[allow(unused)]\npub const ERR_CALL_FAILED: zx_status_t = -5;\n\n// ERR_INTERRUPTED_RETRY: The system call was interrupted, but should be\n// retried.  This should not be seen outside of the VDSO.\n#[allow(unused)]\npub const ERR_INTERRUPTED_RETRY: zx_status_t = -6;\n\n// ======= Parameter errors =======\n// ERR_INVALID_ARGS: an argument is invalid, ex. null pointer\n#[allow(unused)]\npub const ERR_INVALID_ARGS: zx_status_t = -10;\n\n// ERR_BAD_HANDLE: A specified handle value does not refer to a handle.\n#[allow(unused)]\npub const ERR_BAD_HANDLE: zx_status_t = -11;\n\n// ERR_WRONG_TYPE: The subject of the operation is the wrong type to\n// perform the operation.\n// Example: Attempting a message_read on a thread handle.\n#[allow(unused)]\npub const ERR_WRONG_TYPE: zx_status_t = -12;\n\n// ERR_BAD_SYSCALL: The specified syscall number is invalid.\n#[allow(unused)]\npub const ERR_BAD_SYSCALL: zx_status_t = -13;\n\n// ERR_OUT_OF_RANGE: An argument is outside the valid range for this\n// operation.\n#[allow(unused)]\npub const ERR_OUT_OF_RANGE: zx_status_t = -14;\n\n// ERR_BUFFER_TOO_SMALL: A caller provided buffer is too small for\n// this operation.\n#[allow(unused)]\npub const ERR_BUFFER_TOO_SMALL: zx_status_t = -15;\n\n// ======= Precondition or state errors =======\n// ERR_BAD_STATE: operation failed because the current state of the\n// object does not allow it, or a precondition of the operation is\n// not satisfied\n#[allow(unused)]\npub const ERR_BAD_STATE: zx_status_t = -20;\n\n// ERR_TIMED_OUT: The time limit for the operation elapsed before\n// the operation completed.\n#[allow(unused)]\npub const ERR_TIMED_OUT: zx_status_t = -21;\n\n// ERR_SHOULD_WAIT: The operation cannot be performed currently but\n// potentially could succeed if the caller waits for a prerequisite\n// to be satisfied, for example waiting for a handle to be readable\n// or writable.\n// Example: Attempting to read from a message pipe that has no\n// messages waiting but has an open remote will return ERR_SHOULD_WAIT.\n// Attempting to read from a message pipe that has no messages waiting\n// and has a closed remote end will return ERR_REMOTE_CLOSED.\n#[allow(unused)]\npub const ERR_SHOULD_WAIT: zx_status_t = -22;\n\n// ERR_CANCELED: The in-progress operation (e.g., a wait) has been\n// // canceled.\n#[allow(unused)]\npub const ERR_CANCELED: zx_status_t = -23;\n\n// ERR_PEER_CLOSED: The operation failed because the remote end\n// of the subject of the operation was closed.\n#[allow(unused)]\npub const ERR_PEER_CLOSED: zx_status_t = -24;\n\n// ERR_NOT_FOUND: The requested entity is not found.\n#[allow(unused)]\npub const ERR_NOT_FOUND: zx_status_t = -25;\n\n// ERR_ALREADY_EXISTS: An object with the specified identifier\n// already exists.\n// Example: Attempting to create a file when a file already exists\n// with that name.\n#[allow(unused)]\npub const ERR_ALREADY_EXISTS: zx_status_t = -26;\n\n// ERR_ALREADY_BOUND: The operation failed because the named entity\n// is already owned or controlled by another entity. The operation\n// could succeed later if the current owner releases the entity.\n#[allow(unused)]\npub const ERR_ALREADY_BOUND: zx_status_t = -27;\n\n// ERR_UNAVAILABLE: The subject of the operation is currently unable\n// to perform the operation.\n// Note: This is used when there's no direct way for the caller to\n// observe when the subject will be able to perform the operation\n// and should thus retry.\n#[allow(unused)]\npub const ERR_UNAVAILABLE: zx_status_t = -28;\n\n// ======= Permission check errors =======\n// ERR_ACCESS_DENIED: The caller did not have permission to perform\n// the specified operation.\n#[allow(unused)]\npub const ERR_ACCESS_DENIED: zx_status_t = -30;\n\n// ======= Input-output errors =======\n// ERR_IO: Otherwise unspecified error occurred during I/O.\n#[allow(unused)]\npub const ERR_IO: zx_status_t = -40;\n\n// ERR_REFUSED: The entity the I/O operation is being performed on\n// rejected the operation.\n// Example: an I2C device NAK'ing a transaction or a disk controller\n// rejecting an invalid command.\n#[allow(unused)]\npub const ERR_IO_REFUSED: zx_status_t = -41;\n\n// ERR_IO_DATA_INTEGRITY: The data in the operation failed an integrity\n// check and is possibly corrupted.\n// Example: CRC or Parity error.\n#[allow(unused)]\npub const ERR_IO_DATA_INTEGRITY: zx_status_t = -42;\n\n// ERR_IO_DATA_LOSS: The data in the operation is currently unavailable\n// and may be permanently lost.\n// Example: A disk block is irrecoverably damaged.\n#[allow(unused)]\npub const ERR_IO_DATA_LOSS: zx_status_t = -43;\n\n// Filesystem specific errors\n#[allow(unused)]\npub const ERR_BAD_PATH: zx_status_t = -50;\n#[allow(unused)]\npub const ERR_NOT_DIR: zx_status_t = -51;\n#[allow(unused)]\npub const ERR_NOT_FILE: zx_status_t = -52;\n// ERR_FILE_BIG: A file exceeds a filesystem-specific size limit.\n#[allow(unused)]\npub const ERR_FILE_BIG: zx_status_t = -53;\n// ERR_NO_SPACE: Filesystem or device space is exhausted.\n#[allow(unused)]\npub const ERR_NO_SPACE: zx_status_t = -54;\n"],[2328,"use crate::convert::{TryFrom, TryInto};\nuse crate::fmt;\nuse crate::io;\nuse crate::mem;\nuse crate::num::{NonZeroI32, NonZeroI64};\nuse crate::ptr;\n\nuse crate::sys::process::process_common::*;\nuse crate::sys::process::zircon::{zx_handle_t, Handle};\n\nuse libc::{c_int, size_t};\n\n////////////////////////////////////////////////////////////////////////////////\n// Command\n////////////////////////////////////////////////////////////////////////////////\n\nimpl Command {\n    pub fn spawn(\n        &mut self,\n        default: Stdio,\n        needs_stdin: bool,\n    ) -> io::Result<(Process, StdioPipes)> {\n        let envp = self.capture_env();\n\n        if self.saw_nul() {\n            return Err(io::Error::new_const(\n                io::ErrorKind::InvalidInput,\n                &\"nul byte found in provided data\",\n            ));\n        }\n\n        let (ours, theirs) = self.setup_io(default, needs_stdin)?;\n\n        let process_handle = unsafe { self.do_exec(theirs, envp.as_ref())? };\n\n        Ok((Process { handle: Handle::new(process_handle) }, ours))\n    }\n\n    pub fn exec(&mut self, default: Stdio) -> io::Error {\n        if self.saw_nul() {\n            return io::Error::new_const(\n                io::ErrorKind::InvalidInput,\n                &\"nul byte found in provided data\",\n            );\n        }\n\n        match self.setup_io(default, true) {\n            Ok((_, _)) => {\n                // FIXME: This is tough because we don't support the exec syscalls\n                unimplemented!();\n            }\n            Err(e) => e,\n        }\n    }\n\n    unsafe fn do_exec(\n        &mut self,\n        stdio: ChildPipes,\n        maybe_envp: Option<&CStringArray>,\n    ) -> io::Result<zx_handle_t> {\n        use crate::sys::process::zircon::*;\n\n        let envp = match maybe_envp {\n            // None means to clone the current environment, which is done in the\n            // flags below.\n            None => ptr::null(),\n            Some(envp) => envp.as_ptr(),\n        };\n\n        let make_action = |local_io: &ChildStdio, target_fd| -> io::Result<fdio_spawn_action_t> {\n            if let Some(local_fd) = local_io.fd() {\n                Ok(fdio_spawn_action_t {\n                    action: FDIO_SPAWN_ACTION_TRANSFER_FD,\n                    local_fd,\n                    target_fd,\n                    ..Default::default()\n                })\n            } else {\n                if let ChildStdio::Null = local_io {\n                    // acts as no-op\n                    return Ok(Default::default());\n                }\n\n                let mut handle = ZX_HANDLE_INVALID;\n                let status = fdio_fd_clone(target_fd, &mut handle);\n                if status == ERR_INVALID_ARGS || status == ERR_NOT_SUPPORTED {\n                    // This descriptor is closed; skip it rather than generating an\n                    // error.\n                    return Ok(Default::default());\n                }\n                zx_cvt(status)?;\n\n                let mut cloned_fd = 0;\n                zx_cvt(fdio_fd_create(handle, &mut cloned_fd))?;\n\n                Ok(fdio_spawn_action_t {\n                    action: FDIO_SPAWN_ACTION_TRANSFER_FD,\n                    local_fd: cloned_fd as i32,\n                    target_fd,\n                    ..Default::default()\n                })\n            }\n        };\n\n        // Clone stdin, stdout, and stderr\n        let action1 = make_action(&stdio.stdin, 0)?;\n        let action2 = make_action(&stdio.stdout, 1)?;\n        let action3 = make_action(&stdio.stderr, 2)?;\n        let actions = [action1, action2, action3];\n\n        // We don't want FileDesc::drop to be called on any stdio. fdio_spawn_etc\n        // always consumes transferred file descriptors.\n        mem::forget(stdio);\n\n        for callback in self.get_closures().iter_mut() {\n            callback()?;\n        }\n\n        let mut process_handle: zx_handle_t = 0;\n        zx_cvt(fdio_spawn_etc(\n            ZX_HANDLE_INVALID,\n            FDIO_SPAWN_CLONE_JOB\n                | FDIO_SPAWN_CLONE_LDSVC\n                | FDIO_SPAWN_CLONE_NAMESPACE\n                | FDIO_SPAWN_CLONE_ENVIRON // this is ignored when envp is non-null\n                | FDIO_SPAWN_CLONE_UTC_CLOCK,\n            self.get_program_cstr().as_ptr(),\n            self.get_argv().as_ptr(),\n            envp,\n            actions.len() as size_t,\n            actions.as_ptr(),\n            &mut process_handle,\n            ptr::null_mut(),\n        ))?;\n        // FIXME: See if we want to do something with that err_msg\n\n        Ok(process_handle)\n    }\n}\n\n////////////////////////////////////////////////////////////////////////////////\n// Processes\n////////////////////////////////////////////////////////////////////////////////\n\npub struct Process {\n    handle: Handle,\n}\n\nimpl Process {\n    pub fn id(&self) -> u32 {\n        self.handle.raw() as u32\n    }\n\n    pub fn kill(&mut self) -> io::Result<()> {\n        use crate::sys::process::zircon::*;\n\n        unsafe {\n            zx_cvt(zx_task_kill(self.handle.raw()))?;\n        }\n\n        Ok(())\n    }\n\n    pub fn wait(&mut self) -> io::Result<ExitStatus> {\n        use crate::default::Default;\n        use crate::sys::process::zircon::*;\n\n        let mut proc_info: zx_info_process_t = Default::default();\n        let mut actual: size_t = 0;\n        let mut avail: size_t = 0;\n\n        unsafe {\n            zx_cvt(zx_object_wait_one(\n                self.handle.raw(),\n                ZX_TASK_TERMINATED,\n                ZX_TIME_INFINITE,\n                ptr::null_mut(),\n            ))?;\n            zx_cvt(zx_object_get_info(\n                self.handle.raw(),\n                ZX_INFO_PROCESS,\n                &mut proc_info as *mut _ as *mut libc::c_void,\n                mem::size_of::<zx_info_process_t>(),\n                &mut actual,\n                &mut avail,\n            ))?;\n        }\n        if actual != 1 {\n            return Err(io::Error::new_const(\n                io::ErrorKind::InvalidData,\n                &\"Failed to get exit status of process\",\n            ));\n        }\n        Ok(ExitStatus(proc_info.return_code))\n    }\n\n    pub fn try_wait(&mut self) -> io::Result<Option<ExitStatus>> {\n        use crate::default::Default;\n        use crate::sys::process::zircon::*;\n\n        let mut proc_info: zx_info_process_t = Default::default();\n        let mut actual: size_t = 0;\n        let mut avail: size_t = 0;\n\n        unsafe {\n            let status =\n                zx_object_wait_one(self.handle.raw(), ZX_TASK_TERMINATED, 0, ptr::null_mut());\n            match status {\n                0 => {} // Success\n                x if x == ERR_TIMED_OUT => {\n                    return Ok(None);\n                }\n                _ => {\n                    panic!(\"Failed to wait on process handle: {}\", status);\n                }\n            }\n            zx_cvt(zx_object_get_info(\n                self.handle.raw(),\n                ZX_INFO_PROCESS,\n                &mut proc_info as *mut _ as *mut libc::c_void,\n                mem::size_of::<zx_info_process_t>(),\n                &mut actual,\n                &mut avail,\n            ))?;\n        }\n        if actual != 1 {\n            return Err(io::Error::new_const(\n                io::ErrorKind::InvalidData,\n                &\"Failed to get exit status of process\",\n            ));\n        }\n        Ok(Some(ExitStatus(proc_info.return_code)))\n    }\n}\n\n#[derive(PartialEq, Eq, Clone, Copy, Debug)]\npub struct ExitStatus(i64);\n\nimpl ExitStatus {\n    pub fn exit_ok(&self) -> Result<(), ExitStatusError> {\n        match NonZeroI64::try_from(self.0) {\n            /* was nonzero */ Ok(failure) => Err(ExitStatusError(failure)),\n            /* was zero, couldn't convert */ Err(_) => Ok(()),\n        }\n    }\n\n    pub fn code(&self) -> Option<i32> {\n        // FIXME: support extracting return code as an i64\n        self.0.try_into().ok()\n    }\n\n    pub fn signal(&self) -> Option<i32> {\n        None\n    }\n\n    // FIXME: The actually-Unix implementation in process_unix.rs uses WSTOPSIG, WCOREDUMP et al.\n    // I infer from the implementation of `success`, `code` and `signal` above that these are not\n    // available on Fuchsia.\n    //\n    // It does not appear that Fuchsia is Unix-like enough to implement ExitStatus (or indeed many\n    // other things from std::os::unix) properly.  This veneer is always going to be a bodge.  So\n    // while I don't know if these implementations are actually correct, I think they will do for\n    // now at least.\n    pub fn core_dumped(&self) -> bool {\n        false\n    }\n    pub fn stopped_signal(&self) -> Option<i32> {\n        None\n    }\n    pub fn continued(&self) -> bool {\n        false\n    }\n\n    pub fn into_raw(&self) -> c_int {\n        // We don't know what someone who calls into_raw() will do with this value, but it should\n        // have the conventional Unix representation.  Despite the fact that this is not\n        // standardised in SuS or POSIX, all Unix systems encode the signal and exit status the\n        // same way.  (Ie the WIFEXITED, WEXITSTATUS etc. macros have identical behaviour on every\n        // Unix.)\n        //\n        // The caller of `std::os::unix::into_raw` is probably wanting a Unix exit status, and may\n        // do their own shifting and masking, or even pass the status to another computer running a\n        // different Unix variant.\n        //\n        // The other view would be to say that the caller on Fuchsia ought to know that `into_raw`\n        // will give a raw Fuchsia status (whatever that is - I don't know, personally).  That is\n        // not possible here becaause we must return a c_int because that's what Unix (including\n        // SuS and POSIX) say a wait status is, but Fuchsia apparently uses a u64, so it won't\n        // necessarily fit.\n        //\n        // It seems to me that that the right answer would be to provide std::os::fuchsia with its\n        // own ExitStatusExt, rather that trying to provide a not very convincing imitation of\n        // Unix.  Ie, std::os::unix::process:ExitStatusExt ought not to exist on Fuchsia.  But\n        // fixing this up that is beyond the scope of my efforts now.\n        let exit_status_as_if_unix: u8 = self.0.try_into().expect(\"Fuchsia process return code bigger than 8 bits, but std::os::unix::ExitStatusExt::into_raw() was called to try to convert the value into a traditional Unix-style wait status, which cannot represent values greater than 255.\");\n        let wait_status_as_if_unix = (exit_status_as_if_unix as c_int) << 8;\n        wait_status_as_if_unix\n    }\n}\n\n/// Converts a raw `c_int` to a type-safe `ExitStatus` by wrapping it without copying.\nimpl From<c_int> for ExitStatus {\n    fn from(a: c_int) -> ExitStatus {\n        ExitStatus(a as i64)\n    }\n}\n\nimpl fmt::Display for ExitStatus {\n    fn fmt(&self, f: &mut fmt::Formatter<'_>) -> fmt::Result {\n        write!(f, \"exit code: {}\", self.0)\n    }\n}\n\n#[derive(PartialEq, Eq, Clone, Copy, Debug)]\npub struct ExitStatusError(NonZeroI64);\n\nimpl Into<ExitStatus> for ExitStatusError {\n    fn into(self) -> ExitStatus {\n        ExitStatus(self.0.into())\n    }\n}\n\nimpl ExitStatusError {\n    pub fn code(self) -> Option<NonZeroI32> {\n        // fixme: affected by the same bug as ExitStatus::code()\n        ExitStatus(self.0.into()).code().map(|st| st.try_into().unwrap())\n    }\n}\n"],[2329,"use crate::convert::{TryFrom, TryInto};\nuse crate::fmt;\nuse crate::io::{self, Error, ErrorKind};\nuse crate::mem;\nuse crate::num::NonZeroI32;\nuse crate::os::raw::NonZero_c_int;\nuse crate::ptr;\nuse crate::sys;\nuse crate::sys::cvt;\nuse crate::sys::process::process_common::*;\n\n#[cfg(target_os = \"vxworks\")]\nuse libc::RTP_ID as pid_t;\n\n#[cfg(not(target_os = \"vxworks\"))]\nuse libc::{c_int, gid_t, pid_t, uid_t};\n\n////////////////////////////////////////////////////////////////////////////////\n// Command\n////////////////////////////////////////////////////////////////////////////////\n\nimpl Command {\n    pub fn spawn(\n        &mut self,\n        default: Stdio,\n        needs_stdin: bool,\n    ) -> io::Result<(Process, StdioPipes)> {\n        const CLOEXEC_MSG_FOOTER: [u8; 4] = *b\"NOEX\";\n\n        let envp = self.capture_env();\n\n        if self.saw_nul() {\n            return Err(io::Error::new_const(\n                ErrorKind::InvalidInput,\n                &\"nul byte found in provided data\",\n            ));\n        }\n\n        let (ours, theirs) = self.setup_io(default, needs_stdin)?;\n\n        if let Some(ret) = self.posix_spawn(&theirs, envp.as_ref())? {\n            return Ok((ret, ours));\n        }\n\n        let (input, output) = sys::pipe::anon_pipe()?;\n\n        // Whatever happens after the fork is almost for sure going to touch or\n        // look at the environment in one way or another (PATH in `execvp` or\n        // accessing the `environ` pointer ourselves). Make sure no other thread\n        // is accessing the environment when we do the fork itself.\n        //\n        // Note that as soon as we're done with the fork there's no need to hold\n        // a lock any more because the parent won't do anything and the child is\n        // in its own process. Thus the parent drops the lock guard while the child\n        // forgets it to avoid unlocking it on a new thread, which would be invalid.\n        let (env_lock, pid) = unsafe { (sys::os::env_read_lock(), cvt(libc::fork())?) };\n\n        if pid == 0 {\n            crate::panic::always_abort();\n            mem::forget(env_lock);\n            drop(input);\n            let Err(err) = unsafe { self.do_exec(theirs, envp.as_ref()) };\n            let errno = err.raw_os_error().unwrap_or(libc::EINVAL) as u32;\n            let errno = errno.to_be_bytes();\n            let bytes = [\n                errno[0],\n                errno[1],\n                errno[2],\n                errno[3],\n                CLOEXEC_MSG_FOOTER[0],\n                CLOEXEC_MSG_FOOTER[1],\n                CLOEXEC_MSG_FOOTER[2],\n                CLOEXEC_MSG_FOOTER[3],\n            ];\n            // pipe I/O up to PIPE_BUF bytes should be atomic, and then\n            // we want to be sure we *don't* run at_exit destructors as\n            // we're being torn down regardless\n            rtassert!(output.write(&bytes).is_ok());\n            unsafe { libc::_exit(1) }\n        }\n\n        drop(env_lock);\n        drop(output);\n\n        let mut p = Process { pid, status: None };\n        let mut bytes = [0; 8];\n\n        // loop to handle EINTR\n        loop {\n            match input.read(&mut bytes) {\n                Ok(0) => return Ok((p, ours)),\n                Ok(8) => {\n                    let (errno, footer) = bytes.split_at(4);\n                    assert_eq!(\n                        CLOEXEC_MSG_FOOTER, footer,\n                        \"Validation on the CLOEXEC pipe failed: {:?}\",\n                        bytes\n                    );\n                    let errno = i32::from_be_bytes(errno.try_into().unwrap());\n                    assert!(p.wait().is_ok(), \"wait() should either return Ok or panic\");\n                    return Err(Error::from_raw_os_error(errno));\n                }\n                Err(ref e) if e.kind() == ErrorKind::Interrupted => {}\n                Err(e) => {\n                    assert!(p.wait().is_ok(), \"wait() should either return Ok or panic\");\n                    panic!(\"the CLOEXEC pipe failed: {:?}\", e)\n                }\n                Ok(..) => {\n                    // pipe I/O up to PIPE_BUF bytes should be atomic\n                    assert!(p.wait().is_ok(), \"wait() should either return Ok or panic\");\n                    panic!(\"short read on the CLOEXEC pipe\")\n                }\n            }\n        }\n    }\n\n    pub fn exec(&mut self, default: Stdio) -> io::Error {\n        let envp = self.capture_env();\n\n        if self.saw_nul() {\n            return io::Error::new_const(\n                ErrorKind::InvalidInput,\n                &\"nul byte found in provided data\",\n            );\n        }\n\n        match self.setup_io(default, true) {\n            Ok((_, theirs)) => {\n                unsafe {\n                    // Similar to when forking, we want to ensure that access to\n                    // the environment is synchronized, so make sure to grab the\n                    // environment lock before we try to exec.\n                    let _lock = sys::os::env_read_lock();\n\n                    let Err(e) = self.do_exec(theirs, envp.as_ref());\n                    e\n                }\n            }\n            Err(e) => e,\n        }\n    }\n\n    // And at this point we've reached a special time in the life of the\n    // child. The child must now be considered hamstrung and unable to\n    // do anything other than syscalls really. Consider the following\n    // scenario:\n    //\n    //      1. Thread A of process 1 grabs the malloc() mutex\n    //      2. Thread B of process 1 forks(), creating thread C\n    //      3. Thread C of process 2 then attempts to malloc()\n    //      4. The memory of process 2 is the same as the memory of\n    //         process 1, so the mutex is locked.\n    //\n    // This situation looks a lot like deadlock, right? It turns out\n    // that this is what pthread_atfork() takes care of, which is\n    // presumably implemented across platforms. The first thing that\n    // threads to *before* forking is to do things like grab the malloc\n    // mutex, and then after the fork they unlock it.\n    //\n    // Despite this information, libnative's spawn has been witnessed to\n    // deadlock on both macOS and FreeBSD. I'm not entirely sure why, but\n    // all collected backtraces point at malloc/free traffic in the\n    // child spawned process.\n    //\n    // For this reason, the block of code below should contain 0\n    // invocations of either malloc of free (or their related friends).\n    //\n    // As an example of not having malloc/free traffic, we don't close\n    // this file descriptor by dropping the FileDesc (which contains an\n    // allocation). Instead we just close it manually. This will never\n    // have the drop glue anyway because this code never returns (the\n    // child will either exec() or invoke libc::exit)\n    unsafe fn do_exec(\n        &mut self,\n        stdio: ChildPipes,\n        maybe_envp: Option<&CStringArray>,\n    ) -> Result<!, io::Error> {\n        use crate::sys::{self, cvt_r};\n\n        if let Some(fd) = stdio.stdin.fd() {\n            cvt_r(|| libc::dup2(fd, libc::STDIN_FILENO))?;\n        }\n        if let Some(fd) = stdio.stdout.fd() {\n            cvt_r(|| libc::dup2(fd, libc::STDOUT_FILENO))?;\n        }\n        if let Some(fd) = stdio.stderr.fd() {\n            cvt_r(|| libc::dup2(fd, libc::STDERR_FILENO))?;\n        }\n\n        #[cfg(not(target_os = \"l4re\"))]\n        {\n            if let Some(_g) = self.get_groups() {\n                //FIXME: Redox kernel does not support setgroups yet\n                #[cfg(not(target_os = \"redox\"))]\n                cvt(libc::setgroups(_g.len().try_into().unwrap(), _g.as_ptr()))?;\n            }\n            if let Some(u) = self.get_gid() {\n                cvt(libc::setgid(u as gid_t))?;\n            }\n            if let Some(u) = self.get_uid() {\n                // When dropping privileges from root, the `setgroups` call\n                // will remove any extraneous groups. We only drop groups\n                // if the current uid is 0 and we weren't given an explicit\n                // set of groups. If we don't call this, then even though our\n                // uid has dropped, we may still have groups that enable us to\n                // do super-user things.\n                //FIXME: Redox kernel does not support setgroups yet\n                #[cfg(not(target_os = \"redox\"))]\n                if libc::getuid() == 0 && self.get_groups().is_none() {\n                    cvt(libc::setgroups(0, ptr::null()))?;\n                }\n                cvt(libc::setuid(u as uid_t))?;\n            }\n        }\n        if let Some(ref cwd) = *self.get_cwd() {\n            cvt(libc::chdir(cwd.as_ptr()))?;\n        }\n\n        // emscripten has no signal support.\n        #[cfg(not(target_os = \"emscripten\"))]\n        {\n            use crate::mem::MaybeUninit;\n            // Reset signal handling so the child process starts in a\n            // standardized state. libstd ignores SIGPIPE, and signal-handling\n            // libraries often set a mask. Child processes inherit ignored\n            // signals and the signal mask from their parent, but most\n            // UNIX programs do not reset these things on their own, so we\n            // need to clean things up now to avoid confusing the program\n            // we're about to run.\n            let mut set = MaybeUninit::<libc::sigset_t>::uninit();\n            cvt(sigemptyset(set.as_mut_ptr()))?;\n            cvt(libc::pthread_sigmask(libc::SIG_SETMASK, set.as_ptr(), ptr::null_mut()))?;\n            let ret = sys::signal(libc::SIGPIPE, libc::SIG_DFL);\n            if ret == libc::SIG_ERR {\n                return Err(io::Error::last_os_error());\n            }\n        }\n\n        for callback in self.get_closures().iter_mut() {\n            callback()?;\n        }\n\n        // Although we're performing an exec here we may also return with an\n        // error from this function (without actually exec'ing) in which case we\n        // want to be sure to restore the global environment back to what it\n        // once was, ensuring that our temporary override, when free'd, doesn't\n        // corrupt our process's environment.\n        let mut _reset = None;\n        if let Some(envp) = maybe_envp {\n            struct Reset(*const *const libc::c_char);\n\n            impl Drop for Reset {\n                fn drop(&mut self) {\n                    unsafe {\n                        *sys::os::environ() = self.0;\n                    }\n                }\n            }\n\n            _reset = Some(Reset(*sys::os::environ()));\n            *sys::os::environ() = envp.as_ptr();\n        }\n\n        libc::execvp(self.get_program_cstr().as_ptr(), self.get_argv().as_ptr());\n        Err(io::Error::last_os_error())\n    }\n\n    #[cfg(not(any(\n        target_os = \"macos\",\n        target_os = \"freebsd\",\n        all(target_os = \"linux\", target_env = \"gnu\"),\n        all(target_os = \"linux\", target_env = \"musl\"),\n    )))]\n    fn posix_spawn(\n        &mut self,\n        _: &ChildPipes,\n        _: Option<&CStringArray>,\n    ) -> io::Result<Option<Process>> {\n        Ok(None)\n    }\n\n    // Only support platforms for which posix_spawn() can return ENOENT\n    // directly.\n    #[cfg(any(\n        target_os = \"macos\",\n        target_os = \"freebsd\",\n        all(target_os = \"linux\", target_env = \"gnu\"),\n        all(target_os = \"linux\", target_env = \"musl\"),\n    ))]\n    fn posix_spawn(\n        &mut self,\n        stdio: &ChildPipes,\n        envp: Option<&CStringArray>,\n    ) -> io::Result<Option<Process>> {\n        use crate::mem::MaybeUninit;\n        use crate::sys::{self, cvt_nz};\n\n        if self.get_gid().is_some()\n            || self.get_uid().is_some()\n            || (self.env_saw_path() && !self.program_is_path())\n            || !self.get_closures().is_empty()\n            || self.get_groups().is_some()\n        {\n            return Ok(None);\n        }\n\n        // Only glibc 2.24+ posix_spawn() supports returning ENOENT directly.\n        #[cfg(all(target_os = \"linux\", target_env = \"gnu\"))]\n        {\n            if let Some(version) = sys::os::glibc_version() {\n                if version < (2, 24) {\n                    return Ok(None);\n                }\n            } else {\n                return Ok(None);\n            }\n        }\n\n        // Solaris, glibc 2.29+, and musl 1.24+ can set a new working directory,\n        // and maybe others will gain this non-POSIX function too. We'll check\n        // for this weak symbol as soon as it's needed, so we can return early\n        // otherwise to do a manual chdir before exec.\n        weak! {\n            fn posix_spawn_file_actions_addchdir_np(\n                *mut libc::posix_spawn_file_actions_t,\n                *const libc::c_char\n            ) -> libc::c_int\n        }\n        let addchdir = match self.get_cwd() {\n            Some(cwd) => {\n                if cfg!(target_os = \"macos\") {\n                    // There is a bug in macOS where a relative executable\n                    // path like \"../myprogram\" will cause `posix_spawn` to\n                    // successfully launch the program, but erroneously return\n                    // ENOENT when used with posix_spawn_file_actions_addchdir_np\n                    // which was introduced in macOS 10.15.\n                    return Ok(None);\n                }\n                match posix_spawn_file_actions_addchdir_np.get() {\n                    Some(f) => Some((f, cwd)),\n                    None => return Ok(None),\n                }\n            }\n            None => None,\n        };\n\n        let mut p = Process { pid: 0, status: None };\n\n        struct PosixSpawnFileActions<'a>(&'a mut MaybeUninit<libc::posix_spawn_file_actions_t>);\n\n        impl Drop for PosixSpawnFileActions<'_> {\n            fn drop(&mut self) {\n                unsafe {\n                    libc::posix_spawn_file_actions_destroy(self.0.as_mut_ptr());\n                }\n            }\n        }\n\n        struct PosixSpawnattr<'a>(&'a mut MaybeUninit<libc::posix_spawnattr_t>);\n\n        impl Drop for PosixSpawnattr<'_> {\n            fn drop(&mut self) {\n                unsafe {\n                    libc::posix_spawnattr_destroy(self.0.as_mut_ptr());\n                }\n            }\n        }\n\n        unsafe {\n            let mut attrs = MaybeUninit::uninit();\n            cvt_nz(libc::posix_spawnattr_init(attrs.as_mut_ptr()))?;\n            let attrs = PosixSpawnattr(&mut attrs);\n\n            let mut file_actions = MaybeUninit::uninit();\n            cvt_nz(libc::posix_spawn_file_actions_init(file_actions.as_mut_ptr()))?;\n            let file_actions = PosixSpawnFileActions(&mut file_actions);\n\n            if let Some(fd) = stdio.stdin.fd() {\n                cvt_nz(libc::posix_spawn_file_actions_adddup2(\n                    file_actions.0.as_mut_ptr(),\n                    fd,\n                    libc::STDIN_FILENO,\n                ))?;\n            }\n            if let Some(fd) = stdio.stdout.fd() {\n                cvt_nz(libc::posix_spawn_file_actions_adddup2(\n                    file_actions.0.as_mut_ptr(),\n                    fd,\n                    libc::STDOUT_FILENO,\n                ))?;\n            }\n            if let Some(fd) = stdio.stderr.fd() {\n                cvt_nz(libc::posix_spawn_file_actions_adddup2(\n                    file_actions.0.as_mut_ptr(),\n                    fd,\n                    libc::STDERR_FILENO,\n                ))?;\n            }\n            if let Some((f, cwd)) = addchdir {\n                cvt_nz(f(file_actions.0.as_mut_ptr(), cwd.as_ptr()))?;\n            }\n\n            let mut set = MaybeUninit::<libc::sigset_t>::uninit();\n            cvt(sigemptyset(set.as_mut_ptr()))?;\n            cvt_nz(libc::posix_spawnattr_setsigmask(attrs.0.as_mut_ptr(), set.as_ptr()))?;\n            cvt(sigaddset(set.as_mut_ptr(), libc::SIGPIPE))?;\n            cvt_nz(libc::posix_spawnattr_setsigdefault(attrs.0.as_mut_ptr(), set.as_ptr()))?;\n\n            let flags = libc::POSIX_SPAWN_SETSIGDEF | libc::POSIX_SPAWN_SETSIGMASK;\n            cvt_nz(libc::posix_spawnattr_setflags(attrs.0.as_mut_ptr(), flags as _))?;\n\n            // Make sure we synchronize access to the global `environ` resource\n            let _env_lock = sys::os::env_read_lock();\n            let envp = envp.map(|c| c.as_ptr()).unwrap_or_else(|| *sys::os::environ() as *const _);\n            cvt_nz(libc::posix_spawnp(\n                &mut p.pid,\n                self.get_program_cstr().as_ptr(),\n                file_actions.0.as_ptr(),\n                attrs.0.as_ptr(),\n                self.get_argv().as_ptr() as *const _,\n                envp as *const _,\n            ))?;\n            Ok(Some(p))\n        }\n    }\n}\n\n////////////////////////////////////////////////////////////////////////////////\n// Processes\n////////////////////////////////////////////////////////////////////////////////\n\n/// The unique ID of the process (this should never be negative).\npub struct Process {\n    pid: pid_t,\n    status: Option<ExitStatus>,\n}\n\nimpl Process {\n    pub fn id(&self) -> u32 {\n        self.pid as u32\n    }\n\n    pub fn kill(&mut self) -> io::Result<()> {\n        // If we've already waited on this process then the pid can be recycled\n        // and used for another process, and we probably shouldn't be killing\n        // random processes, so just return an error.\n        if self.status.is_some() {\n            Err(Error::new_const(\n                ErrorKind::InvalidInput,\n                &\"invalid argument: can't kill an exited process\",\n            ))\n        } else {\n            cvt(unsafe { libc::kill(self.pid, libc::SIGKILL) }).map(drop)\n        }\n    }\n\n    pub fn wait(&mut self) -> io::Result<ExitStatus> {\n        use crate::sys::cvt_r;\n        if let Some(status) = self.status {\n            return Ok(status);\n        }\n        let mut status = 0 as c_int;\n        cvt_r(|| unsafe { libc::waitpid(self.pid, &mut status, 0) })?;\n        self.status = Some(ExitStatus::new(status));\n        Ok(ExitStatus::new(status))\n    }\n\n    pub fn try_wait(&mut self) -> io::Result<Option<ExitStatus>> {\n        if let Some(status) = self.status {\n            return Ok(Some(status));\n        }\n        let mut status = 0 as c_int;\n        let pid = cvt(unsafe { libc::waitpid(self.pid, &mut status, libc::WNOHANG) })?;\n        if pid == 0 {\n            Ok(None)\n        } else {\n            self.status = Some(ExitStatus::new(status));\n            Ok(Some(ExitStatus::new(status)))\n        }\n    }\n}\n\n/// Unix exit statuses\n#[derive(PartialEq, Eq, Clone, Copy, Debug)]\npub struct ExitStatus(c_int);\n\nimpl ExitStatus {\n    pub fn new(status: c_int) -> ExitStatus {\n        ExitStatus(status)\n    }\n\n    fn exited(&self) -> bool {\n        libc::WIFEXITED(self.0)\n    }\n\n    pub fn exit_ok(&self) -> Result<(), ExitStatusError> {\n        // This assumes that WIFEXITED(status) && WEXITSTATUS==0 corresponds to status==0.  This is\n        // true on all actual versions of Unix, is widely assumed, and is specified in SuS\n        // https://pubs.opengroup.org/onlinepubs/9699919799/functions/wait.html .  If it is not\n        // true for a platform pretending to be Unix, the tests (our doctests, and also\n        // procsss_unix/tests.rs) will spot it.  `ExitStatusError::code` assumes this too.\n        match NonZero_c_int::try_from(self.0) {\n            /* was nonzero */ Ok(failure) => Err(ExitStatusError(failure)),\n            /* was zero, couldn't convert */ Err(_) => Ok(()),\n        }\n    }\n\n    pub fn code(&self) -> Option<i32> {\n        if self.exited() { Some(libc::WEXITSTATUS(self.0)) } else { None }\n    }\n\n    pub fn signal(&self) -> Option<i32> {\n        if libc::WIFSIGNALED(self.0) { Some(libc::WTERMSIG(self.0)) } else { None }\n    }\n\n    pub fn core_dumped(&self) -> bool {\n        libc::WIFSIGNALED(self.0) && libc::WCOREDUMP(self.0)\n    }\n\n    pub fn stopped_signal(&self) -> Option<i32> {\n        if libc::WIFSTOPPED(self.0) { Some(libc::WSTOPSIG(self.0)) } else { None }\n    }\n\n    pub fn continued(&self) -> bool {\n        libc::WIFCONTINUED(self.0)\n    }\n\n    pub fn into_raw(&self) -> c_int {\n        self.0\n    }\n}\n\n/// Converts a raw `c_int` to a type-safe `ExitStatus` by wrapping it without copying.\nimpl From<c_int> for ExitStatus {\n    fn from(a: c_int) -> ExitStatus {\n        ExitStatus(a)\n    }\n}\n\nimpl fmt::Display for ExitStatus {\n    fn fmt(&self, f: &mut fmt::Formatter<'_>) -> fmt::Result {\n        if let Some(code) = self.code() {\n            write!(f, \"exit status: {}\", code)\n        } else if let Some(signal) = self.signal() {\n            if self.core_dumped() {\n                write!(f, \"signal: {} (core dumped)\", signal)\n            } else {\n                write!(f, \"signal: {}\", signal)\n            }\n        } else if let Some(signal) = self.stopped_signal() {\n            write!(f, \"stopped (not terminated) by signal: {}\", signal)\n        } else if self.continued() {\n            write!(f, \"continued (WIFCONTINUED)\")\n        } else {\n            write!(f, \"unrecognised wait status: {} {:#x}\", self.0, self.0)\n        }\n    }\n}\n\n#[derive(PartialEq, Eq, Clone, Copy, Debug)]\npub struct ExitStatusError(NonZero_c_int);\n\nimpl Into<ExitStatus> for ExitStatusError {\n    fn into(self) -> ExitStatus {\n        ExitStatus(self.0.into())\n    }\n}\n\nimpl ExitStatusError {\n    pub fn code(self) -> Option<NonZeroI32> {\n        ExitStatus(self.0.into()).code().map(|st| st.try_into().unwrap())\n    }\n}\n\n#[cfg(test)]\n#[path = \"process_unix/tests.rs\"]\nmod tests;\n"],[2330,"use super::*;\n\nuse crate::ffi::OsStr;\nuse crate::mem;\nuse crate::ptr;\nuse crate::sys::cvt;\n\nmacro_rules! t {\n    ($e:expr) => {\n        match $e {\n            Ok(t) => t,\n            Err(e) => panic!(\"received error for `{}`: {}\", stringify!($e), e),\n        }\n    };\n}\n\n#[test]\n#[cfg_attr(\n    any(\n        // See #14232 for more information, but it appears that signal delivery to a\n        // newly spawned process may just be raced in the macOS, so to prevent this\n        // test from being flaky we ignore it on macOS.\n        target_os = \"macos\",\n        // When run under our current QEMU emulation test suite this test fails,\n        // although the reason isn't very clear as to why. For now this test is\n        // ignored there.\n        target_arch = \"arm\",\n        target_arch = \"aarch64\",\n        target_arch = \"riscv64\",\n    ),\n    ignore\n)]\nfn test_process_mask() {\n    unsafe {\n        // Test to make sure that a signal mask does not get inherited.\n        let mut cmd = Command::new(OsStr::new(\"cat\"));\n\n        let mut set = mem::MaybeUninit::<libc::sigset_t>::uninit();\n        let mut old_set = mem::MaybeUninit::<libc::sigset_t>::uninit();\n        t!(cvt(sigemptyset(set.as_mut_ptr())));\n        t!(cvt(sigaddset(set.as_mut_ptr(), libc::SIGINT)));\n        t!(cvt(libc::pthread_sigmask(libc::SIG_SETMASK, set.as_ptr(), old_set.as_mut_ptr())));\n\n        cmd.stdin(Stdio::MakePipe);\n        cmd.stdout(Stdio::MakePipe);\n\n        let (mut cat, mut pipes) = t!(cmd.spawn(Stdio::Null, true));\n        let stdin_write = pipes.stdin.take().unwrap();\n        let stdout_read = pipes.stdout.take().unwrap();\n\n        t!(cvt(libc::pthread_sigmask(libc::SIG_SETMASK, old_set.as_ptr(), ptr::null_mut())));\n\n        t!(cvt(libc::kill(cat.id() as libc::pid_t, libc::SIGINT)));\n        // We need to wait until SIGINT is definitely delivered. The\n        // easiest way is to write something to cat, and try to read it\n        // back: if SIGINT is unmasked, it'll get delivered when cat is\n        // next scheduled.\n        let _ = stdin_write.write(b\"Hello\");\n        drop(stdin_write);\n\n        // Either EOF or failure (EPIPE) is okay.\n        let mut buf = [0; 5];\n        if let Ok(ret) = stdout_read.read(&mut buf) {\n            assert_eq!(ret, 0);\n        }\n\n        t!(cat.wait());\n    }\n}\n"],[2331,"use crate::convert::{TryFrom, TryInto};\nuse crate::fmt;\nuse crate::io::{self, Error, ErrorKind};\nuse crate::num::NonZeroI32;\nuse crate::os::raw::NonZero_c_int;\nuse crate::sys;\nuse crate::sys::cvt;\nuse crate::sys::process::process_common::*;\nuse crate::sys_common::thread;\nuse libc::RTP_ID;\nuse libc::{self, c_char, c_int};\n\n////////////////////////////////////////////////////////////////////////////////\n// Command\n////////////////////////////////////////////////////////////////////////////////\n\nimpl Command {\n    pub fn spawn(\n        &mut self,\n        default: Stdio,\n        needs_stdin: bool,\n    ) -> io::Result<(Process, StdioPipes)> {\n        use crate::sys::cvt_r;\n        let envp = self.capture_env();\n\n        if self.saw_nul() {\n            return Err(io::Error::new_const(\n                ErrorKind::InvalidInput,\n                &\"nul byte found in provided data\",\n            ));\n        }\n        let (ours, theirs) = self.setup_io(default, needs_stdin)?;\n        let mut p = Process { pid: 0, status: None };\n\n        unsafe {\n            macro_rules! t {\n                ($e:expr) => {\n                    match $e {\n                        Ok(e) => e,\n                        Err(e) => return Err(e.into()),\n                    }\n                };\n            }\n\n            let mut orig_stdin = libc::STDIN_FILENO;\n            let mut orig_stdout = libc::STDOUT_FILENO;\n            let mut orig_stderr = libc::STDERR_FILENO;\n\n            if let Some(fd) = theirs.stdin.fd() {\n                orig_stdin = t!(cvt_r(|| libc::dup(libc::STDIN_FILENO)));\n                t!(cvt_r(|| libc::dup2(fd, libc::STDIN_FILENO)));\n            }\n            if let Some(fd) = theirs.stdout.fd() {\n                orig_stdout = t!(cvt_r(|| libc::dup(libc::STDOUT_FILENO)));\n                t!(cvt_r(|| libc::dup2(fd, libc::STDOUT_FILENO)));\n            }\n            if let Some(fd) = theirs.stderr.fd() {\n                orig_stderr = t!(cvt_r(|| libc::dup(libc::STDERR_FILENO)));\n                t!(cvt_r(|| libc::dup2(fd, libc::STDERR_FILENO)));\n            }\n\n            if let Some(ref cwd) = *self.get_cwd() {\n                t!(cvt(libc::chdir(cwd.as_ptr())));\n            }\n\n            // pre_exec closures are ignored on VxWorks\n            let _ = self.get_closures();\n\n            let c_envp = envp\n                .as_ref()\n                .map(|c| c.as_ptr())\n                .unwrap_or_else(|| *sys::os::environ() as *const _);\n            let stack_size = thread::min_stack();\n\n            // ensure that access to the environment is synchronized\n            let _lock = sys::os::env_read_lock();\n\n            let ret = libc::rtpSpawn(\n                self.get_program_cstr().as_ptr(),\n                self.get_argv().as_ptr() as *mut *const c_char, // argv\n                c_envp as *mut *const c_char,\n                100 as c_int, // initial priority\n                stack_size,   // initial stack size.\n                0,            // options\n                0,            // task options\n            );\n\n            // Because FileDesc was not used, each duplicated file descriptor\n            // needs to be closed manually\n            if orig_stdin != libc::STDIN_FILENO {\n                t!(cvt_r(|| libc::dup2(orig_stdin, libc::STDIN_FILENO)));\n                libc::close(orig_stdin);\n            }\n            if orig_stdout != libc::STDOUT_FILENO {\n                t!(cvt_r(|| libc::dup2(orig_stdout, libc::STDOUT_FILENO)));\n                libc::close(orig_stdout);\n            }\n            if orig_stderr != libc::STDERR_FILENO {\n                t!(cvt_r(|| libc::dup2(orig_stderr, libc::STDERR_FILENO)));\n                libc::close(orig_stderr);\n            }\n\n            if ret != libc::RTP_ID_ERROR {\n                p.pid = ret;\n                Ok((p, ours))\n            } else {\n                Err(io::Error::last_os_error())\n            }\n        }\n    }\n\n    pub fn exec(&mut self, default: Stdio) -> io::Error {\n        let ret = Command::spawn(self, default, false);\n        match ret {\n            Ok(t) => unsafe {\n                let mut status = 0 as c_int;\n                libc::waitpid(t.0.pid, &mut status, 0);\n                libc::exit(0);\n            },\n            Err(e) => e,\n        }\n    }\n}\n\n////////////////////////////////////////////////////////////////////////////////\n// Processes\n////////////////////////////////////////////////////////////////////////////////\n\n/// The unique id of the process (this should never be negative).\npub struct Process {\n    pid: RTP_ID,\n    status: Option<ExitStatus>,\n}\n\nimpl Process {\n    pub fn id(&self) -> u32 {\n        self.pid as u32\n    }\n\n    pub fn kill(&mut self) -> io::Result<()> {\n        // If we've already waited on this process then the pid can be recycled\n        // and used for another process, and we probably shouldn't be killing\n        // random processes, so just return an error.\n        if self.status.is_some() {\n            Err(Error::new_const(\n                ErrorKind::InvalidInput,\n                &\"invalid argument: can't kill an exited process\",\n            ))\n        } else {\n            cvt(unsafe { libc::kill(self.pid, libc::SIGKILL) }).map(drop)\n        }\n    }\n\n    pub fn wait(&mut self) -> io::Result<ExitStatus> {\n        use crate::sys::cvt_r;\n        if let Some(status) = self.status {\n            return Ok(status);\n        }\n        let mut status = 0 as c_int;\n        cvt_r(|| unsafe { libc::waitpid(self.pid, &mut status, 0) })?;\n        self.status = Some(ExitStatus::new(status));\n        Ok(ExitStatus::new(status))\n    }\n\n    pub fn try_wait(&mut self) -> io::Result<Option<ExitStatus>> {\n        if let Some(status) = self.status {\n            return Ok(Some(status));\n        }\n        let mut status = 0 as c_int;\n        let pid = cvt(unsafe { libc::waitpid(self.pid, &mut status, libc::WNOHANG) })?;\n        if pid == 0 {\n            Ok(None)\n        } else {\n            self.status = Some(ExitStatus::new(status));\n            Ok(Some(ExitStatus::new(status)))\n        }\n    }\n}\n\n/// Unix exit statuses\n#[derive(PartialEq, Eq, Clone, Copy, Debug)]\npub struct ExitStatus(c_int);\n\nimpl ExitStatus {\n    pub fn new(status: c_int) -> ExitStatus {\n        ExitStatus(status)\n    }\n\n    fn exited(&self) -> bool {\n        libc::WIFEXITED(self.0)\n    }\n\n    pub fn exit_ok(&self) -> Result<(), ExitStatusError> {\n        // This assumes that WIFEXITED(status) && WEXITSTATUS==0 corresponds to status==0.  This is\n        // true on all actual versions of Unix, is widely assumed, and is specified in SuS\n        // https://pubs.opengroup.org/onlinepubs/9699919799/functions/wait.html .  If it is not\n        // true for a platform pretending to be Unix, the tests (our doctests, and also\n        // procsss_unix/tests.rs) will spot it.  `ExitStatusError::code` assumes this too.\n        match NonZero_c_int::try_from(self.0) {\n            Ok(failure) => Err(ExitStatusError(failure)),\n            Err(_) => Ok(()),\n        }\n    }\n\n    pub fn code(&self) -> Option<i32> {\n        if self.exited() { Some(libc::WEXITSTATUS(self.0)) } else { None }\n    }\n\n    pub fn signal(&self) -> Option<i32> {\n        if !self.exited() { Some(libc::WTERMSIG(self.0)) } else { None }\n    }\n\n    pub fn core_dumped(&self) -> bool {\n        // This method is not yet properly implemented on VxWorks\n        false\n    }\n\n    pub fn stopped_signal(&self) -> Option<i32> {\n        if libc::WIFSTOPPED(self.0) { Some(libc::WSTOPSIG(self.0)) } else { None }\n    }\n\n    pub fn continued(&self) -> bool {\n        // This method is not yet properly implemented on VxWorks\n        false\n    }\n\n    pub fn into_raw(&self) -> c_int {\n        self.0\n    }\n}\n\n/// Converts a raw `c_int` to a type-safe `ExitStatus` by wrapping it without copying.\nimpl From<c_int> for ExitStatus {\n    fn from(a: c_int) -> ExitStatus {\n        ExitStatus(a)\n    }\n}\n\nimpl fmt::Display for ExitStatus {\n    fn fmt(&self, f: &mut fmt::Formatter<'_>) -> fmt::Result {\n        if let Some(code) = self.code() {\n            write!(f, \"exit code: {}\", code)\n        } else {\n            let signal = self.signal().unwrap();\n            write!(f, \"signal: {}\", signal)\n        }\n    }\n}\n\n#[derive(PartialEq, Eq, Clone, Copy, Debug)]\npub struct ExitStatusError(NonZero_c_int);\n\nimpl Into<ExitStatus> for ExitStatusError {\n    fn into(self) -> ExitStatus {\n        ExitStatus(self.0.into())\n    }\n}\n\nimpl ExitStatusError {\n    pub fn code(self) -> Option<NonZeroI32> {\n        ExitStatus(self.0.into()).code().map(|st| st.try_into().unwrap())\n    }\n}\n"],[2332,"use crate::os::unix::process::{CommandExt, ExitStatusExt};\nuse crate::panic::catch_unwind;\nuse crate::process::Command;\n\n// Many of the other aspects of this situation, including heap alloc concurrency\n// safety etc., are tested in src/test/ui/process/process-panic-after-fork.rs\n\n#[test]\nfn exitstatus_display_tests() {\n    // In practice this is the same on every Unix.\n    // If some weird platform turns out to be different, and this test fails, use #[cfg].\n    use crate::os::unix::process::ExitStatusExt;\n    use crate::process::ExitStatus;\n\n    let t = |v, s| assert_eq!(s, format!(\"{}\", <ExitStatus as ExitStatusExt>::from_raw(v)));\n\n    t(0x0000f, \"signal: 15\");\n    t(0x0008b, \"signal: 11 (core dumped)\");\n    t(0x00000, \"exit status: 0\");\n    t(0x0ff00, \"exit status: 255\");\n\n    // On MacOS, 0x0137f is WIFCONTINUED, not WIFSTOPPED.  Probably *BSD is similar.\n    //   https://github.com/rust-lang/rust/pull/82749#issuecomment-790525956\n    // The purpose of this test is to test our string formatting, not our understanding of the wait\n    // status magic numbers.  So restrict these to Linux.\n    if cfg!(target_os = \"linux\") {\n        t(0x0137f, \"stopped (not terminated) by signal: 19\");\n        t(0x0ffff, \"continued (WIFCONTINUED)\");\n    }\n\n    // Testing \"unrecognised wait status\" is hard because the wait.h macros typically\n    // assume that the value came from wait and isn't mad.  With the glibc I have here\n    // this works:\n    if cfg!(all(target_os = \"linux\", target_env = \"gnu\")) {\n        t(0x000ff, \"unrecognised wait status: 255 0xff\");\n    }\n}\n\n#[test]\n#[cfg_attr(target_os = \"emscripten\", ignore)]\nfn test_command_fork_no_unwind() {\n    let got = catch_unwind(|| {\n        let mut c = Command::new(\"echo\");\n        c.arg(\"hi\");\n        unsafe {\n            c.pre_exec(|| panic!(\"{}\", \"crash now!\"));\n        }\n        let st = c.status().expect(\"failed to get command status\");\n        dbg!(st);\n        st\n    });\n    dbg!(&got);\n    let status = got.expect(\"panic unexpectedly propagated\");\n    dbg!(status);\n    let signal = status.signal().expect(\"expected child process to die of signal\");\n    assert!(signal == libc::SIGABRT || signal == libc::SIGILL || signal == libc::SIGTRAP);\n}\n"],[2333,"#[cfg(all(test, not(target_os = \"emscripten\")))]\nmod tests;\n\nuse crate::os::unix::prelude::*;\n\nuse crate::collections::BTreeMap;\nuse crate::ffi::{CStr, CString, OsStr, OsString};\nuse crate::fmt;\nuse crate::io;\nuse crate::path::Path;\nuse crate::ptr;\nuse crate::sys::fd::FileDesc;\nuse crate::sys::fs::File;\nuse crate::sys::pipe::{self, AnonPipe};\nuse crate::sys_common::process::{CommandEnv, CommandEnvs};\n\n#[cfg(not(target_os = \"fuchsia\"))]\nuse crate::sys::fs::OpenOptions;\n\nuse libc::{c_char, c_int, gid_t, uid_t, EXIT_FAILURE, EXIT_SUCCESS};\n\ncfg_if::cfg_if! {\n    if #[cfg(target_os = \"fuchsia\")] {\n        // fuchsia doesn't have /dev/null\n    } else if #[cfg(target_os = \"redox\")] {\n        const DEV_NULL: &str = \"null:\\0\";\n    } else if #[cfg(target_os = \"vxworks\")] {\n        const DEV_NULL: &str = \"/null\\0\";\n    } else {\n        const DEV_NULL: &str = \"/dev/null\\0\";\n    }\n}\n\n// Android with api less than 21 define sig* functions inline, so it is not\n// available for dynamic link. Implementing sigemptyset and sigaddset allow us\n// to support older Android version (independent of libc version).\n// The following implementations are based on https://git.io/vSkNf\ncfg_if::cfg_if! {\n    if #[cfg(target_os = \"android\")] {\n        pub unsafe fn sigemptyset(set: *mut libc::sigset_t) -> libc::c_int {\n            set.write_bytes(0u8, 1);\n            return 0;\n        }\n        #[allow(dead_code)]\n        pub unsafe fn sigaddset(set: *mut libc::sigset_t, signum: libc::c_int) -> libc::c_int {\n            use crate::{slice, mem};\n\n            let raw = slice::from_raw_parts_mut(set as *mut u8, mem::size_of::<libc::sigset_t>());\n            let bit = (signum - 1) as usize;\n            raw[bit / 8] |= 1 << (bit % 8);\n            return 0;\n        }\n    } else if #[cfg(not(target_os = \"vxworks\"))] {\n        pub use libc::{sigemptyset, sigaddset};\n    }\n}\n\n////////////////////////////////////////////////////////////////////////////////\n// Command\n////////////////////////////////////////////////////////////////////////////////\n\npub struct Command {\n    program: CString,\n    args: Vec<CString>,\n    /// Exactly what will be passed to `execvp`.\n    ///\n    /// First element is a pointer to `program`, followed by pointers to\n    /// `args`, followed by a `null`. Be careful when modifying `program` or\n    /// `args` to properly update this as well.\n    argv: Argv,\n    env: CommandEnv,\n\n    cwd: Option<CString>,\n    uid: Option<uid_t>,\n    gid: Option<gid_t>,\n    saw_nul: bool,\n    closures: Vec<Box<dyn FnMut() -> io::Result<()> + Send + Sync>>,\n    groups: Option<Box<[gid_t]>>,\n    stdin: Option<Stdio>,\n    stdout: Option<Stdio>,\n    stderr: Option<Stdio>,\n}\n\n// Create a new type for argv, so that we can make it `Send` and `Sync`\nstruct Argv(Vec<*const c_char>);\n\n// It is safe to make `Argv` `Send` and `Sync`, because it contains\n// pointers to memory owned by `Command.args`\nunsafe impl Send for Argv {}\nunsafe impl Sync for Argv {}\n\n// passed back to std::process with the pipes connected to the child, if any\n// were requested\npub struct StdioPipes {\n    pub stdin: Option<AnonPipe>,\n    pub stdout: Option<AnonPipe>,\n    pub stderr: Option<AnonPipe>,\n}\n\n// passed to do_exec() with configuration of what the child stdio should look\n// like\npub struct ChildPipes {\n    pub stdin: ChildStdio,\n    pub stdout: ChildStdio,\n    pub stderr: ChildStdio,\n}\n\npub enum ChildStdio {\n    Inherit,\n    Explicit(c_int),\n    Owned(FileDesc),\n\n    // On Fuchsia, null stdio is the default, so we simply don't specify\n    // any actions at the time of spawning.\n    #[cfg(target_os = \"fuchsia\")]\n    Null,\n}\n\npub enum Stdio {\n    Inherit,\n    Null,\n    MakePipe,\n    Fd(FileDesc),\n}\n\nimpl Command {\n    pub fn new(program: &OsStr) -> Command {\n        let mut saw_nul = false;\n        let program = os2c(program, &mut saw_nul);\n        Command {\n            argv: Argv(vec![program.as_ptr(), ptr::null()]),\n            args: vec![program.clone()],\n            program,\n            env: Default::default(),\n            cwd: None,\n            uid: None,\n            gid: None,\n            saw_nul,\n            closures: Vec::new(),\n            groups: None,\n            stdin: None,\n            stdout: None,\n            stderr: None,\n        }\n    }\n\n    pub fn set_arg_0(&mut self, arg: &OsStr) {\n        // Set a new arg0\n        let arg = os2c(arg, &mut self.saw_nul);\n        debug_assert!(self.argv.0.len() > 1);\n        self.argv.0[0] = arg.as_ptr();\n        self.args[0] = arg;\n    }\n\n    pub fn arg(&mut self, arg: &OsStr) {\n        // Overwrite the trailing null pointer in `argv` and then add a new null\n        // pointer.\n        let arg = os2c(arg, &mut self.saw_nul);\n        self.argv.0[self.args.len()] = arg.as_ptr();\n        self.argv.0.push(ptr::null());\n\n        // Also make sure we keep track of the owned value to schedule a\n        // destructor for this memory.\n        self.args.push(arg);\n    }\n\n    pub fn cwd(&mut self, dir: &OsStr) {\n        self.cwd = Some(os2c(dir, &mut self.saw_nul));\n    }\n    pub fn uid(&mut self, id: uid_t) {\n        self.uid = Some(id);\n    }\n    pub fn gid(&mut self, id: gid_t) {\n        self.gid = Some(id);\n    }\n    pub fn groups(&mut self, groups: &[gid_t]) {\n        self.groups = Some(Box::from(groups));\n    }\n\n    pub fn saw_nul(&self) -> bool {\n        self.saw_nul\n    }\n\n    pub fn get_program(&self) -> &OsStr {\n        OsStr::from_bytes(self.program.as_bytes())\n    }\n\n    pub fn get_args(&self) -> CommandArgs<'_> {\n        let mut iter = self.args.iter();\n        iter.next();\n        CommandArgs { iter }\n    }\n\n    pub fn get_envs(&self) -> CommandEnvs<'_> {\n        self.env.iter()\n    }\n\n    pub fn get_current_dir(&self) -> Option<&Path> {\n        self.cwd.as_ref().map(|cs| Path::new(OsStr::from_bytes(cs.as_bytes())))\n    }\n\n    pub fn get_argv(&self) -> &Vec<*const c_char> {\n        &self.argv.0\n    }\n\n    pub fn get_program_cstr(&self) -> &CStr {\n        &*self.program\n    }\n\n    #[allow(dead_code)]\n    pub fn get_cwd(&self) -> &Option<CString> {\n        &self.cwd\n    }\n    #[allow(dead_code)]\n    pub fn get_uid(&self) -> Option<uid_t> {\n        self.uid\n    }\n    #[allow(dead_code)]\n    pub fn get_gid(&self) -> Option<gid_t> {\n        self.gid\n    }\n    #[allow(dead_code)]\n    pub fn get_groups(&self) -> Option<&[gid_t]> {\n        self.groups.as_deref()\n    }\n\n    pub fn get_closures(&mut self) -> &mut Vec<Box<dyn FnMut() -> io::Result<()> + Send + Sync>> {\n        &mut self.closures\n    }\n\n    pub unsafe fn pre_exec(&mut self, f: Box<dyn FnMut() -> io::Result<()> + Send + Sync>) {\n        self.closures.push(f);\n    }\n\n    pub fn stdin(&mut self, stdin: Stdio) {\n        self.stdin = Some(stdin);\n    }\n\n    pub fn stdout(&mut self, stdout: Stdio) {\n        self.stdout = Some(stdout);\n    }\n\n    pub fn stderr(&mut self, stderr: Stdio) {\n        self.stderr = Some(stderr);\n    }\n\n    pub fn env_mut(&mut self) -> &mut CommandEnv {\n        &mut self.env\n    }\n\n    pub fn capture_env(&mut self) -> Option<CStringArray> {\n        let maybe_env = self.env.capture_if_changed();\n        maybe_env.map(|env| construct_envp(env, &mut self.saw_nul))\n    }\n\n    #[allow(dead_code)]\n    pub fn env_saw_path(&self) -> bool {\n        self.env.have_changed_path()\n    }\n\n    #[allow(dead_code)]\n    pub fn program_is_path(&self) -> bool {\n        self.program.to_bytes().contains(&b'/')\n    }\n\n    pub fn setup_io(\n        &self,\n        default: Stdio,\n        needs_stdin: bool,\n    ) -> io::Result<(StdioPipes, ChildPipes)> {\n        let null = Stdio::Null;\n        let default_stdin = if needs_stdin { &default } else { &null };\n        let stdin = self.stdin.as_ref().unwrap_or(default_stdin);\n        let stdout = self.stdout.as_ref().unwrap_or(&default);\n        let stderr = self.stderr.as_ref().unwrap_or(&default);\n        let (their_stdin, our_stdin) = stdin.to_child_stdio(true)?;\n        let (their_stdout, our_stdout) = stdout.to_child_stdio(false)?;\n        let (their_stderr, our_stderr) = stderr.to_child_stdio(false)?;\n        let ours = StdioPipes { stdin: our_stdin, stdout: our_stdout, stderr: our_stderr };\n        let theirs = ChildPipes { stdin: their_stdin, stdout: their_stdout, stderr: their_stderr };\n        Ok((ours, theirs))\n    }\n}\n\nfn os2c(s: &OsStr, saw_nul: &mut bool) -> CString {\n    CString::new(s.as_bytes()).unwrap_or_else(|_e| {\n        *saw_nul = true;\n        CString::new(\"<string-with-nul>\").unwrap()\n    })\n}\n\n// Helper type to manage ownership of the strings within a C-style array.\npub struct CStringArray {\n    items: Vec<CString>,\n    ptrs: Vec<*const c_char>,\n}\n\nimpl CStringArray {\n    pub fn with_capacity(capacity: usize) -> Self {\n        let mut result = CStringArray {\n            items: Vec::with_capacity(capacity),\n            ptrs: Vec::with_capacity(capacity + 1),\n        };\n        result.ptrs.push(ptr::null());\n        result\n    }\n    pub fn push(&mut self, item: CString) {\n        let l = self.ptrs.len();\n        self.ptrs[l - 1] = item.as_ptr();\n        self.ptrs.push(ptr::null());\n        self.items.push(item);\n    }\n    pub fn as_ptr(&self) -> *const *const c_char {\n        self.ptrs.as_ptr()\n    }\n}\n\nfn construct_envp(env: BTreeMap<OsString, OsString>, saw_nul: &mut bool) -> CStringArray {\n    let mut result = CStringArray::with_capacity(env.len());\n    for (mut k, v) in env {\n        // Reserve additional space for '=' and null terminator\n        k.reserve_exact(v.len() + 2);\n        k.push(\"=\");\n        k.push(&v);\n\n        // Add the new entry into the array\n        if let Ok(item) = CString::new(k.into_vec()) {\n            result.push(item);\n        } else {\n            *saw_nul = true;\n        }\n    }\n\n    result\n}\n\nimpl Stdio {\n    pub fn to_child_stdio(&self, readable: bool) -> io::Result<(ChildStdio, Option<AnonPipe>)> {\n        match *self {\n            Stdio::Inherit => Ok((ChildStdio::Inherit, None)),\n\n            // Make sure that the source descriptors are not an stdio\n            // descriptor, otherwise the order which we set the child's\n            // descriptors may blow away a descriptor which we are hoping to\n            // save. For example, suppose we want the child's stderr to be the\n            // parent's stdout, and the child's stdout to be the parent's\n            // stderr. No matter which we dup first, the second will get\n            // overwritten prematurely.\n            Stdio::Fd(ref fd) => {\n                if fd.raw() >= 0 && fd.raw() <= libc::STDERR_FILENO {\n                    Ok((ChildStdio::Owned(fd.duplicate()?), None))\n                } else {\n                    Ok((ChildStdio::Explicit(fd.raw()), None))\n                }\n            }\n\n            Stdio::MakePipe => {\n                let (reader, writer) = pipe::anon_pipe()?;\n                let (ours, theirs) = if readable { (writer, reader) } else { (reader, writer) };\n                Ok((ChildStdio::Owned(theirs.into_fd()), Some(ours)))\n            }\n\n            #[cfg(not(target_os = \"fuchsia\"))]\n            Stdio::Null => {\n                let mut opts = OpenOptions::new();\n                opts.read(readable);\n                opts.write(!readable);\n                let path = unsafe { CStr::from_ptr(DEV_NULL.as_ptr() as *const _) };\n                let fd = File::open_c(&path, &opts)?;\n                Ok((ChildStdio::Owned(fd.into_fd()), None))\n            }\n\n            #[cfg(target_os = \"fuchsia\")]\n            Stdio::Null => Ok((ChildStdio::Null, None)),\n        }\n    }\n}\n\nimpl From<AnonPipe> for Stdio {\n    fn from(pipe: AnonPipe) -> Stdio {\n        Stdio::Fd(pipe.into_fd())\n    }\n}\n\nimpl From<File> for Stdio {\n    fn from(file: File) -> Stdio {\n        Stdio::Fd(file.into_fd())\n    }\n}\n\nimpl ChildStdio {\n    pub fn fd(&self) -> Option<c_int> {\n        match *self {\n            ChildStdio::Inherit => None,\n            ChildStdio::Explicit(fd) => Some(fd),\n            ChildStdio::Owned(ref fd) => Some(fd.raw()),\n\n            #[cfg(target_os = \"fuchsia\")]\n            ChildStdio::Null => None,\n        }\n    }\n}\n\nimpl fmt::Debug for Command {\n    fn fmt(&self, f: &mut fmt::Formatter<'_>) -> fmt::Result {\n        if self.program != self.args[0] {\n            write!(f, \"[{:?}] \", self.program)?;\n        }\n        write!(f, \"{:?}\", self.args[0])?;\n\n        for arg in &self.args[1..] {\n            write!(f, \" {:?}\", arg)?;\n        }\n        Ok(())\n    }\n}\n\n#[derive(PartialEq, Eq, Clone, Copy, Debug)]\npub struct ExitCode(u8);\n\nimpl ExitCode {\n    pub const SUCCESS: ExitCode = ExitCode(EXIT_SUCCESS as _);\n    pub const FAILURE: ExitCode = ExitCode(EXIT_FAILURE as _);\n\n    #[inline]\n    pub fn as_i32(&self) -> i32 {\n        self.0 as i32\n    }\n}\n\npub struct CommandArgs<'a> {\n    iter: crate::slice::Iter<'a, CString>,\n}\n\nimpl<'a> Iterator for CommandArgs<'a> {\n    type Item = &'a OsStr;\n    fn next(&mut self) -> Option<&'a OsStr> {\n        self.iter.next().map(|cs| OsStr::from_bytes(cs.as_bytes()))\n    }\n    fn size_hint(&self) -> (usize, Option<usize>) {\n        self.iter.size_hint()\n    }\n}\n\nimpl<'a> ExactSizeIterator for CommandArgs<'a> {\n    fn len(&self) -> usize {\n        self.iter.len()\n    }\n    fn is_empty(&self) -> bool {\n        self.iter.is_empty()\n    }\n}\n\nimpl<'a> fmt::Debug for CommandArgs<'a> {\n    fn fmt(&self, f: &mut fmt::Formatter<'_>) -> fmt::Result {\n        f.debug_list().entries(self.iter.clone()).finish()\n    }\n}\n"],[2334,"pub use self::process_common::{Command, CommandArgs, ExitCode, Stdio, StdioPipes};\npub use self::process_inner::{ExitStatus, ExitStatusError, Process};\npub use crate::ffi::OsString as EnvKey;\npub use crate::sys_common::process::CommandEnvs;\n\nmod process_common;\n\ncfg_if::cfg_if! {\n    if #[cfg(target_os = \"fuchsia\")] {\n        #[path = \"process_fuchsia.rs\"]\n        mod process_inner;\n        mod zircon;\n    } else if #[cfg(target_os = \"vxworks\")] {\n        #[path = \"process_vxworks.rs\"]\n        mod process_inner;\n    } else {\n        #[path = \"process_unix.rs\"]\n        mod process_inner;\n    }\n}\n"],[2335,"#![allow(dead_code)] // not used on all platforms\n\nuse crate::mem;\n\npub type Key = libc::pthread_key_t;\n\n#[inline]\npub unsafe fn create(dtor: Option<unsafe extern \"C\" fn(*mut u8)>) -> Key {\n    let mut key = 0;\n    assert_eq!(libc::pthread_key_create(&mut key, mem::transmute(dtor)), 0);\n    key\n}\n\n#[inline]\npub unsafe fn set(key: Key, value: *mut u8) {\n    let r = libc::pthread_setspecific(key, value as *mut _);\n    debug_assert_eq!(r, 0);\n}\n\n#[inline]\npub unsafe fn get(key: Key) -> *mut u8 {\n    libc::pthread_getspecific(key) as *mut u8\n}\n\n#[inline]\npub unsafe fn destroy(key: Key) {\n    let r = libc::pthread_key_delete(key);\n    debug_assert_eq!(r, 0);\n}\n\n#[inline]\npub fn requires_synchronized_create() -> bool {\n    false\n}\n"],[2336,"use crate::ffi::OsStr;\nuse crate::path::Prefix;\n\n#[inline]\npub fn is_sep_byte(b: u8) -> bool {\n    b == b'/'\n}\n\n#[inline]\npub fn is_verbatim_sep(b: u8) -> bool {\n    b == b'/'\n}\n\npub fn parse_prefix(_: &OsStr) -> Option<Prefix<'_>> {\n    None\n}\n\npub const MAIN_SEP_STR: &str = \"/\";\npub const MAIN_SEP: char = '/';\n"],[2337,"#![cfg(target_thread_local)]\n#![unstable(feature = \"thread_local_internals\", issue = \"none\")]\n\n//! Provides thread-local destructors without an associated \"key\", which\n//! can be more efficient.\n\n// Since what appears to be glibc 2.18 this symbol has been shipped which\n// GCC and clang both use to invoke destructors in thread_local globals, so\n// let's do the same!\n//\n// Note, however, that we run on lots older linuxes, as well as cross\n// compiling from a newer linux to an older linux, so we also have a\n// fallback implementation to use as well.\n#[cfg(any(\n    target_os = \"linux\",\n    target_os = \"fuchsia\",\n    target_os = \"redox\",\n    target_os = \"emscripten\"\n))]\npub unsafe fn register_dtor(t: *mut u8, dtor: unsafe extern \"C\" fn(*mut u8)) {\n    use crate::mem;\n    use crate::sys_common::thread_local_dtor::register_dtor_fallback;\n\n    extern \"C\" {\n        #[linkage = \"extern_weak\"]\n        static __dso_handle: *mut u8;\n        #[linkage = \"extern_weak\"]\n        static __cxa_thread_atexit_impl: *const libc::c_void;\n    }\n    if !__cxa_thread_atexit_impl.is_null() {\n        type F = unsafe extern \"C\" fn(\n            dtor: unsafe extern \"C\" fn(*mut u8),\n            arg: *mut u8,\n            dso_handle: *mut u8,\n        ) -> libc::c_int;\n        mem::transmute::<*const libc::c_void, F>(__cxa_thread_atexit_impl)(\n            dtor,\n            t,\n            &__dso_handle as *const _ as *mut _,\n        );\n        return;\n    }\n    register_dtor_fallback(t, dtor);\n}\n\n// This implementation is very similar to register_dtor_fallback in\n// sys_common/thread_local.rs. The main difference is that we want to hook into\n// macOS's analog of the above linux function, _tlv_atexit. OSX will run the\n// registered dtors before any TLS slots get freed, and when the main thread\n// exits.\n//\n// Unfortunately, calling _tlv_atexit while tls dtors are running is UB. The\n// workaround below is to register, via _tlv_atexit, a custom DTOR list once per\n// thread. thread_local dtors are pushed to the DTOR list without calling\n// _tlv_atexit.\n#[cfg(target_os = \"macos\")]\npub unsafe fn register_dtor(t: *mut u8, dtor: unsafe extern \"C\" fn(*mut u8)) {\n    use crate::cell::Cell;\n    use crate::ptr;\n\n    #[thread_local]\n    static REGISTERED: Cell<bool> = Cell::new(false);\n    if !REGISTERED.get() {\n        _tlv_atexit(run_dtors, ptr::null_mut());\n        REGISTERED.set(true);\n    }\n\n    type List = Vec<(*mut u8, unsafe extern \"C\" fn(*mut u8))>;\n\n    #[thread_local]\n    static DTORS: Cell<*mut List> = Cell::new(ptr::null_mut());\n    if DTORS.get().is_null() {\n        let v: Box<List> = box Vec::new();\n        DTORS.set(Box::into_raw(v));\n    }\n\n    extern \"C\" {\n        fn _tlv_atexit(dtor: unsafe extern \"C\" fn(*mut u8), arg: *mut u8);\n    }\n\n    let list: &mut List = &mut *DTORS.get();\n    list.push((t, dtor));\n\n    unsafe extern \"C\" fn run_dtors(_: *mut u8) {\n        let mut ptr = DTORS.replace(ptr::null_mut());\n        while !ptr.is_null() {\n            let list = Box::from_raw(ptr);\n            for (ptr, dtor) in list.into_iter() {\n                dtor(ptr);\n            }\n            ptr = DTORS.replace(ptr::null_mut());\n        }\n    }\n}\n\n#[cfg(target_os = \"vxworks\")]\npub unsafe fn register_dtor(t: *mut u8, dtor: unsafe extern \"C\" fn(*mut u8)) {\n    use crate::sys_common::thread_local_dtor::register_dtor_fallback;\n    register_dtor_fallback(t, dtor);\n}\n"],[2338,"#[cfg(target_os = \"linux\")]\npub mod os {\n    pub const FAMILY: &str = \"unix\";\n    pub const OS: &str = \"linux\";\n    pub const DLL_PREFIX: &str = \"lib\";\n    pub const DLL_SUFFIX: &str = \".so\";\n    pub const DLL_EXTENSION: &str = \"so\";\n    pub const EXE_SUFFIX: &str = \"\";\n    pub const EXE_EXTENSION: &str = \"\";\n}\n\n#[cfg(target_os = \"macos\")]\npub mod os {\n    pub const FAMILY: &str = \"unix\";\n    pub const OS: &str = \"macos\";\n    pub const DLL_PREFIX: &str = \"lib\";\n    pub const DLL_SUFFIX: &str = \".dylib\";\n    pub const DLL_EXTENSION: &str = \"dylib\";\n    pub const EXE_SUFFIX: &str = \"\";\n    pub const EXE_EXTENSION: &str = \"\";\n}\n\n#[cfg(target_os = \"ios\")]\npub mod os {\n    pub const FAMILY: &str = \"unix\";\n    pub const OS: &str = \"ios\";\n    pub const DLL_PREFIX: &str = \"lib\";\n    pub const DLL_SUFFIX: &str = \".dylib\";\n    pub const DLL_EXTENSION: &str = \"dylib\";\n    pub const EXE_SUFFIX: &str = \"\";\n    pub const EXE_EXTENSION: &str = \"\";\n}\n\n#[cfg(target_os = \"freebsd\")]\npub mod os {\n    pub const FAMILY: &str = \"unix\";\n    pub const OS: &str = \"freebsd\";\n    pub const DLL_PREFIX: &str = \"lib\";\n    pub const DLL_SUFFIX: &str = \".so\";\n    pub const DLL_EXTENSION: &str = \"so\";\n    pub const EXE_SUFFIX: &str = \"\";\n    pub const EXE_EXTENSION: &str = \"\";\n}\n\n#[cfg(target_os = \"dragonfly\")]\npub mod os {\n    pub const FAMILY: &str = \"unix\";\n    pub const OS: &str = \"dragonfly\";\n    pub const DLL_PREFIX: &str = \"lib\";\n    pub const DLL_SUFFIX: &str = \".so\";\n    pub const DLL_EXTENSION: &str = \"so\";\n    pub const EXE_SUFFIX: &str = \"\";\n    pub const EXE_EXTENSION: &str = \"\";\n}\n\n#[cfg(target_os = \"netbsd\")]\npub mod os {\n    pub const FAMILY: &str = \"unix\";\n    pub const OS: &str = \"netbsd\";\n    pub const DLL_PREFIX: &str = \"lib\";\n    pub const DLL_SUFFIX: &str = \".so\";\n    pub const DLL_EXTENSION: &str = \"so\";\n    pub const EXE_SUFFIX: &str = \"\";\n    pub const EXE_EXTENSION: &str = \"\";\n}\n\n#[cfg(target_os = \"openbsd\")]\npub mod os {\n    pub const FAMILY: &str = \"unix\";\n    pub const OS: &str = \"openbsd\";\n    pub const DLL_PREFIX: &str = \"lib\";\n    pub const DLL_SUFFIX: &str = \".so\";\n    pub const DLL_EXTENSION: &str = \"so\";\n    pub const EXE_SUFFIX: &str = \"\";\n    pub const EXE_EXTENSION: &str = \"\";\n}\n\n#[cfg(target_os = \"android\")]\npub mod os {\n    pub const FAMILY: &str = \"unix\";\n    pub const OS: &str = \"android\";\n    pub const DLL_PREFIX: &str = \"lib\";\n    pub const DLL_SUFFIX: &str = \".so\";\n    pub const DLL_EXTENSION: &str = \"so\";\n    pub const EXE_SUFFIX: &str = \"\";\n    pub const EXE_EXTENSION: &str = \"\";\n}\n\n#[cfg(target_os = \"solaris\")]\npub mod os {\n    pub const FAMILY: &str = \"unix\";\n    pub const OS: &str = \"solaris\";\n    pub const DLL_PREFIX: &str = \"lib\";\n    pub const DLL_SUFFIX: &str = \".so\";\n    pub const DLL_EXTENSION: &str = \"so\";\n    pub const EXE_SUFFIX: &str = \"\";\n    pub const EXE_EXTENSION: &str = \"\";\n}\n\n#[cfg(target_os = \"illumos\")]\npub mod os {\n    pub const FAMILY: &str = \"unix\";\n    pub const OS: &str = \"illumos\";\n    pub const DLL_PREFIX: &str = \"lib\";\n    pub const DLL_SUFFIX: &str = \".so\";\n    pub const DLL_EXTENSION: &str = \"so\";\n    pub const EXE_SUFFIX: &str = \"\";\n    pub const EXE_EXTENSION: &str = \"\";\n}\n\n#[cfg(target_os = \"haiku\")]\npub mod os {\n    pub const FAMILY: &str = \"unix\";\n    pub const OS: &str = \"haiku\";\n    pub const DLL_PREFIX: &str = \"lib\";\n    pub const DLL_SUFFIX: &str = \".so\";\n    pub const DLL_EXTENSION: &str = \"so\";\n    pub const EXE_SUFFIX: &str = \"\";\n    pub const EXE_EXTENSION: &str = \"\";\n}\n\n#[cfg(all(target_os = \"emscripten\", target_arch = \"asmjs\"))]\npub mod os {\n    pub const FAMILY: &str = \"unix\";\n    pub const OS: &str = \"emscripten\";\n    pub const DLL_PREFIX: &str = \"lib\";\n    pub const DLL_SUFFIX: &str = \".so\";\n    pub const DLL_EXTENSION: &str = \"so\";\n    pub const EXE_SUFFIX: &str = \".js\";\n    pub const EXE_EXTENSION: &str = \"js\";\n}\n\n#[cfg(all(target_os = \"emscripten\", target_arch = \"wasm32\"))]\npub mod os {\n    pub const FAMILY: &str = \"unix\";\n    pub const OS: &str = \"emscripten\";\n    pub const DLL_PREFIX: &str = \"lib\";\n    pub const DLL_SUFFIX: &str = \".so\";\n    pub const DLL_EXTENSION: &str = \"so\";\n    pub const EXE_SUFFIX: &str = \".js\";\n    pub const EXE_EXTENSION: &str = \"js\";\n}\n\n#[cfg(target_os = \"fuchsia\")]\npub mod os {\n    pub const FAMILY: &str = \"unix\";\n    pub const OS: &str = \"fuchsia\";\n    pub const DLL_PREFIX: &str = \"lib\";\n    pub const DLL_SUFFIX: &str = \".so\";\n    pub const DLL_EXTENSION: &str = \"so\";\n    pub const EXE_SUFFIX: &str = \"\";\n    pub const EXE_EXTENSION: &str = \"\";\n}\n\n#[cfg(target_os = \"l4re\")]\npub mod os {\n    pub const FAMILY: &str = \"unix\";\n    pub const OS: &str = \"l4re\";\n    pub const DLL_PREFIX: &str = \"lib\";\n    pub const DLL_SUFFIX: &str = \".so\";\n    pub const DLL_EXTENSION: &str = \"so\";\n    pub const EXE_SUFFIX: &str = \"\";\n    pub const EXE_EXTENSION: &str = \"\";\n}\n\n#[cfg(target_os = \"redox\")]\npub mod os {\n    pub const FAMILY: &str = \"unix\";\n    pub const OS: &str = \"redox\";\n    pub const DLL_PREFIX: &str = \"lib\";\n    pub const DLL_SUFFIX: &str = \".so\";\n    pub const DLL_EXTENSION: &str = \"so\";\n    pub const EXE_SUFFIX: &str = \"\";\n    pub const EXE_EXTENSION: &str = \"\";\n}\n\n#[cfg(target_os = \"vxworks\")]\npub mod os {\n    pub const FAMILY: &str = \"unix\";\n    pub const OS: &str = \"vxworks\";\n    pub const DLL_PREFIX: &str = \"lib\";\n    pub const DLL_SUFFIX: &str = \".so\";\n    pub const DLL_EXTENSION: &str = \"so\";\n    pub const EXE_SUFFIX: &str = \"\";\n    pub const EXE_EXTENSION: &str = \"\";\n}\n"],[2339,"#![allow(missing_docs, nonstandard_style)]\n\nuse crate::io::ErrorKind;\n\npub use self::rand::hashmap_random_keys;\npub use libc::strlen;\n\n#[macro_use]\npub mod weak;\n\npub mod alloc;\npub mod android;\npub mod args;\n#[path = \"../unix/cmath.rs\"]\npub mod cmath;\npub mod condvar;\npub mod env;\npub mod fd;\npub mod fs;\npub mod futex;\npub mod io;\n#[cfg(any(target_os = \"linux\", target_os = \"android\"))]\npub mod kernel_copy;\n#[cfg(target_os = \"l4re\")]\nmod l4re;\npub mod memchr;\npub mod mutex;\n#[cfg(not(target_os = \"l4re\"))]\npub mod net;\n#[cfg(target_os = \"l4re\")]\npub use self::l4re::net;\npub mod os;\npub mod path;\npub mod pipe;\npub mod process;\npub mod rand;\npub mod rwlock;\npub mod stack_overflow;\npub mod stdio;\npub mod thread;\npub mod thread_local_dtor;\npub mod thread_local_key;\npub mod time;\n\npub use crate::sys_common::os_str_bytes as os_str;\n\n// SAFETY: must be called only once during runtime initialization.\n// NOTE: this is not guaranteed to run, for example when Rust code is called externally.\npub unsafe fn init(argc: isize, argv: *const *const u8) {\n    // The standard streams might be closed on application startup. To prevent\n    // std::io::{stdin, stdout,stderr} objects from using other unrelated file\n    // resources opened later, we reopen standards streams when they are closed.\n    sanitize_standard_fds();\n\n    // By default, some platforms will send a *signal* when an EPIPE error\n    // would otherwise be delivered. This runtime doesn't install a SIGPIPE\n    // handler, causing it to kill the program, which isn't exactly what we\n    // want!\n    //\n    // Hence, we set SIGPIPE to ignore when the program starts up in order\n    // to prevent this problem.\n    reset_sigpipe();\n\n    stack_overflow::init();\n    args::init(argc, argv);\n\n    unsafe fn sanitize_standard_fds() {\n        #[cfg(not(miri))]\n        // The standard fds are always available in Miri.\n        cfg_if::cfg_if! {\n            if #[cfg(not(any(\n                target_os = \"emscripten\",\n                target_os = \"fuchsia\",\n                target_os = \"vxworks\",\n                // The poll on Darwin doesn't set POLLNVAL for closed fds.\n                target_os = \"macos\",\n                target_os = \"ios\",\n                target_os = \"redox\",\n            )))] {\n                use crate::sys::os::errno;\n                let pfds: &mut [_] = &mut [\n                    libc::pollfd { fd: 0, events: 0, revents: 0 },\n                    libc::pollfd { fd: 1, events: 0, revents: 0 },\n                    libc::pollfd { fd: 2, events: 0, revents: 0 },\n                ];\n                while libc::poll(pfds.as_mut_ptr(), 3, 0) == -1 {\n                    if errno() == libc::EINTR {\n                        continue;\n                    }\n                    libc::abort();\n                }\n                for pfd in pfds {\n                    if pfd.revents & libc::POLLNVAL == 0 {\n                        continue;\n                    }\n                    if libc::open(\"/dev/null\\0\".as_ptr().cast(), libc::O_RDWR, 0) == -1 {\n                        // If the stream is closed but we failed to reopen it, abort the\n                        // process. Otherwise we wouldn't preserve the safety of\n                        // operations on the corresponding Rust object Stdin, Stdout, or\n                        // Stderr.\n                        libc::abort();\n                    }\n                }\n            } else if #[cfg(any(target_os = \"macos\", target_os = \"ios\", target_os = \"redox\"))] {\n                use crate::sys::os::errno;\n                for fd in 0..3 {\n                    if libc::fcntl(fd, libc::F_GETFD) == -1 && errno() == libc::EBADF {\n                        if libc::open(\"/dev/null\\0\".as_ptr().cast(), libc::O_RDWR, 0) == -1 {\n                            libc::abort();\n                        }\n                    }\n                }\n            }\n        }\n    }\n\n    unsafe fn reset_sigpipe() {\n        #[cfg(not(any(target_os = \"emscripten\", target_os = \"fuchsia\")))]\n        assert!(signal(libc::SIGPIPE, libc::SIG_IGN) != libc::SIG_ERR);\n    }\n}\n\n// SAFETY: must be called only once during runtime cleanup.\n// NOTE: this is not guaranteed to run, for example when the program aborts.\npub unsafe fn cleanup() {\n    args::cleanup();\n    stack_overflow::cleanup();\n}\n\n#[cfg(target_os = \"android\")]\npub use crate::sys::android::signal;\n#[cfg(not(target_os = \"android\"))]\npub use libc::signal;\n\npub fn decode_error_kind(errno: i32) -> ErrorKind {\n    match errno as libc::c_int {\n        libc::ECONNREFUSED => ErrorKind::ConnectionRefused,\n        libc::ECONNRESET => ErrorKind::ConnectionReset,\n        libc::EPERM | libc::EACCES => ErrorKind::PermissionDenied,\n        libc::EPIPE => ErrorKind::BrokenPipe,\n        libc::ENOTCONN => ErrorKind::NotConnected,\n        libc::ECONNABORTED => ErrorKind::ConnectionAborted,\n        libc::EADDRNOTAVAIL => ErrorKind::AddrNotAvailable,\n        libc::EADDRINUSE => ErrorKind::AddrInUse,\n        libc::ENOENT => ErrorKind::NotFound,\n        libc::EINTR => ErrorKind::Interrupted,\n        libc::EINVAL => ErrorKind::InvalidInput,\n        libc::ETIMEDOUT => ErrorKind::TimedOut,\n        libc::EEXIST => ErrorKind::AlreadyExists,\n        libc::ENOSYS => ErrorKind::Unsupported,\n        libc::ENOMEM => ErrorKind::OutOfMemory,\n\n        // These two constants can have the same value on some systems,\n        // but different values on others, so we can't use a match\n        // clause\n        x if x == libc::EAGAIN || x == libc::EWOULDBLOCK => ErrorKind::WouldBlock,\n\n        _ => ErrorKind::Other,\n    }\n}\n\n#[doc(hidden)]\npub trait IsMinusOne {\n    fn is_minus_one(&self) -> bool;\n}\n\nmacro_rules! impl_is_minus_one {\n    ($($t:ident)*) => ($(impl IsMinusOne for $t {\n        fn is_minus_one(&self) -> bool {\n            *self == -1\n        }\n    })*)\n}\n\nimpl_is_minus_one! { i8 i16 i32 i64 isize }\n\npub fn cvt<T: IsMinusOne>(t: T) -> crate::io::Result<T> {\n    if t.is_minus_one() { Err(crate::io::Error::last_os_error()) } else { Ok(t) }\n}\n\npub fn cvt_r<T, F>(mut f: F) -> crate::io::Result<T>\nwhere\n    T: IsMinusOne,\n    F: FnMut() -> T,\n{\n    loop {\n        match cvt(f()) {\n            Err(ref e) if e.kind() == ErrorKind::Interrupted => {}\n            other => return other,\n        }\n    }\n}\n\npub fn cvt_nz(error: libc::c_int) -> crate::io::Result<()> {\n    if error == 0 { Ok(()) } else { Err(crate::io::Error::from_raw_os_error(error)) }\n}\n\n// On Unix-like platforms, libc::abort will unregister signal handlers\n// including the SIGABRT handler, preventing the abort from being blocked, and\n// fclose streams, with the side effect of flushing them so libc buffered\n// output will be printed.  Additionally the shell will generally print a more\n// understandable error message like \"Abort trap\" rather than \"Illegal\n// instruction\" that intrinsics::abort would cause, as intrinsics::abort is\n// implemented as an illegal instruction.\npub fn abort_internal() -> ! {\n    unsafe { libc::abort() }\n}\n\ncfg_if::cfg_if! {\n    if #[cfg(target_os = \"android\")] {\n        #[link(name = \"dl\")]\n        #[link(name = \"log\")]\n        extern \"C\" {}\n    } else if #[cfg(target_os = \"freebsd\")] {\n        #[link(name = \"execinfo\")]\n        #[link(name = \"pthread\")]\n        extern \"C\" {}\n    } else if #[cfg(target_os = \"netbsd\")] {\n        #[link(name = \"pthread\")]\n        #[link(name = \"rt\")]\n        extern \"C\" {}\n    } else if #[cfg(any(target_os = \"dragonfly\", target_os = \"openbsd\"))] {\n        #[link(name = \"pthread\")]\n        extern \"C\" {}\n    } else if #[cfg(target_os = \"solaris\")] {\n        #[link(name = \"socket\")]\n        #[link(name = \"posix4\")]\n        #[link(name = \"pthread\")]\n        #[link(name = \"resolv\")]\n        extern \"C\" {}\n    } else if #[cfg(target_os = \"illumos\")] {\n        #[link(name = \"socket\")]\n        #[link(name = \"posix4\")]\n        #[link(name = \"pthread\")]\n        #[link(name = \"resolv\")]\n        #[link(name = \"nsl\")]\n        // Use libumem for the (malloc-compatible) allocator\n        #[link(name = \"umem\")]\n        extern \"C\" {}\n    } else if #[cfg(target_os = \"macos\")] {\n        #[link(name = \"System\")]\n        // res_init and friends require -lresolv on macOS/iOS.\n        // See #41582 and https://blog.achernya.com/2013/03/os-x-has-silly-libsystem.html\n        #[link(name = \"resolv\")]\n        extern \"C\" {}\n    } else if #[cfg(target_os = \"ios\")] {\n        #[link(name = \"System\")]\n        #[link(name = \"objc\")]\n        #[link(name = \"Security\", kind = \"framework\")]\n        #[link(name = \"Foundation\", kind = \"framework\")]\n        #[link(name = \"resolv\")]\n        extern \"C\" {}\n    } else if #[cfg(target_os = \"fuchsia\")] {\n        #[link(name = \"zircon\")]\n        #[link(name = \"fdio\")]\n        extern \"C\" {}\n    }\n}\n"],[2340,"use crate::cmp;\nuse crate::ffi::CStr;\nuse crate::io::{self, IoSlice, IoSliceMut};\nuse crate::mem;\nuse crate::net::{Shutdown, SocketAddr};\nuse crate::str;\nuse crate::sys::fd::FileDesc;\nuse crate::sys_common::net::{getsockopt, setsockopt, sockaddr_to_addr};\nuse crate::sys_common::{AsInner, FromInner, IntoInner};\nuse crate::time::{Duration, Instant};\n\nuse libc::{c_int, c_void, size_t, sockaddr, socklen_t, EAI_SYSTEM, MSG_PEEK};\n\npub use crate::sys::{cvt, cvt_r};\n\n#[allow(unused_extern_crates)]\npub extern crate libc as netc;\n\npub type wrlen_t = size_t;\n\npub struct Socket(FileDesc);\n\npub fn init() {}\n\npub fn cvt_gai(err: c_int) -> io::Result<()> {\n    if err == 0 {\n        return Ok(());\n    }\n\n    // We may need to trigger a glibc workaround. See on_resolver_failure() for details.\n    on_resolver_failure();\n\n    if err == EAI_SYSTEM {\n        return Err(io::Error::last_os_error());\n    }\n\n    let detail = unsafe {\n        str::from_utf8(CStr::from_ptr(libc::gai_strerror(err)).to_bytes()).unwrap().to_owned()\n    };\n    Err(io::Error::new(\n        io::ErrorKind::Other,\n        &format!(\"failed to lookup address information: {}\", detail)[..],\n    ))\n}\n\nimpl Socket {\n    pub fn new(addr: &SocketAddr, ty: c_int) -> io::Result<Socket> {\n        let fam = match *addr {\n            SocketAddr::V4(..) => libc::AF_INET,\n            SocketAddr::V6(..) => libc::AF_INET6,\n        };\n        Socket::new_raw(fam, ty)\n    }\n\n    pub fn new_raw(fam: c_int, ty: c_int) -> io::Result<Socket> {\n        unsafe {\n            cfg_if::cfg_if! {\n                if #[cfg(any(\n                    target_os = \"android\",\n                    target_os = \"dragonfly\",\n                    target_os = \"freebsd\",\n                    target_os = \"illumos\",\n                    target_os = \"linux\",\n                    target_os = \"netbsd\",\n                    target_os = \"openbsd\",\n                ))] {\n                    // On platforms that support it we pass the SOCK_CLOEXEC\n                    // flag to atomically create the socket and set it as\n                    // CLOEXEC. On Linux this was added in 2.6.27.\n                    let fd = cvt(libc::socket(fam, ty | libc::SOCK_CLOEXEC, 0))?;\n                    Ok(Socket(FileDesc::new(fd)))\n                } else {\n                    let fd = cvt(libc::socket(fam, ty, 0))?;\n                    let fd = FileDesc::new(fd);\n                    fd.set_cloexec()?;\n                    let socket = Socket(fd);\n\n                    // macOS and iOS use `SO_NOSIGPIPE` as a `setsockopt`\n                    // flag to disable `SIGPIPE` emission on socket.\n                    #[cfg(target_vendor = \"apple\")]\n                    setsockopt(&socket, libc::SOL_SOCKET, libc::SO_NOSIGPIPE, 1)?;\n\n                    Ok(socket)\n                }\n            }\n        }\n    }\n\n    #[cfg(not(target_os = \"vxworks\"))]\n    pub fn new_pair(fam: c_int, ty: c_int) -> io::Result<(Socket, Socket)> {\n        unsafe {\n            let mut fds = [0, 0];\n\n            cfg_if::cfg_if! {\n                if #[cfg(any(\n                    target_os = \"android\",\n                    target_os = \"dragonfly\",\n                    target_os = \"freebsd\",\n                    target_os = \"illumos\",\n                    target_os = \"linux\",\n                    target_os = \"netbsd\",\n                    target_os = \"openbsd\",\n                ))] {\n                    // Like above, set cloexec atomically\n                    cvt(libc::socketpair(fam, ty | libc::SOCK_CLOEXEC, 0, fds.as_mut_ptr()))?;\n                    Ok((Socket(FileDesc::new(fds[0])), Socket(FileDesc::new(fds[1]))))\n                } else {\n                    cvt(libc::socketpair(fam, ty, 0, fds.as_mut_ptr()))?;\n                    let a = FileDesc::new(fds[0]);\n                    let b = FileDesc::new(fds[1]);\n                    a.set_cloexec()?;\n                    b.set_cloexec()?;\n                    Ok((Socket(a), Socket(b)))\n                }\n            }\n        }\n    }\n\n    #[cfg(target_os = \"vxworks\")]\n    pub fn new_pair(_fam: c_int, _ty: c_int) -> io::Result<(Socket, Socket)> {\n        unimplemented!()\n    }\n\n    pub fn connect_timeout(&self, addr: &SocketAddr, timeout: Duration) -> io::Result<()> {\n        self.set_nonblocking(true)?;\n        let r = unsafe {\n            let (addrp, len) = addr.into_inner();\n            cvt(libc::connect(self.0.raw(), addrp, len))\n        };\n        self.set_nonblocking(false)?;\n\n        match r {\n            Ok(_) => return Ok(()),\n            // there's no ErrorKind for EINPROGRESS :(\n            Err(ref e) if e.raw_os_error() == Some(libc::EINPROGRESS) => {}\n            Err(e) => return Err(e),\n        }\n\n        let mut pollfd = libc::pollfd { fd: self.0.raw(), events: libc::POLLOUT, revents: 0 };\n\n        if timeout.as_secs() == 0 && timeout.subsec_nanos() == 0 {\n            return Err(io::Error::new_const(\n                io::ErrorKind::InvalidInput,\n                &\"cannot set a 0 duration timeout\",\n            ));\n        }\n\n        let start = Instant::now();\n\n        loop {\n            let elapsed = start.elapsed();\n            if elapsed >= timeout {\n                return Err(io::Error::new_const(io::ErrorKind::TimedOut, &\"connection timed out\"));\n            }\n\n            let timeout = timeout - elapsed;\n            let mut timeout = timeout\n                .as_secs()\n                .saturating_mul(1_000)\n                .saturating_add(timeout.subsec_nanos() as u64 / 1_000_000);\n            if timeout == 0 {\n                timeout = 1;\n            }\n\n            let timeout = cmp::min(timeout, c_int::MAX as u64) as c_int;\n\n            match unsafe { libc::poll(&mut pollfd, 1, timeout) } {\n                -1 => {\n                    let err = io::Error::last_os_error();\n                    if err.kind() != io::ErrorKind::Interrupted {\n                        return Err(err);\n                    }\n                }\n                0 => {}\n                _ => {\n                    // linux returns POLLOUT|POLLERR|POLLHUP for refused connections (!), so look\n                    // for POLLHUP rather than read readiness\n                    if pollfd.revents & libc::POLLHUP != 0 {\n                        let e = self.take_error()?.unwrap_or_else(|| {\n                            io::Error::new_const(\n                                io::ErrorKind::Other,\n                                &\"no error set after POLLHUP\",\n                            )\n                        });\n                        return Err(e);\n                    }\n\n                    return Ok(());\n                }\n            }\n        }\n    }\n\n    pub fn accept(&self, storage: *mut sockaddr, len: *mut socklen_t) -> io::Result<Socket> {\n        // Unfortunately the only known way right now to accept a socket and\n        // atomically set the CLOEXEC flag is to use the `accept4` syscall on\n        // platforms that support it. On Linux, this was added in 2.6.28,\n        // glibc 2.10 and musl 0.9.5.\n        cfg_if::cfg_if! {\n            if #[cfg(any(\n                target_os = \"android\",\n                target_os = \"dragonfly\",\n                target_os = \"freebsd\",\n                target_os = \"illumos\",\n                target_os = \"linux\",\n                target_os = \"netbsd\",\n                target_os = \"openbsd\",\n            ))] {\n                let fd = cvt_r(|| unsafe {\n                    libc::accept4(self.0.raw(), storage, len, libc::SOCK_CLOEXEC)\n                })?;\n                Ok(Socket(FileDesc::new(fd)))\n            } else {\n                let fd = cvt_r(|| unsafe { libc::accept(self.0.raw(), storage, len) })?;\n                let fd = FileDesc::new(fd);\n                fd.set_cloexec()?;\n                Ok(Socket(fd))\n            }\n        }\n    }\n\n    pub fn duplicate(&self) -> io::Result<Socket> {\n        self.0.duplicate().map(Socket)\n    }\n\n    fn recv_with_flags(&self, buf: &mut [u8], flags: c_int) -> io::Result<usize> {\n        let ret = cvt(unsafe {\n            libc::recv(self.0.raw(), buf.as_mut_ptr() as *mut c_void, buf.len(), flags)\n        })?;\n        Ok(ret as usize)\n    }\n\n    pub fn read(&self, buf: &mut [u8]) -> io::Result<usize> {\n        self.recv_with_flags(buf, 0)\n    }\n\n    pub fn peek(&self, buf: &mut [u8]) -> io::Result<usize> {\n        self.recv_with_flags(buf, MSG_PEEK)\n    }\n\n    pub fn read_vectored(&self, bufs: &mut [IoSliceMut<'_>]) -> io::Result<usize> {\n        self.0.read_vectored(bufs)\n    }\n\n    #[inline]\n    pub fn is_read_vectored(&self) -> bool {\n        self.0.is_read_vectored()\n    }\n\n    fn recv_from_with_flags(\n        &self,\n        buf: &mut [u8],\n        flags: c_int,\n    ) -> io::Result<(usize, SocketAddr)> {\n        let mut storage: libc::sockaddr_storage = unsafe { mem::zeroed() };\n        let mut addrlen = mem::size_of_val(&storage) as libc::socklen_t;\n\n        let n = cvt(unsafe {\n            libc::recvfrom(\n                self.0.raw(),\n                buf.as_mut_ptr() as *mut c_void,\n                buf.len(),\n                flags,\n                &mut storage as *mut _ as *mut _,\n                &mut addrlen,\n            )\n        })?;\n        Ok((n as usize, sockaddr_to_addr(&storage, addrlen as usize)?))\n    }\n\n    pub fn recv_from(&self, buf: &mut [u8]) -> io::Result<(usize, SocketAddr)> {\n        self.recv_from_with_flags(buf, 0)\n    }\n\n    #[cfg(any(\n        target_os = \"android\",\n        target_os = \"dragonfly\",\n        target_os = \"emscripten\",\n        target_os = \"freebsd\",\n        target_os = \"linux\",\n        target_os = \"netbsd\",\n        target_os = \"openbsd\",\n    ))]\n    pub fn recv_msg(&self, msg: &mut libc::msghdr) -> io::Result<usize> {\n        let n = cvt(unsafe { libc::recvmsg(self.0.raw(), msg, libc::MSG_CMSG_CLOEXEC) })?;\n        Ok(n as usize)\n    }\n\n    pub fn peek_from(&self, buf: &mut [u8]) -> io::Result<(usize, SocketAddr)> {\n        self.recv_from_with_flags(buf, MSG_PEEK)\n    }\n\n    pub fn write(&self, buf: &[u8]) -> io::Result<usize> {\n        self.0.write(buf)\n    }\n\n    pub fn write_vectored(&self, bufs: &[IoSlice<'_>]) -> io::Result<usize> {\n        self.0.write_vectored(bufs)\n    }\n\n    #[inline]\n    pub fn is_write_vectored(&self) -> bool {\n        self.0.is_write_vectored()\n    }\n\n    #[cfg(any(\n        target_os = \"android\",\n        target_os = \"dragonfly\",\n        target_os = \"emscripten\",\n        target_os = \"freebsd\",\n        target_os = \"linux\",\n        target_os = \"netbsd\",\n        target_os = \"openbsd\",\n    ))]\n    pub fn send_msg(&self, msg: &mut libc::msghdr) -> io::Result<usize> {\n        let n = cvt(unsafe { libc::sendmsg(self.0.raw(), msg, 0) })?;\n        Ok(n as usize)\n    }\n\n    pub fn set_timeout(&self, dur: Option<Duration>, kind: libc::c_int) -> io::Result<()> {\n        let timeout = match dur {\n            Some(dur) => {\n                if dur.as_secs() == 0 && dur.subsec_nanos() == 0 {\n                    return Err(io::Error::new_const(\n                        io::ErrorKind::InvalidInput,\n                        &\"cannot set a 0 duration timeout\",\n                    ));\n                }\n\n                let secs = if dur.as_secs() > libc::time_t::MAX as u64 {\n                    libc::time_t::MAX\n                } else {\n                    dur.as_secs() as libc::time_t\n                };\n                let mut timeout = libc::timeval {\n                    tv_sec: secs,\n                    tv_usec: dur.subsec_micros() as libc::suseconds_t,\n                };\n                if timeout.tv_sec == 0 && timeout.tv_usec == 0 {\n                    timeout.tv_usec = 1;\n                }\n                timeout\n            }\n            None => libc::timeval { tv_sec: 0, tv_usec: 0 },\n        };\n        setsockopt(self, libc::SOL_SOCKET, kind, timeout)\n    }\n\n    pub fn timeout(&self, kind: libc::c_int) -> io::Result<Option<Duration>> {\n        let raw: libc::timeval = getsockopt(self, libc::SOL_SOCKET, kind)?;\n        if raw.tv_sec == 0 && raw.tv_usec == 0 {\n            Ok(None)\n        } else {\n            let sec = raw.tv_sec as u64;\n            let nsec = (raw.tv_usec as u32) * 1000;\n            Ok(Some(Duration::new(sec, nsec)))\n        }\n    }\n\n    pub fn shutdown(&self, how: Shutdown) -> io::Result<()> {\n        let how = match how {\n            Shutdown::Write => libc::SHUT_WR,\n            Shutdown::Read => libc::SHUT_RD,\n            Shutdown::Both => libc::SHUT_RDWR,\n        };\n        cvt(unsafe { libc::shutdown(self.0.raw(), how) })?;\n        Ok(())\n    }\n\n    pub fn set_nodelay(&self, nodelay: bool) -> io::Result<()> {\n        setsockopt(self, libc::IPPROTO_TCP, libc::TCP_NODELAY, nodelay as c_int)\n    }\n\n    pub fn nodelay(&self) -> io::Result<bool> {\n        let raw: c_int = getsockopt(self, libc::IPPROTO_TCP, libc::TCP_NODELAY)?;\n        Ok(raw != 0)\n    }\n\n    #[cfg(any(target_os = \"android\", target_os = \"linux\",))]\n    pub fn set_passcred(&self, passcred: bool) -> io::Result<()> {\n        setsockopt(self, libc::SOL_SOCKET, libc::SO_PASSCRED, passcred as libc::c_int)\n    }\n\n    #[cfg(any(target_os = \"android\", target_os = \"linux\",))]\n    pub fn passcred(&self) -> io::Result<bool> {\n        let passcred: libc::c_int = getsockopt(self, libc::SOL_SOCKET, libc::SO_PASSCRED)?;\n        Ok(passcred != 0)\n    }\n\n    #[cfg(not(any(target_os = \"solaris\", target_os = \"illumos\")))]\n    pub fn set_nonblocking(&self, nonblocking: bool) -> io::Result<()> {\n        let mut nonblocking = nonblocking as libc::c_int;\n        cvt(unsafe { libc::ioctl(*self.as_inner(), libc::FIONBIO, &mut nonblocking) }).map(drop)\n    }\n\n    #[cfg(any(target_os = \"solaris\", target_os = \"illumos\"))]\n    pub fn set_nonblocking(&self, nonblocking: bool) -> io::Result<()> {\n        // FIONBIO is inadequate for sockets on illumos/Solaris, so use the\n        // fcntl(F_[GS]ETFL)-based method provided by FileDesc instead.\n        self.0.set_nonblocking(nonblocking)\n    }\n\n    pub fn take_error(&self) -> io::Result<Option<io::Error>> {\n        let raw: c_int = getsockopt(self, libc::SOL_SOCKET, libc::SO_ERROR)?;\n        if raw == 0 { Ok(None) } else { Ok(Some(io::Error::from_raw_os_error(raw as i32))) }\n    }\n}\n\nimpl AsInner<c_int> for Socket {\n    fn as_inner(&self) -> &c_int {\n        self.0.as_inner()\n    }\n}\n\nimpl FromInner<c_int> for Socket {\n    fn from_inner(fd: c_int) -> Socket {\n        Socket(FileDesc::new(fd))\n    }\n}\n\nimpl IntoInner<c_int> for Socket {\n    fn into_inner(self) -> c_int {\n        self.0.into_raw()\n    }\n}\n\n// In versions of glibc prior to 2.26, there's a bug where the DNS resolver\n// will cache the contents of /etc/resolv.conf, so changes to that file on disk\n// can be ignored by a long-running program. That can break DNS lookups on e.g.\n// laptops where the network comes and goes. See\n// https://sourceware.org/bugzilla/show_bug.cgi?id=984. Note however that some\n// distros including Debian have patched glibc to fix this for a long time.\n//\n// A workaround for this bug is to call the res_init libc function, to clear\n// the cached configs. Unfortunately, while we believe glibc's implementation\n// of res_init is thread-safe, we know that other implementations are not\n// (https://github.com/rust-lang/rust/issues/43592). Code here in libstd could\n// try to synchronize its res_init calls with a Mutex, but that wouldn't\n// protect programs that call into libc in other ways. So instead of calling\n// res_init unconditionally, we call it only when we detect we're linking\n// against glibc version < 2.26. (That is, when we both know its needed and\n// believe it's thread-safe).\n#[cfg(all(target_env = \"gnu\", not(target_os = \"vxworks\")))]\nfn on_resolver_failure() {\n    use crate::sys;\n\n    // If the version fails to parse, we treat it the same as \"not glibc\".\n    if let Some(version) = sys::os::glibc_version() {\n        if version < (2, 26) {\n            unsafe { libc::res_init() };\n        }\n    }\n}\n\n#[cfg(any(not(target_env = \"gnu\"), target_os = \"vxworks\"))]\nfn on_resolver_failure() {}\n"],[2341,"#![unstable(reason = \"not public\", issue = \"none\", feature = \"fd\")]\n\n#[cfg(test)]\nmod tests;\n\nuse crate::cmp;\nuse crate::io::{self, Initializer, IoSlice, IoSliceMut, Read};\nuse crate::mem;\nuse crate::sys::cvt;\nuse crate::sys_common::AsInner;\n\nuse libc::{c_int, c_void};\n\n#[derive(Debug)]\n#[rustc_layout_scalar_valid_range_start(0)]\n// libstd/os/raw/mod.rs assures me that every libstd-supported platform has a\n// 32-bit c_int. Below is -2, in two's complement, but that only works out\n// because c_int is 32 bits.\n#[rustc_layout_scalar_valid_range_end(0xFF_FF_FF_FE)]\npub struct FileDesc {\n    fd: c_int,\n}\n\n// The maximum read limit on most POSIX-like systems is `SSIZE_MAX`,\n// with the man page quoting that if the count of bytes to read is\n// greater than `SSIZE_MAX` the result is \"unspecified\".\n//\n// On macOS, however, apparently the 64-bit libc is either buggy or\n// intentionally showing odd behavior by rejecting any read with a size\n// larger than or equal to INT_MAX. To handle both of these the read\n// size is capped on both platforms.\n#[cfg(target_os = \"macos\")]\nconst READ_LIMIT: usize = c_int::MAX as usize - 1;\n#[cfg(not(target_os = \"macos\"))]\nconst READ_LIMIT: usize = libc::ssize_t::MAX as usize;\n\n#[cfg(any(\n    target_os = \"dragonfly\",\n    target_os = \"freebsd\",\n    target_os = \"ios\",\n    target_os = \"macos\",\n    target_os = \"netbsd\",\n    target_os = \"openbsd\",\n))]\nconst fn max_iov() -> usize {\n    libc::IOV_MAX as usize\n}\n\n#[cfg(any(target_os = \"android\", target_os = \"emscripten\", target_os = \"linux\"))]\nconst fn max_iov() -> usize {\n    libc::UIO_MAXIOV as usize\n}\n\n#[cfg(not(any(\n    target_os = \"android\",\n    target_os = \"dragonfly\",\n    target_os = \"emscripten\",\n    target_os = \"freebsd\",\n    target_os = \"ios\",\n    target_os = \"linux\",\n    target_os = \"macos\",\n    target_os = \"netbsd\",\n    target_os = \"openbsd\",\n)))]\nconst fn max_iov() -> usize {\n    16 // The minimum value required by POSIX.\n}\n\nimpl FileDesc {\n    pub fn new(fd: c_int) -> FileDesc {\n        assert_ne!(fd, -1i32);\n        // SAFETY: we just asserted that the value is in the valid range and isn't `-1` (the only value bigger than `0xFF_FF_FF_FE` unsigned)\n        unsafe { FileDesc { fd } }\n    }\n\n    pub fn raw(&self) -> c_int {\n        self.fd\n    }\n\n    /// Extracts the actual file descriptor without closing it.\n    pub fn into_raw(self) -> c_int {\n        let fd = self.fd;\n        mem::forget(self);\n        fd\n    }\n\n    pub fn read(&self, buf: &mut [u8]) -> io::Result<usize> {\n        let ret = cvt(unsafe {\n            libc::read(self.fd, buf.as_mut_ptr() as *mut c_void, cmp::min(buf.len(), READ_LIMIT))\n        })?;\n        Ok(ret as usize)\n    }\n\n    pub fn read_vectored(&self, bufs: &mut [IoSliceMut<'_>]) -> io::Result<usize> {\n        let ret = cvt(unsafe {\n            libc::readv(\n                self.fd,\n                bufs.as_ptr() as *const libc::iovec,\n                cmp::min(bufs.len(), max_iov()) as c_int,\n            )\n        })?;\n        Ok(ret as usize)\n    }\n\n    #[inline]\n    pub fn is_read_vectored(&self) -> bool {\n        true\n    }\n\n    pub fn read_to_end(&self, buf: &mut Vec<u8>) -> io::Result<usize> {\n        let mut me = self;\n        (&mut me).read_to_end(buf)\n    }\n\n    pub fn read_at(&self, buf: &mut [u8], offset: u64) -> io::Result<usize> {\n        #[cfg(target_os = \"android\")]\n        use super::android::cvt_pread64;\n\n        #[cfg(not(target_os = \"android\"))]\n        unsafe fn cvt_pread64(\n            fd: c_int,\n            buf: *mut c_void,\n            count: usize,\n            offset: i64,\n        ) -> io::Result<isize> {\n            #[cfg(not(target_os = \"linux\"))]\n            use libc::pread as pread64;\n            #[cfg(target_os = \"linux\")]\n            use libc::pread64;\n            cvt(pread64(fd, buf, count, offset))\n        }\n\n        unsafe {\n            cvt_pread64(\n                self.fd,\n                buf.as_mut_ptr() as *mut c_void,\n                cmp::min(buf.len(), READ_LIMIT),\n                offset as i64,\n            )\n            .map(|n| n as usize)\n        }\n    }\n\n    pub fn write(&self, buf: &[u8]) -> io::Result<usize> {\n        let ret = cvt(unsafe {\n            libc::write(self.fd, buf.as_ptr() as *const c_void, cmp::min(buf.len(), READ_LIMIT))\n        })?;\n        Ok(ret as usize)\n    }\n\n    pub fn write_vectored(&self, bufs: &[IoSlice<'_>]) -> io::Result<usize> {\n        let ret = cvt(unsafe {\n            libc::writev(\n                self.fd,\n                bufs.as_ptr() as *const libc::iovec,\n                cmp::min(bufs.len(), max_iov()) as c_int,\n            )\n        })?;\n        Ok(ret as usize)\n    }\n\n    #[inline]\n    pub fn is_write_vectored(&self) -> bool {\n        true\n    }\n\n    pub fn write_at(&self, buf: &[u8], offset: u64) -> io::Result<usize> {\n        #[cfg(target_os = \"android\")]\n        use super::android::cvt_pwrite64;\n\n        #[cfg(not(target_os = \"android\"))]\n        unsafe fn cvt_pwrite64(\n            fd: c_int,\n            buf: *const c_void,\n            count: usize,\n            offset: i64,\n        ) -> io::Result<isize> {\n            #[cfg(not(target_os = \"linux\"))]\n            use libc::pwrite as pwrite64;\n            #[cfg(target_os = \"linux\")]\n            use libc::pwrite64;\n            cvt(pwrite64(fd, buf, count, offset))\n        }\n\n        unsafe {\n            cvt_pwrite64(\n                self.fd,\n                buf.as_ptr() as *const c_void,\n                cmp::min(buf.len(), READ_LIMIT),\n                offset as i64,\n            )\n            .map(|n| n as usize)\n        }\n    }\n\n    #[cfg(target_os = \"linux\")]\n    pub fn get_cloexec(&self) -> io::Result<bool> {\n        unsafe { Ok((cvt(libc::fcntl(self.fd, libc::F_GETFD))? & libc::FD_CLOEXEC) != 0) }\n    }\n\n    #[cfg(not(any(\n        target_env = \"newlib\",\n        target_os = \"solaris\",\n        target_os = \"illumos\",\n        target_os = \"emscripten\",\n        target_os = \"fuchsia\",\n        target_os = \"l4re\",\n        target_os = \"linux\",\n        target_os = \"haiku\",\n        target_os = \"redox\",\n        target_os = \"vxworks\"\n    )))]\n    pub fn set_cloexec(&self) -> io::Result<()> {\n        unsafe {\n            cvt(libc::ioctl(self.fd, libc::FIOCLEX))?;\n            Ok(())\n        }\n    }\n    #[cfg(any(\n        target_env = \"newlib\",\n        target_os = \"solaris\",\n        target_os = \"illumos\",\n        target_os = \"emscripten\",\n        target_os = \"fuchsia\",\n        target_os = \"l4re\",\n        target_os = \"linux\",\n        target_os = \"haiku\",\n        target_os = \"redox\",\n        target_os = \"vxworks\"\n    ))]\n    pub fn set_cloexec(&self) -> io::Result<()> {\n        unsafe {\n            let previous = cvt(libc::fcntl(self.fd, libc::F_GETFD))?;\n            let new = previous | libc::FD_CLOEXEC;\n            if new != previous {\n                cvt(libc::fcntl(self.fd, libc::F_SETFD, new))?;\n            }\n            Ok(())\n        }\n    }\n\n    #[cfg(target_os = \"linux\")]\n    pub fn set_nonblocking(&self, nonblocking: bool) -> io::Result<()> {\n        unsafe {\n            let v = nonblocking as c_int;\n            cvt(libc::ioctl(self.fd, libc::FIONBIO, &v))?;\n            Ok(())\n        }\n    }\n\n    #[cfg(not(target_os = \"linux\"))]\n    pub fn set_nonblocking(&self, nonblocking: bool) -> io::Result<()> {\n        unsafe {\n            let previous = cvt(libc::fcntl(self.fd, libc::F_GETFL))?;\n            let new = if nonblocking {\n                previous | libc::O_NONBLOCK\n            } else {\n                previous & !libc::O_NONBLOCK\n            };\n            if new != previous {\n                cvt(libc::fcntl(self.fd, libc::F_SETFL, new))?;\n            }\n            Ok(())\n        }\n    }\n\n    pub fn duplicate(&self) -> io::Result<FileDesc> {\n        // We want to atomically duplicate this file descriptor and set the\n        // CLOEXEC flag, and currently that's done via F_DUPFD_CLOEXEC. This\n        // is a POSIX flag that was added to Linux in 2.6.24.\n        let fd = cvt(unsafe { libc::fcntl(self.raw(), libc::F_DUPFD_CLOEXEC, 0) })?;\n        Ok(FileDesc::new(fd))\n    }\n}\n\nimpl<'a> Read for &'a FileDesc {\n    fn read(&mut self, buf: &mut [u8]) -> io::Result<usize> {\n        (**self).read(buf)\n    }\n\n    #[inline]\n    unsafe fn initializer(&self) -> Initializer {\n        Initializer::nop()\n    }\n}\n\nimpl AsInner<c_int> for FileDesc {\n    fn as_inner(&self) -> &c_int {\n        &self.fd\n    }\n}\n\nimpl Drop for FileDesc {\n    fn drop(&mut self) {\n        // Note that errors are ignored when closing a file descriptor. The\n        // reason for this is that if an error occurs we don't actually know if\n        // the file descriptor was closed or not, and if we retried (for\n        // something like EINTR), we might close another valid file descriptor\n        // opened after we closed ours.\n        let _ = unsafe { libc::close(self.fd) };\n    }\n}\n"],[2342,"use crate::cell::UnsafeCell;\nuse crate::sync::atomic::{AtomicUsize, Ordering};\n\npub struct RWLock {\n    inner: UnsafeCell<libc::pthread_rwlock_t>,\n    write_locked: UnsafeCell<bool>, // guarded by the `inner` RwLock\n    num_readers: AtomicUsize,\n}\n\npub type MovableRWLock = Box<RWLock>;\n\nunsafe impl Send for RWLock {}\nunsafe impl Sync for RWLock {}\n\nimpl RWLock {\n    pub const fn new() -> RWLock {\n        RWLock {\n            inner: UnsafeCell::new(libc::PTHREAD_RWLOCK_INITIALIZER),\n            write_locked: UnsafeCell::new(false),\n            num_readers: AtomicUsize::new(0),\n        }\n    }\n    #[inline]\n    pub unsafe fn read(&self) {\n        let r = libc::pthread_rwlock_rdlock(self.inner.get());\n\n        // According to POSIX, when a thread tries to acquire this read lock\n        // while it already holds the write lock\n        // (or vice versa, or tries to acquire the write lock twice),\n        // \"the call shall either deadlock or return [EDEADLK]\"\n        // (https://pubs.opengroup.org/onlinepubs/9699919799/functions/pthread_rwlock_wrlock.html,\n        // https://pubs.opengroup.org/onlinepubs/9699919799/functions/pthread_rwlock_rdlock.html).\n        // So, in principle, all we have to do here is check `r == 0` to be sure we properly\n        // got the lock.\n        //\n        // However, (at least) glibc before version 2.25 does not conform to this spec,\n        // and can return `r == 0` even when this thread already holds the write lock.\n        // We thus check for this situation ourselves and panic when detecting that a thread\n        // got the write lock more than once, or got a read and a write lock.\n        if r == libc::EAGAIN {\n            panic!(\"rwlock maximum reader count exceeded\");\n        } else if r == libc::EDEADLK || (r == 0 && *self.write_locked.get()) {\n            // Above, we make sure to only access `write_locked` when `r == 0` to avoid\n            // data races.\n            if r == 0 {\n                // `pthread_rwlock_rdlock` succeeded when it should not have.\n                self.raw_unlock();\n            }\n            panic!(\"rwlock read lock would result in deadlock\");\n        } else {\n            // According to POSIX, for a properly initialized rwlock this can only\n            // return EAGAIN or EDEADLK or 0. We rely on that.\n            debug_assert_eq!(r, 0);\n            self.num_readers.fetch_add(1, Ordering::Relaxed);\n        }\n    }\n    #[inline]\n    pub unsafe fn try_read(&self) -> bool {\n        let r = libc::pthread_rwlock_tryrdlock(self.inner.get());\n        if r == 0 {\n            if *self.write_locked.get() {\n                // `pthread_rwlock_tryrdlock` succeeded when it should not have.\n                self.raw_unlock();\n                false\n            } else {\n                self.num_readers.fetch_add(1, Ordering::Relaxed);\n                true\n            }\n        } else {\n            false\n        }\n    }\n    #[inline]\n    pub unsafe fn write(&self) {\n        let r = libc::pthread_rwlock_wrlock(self.inner.get());\n        // See comments above for why we check for EDEADLK and write_locked. For the same reason,\n        // we also need to check that there are no readers (tracked in `num_readers`).\n        if r == libc::EDEADLK\n            || (r == 0 && *self.write_locked.get())\n            || self.num_readers.load(Ordering::Relaxed) != 0\n        {\n            // Above, we make sure to only access `write_locked` when `r == 0` to avoid\n            // data races.\n            if r == 0 {\n                // `pthread_rwlock_wrlock` succeeded when it should not have.\n                self.raw_unlock();\n            }\n            panic!(\"rwlock write lock would result in deadlock\");\n        } else {\n            // According to POSIX, for a properly initialized rwlock this can only\n            // return EDEADLK or 0. We rely on that.\n            debug_assert_eq!(r, 0);\n        }\n        *self.write_locked.get() = true;\n    }\n    #[inline]\n    pub unsafe fn try_write(&self) -> bool {\n        let r = libc::pthread_rwlock_trywrlock(self.inner.get());\n        if r == 0 {\n            if *self.write_locked.get() || self.num_readers.load(Ordering::Relaxed) != 0 {\n                // `pthread_rwlock_trywrlock` succeeded when it should not have.\n                self.raw_unlock();\n                false\n            } else {\n                *self.write_locked.get() = true;\n                true\n            }\n        } else {\n            false\n        }\n    }\n    #[inline]\n    unsafe fn raw_unlock(&self) {\n        let r = libc::pthread_rwlock_unlock(self.inner.get());\n        debug_assert_eq!(r, 0);\n    }\n    #[inline]\n    pub unsafe fn read_unlock(&self) {\n        debug_assert!(!*self.write_locked.get());\n        self.num_readers.fetch_sub(1, Ordering::Relaxed);\n        self.raw_unlock();\n    }\n    #[inline]\n    pub unsafe fn write_unlock(&self) {\n        debug_assert_eq!(self.num_readers.load(Ordering::Relaxed), 0);\n        debug_assert!(*self.write_locked.get());\n        *self.write_locked.get() = false;\n        self.raw_unlock();\n    }\n    #[inline]\n    pub unsafe fn destroy(&self) {\n        let r = libc::pthread_rwlock_destroy(self.inner.get());\n        // On DragonFly pthread_rwlock_destroy() returns EINVAL if called on a\n        // rwlock that was just initialized with\n        // libc::PTHREAD_RWLOCK_INITIALIZER. Once it is used (locked/unlocked)\n        // or pthread_rwlock_init() is called, this behaviour no longer occurs.\n        if cfg!(target_os = \"dragonfly\") {\n            debug_assert!(r == 0 || r == libc::EINVAL);\n        } else {\n            debug_assert_eq!(r, 0);\n        }\n    }\n}\n"],[2343,"use crate::os::unix::prelude::*;\n\nuse crate::ffi::{CStr, CString, OsStr, OsString};\nuse crate::fmt;\nuse crate::io::{self, Error, IoSlice, IoSliceMut, SeekFrom};\nuse crate::mem;\nuse crate::path::{Path, PathBuf};\nuse crate::ptr;\nuse crate::sync::Arc;\nuse crate::sys::fd::FileDesc;\nuse crate::sys::time::SystemTime;\nuse crate::sys::{cvt, cvt_r};\nuse crate::sys_common::{AsInner, FromInner};\n\nuse libc::{c_int, mode_t};\n\n#[cfg(any(target_os = \"linux\", target_os = \"emscripten\", target_os = \"android\"))]\nuse libc::dirfd;\n#[cfg(any(target_os = \"linux\", target_os = \"emscripten\"))]\nuse libc::fstatat64;\n#[cfg(not(any(\n    target_os = \"linux\",\n    target_os = \"emscripten\",\n    target_os = \"solaris\",\n    target_os = \"illumos\",\n    target_os = \"l4re\",\n    target_os = \"fuchsia\",\n    target_os = \"redox\"\n)))]\nuse libc::readdir_r as readdir64_r;\n#[cfg(target_os = \"android\")]\nuse libc::{\n    dirent as dirent64, fstat as fstat64, fstatat as fstatat64, lseek64, lstat as lstat64,\n    open as open64, stat as stat64,\n};\n#[cfg(not(any(\n    target_os = \"linux\",\n    target_os = \"emscripten\",\n    target_os = \"l4re\",\n    target_os = \"android\"\n)))]\nuse libc::{\n    dirent as dirent64, fstat as fstat64, ftruncate as ftruncate64, lseek as lseek64,\n    lstat as lstat64, off_t as off64_t, open as open64, stat as stat64,\n};\n#[cfg(any(target_os = \"linux\", target_os = \"emscripten\", target_os = \"l4re\"))]\nuse libc::{\n    dirent64, fstat64, ftruncate64, lseek64, lstat64, off64_t, open64, readdir64_r, stat64,\n};\n\npub use crate::sys_common::fs::{remove_dir_all, try_exists};\n\npub struct File(FileDesc);\n\n// FIXME: This should be available on Linux with all `target_env`.\n// But currently only glibc exposes `statx` fn and structs.\n// We don't want to import unverified raw C structs here directly.\n// https://github.com/rust-lang/rust/pull/67774\nmacro_rules! cfg_has_statx {\n    ({ $($then_tt:tt)* } else { $($else_tt:tt)* }) => {\n        cfg_if::cfg_if! {\n            if #[cfg(all(target_os = \"linux\", target_env = \"gnu\"))] {\n                $($then_tt)*\n            } else {\n                $($else_tt)*\n            }\n        }\n    };\n    ($($block_inner:tt)*) => {\n        #[cfg(all(target_os = \"linux\", target_env = \"gnu\"))]\n        {\n            $($block_inner)*\n        }\n    };\n}\n\ncfg_has_statx! {{\n    #[derive(Clone)]\n    pub struct FileAttr {\n        stat: stat64,\n        statx_extra_fields: Option<StatxExtraFields>,\n    }\n\n    #[derive(Clone)]\n    struct StatxExtraFields {\n        // This is needed to check if btime is supported by the filesystem.\n        stx_mask: u32,\n        stx_btime: libc::statx_timestamp,\n    }\n\n    // We prefer `statx` on Linux if available, which contains file creation time.\n    // Default `stat64` contains no creation time.\n    unsafe fn try_statx(\n        fd: c_int,\n        path: *const libc::c_char,\n        flags: i32,\n        mask: u32,\n    ) -> Option<io::Result<FileAttr>> {\n        use crate::sync::atomic::{AtomicU8, Ordering};\n\n        // Linux kernel prior to 4.11 or glibc prior to glibc 2.28 don't support `statx`\n        // We store the availability in global to avoid unnecessary syscalls.\n        // 0: Unknown\n        // 1: Not available\n        // 2: Available\n        static STATX_STATE: AtomicU8 = AtomicU8::new(0);\n        syscall! {\n            fn statx(\n                fd: c_int,\n                pathname: *const libc::c_char,\n                flags: c_int,\n                mask: libc::c_uint,\n                statxbuf: *mut libc::statx\n            ) -> c_int\n        }\n\n        match STATX_STATE.load(Ordering::Relaxed) {\n            0 => {\n                // It is a trick to call `statx` with null pointers to check if the syscall\n                // is available. According to the manual, it is expected to fail with EFAULT.\n                // We do this mainly for performance, since it is nearly hundreds times\n                // faster than a normal successful call.\n                let err = cvt(statx(0, ptr::null(), 0, libc::STATX_ALL, ptr::null_mut()))\n                    .err()\n                    .and_then(|e| e.raw_os_error());\n                // We don't check `err == Some(libc::ENOSYS)` because the syscall may be limited\n                // and returns `EPERM`. Listing all possible errors seems not a good idea.\n                // See: https://github.com/rust-lang/rust/issues/65662\n                if err != Some(libc::EFAULT) {\n                    STATX_STATE.store(1, Ordering::Relaxed);\n                    return None;\n                }\n                STATX_STATE.store(2, Ordering::Relaxed);\n            }\n            1 => return None,\n            _ => {}\n        }\n\n        let mut buf: libc::statx = mem::zeroed();\n        if let Err(err) = cvt(statx(fd, path, flags, mask, &mut buf)) {\n            return Some(Err(err));\n        }\n\n        // We cannot fill `stat64` exhaustively because of private padding fields.\n        let mut stat: stat64 = mem::zeroed();\n        // `c_ulong` on gnu-mips, `dev_t` otherwise\n        stat.st_dev = libc::makedev(buf.stx_dev_major, buf.stx_dev_minor) as _;\n        stat.st_ino = buf.stx_ino as libc::ino64_t;\n        stat.st_nlink = buf.stx_nlink as libc::nlink_t;\n        stat.st_mode = buf.stx_mode as libc::mode_t;\n        stat.st_uid = buf.stx_uid as libc::uid_t;\n        stat.st_gid = buf.stx_gid as libc::gid_t;\n        stat.st_rdev = libc::makedev(buf.stx_rdev_major, buf.stx_rdev_minor) as _;\n        stat.st_size = buf.stx_size as off64_t;\n        stat.st_blksize = buf.stx_blksize as libc::blksize_t;\n        stat.st_blocks = buf.stx_blocks as libc::blkcnt64_t;\n        stat.st_atime = buf.stx_atime.tv_sec as libc::time_t;\n        // `i64` on gnu-x86_64-x32, `c_ulong` otherwise.\n        stat.st_atime_nsec = buf.stx_atime.tv_nsec as _;\n        stat.st_mtime = buf.stx_mtime.tv_sec as libc::time_t;\n        stat.st_mtime_nsec = buf.stx_mtime.tv_nsec as _;\n        stat.st_ctime = buf.stx_ctime.tv_sec as libc::time_t;\n        stat.st_ctime_nsec = buf.stx_ctime.tv_nsec as _;\n\n        let extra = StatxExtraFields {\n            stx_mask: buf.stx_mask,\n            stx_btime: buf.stx_btime,\n        };\n\n        Some(Ok(FileAttr { stat, statx_extra_fields: Some(extra) }))\n    }\n\n} else {\n    #[derive(Clone)]\n    pub struct FileAttr {\n        stat: stat64,\n    }\n}}\n\n// all DirEntry's will have a reference to this struct\nstruct InnerReadDir {\n    dirp: Dir,\n    root: PathBuf,\n}\n\npub struct ReadDir {\n    inner: Arc<InnerReadDir>,\n    #[cfg(not(any(\n        target_os = \"solaris\",\n        target_os = \"illumos\",\n        target_os = \"fuchsia\",\n        target_os = \"redox\",\n    )))]\n    end_of_stream: bool,\n}\n\nstruct Dir(*mut libc::DIR);\n\nunsafe impl Send for Dir {}\nunsafe impl Sync for Dir {}\n\npub struct DirEntry {\n    entry: dirent64,\n    dir: Arc<InnerReadDir>,\n    // We need to store an owned copy of the entry name\n    // on Solaris and Fuchsia because a) it uses a zero-length\n    // array to store the name, b) its lifetime between readdir\n    // calls is not guaranteed.\n    #[cfg(any(\n        target_os = \"solaris\",\n        target_os = \"illumos\",\n        target_os = \"fuchsia\",\n        target_os = \"redox\"\n    ))]\n    name: Box<[u8]>,\n}\n\n#[derive(Clone, Debug)]\npub struct OpenOptions {\n    // generic\n    read: bool,\n    write: bool,\n    append: bool,\n    truncate: bool,\n    create: bool,\n    create_new: bool,\n    // system-specific\n    custom_flags: i32,\n    mode: mode_t,\n}\n\n#[derive(Clone, PartialEq, Eq, Debug)]\npub struct FilePermissions {\n    mode: mode_t,\n}\n\n#[derive(Copy, Clone, PartialEq, Eq, Hash, Debug)]\npub struct FileType {\n    mode: mode_t,\n}\n\n#[derive(Debug)]\npub struct DirBuilder {\n    mode: mode_t,\n}\n\ncfg_has_statx! {{\n    impl FileAttr {\n        fn from_stat64(stat: stat64) -> Self {\n            Self { stat, statx_extra_fields: None }\n        }\n    }\n} else {\n    impl FileAttr {\n        fn from_stat64(stat: stat64) -> Self {\n            Self { stat }\n        }\n    }\n}}\n\nimpl FileAttr {\n    pub fn size(&self) -> u64 {\n        self.stat.st_size as u64\n    }\n    pub fn perm(&self) -> FilePermissions {\n        FilePermissions { mode: (self.stat.st_mode as mode_t) }\n    }\n\n    pub fn file_type(&self) -> FileType {\n        FileType { mode: self.stat.st_mode as mode_t }\n    }\n}\n\n#[cfg(target_os = \"netbsd\")]\nimpl FileAttr {\n    pub fn modified(&self) -> io::Result<SystemTime> {\n        Ok(SystemTime::from(libc::timespec {\n            tv_sec: self.stat.st_mtime as libc::time_t,\n            tv_nsec: self.stat.st_mtimensec as libc::c_long,\n        }))\n    }\n\n    pub fn accessed(&self) -> io::Result<SystemTime> {\n        Ok(SystemTime::from(libc::timespec {\n            tv_sec: self.stat.st_atime as libc::time_t,\n            tv_nsec: self.stat.st_atimensec as libc::c_long,\n        }))\n    }\n\n    pub fn created(&self) -> io::Result<SystemTime> {\n        Ok(SystemTime::from(libc::timespec {\n            tv_sec: self.stat.st_birthtime as libc::time_t,\n            tv_nsec: self.stat.st_birthtimensec as libc::c_long,\n        }))\n    }\n}\n\n#[cfg(not(target_os = \"netbsd\"))]\nimpl FileAttr {\n    #[cfg(not(target_os = \"vxworks\"))]\n    pub fn modified(&self) -> io::Result<SystemTime> {\n        Ok(SystemTime::from(libc::timespec {\n            tv_sec: self.stat.st_mtime as libc::time_t,\n            tv_nsec: self.stat.st_mtime_nsec as _,\n        }))\n    }\n\n    #[cfg(target_os = \"vxworks\")]\n    pub fn modified(&self) -> io::Result<SystemTime> {\n        Ok(SystemTime::from(libc::timespec {\n            tv_sec: self.stat.st_mtime as libc::time_t,\n            tv_nsec: 0,\n        }))\n    }\n\n    #[cfg(not(target_os = \"vxworks\"))]\n    pub fn accessed(&self) -> io::Result<SystemTime> {\n        Ok(SystemTime::from(libc::timespec {\n            tv_sec: self.stat.st_atime as libc::time_t,\n            tv_nsec: self.stat.st_atime_nsec as _,\n        }))\n    }\n\n    #[cfg(target_os = \"vxworks\")]\n    pub fn accessed(&self) -> io::Result<SystemTime> {\n        Ok(SystemTime::from(libc::timespec {\n            tv_sec: self.stat.st_atime as libc::time_t,\n            tv_nsec: 0,\n        }))\n    }\n\n    #[cfg(any(\n        target_os = \"freebsd\",\n        target_os = \"openbsd\",\n        target_os = \"macos\",\n        target_os = \"ios\"\n    ))]\n    pub fn created(&self) -> io::Result<SystemTime> {\n        Ok(SystemTime::from(libc::timespec {\n            tv_sec: self.stat.st_birthtime as libc::time_t,\n            tv_nsec: self.stat.st_birthtime_nsec as libc::c_long,\n        }))\n    }\n\n    #[cfg(not(any(\n        target_os = \"freebsd\",\n        target_os = \"openbsd\",\n        target_os = \"macos\",\n        target_os = \"ios\"\n    )))]\n    pub fn created(&self) -> io::Result<SystemTime> {\n        cfg_has_statx! {\n            if let Some(ext) = &self.statx_extra_fields {\n                return if (ext.stx_mask & libc::STATX_BTIME) != 0 {\n                    Ok(SystemTime::from(libc::timespec {\n                        tv_sec: ext.stx_btime.tv_sec as libc::time_t,\n                        tv_nsec: ext.stx_btime.tv_nsec as _,\n                    }))\n                } else {\n                    Err(io::Error::new_const(\n                        io::ErrorKind::Other,\n                        &\"creation time is not available for the filesystem\",\n                    ))\n                };\n            }\n        }\n\n        Err(io::Error::new_const(\n            io::ErrorKind::Unsupported,\n            &\"creation time is not available on this platform \\\n                            currently\",\n        ))\n    }\n}\n\nimpl AsInner<stat64> for FileAttr {\n    fn as_inner(&self) -> &stat64 {\n        &self.stat\n    }\n}\n\nimpl FilePermissions {\n    pub fn readonly(&self) -> bool {\n        // check if any class (owner, group, others) has write permission\n        self.mode & 0o222 == 0\n    }\n\n    pub fn set_readonly(&mut self, readonly: bool) {\n        if readonly {\n            // remove write permission for all classes; equivalent to `chmod a-w <file>`\n            self.mode &= !0o222;\n        } else {\n            // add write permission for all classes; equivalent to `chmod a+w <file>`\n            self.mode |= 0o222;\n        }\n    }\n    pub fn mode(&self) -> u32 {\n        self.mode as u32\n    }\n}\n\nimpl FileType {\n    pub fn is_dir(&self) -> bool {\n        self.is(libc::S_IFDIR)\n    }\n    pub fn is_file(&self) -> bool {\n        self.is(libc::S_IFREG)\n    }\n    pub fn is_symlink(&self) -> bool {\n        self.is(libc::S_IFLNK)\n    }\n\n    pub fn is(&self, mode: mode_t) -> bool {\n        self.mode & libc::S_IFMT == mode\n    }\n}\n\nimpl FromInner<u32> for FilePermissions {\n    fn from_inner(mode: u32) -> FilePermissions {\n        FilePermissions { mode: mode as mode_t }\n    }\n}\n\nimpl fmt::Debug for ReadDir {\n    fn fmt(&self, f: &mut fmt::Formatter<'_>) -> fmt::Result {\n        // This will only be called from std::fs::ReadDir, which will add a \"ReadDir()\" frame.\n        // Thus the result will be e g 'ReadDir(\"/home\")'\n        fmt::Debug::fmt(&*self.inner.root, f)\n    }\n}\n\nimpl Iterator for ReadDir {\n    type Item = io::Result<DirEntry>;\n\n    #[cfg(any(\n        target_os = \"solaris\",\n        target_os = \"fuchsia\",\n        target_os = \"redox\",\n        target_os = \"illumos\"\n    ))]\n    fn next(&mut self) -> Option<io::Result<DirEntry>> {\n        use crate::slice;\n\n        unsafe {\n            loop {\n                // Although readdir_r(3) would be a correct function to use here because\n                // of the thread safety, on Illumos and Fuchsia the readdir(3C) function\n                // is safe to use in threaded applications and it is generally preferred\n                // over the readdir_r(3C) function.\n                super::os::set_errno(0);\n                let entry_ptr = libc::readdir(self.inner.dirp.0);\n                if entry_ptr.is_null() {\n                    // null can mean either the end is reached or an error occurred.\n                    // So we had to clear errno beforehand to check for an error now.\n                    return match super::os::errno() {\n                        0 => None,\n                        e => Some(Err(Error::from_raw_os_error(e))),\n                    };\n                }\n\n                let name = (*entry_ptr).d_name.as_ptr();\n                let namelen = libc::strlen(name) as usize;\n\n                let ret = DirEntry {\n                    entry: *entry_ptr,\n                    name: slice::from_raw_parts(name as *const u8, namelen as usize)\n                        .to_owned()\n                        .into_boxed_slice(),\n                    dir: Arc::clone(&self.inner),\n                };\n                if ret.name_bytes() != b\".\" && ret.name_bytes() != b\"..\" {\n                    return Some(Ok(ret));\n                }\n            }\n        }\n    }\n\n    #[cfg(not(any(\n        target_os = \"solaris\",\n        target_os = \"fuchsia\",\n        target_os = \"redox\",\n        target_os = \"illumos\"\n    )))]\n    fn next(&mut self) -> Option<io::Result<DirEntry>> {\n        if self.end_of_stream {\n            return None;\n        }\n\n        unsafe {\n            let mut ret = DirEntry { entry: mem::zeroed(), dir: Arc::clone(&self.inner) };\n            let mut entry_ptr = ptr::null_mut();\n            loop {\n                if readdir64_r(self.inner.dirp.0, &mut ret.entry, &mut entry_ptr) != 0 {\n                    if entry_ptr.is_null() {\n                        // We encountered an error (which will be returned in this iteration), but\n                        // we also reached the end of the directory stream. The `end_of_stream`\n                        // flag is enabled to make sure that we return `None` in the next iteration\n                        // (instead of looping forever)\n                        self.end_of_stream = true;\n                    }\n                    return Some(Err(Error::last_os_error()));\n                }\n                if entry_ptr.is_null() {\n                    return None;\n                }\n                if ret.name_bytes() != b\".\" && ret.name_bytes() != b\"..\" {\n                    return Some(Ok(ret));\n                }\n            }\n        }\n    }\n}\n\nimpl Drop for Dir {\n    fn drop(&mut self) {\n        let r = unsafe { libc::closedir(self.0) };\n        debug_assert_eq!(r, 0);\n    }\n}\n\nimpl DirEntry {\n    pub fn path(&self) -> PathBuf {\n        self.dir.root.join(OsStr::from_bytes(self.name_bytes()))\n    }\n\n    pub fn file_name(&self) -> OsString {\n        OsStr::from_bytes(self.name_bytes()).to_os_string()\n    }\n\n    #[cfg(any(target_os = \"linux\", target_os = \"emscripten\", target_os = \"android\"))]\n    pub fn metadata(&self) -> io::Result<FileAttr> {\n        let fd = cvt(unsafe { dirfd(self.dir.dirp.0) })?;\n        let name = self.entry.d_name.as_ptr();\n\n        cfg_has_statx! {\n            if let Some(ret) = unsafe { try_statx(\n                fd,\n                name,\n                libc::AT_SYMLINK_NOFOLLOW | libc::AT_STATX_SYNC_AS_STAT,\n                libc::STATX_ALL,\n            ) } {\n                return ret;\n            }\n        }\n\n        let mut stat: stat64 = unsafe { mem::zeroed() };\n        cvt(unsafe { fstatat64(fd, name, &mut stat, libc::AT_SYMLINK_NOFOLLOW) })?;\n        Ok(FileAttr::from_stat64(stat))\n    }\n\n    #[cfg(not(any(target_os = \"linux\", target_os = \"emscripten\", target_os = \"android\")))]\n    pub fn metadata(&self) -> io::Result<FileAttr> {\n        lstat(&self.path())\n    }\n\n    #[cfg(any(\n        target_os = \"solaris\",\n        target_os = \"illumos\",\n        target_os = \"haiku\",\n        target_os = \"vxworks\"\n    ))]\n    pub fn file_type(&self) -> io::Result<FileType> {\n        lstat(&self.path()).map(|m| m.file_type())\n    }\n\n    #[cfg(not(any(\n        target_os = \"solaris\",\n        target_os = \"illumos\",\n        target_os = \"haiku\",\n        target_os = \"vxworks\"\n    )))]\n    pub fn file_type(&self) -> io::Result<FileType> {\n        match self.entry.d_type {\n            libc::DT_CHR => Ok(FileType { mode: libc::S_IFCHR }),\n            libc::DT_FIFO => Ok(FileType { mode: libc::S_IFIFO }),\n            libc::DT_LNK => Ok(FileType { mode: libc::S_IFLNK }),\n            libc::DT_REG => Ok(FileType { mode: libc::S_IFREG }),\n            libc::DT_SOCK => Ok(FileType { mode: libc::S_IFSOCK }),\n            libc::DT_DIR => Ok(FileType { mode: libc::S_IFDIR }),\n            libc::DT_BLK => Ok(FileType { mode: libc::S_IFBLK }),\n            _ => lstat(&self.path()).map(|m| m.file_type()),\n        }\n    }\n\n    #[cfg(any(\n        target_os = \"macos\",\n        target_os = \"ios\",\n        target_os = \"linux\",\n        target_os = \"emscripten\",\n        target_os = \"android\",\n        target_os = \"solaris\",\n        target_os = \"illumos\",\n        target_os = \"haiku\",\n        target_os = \"l4re\",\n        target_os = \"fuchsia\",\n        target_os = \"redox\",\n        target_os = \"vxworks\"\n    ))]\n    pub fn ino(&self) -> u64 {\n        self.entry.d_ino as u64\n    }\n\n    #[cfg(any(\n        target_os = \"freebsd\",\n        target_os = \"openbsd\",\n        target_os = \"netbsd\",\n        target_os = \"dragonfly\"\n    ))]\n    pub fn ino(&self) -> u64 {\n        self.entry.d_fileno as u64\n    }\n\n    #[cfg(any(\n        target_os = \"macos\",\n        target_os = \"ios\",\n        target_os = \"netbsd\",\n        target_os = \"openbsd\",\n        target_os = \"freebsd\",\n        target_os = \"dragonfly\"\n    ))]\n    fn name_bytes(&self) -> &[u8] {\n        use crate::slice;\n        unsafe {\n            slice::from_raw_parts(\n                self.entry.d_name.as_ptr() as *const u8,\n                self.entry.d_namlen as usize,\n            )\n        }\n    }\n    #[cfg(any(\n        target_os = \"android\",\n        target_os = \"linux\",\n        target_os = \"emscripten\",\n        target_os = \"l4re\",\n        target_os = \"haiku\",\n        target_os = \"vxworks\"\n    ))]\n    fn name_bytes(&self) -> &[u8] {\n        unsafe { CStr::from_ptr(self.entry.d_name.as_ptr()).to_bytes() }\n    }\n    #[cfg(any(\n        target_os = \"solaris\",\n        target_os = \"illumos\",\n        target_os = \"fuchsia\",\n        target_os = \"redox\"\n    ))]\n    fn name_bytes(&self) -> &[u8] {\n        &*self.name\n    }\n}\n\nimpl OpenOptions {\n    pub fn new() -> OpenOptions {\n        OpenOptions {\n            // generic\n            read: false,\n            write: false,\n            append: false,\n            truncate: false,\n            create: false,\n            create_new: false,\n            // system-specific\n            custom_flags: 0,\n            mode: 0o666,\n        }\n    }\n\n    pub fn read(&mut self, read: bool) {\n        self.read = read;\n    }\n    pub fn write(&mut self, write: bool) {\n        self.write = write;\n    }\n    pub fn append(&mut self, append: bool) {\n        self.append = append;\n    }\n    pub fn truncate(&mut self, truncate: bool) {\n        self.truncate = truncate;\n    }\n    pub fn create(&mut self, create: bool) {\n        self.create = create;\n    }\n    pub fn create_new(&mut self, create_new: bool) {\n        self.create_new = create_new;\n    }\n\n    pub fn custom_flags(&mut self, flags: i32) {\n        self.custom_flags = flags;\n    }\n    pub fn mode(&mut self, mode: u32) {\n        self.mode = mode as mode_t;\n    }\n\n    fn get_access_mode(&self) -> io::Result<c_int> {\n        match (self.read, self.write, self.append) {\n            (true, false, false) => Ok(libc::O_RDONLY),\n            (false, true, false) => Ok(libc::O_WRONLY),\n            (true, true, false) => Ok(libc::O_RDWR),\n            (false, _, true) => Ok(libc::O_WRONLY | libc::O_APPEND),\n            (true, _, true) => Ok(libc::O_RDWR | libc::O_APPEND),\n            (false, false, false) => Err(Error::from_raw_os_error(libc::EINVAL)),\n        }\n    }\n\n    fn get_creation_mode(&self) -> io::Result<c_int> {\n        match (self.write, self.append) {\n            (true, false) => {}\n            (false, false) => {\n                if self.truncate || self.create || self.create_new {\n                    return Err(Error::from_raw_os_error(libc::EINVAL));\n                }\n            }\n            (_, true) => {\n                if self.truncate && !self.create_new {\n                    return Err(Error::from_raw_os_error(libc::EINVAL));\n                }\n            }\n        }\n\n        Ok(match (self.create, self.truncate, self.create_new) {\n            (false, false, false) => 0,\n            (true, false, false) => libc::O_CREAT,\n            (false, true, false) => libc::O_TRUNC,\n            (true, true, false) => libc::O_CREAT | libc::O_TRUNC,\n            (_, _, true) => libc::O_CREAT | libc::O_EXCL,\n        })\n    }\n}\n\nimpl File {\n    pub fn open(path: &Path, opts: &OpenOptions) -> io::Result<File> {\n        let path = cstr(path)?;\n        File::open_c(&path, opts)\n    }\n\n    pub fn open_c(path: &CStr, opts: &OpenOptions) -> io::Result<File> {\n        let flags = libc::O_CLOEXEC\n            | opts.get_access_mode()?\n            | opts.get_creation_mode()?\n            | (opts.custom_flags as c_int & !libc::O_ACCMODE);\n        // The third argument of `open64` is documented to have type `mode_t`. On\n        // some platforms (like macOS, where `open64` is actually `open`), `mode_t` is `u16`.\n        // However, since this is a variadic function, C integer promotion rules mean that on\n        // the ABI level, this still gets passed as `c_int` (aka `u32` on Unix platforms).\n        let fd = cvt_r(|| unsafe { open64(path.as_ptr(), flags, opts.mode as c_int) })?;\n        Ok(File(FileDesc::new(fd)))\n    }\n\n    pub fn file_attr(&self) -> io::Result<FileAttr> {\n        let fd = self.0.raw();\n\n        cfg_has_statx! {\n            if let Some(ret) = unsafe { try_statx(\n                fd,\n                b\"\\0\" as *const _ as *const libc::c_char,\n                libc::AT_EMPTY_PATH | libc::AT_STATX_SYNC_AS_STAT,\n                libc::STATX_ALL,\n            ) } {\n                return ret;\n            }\n        }\n\n        let mut stat: stat64 = unsafe { mem::zeroed() };\n        cvt(unsafe { fstat64(fd, &mut stat) })?;\n        Ok(FileAttr::from_stat64(stat))\n    }\n\n    pub fn fsync(&self) -> io::Result<()> {\n        cvt_r(|| unsafe { os_fsync(self.0.raw()) })?;\n        return Ok(());\n\n        #[cfg(any(target_os = \"macos\", target_os = \"ios\"))]\n        unsafe fn os_fsync(fd: c_int) -> c_int {\n            libc::fcntl(fd, libc::F_FULLFSYNC)\n        }\n        #[cfg(not(any(target_os = \"macos\", target_os = \"ios\")))]\n        unsafe fn os_fsync(fd: c_int) -> c_int {\n            libc::fsync(fd)\n        }\n    }\n\n    pub fn datasync(&self) -> io::Result<()> {\n        cvt_r(|| unsafe { os_datasync(self.0.raw()) })?;\n        return Ok(());\n\n        #[cfg(any(target_os = \"macos\", target_os = \"ios\"))]\n        unsafe fn os_datasync(fd: c_int) -> c_int {\n            libc::fcntl(fd, libc::F_FULLFSYNC)\n        }\n        #[cfg(any(\n            target_os = \"freebsd\",\n            target_os = \"linux\",\n            target_os = \"android\",\n            target_os = \"netbsd\",\n            target_os = \"openbsd\"\n        ))]\n        unsafe fn os_datasync(fd: c_int) -> c_int {\n            libc::fdatasync(fd)\n        }\n        #[cfg(not(any(\n            target_os = \"android\",\n            target_os = \"freebsd\",\n            target_os = \"ios\",\n            target_os = \"linux\",\n            target_os = \"macos\",\n            target_os = \"netbsd\",\n            target_os = \"openbsd\"\n        )))]\n        unsafe fn os_datasync(fd: c_int) -> c_int {\n            libc::fsync(fd)\n        }\n    }\n\n    pub fn truncate(&self, size: u64) -> io::Result<()> {\n        #[cfg(target_os = \"android\")]\n        return crate::sys::android::ftruncate64(self.0.raw(), size);\n\n        #[cfg(not(target_os = \"android\"))]\n        {\n            use crate::convert::TryInto;\n            let size: off64_t =\n                size.try_into().map_err(|e| io::Error::new(io::ErrorKind::InvalidInput, e))?;\n            cvt_r(|| unsafe { ftruncate64(self.0.raw(), size) }).map(drop)\n        }\n    }\n\n    pub fn read(&self, buf: &mut [u8]) -> io::Result<usize> {\n        self.0.read(buf)\n    }\n\n    pub fn read_vectored(&self, bufs: &mut [IoSliceMut<'_>]) -> io::Result<usize> {\n        self.0.read_vectored(bufs)\n    }\n\n    #[inline]\n    pub fn is_read_vectored(&self) -> bool {\n        self.0.is_read_vectored()\n    }\n\n    pub fn read_at(&self, buf: &mut [u8], offset: u64) -> io::Result<usize> {\n        self.0.read_at(buf, offset)\n    }\n\n    pub fn write(&self, buf: &[u8]) -> io::Result<usize> {\n        self.0.write(buf)\n    }\n\n    pub fn write_vectored(&self, bufs: &[IoSlice<'_>]) -> io::Result<usize> {\n        self.0.write_vectored(bufs)\n    }\n\n    #[inline]\n    pub fn is_write_vectored(&self) -> bool {\n        self.0.is_write_vectored()\n    }\n\n    pub fn write_at(&self, buf: &[u8], offset: u64) -> io::Result<usize> {\n        self.0.write_at(buf, offset)\n    }\n\n    pub fn flush(&self) -> io::Result<()> {\n        Ok(())\n    }\n\n    pub fn seek(&self, pos: SeekFrom) -> io::Result<u64> {\n        let (whence, pos) = match pos {\n            // Casting to `i64` is fine, too large values will end up as\n            // negative which will cause an error in `lseek64`.\n            SeekFrom::Start(off) => (libc::SEEK_SET, off as i64),\n            SeekFrom::End(off) => (libc::SEEK_END, off),\n            SeekFrom::Current(off) => (libc::SEEK_CUR, off),\n        };\n        let n = cvt(unsafe { lseek64(self.0.raw(), pos, whence) })?;\n        Ok(n as u64)\n    }\n\n    pub fn duplicate(&self) -> io::Result<File> {\n        self.0.duplicate().map(File)\n    }\n\n    pub fn fd(&self) -> &FileDesc {\n        &self.0\n    }\n\n    pub fn into_fd(self) -> FileDesc {\n        self.0\n    }\n\n    pub fn set_permissions(&self, perm: FilePermissions) -> io::Result<()> {\n        cvt_r(|| unsafe { libc::fchmod(self.0.raw(), perm.mode) })?;\n        Ok(())\n    }\n}\n\nimpl DirBuilder {\n    pub fn new() -> DirBuilder {\n        DirBuilder { mode: 0o777 }\n    }\n\n    pub fn mkdir(&self, p: &Path) -> io::Result<()> {\n        let p = cstr(p)?;\n        cvt(unsafe { libc::mkdir(p.as_ptr(), self.mode) })?;\n        Ok(())\n    }\n\n    pub fn set_mode(&mut self, mode: u32) {\n        self.mode = mode as mode_t;\n    }\n}\n\nfn cstr(path: &Path) -> io::Result<CString> {\n    Ok(CString::new(path.as_os_str().as_bytes())?)\n}\n\nimpl FromInner<c_int> for File {\n    fn from_inner(fd: c_int) -> File {\n        File(FileDesc::new(fd))\n    }\n}\n\nimpl fmt::Debug for File {\n    fn fmt(&self, f: &mut fmt::Formatter<'_>) -> fmt::Result {\n        #[cfg(target_os = \"linux\")]\n        fn get_path(fd: c_int) -> Option<PathBuf> {\n            let mut p = PathBuf::from(\"/proc/self/fd\");\n            p.push(&fd.to_string());\n            readlink(&p).ok()\n        }\n\n        #[cfg(target_os = \"macos\")]\n        fn get_path(fd: c_int) -> Option<PathBuf> {\n            // FIXME: The use of PATH_MAX is generally not encouraged, but it\n            // is inevitable in this case because macOS defines `fcntl` with\n            // `F_GETPATH` in terms of `MAXPATHLEN`, and there are no\n            // alternatives. If a better method is invented, it should be used\n            // instead.\n            let mut buf = vec![0; libc::PATH_MAX as usize];\n            let n = unsafe { libc::fcntl(fd, libc::F_GETPATH, buf.as_ptr()) };\n            if n == -1 {\n                return None;\n            }\n            let l = buf.iter().position(|&c| c == 0).unwrap();\n            buf.truncate(l as usize);\n            buf.shrink_to_fit();\n            Some(PathBuf::from(OsString::from_vec(buf)))\n        }\n\n        #[cfg(target_os = \"vxworks\")]\n        fn get_path(fd: c_int) -> Option<PathBuf> {\n            let mut buf = vec![0; libc::PATH_MAX as usize];\n            let n = unsafe { libc::ioctl(fd, libc::FIOGETNAME, buf.as_ptr()) };\n            if n == -1 {\n                return None;\n            }\n            let l = buf.iter().position(|&c| c == 0).unwrap();\n            buf.truncate(l as usize);\n            Some(PathBuf::from(OsString::from_vec(buf)))\n        }\n\n        #[cfg(not(any(target_os = \"linux\", target_os = \"macos\", target_os = \"vxworks\")))]\n        fn get_path(_fd: c_int) -> Option<PathBuf> {\n            // FIXME(#24570): implement this for other Unix platforms\n            None\n        }\n\n        #[cfg(any(target_os = \"linux\", target_os = \"macos\", target_os = \"vxworks\"))]\n        fn get_mode(fd: c_int) -> Option<(bool, bool)> {\n            let mode = unsafe { libc::fcntl(fd, libc::F_GETFL) };\n            if mode == -1 {\n                return None;\n            }\n            match mode & libc::O_ACCMODE {\n                libc::O_RDONLY => Some((true, false)),\n                libc::O_RDWR => Some((true, true)),\n                libc::O_WRONLY => Some((false, true)),\n                _ => None,\n            }\n        }\n\n        #[cfg(not(any(target_os = \"linux\", target_os = \"macos\", target_os = \"vxworks\")))]\n        fn get_mode(_fd: c_int) -> Option<(bool, bool)> {\n            // FIXME(#24570): implement this for other Unix platforms\n            None\n        }\n\n        let fd = self.0.raw();\n        let mut b = f.debug_struct(\"File\");\n        b.field(\"fd\", &fd);\n        if let Some(path) = get_path(fd) {\n            b.field(\"path\", &path);\n        }\n        if let Some((read, write)) = get_mode(fd) {\n            b.field(\"read\", &read).field(\"write\", &write);\n        }\n        b.finish()\n    }\n}\n\npub fn readdir(p: &Path) -> io::Result<ReadDir> {\n    let root = p.to_path_buf();\n    let p = cstr(p)?;\n    unsafe {\n        let ptr = libc::opendir(p.as_ptr());\n        if ptr.is_null() {\n            Err(Error::last_os_error())\n        } else {\n            let inner = InnerReadDir { dirp: Dir(ptr), root };\n            Ok(ReadDir {\n                inner: Arc::new(inner),\n                #[cfg(not(any(\n                    target_os = \"solaris\",\n                    target_os = \"illumos\",\n                    target_os = \"fuchsia\",\n                    target_os = \"redox\",\n                )))]\n                end_of_stream: false,\n            })\n        }\n    }\n}\n\npub fn unlink(p: &Path) -> io::Result<()> {\n    let p = cstr(p)?;\n    cvt(unsafe { libc::unlink(p.as_ptr()) })?;\n    Ok(())\n}\n\npub fn rename(old: &Path, new: &Path) -> io::Result<()> {\n    let old = cstr(old)?;\n    let new = cstr(new)?;\n    cvt(unsafe { libc::rename(old.as_ptr(), new.as_ptr()) })?;\n    Ok(())\n}\n\npub fn set_perm(p: &Path, perm: FilePermissions) -> io::Result<()> {\n    let p = cstr(p)?;\n    cvt_r(|| unsafe { libc::chmod(p.as_ptr(), perm.mode) })?;\n    Ok(())\n}\n\npub fn rmdir(p: &Path) -> io::Result<()> {\n    let p = cstr(p)?;\n    cvt(unsafe { libc::rmdir(p.as_ptr()) })?;\n    Ok(())\n}\n\npub fn readlink(p: &Path) -> io::Result<PathBuf> {\n    let c_path = cstr(p)?;\n    let p = c_path.as_ptr();\n\n    let mut buf = Vec::with_capacity(256);\n\n    loop {\n        let buf_read =\n            cvt(unsafe { libc::readlink(p, buf.as_mut_ptr() as *mut _, buf.capacity()) })? as usize;\n\n        unsafe {\n            buf.set_len(buf_read);\n        }\n\n        if buf_read != buf.capacity() {\n            buf.shrink_to_fit();\n\n            return Ok(PathBuf::from(OsString::from_vec(buf)));\n        }\n\n        // Trigger the internal buffer resizing logic of `Vec` by requiring\n        // more space than the current capacity. The length is guaranteed to be\n        // the same as the capacity due to the if statement above.\n        buf.reserve(1);\n    }\n}\n\npub fn symlink(original: &Path, link: &Path) -> io::Result<()> {\n    let original = cstr(original)?;\n    let link = cstr(link)?;\n    cvt(unsafe { libc::symlink(original.as_ptr(), link.as_ptr()) })?;\n    Ok(())\n}\n\npub fn link(original: &Path, link: &Path) -> io::Result<()> {\n    let original = cstr(original)?;\n    let link = cstr(link)?;\n    cfg_if::cfg_if! {\n        if #[cfg(any(target_os = \"vxworks\", target_os = \"redox\", target_os = \"android\"))] {\n            // VxWorks, Redox, and old versions of Android lack `linkat`, so use\n            // `link` instead. POSIX leaves it implementation-defined whether\n            // `link` follows symlinks, so rely on the `symlink_hard_link` test\n            // in library/std/src/fs/tests.rs to check the behavior.\n            cvt(unsafe { libc::link(original.as_ptr(), link.as_ptr()) })?;\n        } else {\n            // Use `linkat` with `AT_FDCWD` instead of `link` as `linkat` gives\n            // us a flag to specify how symlinks should be handled. Pass 0 as\n            // the flags argument, meaning don't follow symlinks.\n            cvt(unsafe { libc::linkat(libc::AT_FDCWD, original.as_ptr(), libc::AT_FDCWD, link.as_ptr(), 0) })?;\n        }\n    }\n    Ok(())\n}\n\npub fn stat(p: &Path) -> io::Result<FileAttr> {\n    let p = cstr(p)?;\n\n    cfg_has_statx! {\n        if let Some(ret) = unsafe { try_statx(\n            libc::AT_FDCWD,\n            p.as_ptr(),\n            libc::AT_STATX_SYNC_AS_STAT,\n            libc::STATX_ALL,\n        ) } {\n            return ret;\n        }\n    }\n\n    let mut stat: stat64 = unsafe { mem::zeroed() };\n    cvt(unsafe { stat64(p.as_ptr(), &mut stat) })?;\n    Ok(FileAttr::from_stat64(stat))\n}\n\npub fn lstat(p: &Path) -> io::Result<FileAttr> {\n    let p = cstr(p)?;\n\n    cfg_has_statx! {\n        if let Some(ret) = unsafe { try_statx(\n            libc::AT_FDCWD,\n            p.as_ptr(),\n            libc::AT_SYMLINK_NOFOLLOW | libc::AT_STATX_SYNC_AS_STAT,\n            libc::STATX_ALL,\n        ) } {\n            return ret;\n        }\n    }\n\n    let mut stat: stat64 = unsafe { mem::zeroed() };\n    cvt(unsafe { lstat64(p.as_ptr(), &mut stat) })?;\n    Ok(FileAttr::from_stat64(stat))\n}\n\npub fn canonicalize(p: &Path) -> io::Result<PathBuf> {\n    let path = CString::new(p.as_os_str().as_bytes())?;\n    let buf;\n    unsafe {\n        let r = libc::realpath(path.as_ptr(), ptr::null_mut());\n        if r.is_null() {\n            return Err(io::Error::last_os_error());\n        }\n        buf = CStr::from_ptr(r).to_bytes().to_vec();\n        libc::free(r as *mut _);\n    }\n    Ok(PathBuf::from(OsString::from_vec(buf)))\n}\n\nfn open_from(from: &Path) -> io::Result<(crate::fs::File, crate::fs::Metadata)> {\n    use crate::fs::File;\n    use crate::sys_common::fs::NOT_FILE_ERROR;\n\n    let reader = File::open(from)?;\n    let metadata = reader.metadata()?;\n    if !metadata.is_file() {\n        return Err(NOT_FILE_ERROR);\n    }\n    Ok((reader, metadata))\n}\n\nfn open_to_and_set_permissions(\n    to: &Path,\n    reader_metadata: crate::fs::Metadata,\n) -> io::Result<(crate::fs::File, crate::fs::Metadata)> {\n    use crate::fs::OpenOptions;\n    use crate::os::unix::fs::{OpenOptionsExt, PermissionsExt};\n\n    let perm = reader_metadata.permissions();\n    let writer = OpenOptions::new()\n        // create the file with the correct mode right away\n        .mode(perm.mode())\n        .write(true)\n        .create(true)\n        .truncate(true)\n        .open(to)?;\n    let writer_metadata = writer.metadata()?;\n    if writer_metadata.is_file() {\n        // Set the correct file permissions, in case the file already existed.\n        // Don't set the permissions on already existing non-files like\n        // pipes/FIFOs or device nodes.\n        writer.set_permissions(perm)?;\n    }\n    Ok((writer, writer_metadata))\n}\n\n#[cfg(not(any(\n    target_os = \"linux\",\n    target_os = \"android\",\n    target_os = \"macos\",\n    target_os = \"ios\"\n)))]\npub fn copy(from: &Path, to: &Path) -> io::Result<u64> {\n    let (mut reader, reader_metadata) = open_from(from)?;\n    let (mut writer, _) = open_to_and_set_permissions(to, reader_metadata)?;\n\n    io::copy(&mut reader, &mut writer)\n}\n\n#[cfg(any(target_os = \"linux\", target_os = \"android\"))]\npub fn copy(from: &Path, to: &Path) -> io::Result<u64> {\n    let (mut reader, reader_metadata) = open_from(from)?;\n    let max_len = u64::MAX;\n    let (mut writer, _) = open_to_and_set_permissions(to, reader_metadata)?;\n\n    use super::kernel_copy::{copy_regular_files, CopyResult};\n\n    match copy_regular_files(reader.as_raw_fd(), writer.as_raw_fd(), max_len) {\n        CopyResult::Ended(bytes) => Ok(bytes),\n        CopyResult::Error(e, _) => Err(e),\n        CopyResult::Fallback(written) => match io::copy::generic_copy(&mut reader, &mut writer) {\n            Ok(bytes) => Ok(bytes + written),\n            Err(e) => Err(e),\n        },\n    }\n}\n\n#[cfg(any(target_os = \"macos\", target_os = \"ios\"))]\npub fn copy(from: &Path, to: &Path) -> io::Result<u64> {\n    use crate::sync::atomic::{AtomicBool, Ordering};\n\n    const COPYFILE_ACL: u32 = 1 << 0;\n    const COPYFILE_STAT: u32 = 1 << 1;\n    const COPYFILE_XATTR: u32 = 1 << 2;\n    const COPYFILE_DATA: u32 = 1 << 3;\n\n    const COPYFILE_SECURITY: u32 = COPYFILE_STAT | COPYFILE_ACL;\n    const COPYFILE_METADATA: u32 = COPYFILE_SECURITY | COPYFILE_XATTR;\n    const COPYFILE_ALL: u32 = COPYFILE_METADATA | COPYFILE_DATA;\n\n    const COPYFILE_STATE_COPIED: u32 = 8;\n\n    #[allow(non_camel_case_types)]\n    type copyfile_state_t = *mut libc::c_void;\n    #[allow(non_camel_case_types)]\n    type copyfile_flags_t = u32;\n\n    extern \"C\" {\n        fn fcopyfile(\n            from: libc::c_int,\n            to: libc::c_int,\n            state: copyfile_state_t,\n            flags: copyfile_flags_t,\n        ) -> libc::c_int;\n        fn copyfile_state_alloc() -> copyfile_state_t;\n        fn copyfile_state_free(state: copyfile_state_t) -> libc::c_int;\n        fn copyfile_state_get(\n            state: copyfile_state_t,\n            flag: u32,\n            dst: *mut libc::c_void,\n        ) -> libc::c_int;\n    }\n\n    struct FreeOnDrop(copyfile_state_t);\n    impl Drop for FreeOnDrop {\n        fn drop(&mut self) {\n            // The code below ensures that `FreeOnDrop` is never a null pointer\n            unsafe {\n                // `copyfile_state_free` returns -1 if the `to` or `from` files\n                // cannot be closed. However, this is not considered this an\n                // error.\n                copyfile_state_free(self.0);\n            }\n        }\n    }\n\n    // MacOS prior to 10.12 don't support `fclonefileat`\n    // We store the availability in a global to avoid unnecessary syscalls\n    static HAS_FCLONEFILEAT: AtomicBool = AtomicBool::new(true);\n    syscall! {\n        fn fclonefileat(\n            srcfd: libc::c_int,\n            dst_dirfd: libc::c_int,\n            dst: *const libc::c_char,\n            flags: libc::c_int\n        ) -> libc::c_int\n    }\n\n    let (reader, reader_metadata) = open_from(from)?;\n\n    // Opportunistically attempt to create a copy-on-write clone of `from`\n    // using `fclonefileat`.\n    if HAS_FCLONEFILEAT.load(Ordering::Relaxed) {\n        let to = cstr(to)?;\n        let clonefile_result =\n            cvt(unsafe { fclonefileat(reader.as_raw_fd(), libc::AT_FDCWD, to.as_ptr(), 0) });\n        match clonefile_result {\n            Ok(_) => return Ok(reader_metadata.len()),\n            Err(err) => match err.raw_os_error() {\n                // `fclonefileat` will fail on non-APFS volumes, if the\n                // destination already exists, or if the source and destination\n                // are on different devices. In all these cases `fcopyfile`\n                // should succeed.\n                Some(libc::ENOTSUP) | Some(libc::EEXIST) | Some(libc::EXDEV) => (),\n                Some(libc::ENOSYS) => HAS_FCLONEFILEAT.store(false, Ordering::Relaxed),\n                _ => return Err(err),\n            },\n        }\n    }\n\n    // Fall back to using `fcopyfile` if `fclonefileat` does not succeed.\n    let (writer, writer_metadata) = open_to_and_set_permissions(to, reader_metadata)?;\n\n    // We ensure that `FreeOnDrop` never contains a null pointer so it is\n    // always safe to call `copyfile_state_free`\n    let state = unsafe {\n        let state = copyfile_state_alloc();\n        if state.is_null() {\n            return Err(crate::io::Error::last_os_error());\n        }\n        FreeOnDrop(state)\n    };\n\n    let flags = if writer_metadata.is_file() { COPYFILE_ALL } else { COPYFILE_DATA };\n\n    cvt(unsafe { fcopyfile(reader.as_raw_fd(), writer.as_raw_fd(), state.0, flags) })?;\n\n    let mut bytes_copied: libc::off_t = 0;\n    cvt(unsafe {\n        copyfile_state_get(\n            state.0,\n            COPYFILE_STATE_COPIED,\n            &mut bytes_copied as *mut libc::off_t as *mut libc::c_void,\n        )\n    })?;\n    Ok(bytes_copied as u64)\n}\n\n#[cfg(not(any(target_os = \"fuchsia\", target_os = \"vxworks\")))]\npub fn chroot(dir: &Path) -> io::Result<()> {\n    let dir = cstr(dir)?;\n    cvt(unsafe { libc::chroot(dir.as_ptr()) })?;\n    Ok(())\n}\n"],[2344,"//! Implementation of `std::os` functionality for unix systems\n\n#![allow(unused_imports)] // lots of cfg code here\n\n#[cfg(all(test, target_env = \"gnu\"))]\nmod tests;\n\nuse crate::os::unix::prelude::*;\n\nuse crate::error::Error as StdError;\nuse crate::ffi::{CStr, CString, OsStr, OsString};\nuse crate::fmt;\nuse crate::io;\nuse crate::iter;\nuse crate::mem;\nuse crate::path::{self, PathBuf};\nuse crate::ptr;\nuse crate::slice;\nuse crate::str;\nuse crate::sys::cvt;\nuse crate::sys::fd;\nuse crate::sys::memchr;\nuse crate::sys_common::rwlock::{StaticRWLock, StaticRWLockReadGuard};\nuse crate::vec;\n\nuse libc::{c_char, c_int, c_void};\n\nconst TMPBUF_SZ: usize = 128;\n\ncfg_if::cfg_if! {\n    if #[cfg(target_os = \"redox\")] {\n        const PATH_SEPARATOR: u8 = b';';\n    } else {\n        const PATH_SEPARATOR: u8 = b':';\n    }\n}\n\nextern \"C\" {\n    #[cfg(not(any(target_os = \"dragonfly\", target_os = \"vxworks\")))]\n    #[cfg_attr(\n        any(\n            target_os = \"linux\",\n            target_os = \"emscripten\",\n            target_os = \"fuchsia\",\n            target_os = \"l4re\"\n        ),\n        link_name = \"__errno_location\"\n    )]\n    #[cfg_attr(\n        any(\n            target_os = \"netbsd\",\n            target_os = \"openbsd\",\n            target_os = \"android\",\n            target_os = \"redox\",\n            target_env = \"newlib\"\n        ),\n        link_name = \"__errno\"\n    )]\n    #[cfg_attr(any(target_os = \"solaris\", target_os = \"illumos\"), link_name = \"___errno\")]\n    #[cfg_attr(\n        any(target_os = \"macos\", target_os = \"ios\", target_os = \"freebsd\"),\n        link_name = \"__error\"\n    )]\n    #[cfg_attr(target_os = \"haiku\", link_name = \"_errnop\")]\n    fn errno_location() -> *mut c_int;\n}\n\n/// Returns the platform-specific value of errno\n#[cfg(not(any(target_os = \"dragonfly\", target_os = \"vxworks\")))]\npub fn errno() -> i32 {\n    unsafe { (*errno_location()) as i32 }\n}\n\n/// Sets the platform-specific value of errno\n#[cfg(all(not(target_os = \"linux\"), not(target_os = \"dragonfly\"), not(target_os = \"vxworks\")))] // needed for readdir and syscall!\n#[allow(dead_code)] // but not all target cfgs actually end up using it\npub fn set_errno(e: i32) {\n    unsafe { *errno_location() = e as c_int }\n}\n\n#[cfg(target_os = \"vxworks\")]\npub fn errno() -> i32 {\n    unsafe { libc::errnoGet() }\n}\n\n#[cfg(target_os = \"dragonfly\")]\npub fn errno() -> i32 {\n    extern \"C\" {\n        #[thread_local]\n        static errno: c_int;\n    }\n\n    unsafe { errno as i32 }\n}\n\n#[cfg(target_os = \"dragonfly\")]\npub fn set_errno(e: i32) {\n    extern \"C\" {\n        #[thread_local]\n        static mut errno: c_int;\n    }\n\n    unsafe {\n        errno = e;\n    }\n}\n\n/// Gets a detailed string description for the given error number.\npub fn error_string(errno: i32) -> String {\n    extern \"C\" {\n        #[cfg_attr(any(target_os = \"linux\", target_env = \"newlib\"), link_name = \"__xpg_strerror_r\")]\n        fn strerror_r(errnum: c_int, buf: *mut c_char, buflen: libc::size_t) -> c_int;\n    }\n\n    let mut buf = [0 as c_char; TMPBUF_SZ];\n\n    let p = buf.as_mut_ptr();\n    unsafe {\n        if strerror_r(errno as c_int, p, buf.len()) < 0 {\n            panic!(\"strerror_r failure\");\n        }\n\n        let p = p as *const _;\n        str::from_utf8(CStr::from_ptr(p).to_bytes()).unwrap().to_owned()\n    }\n}\n\npub fn getcwd() -> io::Result<PathBuf> {\n    let mut buf = Vec::with_capacity(512);\n    loop {\n        unsafe {\n            let ptr = buf.as_mut_ptr() as *mut libc::c_char;\n            if !libc::getcwd(ptr, buf.capacity()).is_null() {\n                let len = CStr::from_ptr(buf.as_ptr() as *const libc::c_char).to_bytes().len();\n                buf.set_len(len);\n                buf.shrink_to_fit();\n                return Ok(PathBuf::from(OsString::from_vec(buf)));\n            } else {\n                let error = io::Error::last_os_error();\n                if error.raw_os_error() != Some(libc::ERANGE) {\n                    return Err(error);\n                }\n            }\n\n            // Trigger the internal buffer resizing logic of `Vec` by requiring\n            // more space than the current capacity.\n            let cap = buf.capacity();\n            buf.set_len(cap);\n            buf.reserve(1);\n        }\n    }\n}\n\npub fn chdir(p: &path::Path) -> io::Result<()> {\n    let p: &OsStr = p.as_ref();\n    let p = CString::new(p.as_bytes())?;\n    if unsafe { libc::chdir(p.as_ptr()) } != 0 {\n        return Err(io::Error::last_os_error());\n    }\n    Ok(())\n}\n\npub struct SplitPaths<'a> {\n    iter: iter::Map<slice::Split<'a, u8, fn(&u8) -> bool>, fn(&'a [u8]) -> PathBuf>,\n}\n\npub fn split_paths(unparsed: &OsStr) -> SplitPaths<'_> {\n    fn bytes_to_path(b: &[u8]) -> PathBuf {\n        PathBuf::from(<OsStr as OsStrExt>::from_bytes(b))\n    }\n    fn is_separator(b: &u8) -> bool {\n        *b == PATH_SEPARATOR\n    }\n    let unparsed = unparsed.as_bytes();\n    SplitPaths {\n        iter: unparsed\n            .split(is_separator as fn(&u8) -> bool)\n            .map(bytes_to_path as fn(&[u8]) -> PathBuf),\n    }\n}\n\nimpl<'a> Iterator for SplitPaths<'a> {\n    type Item = PathBuf;\n    fn next(&mut self) -> Option<PathBuf> {\n        self.iter.next()\n    }\n    fn size_hint(&self) -> (usize, Option<usize>) {\n        self.iter.size_hint()\n    }\n}\n\n#[derive(Debug)]\npub struct JoinPathsError;\n\npub fn join_paths<I, T>(paths: I) -> Result<OsString, JoinPathsError>\nwhere\n    I: Iterator<Item = T>,\n    T: AsRef<OsStr>,\n{\n    let mut joined = Vec::new();\n\n    for (i, path) in paths.enumerate() {\n        let path = path.as_ref().as_bytes();\n        if i > 0 {\n            joined.push(PATH_SEPARATOR)\n        }\n        if path.contains(&PATH_SEPARATOR) {\n            return Err(JoinPathsError);\n        }\n        joined.extend_from_slice(path);\n    }\n    Ok(OsStringExt::from_vec(joined))\n}\n\nimpl fmt::Display for JoinPathsError {\n    fn fmt(&self, f: &mut fmt::Formatter<'_>) -> fmt::Result {\n        write!(f, \"path segment contains separator `{}`\", char::from(PATH_SEPARATOR))\n    }\n}\n\nimpl StdError for JoinPathsError {\n    #[allow(deprecated)]\n    fn description(&self) -> &str {\n        \"failed to join paths\"\n    }\n}\n\n#[cfg(any(target_os = \"freebsd\", target_os = \"dragonfly\"))]\npub fn current_exe() -> io::Result<PathBuf> {\n    unsafe {\n        let mut mib = [\n            libc::CTL_KERN as c_int,\n            libc::KERN_PROC as c_int,\n            libc::KERN_PROC_PATHNAME as c_int,\n            -1 as c_int,\n        ];\n        let mut sz = 0;\n        cvt(libc::sysctl(\n            mib.as_mut_ptr(),\n            mib.len() as libc::c_uint,\n            ptr::null_mut(),\n            &mut sz,\n            ptr::null_mut(),\n            0,\n        ))?;\n        if sz == 0 {\n            return Err(io::Error::last_os_error());\n        }\n        let mut v: Vec<u8> = Vec::with_capacity(sz);\n        cvt(libc::sysctl(\n            mib.as_mut_ptr(),\n            mib.len() as libc::c_uint,\n            v.as_mut_ptr() as *mut libc::c_void,\n            &mut sz,\n            ptr::null_mut(),\n            0,\n        ))?;\n        if sz == 0 {\n            return Err(io::Error::last_os_error());\n        }\n        v.set_len(sz - 1); // chop off trailing NUL\n        Ok(PathBuf::from(OsString::from_vec(v)))\n    }\n}\n\n#[cfg(target_os = \"netbsd\")]\npub fn current_exe() -> io::Result<PathBuf> {\n    fn sysctl() -> io::Result<PathBuf> {\n        unsafe {\n            let mib = [libc::CTL_KERN, libc::KERN_PROC_ARGS, -1, libc::KERN_PROC_PATHNAME];\n            let mut path_len: usize = 0;\n            cvt(libc::sysctl(\n                mib.as_ptr(),\n                mib.len() as libc::c_uint,\n                ptr::null_mut(),\n                &mut path_len,\n                ptr::null(),\n                0,\n            ))?;\n            if path_len <= 1 {\n                return Err(io::Error::new_const(\n                    io::ErrorKind::Other,\n                    &\"KERN_PROC_PATHNAME sysctl returned zero-length string\",\n                ));\n            }\n            let mut path: Vec<u8> = Vec::with_capacity(path_len);\n            cvt(libc::sysctl(\n                mib.as_ptr(),\n                mib.len() as libc::c_uint,\n                path.as_ptr() as *mut libc::c_void,\n                &mut path_len,\n                ptr::null(),\n                0,\n            ))?;\n            path.set_len(path_len - 1); // chop off NUL\n            Ok(PathBuf::from(OsString::from_vec(path)))\n        }\n    }\n    fn procfs() -> io::Result<PathBuf> {\n        let curproc_exe = path::Path::new(\"/proc/curproc/exe\");\n        if curproc_exe.is_file() {\n            return crate::fs::read_link(curproc_exe);\n        }\n        Err(io::Error::new_const(\n            io::ErrorKind::Other,\n            &\"/proc/curproc/exe doesn't point to regular file.\",\n        ))\n    }\n    sysctl().or_else(|_| procfs())\n}\n\n#[cfg(target_os = \"openbsd\")]\npub fn current_exe() -> io::Result<PathBuf> {\n    unsafe {\n        let mut mib = [libc::CTL_KERN, libc::KERN_PROC_ARGS, libc::getpid(), libc::KERN_PROC_ARGV];\n        let mib = mib.as_mut_ptr();\n        let mut argv_len = 0;\n        cvt(libc::sysctl(mib, 4, ptr::null_mut(), &mut argv_len, ptr::null_mut(), 0))?;\n        let mut argv = Vec::<*const libc::c_char>::with_capacity(argv_len as usize);\n        cvt(libc::sysctl(mib, 4, argv.as_mut_ptr() as *mut _, &mut argv_len, ptr::null_mut(), 0))?;\n        argv.set_len(argv_len as usize);\n        if argv[0].is_null() {\n            return Err(io::Error::new_const(io::ErrorKind::Other, &\"no current exe available\"));\n        }\n        let argv0 = CStr::from_ptr(argv[0]).to_bytes();\n        if argv0[0] == b'.' || argv0.iter().any(|b| *b == b'/') {\n            crate::fs::canonicalize(OsStr::from_bytes(argv0))\n        } else {\n            Ok(PathBuf::from(OsStr::from_bytes(argv0)))\n        }\n    }\n}\n\n#[cfg(any(target_os = \"linux\", target_os = \"android\", target_os = \"emscripten\"))]\npub fn current_exe() -> io::Result<PathBuf> {\n    match crate::fs::read_link(\"/proc/self/exe\") {\n        Err(ref e) if e.kind() == io::ErrorKind::NotFound => Err(io::Error::new_const(\n            io::ErrorKind::Other,\n            &\"no /proc/self/exe available. Is /proc mounted?\",\n        )),\n        other => other,\n    }\n}\n\n#[cfg(any(target_os = \"macos\", target_os = \"ios\"))]\npub fn current_exe() -> io::Result<PathBuf> {\n    extern \"C\" {\n        fn _NSGetExecutablePath(buf: *mut libc::c_char, bufsize: *mut u32) -> libc::c_int;\n    }\n    unsafe {\n        let mut sz: u32 = 0;\n        _NSGetExecutablePath(ptr::null_mut(), &mut sz);\n        if sz == 0 {\n            return Err(io::Error::last_os_error());\n        }\n        let mut v: Vec<u8> = Vec::with_capacity(sz as usize);\n        let err = _NSGetExecutablePath(v.as_mut_ptr() as *mut i8, &mut sz);\n        if err != 0 {\n            return Err(io::Error::last_os_error());\n        }\n        v.set_len(sz as usize - 1); // chop off trailing NUL\n        Ok(PathBuf::from(OsString::from_vec(v)))\n    }\n}\n\n#[cfg(any(target_os = \"solaris\", target_os = \"illumos\"))]\npub fn current_exe() -> io::Result<PathBuf> {\n    extern \"C\" {\n        fn getexecname() -> *const c_char;\n    }\n    unsafe {\n        let path = getexecname();\n        if path.is_null() {\n            Err(io::Error::last_os_error())\n        } else {\n            let filename = CStr::from_ptr(path).to_bytes();\n            let path = PathBuf::from(<OsStr as OsStrExt>::from_bytes(filename));\n\n            // Prepend a current working directory to the path if\n            // it doesn't contain an absolute pathname.\n            if filename[0] == b'/' { Ok(path) } else { getcwd().map(|cwd| cwd.join(path)) }\n        }\n    }\n}\n\n#[cfg(target_os = \"haiku\")]\npub fn current_exe() -> io::Result<PathBuf> {\n    // Use Haiku's image info functions\n    #[repr(C)]\n    struct image_info {\n        id: i32,\n        type_: i32,\n        sequence: i32,\n        init_order: i32,\n        init_routine: *mut libc::c_void, // function pointer\n        term_routine: *mut libc::c_void, // function pointer\n        device: libc::dev_t,\n        node: libc::ino_t,\n        name: [libc::c_char; 1024], // MAXPATHLEN\n        text: *mut libc::c_void,\n        data: *mut libc::c_void,\n        text_size: i32,\n        data_size: i32,\n        api_version: i32,\n        abi: i32,\n    }\n\n    unsafe {\n        extern \"C\" {\n            fn _get_next_image_info(\n                team_id: i32,\n                cookie: *mut i32,\n                info: *mut image_info,\n                size: i32,\n            ) -> i32;\n        }\n\n        let mut info: image_info = mem::zeroed();\n        let mut cookie: i32 = 0;\n        // the executable can be found at team id 0\n        let result =\n            _get_next_image_info(0, &mut cookie, &mut info, mem::size_of::<image_info>() as i32);\n        if result != 0 {\n            use crate::io::ErrorKind;\n            Err(io::Error::new_const(ErrorKind::Other, &\"Error getting executable path\"))\n        } else {\n            let name = CStr::from_ptr(info.name.as_ptr()).to_bytes();\n            Ok(PathBuf::from(OsStr::from_bytes(name)))\n        }\n    }\n}\n\n#[cfg(target_os = \"redox\")]\npub fn current_exe() -> io::Result<PathBuf> {\n    crate::fs::read_to_string(\"sys:exe\").map(PathBuf::from)\n}\n\n#[cfg(any(target_os = \"fuchsia\", target_os = \"l4re\"))]\npub fn current_exe() -> io::Result<PathBuf> {\n    use crate::io::ErrorKind;\n    Err(io::Error::new_const(ErrorKind::Unsupported, &\"Not yet implemented!\"))\n}\n\n#[cfg(target_os = \"vxworks\")]\npub fn current_exe() -> io::Result<PathBuf> {\n    #[cfg(test)]\n    use realstd::env;\n\n    #[cfg(not(test))]\n    use crate::env;\n\n    let exe_path = env::args().next().unwrap();\n    let path = path::Path::new(&exe_path);\n    path.canonicalize()\n}\n\npub struct Env {\n    iter: vec::IntoIter<(OsString, OsString)>,\n}\n\nimpl !Send for Env {}\nimpl !Sync for Env {}\n\nimpl Iterator for Env {\n    type Item = (OsString, OsString);\n    fn next(&mut self) -> Option<(OsString, OsString)> {\n        self.iter.next()\n    }\n    fn size_hint(&self) -> (usize, Option<usize>) {\n        self.iter.size_hint()\n    }\n}\n\n#[cfg(target_os = \"macos\")]\npub unsafe fn environ() -> *mut *const *const c_char {\n    extern \"C\" {\n        fn _NSGetEnviron() -> *mut *const *const c_char;\n    }\n    _NSGetEnviron()\n}\n\n#[cfg(not(target_os = \"macos\"))]\npub unsafe fn environ() -> *mut *const *const c_char {\n    extern \"C\" {\n        static mut environ: *const *const c_char;\n    }\n    ptr::addr_of_mut!(environ)\n}\n\nstatic ENV_LOCK: StaticRWLock = StaticRWLock::new();\n\npub fn env_read_lock() -> StaticRWLockReadGuard {\n    ENV_LOCK.read()\n}\n\n/// Returns a vector of (variable, value) byte-vector pairs for all the\n/// environment variables of the current process.\npub fn env() -> Env {\n    unsafe {\n        let _guard = env_read_lock();\n        let mut environ = *environ();\n        let mut result = Vec::new();\n        if !environ.is_null() {\n            while !(*environ).is_null() {\n                if let Some(key_value) = parse(CStr::from_ptr(*environ).to_bytes()) {\n                    result.push(key_value);\n                }\n                environ = environ.add(1);\n            }\n        }\n        return Env { iter: result.into_iter() };\n    }\n\n    fn parse(input: &[u8]) -> Option<(OsString, OsString)> {\n        // Strategy (copied from glibc): Variable name and value are separated\n        // by an ASCII equals sign '='. Since a variable name must not be\n        // empty, allow variable names starting with an equals sign. Skip all\n        // malformed lines.\n        if input.is_empty() {\n            return None;\n        }\n        let pos = memchr::memchr(b'=', &input[1..]).map(|p| p + 1);\n        pos.map(|p| {\n            (\n                OsStringExt::from_vec(input[..p].to_vec()),\n                OsStringExt::from_vec(input[p + 1..].to_vec()),\n            )\n        })\n    }\n}\n\npub fn getenv(k: &OsStr) -> io::Result<Option<OsString>> {\n    // environment variables with a nul byte can't be set, so their value is\n    // always None as well\n    let k = CString::new(k.as_bytes())?;\n    unsafe {\n        let _guard = env_read_lock();\n        let s = libc::getenv(k.as_ptr()) as *const libc::c_char;\n        let ret = if s.is_null() {\n            None\n        } else {\n            Some(OsStringExt::from_vec(CStr::from_ptr(s).to_bytes().to_vec()))\n        };\n        Ok(ret)\n    }\n}\n\npub fn setenv(k: &OsStr, v: &OsStr) -> io::Result<()> {\n    let k = CString::new(k.as_bytes())?;\n    let v = CString::new(v.as_bytes())?;\n\n    unsafe {\n        let _guard = ENV_LOCK.write();\n        cvt(libc::setenv(k.as_ptr(), v.as_ptr(), 1)).map(drop)\n    }\n}\n\npub fn unsetenv(n: &OsStr) -> io::Result<()> {\n    let nbuf = CString::new(n.as_bytes())?;\n\n    unsafe {\n        let _guard = ENV_LOCK.write();\n        cvt(libc::unsetenv(nbuf.as_ptr())).map(drop)\n    }\n}\n\npub fn page_size() -> usize {\n    unsafe { libc::sysconf(libc::_SC_PAGESIZE) as usize }\n}\n\npub fn temp_dir() -> PathBuf {\n    crate::env::var_os(\"TMPDIR\").map(PathBuf::from).unwrap_or_else(|| {\n        if cfg!(target_os = \"android\") {\n            PathBuf::from(\"/data/local/tmp\")\n        } else {\n            PathBuf::from(\"/tmp\")\n        }\n    })\n}\n\npub fn home_dir() -> Option<PathBuf> {\n    return crate::env::var_os(\"HOME\").or_else(|| unsafe { fallback() }).map(PathBuf::from);\n\n    #[cfg(any(\n        target_os = \"android\",\n        target_os = \"ios\",\n        target_os = \"emscripten\",\n        target_os = \"redox\",\n        target_os = \"vxworks\"\n    ))]\n    unsafe fn fallback() -> Option<OsString> {\n        None\n    }\n    #[cfg(not(any(\n        target_os = \"android\",\n        target_os = \"ios\",\n        target_os = \"emscripten\",\n        target_os = \"redox\",\n        target_os = \"vxworks\"\n    )))]\n    unsafe fn fallback() -> Option<OsString> {\n        let amt = match libc::sysconf(libc::_SC_GETPW_R_SIZE_MAX) {\n            n if n < 0 => 512 as usize,\n            n => n as usize,\n        };\n        let mut buf = Vec::with_capacity(amt);\n        let mut passwd: libc::passwd = mem::zeroed();\n        let mut result = ptr::null_mut();\n        match libc::getpwuid_r(\n            libc::getuid(),\n            &mut passwd,\n            buf.as_mut_ptr(),\n            buf.capacity(),\n            &mut result,\n        ) {\n            0 if !result.is_null() => {\n                let ptr = passwd.pw_dir as *const _;\n                let bytes = CStr::from_ptr(ptr).to_bytes().to_vec();\n                Some(OsStringExt::from_vec(bytes))\n            }\n            _ => None,\n        }\n    }\n}\n\npub fn exit(code: i32) -> ! {\n    unsafe { libc::exit(code as c_int) }\n}\n\npub fn getpid() -> u32 {\n    unsafe { libc::getpid() as u32 }\n}\n\npub fn getppid() -> u32 {\n    unsafe { libc::getppid() as u32 }\n}\n\n#[cfg(all(target_env = \"gnu\", not(target_os = \"vxworks\")))]\npub fn glibc_version() -> Option<(usize, usize)> {\n    if let Some(Ok(version_str)) = glibc_version_cstr().map(CStr::to_str) {\n        parse_glibc_version(version_str)\n    } else {\n        None\n    }\n}\n\n#[cfg(all(target_env = \"gnu\", not(target_os = \"vxworks\")))]\nfn glibc_version_cstr() -> Option<&'static CStr> {\n    weak! {\n        fn gnu_get_libc_version() -> *const libc::c_char\n    }\n    if let Some(f) = gnu_get_libc_version.get() {\n        unsafe { Some(CStr::from_ptr(f())) }\n    } else {\n        None\n    }\n}\n\n// Returns Some((major, minor)) if the string is a valid \"x.y\" version,\n// ignoring any extra dot-separated parts. Otherwise return None.\n#[cfg(all(target_env = \"gnu\", not(target_os = \"vxworks\")))]\nfn parse_glibc_version(version: &str) -> Option<(usize, usize)> {\n    let mut parsed_ints = version.split('.').map(str::parse::<usize>).fuse();\n    match (parsed_ints.next(), parsed_ints.next()) {\n        (Some(Ok(major)), Some(Ok(minor))) => Some((major, minor)),\n        _ => None,\n    }\n}\n"],[2345,"// Original implementation taken from rust-memchr.\n// Copyright 2015 Andrew Gallant, bluss and Nicolas Koch\n\npub fn memchr(needle: u8, haystack: &[u8]) -> Option<usize> {\n    let p = unsafe {\n        libc::memchr(\n            haystack.as_ptr() as *const libc::c_void,\n            needle as libc::c_int,\n            haystack.len(),\n        )\n    };\n    if p.is_null() { None } else { Some(p as usize - (haystack.as_ptr() as usize)) }\n}\n\npub fn memrchr(needle: u8, haystack: &[u8]) -> Option<usize> {\n    #[cfg(target_os = \"linux\")]\n    fn memrchr_specific(needle: u8, haystack: &[u8]) -> Option<usize> {\n        // GNU's memrchr() will - unlike memchr() - error if haystack is empty.\n        if haystack.is_empty() {\n            return None;\n        }\n        let p = unsafe {\n            libc::memrchr(\n                haystack.as_ptr() as *const libc::c_void,\n                needle as libc::c_int,\n                haystack.len(),\n            )\n        };\n        if p.is_null() { None } else { Some(p as usize - (haystack.as_ptr() as usize)) }\n    }\n\n    #[cfg(not(target_os = \"linux\"))]\n    fn memrchr_specific(needle: u8, haystack: &[u8]) -> Option<usize> {\n        core::slice::memchr::memrchr(needle, haystack)\n    }\n\n    memrchr_specific(needle, haystack)\n}\n"],[2346,"use crate::cell::UnsafeCell;\nuse crate::mem::MaybeUninit;\nuse crate::sys::cvt_nz;\n\npub struct Mutex {\n    inner: UnsafeCell<libc::pthread_mutex_t>,\n}\n\npub type MovableMutex = Box<Mutex>;\n\n#[inline]\npub unsafe fn raw(m: &Mutex) -> *mut libc::pthread_mutex_t {\n    m.inner.get()\n}\n\nunsafe impl Send for Mutex {}\nunsafe impl Sync for Mutex {}\n\n#[allow(dead_code)] // sys isn't exported yet\nimpl Mutex {\n    pub const fn new() -> Mutex {\n        // Might be moved to a different address, so it is better to avoid\n        // initialization of potentially opaque OS data before it landed.\n        // Be very careful using this newly constructed `Mutex`, reentrant\n        // locking is undefined behavior until `init` is called!\n        Mutex { inner: UnsafeCell::new(libc::PTHREAD_MUTEX_INITIALIZER) }\n    }\n    #[inline]\n    pub unsafe fn init(&mut self) {\n        // Issue #33770\n        //\n        // A pthread mutex initialized with PTHREAD_MUTEX_INITIALIZER will have\n        // a type of PTHREAD_MUTEX_DEFAULT, which has undefined behavior if you\n        // try to re-lock it from the same thread when you already hold a lock\n        // (https://pubs.opengroup.org/onlinepubs/9699919799/functions/pthread_mutex_init.html).\n        // This is the case even if PTHREAD_MUTEX_DEFAULT == PTHREAD_MUTEX_NORMAL\n        // (https://github.com/rust-lang/rust/issues/33770#issuecomment-220847521) -- in that\n        // case, `pthread_mutexattr_settype(PTHREAD_MUTEX_DEFAULT)` will of course be the same\n        // as setting it to `PTHREAD_MUTEX_NORMAL`, but not setting any mode will result in\n        // a Mutex where re-locking is UB.\n        //\n        // In practice, glibc takes advantage of this undefined behavior to\n        // implement hardware lock elision, which uses hardware transactional\n        // memory to avoid acquiring the lock. While a transaction is in\n        // progress, the lock appears to be unlocked. This isn't a problem for\n        // other threads since the transactional memory will abort if a conflict\n        // is detected, however no abort is generated when re-locking from the\n        // same thread.\n        //\n        // Since locking the same mutex twice will result in two aliasing &mut\n        // references, we instead create the mutex with type\n        // PTHREAD_MUTEX_NORMAL which is guaranteed to deadlock if we try to\n        // re-lock it from the same thread, thus avoiding undefined behavior.\n        let mut attr = MaybeUninit::<libc::pthread_mutexattr_t>::uninit();\n        cvt_nz(libc::pthread_mutexattr_init(attr.as_mut_ptr())).unwrap();\n        let attr = PthreadMutexAttr(&mut attr);\n        cvt_nz(libc::pthread_mutexattr_settype(attr.0.as_mut_ptr(), libc::PTHREAD_MUTEX_NORMAL))\n            .unwrap();\n        cvt_nz(libc::pthread_mutex_init(self.inner.get(), attr.0.as_ptr())).unwrap();\n    }\n    #[inline]\n    pub unsafe fn lock(&self) {\n        let r = libc::pthread_mutex_lock(self.inner.get());\n        debug_assert_eq!(r, 0);\n    }\n    #[inline]\n    pub unsafe fn unlock(&self) {\n        let r = libc::pthread_mutex_unlock(self.inner.get());\n        debug_assert_eq!(r, 0);\n    }\n    #[inline]\n    pub unsafe fn try_lock(&self) -> bool {\n        libc::pthread_mutex_trylock(self.inner.get()) == 0\n    }\n    #[inline]\n    #[cfg(not(target_os = \"dragonfly\"))]\n    pub unsafe fn destroy(&self) {\n        let r = libc::pthread_mutex_destroy(self.inner.get());\n        debug_assert_eq!(r, 0);\n    }\n    #[inline]\n    #[cfg(target_os = \"dragonfly\")]\n    pub unsafe fn destroy(&self) {\n        let r = libc::pthread_mutex_destroy(self.inner.get());\n        // On DragonFly pthread_mutex_destroy() returns EINVAL if called on a\n        // mutex that was just initialized with libc::PTHREAD_MUTEX_INITIALIZER.\n        // Once it is used (locked/unlocked) or pthread_mutex_init() is called,\n        // this behaviour no longer occurs.\n        debug_assert!(r == 0 || r == libc::EINVAL);\n    }\n}\n\npub struct ReentrantMutex {\n    inner: UnsafeCell<libc::pthread_mutex_t>,\n}\n\nunsafe impl Send for ReentrantMutex {}\nunsafe impl Sync for ReentrantMutex {}\n\nimpl ReentrantMutex {\n    pub const unsafe fn uninitialized() -> ReentrantMutex {\n        ReentrantMutex { inner: UnsafeCell::new(libc::PTHREAD_MUTEX_INITIALIZER) }\n    }\n\n    pub unsafe fn init(&self) {\n        let mut attr = MaybeUninit::<libc::pthread_mutexattr_t>::uninit();\n        cvt_nz(libc::pthread_mutexattr_init(attr.as_mut_ptr())).unwrap();\n        let attr = PthreadMutexAttr(&mut attr);\n        cvt_nz(libc::pthread_mutexattr_settype(attr.0.as_mut_ptr(), libc::PTHREAD_MUTEX_RECURSIVE))\n            .unwrap();\n        cvt_nz(libc::pthread_mutex_init(self.inner.get(), attr.0.as_ptr())).unwrap();\n    }\n\n    pub unsafe fn lock(&self) {\n        let result = libc::pthread_mutex_lock(self.inner.get());\n        debug_assert_eq!(result, 0);\n    }\n\n    #[inline]\n    pub unsafe fn try_lock(&self) -> bool {\n        libc::pthread_mutex_trylock(self.inner.get()) == 0\n    }\n\n    pub unsafe fn unlock(&self) {\n        let result = libc::pthread_mutex_unlock(self.inner.get());\n        debug_assert_eq!(result, 0);\n    }\n\n    pub unsafe fn destroy(&self) {\n        let result = libc::pthread_mutex_destroy(self.inner.get());\n        debug_assert_eq!(result, 0);\n    }\n}\n\nstruct PthreadMutexAttr<'a>(&'a mut MaybeUninit<libc::pthread_mutexattr_t>);\n\nimpl Drop for PthreadMutexAttr<'_> {\n    fn drop(&mut self) {\n        unsafe {\n            let result = libc::pthread_mutexattr_destroy(self.0.as_mut_ptr());\n            debug_assert_eq!(result, 0);\n        }\n    }\n}\n"],[2347,"//! Support for \"weak linkage\" to symbols on Unix\n//!\n//! Some I/O operations we do in libstd require newer versions of OSes but we\n//! need to maintain binary compatibility with older releases for now. In order\n//! to use the new functionality when available we use this module for\n//! detection.\n//!\n//! One option to use here is weak linkage, but that is unfortunately only\n//! really workable on Linux. Hence, use dlsym to get the symbol value at\n//! runtime. This is also done for compatibility with older versions of glibc,\n//! and to avoid creating dependencies on GLIBC_PRIVATE symbols. It assumes that\n//! we've been dynamically linked to the library the symbol comes from, but that\n//! is currently always the case for things like libpthread/libc.\n//!\n//! A long time ago this used weak linkage for the __pthread_get_minstack\n//! symbol, but that caused Debian to detect an unnecessarily strict versioned\n//! dependency on libc6 (#23628).\n\n// There are a variety of `#[cfg]`s controlling which targets are involved in\n// each instance of `weak!` and `syscall!`. Rather than trying to unify all of\n// that, we'll just allow that some unix targets don't use this module at all.\n#![allow(dead_code, unused_macros)]\n\nuse crate::ffi::CStr;\nuse crate::marker;\nuse crate::mem;\nuse crate::sync::atomic::{self, AtomicUsize, Ordering};\n\nmacro_rules! weak {\n    (fn $name:ident($($t:ty),*) -> $ret:ty) => (\n        static $name: crate::sys::weak::Weak<unsafe extern \"C\" fn($($t),*) -> $ret> =\n            crate::sys::weak::Weak::new(concat!(stringify!($name), '\\0'));\n    )\n}\n\npub struct Weak<F> {\n    name: &'static str,\n    addr: AtomicUsize,\n    _marker: marker::PhantomData<F>,\n}\n\nimpl<F> Weak<F> {\n    pub const fn new(name: &'static str) -> Weak<F> {\n        Weak { name, addr: AtomicUsize::new(1), _marker: marker::PhantomData }\n    }\n\n    pub fn get(&self) -> Option<F> {\n        assert_eq!(mem::size_of::<F>(), mem::size_of::<usize>());\n        unsafe {\n            // Relaxed is fine here because we fence before reading through the\n            // pointer (see the comment below).\n            match self.addr.load(Ordering::Relaxed) {\n                1 => self.initialize(),\n                0 => None,\n                addr => {\n                    let func = mem::transmute_copy::<usize, F>(&addr);\n                    // The caller is presumably going to read through this value\n                    // (by calling the function we've dlsymed). This means we'd\n                    // need to have loaded it with at least C11's consume\n                    // ordering in order to be guaranteed that the data we read\n                    // from the pointer isn't from before the pointer was\n                    // stored. Rust has no equivalent to memory_order_consume,\n                    // so we use an acquire fence (sorry, ARM).\n                    //\n                    // Now, in practice this likely isn't needed even on CPUs\n                    // where relaxed and consume mean different things. The\n                    // symbols we're loading are probably present (or not) at\n                    // init, and even if they aren't the runtime dynamic loader\n                    // is extremely likely have sufficient barriers internally\n                    // (possibly implicitly, for example the ones provided by\n                    // invoking `mprotect`).\n                    //\n                    // That said, none of that's *guaranteed*, and so we fence.\n                    atomic::fence(Ordering::Acquire);\n                    Some(func)\n                }\n            }\n        }\n    }\n\n    // Cold because it should only happen during first-time initalization.\n    #[cold]\n    unsafe fn initialize(&self) -> Option<F> {\n        let val = fetch(self.name);\n        // This synchronizes with the acquire fence in `get`.\n        self.addr.store(val, Ordering::Release);\n\n        match val {\n            0 => None,\n            addr => Some(mem::transmute_copy::<usize, F>(&addr)),\n        }\n    }\n}\n\nunsafe fn fetch(name: &str) -> usize {\n    let name = match CStr::from_bytes_with_nul(name.as_bytes()) {\n        Ok(cstr) => cstr,\n        Err(..) => return 0,\n    };\n    libc::dlsym(libc::RTLD_DEFAULT, name.as_ptr()) as usize\n}\n\n#[cfg(not(any(target_os = \"linux\", target_os = \"android\")))]\nmacro_rules! syscall {\n    (fn $name:ident($($arg_name:ident: $t:ty),*) -> $ret:ty) => (\n        unsafe fn $name($($arg_name: $t),*) -> $ret {\n            use super::os;\n\n            weak! { fn $name($($t),*) -> $ret }\n\n            if let Some(fun) = $name.get() {\n                fun($($arg_name),*)\n            } else {\n                os::set_errno(libc::ENOSYS);\n                -1\n            }\n        }\n    )\n}\n\n#[cfg(any(target_os = \"linux\", target_os = \"android\"))]\nmacro_rules! syscall {\n    (fn $name:ident($($arg_name:ident: $t:ty),*) -> $ret:ty) => (\n        unsafe fn $name($($arg_name:$t),*) -> $ret {\n            // This looks like a hack, but concat_idents only accepts idents\n            // (not paths).\n            use libc::*;\n\n            weak! { fn $name($($t),*) -> $ret }\n\n            // Use a weak symbol from libc when possible, allowing `LD_PRELOAD`\n            // interposition, but if it's not found just use a raw syscall.\n            if let Some(fun) = $name.get() {\n                fun($($arg_name),*)\n            } else {\n                syscall(\n                    concat_idents!(SYS_, $name),\n                    $($arg_name),*\n                ) as $ret\n            }\n        }\n    )\n}\n"],[2348,"#![cfg(not(test))]\n\n// These symbols are all defined by `libm`,\n// or by `compiler-builtins` on unsupported platforms.\n\nextern \"C\" {\n    pub fn acos(n: f64) -> f64;\n    pub fn acosf(n: f32) -> f32;\n    pub fn asin(n: f64) -> f64;\n    pub fn asinf(n: f32) -> f32;\n    pub fn atan(n: f64) -> f64;\n    pub fn atan2(a: f64, b: f64) -> f64;\n    pub fn atan2f(a: f32, b: f32) -> f32;\n    pub fn atanf(n: f32) -> f32;\n    pub fn cbrt(n: f64) -> f64;\n    pub fn cbrtf(n: f32) -> f32;\n    pub fn cosh(n: f64) -> f64;\n    pub fn coshf(n: f32) -> f32;\n    pub fn expm1(n: f64) -> f64;\n    pub fn expm1f(n: f32) -> f32;\n    pub fn fdim(a: f64, b: f64) -> f64;\n    pub fn fdimf(a: f32, b: f32) -> f32;\n    pub fn hypot(x: f64, y: f64) -> f64;\n    pub fn hypotf(x: f32, y: f32) -> f32;\n    pub fn log1p(n: f64) -> f64;\n    pub fn log1pf(n: f32) -> f32;\n    pub fn sinh(n: f64) -> f64;\n    pub fn sinhf(n: f32) -> f32;\n    pub fn tan(n: f64) -> f64;\n    pub fn tanf(n: f32) -> f32;\n    pub fn tanh(n: f64) -> f64;\n    pub fn tanhf(n: f32) -> f32;\n}\n"],[2349,"macro_rules! unimpl {\n    () => {\n        return Err(io::Error::new_const(\n            io::ErrorKind::Unsupported,\n            &\"No networking available on L4Re.\",\n        ));\n    };\n}\n\npub mod net {\n    #![allow(warnings)]\n    use crate::convert::TryFrom;\n    use crate::fmt;\n    use crate::io::{self, IoSlice, IoSliceMut};\n    use crate::net::{Ipv4Addr, Ipv6Addr, Shutdown, SocketAddr};\n    use crate::sys::fd::FileDesc;\n    use crate::sys_common::{AsInner, FromInner, IntoInner};\n    use crate::time::Duration;\n\n    #[allow(unused_extern_crates)]\n    pub extern crate libc as netc;\n\n    pub struct Socket(FileDesc);\n    impl Socket {\n        pub fn new(_: &SocketAddr, _: libc::c_int) -> io::Result<Socket> {\n            unimpl!();\n        }\n\n        pub fn new_raw(_: libc::c_int, _: libc::c_int) -> io::Result<Socket> {\n            unimpl!();\n        }\n\n        pub fn new_pair(_: libc::c_int, _: libc::c_int) -> io::Result<(Socket, Socket)> {\n            unimpl!();\n        }\n\n        pub fn connect_timeout(&self, _: &SocketAddr, _: Duration) -> io::Result<()> {\n            unimpl!();\n        }\n\n        pub fn accept(\n            &self,\n            _: *mut libc::sockaddr,\n            _: *mut libc::socklen_t,\n        ) -> io::Result<Socket> {\n            unimpl!();\n        }\n\n        pub fn duplicate(&self) -> io::Result<Socket> {\n            unimpl!();\n        }\n\n        pub fn read(&self, _: &mut [u8]) -> io::Result<usize> {\n            unimpl!();\n        }\n\n        pub fn read_vectored(&self, _: &mut [IoSliceMut<'_>]) -> io::Result<usize> {\n            unimpl!();\n        }\n\n        pub fn is_read_vectored(&self) -> bool {\n            unimpl!();\n        }\n\n        pub fn peek(&self, _: &mut [u8]) -> io::Result<usize> {\n            unimpl!();\n        }\n\n        pub fn recv_from(&self, _: &mut [u8]) -> io::Result<(usize, SocketAddr)> {\n            unimpl!();\n        }\n\n        pub fn peek_from(&self, _: &mut [u8]) -> io::Result<(usize, SocketAddr)> {\n            unimpl!();\n        }\n\n        pub fn write(&self, _: &[u8]) -> io::Result<usize> {\n            unimpl!();\n        }\n\n        pub fn write_vectored(&self, _: &[IoSlice<'_>]) -> io::Result<usize> {\n            unimpl!();\n        }\n\n        pub fn is_write_vectored(&self) -> bool {\n            unimpl!();\n        }\n\n        pub fn set_timeout(&self, _: Option<Duration>, _: libc::c_int) -> io::Result<()> {\n            unimpl!();\n        }\n\n        pub fn timeout(&self, _: libc::c_int) -> io::Result<Option<Duration>> {\n            unimpl!();\n        }\n\n        pub fn shutdown(&self, _: Shutdown) -> io::Result<()> {\n            unimpl!();\n        }\n\n        pub fn set_nodelay(&self, _: bool) -> io::Result<()> {\n            unimpl!();\n        }\n\n        pub fn nodelay(&self) -> io::Result<bool> {\n            unimpl!();\n        }\n\n        pub fn set_nonblocking(&self, _: bool) -> io::Result<()> {\n            unimpl!();\n        }\n\n        pub fn take_error(&self) -> io::Result<Option<io::Error>> {\n            unimpl!();\n        }\n    }\n\n    impl AsInner<libc::c_int> for Socket {\n        fn as_inner(&self) -> &libc::c_int {\n            self.0.as_inner()\n        }\n    }\n\n    impl FromInner<libc::c_int> for Socket {\n        fn from_inner(fd: libc::c_int) -> Socket {\n            Socket(FileDesc::new(fd))\n        }\n    }\n\n    impl IntoInner<libc::c_int> for Socket {\n        fn into_inner(self) -> libc::c_int {\n            self.0.into_raw()\n        }\n    }\n\n    pub struct TcpStream {\n        inner: Socket,\n    }\n\n    impl TcpStream {\n        pub fn connect(_: io::Result<&SocketAddr>) -> io::Result<TcpStream> {\n            unimpl!();\n        }\n\n        pub fn connect_timeout(_: &SocketAddr, _: Duration) -> io::Result<TcpStream> {\n            unimpl!();\n        }\n\n        pub fn socket(&self) -> &Socket {\n            &self.inner\n        }\n\n        pub fn into_socket(self) -> Socket {\n            self.inner\n        }\n\n        pub fn set_read_timeout(&self, _: Option<Duration>) -> io::Result<()> {\n            unimpl!();\n        }\n\n        pub fn set_write_timeout(&self, _: Option<Duration>) -> io::Result<()> {\n            unimpl!();\n        }\n\n        pub fn read_timeout(&self) -> io::Result<Option<Duration>> {\n            unimpl!();\n        }\n\n        pub fn write_timeout(&self) -> io::Result<Option<Duration>> {\n            unimpl!();\n        }\n\n        pub fn peek(&self, _: &mut [u8]) -> io::Result<usize> {\n            unimpl!();\n        }\n\n        pub fn read(&self, _: &mut [u8]) -> io::Result<usize> {\n            unimpl!();\n        }\n\n        pub fn read_vectored(&self, _: &mut [IoSliceMut<'_>]) -> io::Result<usize> {\n            unimpl!();\n        }\n\n        pub fn is_read_vectored(&self) -> bool {\n            unimpl!();\n        }\n\n        pub fn write(&self, _: &[u8]) -> io::Result<usize> {\n            unimpl!();\n        }\n\n        pub fn write_vectored(&self, _: &[IoSlice<'_>]) -> io::Result<usize> {\n            unimpl!();\n        }\n\n        pub fn is_write_vectored(&self) -> bool {\n            unimpl!();\n        }\n\n        pub fn peer_addr(&self) -> io::Result<SocketAddr> {\n            unimpl!();\n        }\n\n        pub fn socket_addr(&self) -> io::Result<SocketAddr> {\n            unimpl!();\n        }\n\n        pub fn shutdown(&self, _: Shutdown) -> io::Result<()> {\n            unimpl!();\n        }\n\n        pub fn duplicate(&self) -> io::Result<TcpStream> {\n            unimpl!();\n        }\n\n        pub fn set_nodelay(&self, _: bool) -> io::Result<()> {\n            unimpl!();\n        }\n\n        pub fn nodelay(&self) -> io::Result<bool> {\n            unimpl!();\n        }\n\n        pub fn set_ttl(&self, _: u32) -> io::Result<()> {\n            unimpl!();\n        }\n\n        pub fn ttl(&self) -> io::Result<u32> {\n            unimpl!();\n        }\n\n        pub fn take_error(&self) -> io::Result<Option<io::Error>> {\n            unimpl!();\n        }\n\n        pub fn set_nonblocking(&self, _: bool) -> io::Result<()> {\n            unimpl!();\n        }\n    }\n\n    impl FromInner<Socket> for TcpStream {\n        fn from_inner(socket: Socket) -> TcpStream {\n            TcpStream { inner: socket }\n        }\n    }\n\n    impl fmt::Debug for TcpStream {\n        fn fmt(&self, f: &mut fmt::Formatter<'_>) -> fmt::Result {\n            write!(f, \"No networking support available on L4Re\")\n        }\n    }\n\n    pub struct TcpListener {\n        inner: Socket,\n    }\n\n    impl TcpListener {\n        pub fn bind(_: io::Result<&SocketAddr>) -> io::Result<TcpListener> {\n            unimpl!();\n        }\n\n        pub fn socket(&self) -> &Socket {\n            &self.inner\n        }\n\n        pub fn into_socket(self) -> Socket {\n            self.inner\n        }\n\n        pub fn socket_addr(&self) -> io::Result<SocketAddr> {\n            unimpl!();\n        }\n\n        pub fn accept(&self) -> io::Result<(TcpStream, SocketAddr)> {\n            unimpl!();\n        }\n\n        pub fn duplicate(&self) -> io::Result<TcpListener> {\n            unimpl!();\n        }\n\n        pub fn set_ttl(&self, _: u32) -> io::Result<()> {\n            unimpl!();\n        }\n\n        pub fn ttl(&self) -> io::Result<u32> {\n            unimpl!();\n        }\n\n        pub fn set_only_v6(&self, _: bool) -> io::Result<()> {\n            unimpl!();\n        }\n\n        pub fn only_v6(&self) -> io::Result<bool> {\n            unimpl!();\n        }\n\n        pub fn take_error(&self) -> io::Result<Option<io::Error>> {\n            unimpl!();\n        }\n\n        pub fn set_nonblocking(&self, _: bool) -> io::Result<()> {\n            unimpl!();\n        }\n    }\n\n    impl FromInner<Socket> for TcpListener {\n        fn from_inner(socket: Socket) -> TcpListener {\n            TcpListener { inner: socket }\n        }\n    }\n\n    impl fmt::Debug for TcpListener {\n        fn fmt(&self, f: &mut fmt::Formatter<'_>) -> fmt::Result {\n            write!(f, \"No networking support available on L4Re.\")\n        }\n    }\n\n    pub struct UdpSocket {\n        inner: Socket,\n    }\n\n    impl UdpSocket {\n        pub fn bind(_: io::Result<&SocketAddr>) -> io::Result<UdpSocket> {\n            unimpl!();\n        }\n\n        pub fn socket(&self) -> &Socket {\n            &self.inner\n        }\n\n        pub fn into_socket(self) -> Socket {\n            self.inner\n        }\n\n        pub fn peer_addr(&self) -> io::Result<SocketAddr> {\n            unimpl!();\n        }\n\n        pub fn socket_addr(&self) -> io::Result<SocketAddr> {\n            unimpl!();\n        }\n\n        pub fn recv_from(&self, _: &mut [u8]) -> io::Result<(usize, SocketAddr)> {\n            unimpl!();\n        }\n\n        pub fn peek_from(&self, _: &mut [u8]) -> io::Result<(usize, SocketAddr)> {\n            unimpl!();\n        }\n\n        pub fn send_to(&self, _: &[u8], _: &SocketAddr) -> io::Result<usize> {\n            unimpl!();\n        }\n\n        pub fn duplicate(&self) -> io::Result<UdpSocket> {\n            unimpl!();\n        }\n\n        pub fn set_read_timeout(&self, _: Option<Duration>) -> io::Result<()> {\n            unimpl!();\n        }\n\n        pub fn set_write_timeout(&self, _: Option<Duration>) -> io::Result<()> {\n            unimpl!();\n        }\n\n        pub fn read_timeout(&self) -> io::Result<Option<Duration>> {\n            unimpl!();\n        }\n\n        pub fn write_timeout(&self) -> io::Result<Option<Duration>> {\n            unimpl!();\n        }\n\n        pub fn set_broadcast(&self, _: bool) -> io::Result<()> {\n            unimpl!();\n        }\n\n        pub fn broadcast(&self) -> io::Result<bool> {\n            unimpl!();\n        }\n\n        pub fn set_multicast_loop_v4(&self, _: bool) -> io::Result<()> {\n            unimpl!();\n        }\n\n        pub fn multicast_loop_v4(&self) -> io::Result<bool> {\n            unimpl!();\n        }\n\n        pub fn set_multicast_ttl_v4(&self, _: u32) -> io::Result<()> {\n            unimpl!();\n        }\n\n        pub fn multicast_ttl_v4(&self) -> io::Result<u32> {\n            unimpl!();\n        }\n\n        pub fn set_multicast_loop_v6(&self, _: bool) -> io::Result<()> {\n            unimpl!();\n        }\n\n        pub fn multicast_loop_v6(&self) -> io::Result<bool> {\n            unimpl!();\n        }\n\n        pub fn join_multicast_v4(&self, _: &Ipv4Addr, _: &Ipv4Addr) -> io::Result<()> {\n            unimpl!();\n        }\n\n        pub fn join_multicast_v6(&self, _: &Ipv6Addr, _: u32) -> io::Result<()> {\n            unimpl!();\n        }\n\n        pub fn leave_multicast_v4(&self, _: &Ipv4Addr, _: &Ipv4Addr) -> io::Result<()> {\n            unimpl!();\n        }\n\n        pub fn leave_multicast_v6(&self, _: &Ipv6Addr, _: u32) -> io::Result<()> {\n            unimpl!();\n        }\n\n        pub fn set_ttl(&self, _: u32) -> io::Result<()> {\n            unimpl!();\n        }\n\n        pub fn ttl(&self) -> io::Result<u32> {\n            unimpl!();\n        }\n\n        pub fn take_error(&self) -> io::Result<Option<io::Error>> {\n            unimpl!();\n        }\n\n        pub fn set_nonblocking(&self, _: bool) -> io::Result<()> {\n            unimpl!();\n        }\n\n        pub fn recv(&self, _: &mut [u8]) -> io::Result<usize> {\n            unimpl!();\n        }\n\n        pub fn peek(&self, _: &mut [u8]) -> io::Result<usize> {\n            unimpl!();\n        }\n\n        pub fn send(&self, _: &[u8]) -> io::Result<usize> {\n            unimpl!();\n        }\n\n        pub fn connect(&self, _: io::Result<&SocketAddr>) -> io::Result<()> {\n            unimpl!();\n        }\n    }\n\n    impl FromInner<Socket> for UdpSocket {\n        fn from_inner(socket: Socket) -> UdpSocket {\n            UdpSocket { inner: socket }\n        }\n    }\n\n    impl fmt::Debug for UdpSocket {\n        fn fmt(&self, f: &mut fmt::Formatter<'_>) -> fmt::Result {\n            write!(f, \"No networking support on L4Re available.\")\n        }\n    }\n\n    pub struct LookupHost {\n        original: *mut libc::addrinfo,\n        cur: *mut libc::addrinfo,\n    }\n\n    impl Iterator for LookupHost {\n        type Item = SocketAddr;\n        fn next(&mut self) -> Option<SocketAddr> {\n            None\n        }\n    }\n\n    impl LookupHost {\n        pub fn port(&self) -> u16 {\n            unimpl!();\n        }\n    }\n\n    unsafe impl Sync for LookupHost {}\n    unsafe impl Send for LookupHost {}\n\n    impl TryFrom<&str> for LookupHost {\n        type Error = io::Error;\n\n        fn try_from(_v: &str) -> io::Result<LookupHost> {\n            unimpl!();\n        }\n    }\n\n    impl<'a> TryFrom<(&'a str, u16)> for LookupHost {\n        type Error = io::Error;\n\n        fn try_from(_v: (&'a str, u16)) -> io::Result<LookupHost> {\n            unimpl!();\n        }\n    }\n}\n"],[2350,"#![cfg(any(\n    target_os = \"linux\",\n    target_os = \"android\",\n    all(target_os = \"emscripten\", target_feature = \"atomics\")\n))]\n\n#[cfg(any(target_os = \"linux\", target_os = \"android\"))]\nuse crate::convert::TryInto;\n#[cfg(any(target_os = \"linux\", target_os = \"android\"))]\nuse crate::ptr::null;\nuse crate::sync::atomic::AtomicI32;\nuse crate::time::Duration;\n\n#[cfg(any(target_os = \"linux\", target_os = \"android\"))]\npub fn futex_wait(futex: &AtomicI32, expected: i32, timeout: Option<Duration>) {\n    let timespec = timeout.and_then(|d| {\n        Some(libc::timespec {\n            // Sleep forever if the timeout is longer than fits in a timespec.\n            tv_sec: d.as_secs().try_into().ok()?,\n            // This conversion never truncates, as subsec_nanos is always <1e9.\n            tv_nsec: d.subsec_nanos() as _,\n        })\n    });\n    unsafe {\n        libc::syscall(\n            libc::SYS_futex,\n            futex as *const AtomicI32,\n            libc::FUTEX_WAIT | libc::FUTEX_PRIVATE_FLAG,\n            expected,\n            timespec.as_ref().map_or(null(), |d| d as *const libc::timespec),\n        );\n    }\n}\n\n#[cfg(target_os = \"emscripten\")]\npub fn futex_wait(futex: &AtomicI32, expected: i32, timeout: Option<Duration>) {\n    extern \"C\" {\n        fn emscripten_futex_wait(\n            addr: *const AtomicI32,\n            val: libc::c_uint,\n            max_wait_ms: libc::c_double,\n        ) -> libc::c_int;\n    }\n\n    unsafe {\n        emscripten_futex_wait(\n            futex as *const AtomicI32,\n            // `val` is declared unsigned to match the Emscripten headers, but since it's used as\n            // an opaque value, we can ignore the meaning of signed vs. unsigned and cast here.\n            expected as libc::c_uint,\n            timeout.map_or(crate::f64::INFINITY, |d| d.as_secs_f64() * 1000.0),\n        );\n    }\n}\n\n#[cfg(any(target_os = \"linux\", target_os = \"android\"))]\npub fn futex_wake(futex: &AtomicI32) {\n    unsafe {\n        libc::syscall(\n            libc::SYS_futex,\n            futex as *const AtomicI32,\n            libc::FUTEX_WAKE | libc::FUTEX_PRIVATE_FLAG,\n            1,\n        );\n    }\n}\n\n#[cfg(target_os = \"emscripten\")]\npub fn futex_wake(futex: &AtomicI32) {\n    extern \"C\" {\n        fn emscripten_futex_wake(addr: *const AtomicI32, count: libc::c_int) -> libc::c_int;\n    }\n\n    unsafe {\n        emscripten_futex_wake(futex as *const AtomicI32, 1);\n    }\n}\n"],[2351,"use crate::fs::OpenOptions;\nuse crate::io;\nuse crate::io::Result;\nuse crate::io::SeekFrom;\nuse crate::io::{BufRead, Read, Seek, Write};\nuse crate::os::unix::io::AsRawFd;\nuse crate::sys_common::io::test::tmpdir;\n\n#[test]\nfn copy_specialization() -> Result<()> {\n    use crate::io::{BufReader, BufWriter};\n\n    let tmp_path = tmpdir();\n    let source_path = tmp_path.join(\"copy-spec.source\");\n    let sink_path = tmp_path.join(\"copy-spec.sink\");\n\n    let result: Result<()> = try {\n        let mut source = crate::fs::OpenOptions::new()\n            .read(true)\n            .write(true)\n            .create(true)\n            .truncate(true)\n            .open(&source_path)?;\n        source.write_all(b\"abcdefghiklmnopqr\")?;\n        source.seek(SeekFrom::Start(8))?;\n        let mut source = BufReader::with_capacity(8, source.take(5));\n        source.fill_buf()?;\n        assert_eq!(source.buffer(), b\"iklmn\");\n        source.get_mut().set_limit(6);\n        source.get_mut().get_mut().seek(SeekFrom::Start(1))?; // \"bcdefg\"\n        let mut source = source.take(10); // \"iklmnbcdef\"\n\n        let mut sink = crate::fs::OpenOptions::new()\n            .read(true)\n            .write(true)\n            .create(true)\n            .truncate(true)\n            .open(&sink_path)?;\n        sink.write_all(b\"000000\")?;\n        let mut sink = BufWriter::with_capacity(5, sink);\n        sink.write_all(b\"wxyz\")?;\n        assert_eq!(sink.buffer(), b\"wxyz\");\n\n        let copied = crate::io::copy(&mut source, &mut sink)?;\n        assert_eq!(copied, 10, \"copy obeyed limit imposed by Take\");\n        assert_eq!(sink.buffer().len(), 0, \"sink buffer was flushed\");\n        assert_eq!(source.limit(), 0, \"outer Take was exhausted\");\n        assert_eq!(source.get_ref().buffer().len(), 0, \"source buffer should be drained\");\n        assert_eq!(\n            source.get_ref().get_ref().limit(),\n            1,\n            \"inner Take allowed reading beyond end of file, some bytes should be left\"\n        );\n\n        let mut sink = sink.into_inner()?;\n        sink.seek(SeekFrom::Start(0))?;\n        let mut copied = Vec::new();\n        sink.read_to_end(&mut copied)?;\n        assert_eq!(&copied, b\"000000wxyziklmnbcdef\");\n    };\n\n    let rm1 = crate::fs::remove_file(source_path);\n    let rm2 = crate::fs::remove_file(sink_path);\n\n    result.and(rm1).and(rm2)\n}\n\n#[test]\nfn copies_append_mode_sink() -> Result<()> {\n    let tmp_path = tmpdir();\n    let source_path = tmp_path.join(\"copies_append_mode.source\");\n    let sink_path = tmp_path.join(\"copies_append_mode.sink\");\n    let mut source =\n        OpenOptions::new().create(true).truncate(true).write(true).read(true).open(&source_path)?;\n    write!(source, \"not empty\")?;\n    source.seek(SeekFrom::Start(0))?;\n    let mut sink = OpenOptions::new().create(true).append(true).open(&sink_path)?;\n\n    let copied = crate::io::copy(&mut source, &mut sink)?;\n\n    assert_eq!(copied, 9);\n\n    Ok(())\n}\n\n#[bench]\nfn bench_file_to_file_copy(b: &mut test::Bencher) {\n    const BYTES: usize = 128 * 1024;\n    let temp_path = tmpdir();\n    let src_path = temp_path.join(\"file-copy-bench-src\");\n    let mut src = crate::fs::OpenOptions::new()\n        .create(true)\n        .truncate(true)\n        .read(true)\n        .write(true)\n        .open(src_path)\n        .unwrap();\n    src.write(&vec![0u8; BYTES]).unwrap();\n\n    let sink_path = temp_path.join(\"file-copy-bench-sink\");\n    let mut sink = crate::fs::OpenOptions::new()\n        .create(true)\n        .truncate(true)\n        .write(true)\n        .open(sink_path)\n        .unwrap();\n\n    b.bytes = BYTES as u64;\n    b.iter(|| {\n        src.seek(SeekFrom::Start(0)).unwrap();\n        sink.seek(SeekFrom::Start(0)).unwrap();\n        assert_eq!(BYTES as u64, io::copy(&mut src, &mut sink).unwrap());\n    });\n}\n\n#[bench]\nfn bench_file_to_socket_copy(b: &mut test::Bencher) {\n    const BYTES: usize = 128 * 1024;\n    let temp_path = tmpdir();\n    let src_path = temp_path.join(\"pipe-copy-bench-src\");\n    let mut src = OpenOptions::new()\n        .create(true)\n        .truncate(true)\n        .read(true)\n        .write(true)\n        .open(src_path)\n        .unwrap();\n    src.write(&vec![0u8; BYTES]).unwrap();\n\n    let sink_drainer = crate::net::TcpListener::bind(\"localhost:0\").unwrap();\n    let mut sink = crate::net::TcpStream::connect(sink_drainer.local_addr().unwrap()).unwrap();\n    let mut sink_drainer = sink_drainer.accept().unwrap().0;\n\n    crate::thread::spawn(move || {\n        let mut sink_buf = vec![0u8; 1024 * 1024];\n        loop {\n            sink_drainer.read(&mut sink_buf[..]).unwrap();\n        }\n    });\n\n    b.bytes = BYTES as u64;\n    b.iter(|| {\n        src.seek(SeekFrom::Start(0)).unwrap();\n        assert_eq!(BYTES as u64, io::copy(&mut src, &mut sink).unwrap());\n    });\n}\n\n#[bench]\nfn bench_file_to_uds_copy(b: &mut test::Bencher) {\n    const BYTES: usize = 128 * 1024;\n    let temp_path = tmpdir();\n    let src_path = temp_path.join(\"uds-copy-bench-src\");\n    let mut src = OpenOptions::new()\n        .create(true)\n        .truncate(true)\n        .read(true)\n        .write(true)\n        .open(src_path)\n        .unwrap();\n    src.write(&vec![0u8; BYTES]).unwrap();\n\n    let (mut sink, mut sink_drainer) = crate::os::unix::net::UnixStream::pair().unwrap();\n\n    crate::thread::spawn(move || {\n        let mut sink_buf = vec![0u8; 1024 * 1024];\n        loop {\n            sink_drainer.read(&mut sink_buf[..]).unwrap();\n        }\n    });\n\n    b.bytes = BYTES as u64;\n    b.iter(|| {\n        src.seek(SeekFrom::Start(0)).unwrap();\n        assert_eq!(BYTES as u64, io::copy(&mut src, &mut sink).unwrap());\n    });\n}\n\n#[cfg(any(target_os = \"linux\", target_os = \"android\"))]\n#[bench]\nfn bench_socket_pipe_socket_copy(b: &mut test::Bencher) {\n    use super::CopyResult;\n    use crate::io::ErrorKind;\n    use crate::process::{ChildStdin, ChildStdout};\n    use crate::sys_common::FromInner;\n\n    let (read_end, write_end) = crate::sys::pipe::anon_pipe().unwrap();\n\n    let mut read_end = ChildStdout::from_inner(read_end);\n    let write_end = ChildStdin::from_inner(write_end);\n\n    let acceptor = crate::net::TcpListener::bind(\"localhost:0\").unwrap();\n    let mut remote_end = crate::net::TcpStream::connect(acceptor.local_addr().unwrap()).unwrap();\n\n    let local_end = crate::sync::Arc::new(acceptor.accept().unwrap().0);\n\n    // the data flow in this benchmark:\n    //\n    //                      socket(tx)  local_source\n    // remote_end (write)  +-------->   (splice to)\n    //                                  write_end\n    //                                     +\n    //                                     |\n    //                                     | pipe\n    //                                     v\n    //                                  read_end\n    // remote_end (read)   <---------+  (splice to) *\n    //                      socket(rx)  local_end\n    //\n    // * benchmark loop using io::copy\n\n    crate::thread::spawn(move || {\n        let mut sink_buf = vec![0u8; 1024 * 1024];\n        remote_end.set_nonblocking(true).unwrap();\n        loop {\n            match remote_end.write(&mut sink_buf[..]) {\n                Err(err) if err.kind() == ErrorKind::WouldBlock => {}\n                Ok(_) => {}\n                err => {\n                    err.expect(\"write failed\");\n                }\n            };\n            match remote_end.read(&mut sink_buf[..]) {\n                Err(err) if err.kind() == ErrorKind::WouldBlock => {}\n                Ok(_) => {}\n                err => {\n                    err.expect(\"read failed\");\n                }\n            };\n        }\n    });\n\n    // check that splice works, otherwise the benchmark would hang\n    let probe = super::sendfile_splice(\n        super::SpliceMode::Splice,\n        local_end.as_raw_fd(),\n        write_end.as_raw_fd(),\n        1,\n    );\n\n    match probe {\n        CopyResult::Ended(1) => {\n            // splice works\n        }\n        _ => {\n            eprintln!(\"splice failed, skipping benchmark\");\n            return;\n        }\n    }\n\n    let local_source = local_end.clone();\n    crate::thread::spawn(move || {\n        loop {\n            super::sendfile_splice(\n                super::SpliceMode::Splice,\n                local_source.as_raw_fd(),\n                write_end.as_raw_fd(),\n                u64::MAX,\n            );\n        }\n    });\n\n    const BYTES: usize = 128 * 1024;\n    b.bytes = BYTES as u64;\n    b.iter(|| {\n        assert_eq!(\n            BYTES as u64,\n            io::copy(&mut (&mut read_end).take(BYTES as u64), &mut &*local_end).unwrap()\n        );\n    });\n}\n"],[2352,"use crate::mem;\nuse crate::slice;\n\npub fn hashmap_random_keys() -> (u64, u64) {\n    let mut v = (0, 0);\n    unsafe {\n        let view = slice::from_raw_parts_mut(&mut v as *mut _ as *mut u8, mem::size_of_val(&v));\n        imp::fill_bytes(view);\n    }\n    v\n}\n\n#[cfg(all(\n    unix,\n    not(target_os = \"macos\"),\n    not(target_os = \"ios\"),\n    not(target_os = \"openbsd\"),\n    not(target_os = \"freebsd\"),\n    not(target_os = \"netbsd\"),\n    not(target_os = \"fuchsia\"),\n    not(target_os = \"redox\"),\n    not(target_os = \"vxworks\")\n))]\nmod imp {\n    use crate::fs::File;\n    use crate::io::Read;\n\n    #[cfg(any(target_os = \"linux\", target_os = \"android\"))]\n    fn getrandom(buf: &mut [u8]) -> libc::ssize_t {\n        // A weak symbol allows interposition, e.g. for perf measurements that want to\n        // disable randomness for consistency. Otherwise, we'll try a raw syscall.\n        // (`getrandom` was added in glibc 2.25, musl 1.1.20, android API level 28)\n        syscall! {\n            fn getrandom(\n                buffer: *mut libc::c_void,\n                length: libc::size_t,\n                flags: libc::c_uint\n            ) -> libc::ssize_t\n        }\n\n        unsafe { getrandom(buf.as_mut_ptr().cast(), buf.len(), libc::GRND_NONBLOCK) }\n    }\n\n    #[cfg(not(any(target_os = \"linux\", target_os = \"android\")))]\n    fn getrandom_fill_bytes(_buf: &mut [u8]) -> bool {\n        false\n    }\n\n    #[cfg(any(target_os = \"linux\", target_os = \"android\"))]\n    fn getrandom_fill_bytes(v: &mut [u8]) -> bool {\n        use crate::sync::atomic::{AtomicBool, Ordering};\n        use crate::sys::os::errno;\n\n        static GETRANDOM_UNAVAILABLE: AtomicBool = AtomicBool::new(false);\n        if GETRANDOM_UNAVAILABLE.load(Ordering::Relaxed) {\n            return false;\n        }\n\n        let mut read = 0;\n        while read < v.len() {\n            let result = getrandom(&mut v[read..]);\n            if result == -1 {\n                let err = errno() as libc::c_int;\n                if err == libc::EINTR {\n                    continue;\n                } else if err == libc::ENOSYS || err == libc::EPERM {\n                    // Fall back to reading /dev/urandom if `getrandom` is not\n                    // supported on the current kernel.\n                    //\n                    // Also fall back in case it is disabled by something like\n                    // seccomp or inside of virtual machines.\n                    GETRANDOM_UNAVAILABLE.store(true, Ordering::Relaxed);\n                    return false;\n                } else if err == libc::EAGAIN {\n                    return false;\n                } else {\n                    panic!(\"unexpected getrandom error: {}\", err);\n                }\n            } else {\n                read += result as usize;\n            }\n        }\n        true\n    }\n\n    pub fn fill_bytes(v: &mut [u8]) {\n        // getrandom_fill_bytes here can fail if getrandom() returns EAGAIN,\n        // meaning it would have blocked because the non-blocking pool (urandom)\n        // has not initialized in the kernel yet due to a lack of entropy. The\n        // fallback we do here is to avoid blocking applications which could\n        // depend on this call without ever knowing they do and don't have a\n        // work around. The PRNG of /dev/urandom will still be used but over a\n        // possibly predictable entropy pool.\n        if getrandom_fill_bytes(v) {\n            return;\n        }\n\n        // getrandom failed because it is permanently or temporarily (because\n        // of missing entropy) unavailable. Open /dev/urandom, read from it,\n        // and close it again.\n        let mut file = File::open(\"/dev/urandom\").expect(\"failed to open /dev/urandom\");\n        file.read_exact(v).expect(\"failed to read /dev/urandom\")\n    }\n}\n\n#[cfg(target_os = \"macos\")]\nmod imp {\n    use crate::fs::File;\n    use crate::io::Read;\n    use crate::sys::os::errno;\n    use libc::{c_int, c_void, size_t};\n\n    fn getentropy_fill_bytes(v: &mut [u8]) -> bool {\n        weak!(fn getentropy(*mut c_void, size_t) -> c_int);\n\n        getentropy\n            .get()\n            .map(|f| {\n                // getentropy(2) permits a maximum buffer size of 256 bytes\n                for s in v.chunks_mut(256) {\n                    let ret = unsafe { f(s.as_mut_ptr() as *mut c_void, s.len()) };\n                    if ret == -1 {\n                        panic!(\"unexpected getentropy error: {}\", errno());\n                    }\n                }\n                true\n            })\n            .unwrap_or(false)\n    }\n\n    pub fn fill_bytes(v: &mut [u8]) {\n        if getentropy_fill_bytes(v) {\n            return;\n        }\n\n        // for older macos which doesn't support getentropy\n        let mut file = File::open(\"/dev/urandom\").expect(\"failed to open /dev/urandom\");\n        file.read_exact(v).expect(\"failed to read /dev/urandom\")\n    }\n}\n\n#[cfg(target_os = \"openbsd\")]\nmod imp {\n    use crate::sys::os::errno;\n\n    pub fn fill_bytes(v: &mut [u8]) {\n        // getentropy(2) permits a maximum buffer size of 256 bytes\n        for s in v.chunks_mut(256) {\n            let ret = unsafe { libc::getentropy(s.as_mut_ptr() as *mut libc::c_void, s.len()) };\n            if ret == -1 {\n                panic!(\"unexpected getentropy error: {}\", errno());\n            }\n        }\n    }\n}\n\n// On iOS and MacOS `SecRandomCopyBytes` calls `CCRandomCopyBytes` with\n// `kCCRandomDefault`. `CCRandomCopyBytes` manages a CSPRNG which is seeded\n// from `/dev/random` and which runs on its own thread accessed via GCD.\n// This seems needlessly heavyweight for the purposes of generating two u64s\n// once per thread in `hashmap_random_keys`. Therefore `SecRandomCopyBytes` is\n// only used on iOS where direct access to `/dev/urandom` is blocked by the\n// sandbox.\n#[cfg(target_os = \"ios\")]\nmod imp {\n    use crate::io;\n    use crate::ptr;\n    use libc::{c_int, size_t};\n\n    enum SecRandom {}\n\n    #[allow(non_upper_case_globals)]\n    const kSecRandomDefault: *const SecRandom = ptr::null();\n\n    extern \"C\" {\n        fn SecRandomCopyBytes(rnd: *const SecRandom, count: size_t, bytes: *mut u8) -> c_int;\n    }\n\n    pub fn fill_bytes(v: &mut [u8]) {\n        let ret = unsafe { SecRandomCopyBytes(kSecRandomDefault, v.len(), v.as_mut_ptr()) };\n        if ret == -1 {\n            panic!(\"couldn't generate random bytes: {}\", io::Error::last_os_error());\n        }\n    }\n}\n\n#[cfg(any(target_os = \"freebsd\", target_os = \"netbsd\"))]\nmod imp {\n    use crate::ptr;\n\n    pub fn fill_bytes(v: &mut [u8]) {\n        let mib = [libc::CTL_KERN, libc::KERN_ARND];\n        // kern.arandom permits a maximum buffer size of 256 bytes\n        for s in v.chunks_mut(256) {\n            let mut s_len = s.len();\n            let ret = unsafe {\n                libc::sysctl(\n                    mib.as_ptr(),\n                    mib.len() as libc::c_uint,\n                    s.as_mut_ptr() as *mut _,\n                    &mut s_len,\n                    ptr::null(),\n                    0,\n                )\n            };\n            if ret == -1 || s_len != s.len() {\n                panic!(\n                    \"kern.arandom sysctl failed! (returned {}, s.len() {}, oldlenp {})\",\n                    ret,\n                    s.len(),\n                    s_len\n                );\n            }\n        }\n    }\n}\n\n#[cfg(target_os = \"fuchsia\")]\nmod imp {\n    #[link(name = \"zircon\")]\n    extern \"C\" {\n        fn zx_cprng_draw(buffer: *mut u8, len: usize);\n    }\n\n    pub fn fill_bytes(v: &mut [u8]) {\n        unsafe { zx_cprng_draw(v.as_mut_ptr(), v.len()) }\n    }\n}\n\n#[cfg(target_os = \"redox\")]\nmod imp {\n    use crate::fs::File;\n    use crate::io::Read;\n\n    pub fn fill_bytes(v: &mut [u8]) {\n        // Open rand:, read from it, and close it again.\n        let mut file = File::open(\"rand:\").expect(\"failed to open rand:\");\n        file.read_exact(v).expect(\"failed to read rand:\")\n    }\n}\n\n#[cfg(target_os = \"vxworks\")]\nmod imp {\n    use crate::io;\n    use core::sync::atomic::{AtomicBool, Ordering::Relaxed};\n\n    pub fn fill_bytes(v: &mut [u8]) {\n        static RNG_INIT: AtomicBool = AtomicBool::new(false);\n        while !RNG_INIT.load(Relaxed) {\n            let ret = unsafe { libc::randSecure() };\n            if ret < 0 {\n                panic!(\"couldn't generate random bytes: {}\", io::Error::last_os_error());\n            } else if ret > 0 {\n                RNG_INIT.store(true, Relaxed);\n                break;\n            }\n            unsafe { libc::usleep(10) };\n        }\n        let ret = unsafe {\n            libc::randABytes(v.as_mut_ptr() as *mut libc::c_uchar, v.len() as libc::c_int)\n        };\n        if ret < 0 {\n            panic!(\"couldn't generate random bytes: {}\", io::Error::last_os_error());\n        }\n    }\n}\n"],[2353,"use super::{FileDesc, IoSlice};\nuse core::mem::ManuallyDrop;\n\n#[test]\nfn limit_vector_count() {\n    let stdout = ManuallyDrop::new(unsafe { FileDesc { fd: 1 } });\n    let bufs = (0..1500).map(|_| IoSlice::new(&[])).collect::<Vec<_>>();\n    assert!(stdout.write_vectored(&bufs).is_ok());\n}\n"],[2354,"use super::*;\n\n#[test]\nfn test_glibc_version() {\n    // This mostly just tests that the weak linkage doesn't panic wildly...\n    glibc_version();\n}\n\n#[test]\nfn test_parse_glibc_version() {\n    let cases = [\n        (\"0.0\", Some((0, 0))),\n        (\"01.+2\", Some((1, 2))),\n        (\"3.4.5.six\", Some((3, 4))),\n        (\"1\", None),\n        (\"1.-2\", None),\n        (\"1.foo\", None),\n        (\"foo.1\", None),\n    ];\n    for &(version_str, parsed) in cases.iter() {\n        assert_eq!(parsed, parse_glibc_version(version_str));\n    }\n}\n"],[2355,"use crate::cmp;\nuse crate::ffi::CStr;\nuse crate::io;\nuse crate::mem;\nuse crate::num::NonZeroUsize;\nuse crate::ptr;\nuse crate::sys::{os, stack_overflow};\nuse crate::time::Duration;\n\n#[cfg(not(any(target_os = \"l4re\", target_os = \"vxworks\")))]\npub const DEFAULT_MIN_STACK_SIZE: usize = 2 * 1024 * 1024;\n#[cfg(target_os = \"l4re\")]\npub const DEFAULT_MIN_STACK_SIZE: usize = 1024 * 1024;\n#[cfg(target_os = \"vxworks\")]\npub const DEFAULT_MIN_STACK_SIZE: usize = 256 * 1024;\n\npub struct Thread {\n    id: libc::pthread_t,\n}\n\n// Some platforms may have pthread_t as a pointer in which case we still want\n// a thread to be Send/Sync\nunsafe impl Send for Thread {}\nunsafe impl Sync for Thread {}\n\nimpl Thread {\n    // unsafe: see thread::Builder::spawn_unchecked for safety requirements\n    pub unsafe fn new(stack: usize, p: Box<dyn FnOnce()>) -> io::Result<Thread> {\n        let p = Box::into_raw(box p);\n        let mut native: libc::pthread_t = mem::zeroed();\n        let mut attr: libc::pthread_attr_t = mem::zeroed();\n        assert_eq!(libc::pthread_attr_init(&mut attr), 0);\n\n        let stack_size = cmp::max(stack, min_stack_size(&attr));\n\n        match libc::pthread_attr_setstacksize(&mut attr, stack_size) {\n            0 => {}\n            n => {\n                assert_eq!(n, libc::EINVAL);\n                // EINVAL means |stack_size| is either too small or not a\n                // multiple of the system page size.  Because it's definitely\n                // >= PTHREAD_STACK_MIN, it must be an alignment issue.\n                // Round up to the nearest page and try again.\n                let page_size = os::page_size();\n                let stack_size =\n                    (stack_size + page_size - 1) & (-(page_size as isize - 1) as usize - 1);\n                assert_eq!(libc::pthread_attr_setstacksize(&mut attr, stack_size), 0);\n            }\n        };\n\n        let ret = libc::pthread_create(&mut native, &attr, thread_start, p as *mut _);\n        // Note: if the thread creation fails and this assert fails, then p will\n        // be leaked. However, an alternative design could cause double-free\n        // which is clearly worse.\n        assert_eq!(libc::pthread_attr_destroy(&mut attr), 0);\n\n        return if ret != 0 {\n            // The thread failed to start and as a result p was not consumed. Therefore, it is\n            // safe to reconstruct the box so that it gets deallocated.\n            drop(Box::from_raw(p));\n            Err(io::Error::from_raw_os_error(ret))\n        } else {\n            Ok(Thread { id: native })\n        };\n\n        extern \"C\" fn thread_start(main: *mut libc::c_void) -> *mut libc::c_void {\n            unsafe {\n                // Next, set up our stack overflow handler which may get triggered if we run\n                // out of stack.\n                let _handler = stack_overflow::Handler::new();\n                // Finally, let's run some code.\n                Box::from_raw(main as *mut Box<dyn FnOnce()>)();\n            }\n            ptr::null_mut()\n        }\n    }\n\n    pub fn yield_now() {\n        let ret = unsafe { libc::sched_yield() };\n        debug_assert_eq!(ret, 0);\n    }\n\n    #[cfg(any(target_os = \"linux\", target_os = \"android\"))]\n    pub fn set_name(name: &CStr) {\n        const PR_SET_NAME: libc::c_int = 15;\n        // pthread wrapper only appeared in glibc 2.12, so we use syscall\n        // directly.\n        unsafe {\n            libc::prctl(PR_SET_NAME, name.as_ptr() as libc::c_ulong, 0, 0, 0);\n        }\n    }\n\n    #[cfg(any(target_os = \"freebsd\", target_os = \"dragonfly\", target_os = \"openbsd\"))]\n    pub fn set_name(name: &CStr) {\n        unsafe {\n            libc::pthread_set_name_np(libc::pthread_self(), name.as_ptr());\n        }\n    }\n\n    #[cfg(any(target_os = \"macos\", target_os = \"ios\"))]\n    pub fn set_name(name: &CStr) {\n        unsafe {\n            libc::pthread_setname_np(name.as_ptr());\n        }\n    }\n\n    #[cfg(target_os = \"netbsd\")]\n    pub fn set_name(name: &CStr) {\n        use crate::ffi::CString;\n        let cname = CString::new(&b\"%s\"[..]).unwrap();\n        unsafe {\n            libc::pthread_setname_np(\n                libc::pthread_self(),\n                cname.as_ptr(),\n                name.as_ptr() as *mut libc::c_void,\n            );\n        }\n    }\n\n    #[cfg(any(target_os = \"solaris\", target_os = \"illumos\"))]\n    pub fn set_name(name: &CStr) {\n        weak! {\n            fn pthread_setname_np(\n                libc::pthread_t, *const libc::c_char\n            ) -> libc::c_int\n        }\n\n        if let Some(f) = pthread_setname_np.get() {\n            unsafe {\n                f(libc::pthread_self(), name.as_ptr());\n            }\n        }\n    }\n\n    #[cfg(any(\n        target_env = \"newlib\",\n        target_os = \"haiku\",\n        target_os = \"l4re\",\n        target_os = \"emscripten\",\n        target_os = \"redox\",\n        target_os = \"vxworks\"\n    ))]\n    pub fn set_name(_name: &CStr) {\n        // Newlib, Haiku, Emscripten, and VxWorks have no way to set a thread name.\n    }\n    #[cfg(target_os = \"fuchsia\")]\n    pub fn set_name(_name: &CStr) {\n        // FIXME: determine whether Fuchsia has a way to set a thread name.\n    }\n\n    pub fn sleep(dur: Duration) {\n        let mut secs = dur.as_secs();\n        let mut nsecs = dur.subsec_nanos() as _;\n\n        // If we're awoken with a signal then the return value will be -1 and\n        // nanosleep will fill in `ts` with the remaining time.\n        unsafe {\n            while secs > 0 || nsecs > 0 {\n                let mut ts = libc::timespec {\n                    tv_sec: cmp::min(libc::time_t::MAX as u64, secs) as libc::time_t,\n                    tv_nsec: nsecs,\n                };\n                secs -= ts.tv_sec as u64;\n                let ts_ptr = &mut ts as *mut _;\n                if libc::nanosleep(ts_ptr, ts_ptr) == -1 {\n                    assert_eq!(os::errno(), libc::EINTR);\n                    secs += ts.tv_sec as u64;\n                    nsecs = ts.tv_nsec;\n                } else {\n                    nsecs = 0;\n                }\n            }\n        }\n    }\n\n    pub fn join(self) {\n        unsafe {\n            let ret = libc::pthread_join(self.id, ptr::null_mut());\n            mem::forget(self);\n            assert!(ret == 0, \"failed to join thread: {}\", io::Error::from_raw_os_error(ret));\n        }\n    }\n\n    pub fn id(&self) -> libc::pthread_t {\n        self.id\n    }\n\n    pub fn into_id(self) -> libc::pthread_t {\n        let id = self.id;\n        mem::forget(self);\n        id\n    }\n}\n\nimpl Drop for Thread {\n    fn drop(&mut self) {\n        let ret = unsafe { libc::pthread_detach(self.id) };\n        debug_assert_eq!(ret, 0);\n    }\n}\n\npub fn available_concurrency() -> io::Result<NonZeroUsize> {\n    cfg_if::cfg_if! {\n        if #[cfg(any(\n            target_os = \"android\",\n            target_os = \"emscripten\",\n            target_os = \"fuchsia\",\n            target_os = \"ios\",\n            target_os = \"linux\",\n            target_os = \"macos\",\n            target_os = \"solaris\",\n            target_os = \"illumos\",\n        ))] {\n            match unsafe { libc::sysconf(libc::_SC_NPROCESSORS_ONLN) } {\n                -1 => Err(io::Error::last_os_error()),\n                0 => Err(io::Error::new_const(io::ErrorKind::NotFound, &\"The number of hardware threads is not known for the target platform\")),\n                cpus => Ok(unsafe { NonZeroUsize::new_unchecked(cpus as usize) }),\n            }\n        } else if #[cfg(any(target_os = \"freebsd\", target_os = \"dragonfly\", target_os = \"netbsd\"))] {\n            use crate::ptr;\n\n            let mut cpus: libc::c_uint = 0;\n            let mut cpus_size = crate::mem::size_of_val(&cpus);\n\n            unsafe {\n                cpus = libc::sysconf(libc::_SC_NPROCESSORS_ONLN) as libc::c_uint;\n            }\n\n            // Fallback approach in case of errors or no hardware threads.\n            if cpus < 1 {\n                let mut mib = [libc::CTL_HW, libc::HW_NCPU, 0, 0];\n                let res = unsafe {\n                    libc::sysctl(\n                        mib.as_mut_ptr(),\n                        2,\n                        &mut cpus as *mut _ as *mut _,\n                        &mut cpus_size as *mut _ as *mut _,\n                        ptr::null_mut(),\n                        0,\n                    )\n                };\n\n                // Handle errors if any.\n                if res == -1 {\n                    return Err(io::Error::last_os_error());\n                } else if cpus == 0 {\n                    return Err(io::Error::new_const(io::ErrorKind::NotFound, &\"The number of hardware threads is not known for the target platform\"));\n                }\n            }\n            Ok(unsafe { NonZeroUsize::new_unchecked(cpus as usize) })\n        } else if #[cfg(target_os = \"openbsd\")] {\n            use crate::ptr;\n\n            let mut cpus: libc::c_uint = 0;\n            let mut cpus_size = crate::mem::size_of_val(&cpus);\n            let mut mib = [libc::CTL_HW, libc::HW_NCPU, 0, 0];\n\n            let res = unsafe {\n                libc::sysctl(\n                    mib.as_mut_ptr(),\n                    2,\n                    &mut cpus as *mut _ as *mut _,\n                    &mut cpus_size as *mut _ as *mut _,\n                    ptr::null_mut(),\n                    0,\n                )\n            };\n\n            // Handle errors if any.\n            if res == -1 {\n                return Err(io::Error::last_os_error());\n            } else if cpus == 0 {\n                return Err(io::Error::new_const(io::ErrorKind::NotFound, &\"The number of hardware threads is not known for the target platform\"));\n            }\n\n            Ok(unsafe { NonZeroUsize::new_unchecked(cpus as usize) })\n        } else {\n            // FIXME: implement on vxWorks, Redox, Haiku, l4re\n            Err(io::Error::new_const(io::ErrorKind::Unsupported, &\"Getting the number of hardware threads is not supported on the target platform\"))\n        }\n    }\n}\n\n#[cfg(all(\n    not(target_os = \"linux\"),\n    not(target_os = \"freebsd\"),\n    not(target_os = \"macos\"),\n    not(target_os = \"netbsd\"),\n    not(target_os = \"openbsd\"),\n    not(target_os = \"solaris\")\n))]\n#[cfg_attr(test, allow(dead_code))]\npub mod guard {\n    use crate::ops::Range;\n    pub type Guard = Range<usize>;\n    pub unsafe fn current() -> Option<Guard> {\n        None\n    }\n    pub unsafe fn init() -> Option<Guard> {\n        None\n    }\n}\n\n#[cfg(any(\n    target_os = \"linux\",\n    target_os = \"freebsd\",\n    target_os = \"macos\",\n    target_os = \"netbsd\",\n    target_os = \"openbsd\",\n    target_os = \"solaris\"\n))]\n#[cfg_attr(test, allow(dead_code))]\npub mod guard {\n    use libc::{mmap, mprotect};\n    use libc::{MAP_ANON, MAP_FAILED, MAP_FIXED, MAP_PRIVATE, PROT_NONE, PROT_READ, PROT_WRITE};\n\n    use crate::io;\n    use crate::ops::Range;\n    use crate::sync::atomic::{AtomicUsize, Ordering};\n    use crate::sys::os;\n\n    // This is initialized in init() and only read from after\n    static PAGE_SIZE: AtomicUsize = AtomicUsize::new(0);\n\n    pub type Guard = Range<usize>;\n\n    #[cfg(target_os = \"solaris\")]\n    unsafe fn get_stack_start() -> Option<*mut libc::c_void> {\n        let mut current_stack: libc::stack_t = crate::mem::zeroed();\n        assert_eq!(libc::stack_getbounds(&mut current_stack), 0);\n        Some(current_stack.ss_sp)\n    }\n\n    #[cfg(target_os = \"macos\")]\n    unsafe fn get_stack_start() -> Option<*mut libc::c_void> {\n        let th = libc::pthread_self();\n        let stackaddr =\n            libc::pthread_get_stackaddr_np(th) as usize - libc::pthread_get_stacksize_np(th);\n        Some(stackaddr as *mut libc::c_void)\n    }\n\n    #[cfg(target_os = \"openbsd\")]\n    unsafe fn get_stack_start() -> Option<*mut libc::c_void> {\n        let mut current_stack: libc::stack_t = crate::mem::zeroed();\n        assert_eq!(libc::pthread_stackseg_np(libc::pthread_self(), &mut current_stack), 0);\n\n        let stackaddr = if libc::pthread_main_np() == 1 {\n            // main thread\n            current_stack.ss_sp as usize - current_stack.ss_size + PAGE_SIZE.load(Ordering::Relaxed)\n        } else {\n            // new thread\n            current_stack.ss_sp as usize - current_stack.ss_size\n        };\n        Some(stackaddr as *mut libc::c_void)\n    }\n\n    #[cfg(any(\n        target_os = \"android\",\n        target_os = \"freebsd\",\n        target_os = \"linux\",\n        target_os = \"netbsd\",\n        target_os = \"l4re\"\n    ))]\n    unsafe fn get_stack_start() -> Option<*mut libc::c_void> {\n        let mut ret = None;\n        let mut attr: libc::pthread_attr_t = crate::mem::zeroed();\n        #[cfg(target_os = \"freebsd\")]\n        assert_eq!(libc::pthread_attr_init(&mut attr), 0);\n        #[cfg(target_os = \"freebsd\")]\n        let e = libc::pthread_attr_get_np(libc::pthread_self(), &mut attr);\n        #[cfg(not(target_os = \"freebsd\"))]\n        let e = libc::pthread_getattr_np(libc::pthread_self(), &mut attr);\n        if e == 0 {\n            let mut stackaddr = crate::ptr::null_mut();\n            let mut stacksize = 0;\n            assert_eq!(libc::pthread_attr_getstack(&attr, &mut stackaddr, &mut stacksize), 0);\n            ret = Some(stackaddr);\n        }\n        if e == 0 || cfg!(target_os = \"freebsd\") {\n            assert_eq!(libc::pthread_attr_destroy(&mut attr), 0);\n        }\n        ret\n    }\n\n    // Precondition: PAGE_SIZE is initialized.\n    unsafe fn get_stack_start_aligned() -> Option<*mut libc::c_void> {\n        let page_size = PAGE_SIZE.load(Ordering::Relaxed);\n        assert!(page_size != 0);\n        let stackaddr = get_stack_start()?;\n\n        // Ensure stackaddr is page aligned! A parent process might\n        // have reset RLIMIT_STACK to be non-page aligned. The\n        // pthread_attr_getstack() reports the usable stack area\n        // stackaddr < stackaddr + stacksize, so if stackaddr is not\n        // page-aligned, calculate the fix such that stackaddr <\n        // new_page_aligned_stackaddr < stackaddr + stacksize\n        let remainder = (stackaddr as usize) % page_size;\n        Some(if remainder == 0 {\n            stackaddr\n        } else {\n            ((stackaddr as usize) + page_size - remainder) as *mut libc::c_void\n        })\n    }\n\n    pub unsafe fn init() -> Option<Guard> {\n        let page_size = os::page_size();\n        PAGE_SIZE.store(page_size, Ordering::Relaxed);\n\n        if cfg!(all(target_os = \"linux\", not(target_env = \"musl\"))) {\n            // Linux doesn't allocate the whole stack right away, and\n            // the kernel has its own stack-guard mechanism to fault\n            // when growing too close to an existing mapping.  If we map\n            // our own guard, then the kernel starts enforcing a rather\n            // large gap above that, rendering much of the possible\n            // stack space useless.  See #43052.\n            //\n            // Instead, we'll just note where we expect rlimit to start\n            // faulting, so our handler can report \"stack overflow\", and\n            // trust that the kernel's own stack guard will work.\n            let stackaddr = get_stack_start_aligned()?;\n            let stackaddr = stackaddr as usize;\n            Some(stackaddr - page_size..stackaddr)\n        } else if cfg!(all(target_os = \"linux\", target_env = \"musl\")) {\n            // For the main thread, the musl's pthread_attr_getstack\n            // returns the current stack size, rather than maximum size\n            // it can eventually grow to. It cannot be used to determine\n            // the position of kernel's stack guard.\n            None\n        } else if cfg!(target_os = \"freebsd\") {\n            // FreeBSD's stack autogrows, and optionally includes a guard page\n            // at the bottom.  If we try to remap the bottom of the stack\n            // ourselves, FreeBSD's guard page moves upwards.  So we'll just use\n            // the builtin guard page.\n            let stackaddr = get_stack_start_aligned()?;\n            let guardaddr = stackaddr as usize;\n            // Technically the number of guard pages is tunable and controlled\n            // by the security.bsd.stack_guard_page sysctl, but there are\n            // few reasons to change it from the default.  The default value has\n            // been 1 ever since FreeBSD 11.1 and 10.4.\n            const GUARD_PAGES: usize = 1;\n            let guard = guardaddr..guardaddr + GUARD_PAGES * page_size;\n            Some(guard)\n        } else {\n            // Reallocate the last page of the stack.\n            // This ensures SIGBUS will be raised on\n            // stack overflow.\n            // Systems which enforce strict PAX MPROTECT do not allow\n            // to mprotect() a mapping with less restrictive permissions\n            // than the initial mmap() used, so we mmap() here with\n            // read/write permissions and only then mprotect() it to\n            // no permissions at all. See issue #50313.\n            let stackaddr = get_stack_start_aligned()?;\n            let result = mmap(\n                stackaddr,\n                page_size,\n                PROT_READ | PROT_WRITE,\n                MAP_PRIVATE | MAP_ANON | MAP_FIXED,\n                -1,\n                0,\n            );\n            if result != stackaddr || result == MAP_FAILED {\n                panic!(\"failed to allocate a guard page: {}\", io::Error::last_os_error());\n            }\n\n            let result = mprotect(stackaddr, page_size, PROT_NONE);\n            if result != 0 {\n                panic!(\"failed to protect the guard page: {}\", io::Error::last_os_error());\n            }\n\n            let guardaddr = stackaddr as usize;\n\n            Some(guardaddr..guardaddr + page_size)\n        }\n    }\n\n    #[cfg(any(target_os = \"macos\", target_os = \"openbsd\", target_os = \"solaris\"))]\n    pub unsafe fn current() -> Option<Guard> {\n        let stackaddr = get_stack_start()? as usize;\n        Some(stackaddr - PAGE_SIZE.load(Ordering::Relaxed)..stackaddr)\n    }\n\n    #[cfg(any(\n        target_os = \"android\",\n        target_os = \"freebsd\",\n        target_os = \"linux\",\n        target_os = \"netbsd\",\n        target_os = \"l4re\"\n    ))]\n    pub unsafe fn current() -> Option<Guard> {\n        let mut ret = None;\n        let mut attr: libc::pthread_attr_t = crate::mem::zeroed();\n        #[cfg(target_os = \"freebsd\")]\n        assert_eq!(libc::pthread_attr_init(&mut attr), 0);\n        #[cfg(target_os = \"freebsd\")]\n        let e = libc::pthread_attr_get_np(libc::pthread_self(), &mut attr);\n        #[cfg(not(target_os = \"freebsd\"))]\n        let e = libc::pthread_getattr_np(libc::pthread_self(), &mut attr);\n        if e == 0 {\n            let mut guardsize = 0;\n            assert_eq!(libc::pthread_attr_getguardsize(&attr, &mut guardsize), 0);\n            if guardsize == 0 {\n                if cfg!(all(target_os = \"linux\", target_env = \"musl\")) {\n                    // musl versions before 1.1.19 always reported guard\n                    // size obtained from pthread_attr_get_np as zero.\n                    // Use page size as a fallback.\n                    guardsize = PAGE_SIZE.load(Ordering::Relaxed);\n                } else {\n                    panic!(\"there is no guard page\");\n                }\n            }\n            let mut stackaddr = crate::ptr::null_mut();\n            let mut size = 0;\n            assert_eq!(libc::pthread_attr_getstack(&attr, &mut stackaddr, &mut size), 0);\n\n            let stackaddr = stackaddr as usize;\n            ret = if cfg!(any(target_os = \"freebsd\", target_os = \"netbsd\")) {\n                Some(stackaddr - guardsize..stackaddr)\n            } else if cfg!(all(target_os = \"linux\", target_env = \"musl\")) {\n                Some(stackaddr - guardsize..stackaddr)\n            } else if cfg!(all(target_os = \"linux\", target_env = \"gnu\")) {\n                // glibc used to include the guard area within the stack, as noted in the BUGS\n                // section of `man pthread_attr_getguardsize`.  This has been corrected starting\n                // with glibc 2.27, and in some distro backports, so the guard is now placed at the\n                // end (below) the stack.  There's no easy way for us to know which we have at\n                // runtime, so we'll just match any fault in the range right above or below the\n                // stack base to call that fault a stack overflow.\n                Some(stackaddr - guardsize..stackaddr + guardsize)\n            } else {\n                Some(stackaddr..stackaddr + guardsize)\n            };\n        }\n        if e == 0 || cfg!(target_os = \"freebsd\") {\n            assert_eq!(libc::pthread_attr_destroy(&mut attr), 0);\n        }\n        ret\n    }\n}\n\n// glibc >= 2.15 has a __pthread_get_minstack() function that returns\n// PTHREAD_STACK_MIN plus bytes needed for thread-local storage.\n// We need that information to avoid blowing up when a small stack\n// is created in an application with big thread-local storage requirements.\n// See #6233 for rationale and details.\n#[cfg(target_os = \"linux\")]\n#[allow(deprecated)]\nfn min_stack_size(attr: *const libc::pthread_attr_t) -> usize {\n    weak!(fn __pthread_get_minstack(*const libc::pthread_attr_t) -> libc::size_t);\n\n    match __pthread_get_minstack.get() {\n        None => libc::PTHREAD_STACK_MIN,\n        Some(f) => unsafe { f(attr) },\n    }\n}\n\n// No point in looking up __pthread_get_minstack() on non-glibc\n// platforms.\n#[cfg(all(not(target_os = \"linux\"), not(target_os = \"netbsd\")))]\nfn min_stack_size(_: *const libc::pthread_attr_t) -> usize {\n    libc::PTHREAD_STACK_MIN\n}\n\n#[cfg(target_os = \"netbsd\")]\nfn min_stack_size(_: *const libc::pthread_attr_t) -> usize {\n    2048 // just a guess\n}\n"],[2356,"use crate::cmp::Ordering;\nuse crate::time::Duration;\n\nuse core::hash::{Hash, Hasher};\n\npub use self::inner::{Instant, SystemTime, UNIX_EPOCH};\nuse crate::convert::TryInto;\n\nconst NSEC_PER_SEC: u64 = 1_000_000_000;\n\n#[derive(Copy, Clone)]\nstruct Timespec {\n    t: libc::timespec,\n}\n\nimpl Timespec {\n    const fn zero() -> Timespec {\n        Timespec { t: libc::timespec { tv_sec: 0, tv_nsec: 0 } }\n    }\n\n    fn sub_timespec(&self, other: &Timespec) -> Result<Duration, Duration> {\n        if self >= other {\n            // NOTE(eddyb) two aspects of this `if`-`else` are required for LLVM\n            // to optimize it into a branchless form (see also #75545):\n            //\n            // 1. `self.t.tv_sec - other.t.tv_sec` shows up as a common expression\n            //    in both branches, i.e. the `else` must have its `- 1`\n            //    subtraction after the common one, not interleaved with it\n            //    (it used to be `self.t.tv_sec - 1 - other.t.tv_sec`)\n            //\n            // 2. the `Duration::new` call (or any other additional complexity)\n            //    is outside of the `if`-`else`, not duplicated in both branches\n            //\n            // Ideally this code could be rearranged such that it more\n            // directly expresses the lower-cost behavior we want from it.\n            let (secs, nsec) = if self.t.tv_nsec >= other.t.tv_nsec {\n                ((self.t.tv_sec - other.t.tv_sec) as u64, (self.t.tv_nsec - other.t.tv_nsec) as u32)\n            } else {\n                (\n                    (self.t.tv_sec - other.t.tv_sec - 1) as u64,\n                    self.t.tv_nsec as u32 + (NSEC_PER_SEC as u32) - other.t.tv_nsec as u32,\n                )\n            };\n\n            Ok(Duration::new(secs, nsec))\n        } else {\n            match other.sub_timespec(self) {\n                Ok(d) => Err(d),\n                Err(d) => Ok(d),\n            }\n        }\n    }\n\n    fn checked_add_duration(&self, other: &Duration) -> Option<Timespec> {\n        let mut secs = other\n            .as_secs()\n            .try_into() // <- target type would be `libc::time_t`\n            .ok()\n            .and_then(|secs| self.t.tv_sec.checked_add(secs))?;\n\n        // Nano calculations can't overflow because nanos are <1B which fit\n        // in a u32.\n        let mut nsec = other.subsec_nanos() + self.t.tv_nsec as u32;\n        if nsec >= NSEC_PER_SEC as u32 {\n            nsec -= NSEC_PER_SEC as u32;\n            secs = secs.checked_add(1)?;\n        }\n        Some(Timespec { t: libc::timespec { tv_sec: secs, tv_nsec: nsec as _ } })\n    }\n\n    fn checked_sub_duration(&self, other: &Duration) -> Option<Timespec> {\n        let mut secs = other\n            .as_secs()\n            .try_into() // <- target type would be `libc::time_t`\n            .ok()\n            .and_then(|secs| self.t.tv_sec.checked_sub(secs))?;\n\n        // Similar to above, nanos can't overflow.\n        let mut nsec = self.t.tv_nsec as i32 - other.subsec_nanos() as i32;\n        if nsec < 0 {\n            nsec += NSEC_PER_SEC as i32;\n            secs = secs.checked_sub(1)?;\n        }\n        Some(Timespec { t: libc::timespec { tv_sec: secs, tv_nsec: nsec as _ } })\n    }\n}\n\nimpl PartialEq for Timespec {\n    fn eq(&self, other: &Timespec) -> bool {\n        self.t.tv_sec == other.t.tv_sec && self.t.tv_nsec == other.t.tv_nsec\n    }\n}\n\nimpl Eq for Timespec {}\n\nimpl PartialOrd for Timespec {\n    fn partial_cmp(&self, other: &Timespec) -> Option<Ordering> {\n        Some(self.cmp(other))\n    }\n}\n\nimpl Ord for Timespec {\n    fn cmp(&self, other: &Timespec) -> Ordering {\n        let me = (self.t.tv_sec, self.t.tv_nsec);\n        let other = (other.t.tv_sec, other.t.tv_nsec);\n        me.cmp(&other)\n    }\n}\n\nimpl Hash for Timespec {\n    fn hash<H: Hasher>(&self, state: &mut H) {\n        self.t.tv_sec.hash(state);\n        self.t.tv_nsec.hash(state);\n    }\n}\n\n#[cfg(any(target_os = \"macos\", target_os = \"ios\"))]\nmod inner {\n    use crate::fmt;\n    use crate::sync::atomic::{AtomicU64, Ordering};\n    use crate::sys::cvt;\n    use crate::sys_common::mul_div_u64;\n    use crate::time::Duration;\n\n    use super::Timespec;\n    use super::NSEC_PER_SEC;\n\n    #[derive(Copy, Clone, PartialEq, Eq, PartialOrd, Ord, Debug, Hash)]\n    pub struct Instant {\n        t: u64,\n    }\n\n    #[derive(Copy, Clone, PartialEq, Eq, PartialOrd, Ord, Hash)]\n    pub struct SystemTime {\n        t: Timespec,\n    }\n\n    pub const UNIX_EPOCH: SystemTime = SystemTime { t: Timespec::zero() };\n\n    #[repr(C)]\n    #[derive(Copy, Clone)]\n    struct mach_timebase_info {\n        numer: u32,\n        denom: u32,\n    }\n    type mach_timebase_info_t = *mut mach_timebase_info;\n    type kern_return_t = libc::c_int;\n\n    impl Instant {\n        pub fn now() -> Instant {\n            extern \"C\" {\n                fn mach_absolute_time() -> u64;\n            }\n            Instant { t: unsafe { mach_absolute_time() } }\n        }\n\n        pub const fn zero() -> Instant {\n            Instant { t: 0 }\n        }\n\n        pub fn actually_monotonic() -> bool {\n            true\n        }\n\n        pub fn checked_sub_instant(&self, other: &Instant) -> Option<Duration> {\n            let diff = self.t.checked_sub(other.t)?;\n            let info = info();\n            let nanos = mul_div_u64(diff, info.numer as u64, info.denom as u64);\n            Some(Duration::new(nanos / NSEC_PER_SEC, (nanos % NSEC_PER_SEC) as u32))\n        }\n\n        pub fn checked_add_duration(&self, other: &Duration) -> Option<Instant> {\n            Some(Instant { t: self.t.checked_add(checked_dur2intervals(other)?)? })\n        }\n\n        pub fn checked_sub_duration(&self, other: &Duration) -> Option<Instant> {\n            Some(Instant { t: self.t.checked_sub(checked_dur2intervals(other)?)? })\n        }\n    }\n\n    impl SystemTime {\n        pub fn now() -> SystemTime {\n            use crate::ptr;\n\n            let mut s = libc::timeval { tv_sec: 0, tv_usec: 0 };\n            cvt(unsafe { libc::gettimeofday(&mut s, ptr::null_mut()) }).unwrap();\n            return SystemTime::from(s);\n        }\n\n        pub fn sub_time(&self, other: &SystemTime) -> Result<Duration, Duration> {\n            self.t.sub_timespec(&other.t)\n        }\n\n        pub fn checked_add_duration(&self, other: &Duration) -> Option<SystemTime> {\n            Some(SystemTime { t: self.t.checked_add_duration(other)? })\n        }\n\n        pub fn checked_sub_duration(&self, other: &Duration) -> Option<SystemTime> {\n            Some(SystemTime { t: self.t.checked_sub_duration(other)? })\n        }\n    }\n\n    impl From<libc::timeval> for SystemTime {\n        fn from(t: libc::timeval) -> SystemTime {\n            SystemTime::from(libc::timespec {\n                tv_sec: t.tv_sec,\n                tv_nsec: (t.tv_usec * 1000) as libc::c_long,\n            })\n        }\n    }\n\n    impl From<libc::timespec> for SystemTime {\n        fn from(t: libc::timespec) -> SystemTime {\n            SystemTime { t: Timespec { t } }\n        }\n    }\n\n    impl fmt::Debug for SystemTime {\n        fn fmt(&self, f: &mut fmt::Formatter<'_>) -> fmt::Result {\n            f.debug_struct(\"SystemTime\")\n                .field(\"tv_sec\", &self.t.t.tv_sec)\n                .field(\"tv_nsec\", &self.t.t.tv_nsec)\n                .finish()\n        }\n    }\n\n    fn checked_dur2intervals(dur: &Duration) -> Option<u64> {\n        let nanos =\n            dur.as_secs().checked_mul(NSEC_PER_SEC)?.checked_add(dur.subsec_nanos() as u64)?;\n        let info = info();\n        Some(mul_div_u64(nanos, info.denom as u64, info.numer as u64))\n    }\n\n    fn info() -> mach_timebase_info {\n        // INFO_BITS conceptually is an `Option<mach_timebase_info>`. We can do\n        // this in 64 bits because we know 0 is never a valid value for the\n        // `denom` field.\n        //\n        // Encoding this as a single `AtomicU64` allows us to use `Relaxed`\n        // operations, as we are only interested in the effects on a single\n        // memory location.\n        static INFO_BITS: AtomicU64 = AtomicU64::new(0);\n\n        // If a previous thread has initialized `INFO_BITS`, use it.\n        let info_bits = INFO_BITS.load(Ordering::Relaxed);\n        if info_bits != 0 {\n            return info_from_bits(info_bits);\n        }\n\n        // ... otherwise learn for ourselves ...\n        extern \"C\" {\n            fn mach_timebase_info(info: mach_timebase_info_t) -> kern_return_t;\n        }\n\n        let mut info = info_from_bits(0);\n        unsafe {\n            mach_timebase_info(&mut info);\n        }\n        INFO_BITS.store(info_to_bits(info), Ordering::Relaxed);\n        info\n    }\n\n    #[inline]\n    fn info_to_bits(info: mach_timebase_info) -> u64 {\n        ((info.denom as u64) << 32) | (info.numer as u64)\n    }\n\n    #[inline]\n    fn info_from_bits(bits: u64) -> mach_timebase_info {\n        mach_timebase_info { numer: bits as u32, denom: (bits >> 32) as u32 }\n    }\n}\n\n#[cfg(not(any(target_os = \"macos\", target_os = \"ios\")))]\nmod inner {\n    use crate::fmt;\n    use crate::sys::cvt;\n    use crate::time::Duration;\n\n    use super::Timespec;\n\n    #[derive(Copy, Clone, PartialEq, Eq, PartialOrd, Ord, Hash)]\n    pub struct Instant {\n        t: Timespec,\n    }\n\n    #[derive(Copy, Clone, PartialEq, Eq, PartialOrd, Ord, Hash)]\n    pub struct SystemTime {\n        t: Timespec,\n    }\n\n    pub const UNIX_EPOCH: SystemTime = SystemTime { t: Timespec::zero() };\n\n    impl Instant {\n        pub fn now() -> Instant {\n            Instant { t: now(libc::CLOCK_MONOTONIC) }\n        }\n\n        pub const fn zero() -> Instant {\n            Instant { t: Timespec::zero() }\n        }\n\n        pub fn actually_monotonic() -> bool {\n            (cfg!(target_os = \"linux\") && cfg!(target_arch = \"x86_64\"))\n                || (cfg!(target_os = \"linux\") && cfg!(target_arch = \"x86\"))\n                || cfg!(target_os = \"fuchsia\")\n        }\n\n        pub fn checked_sub_instant(&self, other: &Instant) -> Option<Duration> {\n            self.t.sub_timespec(&other.t).ok()\n        }\n\n        pub fn checked_add_duration(&self, other: &Duration) -> Option<Instant> {\n            Some(Instant { t: self.t.checked_add_duration(other)? })\n        }\n\n        pub fn checked_sub_duration(&self, other: &Duration) -> Option<Instant> {\n            Some(Instant { t: self.t.checked_sub_duration(other)? })\n        }\n    }\n\n    impl fmt::Debug for Instant {\n        fn fmt(&self, f: &mut fmt::Formatter<'_>) -> fmt::Result {\n            f.debug_struct(\"Instant\")\n                .field(\"tv_sec\", &self.t.t.tv_sec)\n                .field(\"tv_nsec\", &self.t.t.tv_nsec)\n                .finish()\n        }\n    }\n\n    impl SystemTime {\n        pub fn now() -> SystemTime {\n            SystemTime { t: now(libc::CLOCK_REALTIME) }\n        }\n\n        pub fn sub_time(&self, other: &SystemTime) -> Result<Duration, Duration> {\n            self.t.sub_timespec(&other.t)\n        }\n\n        pub fn checked_add_duration(&self, other: &Duration) -> Option<SystemTime> {\n            Some(SystemTime { t: self.t.checked_add_duration(other)? })\n        }\n\n        pub fn checked_sub_duration(&self, other: &Duration) -> Option<SystemTime> {\n            Some(SystemTime { t: self.t.checked_sub_duration(other)? })\n        }\n    }\n\n    impl From<libc::timespec> for SystemTime {\n        fn from(t: libc::timespec) -> SystemTime {\n            SystemTime { t: Timespec { t } }\n        }\n    }\n\n    impl fmt::Debug for SystemTime {\n        fn fmt(&self, f: &mut fmt::Formatter<'_>) -> fmt::Result {\n            f.debug_struct(\"SystemTime\")\n                .field(\"tv_sec\", &self.t.t.tv_sec)\n                .field(\"tv_nsec\", &self.t.t.tv_nsec)\n                .finish()\n        }\n    }\n\n    #[cfg(not(target_os = \"dragonfly\"))]\n    pub type clock_t = libc::c_int;\n    #[cfg(target_os = \"dragonfly\")]\n    pub type clock_t = libc::c_ulong;\n\n    fn now(clock: clock_t) -> Timespec {\n        let mut t = Timespec { t: libc::timespec { tv_sec: 0, tv_nsec: 0 } };\n        cvt(unsafe { libc::clock_gettime(clock, &mut t.t) }).unwrap();\n        t\n    }\n}\n"],[2357,"//! Global initialization and retrieval of command line arguments.\n//!\n//! On some platforms these are stored during runtime startup,\n//! and on some they are retrieved from the system on demand.\n\n#![allow(dead_code)] // runtime init functions not used during testing\n\nuse crate::ffi::OsString;\nuse crate::fmt;\nuse crate::vec;\n\n/// One-time global initialization.\npub unsafe fn init(argc: isize, argv: *const *const u8) {\n    imp::init(argc, argv)\n}\n\n/// One-time global cleanup.\npub unsafe fn cleanup() {\n    imp::cleanup()\n}\n\n/// Returns the command line arguments\npub fn args() -> Args {\n    imp::args()\n}\n\npub struct Args {\n    iter: vec::IntoIter<OsString>,\n}\n\nimpl !Send for Args {}\nimpl !Sync for Args {}\n\nimpl fmt::Debug for Args {\n    fn fmt(&self, f: &mut fmt::Formatter<'_>) -> fmt::Result {\n        self.iter.as_slice().fmt(f)\n    }\n}\n\nimpl Iterator for Args {\n    type Item = OsString;\n    fn next(&mut self) -> Option<OsString> {\n        self.iter.next()\n    }\n    fn size_hint(&self) -> (usize, Option<usize>) {\n        self.iter.size_hint()\n    }\n}\n\nimpl ExactSizeIterator for Args {\n    fn len(&self) -> usize {\n        self.iter.len()\n    }\n}\n\nimpl DoubleEndedIterator for Args {\n    fn next_back(&mut self) -> Option<OsString> {\n        self.iter.next_back()\n    }\n}\n\n#[cfg(any(\n    target_os = \"linux\",\n    target_os = \"android\",\n    target_os = \"freebsd\",\n    target_os = \"dragonfly\",\n    target_os = \"netbsd\",\n    target_os = \"openbsd\",\n    target_os = \"solaris\",\n    target_os = \"illumos\",\n    target_os = \"emscripten\",\n    target_os = \"haiku\",\n    target_os = \"l4re\",\n    target_os = \"fuchsia\",\n    target_os = \"redox\",\n    target_os = \"vxworks\"\n))]\nmod imp {\n    use super::Args;\n    use crate::ffi::{CStr, OsString};\n    use crate::os::unix::prelude::*;\n    use crate::ptr;\n    use crate::sync::atomic::{AtomicIsize, AtomicPtr, Ordering};\n\n    use crate::sys_common::mutex::StaticMutex;\n\n    static ARGC: AtomicIsize = AtomicIsize::new(0);\n    static ARGV: AtomicPtr<*const u8> = AtomicPtr::new(ptr::null_mut());\n    // We never call `ENV_LOCK.init()`, so it is UB to attempt to\n    // acquire this mutex reentrantly!\n    static LOCK: StaticMutex = StaticMutex::new();\n\n    unsafe fn really_init(argc: isize, argv: *const *const u8) {\n        let _guard = LOCK.lock();\n        ARGC.store(argc, Ordering::Relaxed);\n        ARGV.store(argv as *mut _, Ordering::Relaxed);\n    }\n\n    #[inline(always)]\n    pub unsafe fn init(_argc: isize, _argv: *const *const u8) {\n        // On Linux-GNU, we rely on `ARGV_INIT_ARRAY` below to initialize\n        // `ARGC` and `ARGV`. But in Miri that does not actually happen so we\n        // still initialize here.\n        #[cfg(any(miri, not(all(target_os = \"linux\", target_env = \"gnu\"))))]\n        really_init(_argc, _argv);\n    }\n\n    /// glibc passes argc, argv, and envp to functions in .init_array, as a non-standard extension.\n    /// This allows `std::env::args` to work even in a `cdylib`, as it does on macOS and Windows.\n    #[cfg(all(target_os = \"linux\", target_env = \"gnu\"))]\n    #[used]\n    #[link_section = \".init_array.00099\"]\n    static ARGV_INIT_ARRAY: extern \"C\" fn(\n        crate::os::raw::c_int,\n        *const *const u8,\n        *const *const u8,\n    ) = {\n        extern \"C\" fn init_wrapper(\n            argc: crate::os::raw::c_int,\n            argv: *const *const u8,\n            _envp: *const *const u8,\n        ) {\n            unsafe {\n                really_init(argc as isize, argv);\n            }\n        }\n        init_wrapper\n    };\n\n    pub unsafe fn cleanup() {\n        let _guard = LOCK.lock();\n        ARGC.store(0, Ordering::Relaxed);\n        ARGV.store(ptr::null_mut(), Ordering::Relaxed);\n    }\n\n    pub fn args() -> Args {\n        Args { iter: clone().into_iter() }\n    }\n\n    fn clone() -> Vec<OsString> {\n        unsafe {\n            let _guard = LOCK.lock();\n            let argc = ARGC.load(Ordering::Relaxed);\n            let argv = ARGV.load(Ordering::Relaxed);\n            (0..argc)\n                .map(|i| {\n                    let cstr = CStr::from_ptr(*argv.offset(i) as *const libc::c_char);\n                    OsStringExt::from_vec(cstr.to_bytes().to_vec())\n                })\n                .collect()\n        }\n    }\n}\n\n#[cfg(any(target_os = \"macos\", target_os = \"ios\"))]\nmod imp {\n    use super::Args;\n    use crate::ffi::CStr;\n\n    pub unsafe fn init(_argc: isize, _argv: *const *const u8) {}\n\n    pub fn cleanup() {}\n\n    #[cfg(target_os = \"macos\")]\n    pub fn args() -> Args {\n        use crate::os::unix::prelude::*;\n        extern \"C\" {\n            // These functions are in crt_externs.h.\n            fn _NSGetArgc() -> *mut libc::c_int;\n            fn _NSGetArgv() -> *mut *mut *mut libc::c_char;\n        }\n\n        let vec = unsafe {\n            let (argc, argv) =\n                (*_NSGetArgc() as isize, *_NSGetArgv() as *const *const libc::c_char);\n            (0..argc as isize)\n                .map(|i| {\n                    let bytes = CStr::from_ptr(*argv.offset(i)).to_bytes().to_vec();\n                    OsStringExt::from_vec(bytes)\n                })\n                .collect::<Vec<_>>()\n        };\n        Args { iter: vec.into_iter() }\n    }\n\n    // As _NSGetArgc and _NSGetArgv aren't mentioned in iOS docs\n    // and use underscores in their names - they're most probably\n    // are considered private and therefore should be avoided\n    // Here is another way to get arguments using Objective C\n    // runtime\n    //\n    // In general it looks like:\n    // res = Vec::new()\n    // let args = [[NSProcessInfo processInfo] arguments]\n    // for i in (0..[args count])\n    //      res.push([args objectAtIndex:i])\n    // res\n    #[cfg(target_os = \"ios\")]\n    pub fn args() -> Args {\n        use crate::ffi::OsString;\n        use crate::mem;\n        use crate::str;\n\n        extern \"C\" {\n            fn sel_registerName(name: *const libc::c_uchar) -> Sel;\n            fn objc_getClass(class_name: *const libc::c_uchar) -> NsId;\n        }\n\n        #[cfg(target_arch = \"aarch64\")]\n        extern \"C\" {\n            fn objc_msgSend(obj: NsId, sel: Sel) -> NsId;\n            #[allow(clashing_extern_declarations)]\n            #[link_name = \"objc_msgSend\"]\n            fn objc_msgSend_ul(obj: NsId, sel: Sel, i: libc::c_ulong) -> NsId;\n        }\n\n        #[cfg(not(target_arch = \"aarch64\"))]\n        extern \"C\" {\n            fn objc_msgSend(obj: NsId, sel: Sel, ...) -> NsId;\n            #[allow(clashing_extern_declarations)]\n            #[link_name = \"objc_msgSend\"]\n            fn objc_msgSend_ul(obj: NsId, sel: Sel, ...) -> NsId;\n        }\n\n        type Sel = *const libc::c_void;\n        type NsId = *const libc::c_void;\n\n        let mut res = Vec::new();\n\n        unsafe {\n            let process_info_sel = sel_registerName(\"processInfo\\0\".as_ptr());\n            let arguments_sel = sel_registerName(\"arguments\\0\".as_ptr());\n            let utf8_sel = sel_registerName(\"UTF8String\\0\".as_ptr());\n            let count_sel = sel_registerName(\"count\\0\".as_ptr());\n            let object_at_sel = sel_registerName(\"objectAtIndex:\\0\".as_ptr());\n\n            let klass = objc_getClass(\"NSProcessInfo\\0\".as_ptr());\n            let info = objc_msgSend(klass, process_info_sel);\n            let args = objc_msgSend(info, arguments_sel);\n\n            let cnt: usize = mem::transmute(objc_msgSend(args, count_sel));\n            for i in 0..cnt {\n                let tmp = objc_msgSend_ul(args, object_at_sel, i as libc::c_ulong);\n                let utf_c_str: *const libc::c_char = mem::transmute(objc_msgSend(tmp, utf8_sel));\n                let bytes = CStr::from_ptr(utf_c_str).to_bytes();\n                res.push(OsString::from(str::from_utf8(bytes).unwrap()))\n            }\n        }\n\n        Args { iter: res.into_iter() }\n    }\n}\n"],[2358,"//! A \"compatibility layer\" for supporting older versions of Windows\n//!\n//! The standard library uses some Windows API functions that are not present\n//! on older versions of Windows.  (Note that the oldest version of Windows\n//! that Rust supports is Windows 7 (client) and Windows Server 2008 (server).)\n//! This module implements a form of delayed DLL import binding, using\n//! `GetModuleHandle` and `GetProcAddress` to look up DLL entry points at\n//! runtime.\n//!\n//! This implementation uses a static initializer to look up the DLL entry\n//! points. The CRT (C runtime) executes static initializers before `main`\n//! is called (for binaries) and before `DllMain` is called (for DLLs).\n//! This is the ideal time to look up DLL imports, because we are guaranteed\n//! that no other threads will attempt to call these entry points. Thus,\n//! we can look up the imports and store them in `static mut` fields\n//! without any synchronization.\n//!\n//! This has an additional advantage: Because the DLL import lookup happens\n//! at module initialization, the cost of these lookups is deterministic,\n//! and is removed from the code paths that actually call the DLL imports.\n//! That is, there is no unpredictable \"cache miss\" that occurs when calling\n//! a DLL import. For applications that benefit from predictable delays,\n//! this is a benefit. This also eliminates the comparison-and-branch\n//! from the hot path.\n//!\n//! Currently, the standard library uses only a small number of dynamic\n//! DLL imports. If this number grows substantially, then the cost of\n//! performing all of the lookups at initialization time might become\n//! substantial.\n//!\n//! The mechanism of registering a static initializer with the CRT is\n//! documented in\n//! [CRT Initialization](https://docs.microsoft.com/en-us/cpp/c-runtime-library/crt-initialization?view=msvc-160).\n//! It works by contributing a global symbol to the `.CRT$XCU` section.\n//! The linker builds a table of all static initializer functions.\n//! The CRT startup code then iterates that table, calling each\n//! initializer function.\n//!\n//! # **WARNING!!*\n//! The environment that a static initializer function runs in is highly\n//! constrained. There are **many** restrictions on what static initializers\n//! can safely do. Static initializer functions **MUST NOT** do any of the\n//! following (this list is not comprehensive):\n//! * touch any other static field that is used by a different static\n//!   initializer, because the order that static initializers run in\n//!   is not defined.\n//! * call `LoadLibrary` or any other function that acquires the DLL\n//!   loader lock.\n//! * call any Rust function or CRT function that touches any static\n//!   (global) state.\n\nmacro_rules! compat_fn {\n    ($module:literal: $(\n        $(#[$meta:meta])*\n        pub fn $symbol:ident($($argname:ident: $argtype:ty),*) -> $rettype:ty $fallback_body:block\n    )*) => ($(\n        $(#[$meta])*\n        pub mod $symbol {\n            #[allow(unused_imports)]\n            use super::*;\n            use crate::mem;\n\n            type F = unsafe extern \"system\" fn($($argtype),*) -> $rettype;\n\n            /// Points to the DLL import, or the fallback function.\n            ///\n            /// This static can be an ordinary, unsynchronized, mutable static because\n            /// we guarantee that all of the writes finish during CRT initialization,\n            /// and all of the reads occur after CRT initialization.\n            static mut PTR: Option<F> = None;\n\n            /// This symbol is what allows the CRT to find the `init` function and call it.\n            /// It is marked `#[used]` because otherwise Rust would assume that it was not\n            /// used, and would remove it.\n            #[used]\n            #[link_section = \".CRT$XCU\"]\n            static INIT_TABLE_ENTRY: unsafe extern \"C\" fn() = init;\n\n            unsafe extern \"C\" fn init() {\n                // There is no locking here. This code is executed before main() is entered, and\n                // is guaranteed to be single-threaded.\n                //\n                // DO NOT do anything interesting or complicated in this function! DO NOT call\n                // any Rust functions or CRT functions, if those functions touch any global state,\n                // because this function runs during global initialization. For example, DO NOT\n                // do any dynamic allocation, don't call LoadLibrary, etc.\n                let module_name: *const u8 = concat!($module, \"\\0\").as_ptr();\n                let symbol_name: *const u8 = concat!(stringify!($symbol), \"\\0\").as_ptr();\n                let module_handle = $crate::sys::c::GetModuleHandleA(module_name as *const i8);\n                if !module_handle.is_null() {\n                    match $crate::sys::c::GetProcAddress(module_handle, symbol_name as *const i8) as usize {\n                        0 => {}\n                        n => {\n                            PTR = Some(mem::transmute::<usize, F>(n));\n                        }\n                    }\n                }\n            }\n\n            #[allow(dead_code)]\n            pub fn option() -> Option<F> {\n                unsafe { PTR }\n            }\n\n            #[allow(dead_code)]\n            pub unsafe fn call($($argname: $argtype),*) -> $rettype {\n                if let Some(ptr) = PTR {\n                    ptr($($argname),*)\n                } else {\n                    $fallback_body\n                }\n            }\n        }\n\n        $(#[$meta])*\n        pub use $symbol::call as $symbol;\n    )*)\n}\n"],[2359,"//! C definitions used by libnative that don't belong in liblibc\n\n#![allow(nonstandard_style)]\n#![cfg_attr(test, allow(dead_code))]\n#![unstable(issue = \"none\", feature = \"windows_c\")]\n\nuse crate::os::raw::NonZero_c_ulong;\nuse crate::os::raw::{c_char, c_int, c_long, c_longlong, c_uint, c_ulong, c_ushort};\nuse crate::ptr;\n\nuse libc::{c_void, size_t, wchar_t};\n\npub use self::EXCEPTION_DISPOSITION::*;\npub use self::FILE_INFO_BY_HANDLE_CLASS::*;\n\npub type DWORD_PTR = ULONG_PTR;\npub type DWORD = c_ulong;\npub type NonZeroDWORD = NonZero_c_ulong;\npub type HANDLE = LPVOID;\npub type HINSTANCE = HANDLE;\npub type HMODULE = HINSTANCE;\npub type HRESULT = LONG;\npub type BOOL = c_int;\npub type BYTE = u8;\npub type BOOLEAN = BYTE;\npub type GROUP = c_uint;\npub type LARGE_INTEGER = c_longlong;\npub type LONG = c_long;\npub type UINT = c_uint;\npub type WCHAR = u16;\npub type USHORT = c_ushort;\npub type SIZE_T = usize;\npub type WORD = u16;\npub type CHAR = c_char;\npub type ULONG_PTR = usize;\npub type ULONG = c_ulong;\npub type NTSTATUS = LONG;\npub type ACCESS_MASK = DWORD;\n\npub type LPBOOL = *mut BOOL;\npub type LPBYTE = *mut BYTE;\npub type LPCSTR = *const CHAR;\npub type LPCWSTR = *const WCHAR;\npub type LPDWORD = *mut DWORD;\npub type LPHANDLE = *mut HANDLE;\npub type LPOVERLAPPED = *mut OVERLAPPED;\npub type LPPROCESS_INFORMATION = *mut PROCESS_INFORMATION;\npub type LPSECURITY_ATTRIBUTES = *mut SECURITY_ATTRIBUTES;\npub type LPSTARTUPINFO = *mut STARTUPINFO;\npub type LPVOID = *mut c_void;\npub type LPWCH = *mut WCHAR;\npub type LPWIN32_FIND_DATAW = *mut WIN32_FIND_DATAW;\npub type LPWSADATA = *mut WSADATA;\npub type LPWSAPROTOCOL_INFO = *mut WSAPROTOCOL_INFO;\npub type LPWSTR = *mut WCHAR;\npub type LPFILETIME = *mut FILETIME;\npub type LPSYSTEM_INFO = *mut SYSTEM_INFO;\npub type LPWSABUF = *mut WSABUF;\npub type LPWSAOVERLAPPED = *mut c_void;\npub type LPWSAOVERLAPPED_COMPLETION_ROUTINE = *mut c_void;\n\npub type PCONDITION_VARIABLE = *mut CONDITION_VARIABLE;\npub type PLARGE_INTEGER = *mut c_longlong;\npub type PSRWLOCK = *mut SRWLOCK;\n\npub type SOCKET = crate::os::windows::raw::SOCKET;\npub type socklen_t = c_int;\npub type ADDRESS_FAMILY = USHORT;\n\npub const TRUE: BOOL = 1;\npub const FALSE: BOOL = 0;\n\npub const FILE_ATTRIBUTE_READONLY: DWORD = 0x1;\npub const FILE_ATTRIBUTE_DIRECTORY: DWORD = 0x10;\npub const FILE_ATTRIBUTE_REPARSE_POINT: DWORD = 0x400;\n\npub const FILE_SHARE_DELETE: DWORD = 0x4;\npub const FILE_SHARE_READ: DWORD = 0x1;\npub const FILE_SHARE_WRITE: DWORD = 0x2;\n\npub const CREATE_ALWAYS: DWORD = 2;\npub const CREATE_NEW: DWORD = 1;\npub const OPEN_ALWAYS: DWORD = 4;\npub const OPEN_EXISTING: DWORD = 3;\npub const TRUNCATE_EXISTING: DWORD = 5;\n\npub const FILE_WRITE_DATA: DWORD = 0x00000002;\npub const FILE_APPEND_DATA: DWORD = 0x00000004;\npub const FILE_WRITE_EA: DWORD = 0x00000010;\npub const FILE_WRITE_ATTRIBUTES: DWORD = 0x00000100;\npub const READ_CONTROL: DWORD = 0x00020000;\npub const SYNCHRONIZE: DWORD = 0x00100000;\npub const GENERIC_READ: DWORD = 0x80000000;\npub const GENERIC_WRITE: DWORD = 0x40000000;\npub const STANDARD_RIGHTS_WRITE: DWORD = READ_CONTROL;\npub const FILE_GENERIC_WRITE: DWORD = STANDARD_RIGHTS_WRITE\n    | FILE_WRITE_DATA\n    | FILE_WRITE_ATTRIBUTES\n    | FILE_WRITE_EA\n    | FILE_APPEND_DATA\n    | SYNCHRONIZE;\n\npub const FILE_FLAG_OPEN_REPARSE_POINT: DWORD = 0x00200000;\npub const FILE_FLAG_BACKUP_SEMANTICS: DWORD = 0x02000000;\npub const SECURITY_SQOS_PRESENT: DWORD = 0x00100000;\n\npub const FIONBIO: c_ulong = 0x8004667e;\n\n#[repr(C)]\n#[derive(Copy)]\npub struct WIN32_FIND_DATAW {\n    pub dwFileAttributes: DWORD,\n    pub ftCreationTime: FILETIME,\n    pub ftLastAccessTime: FILETIME,\n    pub ftLastWriteTime: FILETIME,\n    pub nFileSizeHigh: DWORD,\n    pub nFileSizeLow: DWORD,\n    pub dwReserved0: DWORD,\n    pub dwReserved1: DWORD,\n    pub cFileName: [wchar_t; 260], // #define MAX_PATH 260\n    pub cAlternateFileName: [wchar_t; 14],\n}\nimpl Clone for WIN32_FIND_DATAW {\n    fn clone(&self) -> Self {\n        *self\n    }\n}\n\npub const WSA_FLAG_OVERLAPPED: DWORD = 0x01;\npub const WSA_FLAG_NO_HANDLE_INHERIT: DWORD = 0x80;\n\npub const WSADESCRIPTION_LEN: usize = 256;\npub const WSASYS_STATUS_LEN: usize = 128;\npub const WSAPROTOCOL_LEN: DWORD = 255;\npub const INVALID_SOCKET: SOCKET = !0;\n\npub const WSAEACCES: c_int = 10013;\npub const WSAEINVAL: c_int = 10022;\npub const WSAEWOULDBLOCK: c_int = 10035;\npub const WSAEPROTOTYPE: c_int = 10041;\npub const WSAEADDRINUSE: c_int = 10048;\npub const WSAEADDRNOTAVAIL: c_int = 10049;\npub const WSAECONNABORTED: c_int = 10053;\npub const WSAECONNRESET: c_int = 10054;\npub const WSAENOTCONN: c_int = 10057;\npub const WSAESHUTDOWN: c_int = 10058;\npub const WSAETIMEDOUT: c_int = 10060;\npub const WSAECONNREFUSED: c_int = 10061;\n\npub const MAX_PROTOCOL_CHAIN: DWORD = 7;\n\npub const MAXIMUM_REPARSE_DATA_BUFFER_SIZE: usize = 16 * 1024;\npub const FSCTL_GET_REPARSE_POINT: DWORD = 0x900a8;\npub const IO_REPARSE_TAG_SYMLINK: DWORD = 0xa000000c;\npub const IO_REPARSE_TAG_MOUNT_POINT: DWORD = 0xa0000003;\npub const SYMLINK_FLAG_RELATIVE: DWORD = 0x00000001;\npub const FSCTL_SET_REPARSE_POINT: DWORD = 0x900a4;\n\npub const SYMBOLIC_LINK_FLAG_DIRECTORY: DWORD = 0x1;\npub const SYMBOLIC_LINK_FLAG_ALLOW_UNPRIVILEGED_CREATE: DWORD = 0x2;\n\n// Note that these are not actually HANDLEs, just values to pass to GetStdHandle\npub const STD_INPUT_HANDLE: DWORD = -10i32 as DWORD;\npub const STD_OUTPUT_HANDLE: DWORD = -11i32 as DWORD;\npub const STD_ERROR_HANDLE: DWORD = -12i32 as DWORD;\n\npub const PROGRESS_CONTINUE: DWORD = 0;\n\n// List of Windows system error codes with descriptions:\n// https://docs.microsoft.com/en-us/windows/win32/debug/system-error-codes#system-error-codes\npub const ERROR_FILE_NOT_FOUND: DWORD = 2;\npub const ERROR_PATH_NOT_FOUND: DWORD = 3;\npub const ERROR_ACCESS_DENIED: DWORD = 5;\npub const ERROR_INVALID_HANDLE: DWORD = 6;\npub const ERROR_NOT_ENOUGH_MEMORY: DWORD = 8;\npub const ERROR_OUTOFMEMORY: DWORD = 14;\npub const ERROR_NO_MORE_FILES: DWORD = 18;\npub const ERROR_SHARING_VIOLATION: u32 = 32;\npub const ERROR_HANDLE_EOF: DWORD = 38;\npub const ERROR_FILE_EXISTS: DWORD = 80;\npub const ERROR_INVALID_PARAMETER: DWORD = 87;\npub const ERROR_BROKEN_PIPE: DWORD = 109;\npub const ERROR_CALL_NOT_IMPLEMENTED: DWORD = 120;\npub const ERROR_SEM_TIMEOUT: DWORD = 121;\npub const ERROR_INSUFFICIENT_BUFFER: DWORD = 122;\npub const ERROR_ALREADY_EXISTS: DWORD = 183;\npub const ERROR_ENVVAR_NOT_FOUND: DWORD = 203;\npub const ERROR_NO_DATA: DWORD = 232;\npub const ERROR_DRIVER_CANCEL_TIMEOUT: DWORD = 594;\npub const ERROR_OPERATION_ABORTED: DWORD = 995;\npub const ERROR_IO_PENDING: DWORD = 997;\npub const ERROR_SERVICE_REQUEST_TIMEOUT: DWORD = 1053;\npub const ERROR_COUNTER_TIMEOUT: DWORD = 1121;\npub const ERROR_TIMEOUT: DWORD = 1460;\npub const ERROR_RESOURCE_CALL_TIMED_OUT: DWORD = 5910;\npub const ERROR_CTX_MODEM_RESPONSE_TIMEOUT: DWORD = 7012;\npub const ERROR_CTX_CLIENT_QUERY_TIMEOUT: DWORD = 7040;\npub const FRS_ERR_SYSVOL_POPULATE_TIMEOUT: DWORD = 8014;\npub const ERROR_DS_TIMELIMIT_EXCEEDED: DWORD = 8226;\npub const DNS_ERROR_RECORD_TIMED_OUT: DWORD = 9705;\npub const ERROR_IPSEC_IKE_TIMED_OUT: DWORD = 13805;\npub const ERROR_RUNLEVEL_SWITCH_TIMEOUT: DWORD = 15402;\npub const ERROR_RUNLEVEL_SWITCH_AGENT_TIMEOUT: DWORD = 15403;\n\npub const E_NOTIMPL: HRESULT = 0x80004001u32 as HRESULT;\n\npub const INVALID_HANDLE_VALUE: HANDLE = !0 as HANDLE;\n\npub const FACILITY_NT_BIT: DWORD = 0x1000_0000;\n\npub const FORMAT_MESSAGE_FROM_SYSTEM: DWORD = 0x00001000;\npub const FORMAT_MESSAGE_FROM_HMODULE: DWORD = 0x00000800;\npub const FORMAT_MESSAGE_IGNORE_INSERTS: DWORD = 0x00000200;\n\npub const TLS_OUT_OF_INDEXES: DWORD = 0xFFFFFFFF;\n\npub const DLL_THREAD_DETACH: DWORD = 3;\npub const DLL_PROCESS_DETACH: DWORD = 0;\n\npub const INFINITE: DWORD = !0;\n\npub const DUPLICATE_SAME_ACCESS: DWORD = 0x00000002;\n\npub const CONDITION_VARIABLE_INIT: CONDITION_VARIABLE = CONDITION_VARIABLE { ptr: ptr::null_mut() };\npub const SRWLOCK_INIT: SRWLOCK = SRWLOCK { ptr: ptr::null_mut() };\n\npub const DETACHED_PROCESS: DWORD = 0x00000008;\npub const CREATE_NEW_PROCESS_GROUP: DWORD = 0x00000200;\npub const CREATE_UNICODE_ENVIRONMENT: DWORD = 0x00000400;\npub const STARTF_USESTDHANDLES: DWORD = 0x00000100;\n\npub const AF_INET: c_int = 2;\npub const AF_INET6: c_int = 23;\npub const SD_BOTH: c_int = 2;\npub const SD_RECEIVE: c_int = 0;\npub const SD_SEND: c_int = 1;\npub const SOCK_DGRAM: c_int = 2;\npub const SOCK_STREAM: c_int = 1;\npub const SOCKET_ERROR: c_int = -1;\npub const SOL_SOCKET: c_int = 0xffff;\npub const SO_RCVTIMEO: c_int = 0x1006;\npub const SO_SNDTIMEO: c_int = 0x1005;\npub const IPPROTO_IP: c_int = 0;\npub const IPPROTO_TCP: c_int = 6;\npub const IPPROTO_IPV6: c_int = 41;\npub const TCP_NODELAY: c_int = 0x0001;\npub const IP_TTL: c_int = 4;\npub const IPV6_V6ONLY: c_int = 27;\npub const SO_ERROR: c_int = 0x1007;\npub const SO_BROADCAST: c_int = 0x0020;\npub const IP_MULTICAST_LOOP: c_int = 11;\npub const IPV6_MULTICAST_LOOP: c_int = 11;\npub const IP_MULTICAST_TTL: c_int = 10;\npub const IP_ADD_MEMBERSHIP: c_int = 12;\npub const IP_DROP_MEMBERSHIP: c_int = 13;\npub const IPV6_ADD_MEMBERSHIP: c_int = 12;\npub const IPV6_DROP_MEMBERSHIP: c_int = 13;\npub const MSG_PEEK: c_int = 0x2;\n\n#[repr(C)]\npub struct ip_mreq {\n    pub imr_multiaddr: in_addr,\n    pub imr_interface: in_addr,\n}\n\n#[repr(C)]\npub struct ipv6_mreq {\n    pub ipv6mr_multiaddr: in6_addr,\n    pub ipv6mr_interface: c_uint,\n}\n\npub const VOLUME_NAME_DOS: DWORD = 0x0;\npub const MOVEFILE_REPLACE_EXISTING: DWORD = 1;\n\npub const FILE_BEGIN: DWORD = 0;\npub const FILE_CURRENT: DWORD = 1;\npub const FILE_END: DWORD = 2;\n\npub const WAIT_OBJECT_0: DWORD = 0x00000000;\npub const WAIT_TIMEOUT: DWORD = 258;\npub const WAIT_FAILED: DWORD = 0xFFFFFFFF;\n\npub const PIPE_ACCESS_INBOUND: DWORD = 0x00000001;\npub const PIPE_ACCESS_OUTBOUND: DWORD = 0x00000002;\npub const FILE_FLAG_FIRST_PIPE_INSTANCE: DWORD = 0x00080000;\npub const FILE_FLAG_OVERLAPPED: DWORD = 0x40000000;\npub const PIPE_WAIT: DWORD = 0x00000000;\npub const PIPE_TYPE_BYTE: DWORD = 0x00000000;\npub const PIPE_REJECT_REMOTE_CLIENTS: DWORD = 0x00000008;\npub const PIPE_READMODE_BYTE: DWORD = 0x00000000;\n\npub const FD_SETSIZE: usize = 64;\n\npub const STACK_SIZE_PARAM_IS_A_RESERVATION: DWORD = 0x00010000;\n\npub const STATUS_SUCCESS: NTSTATUS = 0x00000000;\n\n#[repr(C)]\n#[cfg(not(target_pointer_width = \"64\"))]\npub struct WSADATA {\n    pub wVersion: WORD,\n    pub wHighVersion: WORD,\n    pub szDescription: [u8; WSADESCRIPTION_LEN + 1],\n    pub szSystemStatus: [u8; WSASYS_STATUS_LEN + 1],\n    pub iMaxSockets: u16,\n    pub iMaxUdpDg: u16,\n    pub lpVendorInfo: *mut u8,\n}\n#[repr(C)]\n#[cfg(target_pointer_width = \"64\")]\npub struct WSADATA {\n    pub wVersion: WORD,\n    pub wHighVersion: WORD,\n    pub iMaxSockets: u16,\n    pub iMaxUdpDg: u16,\n    pub lpVendorInfo: *mut u8,\n    pub szDescription: [u8; WSADESCRIPTION_LEN + 1],\n    pub szSystemStatus: [u8; WSASYS_STATUS_LEN + 1],\n}\n\n#[derive(Copy, Clone)]\n#[repr(C)]\npub struct WSABUF {\n    pub len: ULONG,\n    pub buf: *mut CHAR,\n}\n\n#[repr(C)]\npub struct WSAPROTOCOL_INFO {\n    pub dwServiceFlags1: DWORD,\n    pub dwServiceFlags2: DWORD,\n    pub dwServiceFlags3: DWORD,\n    pub dwServiceFlags4: DWORD,\n    pub dwProviderFlags: DWORD,\n    pub ProviderId: GUID,\n    pub dwCatalogEntryId: DWORD,\n    pub ProtocolChain: WSAPROTOCOLCHAIN,\n    pub iVersion: c_int,\n    pub iAddressFamily: c_int,\n    pub iMaxSockAddr: c_int,\n    pub iMinSockAddr: c_int,\n    pub iSocketType: c_int,\n    pub iProtocol: c_int,\n    pub iProtocolMaxOffset: c_int,\n    pub iNetworkByteOrder: c_int,\n    pub iSecurityScheme: c_int,\n    pub dwMessageSize: DWORD,\n    pub dwProviderReserved: DWORD,\n    pub szProtocol: [u16; (WSAPROTOCOL_LEN as usize) + 1],\n}\n\n#[repr(C)]\n#[derive(Copy, Clone)]\npub struct WIN32_FILE_ATTRIBUTE_DATA {\n    pub dwFileAttributes: DWORD,\n    pub ftCreationTime: FILETIME,\n    pub ftLastAccessTime: FILETIME,\n    pub ftLastWriteTime: FILETIME,\n    pub nFileSizeHigh: DWORD,\n    pub nFileSizeLow: DWORD,\n}\n\n#[repr(C)]\n#[allow(dead_code)] // we only use some variants\npub enum FILE_INFO_BY_HANDLE_CLASS {\n    FileBasicInfo = 0,\n    FileStandardInfo = 1,\n    FileNameInfo = 2,\n    FileRenameInfo = 3,\n    FileDispositionInfo = 4,\n    FileAllocationInfo = 5,\n    FileEndOfFileInfo = 6,\n    FileStreamInfo = 7,\n    FileCompressionInfo = 8,\n    FileAttributeTagInfo = 9,\n    FileIdBothDirectoryInfo = 10,        // 0xA\n    FileIdBothDirectoryRestartInfo = 11, // 0xB\n    FileIoPriorityHintInfo = 12,         // 0xC\n    FileRemoteProtocolInfo = 13,         // 0xD\n    FileFullDirectoryInfo = 14,          // 0xE\n    FileFullDirectoryRestartInfo = 15,   // 0xF\n    FileStorageInfo = 16,                // 0x10\n    FileAlignmentInfo = 17,              // 0x11\n    FileIdInfo = 18,                     // 0x12\n    FileIdExtdDirectoryInfo = 19,        // 0x13\n    FileIdExtdDirectoryRestartInfo = 20, // 0x14\n    MaximumFileInfoByHandlesClass,\n}\n\n#[repr(C)]\npub struct FILE_BASIC_INFO {\n    pub CreationTime: LARGE_INTEGER,\n    pub LastAccessTime: LARGE_INTEGER,\n    pub LastWriteTime: LARGE_INTEGER,\n    pub ChangeTime: LARGE_INTEGER,\n    pub FileAttributes: DWORD,\n}\n\n#[repr(C)]\npub struct FILE_END_OF_FILE_INFO {\n    pub EndOfFile: LARGE_INTEGER,\n}\n\n#[repr(C)]\npub struct REPARSE_DATA_BUFFER {\n    pub ReparseTag: c_uint,\n    pub ReparseDataLength: c_ushort,\n    pub Reserved: c_ushort,\n    pub rest: (),\n}\n\n#[repr(C)]\npub struct SYMBOLIC_LINK_REPARSE_BUFFER {\n    pub SubstituteNameOffset: c_ushort,\n    pub SubstituteNameLength: c_ushort,\n    pub PrintNameOffset: c_ushort,\n    pub PrintNameLength: c_ushort,\n    pub Flags: c_ulong,\n    pub PathBuffer: WCHAR,\n}\n\n#[repr(C)]\npub struct MOUNT_POINT_REPARSE_BUFFER {\n    pub SubstituteNameOffset: c_ushort,\n    pub SubstituteNameLength: c_ushort,\n    pub PrintNameOffset: c_ushort,\n    pub PrintNameLength: c_ushort,\n    pub PathBuffer: WCHAR,\n}\n\npub type LPPROGRESS_ROUTINE = crate::option::Option<\n    unsafe extern \"system\" fn(\n        TotalFileSize: LARGE_INTEGER,\n        TotalBytesTransferred: LARGE_INTEGER,\n        StreamSize: LARGE_INTEGER,\n        StreamBytesTransferred: LARGE_INTEGER,\n        dwStreamNumber: DWORD,\n        dwCallbackReason: DWORD,\n        hSourceFile: HANDLE,\n        hDestinationFile: HANDLE,\n        lpData: LPVOID,\n    ) -> DWORD,\n>;\n\n#[repr(C)]\npub struct CONDITION_VARIABLE {\n    pub ptr: LPVOID,\n}\n#[repr(C)]\npub struct SRWLOCK {\n    pub ptr: LPVOID,\n}\n#[repr(C)]\npub struct CRITICAL_SECTION {\n    CriticalSectionDebug: LPVOID,\n    LockCount: LONG,\n    RecursionCount: LONG,\n    OwningThread: HANDLE,\n    LockSemaphore: HANDLE,\n    SpinCount: ULONG_PTR,\n}\n\n#[repr(C)]\npub struct REPARSE_MOUNTPOINT_DATA_BUFFER {\n    pub ReparseTag: DWORD,\n    pub ReparseDataLength: DWORD,\n    pub Reserved: WORD,\n    pub ReparseTargetLength: WORD,\n    pub ReparseTargetMaximumLength: WORD,\n    pub Reserved1: WORD,\n    pub ReparseTarget: WCHAR,\n}\n\n#[repr(C)]\npub struct GUID {\n    pub Data1: DWORD,\n    pub Data2: WORD,\n    pub Data3: WORD,\n    pub Data4: [BYTE; 8],\n}\n\n#[repr(C)]\npub struct WSAPROTOCOLCHAIN {\n    pub ChainLen: c_int,\n    pub ChainEntries: [DWORD; MAX_PROTOCOL_CHAIN as usize],\n}\n\n#[repr(C)]\npub struct SECURITY_ATTRIBUTES {\n    pub nLength: DWORD,\n    pub lpSecurityDescriptor: LPVOID,\n    pub bInheritHandle: BOOL,\n}\n\n#[repr(C)]\npub struct PROCESS_INFORMATION {\n    pub hProcess: HANDLE,\n    pub hThread: HANDLE,\n    pub dwProcessId: DWORD,\n    pub dwThreadId: DWORD,\n}\n\n#[repr(C)]\npub struct STARTUPINFO {\n    pub cb: DWORD,\n    pub lpReserved: LPWSTR,\n    pub lpDesktop: LPWSTR,\n    pub lpTitle: LPWSTR,\n    pub dwX: DWORD,\n    pub dwY: DWORD,\n    pub dwXSize: DWORD,\n    pub dwYSize: DWORD,\n    pub dwXCountChars: DWORD,\n    pub dwYCountCharts: DWORD,\n    pub dwFillAttribute: DWORD,\n    pub dwFlags: DWORD,\n    pub wShowWindow: WORD,\n    pub cbReserved2: WORD,\n    pub lpReserved2: LPBYTE,\n    pub hStdInput: HANDLE,\n    pub hStdOutput: HANDLE,\n    pub hStdError: HANDLE,\n}\n\n#[repr(C)]\npub struct SOCKADDR {\n    pub sa_family: ADDRESS_FAMILY,\n    pub sa_data: [CHAR; 14],\n}\n\n#[repr(C)]\n#[derive(Copy, Clone)]\npub struct FILETIME {\n    pub dwLowDateTime: DWORD,\n    pub dwHighDateTime: DWORD,\n}\n\n#[repr(C)]\npub struct SYSTEM_INFO {\n    pub wProcessorArchitecture: WORD,\n    pub wReserved: WORD,\n    pub dwPageSize: DWORD,\n    pub lpMinimumApplicationAddress: LPVOID,\n    pub lpMaximumApplicationAddress: LPVOID,\n    pub dwActiveProcessorMask: DWORD_PTR,\n    pub dwNumberOfProcessors: DWORD,\n    pub dwProcessorType: DWORD,\n    pub dwAllocationGranularity: DWORD,\n    pub wProcessorLevel: WORD,\n    pub wProcessorRevision: WORD,\n}\n\n#[repr(C)]\npub struct OVERLAPPED {\n    pub Internal: *mut c_ulong,\n    pub InternalHigh: *mut c_ulong,\n    pub Offset: DWORD,\n    pub OffsetHigh: DWORD,\n    pub hEvent: HANDLE,\n}\n\n#[repr(C)]\n#[allow(dead_code)] // we only use some variants\npub enum ADDRESS_MODE {\n    AddrMode1616,\n    AddrMode1632,\n    AddrModeReal,\n    AddrModeFlat,\n}\n\n#[repr(C)]\npub struct SOCKADDR_STORAGE_LH {\n    pub ss_family: ADDRESS_FAMILY,\n    pub __ss_pad1: [CHAR; 6],\n    pub __ss_align: i64,\n    pub __ss_pad2: [CHAR; 112],\n}\n\n#[repr(C)]\npub struct ADDRINFOA {\n    pub ai_flags: c_int,\n    pub ai_family: c_int,\n    pub ai_socktype: c_int,\n    pub ai_protocol: c_int,\n    pub ai_addrlen: size_t,\n    pub ai_canonname: *mut c_char,\n    pub ai_addr: *mut SOCKADDR,\n    pub ai_next: *mut ADDRINFOA,\n}\n\n#[repr(C)]\n#[derive(Copy, Clone)]\npub struct sockaddr_in {\n    pub sin_family: ADDRESS_FAMILY,\n    pub sin_port: USHORT,\n    pub sin_addr: in_addr,\n    pub sin_zero: [CHAR; 8],\n}\n\n#[repr(C)]\n#[derive(Copy, Clone)]\npub struct sockaddr_in6 {\n    pub sin6_family: ADDRESS_FAMILY,\n    pub sin6_port: USHORT,\n    pub sin6_flowinfo: c_ulong,\n    pub sin6_addr: in6_addr,\n    pub sin6_scope_id: c_ulong,\n}\n\n#[repr(C)]\n#[derive(Copy, Clone)]\npub struct in_addr {\n    pub s_addr: u32,\n}\n\n#[repr(C)]\n#[derive(Copy, Clone)]\npub struct in6_addr {\n    pub s6_addr: [u8; 16],\n}\n\n#[repr(C)]\n#[derive(Copy, Clone)]\n#[allow(dead_code)] // we only use some variants\npub enum EXCEPTION_DISPOSITION {\n    ExceptionContinueExecution,\n    ExceptionContinueSearch,\n    ExceptionNestedException,\n    ExceptionCollidedUnwind,\n}\n\n#[repr(C)]\n#[derive(Copy)]\npub struct fd_set {\n    pub fd_count: c_uint,\n    pub fd_array: [SOCKET; FD_SETSIZE],\n}\n\nimpl Clone for fd_set {\n    fn clone(&self) -> fd_set {\n        *self\n    }\n}\n\n#[repr(C)]\n#[derive(Copy, Clone)]\npub struct timeval {\n    pub tv_sec: c_long,\n    pub tv_usec: c_long,\n}\n\n// Desktop specific functions & types\ncfg_if::cfg_if! {\nif #[cfg(not(target_vendor = \"uwp\"))] {\n    pub const EXCEPTION_CONTINUE_SEARCH: LONG = 0;\n    pub const EXCEPTION_STACK_OVERFLOW: DWORD = 0xc00000fd;\n    pub const EXCEPTION_MAXIMUM_PARAMETERS: usize = 15;\n\n    #[repr(C)]\n    pub struct EXCEPTION_RECORD {\n        pub ExceptionCode: DWORD,\n        pub ExceptionFlags: DWORD,\n        pub ExceptionRecord: *mut EXCEPTION_RECORD,\n        pub ExceptionAddress: LPVOID,\n        pub NumberParameters: DWORD,\n        pub ExceptionInformation: [LPVOID; EXCEPTION_MAXIMUM_PARAMETERS],\n    }\n\n    pub enum CONTEXT {}\n\n    #[repr(C)]\n    pub struct EXCEPTION_POINTERS {\n        pub ExceptionRecord: *mut EXCEPTION_RECORD,\n        pub ContextRecord: *mut CONTEXT,\n    }\n\n    pub type PVECTORED_EXCEPTION_HANDLER =\n        extern \"system\" fn(ExceptionInfo: *mut EXCEPTION_POINTERS) -> LONG;\n\n    #[repr(C)]\n    #[derive(Copy, Clone)]\n    pub struct CONSOLE_READCONSOLE_CONTROL {\n        pub nLength: ULONG,\n        pub nInitialChars: ULONG,\n        pub dwCtrlWakeupMask: ULONG,\n        pub dwControlKeyState: ULONG,\n    }\n\n    pub type PCONSOLE_READCONSOLE_CONTROL = *mut CONSOLE_READCONSOLE_CONTROL;\n\n    #[repr(C)]\n    pub struct BY_HANDLE_FILE_INFORMATION {\n        pub dwFileAttributes: DWORD,\n        pub ftCreationTime: FILETIME,\n        pub ftLastAccessTime: FILETIME,\n        pub ftLastWriteTime: FILETIME,\n        pub dwVolumeSerialNumber: DWORD,\n        pub nFileSizeHigh: DWORD,\n        pub nFileSizeLow: DWORD,\n        pub nNumberOfLinks: DWORD,\n        pub nFileIndexHigh: DWORD,\n        pub nFileIndexLow: DWORD,\n    }\n\n    pub type LPBY_HANDLE_FILE_INFORMATION = *mut BY_HANDLE_FILE_INFORMATION;\n    pub type LPCVOID = *const c_void;\n\n    pub const HANDLE_FLAG_INHERIT: DWORD = 0x00000001;\n\n    pub const TOKEN_READ: DWORD = 0x20008;\n\n    #[link(name = \"advapi32\")]\n    extern \"system\" {\n        // Forbidden when targeting UWP\n        #[link_name = \"SystemFunction036\"]\n        pub fn RtlGenRandom(RandomBuffer: *mut u8, RandomBufferLength: ULONG) -> BOOLEAN;\n\n        // Allowed but unused by UWP\n        pub fn OpenProcessToken(\n            ProcessHandle: HANDLE,\n            DesiredAccess: DWORD,\n            TokenHandle: *mut HANDLE,\n        ) -> BOOL;\n    }\n\n    #[link(name = \"userenv\")]\n    extern \"system\" {\n        // Allowed but unused by UWP\n        pub fn GetUserProfileDirectoryW(\n            hToken: HANDLE,\n            lpProfileDir: LPWSTR,\n            lpcchSize: *mut DWORD,\n        ) -> BOOL;\n    }\n\n    #[link(name = \"kernel32\")]\n    extern \"system\" {\n        // Functions forbidden when targeting UWP\n        pub fn ReadConsoleW(\n            hConsoleInput: HANDLE,\n            lpBuffer: LPVOID,\n            nNumberOfCharsToRead: DWORD,\n            lpNumberOfCharsRead: LPDWORD,\n            pInputControl: PCONSOLE_READCONSOLE_CONTROL,\n        ) -> BOOL;\n\n        pub fn WriteConsoleW(\n            hConsoleOutput: HANDLE,\n            lpBuffer: LPCVOID,\n            nNumberOfCharsToWrite: DWORD,\n            lpNumberOfCharsWritten: LPDWORD,\n            lpReserved: LPVOID,\n        ) -> BOOL;\n\n        pub fn GetConsoleMode(hConsoleHandle: HANDLE, lpMode: LPDWORD) -> BOOL;\n        // Allowed but unused by UWP\n        pub fn GetFileInformationByHandle(\n            hFile: HANDLE,\n            lpFileInformation: LPBY_HANDLE_FILE_INFORMATION,\n        ) -> BOOL;\n        pub fn SetHandleInformation(hObject: HANDLE, dwMask: DWORD, dwFlags: DWORD) -> BOOL;\n        pub fn AddVectoredExceptionHandler(\n            FirstHandler: ULONG,\n            VectoredHandler: PVECTORED_EXCEPTION_HANDLER,\n        ) -> LPVOID;\n        pub fn CreateHardLinkW(\n            lpSymlinkFileName: LPCWSTR,\n            lpTargetFileName: LPCWSTR,\n            lpSecurityAttributes: LPSECURITY_ATTRIBUTES,\n        ) -> BOOL;\n        pub fn SetThreadStackGuarantee(_size: *mut c_ulong) -> BOOL;\n    }\n}\n}\n\n// UWP specific functions & types\ncfg_if::cfg_if! {\nif #[cfg(target_vendor = \"uwp\")] {\n    pub const BCRYPT_USE_SYSTEM_PREFERRED_RNG: DWORD = 0x00000002;\n\n    #[repr(C)]\n    pub struct FILE_STANDARD_INFO {\n        pub AllocationSize: LARGE_INTEGER,\n        pub EndOfFile: LARGE_INTEGER,\n        pub NumberOfLinks: DWORD,\n        pub DeletePending: BOOLEAN,\n        pub Directory: BOOLEAN,\n    }\n\n    #[link(name = \"bcrypt\")]\n    extern \"system\" {\n        pub fn BCryptGenRandom(\n            hAlgorithm: LPVOID,\n            pBuffer: *mut u8,\n            cbBuffer: ULONG,\n            dwFlags: ULONG,\n        ) -> LONG;\n    }\n    #[link(name = \"kernel32\")]\n    extern \"system\" {\n        pub fn GetFileInformationByHandleEx(\n            hFile: HANDLE,\n            fileInfoClass: FILE_INFO_BY_HANDLE_CLASS,\n            lpFileInformation: LPVOID,\n            dwBufferSize: DWORD,\n        ) -> BOOL;\n    }\n}\n}\n\n// Shared between Desktop & UWP\n\n#[link(name = \"kernel32\")]\nextern \"system\" {\n    pub fn GetCurrentProcessId() -> DWORD;\n    pub fn InitializeCriticalSection(CriticalSection: *mut CRITICAL_SECTION);\n    pub fn EnterCriticalSection(CriticalSection: *mut CRITICAL_SECTION);\n    pub fn TryEnterCriticalSection(CriticalSection: *mut CRITICAL_SECTION) -> BOOL;\n    pub fn LeaveCriticalSection(CriticalSection: *mut CRITICAL_SECTION);\n    pub fn DeleteCriticalSection(CriticalSection: *mut CRITICAL_SECTION);\n\n    pub fn RemoveDirectoryW(lpPathName: LPCWSTR) -> BOOL;\n    pub fn SetFileAttributesW(lpFileName: LPCWSTR, dwFileAttributes: DWORD) -> BOOL;\n    pub fn SetLastError(dwErrCode: DWORD);\n    pub fn GetCommandLineW() -> *mut LPCWSTR;\n    pub fn GetTempPathW(nBufferLength: DWORD, lpBuffer: LPCWSTR) -> DWORD;\n    pub fn GetCurrentProcess() -> HANDLE;\n    pub fn GetCurrentThread() -> HANDLE;\n    pub fn GetStdHandle(which: DWORD) -> HANDLE;\n    pub fn ExitProcess(uExitCode: c_uint) -> !;\n    pub fn DeviceIoControl(\n        hDevice: HANDLE,\n        dwIoControlCode: DWORD,\n        lpInBuffer: LPVOID,\n        nInBufferSize: DWORD,\n        lpOutBuffer: LPVOID,\n        nOutBufferSize: DWORD,\n        lpBytesReturned: LPDWORD,\n        lpOverlapped: LPOVERLAPPED,\n    ) -> BOOL;\n    pub fn CreateThread(\n        lpThreadAttributes: LPSECURITY_ATTRIBUTES,\n        dwStackSize: SIZE_T,\n        lpStartAddress: extern \"system\" fn(*mut c_void) -> DWORD,\n        lpParameter: LPVOID,\n        dwCreationFlags: DWORD,\n        lpThreadId: LPDWORD,\n    ) -> HANDLE;\n    pub fn WaitForSingleObject(hHandle: HANDLE, dwMilliseconds: DWORD) -> DWORD;\n    pub fn SwitchToThread() -> BOOL;\n    pub fn Sleep(dwMilliseconds: DWORD);\n    pub fn GetProcessId(handle: HANDLE) -> DWORD;\n    pub fn CopyFileExW(\n        lpExistingFileName: LPCWSTR,\n        lpNewFileName: LPCWSTR,\n        lpProgressRoutine: LPPROGRESS_ROUTINE,\n        lpData: LPVOID,\n        pbCancel: LPBOOL,\n        dwCopyFlags: DWORD,\n    ) -> BOOL;\n    pub fn FormatMessageW(\n        flags: DWORD,\n        lpSrc: LPVOID,\n        msgId: DWORD,\n        langId: DWORD,\n        buf: LPWSTR,\n        nsize: DWORD,\n        args: *const c_void,\n    ) -> DWORD;\n    pub fn TlsAlloc() -> DWORD;\n    pub fn TlsGetValue(dwTlsIndex: DWORD) -> LPVOID;\n    pub fn TlsSetValue(dwTlsIndex: DWORD, lpTlsvalue: LPVOID) -> BOOL;\n    pub fn GetLastError() -> DWORD;\n    pub fn QueryPerformanceFrequency(lpFrequency: *mut LARGE_INTEGER) -> BOOL;\n    pub fn QueryPerformanceCounter(lpPerformanceCount: *mut LARGE_INTEGER) -> BOOL;\n    pub fn GetExitCodeProcess(hProcess: HANDLE, lpExitCode: LPDWORD) -> BOOL;\n    pub fn TerminateProcess(hProcess: HANDLE, uExitCode: UINT) -> BOOL;\n    pub fn CreateProcessW(\n        lpApplicationName: LPCWSTR,\n        lpCommandLine: LPWSTR,\n        lpProcessAttributes: LPSECURITY_ATTRIBUTES,\n        lpThreadAttributes: LPSECURITY_ATTRIBUTES,\n        bInheritHandles: BOOL,\n        dwCreationFlags: DWORD,\n        lpEnvironment: LPVOID,\n        lpCurrentDirectory: LPCWSTR,\n        lpStartupInfo: LPSTARTUPINFO,\n        lpProcessInformation: LPPROCESS_INFORMATION,\n    ) -> BOOL;\n    pub fn GetEnvironmentVariableW(n: LPCWSTR, v: LPWSTR, nsize: DWORD) -> DWORD;\n    pub fn SetEnvironmentVariableW(n: LPCWSTR, v: LPCWSTR) -> BOOL;\n    pub fn GetEnvironmentStringsW() -> LPWCH;\n    pub fn FreeEnvironmentStringsW(env_ptr: LPWCH) -> BOOL;\n    pub fn GetModuleFileNameW(hModule: HMODULE, lpFilename: LPWSTR, nSize: DWORD) -> DWORD;\n    pub fn CreateDirectoryW(\n        lpPathName: LPCWSTR,\n        lpSecurityAttributes: LPSECURITY_ATTRIBUTES,\n    ) -> BOOL;\n    pub fn DeleteFileW(lpPathName: LPCWSTR) -> BOOL;\n    pub fn GetCurrentDirectoryW(nBufferLength: DWORD, lpBuffer: LPWSTR) -> DWORD;\n    pub fn SetCurrentDirectoryW(lpPathName: LPCWSTR) -> BOOL;\n    pub fn DuplicateHandle(\n        hSourceProcessHandle: HANDLE,\n        hSourceHandle: HANDLE,\n        hTargetProcessHandle: HANDLE,\n        lpTargetHandle: LPHANDLE,\n        dwDesiredAccess: DWORD,\n        bInheritHandle: BOOL,\n        dwOptions: DWORD,\n    ) -> BOOL;\n    pub fn ReadFile(\n        hFile: HANDLE,\n        lpBuffer: LPVOID,\n        nNumberOfBytesToRead: DWORD,\n        lpNumberOfBytesRead: LPDWORD,\n        lpOverlapped: LPOVERLAPPED,\n    ) -> BOOL;\n    pub fn WriteFile(\n        hFile: HANDLE,\n        lpBuffer: LPVOID,\n        nNumberOfBytesToWrite: DWORD,\n        lpNumberOfBytesWritten: LPDWORD,\n        lpOverlapped: LPOVERLAPPED,\n    ) -> BOOL;\n    pub fn CloseHandle(hObject: HANDLE) -> BOOL;\n    pub fn MoveFileExW(lpExistingFileName: LPCWSTR, lpNewFileName: LPCWSTR, dwFlags: DWORD)\n    -> BOOL;\n    pub fn SetFilePointerEx(\n        hFile: HANDLE,\n        liDistanceToMove: LARGE_INTEGER,\n        lpNewFilePointer: PLARGE_INTEGER,\n        dwMoveMethod: DWORD,\n    ) -> BOOL;\n    pub fn FlushFileBuffers(hFile: HANDLE) -> BOOL;\n    pub fn CreateFileW(\n        lpFileName: LPCWSTR,\n        dwDesiredAccess: DWORD,\n        dwShareMode: DWORD,\n        lpSecurityAttributes: LPSECURITY_ATTRIBUTES,\n        dwCreationDisposition: DWORD,\n        dwFlagsAndAttributes: DWORD,\n        hTemplateFile: HANDLE,\n    ) -> HANDLE;\n\n    pub fn FindFirstFileW(fileName: LPCWSTR, findFileData: LPWIN32_FIND_DATAW) -> HANDLE;\n    pub fn FindNextFileW(findFile: HANDLE, findFileData: LPWIN32_FIND_DATAW) -> BOOL;\n    pub fn FindClose(findFile: HANDLE) -> BOOL;\n\n    pub fn GetProcAddress(handle: HMODULE, name: LPCSTR) -> *mut c_void;\n    pub fn GetModuleHandleA(lpModuleName: LPCSTR) -> HMODULE;\n    pub fn GetModuleHandleW(lpModuleName: LPCWSTR) -> HMODULE;\n\n    pub fn GetSystemTimeAsFileTime(lpSystemTimeAsFileTime: LPFILETIME);\n    pub fn GetSystemInfo(lpSystemInfo: LPSYSTEM_INFO);\n\n    pub fn CreateEventW(\n        lpEventAttributes: LPSECURITY_ATTRIBUTES,\n        bManualReset: BOOL,\n        bInitialState: BOOL,\n        lpName: LPCWSTR,\n    ) -> HANDLE;\n    pub fn WaitForMultipleObjects(\n        nCount: DWORD,\n        lpHandles: *const HANDLE,\n        bWaitAll: BOOL,\n        dwMilliseconds: DWORD,\n    ) -> DWORD;\n    pub fn CreateNamedPipeW(\n        lpName: LPCWSTR,\n        dwOpenMode: DWORD,\n        dwPipeMode: DWORD,\n        nMaxInstances: DWORD,\n        nOutBufferSize: DWORD,\n        nInBufferSize: DWORD,\n        nDefaultTimeOut: DWORD,\n        lpSecurityAttributes: LPSECURITY_ATTRIBUTES,\n    ) -> HANDLE;\n    pub fn CancelIo(handle: HANDLE) -> BOOL;\n    pub fn GetOverlappedResult(\n        hFile: HANDLE,\n        lpOverlapped: LPOVERLAPPED,\n        lpNumberOfBytesTransferred: LPDWORD,\n        bWait: BOOL,\n    ) -> BOOL;\n    pub fn CreateSymbolicLinkW(\n        lpSymlinkFileName: LPCWSTR,\n        lpTargetFileName: LPCWSTR,\n        dwFlags: DWORD,\n    ) -> BOOLEAN;\n    pub fn GetFinalPathNameByHandleW(\n        hFile: HANDLE,\n        lpszFilePath: LPCWSTR,\n        cchFilePath: DWORD,\n        dwFlags: DWORD,\n    ) -> DWORD;\n    pub fn SetFileInformationByHandle(\n        hFile: HANDLE,\n        FileInformationClass: FILE_INFO_BY_HANDLE_CLASS,\n        lpFileInformation: LPVOID,\n        dwBufferSize: DWORD,\n    ) -> BOOL;\n    pub fn SleepConditionVariableSRW(\n        ConditionVariable: PCONDITION_VARIABLE,\n        SRWLock: PSRWLOCK,\n        dwMilliseconds: DWORD,\n        Flags: ULONG,\n    ) -> BOOL;\n\n    pub fn WakeConditionVariable(ConditionVariable: PCONDITION_VARIABLE);\n    pub fn WakeAllConditionVariable(ConditionVariable: PCONDITION_VARIABLE);\n\n    pub fn AcquireSRWLockExclusive(SRWLock: PSRWLOCK);\n    pub fn AcquireSRWLockShared(SRWLock: PSRWLOCK);\n    pub fn ReleaseSRWLockExclusive(SRWLock: PSRWLOCK);\n    pub fn ReleaseSRWLockShared(SRWLock: PSRWLOCK);\n    pub fn TryAcquireSRWLockExclusive(SRWLock: PSRWLOCK) -> BOOLEAN;\n    pub fn TryAcquireSRWLockShared(SRWLock: PSRWLOCK) -> BOOLEAN;\n}\n\n#[link(name = \"ws2_32\")]\nextern \"system\" {\n    pub fn WSAStartup(wVersionRequested: WORD, lpWSAData: LPWSADATA) -> c_int;\n    pub fn WSACleanup() -> c_int;\n    pub fn WSAGetLastError() -> c_int;\n    pub fn WSADuplicateSocketW(\n        s: SOCKET,\n        dwProcessId: DWORD,\n        lpProtocolInfo: LPWSAPROTOCOL_INFO,\n    ) -> c_int;\n    pub fn WSASend(\n        s: SOCKET,\n        lpBuffers: LPWSABUF,\n        dwBufferCount: DWORD,\n        lpNumberOfBytesSent: LPDWORD,\n        dwFlags: DWORD,\n        lpOverlapped: LPWSAOVERLAPPED,\n        lpCompletionRoutine: LPWSAOVERLAPPED_COMPLETION_ROUTINE,\n    ) -> c_int;\n    pub fn WSARecv(\n        s: SOCKET,\n        lpBuffers: LPWSABUF,\n        dwBufferCount: DWORD,\n        lpNumberOfBytesRecvd: LPDWORD,\n        lpFlags: LPDWORD,\n        lpOverlapped: LPWSAOVERLAPPED,\n        lpCompletionRoutine: LPWSAOVERLAPPED_COMPLETION_ROUTINE,\n    ) -> c_int;\n    pub fn WSASocketW(\n        af: c_int,\n        kind: c_int,\n        protocol: c_int,\n        lpProtocolInfo: LPWSAPROTOCOL_INFO,\n        g: GROUP,\n        dwFlags: DWORD,\n    ) -> SOCKET;\n    pub fn ioctlsocket(s: SOCKET, cmd: c_long, argp: *mut c_ulong) -> c_int;\n    pub fn closesocket(socket: SOCKET) -> c_int;\n    pub fn recv(socket: SOCKET, buf: *mut c_void, len: c_int, flags: c_int) -> c_int;\n    pub fn send(socket: SOCKET, buf: *const c_void, len: c_int, flags: c_int) -> c_int;\n    pub fn recvfrom(\n        socket: SOCKET,\n        buf: *mut c_void,\n        len: c_int,\n        flags: c_int,\n        addr: *mut SOCKADDR,\n        addrlen: *mut c_int,\n    ) -> c_int;\n    pub fn sendto(\n        socket: SOCKET,\n        buf: *const c_void,\n        len: c_int,\n        flags: c_int,\n        addr: *const SOCKADDR,\n        addrlen: c_int,\n    ) -> c_int;\n    pub fn shutdown(socket: SOCKET, how: c_int) -> c_int;\n    pub fn accept(socket: SOCKET, address: *mut SOCKADDR, address_len: *mut c_int) -> SOCKET;\n    pub fn getsockopt(\n        s: SOCKET,\n        level: c_int,\n        optname: c_int,\n        optval: *mut c_char,\n        optlen: *mut c_int,\n    ) -> c_int;\n    pub fn setsockopt(\n        s: SOCKET,\n        level: c_int,\n        optname: c_int,\n        optval: *const c_void,\n        optlen: c_int,\n    ) -> c_int;\n    pub fn getsockname(socket: SOCKET, address: *mut SOCKADDR, address_len: *mut c_int) -> c_int;\n    pub fn getpeername(socket: SOCKET, address: *mut SOCKADDR, address_len: *mut c_int) -> c_int;\n    pub fn bind(socket: SOCKET, address: *const SOCKADDR, address_len: socklen_t) -> c_int;\n    pub fn listen(socket: SOCKET, backlog: c_int) -> c_int;\n    pub fn connect(socket: SOCKET, address: *const SOCKADDR, len: c_int) -> c_int;\n    pub fn getaddrinfo(\n        node: *const c_char,\n        service: *const c_char,\n        hints: *const ADDRINFOA,\n        res: *mut *mut ADDRINFOA,\n    ) -> c_int;\n    pub fn freeaddrinfo(res: *mut ADDRINFOA);\n    pub fn select(\n        nfds: c_int,\n        readfds: *mut fd_set,\n        writefds: *mut fd_set,\n        exceptfds: *mut fd_set,\n        timeout: *const timeval,\n    ) -> c_int;\n}\n\n// Functions that aren't available on every version of Windows that we support,\n// but we still use them and just provide some form of a fallback implementation.\ncompat_fn! {\n    \"kernel32\":\n\n    // >= Win10 1607\n    // https://docs.microsoft.com/en-us/windows/win32/api/processthreadsapi/nf-processthreadsapi-setthreaddescription\n    pub fn SetThreadDescription(hThread: HANDLE,\n                                lpThreadDescription: LPCWSTR) -> HRESULT {\n        SetLastError(ERROR_CALL_NOT_IMPLEMENTED as DWORD); E_NOTIMPL\n    }\n\n    // >= Win8 / Server 2012\n    // https://docs.microsoft.com/en-us/windows/win32/api/sysinfoapi/nf-sysinfoapi-getsystemtimepreciseasfiletime\n    pub fn GetSystemTimePreciseAsFileTime(lpSystemTimeAsFileTime: LPFILETIME)\n                                          -> () {\n        GetSystemTimeAsFileTime(lpSystemTimeAsFileTime)\n    }\n}\n\ncompat_fn! {\n    \"api-ms-win-core-synch-l1-2-0\":\n\n    // >= Windows 8 / Server 2012\n    // https://docs.microsoft.com/en-us/windows/win32/api/synchapi/nf-synchapi-waitonaddress\n    pub fn WaitOnAddress(\n        Address: LPVOID,\n        CompareAddress: LPVOID,\n        AddressSize: SIZE_T,\n        dwMilliseconds: DWORD\n    ) -> BOOL {\n        panic!(\"WaitOnAddress not available\")\n    }\n    pub fn WakeByAddressSingle(Address: LPVOID) -> () {\n        // If this api is unavailable, there cannot be anything waiting, because\n        // WaitOnAddress would've panicked. So it's fine to do nothing here.\n    }\n}\n\ncompat_fn! {\n    \"ntdll\":\n    pub fn NtCreateKeyedEvent(\n        KeyedEventHandle: LPHANDLE,\n        DesiredAccess: ACCESS_MASK,\n        ObjectAttributes: LPVOID,\n        Flags: ULONG\n    ) -> NTSTATUS {\n        panic!(\"keyed events not available\")\n    }\n    pub fn NtReleaseKeyedEvent(\n        EventHandle: HANDLE,\n        Key: LPVOID,\n        Alertable: BOOLEAN,\n        Timeout: PLARGE_INTEGER\n    ) -> NTSTATUS {\n        panic!(\"keyed events not available\")\n    }\n    pub fn NtWaitForKeyedEvent(\n        EventHandle: HANDLE,\n        Key: LPVOID,\n        Alertable: BOOLEAN,\n        Timeout: PLARGE_INTEGER\n    ) -> NTSTATUS {\n        panic!(\"keyed events not available\")\n    }\n}\n"],[2360,"use crate::cell::UnsafeCell;\nuse crate::sys::c;\nuse crate::sys::mutex::{self, Mutex};\nuse crate::sys::os;\nuse crate::time::Duration;\n\npub struct Condvar {\n    inner: UnsafeCell<c::CONDITION_VARIABLE>,\n}\n\npub type MovableCondvar = Condvar;\n\nunsafe impl Send for Condvar {}\nunsafe impl Sync for Condvar {}\n\nimpl Condvar {\n    pub const fn new() -> Condvar {\n        Condvar { inner: UnsafeCell::new(c::CONDITION_VARIABLE_INIT) }\n    }\n\n    #[inline]\n    pub unsafe fn init(&mut self) {}\n\n    #[inline]\n    pub unsafe fn wait(&self, mutex: &Mutex) {\n        let r = c::SleepConditionVariableSRW(self.inner.get(), mutex::raw(mutex), c::INFINITE, 0);\n        debug_assert!(r != 0);\n    }\n\n    pub unsafe fn wait_timeout(&self, mutex: &Mutex, dur: Duration) -> bool {\n        let r = c::SleepConditionVariableSRW(\n            self.inner.get(),\n            mutex::raw(mutex),\n            super::dur2timeout(dur),\n            0,\n        );\n        if r == 0 {\n            debug_assert_eq!(os::errno() as usize, c::ERROR_TIMEOUT as usize);\n            false\n        } else {\n            true\n        }\n    }\n\n    #[inline]\n    pub unsafe fn notify_one(&self) {\n        c::WakeConditionVariable(self.inner.get())\n    }\n\n    #[inline]\n    pub unsafe fn notify_all(&self) {\n        c::WakeAllConditionVariable(self.inner.get())\n    }\n\n    pub unsafe fn destroy(&self) {\n        // ...\n    }\n}\n"],[2361,"#![unstable(feature = \"process_internals\", issue = \"none\")]\n\n#[cfg(test)]\nmod tests;\n\nuse crate::borrow::Borrow;\nuse crate::collections::BTreeMap;\nuse crate::convert::{TryFrom, TryInto};\nuse crate::env;\nuse crate::env::split_paths;\nuse crate::ffi::{OsStr, OsString};\nuse crate::fmt;\nuse crate::fs;\nuse crate::io::{self, Error, ErrorKind};\nuse crate::mem;\nuse crate::num::NonZeroI32;\nuse crate::os::windows::ffi::OsStrExt;\nuse crate::path::Path;\nuse crate::ptr;\nuse crate::sys::c;\nuse crate::sys::c::NonZeroDWORD;\nuse crate::sys::cvt;\nuse crate::sys::fs::{File, OpenOptions};\nuse crate::sys::handle::Handle;\nuse crate::sys::pipe::{self, AnonPipe};\nuse crate::sys::stdio;\nuse crate::sys_common::mutex::StaticMutex;\nuse crate::sys_common::process::{CommandEnv, CommandEnvs};\nuse crate::sys_common::AsInner;\n\nuse libc::{c_void, EXIT_FAILURE, EXIT_SUCCESS};\n\n////////////////////////////////////////////////////////////////////////////////\n// Command\n////////////////////////////////////////////////////////////////////////////////\n\n#[derive(Clone, Debug, Eq, PartialEq, Ord, PartialOrd)]\n#[doc(hidden)]\npub struct EnvKey(OsString);\n\nimpl From<OsString> for EnvKey {\n    fn from(mut k: OsString) -> Self {\n        k.make_ascii_uppercase();\n        EnvKey(k)\n    }\n}\n\nimpl From<EnvKey> for OsString {\n    fn from(k: EnvKey) -> Self {\n        k.0\n    }\n}\n\nimpl Borrow<OsStr> for EnvKey {\n    fn borrow(&self) -> &OsStr {\n        &self.0\n    }\n}\n\nimpl AsRef<OsStr> for EnvKey {\n    fn as_ref(&self) -> &OsStr {\n        &self.0\n    }\n}\n\nfn ensure_no_nuls<T: AsRef<OsStr>>(str: T) -> io::Result<T> {\n    if str.as_ref().encode_wide().any(|b| b == 0) {\n        Err(io::Error::new_const(ErrorKind::InvalidInput, &\"nul byte found in provided data\"))\n    } else {\n        Ok(str)\n    }\n}\n\npub struct Command {\n    program: OsString,\n    args: Vec<OsString>,\n    env: CommandEnv,\n    cwd: Option<OsString>,\n    flags: u32,\n    detach: bool, // not currently exposed in std::process\n    stdin: Option<Stdio>,\n    stdout: Option<Stdio>,\n    stderr: Option<Stdio>,\n    force_quotes_enabled: bool,\n}\n\npub enum Stdio {\n    Inherit,\n    Null,\n    MakePipe,\n    Handle(Handle),\n}\n\npub struct StdioPipes {\n    pub stdin: Option<AnonPipe>,\n    pub stdout: Option<AnonPipe>,\n    pub stderr: Option<AnonPipe>,\n}\n\nimpl Command {\n    pub fn new(program: &OsStr) -> Command {\n        Command {\n            program: program.to_os_string(),\n            args: Vec::new(),\n            env: Default::default(),\n            cwd: None,\n            flags: 0,\n            detach: false,\n            stdin: None,\n            stdout: None,\n            stderr: None,\n            force_quotes_enabled: false,\n        }\n    }\n\n    pub fn arg(&mut self, arg: &OsStr) {\n        self.args.push(arg.to_os_string())\n    }\n    pub fn env_mut(&mut self) -> &mut CommandEnv {\n        &mut self.env\n    }\n    pub fn cwd(&mut self, dir: &OsStr) {\n        self.cwd = Some(dir.to_os_string())\n    }\n    pub fn stdin(&mut self, stdin: Stdio) {\n        self.stdin = Some(stdin);\n    }\n    pub fn stdout(&mut self, stdout: Stdio) {\n        self.stdout = Some(stdout);\n    }\n    pub fn stderr(&mut self, stderr: Stdio) {\n        self.stderr = Some(stderr);\n    }\n    pub fn creation_flags(&mut self, flags: u32) {\n        self.flags = flags;\n    }\n\n    pub fn force_quotes(&mut self, enabled: bool) {\n        self.force_quotes_enabled = enabled;\n    }\n\n    pub fn get_program(&self) -> &OsStr {\n        &self.program\n    }\n\n    pub fn get_args(&self) -> CommandArgs<'_> {\n        let iter = self.args.iter();\n        CommandArgs { iter }\n    }\n\n    pub fn get_envs(&self) -> CommandEnvs<'_> {\n        self.env.iter()\n    }\n\n    pub fn get_current_dir(&self) -> Option<&Path> {\n        self.cwd.as_ref().map(|cwd| Path::new(cwd))\n    }\n\n    pub fn spawn(\n        &mut self,\n        default: Stdio,\n        needs_stdin: bool,\n    ) -> io::Result<(Process, StdioPipes)> {\n        let maybe_env = self.env.capture_if_changed();\n        // To have the spawning semantics of unix/windows stay the same, we need\n        // to read the *child's* PATH if one is provided. See #15149 for more\n        // details.\n        let program = maybe_env.as_ref().and_then(|env| {\n            if let Some(v) = env.get(OsStr::new(\"PATH\")) {\n                // Split the value and test each path to see if the\n                // program exists.\n                for path in split_paths(&v) {\n                    let path = path\n                        .join(self.program.to_str().unwrap())\n                        .with_extension(env::consts::EXE_EXTENSION);\n                    if fs::metadata(&path).is_ok() {\n                        return Some(path.into_os_string());\n                    }\n                }\n            }\n            None\n        });\n\n        let mut si = zeroed_startupinfo();\n        si.cb = mem::size_of::<c::STARTUPINFO>() as c::DWORD;\n        si.dwFlags = c::STARTF_USESTDHANDLES;\n\n        let program = program.as_ref().unwrap_or(&self.program);\n        let mut cmd_str = make_command_line(program, &self.args, self.force_quotes_enabled)?;\n        cmd_str.push(0); // add null terminator\n\n        // stolen from the libuv code.\n        let mut flags = self.flags | c::CREATE_UNICODE_ENVIRONMENT;\n        if self.detach {\n            flags |= c::DETACHED_PROCESS | c::CREATE_NEW_PROCESS_GROUP;\n        }\n\n        let (envp, _data) = make_envp(maybe_env)?;\n        let (dirp, _data) = make_dirp(self.cwd.as_ref())?;\n        let mut pi = zeroed_process_information();\n\n        // Prepare all stdio handles to be inherited by the child. This\n        // currently involves duplicating any existing ones with the ability to\n        // be inherited by child processes. Note, however, that once an\n        // inheritable handle is created, *any* spawned child will inherit that\n        // handle. We only want our own child to inherit this handle, so we wrap\n        // the remaining portion of this spawn in a mutex.\n        //\n        // For more information, msdn also has an article about this race:\n        // https://support.microsoft.com/kb/315939\n        static CREATE_PROCESS_LOCK: StaticMutex = StaticMutex::new();\n\n        let _guard = unsafe { CREATE_PROCESS_LOCK.lock() };\n\n        let mut pipes = StdioPipes { stdin: None, stdout: None, stderr: None };\n        let null = Stdio::Null;\n        let default_stdin = if needs_stdin { &default } else { &null };\n        let stdin = self.stdin.as_ref().unwrap_or(default_stdin);\n        let stdout = self.stdout.as_ref().unwrap_or(&default);\n        let stderr = self.stderr.as_ref().unwrap_or(&default);\n        let stdin = stdin.to_handle(c::STD_INPUT_HANDLE, &mut pipes.stdin)?;\n        let stdout = stdout.to_handle(c::STD_OUTPUT_HANDLE, &mut pipes.stdout)?;\n        let stderr = stderr.to_handle(c::STD_ERROR_HANDLE, &mut pipes.stderr)?;\n        si.hStdInput = stdin.raw();\n        si.hStdOutput = stdout.raw();\n        si.hStdError = stderr.raw();\n\n        unsafe {\n            cvt(c::CreateProcessW(\n                ptr::null(),\n                cmd_str.as_mut_ptr(),\n                ptr::null_mut(),\n                ptr::null_mut(),\n                c::TRUE,\n                flags,\n                envp,\n                dirp,\n                &mut si,\n                &mut pi,\n            ))\n        }?;\n\n        // We close the thread handle because we don't care about keeping\n        // the thread id valid, and we aren't keeping the thread handle\n        // around to be able to close it later.\n        drop(Handle::new(pi.hThread));\n\n        Ok((Process { handle: Handle::new(pi.hProcess) }, pipes))\n    }\n}\n\nimpl fmt::Debug for Command {\n    fn fmt(&self, f: &mut fmt::Formatter<'_>) -> fmt::Result {\n        write!(f, \"{:?}\", self.program)?;\n        for arg in &self.args {\n            write!(f, \" {:?}\", arg)?;\n        }\n        Ok(())\n    }\n}\n\nimpl Stdio {\n    fn to_handle(&self, stdio_id: c::DWORD, pipe: &mut Option<AnonPipe>) -> io::Result<Handle> {\n        match *self {\n            // If no stdio handle is available, then inherit means that it\n            // should still be unavailable so propagate the\n            // INVALID_HANDLE_VALUE.\n            Stdio::Inherit => match stdio::get_handle(stdio_id) {\n                Ok(io) => {\n                    let io = Handle::new(io);\n                    let ret = io.duplicate(0, true, c::DUPLICATE_SAME_ACCESS);\n                    io.into_raw();\n                    ret\n                }\n                Err(..) => Ok(Handle::new(c::INVALID_HANDLE_VALUE)),\n            },\n\n            Stdio::MakePipe => {\n                let ours_readable = stdio_id != c::STD_INPUT_HANDLE;\n                let pipes = pipe::anon_pipe(ours_readable, true)?;\n                *pipe = Some(pipes.ours);\n                Ok(pipes.theirs.into_handle())\n            }\n\n            Stdio::Handle(ref handle) => handle.duplicate(0, true, c::DUPLICATE_SAME_ACCESS),\n\n            // Open up a reference to NUL with appropriate read/write\n            // permissions as well as the ability to be inherited to child\n            // processes (as this is about to be inherited).\n            Stdio::Null => {\n                let size = mem::size_of::<c::SECURITY_ATTRIBUTES>();\n                let mut sa = c::SECURITY_ATTRIBUTES {\n                    nLength: size as c::DWORD,\n                    lpSecurityDescriptor: ptr::null_mut(),\n                    bInheritHandle: 1,\n                };\n                let mut opts = OpenOptions::new();\n                opts.read(stdio_id == c::STD_INPUT_HANDLE);\n                opts.write(stdio_id != c::STD_INPUT_HANDLE);\n                opts.security_attributes(&mut sa);\n                File::open(Path::new(\"NUL\"), &opts).map(|file| file.into_handle())\n            }\n        }\n    }\n}\n\nimpl From<AnonPipe> for Stdio {\n    fn from(pipe: AnonPipe) -> Stdio {\n        Stdio::Handle(pipe.into_handle())\n    }\n}\n\nimpl From<File> for Stdio {\n    fn from(file: File) -> Stdio {\n        Stdio::Handle(file.into_handle())\n    }\n}\n\n////////////////////////////////////////////////////////////////////////////////\n// Processes\n////////////////////////////////////////////////////////////////////////////////\n\n/// A value representing a child process.\n///\n/// The lifetime of this value is linked to the lifetime of the actual\n/// process - the Process destructor calls self.finish() which waits\n/// for the process to terminate.\npub struct Process {\n    handle: Handle,\n}\n\nimpl Process {\n    pub fn kill(&mut self) -> io::Result<()> {\n        cvt(unsafe { c::TerminateProcess(self.handle.raw(), 1) })?;\n        Ok(())\n    }\n\n    pub fn id(&self) -> u32 {\n        unsafe { c::GetProcessId(self.handle.raw()) as u32 }\n    }\n\n    pub fn wait(&mut self) -> io::Result<ExitStatus> {\n        unsafe {\n            let res = c::WaitForSingleObject(self.handle.raw(), c::INFINITE);\n            if res != c::WAIT_OBJECT_0 {\n                return Err(Error::last_os_error());\n            }\n            let mut status = 0;\n            cvt(c::GetExitCodeProcess(self.handle.raw(), &mut status))?;\n            Ok(ExitStatus(status))\n        }\n    }\n\n    pub fn try_wait(&mut self) -> io::Result<Option<ExitStatus>> {\n        unsafe {\n            match c::WaitForSingleObject(self.handle.raw(), 0) {\n                c::WAIT_OBJECT_0 => {}\n                c::WAIT_TIMEOUT => {\n                    return Ok(None);\n                }\n                _ => return Err(io::Error::last_os_error()),\n            }\n            let mut status = 0;\n            cvt(c::GetExitCodeProcess(self.handle.raw(), &mut status))?;\n            Ok(Some(ExitStatus(status)))\n        }\n    }\n\n    pub fn handle(&self) -> &Handle {\n        &self.handle\n    }\n\n    pub fn into_handle(self) -> Handle {\n        self.handle\n    }\n}\n\n#[derive(PartialEq, Eq, Clone, Copy, Debug)]\npub struct ExitStatus(c::DWORD);\n\nimpl ExitStatus {\n    pub fn exit_ok(&self) -> Result<(), ExitStatusError> {\n        match NonZeroDWORD::try_from(self.0) {\n            /* was nonzero */ Ok(failure) => Err(ExitStatusError(failure)),\n            /* was zero, couldn't convert */ Err(_) => Ok(()),\n        }\n    }\n    pub fn code(&self) -> Option<i32> {\n        Some(self.0 as i32)\n    }\n}\n\n/// Converts a raw `c::DWORD` to a type-safe `ExitStatus` by wrapping it without copying.\nimpl From<c::DWORD> for ExitStatus {\n    fn from(u: c::DWORD) -> ExitStatus {\n        ExitStatus(u)\n    }\n}\n\nimpl fmt::Display for ExitStatus {\n    fn fmt(&self, f: &mut fmt::Formatter<'_>) -> fmt::Result {\n        // Windows exit codes with the high bit set typically mean some form of\n        // unhandled exception or warning. In this scenario printing the exit\n        // code in decimal doesn't always make sense because it's a very large\n        // and somewhat gibberish number. The hex code is a bit more\n        // recognizable and easier to search for, so print that.\n        if self.0 & 0x80000000 != 0 {\n            write!(f, \"exit code: {:#x}\", self.0)\n        } else {\n            write!(f, \"exit code: {}\", self.0)\n        }\n    }\n}\n\n#[derive(PartialEq, Eq, Clone, Copy, Debug)]\npub struct ExitStatusError(c::NonZeroDWORD);\n\nimpl Into<ExitStatus> for ExitStatusError {\n    fn into(self) -> ExitStatus {\n        ExitStatus(self.0.into())\n    }\n}\n\nimpl ExitStatusError {\n    pub fn code(self) -> Option<NonZeroI32> {\n        Some((u32::from(self.0) as i32).try_into().unwrap())\n    }\n}\n\n#[derive(PartialEq, Eq, Clone, Copy, Debug)]\npub struct ExitCode(c::DWORD);\n\nimpl ExitCode {\n    pub const SUCCESS: ExitCode = ExitCode(EXIT_SUCCESS as _);\n    pub const FAILURE: ExitCode = ExitCode(EXIT_FAILURE as _);\n\n    #[inline]\n    pub fn as_i32(&self) -> i32 {\n        self.0 as i32\n    }\n}\n\nfn zeroed_startupinfo() -> c::STARTUPINFO {\n    c::STARTUPINFO {\n        cb: 0,\n        lpReserved: ptr::null_mut(),\n        lpDesktop: ptr::null_mut(),\n        lpTitle: ptr::null_mut(),\n        dwX: 0,\n        dwY: 0,\n        dwXSize: 0,\n        dwYSize: 0,\n        dwXCountChars: 0,\n        dwYCountCharts: 0,\n        dwFillAttribute: 0,\n        dwFlags: 0,\n        wShowWindow: 0,\n        cbReserved2: 0,\n        lpReserved2: ptr::null_mut(),\n        hStdInput: c::INVALID_HANDLE_VALUE,\n        hStdOutput: c::INVALID_HANDLE_VALUE,\n        hStdError: c::INVALID_HANDLE_VALUE,\n    }\n}\n\nfn zeroed_process_information() -> c::PROCESS_INFORMATION {\n    c::PROCESS_INFORMATION {\n        hProcess: ptr::null_mut(),\n        hThread: ptr::null_mut(),\n        dwProcessId: 0,\n        dwThreadId: 0,\n    }\n}\n\n// Produces a wide string *without terminating null*; returns an error if\n// `prog` or any of the `args` contain a nul.\nfn make_command_line(prog: &OsStr, args: &[OsString], force_quotes: bool) -> io::Result<Vec<u16>> {\n    // Encode the command and arguments in a command line string such\n    // that the spawned process may recover them using CommandLineToArgvW.\n    let mut cmd: Vec<u16> = Vec::new();\n    // Always quote the program name so CreateProcess doesn't interpret args as\n    // part of the name if the binary wasn't found first time.\n    append_arg(&mut cmd, prog, true)?;\n    for arg in args {\n        cmd.push(' ' as u16);\n        append_arg(&mut cmd, arg, force_quotes)?;\n    }\n    return Ok(cmd);\n\n    fn append_arg(cmd: &mut Vec<u16>, arg: &OsStr, force_quotes: bool) -> io::Result<()> {\n        // If an argument has 0 characters then we need to quote it to ensure\n        // that it actually gets passed through on the command line or otherwise\n        // it will be dropped entirely when parsed on the other end.\n        ensure_no_nuls(arg)?;\n        let arg_bytes = &arg.as_inner().inner.as_inner();\n        let quote = force_quotes\n            || arg_bytes.iter().any(|c| *c == b' ' || *c == b'\\t')\n            || arg_bytes.is_empty();\n        if quote {\n            cmd.push('\"' as u16);\n        }\n\n        let mut backslashes: usize = 0;\n        for x in arg.encode_wide() {\n            if x == '\\\\' as u16 {\n                backslashes += 1;\n            } else {\n                if x == '\"' as u16 {\n                    // Add n+1 backslashes to total 2n+1 before internal '\"'.\n                    cmd.extend((0..=backslashes).map(|_| '\\\\' as u16));\n                }\n                backslashes = 0;\n            }\n            cmd.push(x);\n        }\n\n        if quote {\n            // Add n backslashes to total 2n before ending '\"'.\n            cmd.extend((0..backslashes).map(|_| '\\\\' as u16));\n            cmd.push('\"' as u16);\n        }\n        Ok(())\n    }\n}\n\nfn make_envp(maybe_env: Option<BTreeMap<EnvKey, OsString>>) -> io::Result<(*mut c_void, Vec<u16>)> {\n    // On Windows we pass an \"environment block\" which is not a char**, but\n    // rather a concatenation of null-terminated k=v\\0 sequences, with a final\n    // \\0 to terminate.\n    if let Some(env) = maybe_env {\n        let mut blk = Vec::new();\n\n        // If there are no environment variables to set then signal this by\n        // pushing a null.\n        if env.is_empty() {\n            blk.push(0);\n        }\n\n        for (k, v) in env {\n            blk.extend(ensure_no_nuls(k.0)?.encode_wide());\n            blk.push('=' as u16);\n            blk.extend(ensure_no_nuls(v)?.encode_wide());\n            blk.push(0);\n        }\n        blk.push(0);\n        Ok((blk.as_mut_ptr() as *mut c_void, blk))\n    } else {\n        Ok((ptr::null_mut(), Vec::new()))\n    }\n}\n\nfn make_dirp(d: Option<&OsString>) -> io::Result<(*const u16, Vec<u16>)> {\n    match d {\n        Some(dir) => {\n            let mut dir_str: Vec<u16> = ensure_no_nuls(dir)?.encode_wide().collect();\n            dir_str.push(0);\n            Ok((dir_str.as_ptr(), dir_str))\n        }\n        None => Ok((ptr::null(), Vec::new())),\n    }\n}\n\npub struct CommandArgs<'a> {\n    iter: crate::slice::Iter<'a, OsString>,\n}\n\nimpl<'a> Iterator for CommandArgs<'a> {\n    type Item = &'a OsStr;\n    fn next(&mut self) -> Option<&'a OsStr> {\n        self.iter.next().map(|s| s.as_ref())\n    }\n    fn size_hint(&self) -> (usize, Option<usize>) {\n        self.iter.size_hint()\n    }\n}\n\nimpl<'a> ExactSizeIterator for CommandArgs<'a> {\n    fn len(&self) -> usize {\n        self.iter.len()\n    }\n    fn is_empty(&self) -> bool {\n        self.iter.is_empty()\n    }\n}\n\nimpl<'a> fmt::Debug for CommandArgs<'a> {\n    fn fmt(&self, f: &mut fmt::Formatter<'_>) -> fmt::Result {\n        f.debug_list().entries(self.iter.clone()).finish()\n    }\n}\n"],[2362,"//! System Mutexes\n//!\n//! The Windows implementation of mutexes is a little odd and it may not be\n//! immediately obvious what's going on. The primary oddness is that SRWLock is\n//! used instead of CriticalSection, and this is done because:\n//!\n//! 1. SRWLock is several times faster than CriticalSection according to\n//!    benchmarks performed on both Windows 8 and Windows 7.\n//!\n//! 2. CriticalSection allows recursive locking while SRWLock deadlocks. The\n//!    Unix implementation deadlocks so consistency is preferred. See #19962 for\n//!    more details.\n//!\n//! 3. While CriticalSection is fair and SRWLock is not, the current Rust policy\n//!    is that there are no guarantees of fairness.\n\nuse crate::cell::UnsafeCell;\nuse crate::mem::MaybeUninit;\nuse crate::sys::c;\n\npub struct Mutex {\n    srwlock: UnsafeCell<c::SRWLOCK>,\n}\n\n// Windows SRW Locks are movable (while not borrowed).\npub type MovableMutex = Mutex;\n\nunsafe impl Send for Mutex {}\nunsafe impl Sync for Mutex {}\n\n#[inline]\npub unsafe fn raw(m: &Mutex) -> c::PSRWLOCK {\n    m.srwlock.get()\n}\n\nimpl Mutex {\n    pub const fn new() -> Mutex {\n        Mutex { srwlock: UnsafeCell::new(c::SRWLOCK_INIT) }\n    }\n    #[inline]\n    pub unsafe fn init(&mut self) {}\n\n    #[inline]\n    pub unsafe fn lock(&self) {\n        c::AcquireSRWLockExclusive(raw(self));\n    }\n\n    #[inline]\n    pub unsafe fn try_lock(&self) -> bool {\n        c::TryAcquireSRWLockExclusive(raw(self)) != 0\n    }\n\n    #[inline]\n    pub unsafe fn unlock(&self) {\n        c::ReleaseSRWLockExclusive(raw(self));\n    }\n\n    #[inline]\n    pub unsafe fn destroy(&self) {\n        // SRWLock does not need to be destroyed.\n    }\n}\n\npub struct ReentrantMutex {\n    inner: MaybeUninit<UnsafeCell<c::CRITICAL_SECTION>>,\n}\n\nunsafe impl Send for ReentrantMutex {}\nunsafe impl Sync for ReentrantMutex {}\n\nimpl ReentrantMutex {\n    pub const fn uninitialized() -> ReentrantMutex {\n        ReentrantMutex { inner: MaybeUninit::uninit() }\n    }\n\n    pub unsafe fn init(&self) {\n        c::InitializeCriticalSection(UnsafeCell::raw_get(self.inner.as_ptr()));\n    }\n\n    pub unsafe fn lock(&self) {\n        c::EnterCriticalSection(UnsafeCell::raw_get(self.inner.as_ptr()));\n    }\n\n    #[inline]\n    pub unsafe fn try_lock(&self) -> bool {\n        c::TryEnterCriticalSection(UnsafeCell::raw_get(self.inner.as_ptr())) != 0\n    }\n\n    pub unsafe fn unlock(&self) {\n        c::LeaveCriticalSection(UnsafeCell::raw_get(self.inner.as_ptr()));\n    }\n\n    pub unsafe fn destroy(&self) {\n        c::DeleteCriticalSection(UnsafeCell::raw_get(self.inner.as_ptr()));\n    }\n}\n"],[2363,"// Thread parker implementation for Windows.\n//\n// This uses WaitOnAddress and WakeByAddressSingle if available (Windows 8+).\n// This modern API is exactly the same as the futex syscalls the Linux thread\n// parker uses. When These APIs are available, the implementation of this\n// thread parker matches the Linux thread parker exactly.\n//\n// However, when the modern API is not available, this implementation falls\n// back to NT Keyed Events, which are similar, but have some important\n// differences. These are available since Windows XP.\n//\n// WaitOnAddress first checks the state of the thread parker to make sure it no\n// WakeByAddressSingle calls can be missed between updating the parker state\n// and calling the function.\n//\n// NtWaitForKeyedEvent does not have this option, and unconditionally blocks\n// without checking the parker state first. Instead, NtReleaseKeyedEvent\n// (unlike WakeByAddressSingle) *blocks* until it woke up a thread waiting for\n// it by NtWaitForKeyedEvent. This way, we can be sure no events are missed,\n// but we need to be careful not to block unpark() if park_timeout() was woken\n// up by a timeout instead of unpark().\n//\n// Unlike WaitOnAddress, NtWaitForKeyedEvent/NtReleaseKeyedEvent operate on a\n// HANDLE (created with NtCreateKeyedEvent). This means that we can be sure\n// a succesfully awoken park() was awoken by unpark() and not a\n// NtReleaseKeyedEvent call from some other code, as these events are not only\n// matched by the key (address of the parker (state)), but also by this HANDLE.\n// We lazily allocate this handle the first time it is needed.\n//\n// The fast path (calling park() after unpark() was already called) and the\n// possible states are the same for both implementations. This is used here to\n// make sure the fast path does not even check which API to use, but can return\n// right away, independent of the used API. Only the slow paths (which will\n// actually block/wake a thread) check which API is available and have\n// different implementations.\n//\n// Unfortunately, NT Keyed Events are an undocumented Windows API. However:\n// - This API is relatively simple with obvious behaviour, and there are\n//   several (unofficial) articles documenting the details. [1]\n// - `parking_lot` has been using this API for years (on Windows versions\n//   before Windows 8). [2] Many big projects extensively use parking_lot,\n//   such as servo and the Rust compiler itself.\n// - It is the underlying API used by Windows SRW locks and Windows critical\n//   sections. [3] [4]\n// - The source code of the implementations of Wine, ReactOs, and Windows XP\n//   are available and match the expected behaviour.\n// - The main risk with an undocumented API is that it might change in the\n//   future. But since we only use it for older versions of Windows, that's not\n//   a problem.\n// - Even if these functions do not block or wake as we expect (which is\n//   unlikely, see all previous points), this implementation would still be\n//   memory safe. The NT Keyed Events API is only used to sleep/block in the\n//   right place.\n//\n// [1]: http://www.locklessinc.com/articles/keyed_events/\n// [2]: https://github.com/Amanieu/parking_lot/commit/43abbc964e\n// [3]: https://docs.microsoft.com/en-us/archive/msdn-magazine/2012/november/windows-with-c-the-evolution-of-synchronization-in-windows-and-c\n// [4]: Windows Internals, Part 1, ISBN 9780735671300\n\nuse crate::convert::TryFrom;\nuse crate::ptr;\nuse crate::sync::atomic::{\n    AtomicI8, AtomicUsize,\n    Ordering::{Acquire, Relaxed, Release},\n};\nuse crate::sys::{c, dur2timeout};\nuse crate::time::Duration;\n\npub struct Parker {\n    state: AtomicI8,\n}\n\nconst PARKED: i8 = -1;\nconst EMPTY: i8 = 0;\nconst NOTIFIED: i8 = 1;\n\n// Notes about memory ordering:\n//\n// Memory ordering is only relevant for the relative ordering of operations\n// between different variables. Even Ordering::Relaxed guarantees a\n// monotonic/consistent order when looking at just a single atomic variable.\n//\n// So, since this parker is just a single atomic variable, we only need to look\n// at the ordering guarantees we need to provide to the 'outside world'.\n//\n// The only memory ordering guarantee that parking and unparking provide, is\n// that things which happened before unpark() are visible on the thread\n// returning from park() afterwards. Otherwise, it was effectively unparked\n// before unpark() was called while still consuming the 'token'.\n//\n// In other words, unpark() needs to synchronize with the part of park() that\n// consumes the token and returns.\n//\n// This is done with a release-acquire synchronization, by using\n// Ordering::Release when writing NOTIFIED (the 'token') in unpark(), and using\n// Ordering::Acquire when reading this state in park() after waking up.\nimpl Parker {\n    pub fn new() -> Self {\n        Self { state: AtomicI8::new(EMPTY) }\n    }\n\n    // Assumes this is only called by the thread that owns the Parker,\n    // which means that `self.state != PARKED`.\n    pub unsafe fn park(&self) {\n        // Change NOTIFIED=>EMPTY or EMPTY=>PARKED, and directly return in the\n        // first case.\n        if self.state.fetch_sub(1, Acquire) == NOTIFIED {\n            return;\n        }\n\n        if let Some(wait_on_address) = c::WaitOnAddress::option() {\n            loop {\n                // Wait for something to happen, assuming it's still set to PARKED.\n                wait_on_address(self.ptr(), &PARKED as *const _ as c::LPVOID, 1, c::INFINITE);\n                // Change NOTIFIED=>EMPTY but leave PARKED alone.\n                if self.state.compare_exchange(NOTIFIED, EMPTY, Acquire, Acquire).is_ok() {\n                    // Actually woken up by unpark().\n                    return;\n                } else {\n                    // Spurious wake up. We loop to try again.\n                }\n            }\n        } else {\n            // Wait for unpark() to produce this event.\n            c::NtWaitForKeyedEvent(keyed_event_handle(), self.ptr(), 0, ptr::null_mut());\n            // Set the state back to EMPTY (from either PARKED or NOTIFIED).\n            // Note that we don't just write EMPTY, but use swap() to also\n            // include an acquire-ordered read to synchronize with unpark()'s\n            // release-ordered write.\n            self.state.swap(EMPTY, Acquire);\n        }\n    }\n\n    // Assumes this is only called by the thread that owns the Parker,\n    // which means that `self.state != PARKED`.\n    pub unsafe fn park_timeout(&self, timeout: Duration) {\n        // Change NOTIFIED=>EMPTY or EMPTY=>PARKED, and directly return in the\n        // first case.\n        if self.state.fetch_sub(1, Acquire) == NOTIFIED {\n            return;\n        }\n\n        if let Some(wait_on_address) = c::WaitOnAddress::option() {\n            // Wait for something to happen, assuming it's still set to PARKED.\n            wait_on_address(self.ptr(), &PARKED as *const _ as c::LPVOID, 1, dur2timeout(timeout));\n            // Set the state back to EMPTY (from either PARKED or NOTIFIED).\n            // Note that we don't just write EMPTY, but use swap() to also\n            // include an acquire-ordered read to synchronize with unpark()'s\n            // release-ordered write.\n            if self.state.swap(EMPTY, Acquire) == NOTIFIED {\n                // Actually woken up by unpark().\n            } else {\n                // Timeout or spurious wake up.\n                // We return either way, because we can't easily tell if it was the\n                // timeout or not.\n            }\n        } else {\n            // Need to wait for unpark() using NtWaitForKeyedEvent.\n            let handle = keyed_event_handle();\n\n            // NtWaitForKeyedEvent uses a unit of 100ns, and uses negative\n            // values to indicate a relative time on the monotonic clock.\n            // This is documented here for the underlying KeWaitForSingleObject function:\n            // https://docs.microsoft.com/en-us/windows-hardware/drivers/ddi/wdm/nf-wdm-kewaitforsingleobject\n            let mut timeout = match i64::try_from((timeout.as_nanos() + 99) / 100) {\n                Ok(t) => -t,\n                Err(_) => i64::MIN,\n            };\n\n            // Wait for unpark() to produce this event.\n            let unparked =\n                c::NtWaitForKeyedEvent(handle, self.ptr(), 0, &mut timeout) == c::STATUS_SUCCESS;\n\n            // Set the state back to EMPTY (from either PARKED or NOTIFIED).\n            let prev_state = self.state.swap(EMPTY, Acquire);\n\n            if !unparked && prev_state == NOTIFIED {\n                // We were awoken by a timeout, not by unpark(), but the state\n                // was set to NOTIFIED, which means we *just* missed an\n                // unpark(), which is now blocked on us to wait for it.\n                // Wait for it to consume the event and unblock that thread.\n                c::NtWaitForKeyedEvent(handle, self.ptr(), 0, ptr::null_mut());\n            }\n        }\n    }\n\n    pub fn unpark(&self) {\n        // Change PARKED=>NOTIFIED, EMPTY=>NOTIFIED, or NOTIFIED=>NOTIFIED, and\n        // wake the thread in the first case.\n        //\n        // Note that even NOTIFIED=>NOTIFIED results in a write. This is on\n        // purpose, to make sure every unpark() has a release-acquire ordering\n        // with park().\n        if self.state.swap(NOTIFIED, Release) == PARKED {\n            if let Some(wake_by_address_single) = c::WakeByAddressSingle::option() {\n                unsafe {\n                    wake_by_address_single(self.ptr());\n                }\n            } else {\n                // If we run NtReleaseKeyedEvent before the waiting thread runs\n                // NtWaitForKeyedEvent, this (shortly) blocks until we can wake it up.\n                // If the waiting thread wakes up before we run NtReleaseKeyedEvent\n                // (e.g. due to a timeout), this blocks until we do wake up a thread.\n                // To prevent this thread from blocking indefinitely in that case,\n                // park_impl() will, after seeing the state set to NOTIFIED after\n                // waking up, call NtWaitForKeyedEvent again to unblock us.\n                unsafe {\n                    c::NtReleaseKeyedEvent(keyed_event_handle(), self.ptr(), 0, ptr::null_mut());\n                }\n            }\n        }\n    }\n\n    fn ptr(&self) -> c::LPVOID {\n        &self.state as *const _ as c::LPVOID\n    }\n}\n\nfn keyed_event_handle() -> c::HANDLE {\n    const INVALID: usize = !0;\n    static HANDLE: AtomicUsize = AtomicUsize::new(INVALID);\n    match HANDLE.load(Relaxed) {\n        INVALID => {\n            let mut handle = c::INVALID_HANDLE_VALUE;\n            unsafe {\n                match c::NtCreateKeyedEvent(\n                    &mut handle,\n                    c::GENERIC_READ | c::GENERIC_WRITE,\n                    ptr::null_mut(),\n                    0,\n                ) {\n                    c::STATUS_SUCCESS => {}\n                    r => panic!(\"Unable to create keyed event handle: error {}\", r),\n                }\n            }\n            match HANDLE.compare_exchange(INVALID, handle as usize, Relaxed, Relaxed) {\n                Ok(_) => handle,\n                Err(h) => {\n                    // Lost the race to another thread initializing HANDLE before we did.\n                    // Closing our handle and using theirs instead.\n                    unsafe {\n                        c::CloseHandle(handle);\n                    }\n                    h as c::HANDLE\n                }\n            }\n        }\n        handle => handle as c::HANDLE,\n    }\n}\n"],[2364,"#![cfg_attr(test, allow(dead_code))]\n\npub struct Handler;\n\nimpl Handler {\n    pub fn new() -> Handler {\n        Handler\n    }\n}\n\npub unsafe fn init() {}\n"],[2365,"pub mod os {\n    pub const FAMILY: &str = \"windows\";\n    pub const OS: &str = \"windows\";\n    pub const DLL_PREFIX: &str = \"\";\n    pub const DLL_SUFFIX: &str = \".dll\";\n    pub const DLL_EXTENSION: &str = \"dll\";\n    pub const EXE_SUFFIX: &str = \".exe\";\n    pub const EXE_EXTENSION: &str = \"exe\";\n}\n"],[2366,"#![allow(missing_docs, nonstandard_style)]\n\nuse crate::ffi::{OsStr, OsString};\nuse crate::io::ErrorKind;\nuse crate::os::windows::ffi::{OsStrExt, OsStringExt};\nuse crate::path::PathBuf;\nuse crate::time::Duration;\n\npub use self::rand::hashmap_random_keys;\npub use libc::strlen;\n\n#[macro_use]\npub mod compat;\n\npub mod alloc;\npub mod args;\npub mod c;\npub mod cmath;\npub mod condvar;\npub mod env;\npub mod fs;\npub mod handle;\npub mod io;\npub mod memchr;\npub mod mutex;\npub mod net;\npub mod os;\npub mod os_str;\npub mod path;\npub mod pipe;\npub mod process;\npub mod rand;\npub mod rwlock;\npub mod thread;\npub mod thread_local_dtor;\npub mod thread_local_key;\npub mod thread_parker;\npub mod time;\ncfg_if::cfg_if! {\n    if #[cfg(not(target_vendor = \"uwp\"))] {\n        pub mod stdio;\n        pub mod stack_overflow;\n    } else {\n        pub mod stdio_uwp;\n        pub mod stack_overflow_uwp;\n        pub use self::stdio_uwp as stdio;\n        pub use self::stack_overflow_uwp as stack_overflow;\n    }\n}\n\n// SAFETY: must be called only once during runtime initialization.\n// NOTE: this is not guaranteed to run, for example when Rust code is called externally.\npub unsafe fn init(_argc: isize, _argv: *const *const u8) {\n    stack_overflow::init();\n}\n\n// SAFETY: must be called only once during runtime cleanup.\n// NOTE: this is not guaranteed to run, for example when the program aborts.\npub unsafe fn cleanup() {\n    net::cleanup();\n}\n\npub fn decode_error_kind(errno: i32) -> ErrorKind {\n    match errno as c::DWORD {\n        c::ERROR_ACCESS_DENIED => return ErrorKind::PermissionDenied,\n        c::ERROR_ALREADY_EXISTS => return ErrorKind::AlreadyExists,\n        c::ERROR_FILE_EXISTS => return ErrorKind::AlreadyExists,\n        c::ERROR_BROKEN_PIPE => return ErrorKind::BrokenPipe,\n        c::ERROR_FILE_NOT_FOUND => return ErrorKind::NotFound,\n        c::ERROR_PATH_NOT_FOUND => return ErrorKind::NotFound,\n        c::ERROR_NO_DATA => return ErrorKind::BrokenPipe,\n        c::ERROR_INVALID_PARAMETER => return ErrorKind::InvalidInput,\n        c::ERROR_NOT_ENOUGH_MEMORY | c::ERROR_OUTOFMEMORY => return ErrorKind::OutOfMemory,\n        c::ERROR_SEM_TIMEOUT\n        | c::WAIT_TIMEOUT\n        | c::ERROR_DRIVER_CANCEL_TIMEOUT\n        | c::ERROR_OPERATION_ABORTED\n        | c::ERROR_SERVICE_REQUEST_TIMEOUT\n        | c::ERROR_COUNTER_TIMEOUT\n        | c::ERROR_TIMEOUT\n        | c::ERROR_RESOURCE_CALL_TIMED_OUT\n        | c::ERROR_CTX_MODEM_RESPONSE_TIMEOUT\n        | c::ERROR_CTX_CLIENT_QUERY_TIMEOUT\n        | c::FRS_ERR_SYSVOL_POPULATE_TIMEOUT\n        | c::ERROR_DS_TIMELIMIT_EXCEEDED\n        | c::DNS_ERROR_RECORD_TIMED_OUT\n        | c::ERROR_IPSEC_IKE_TIMED_OUT\n        | c::ERROR_RUNLEVEL_SWITCH_TIMEOUT\n        | c::ERROR_RUNLEVEL_SWITCH_AGENT_TIMEOUT => return ErrorKind::TimedOut,\n        c::ERROR_CALL_NOT_IMPLEMENTED => return ErrorKind::Unsupported,\n        _ => {}\n    }\n\n    match errno {\n        c::WSAEACCES => ErrorKind::PermissionDenied,\n        c::WSAEADDRINUSE => ErrorKind::AddrInUse,\n        c::WSAEADDRNOTAVAIL => ErrorKind::AddrNotAvailable,\n        c::WSAECONNABORTED => ErrorKind::ConnectionAborted,\n        c::WSAECONNREFUSED => ErrorKind::ConnectionRefused,\n        c::WSAECONNRESET => ErrorKind::ConnectionReset,\n        c::WSAEINVAL => ErrorKind::InvalidInput,\n        c::WSAENOTCONN => ErrorKind::NotConnected,\n        c::WSAEWOULDBLOCK => ErrorKind::WouldBlock,\n        c::WSAETIMEDOUT => ErrorKind::TimedOut,\n\n        _ => ErrorKind::Other,\n    }\n}\n\npub fn unrolled_find_u16s(needle: u16, haystack: &[u16]) -> Option<usize> {\n    let ptr = haystack.as_ptr();\n    let mut start = &haystack[..];\n\n    // For performance reasons unfold the loop eight times.\n    while start.len() >= 8 {\n        macro_rules! if_return {\n            ($($n:literal,)+) => {\n                $(\n                    if start[$n] == needle {\n                        return Some((&start[$n] as *const u16 as usize - ptr as usize) / 2);\n                    }\n                )+\n            }\n        }\n\n        if_return!(0, 1, 2, 3, 4, 5, 6, 7,);\n\n        start = &start[8..];\n    }\n\n    for c in start {\n        if *c == needle {\n            return Some((c as *const u16 as usize - ptr as usize) / 2);\n        }\n    }\n    None\n}\n\npub fn to_u16s<S: AsRef<OsStr>>(s: S) -> crate::io::Result<Vec<u16>> {\n    fn inner(s: &OsStr) -> crate::io::Result<Vec<u16>> {\n        let mut maybe_result: Vec<u16> = s.encode_wide().collect();\n        if unrolled_find_u16s(0, &maybe_result).is_some() {\n            return Err(crate::io::Error::new_const(\n                ErrorKind::InvalidInput,\n                &\"strings passed to WinAPI cannot contain NULs\",\n            ));\n        }\n        maybe_result.push(0);\n        Ok(maybe_result)\n    }\n    inner(s.as_ref())\n}\n\n// Many Windows APIs follow a pattern of where we hand a buffer and then they\n// will report back to us how large the buffer should be or how many bytes\n// currently reside in the buffer. This function is an abstraction over these\n// functions by making them easier to call.\n//\n// The first callback, `f1`, is yielded a (pointer, len) pair which can be\n// passed to a syscall. The `ptr` is valid for `len` items (u16 in this case).\n// The closure is expected to return what the syscall returns which will be\n// interpreted by this function to determine if the syscall needs to be invoked\n// again (with more buffer space).\n//\n// Once the syscall has completed (errors bail out early) the second closure is\n// yielded the data which has been read from the syscall. The return value\n// from this closure is then the return value of the function.\nfn fill_utf16_buf<F1, F2, T>(mut f1: F1, f2: F2) -> crate::io::Result<T>\nwhere\n    F1: FnMut(*mut u16, c::DWORD) -> c::DWORD,\n    F2: FnOnce(&[u16]) -> T,\n{\n    // Start off with a stack buf but then spill over to the heap if we end up\n    // needing more space.\n    let mut stack_buf = [0u16; 512];\n    let mut heap_buf = Vec::new();\n    unsafe {\n        let mut n = stack_buf.len();\n        loop {\n            let buf = if n <= stack_buf.len() {\n                &mut stack_buf[..]\n            } else {\n                let extra = n - heap_buf.len();\n                heap_buf.reserve(extra);\n                heap_buf.set_len(n);\n                &mut heap_buf[..]\n            };\n\n            // This function is typically called on windows API functions which\n            // will return the correct length of the string, but these functions\n            // also return the `0` on error. In some cases, however, the\n            // returned \"correct length\" may actually be 0!\n            //\n            // To handle this case we call `SetLastError` to reset it to 0 and\n            // then check it again if we get the \"0 error value\". If the \"last\n            // error\" is still 0 then we interpret it as a 0 length buffer and\n            // not an actual error.\n            c::SetLastError(0);\n            let k = match f1(buf.as_mut_ptr(), n as c::DWORD) {\n                0 if c::GetLastError() == 0 => 0,\n                0 => return Err(crate::io::Error::last_os_error()),\n                n => n,\n            } as usize;\n            if k == n && c::GetLastError() == c::ERROR_INSUFFICIENT_BUFFER {\n                n *= 2;\n            } else if k >= n {\n                n = k;\n            } else {\n                return Ok(f2(&buf[..k]));\n            }\n        }\n    }\n}\n\nfn os2path(s: &[u16]) -> PathBuf {\n    PathBuf::from(OsString::from_wide(s))\n}\n\npub fn truncate_utf16_at_nul(v: &[u16]) -> &[u16] {\n    match unrolled_find_u16s(0, v) {\n        // don't include the 0\n        Some(i) => &v[..i],\n        None => v,\n    }\n}\n\npub trait IsZero {\n    fn is_zero(&self) -> bool;\n}\n\nmacro_rules! impl_is_zero {\n    ($($t:ident)*) => ($(impl IsZero for $t {\n        fn is_zero(&self) -> bool {\n            *self == 0\n        }\n    })*)\n}\n\nimpl_is_zero! { i8 i16 i32 i64 isize u8 u16 u32 u64 usize }\n\npub fn cvt<I: IsZero>(i: I) -> crate::io::Result<I> {\n    if i.is_zero() { Err(crate::io::Error::last_os_error()) } else { Ok(i) }\n}\n\npub fn dur2timeout(dur: Duration) -> c::DWORD {\n    // Note that a duration is a (u64, u32) (seconds, nanoseconds) pair, and the\n    // timeouts in windows APIs are typically u32 milliseconds. To translate, we\n    // have two pieces to take care of:\n    //\n    // * Nanosecond precision is rounded up\n    // * Greater than u32::MAX milliseconds (50 days) is rounded up to INFINITE\n    //   (never time out).\n    dur.as_secs()\n        .checked_mul(1000)\n        .and_then(|ms| ms.checked_add((dur.subsec_nanos() as u64) / 1_000_000))\n        .and_then(|ms| ms.checked_add(if dur.subsec_nanos() % 1_000_000 > 0 { 1 } else { 0 }))\n        .map(|ms| if ms > <c::DWORD>::MAX as u64 { c::INFINITE } else { ms as c::DWORD })\n        .unwrap_or(c::INFINITE)\n}\n\n/// Use `__fastfail` to abort the process\n///\n/// This is the same implementation as in libpanic_abort's `__rust_start_panic`. See\n/// that function for more information on `__fastfail`\n#[allow(unreachable_code)]\npub fn abort_internal() -> ! {\n    const FAST_FAIL_FATAL_APP_EXIT: usize = 7;\n    unsafe {\n        cfg_if::cfg_if! {\n            if #[cfg(any(target_arch = \"x86\", target_arch = \"x86_64\"))] {\n                asm!(\"int $$0x29\", in(\"ecx\") FAST_FAIL_FATAL_APP_EXIT);\n                crate::intrinsics::unreachable();\n            } else if #[cfg(all(target_arch = \"arm\", target_feature = \"thumb-mode\"))] {\n                asm!(\".inst 0xDEFB\", in(\"r0\") FAST_FAIL_FATAL_APP_EXIT);\n                crate::intrinsics::unreachable();\n            } else if #[cfg(target_arch = \"aarch64\")] {\n                asm!(\"brk 0xF003\", in(\"x0\") FAST_FAIL_FATAL_APP_EXIT);\n                crate::intrinsics::unreachable();\n            }\n        }\n    }\n    crate::intrinsics::abort();\n}\n"],[2367,"#![unstable(issue = \"none\", feature = \"windows_net\")]\n\nuse crate::cmp;\nuse crate::io::{self, IoSlice, IoSliceMut, Read};\nuse crate::mem;\nuse crate::net::{Shutdown, SocketAddr};\nuse crate::ptr;\nuse crate::sync::Once;\nuse crate::sys;\nuse crate::sys::c;\nuse crate::sys_common::net;\nuse crate::sys_common::{AsInner, FromInner, IntoInner};\nuse crate::time::Duration;\n\nuse libc::{c_int, c_long, c_ulong};\n\npub type wrlen_t = i32;\n\npub mod netc {\n    pub use crate::sys::c::ADDRESS_FAMILY as sa_family_t;\n    pub use crate::sys::c::ADDRINFOA as addrinfo;\n    pub use crate::sys::c::SOCKADDR as sockaddr;\n    pub use crate::sys::c::SOCKADDR_STORAGE_LH as sockaddr_storage;\n    pub use crate::sys::c::*;\n}\n\npub struct Socket(c::SOCKET);\n\nstatic INIT: Once = Once::new();\n\n/// Checks whether the Windows socket interface has been started already, and\n/// if not, starts it.\npub fn init() {\n    INIT.call_once(|| unsafe {\n        let mut data: c::WSADATA = mem::zeroed();\n        let ret = c::WSAStartup(\n            0x202, // version 2.2\n            &mut data,\n        );\n        assert_eq!(ret, 0);\n    });\n}\n\npub fn cleanup() {\n    if INIT.is_completed() {\n        // only close the socket interface if it has actually been started\n        unsafe {\n            c::WSACleanup();\n        }\n    }\n}\n\n/// Returns the last error from the Windows socket interface.\nfn last_error() -> io::Error {\n    io::Error::from_raw_os_error(unsafe { c::WSAGetLastError() })\n}\n\n#[doc(hidden)]\npub trait IsMinusOne {\n    fn is_minus_one(&self) -> bool;\n}\n\nmacro_rules! impl_is_minus_one {\n    ($($t:ident)*) => ($(impl IsMinusOne for $t {\n        fn is_minus_one(&self) -> bool {\n            *self == -1\n        }\n    })*)\n}\n\nimpl_is_minus_one! { i8 i16 i32 i64 isize }\n\n/// Checks if the signed integer is the Windows constant `SOCKET_ERROR` (-1)\n/// and if so, returns the last error from the Windows socket interface. This\n/// function must be called before another call to the socket API is made.\npub fn cvt<T: IsMinusOne>(t: T) -> io::Result<T> {\n    if t.is_minus_one() { Err(last_error()) } else { Ok(t) }\n}\n\n/// A variant of `cvt` for `getaddrinfo` which return 0 for a success.\npub fn cvt_gai(err: c_int) -> io::Result<()> {\n    if err == 0 { Ok(()) } else { Err(last_error()) }\n}\n\n/// Just to provide the same interface as sys/unix/net.rs\npub fn cvt_r<T, F>(mut f: F) -> io::Result<T>\nwhere\n    T: IsMinusOne,\n    F: FnMut() -> T,\n{\n    cvt(f())\n}\n\nimpl Socket {\n    pub fn new(addr: &SocketAddr, ty: c_int) -> io::Result<Socket> {\n        let family = match *addr {\n            SocketAddr::V4(..) => c::AF_INET,\n            SocketAddr::V6(..) => c::AF_INET6,\n        };\n        let socket = unsafe {\n            c::WSASocketW(\n                family,\n                ty,\n                0,\n                ptr::null_mut(),\n                0,\n                c::WSA_FLAG_OVERLAPPED | c::WSA_FLAG_NO_HANDLE_INHERIT,\n            )\n        };\n\n        if socket != c::INVALID_SOCKET {\n            Ok(Self(socket))\n        } else {\n            let error = unsafe { c::WSAGetLastError() };\n\n            if error != c::WSAEPROTOTYPE && error != c::WSAEINVAL {\n                return Err(io::Error::from_raw_os_error(error));\n            }\n\n            let socket =\n                unsafe { c::WSASocketW(family, ty, 0, ptr::null_mut(), 0, c::WSA_FLAG_OVERLAPPED) };\n\n            if socket == c::INVALID_SOCKET {\n                return Err(last_error());\n            }\n\n            let socket = Self(socket);\n            socket.set_no_inherit()?;\n            Ok(socket)\n        }\n    }\n\n    pub fn connect_timeout(&self, addr: &SocketAddr, timeout: Duration) -> io::Result<()> {\n        self.set_nonblocking(true)?;\n        let result = {\n            let (addrp, len) = addr.into_inner();\n            let result = unsafe { c::connect(self.0, addrp, len) };\n            cvt(result).map(drop)\n        };\n        self.set_nonblocking(false)?;\n\n        match result {\n            Err(ref error) if error.kind() == io::ErrorKind::WouldBlock => {\n                if timeout.as_secs() == 0 && timeout.subsec_nanos() == 0 {\n                    return Err(io::Error::new_const(\n                        io::ErrorKind::InvalidInput,\n                        &\"cannot set a 0 duration timeout\",\n                    ));\n                }\n\n                let mut timeout = c::timeval {\n                    tv_sec: timeout.as_secs() as c_long,\n                    tv_usec: (timeout.subsec_nanos() / 1000) as c_long,\n                };\n\n                if timeout.tv_sec == 0 && timeout.tv_usec == 0 {\n                    timeout.tv_usec = 1;\n                }\n\n                let fds = {\n                    let mut fds = unsafe { mem::zeroed::<c::fd_set>() };\n                    fds.fd_count = 1;\n                    fds.fd_array[0] = self.0;\n                    fds\n                };\n\n                let mut writefds = fds;\n                let mut errorfds = fds;\n\n                let count = {\n                    let result = unsafe {\n                        c::select(1, ptr::null_mut(), &mut writefds, &mut errorfds, &timeout)\n                    };\n                    cvt(result)?\n                };\n\n                match count {\n                    0 => {\n                        Err(io::Error::new_const(io::ErrorKind::TimedOut, &\"connection timed out\"))\n                    }\n                    _ => {\n                        if writefds.fd_count != 1 {\n                            if let Some(e) = self.take_error()? {\n                                return Err(e);\n                            }\n                        }\n\n                        Ok(())\n                    }\n                }\n            }\n            _ => result,\n        }\n    }\n\n    pub fn accept(&self, storage: *mut c::SOCKADDR, len: *mut c_int) -> io::Result<Socket> {\n        let socket = unsafe { c::accept(self.0, storage, len) };\n\n        match socket {\n            c::INVALID_SOCKET => Err(last_error()),\n            _ => Ok(Self(socket)),\n        }\n    }\n\n    pub fn duplicate(&self) -> io::Result<Socket> {\n        let mut info = unsafe { mem::zeroed::<c::WSAPROTOCOL_INFO>() };\n        let result = unsafe { c::WSADuplicateSocketW(self.0, c::GetCurrentProcessId(), &mut info) };\n        cvt(result)?;\n        let socket = unsafe {\n            c::WSASocketW(\n                info.iAddressFamily,\n                info.iSocketType,\n                info.iProtocol,\n                &mut info,\n                0,\n                c::WSA_FLAG_OVERLAPPED | c::WSA_FLAG_NO_HANDLE_INHERIT,\n            )\n        };\n\n        if socket != c::INVALID_SOCKET {\n            Ok(Self(socket))\n        } else {\n            let error = unsafe { c::WSAGetLastError() };\n\n            if error != c::WSAEPROTOTYPE && error != c::WSAEINVAL {\n                return Err(io::Error::from_raw_os_error(error));\n            }\n\n            let socket = unsafe {\n                c::WSASocketW(\n                    info.iAddressFamily,\n                    info.iSocketType,\n                    info.iProtocol,\n                    &mut info,\n                    0,\n                    c::WSA_FLAG_OVERLAPPED,\n                )\n            };\n\n            if socket == c::INVALID_SOCKET {\n                return Err(last_error());\n            }\n\n            let socket = Self(socket);\n            socket.set_no_inherit()?;\n            Ok(socket)\n        }\n    }\n\n    fn recv_with_flags(&self, buf: &mut [u8], flags: c_int) -> io::Result<usize> {\n        // On unix when a socket is shut down all further reads return 0, so we\n        // do the same on windows to map a shut down socket to returning EOF.\n        let length = cmp::min(buf.len(), i32::MAX as usize) as i32;\n        let result = unsafe { c::recv(self.0, buf.as_mut_ptr() as *mut _, length, flags) };\n\n        match result {\n            c::SOCKET_ERROR => {\n                let error = unsafe { c::WSAGetLastError() };\n\n                if error == c::WSAESHUTDOWN {\n                    Ok(0)\n                } else {\n                    Err(io::Error::from_raw_os_error(error))\n                }\n            }\n            _ => Ok(result as usize),\n        }\n    }\n\n    pub fn read(&self, buf: &mut [u8]) -> io::Result<usize> {\n        self.recv_with_flags(buf, 0)\n    }\n\n    pub fn read_vectored(&self, bufs: &mut [IoSliceMut<'_>]) -> io::Result<usize> {\n        // On unix when a socket is shut down all further reads return 0, so we\n        // do the same on windows to map a shut down socket to returning EOF.\n        let length = cmp::min(bufs.len(), c::DWORD::MAX as usize) as c::DWORD;\n        let mut nread = 0;\n        let mut flags = 0;\n        let result = unsafe {\n            c::WSARecv(\n                self.0,\n                bufs.as_mut_ptr() as *mut c::WSABUF,\n                length,\n                &mut nread,\n                &mut flags,\n                ptr::null_mut(),\n                ptr::null_mut(),\n            )\n        };\n\n        match result {\n            0 => Ok(nread as usize),\n            _ => {\n                let error = unsafe { c::WSAGetLastError() };\n\n                if error == c::WSAESHUTDOWN {\n                    Ok(0)\n                } else {\n                    Err(io::Error::from_raw_os_error(error))\n                }\n            }\n        }\n    }\n\n    #[inline]\n    pub fn is_read_vectored(&self) -> bool {\n        true\n    }\n\n    pub fn peek(&self, buf: &mut [u8]) -> io::Result<usize> {\n        self.recv_with_flags(buf, c::MSG_PEEK)\n    }\n\n    fn recv_from_with_flags(\n        &self,\n        buf: &mut [u8],\n        flags: c_int,\n    ) -> io::Result<(usize, SocketAddr)> {\n        let mut storage = unsafe { mem::zeroed::<c::SOCKADDR_STORAGE_LH>() };\n        let mut addrlen = mem::size_of_val(&storage) as c::socklen_t;\n        let length = cmp::min(buf.len(), <wrlen_t>::MAX as usize) as wrlen_t;\n\n        // On unix when a socket is shut down all further reads return 0, so we\n        // do the same on windows to map a shut down socket to returning EOF.\n        let result = unsafe {\n            c::recvfrom(\n                self.0,\n                buf.as_mut_ptr() as *mut _,\n                length,\n                flags,\n                &mut storage as *mut _ as *mut _,\n                &mut addrlen,\n            )\n        };\n\n        match result {\n            c::SOCKET_ERROR => {\n                let error = unsafe { c::WSAGetLastError() };\n\n                if error == c::WSAESHUTDOWN {\n                    Ok((0, net::sockaddr_to_addr(&storage, addrlen as usize)?))\n                } else {\n                    Err(io::Error::from_raw_os_error(error))\n                }\n            }\n            _ => Ok((result as usize, net::sockaddr_to_addr(&storage, addrlen as usize)?)),\n        }\n    }\n\n    pub fn recv_from(&self, buf: &mut [u8]) -> io::Result<(usize, SocketAddr)> {\n        self.recv_from_with_flags(buf, 0)\n    }\n\n    pub fn peek_from(&self, buf: &mut [u8]) -> io::Result<(usize, SocketAddr)> {\n        self.recv_from_with_flags(buf, c::MSG_PEEK)\n    }\n\n    pub fn write_vectored(&self, bufs: &[IoSlice<'_>]) -> io::Result<usize> {\n        let length = cmp::min(bufs.len(), c::DWORD::MAX as usize) as c::DWORD;\n        let mut nwritten = 0;\n        let result = unsafe {\n            c::WSASend(\n                self.0,\n                bufs.as_ptr() as *const c::WSABUF as *mut _,\n                length,\n                &mut nwritten,\n                0,\n                ptr::null_mut(),\n                ptr::null_mut(),\n            )\n        };\n        cvt(result).map(|_| nwritten as usize)\n    }\n\n    #[inline]\n    pub fn is_write_vectored(&self) -> bool {\n        true\n    }\n\n    pub fn set_timeout(&self, dur: Option<Duration>, kind: c_int) -> io::Result<()> {\n        let timeout = match dur {\n            Some(dur) => {\n                let timeout = sys::dur2timeout(dur);\n                if timeout == 0 {\n                    return Err(io::Error::new_const(\n                        io::ErrorKind::InvalidInput,\n                        &\"cannot set a 0 duration timeout\",\n                    ));\n                }\n                timeout\n            }\n            None => 0,\n        };\n        net::setsockopt(self, c::SOL_SOCKET, kind, timeout)\n    }\n\n    pub fn timeout(&self, kind: c_int) -> io::Result<Option<Duration>> {\n        let raw: c::DWORD = net::getsockopt(self, c::SOL_SOCKET, kind)?;\n        if raw == 0 {\n            Ok(None)\n        } else {\n            let secs = raw / 1000;\n            let nsec = (raw % 1000) * 1000000;\n            Ok(Some(Duration::new(secs as u64, nsec as u32)))\n        }\n    }\n\n    #[cfg(not(target_vendor = \"uwp\"))]\n    fn set_no_inherit(&self) -> io::Result<()> {\n        sys::cvt(unsafe { c::SetHandleInformation(self.0 as c::HANDLE, c::HANDLE_FLAG_INHERIT, 0) })\n            .map(drop)\n    }\n\n    #[cfg(target_vendor = \"uwp\")]\n    fn set_no_inherit(&self) -> io::Result<()> {\n        Err(io::Error::new_const(io::ErrorKind::Unsupported, &\"Unavailable on UWP\"))\n    }\n\n    pub fn shutdown(&self, how: Shutdown) -> io::Result<()> {\n        let how = match how {\n            Shutdown::Write => c::SD_SEND,\n            Shutdown::Read => c::SD_RECEIVE,\n            Shutdown::Both => c::SD_BOTH,\n        };\n        let result = unsafe { c::shutdown(self.0, how) };\n        cvt(result).map(drop)\n    }\n\n    pub fn set_nonblocking(&self, nonblocking: bool) -> io::Result<()> {\n        let mut nonblocking = nonblocking as c_ulong;\n        let result = unsafe { c::ioctlsocket(self.0, c::FIONBIO as c_int, &mut nonblocking) };\n        cvt(result).map(drop)\n    }\n\n    pub fn set_nodelay(&self, nodelay: bool) -> io::Result<()> {\n        net::setsockopt(self, c::IPPROTO_TCP, c::TCP_NODELAY, nodelay as c::BYTE)\n    }\n\n    pub fn nodelay(&self) -> io::Result<bool> {\n        let raw: c::BYTE = net::getsockopt(self, c::IPPROTO_TCP, c::TCP_NODELAY)?;\n        Ok(raw != 0)\n    }\n\n    pub fn take_error(&self) -> io::Result<Option<io::Error>> {\n        let raw: c_int = net::getsockopt(self, c::SOL_SOCKET, c::SO_ERROR)?;\n        if raw == 0 { Ok(None) } else { Ok(Some(io::Error::from_raw_os_error(raw as i32))) }\n    }\n}\n\n#[unstable(reason = \"not public\", issue = \"none\", feature = \"fd_read\")]\nimpl<'a> Read for &'a Socket {\n    fn read(&mut self, buf: &mut [u8]) -> io::Result<usize> {\n        (**self).read(buf)\n    }\n}\n\nimpl Drop for Socket {\n    fn drop(&mut self) {\n        let _ = unsafe { c::closesocket(self.0) };\n    }\n}\n\nimpl AsInner<c::SOCKET> for Socket {\n    fn as_inner(&self) -> &c::SOCKET {\n        &self.0\n    }\n}\n\nimpl FromInner<c::SOCKET> for Socket {\n    fn from_inner(sock: c::SOCKET) -> Socket {\n        Socket(sock)\n    }\n}\n\nimpl IntoInner<c::SOCKET> for Socket {\n    fn into_inner(self) -> c::SOCKET {\n        let ret = self.0;\n        mem::forget(self);\n        ret\n    }\n}\n"],[2368,"#![cfg(not(test))]\n\nuse libc::{c_double, c_float};\n\nextern \"C\" {\n    pub fn acos(n: c_double) -> c_double;\n    pub fn asin(n: c_double) -> c_double;\n    pub fn atan(n: c_double) -> c_double;\n    pub fn atan2(a: c_double, b: c_double) -> c_double;\n    pub fn cbrt(n: c_double) -> c_double;\n    pub fn cbrtf(n: c_float) -> c_float;\n    pub fn cosh(n: c_double) -> c_double;\n    pub fn expm1(n: c_double) -> c_double;\n    pub fn expm1f(n: c_float) -> c_float;\n    pub fn fdim(a: c_double, b: c_double) -> c_double;\n    pub fn fdimf(a: c_float, b: c_float) -> c_float;\n    #[cfg_attr(target_env = \"msvc\", link_name = \"_hypot\")]\n    pub fn hypot(x: c_double, y: c_double) -> c_double;\n    #[cfg_attr(target_env = \"msvc\", link_name = \"_hypotf\")]\n    pub fn hypotf(x: c_float, y: c_float) -> c_float;\n    pub fn log1p(n: c_double) -> c_double;\n    pub fn log1pf(n: c_float) -> c_float;\n    pub fn sinh(n: c_double) -> c_double;\n    pub fn tan(n: c_double) -> c_double;\n    pub fn tanh(n: c_double) -> c_double;\n}\n\npub use self::shims::*;\n\n#[cfg(not(all(target_env = \"msvc\", target_arch = \"x86\")))]\nmod shims {\n    use libc::c_float;\n\n    extern \"C\" {\n        pub fn acosf(n: c_float) -> c_float;\n        pub fn asinf(n: c_float) -> c_float;\n        pub fn atan2f(a: c_float, b: c_float) -> c_float;\n        pub fn atanf(n: c_float) -> c_float;\n        pub fn coshf(n: c_float) -> c_float;\n        pub fn sinhf(n: c_float) -> c_float;\n        pub fn tanf(n: c_float) -> c_float;\n        pub fn tanhf(n: c_float) -> c_float;\n    }\n}\n\n// On 32-bit x86 MSVC these functions aren't defined, so we just define shims\n// which promote everything fo f64, perform the calculation, and then demote\n// back to f32. While not precisely correct should be \"correct enough\" for now.\n#[cfg(all(target_env = \"msvc\", target_arch = \"x86\"))]\nmod shims {\n    use libc::c_float;\n\n    #[inline]\n    pub unsafe fn acosf(n: c_float) -> c_float {\n        f64::acos(n as f64) as c_float\n    }\n\n    #[inline]\n    pub unsafe fn asinf(n: c_float) -> c_float {\n        f64::asin(n as f64) as c_float\n    }\n\n    #[inline]\n    pub unsafe fn atan2f(n: c_float, b: c_float) -> c_float {\n        f64::atan2(n as f64, b as f64) as c_float\n    }\n\n    #[inline]\n    pub unsafe fn atanf(n: c_float) -> c_float {\n        f64::atan(n as f64) as c_float\n    }\n\n    #[inline]\n    pub unsafe fn coshf(n: c_float) -> c_float {\n        f64::cosh(n as f64) as c_float\n    }\n\n    #[inline]\n    pub unsafe fn sinhf(n: c_float) -> c_float {\n        f64::sinh(n as f64) as c_float\n    }\n\n    #[inline]\n    pub unsafe fn tanf(n: c_float) -> c_float {\n        f64::tan(n as f64) as c_float\n    }\n\n    #[inline]\n    pub unsafe fn tanhf(n: c_float) -> c_float {\n        f64::tanh(n as f64) as c_float\n    }\n}\n"],[2369,"use crate::io;\nuse crate::mem;\nuse crate::sys::c;\n\n#[cfg(not(target_vendor = \"uwp\"))]\npub fn hashmap_random_keys() -> (u64, u64) {\n    let mut v = (0, 0);\n    let ret =\n        unsafe { c::RtlGenRandom(&mut v as *mut _ as *mut u8, mem::size_of_val(&v) as c::ULONG) };\n    if ret == 0 {\n        panic!(\"couldn't generate random bytes: {}\", io::Error::last_os_error());\n    }\n    v\n}\n\n#[cfg(target_vendor = \"uwp\")]\npub fn hashmap_random_keys() -> (u64, u64) {\n    use crate::ptr;\n\n    let mut v = (0, 0);\n    let ret = unsafe {\n        c::BCryptGenRandom(\n            ptr::null_mut(),\n            &mut v as *mut _ as *mut u8,\n            mem::size_of_val(&v) as c::ULONG,\n            c::BCRYPT_USE_SYSTEM_PREFERRED_RNG,\n        )\n    };\n    if ret != 0 {\n        panic!(\"couldn't generate random bytes: {}\", io::Error::last_os_error());\n    }\n    return v;\n}\n"],[2370,"use super::*;\n\n#[test]\nfn test_parse_next_component() {\n    assert_eq!(\n        parse_next_component(OsStr::new(r\"server\\share\"), true),\n        (OsStr::new(r\"server\"), OsStr::new(r\"share\"))\n    );\n\n    assert_eq!(\n        parse_next_component(OsStr::new(r\"server/share\"), true),\n        (OsStr::new(r\"server/share\"), OsStr::new(r\"\"))\n    );\n\n    assert_eq!(\n        parse_next_component(OsStr::new(r\"server/share\"), false),\n        (OsStr::new(r\"server\"), OsStr::new(r\"share\"))\n    );\n\n    assert_eq!(\n        parse_next_component(OsStr::new(r\"server\\\"), false),\n        (OsStr::new(r\"server\"), OsStr::new(r\"\"))\n    );\n\n    assert_eq!(\n        parse_next_component(OsStr::new(r\"\\server\\\"), false),\n        (OsStr::new(r\"\"), OsStr::new(r\"server\\\"))\n    );\n\n    assert_eq!(\n        parse_next_component(OsStr::new(r\"servershare\"), false),\n        (OsStr::new(r\"servershare\"), OsStr::new(\"\"))\n    );\n\n    assert_eq!(\n        parse_next_component(OsStr::new(r\"server/\\//\\/\\\\\\\\/////\\/share\"), false),\n        (OsStr::new(r\"server\"), OsStr::new(r\"share\"))\n    );\n\n    assert_eq!(\n        parse_next_component(OsStr::new(r\"server\\\\\\\\\\\\\\\\\\\\\\\\\\\\share\"), true),\n        (OsStr::new(r\"server\"), OsStr::new(r\"\\\\\\\\\\\\\\\\\\\\\\\\\\share\"))\n    );\n}\n"],[2371,"use crate::marker::PhantomData;\nuse crate::slice;\nuse crate::sys::c;\n\n#[derive(Copy, Clone)]\n#[repr(transparent)]\npub struct IoSlice<'a> {\n    vec: c::WSABUF,\n    _p: PhantomData<&'a [u8]>,\n}\n\nimpl<'a> IoSlice<'a> {\n    #[inline]\n    pub fn new(buf: &'a [u8]) -> IoSlice<'a> {\n        assert!(buf.len() <= c::ULONG::MAX as usize);\n        IoSlice {\n            vec: c::WSABUF {\n                len: buf.len() as c::ULONG,\n                buf: buf.as_ptr() as *mut u8 as *mut c::CHAR,\n            },\n            _p: PhantomData,\n        }\n    }\n\n    #[inline]\n    pub fn advance(&mut self, n: usize) {\n        if (self.vec.len as usize) < n {\n            panic!(\"advancing IoSlice beyond its length\");\n        }\n\n        unsafe {\n            self.vec.len -= n as c::ULONG;\n            self.vec.buf = self.vec.buf.add(n);\n        }\n    }\n\n    #[inline]\n    pub fn as_slice(&self) -> &[u8] {\n        unsafe { slice::from_raw_parts(self.vec.buf as *mut u8, self.vec.len as usize) }\n    }\n}\n\n#[repr(transparent)]\npub struct IoSliceMut<'a> {\n    vec: c::WSABUF,\n    _p: PhantomData<&'a mut [u8]>,\n}\n\nimpl<'a> IoSliceMut<'a> {\n    #[inline]\n    pub fn new(buf: &'a mut [u8]) -> IoSliceMut<'a> {\n        assert!(buf.len() <= c::ULONG::MAX as usize);\n        IoSliceMut {\n            vec: c::WSABUF { len: buf.len() as c::ULONG, buf: buf.as_mut_ptr() as *mut c::CHAR },\n            _p: PhantomData,\n        }\n    }\n\n    #[inline]\n    pub fn advance(&mut self, n: usize) {\n        if (self.vec.len as usize) < n {\n            panic!(\"advancing IoSliceMut beyond its length\");\n        }\n\n        unsafe {\n            self.vec.len -= n as c::ULONG;\n            self.vec.buf = self.vec.buf.add(n);\n        }\n    }\n\n    #[inline]\n    pub fn as_slice(&self) -> &[u8] {\n        unsafe { slice::from_raw_parts(self.vec.buf as *mut u8, self.vec.len as usize) }\n    }\n\n    #[inline]\n    pub fn as_mut_slice(&mut self) -> &mut [u8] {\n        unsafe { slice::from_raw_parts_mut(self.vec.buf as *mut u8, self.vec.len as usize) }\n    }\n}\n"],[2372,"#![unstable(feature = \"thread_local_internals\", issue = \"none\")]\n#![cfg(target_thread_local)]\n\npub use crate::sys_common::thread_local_dtor::register_dtor_fallback as register_dtor;\n"],[2373,"use crate::cmp::Ordering;\nuse crate::convert::TryInto;\nuse crate::fmt;\nuse crate::mem;\nuse crate::sys::c;\nuse crate::time::Duration;\n\nuse core::hash::{Hash, Hasher};\n\nconst NANOS_PER_SEC: u64 = 1_000_000_000;\nconst INTERVALS_PER_SEC: u64 = NANOS_PER_SEC / 100;\n\n#[derive(Copy, Clone, Eq, PartialEq, Ord, PartialOrd, Debug, Hash)]\npub struct Instant {\n    // This duration is relative to an arbitrary microsecond epoch\n    // from the winapi QueryPerformanceCounter function.\n    t: Duration,\n}\n\n#[derive(Copy, Clone)]\npub struct SystemTime {\n    t: c::FILETIME,\n}\n\nconst INTERVALS_TO_UNIX_EPOCH: u64 = 11_644_473_600 * INTERVALS_PER_SEC;\n\npub const UNIX_EPOCH: SystemTime = SystemTime {\n    t: c::FILETIME {\n        dwLowDateTime: INTERVALS_TO_UNIX_EPOCH as u32,\n        dwHighDateTime: (INTERVALS_TO_UNIX_EPOCH >> 32) as u32,\n    },\n};\n\nimpl Instant {\n    pub fn now() -> Instant {\n        // High precision timing on windows operates in \"Performance Counter\"\n        // units, as returned by the WINAPI QueryPerformanceCounter function.\n        // These relate to seconds by a factor of QueryPerformanceFrequency.\n        // In order to keep unit conversions out of normal interval math, we\n        // measure in QPC units and immediately convert to nanoseconds.\n        perf_counter::PerformanceCounterInstant::now().into()\n    }\n\n    pub fn actually_monotonic() -> bool {\n        false\n    }\n\n    pub const fn zero() -> Instant {\n        Instant { t: Duration::from_secs(0) }\n    }\n\n    pub fn checked_sub_instant(&self, other: &Instant) -> Option<Duration> {\n        // On windows there's a threshold below which we consider two timestamps\n        // equivalent due to measurement error. For more details + doc link,\n        // check the docs on epsilon.\n        let epsilon = perf_counter::PerformanceCounterInstant::epsilon();\n        if other.t > self.t && other.t - self.t <= epsilon {\n            Some(Duration::new(0, 0))\n        } else {\n            self.t.checked_sub(other.t)\n        }\n    }\n\n    pub fn checked_add_duration(&self, other: &Duration) -> Option<Instant> {\n        Some(Instant { t: self.t.checked_add(*other)? })\n    }\n\n    pub fn checked_sub_duration(&self, other: &Duration) -> Option<Instant> {\n        Some(Instant { t: self.t.checked_sub(*other)? })\n    }\n}\n\nimpl SystemTime {\n    pub fn now() -> SystemTime {\n        unsafe {\n            let mut t: SystemTime = mem::zeroed();\n            c::GetSystemTimePreciseAsFileTime(&mut t.t);\n            t\n        }\n    }\n\n    fn from_intervals(intervals: i64) -> SystemTime {\n        SystemTime {\n            t: c::FILETIME {\n                dwLowDateTime: intervals as c::DWORD,\n                dwHighDateTime: (intervals >> 32) as c::DWORD,\n            },\n        }\n    }\n\n    fn intervals(&self) -> i64 {\n        (self.t.dwLowDateTime as i64) | ((self.t.dwHighDateTime as i64) << 32)\n    }\n\n    pub fn sub_time(&self, other: &SystemTime) -> Result<Duration, Duration> {\n        let me = self.intervals();\n        let other = other.intervals();\n        if me >= other {\n            Ok(intervals2dur((me - other) as u64))\n        } else {\n            Err(intervals2dur((other - me) as u64))\n        }\n    }\n\n    pub fn checked_add_duration(&self, other: &Duration) -> Option<SystemTime> {\n        let intervals = self.intervals().checked_add(checked_dur2intervals(other)?)?;\n        Some(SystemTime::from_intervals(intervals))\n    }\n\n    pub fn checked_sub_duration(&self, other: &Duration) -> Option<SystemTime> {\n        let intervals = self.intervals().checked_sub(checked_dur2intervals(other)?)?;\n        Some(SystemTime::from_intervals(intervals))\n    }\n}\n\nimpl PartialEq for SystemTime {\n    fn eq(&self, other: &SystemTime) -> bool {\n        self.intervals() == other.intervals()\n    }\n}\n\nimpl Eq for SystemTime {}\n\nimpl PartialOrd for SystemTime {\n    fn partial_cmp(&self, other: &SystemTime) -> Option<Ordering> {\n        Some(self.cmp(other))\n    }\n}\n\nimpl Ord for SystemTime {\n    fn cmp(&self, other: &SystemTime) -> Ordering {\n        self.intervals().cmp(&other.intervals())\n    }\n}\n\nimpl fmt::Debug for SystemTime {\n    fn fmt(&self, f: &mut fmt::Formatter<'_>) -> fmt::Result {\n        f.debug_struct(\"SystemTime\").field(\"intervals\", &self.intervals()).finish()\n    }\n}\n\nimpl From<c::FILETIME> for SystemTime {\n    fn from(t: c::FILETIME) -> SystemTime {\n        SystemTime { t }\n    }\n}\n\nimpl Hash for SystemTime {\n    fn hash<H: Hasher>(&self, state: &mut H) {\n        self.intervals().hash(state)\n    }\n}\n\nfn checked_dur2intervals(dur: &Duration) -> Option<i64> {\n    dur.as_secs()\n        .checked_mul(INTERVALS_PER_SEC)?\n        .checked_add(dur.subsec_nanos() as u64 / 100)?\n        .try_into()\n        .ok()\n}\n\nfn intervals2dur(intervals: u64) -> Duration {\n    Duration::new(intervals / INTERVALS_PER_SEC, ((intervals % INTERVALS_PER_SEC) * 100) as u32)\n}\n\nmod perf_counter {\n    use super::NANOS_PER_SEC;\n    use crate::sync::atomic::{AtomicU64, Ordering};\n    use crate::sys::c;\n    use crate::sys::cvt;\n    use crate::sys_common::mul_div_u64;\n    use crate::time::Duration;\n\n    pub struct PerformanceCounterInstant {\n        ts: c::LARGE_INTEGER,\n    }\n    impl PerformanceCounterInstant {\n        pub fn now() -> Self {\n            Self { ts: query() }\n        }\n\n        // Per microsoft docs, the margin of error for cross-thread time comparisons\n        // using QueryPerformanceCounter is 1 \"tick\" -- defined as 1/frequency().\n        // Reference: https://docs.microsoft.com/en-us/windows/desktop/SysInfo\n        //                   /acquiring-high-resolution-time-stamps\n        pub fn epsilon() -> Duration {\n            let epsilon = NANOS_PER_SEC / (frequency() as u64);\n            Duration::from_nanos(epsilon)\n        }\n    }\n    impl From<PerformanceCounterInstant> for super::Instant {\n        fn from(other: PerformanceCounterInstant) -> Self {\n            let freq = frequency() as u64;\n            let instant_nsec = mul_div_u64(other.ts as u64, NANOS_PER_SEC, freq);\n            Self { t: Duration::from_nanos(instant_nsec) }\n        }\n    }\n\n    fn frequency() -> c::LARGE_INTEGER {\n        // Either the cached result of `QueryPerformanceFrequency` or `0` for\n        // uninitialized. Storing this as a single `AtomicU64` allows us to use\n        // `Relaxed` operations, as we are only interested in the effects on a\n        // single memory location.\n        static FREQUENCY: AtomicU64 = AtomicU64::new(0);\n\n        let cached = FREQUENCY.load(Ordering::Relaxed);\n        // If a previous thread has filled in this global state, use that.\n        if cached != 0 {\n            return cached as c::LARGE_INTEGER;\n        }\n        // ... otherwise learn for ourselves ...\n        let mut frequency = 0;\n        unsafe {\n            cvt(c::QueryPerformanceFrequency(&mut frequency)).unwrap();\n        }\n\n        FREQUENCY.store(frequency as u64, Ordering::Relaxed);\n        frequency\n    }\n\n    fn query() -> c::LARGE_INTEGER {\n        let mut qpc_value: c::LARGE_INTEGER = 0;\n        cvt(unsafe { c::QueryPerformanceCounter(&mut qpc_value) }).unwrap();\n        qpc_value\n    }\n}\n"],[2374,"#![allow(dead_code)] // runtime init functions not used during testing\n\n#[cfg(test)]\nmod tests;\n\nuse crate::ffi::OsString;\nuse crate::fmt;\nuse crate::os::windows::prelude::*;\nuse crate::path::PathBuf;\nuse crate::slice;\nuse crate::sys::c;\nuse crate::sys::windows::os::current_exe;\nuse crate::vec;\n\nuse core::iter;\n\npub fn args() -> Args {\n    unsafe {\n        let lp_cmd_line = c::GetCommandLineW();\n        let parsed_args_list = parse_lp_cmd_line(lp_cmd_line as *const u16, || {\n            current_exe().map(PathBuf::into_os_string).unwrap_or_else(|_| OsString::new())\n        });\n\n        Args { parsed_args_list: parsed_args_list.into_iter() }\n    }\n}\n\n/// Implements the Windows command-line argument parsing algorithm.\n///\n/// Microsoft's documentation for the Windows CLI argument format can be found at\n/// <https://docs.microsoft.com/en-us/previous-versions//17w5ykft(v=vs.85)>.\n///\n/// Windows includes a function to do this in shell32.dll,\n/// but linking with that DLL causes the process to be registered as a GUI application.\n/// GUI applications add a bunch of overhead, even if no windows are drawn. See\n/// <https://randomascii.wordpress.com/2018/12/03/a-not-called-function-can-cause-a-5x-slowdown/>.\n///\n/// This function was tested for equivalence to the shell32.dll implementation in\n/// Windows 10 Pro v1803, using an exhaustive test suite available at\n/// <https://gist.github.com/notriddle/dde431930c392e428055b2dc22e638f5> or\n/// <https://paste.gg/p/anonymous/47d6ed5f5bd549168b1c69c799825223>.\nunsafe fn parse_lp_cmd_line<F: Fn() -> OsString>(\n    lp_cmd_line: *const u16,\n    exe_name: F,\n) -> Vec<OsString> {\n    const BACKSLASH: u16 = '\\\\' as u16;\n    const QUOTE: u16 = '\"' as u16;\n    const TAB: u16 = '\\t' as u16;\n    const SPACE: u16 = ' ' as u16;\n    let mut ret_val = Vec::new();\n    if lp_cmd_line.is_null() || *lp_cmd_line == 0 {\n        ret_val.push(exe_name());\n        return ret_val;\n    }\n    let mut cmd_line = {\n        let mut end = 0;\n        while *lp_cmd_line.offset(end) != 0 {\n            end += 1;\n        }\n        slice::from_raw_parts(lp_cmd_line, end as usize)\n    };\n    // The executable name at the beginning is special.\n    cmd_line = match cmd_line[0] {\n        // The executable name ends at the next quote mark,\n        // no matter what.\n        QUOTE => {\n            let args = {\n                let mut cut = cmd_line[1..].splitn(2, |&c| c == QUOTE);\n                if let Some(exe) = cut.next() {\n                    ret_val.push(OsString::from_wide(exe));\n                }\n                cut.next()\n            };\n            if let Some(args) = args {\n                args\n            } else {\n                return ret_val;\n            }\n        }\n        // Implement quirk: when they say whitespace here,\n        // they include the entire ASCII control plane:\n        // \"However, if lpCmdLine starts with any amount of whitespace, CommandLineToArgvW\n        // will consider the first argument to be an empty string. Excess whitespace at the\n        // end of lpCmdLine is ignored.\"\n        0..=SPACE => {\n            ret_val.push(OsString::new());\n            &cmd_line[1..]\n        }\n        // The executable name ends at the next whitespace,\n        // no matter what.\n        _ => {\n            let args = {\n                let mut cut = cmd_line.splitn(2, |&c| c > 0 && c <= SPACE);\n                if let Some(exe) = cut.next() {\n                    ret_val.push(OsString::from_wide(exe));\n                }\n                cut.next()\n            };\n            if let Some(args) = args {\n                args\n            } else {\n                return ret_val;\n            }\n        }\n    };\n    let mut cur = Vec::new();\n    let mut in_quotes = false;\n    let mut was_in_quotes = false;\n    let mut backslash_count: usize = 0;\n    for &c in cmd_line {\n        match c {\n            // backslash\n            BACKSLASH => {\n                backslash_count += 1;\n                was_in_quotes = false;\n            }\n            QUOTE if backslash_count % 2 == 0 => {\n                cur.extend(iter::repeat(b'\\\\' as u16).take(backslash_count / 2));\n                backslash_count = 0;\n                if was_in_quotes {\n                    cur.push('\"' as u16);\n                    was_in_quotes = false;\n                } else {\n                    was_in_quotes = in_quotes;\n                    in_quotes = !in_quotes;\n                }\n            }\n            QUOTE if backslash_count % 2 != 0 => {\n                cur.extend(iter::repeat(b'\\\\' as u16).take(backslash_count / 2));\n                backslash_count = 0;\n                was_in_quotes = false;\n                cur.push(b'\"' as u16);\n            }\n            SPACE | TAB if !in_quotes => {\n                cur.extend(iter::repeat(b'\\\\' as u16).take(backslash_count));\n                if !cur.is_empty() || was_in_quotes {\n                    ret_val.push(OsString::from_wide(&cur[..]));\n                    cur.truncate(0);\n                }\n                backslash_count = 0;\n                was_in_quotes = false;\n            }\n            _ => {\n                cur.extend(iter::repeat(b'\\\\' as u16).take(backslash_count));\n                backslash_count = 0;\n                was_in_quotes = false;\n                cur.push(c);\n            }\n        }\n    }\n    cur.extend(iter::repeat(b'\\\\' as u16).take(backslash_count));\n    // include empty quoted strings at the end of the arguments list\n    if !cur.is_empty() || was_in_quotes || in_quotes {\n        ret_val.push(OsString::from_wide(&cur[..]));\n    }\n    ret_val\n}\n\npub struct Args {\n    parsed_args_list: vec::IntoIter<OsString>,\n}\n\nimpl fmt::Debug for Args {\n    fn fmt(&self, f: &mut fmt::Formatter<'_>) -> fmt::Result {\n        self.parsed_args_list.as_slice().fmt(f)\n    }\n}\n\nimpl Iterator for Args {\n    type Item = OsString;\n    fn next(&mut self) -> Option<OsString> {\n        self.parsed_args_list.next()\n    }\n    fn size_hint(&self) -> (usize, Option<usize>) {\n        self.parsed_args_list.size_hint()\n    }\n}\n\nimpl DoubleEndedIterator for Args {\n    fn next_back(&mut self) -> Option<OsString> {\n        self.parsed_args_list.next_back()\n    }\n}\n\nimpl ExactSizeIterator for Args {\n    fn len(&self) -> usize {\n        self.parsed_args_list.len()\n    }\n}\n"],[2375,"use crate::ffi::CStr;\nuse crate::io;\nuse crate::num::NonZeroUsize;\nuse crate::ptr;\nuse crate::sys::c;\nuse crate::sys::handle::Handle;\nuse crate::sys::stack_overflow;\nuse crate::time::Duration;\n\nuse libc::c_void;\n\nuse super::to_u16s;\n\npub const DEFAULT_MIN_STACK_SIZE: usize = 2 * 1024 * 1024;\n\npub struct Thread {\n    handle: Handle,\n}\n\nimpl Thread {\n    // unsafe: see thread::Builder::spawn_unchecked for safety requirements\n    pub unsafe fn new(stack: usize, p: Box<dyn FnOnce()>) -> io::Result<Thread> {\n        let p = Box::into_raw(box p);\n\n        // FIXME On UNIX, we guard against stack sizes that are too small but\n        // that's because pthreads enforces that stacks are at least\n        // PTHREAD_STACK_MIN bytes big.  Windows has no such lower limit, it's\n        // just that below a certain threshold you can't do anything useful.\n        // That threshold is application and architecture-specific, however.\n        // Round up to the next 64 kB because that's what the NT kernel does,\n        // might as well make it explicit.\n        let stack_size = (stack + 0xfffe) & (!0xfffe);\n        let ret = c::CreateThread(\n            ptr::null_mut(),\n            stack_size,\n            thread_start,\n            p as *mut _,\n            c::STACK_SIZE_PARAM_IS_A_RESERVATION,\n            ptr::null_mut(),\n        );\n\n        return if ret as usize == 0 {\n            // The thread failed to start and as a result p was not consumed. Therefore, it is\n            // safe to reconstruct the box so that it gets deallocated.\n            drop(Box::from_raw(p));\n            Err(io::Error::last_os_error())\n        } else {\n            Ok(Thread { handle: Handle::new(ret) })\n        };\n\n        extern \"system\" fn thread_start(main: *mut c_void) -> c::DWORD {\n            unsafe {\n                // Next, set up our stack overflow handler which may get triggered if we run\n                // out of stack.\n                let _handler = stack_overflow::Handler::new();\n                // Finally, let's run some code.\n                Box::from_raw(main as *mut Box<dyn FnOnce()>)();\n            }\n            0\n        }\n    }\n\n    pub fn set_name(name: &CStr) {\n        if let Ok(utf8) = name.to_str() {\n            if let Ok(utf16) = to_u16s(utf8) {\n                unsafe {\n                    c::SetThreadDescription(c::GetCurrentThread(), utf16.as_ptr());\n                };\n            };\n        };\n    }\n\n    pub fn join(self) {\n        let rc = unsafe { c::WaitForSingleObject(self.handle.raw(), c::INFINITE) };\n        if rc == c::WAIT_FAILED {\n            panic!(\"failed to join on thread: {}\", io::Error::last_os_error());\n        }\n    }\n\n    pub fn yield_now() {\n        // This function will return 0 if there are no other threads to execute,\n        // but this also means that the yield was useless so this isn't really a\n        // case that needs to be worried about.\n        unsafe {\n            c::SwitchToThread();\n        }\n    }\n\n    pub fn sleep(dur: Duration) {\n        unsafe { c::Sleep(super::dur2timeout(dur)) }\n    }\n\n    pub fn handle(&self) -> &Handle {\n        &self.handle\n    }\n\n    pub fn into_handle(self) -> Handle {\n        self.handle\n    }\n}\n\npub fn available_concurrency() -> io::Result<NonZeroUsize> {\n    let res = unsafe {\n        let mut sysinfo: c::SYSTEM_INFO = crate::mem::zeroed();\n        c::GetSystemInfo(&mut sysinfo);\n        sysinfo.dwNumberOfProcessors as usize\n    };\n    match res {\n        0 => Err(io::Error::new_const(\n            io::ErrorKind::NotFound,\n            &\"The number of hardware threads is not known for the target platform\",\n        )),\n        cpus => Ok(unsafe { NonZeroUsize::new_unchecked(cpus) }),\n    }\n}\n\n#[cfg_attr(test, allow(dead_code))]\npub mod guard {\n    pub type Guard = !;\n    pub unsafe fn current() -> Option<Guard> {\n        None\n    }\n    pub unsafe fn init() -> Option<Guard> {\n        None\n    }\n}\n"],[2376,"use crate::mem::ManuallyDrop;\nuse crate::ptr;\nuse crate::sync::atomic::AtomicPtr;\nuse crate::sync::atomic::Ordering::SeqCst;\nuse crate::sys::c;\n\npub type Key = c::DWORD;\npub type Dtor = unsafe extern \"C\" fn(*mut u8);\n\n// Turns out, like pretty much everything, Windows is pretty close the\n// functionality that Unix provides, but slightly different! In the case of\n// TLS, Windows does not provide an API to provide a destructor for a TLS\n// variable. This ends up being pretty crucial to this implementation, so we\n// need a way around this.\n//\n// The solution here ended up being a little obscure, but fear not, the\n// internet has informed me [1][2] that this solution is not unique (no way\n// I could have thought of it as well!). The key idea is to insert some hook\n// somewhere to run arbitrary code on thread termination. With this in place\n// we'll be able to run anything we like, including all TLS destructors!\n//\n// To accomplish this feat, we perform a number of threads, all contained\n// within this module:\n//\n// * All TLS destructors are tracked by *us*, not the windows runtime. This\n//   means that we have a global list of destructors for each TLS key that\n//   we know about.\n// * When a thread exits, we run over the entire list and run dtors for all\n//   non-null keys. This attempts to match Unix semantics in this regard.\n//\n// This ends up having the overhead of using a global list, having some\n// locks here and there, and in general just adding some more code bloat. We\n// attempt to optimize runtime by forgetting keys that don't have\n// destructors, but this only gets us so far.\n//\n// For more details and nitty-gritty, see the code sections below!\n//\n// [1]: https://www.codeproject.com/Articles/8113/Thread-Local-Storage-The-C-Way\n// [2]: https://github.com/ChromiumWebApps/chromium/blob/master/base\n//                        /threading/thread_local_storage_win.cc#L42\n\n// -------------------------------------------------------------------------\n// Native bindings\n//\n// This section is just raw bindings to the native functions that Windows\n// provides, There's a few extra calls to deal with destructors.\n\n#[inline]\npub unsafe fn create(dtor: Option<Dtor>) -> Key {\n    let key = c::TlsAlloc();\n    assert!(key != c::TLS_OUT_OF_INDEXES);\n    if let Some(f) = dtor {\n        register_dtor(key, f);\n    }\n    key\n}\n\n#[inline]\npub unsafe fn set(key: Key, value: *mut u8) {\n    let r = c::TlsSetValue(key, value as c::LPVOID);\n    debug_assert!(r != 0);\n}\n\n#[inline]\npub unsafe fn get(key: Key) -> *mut u8 {\n    c::TlsGetValue(key) as *mut u8\n}\n\n#[inline]\npub unsafe fn destroy(_key: Key) {\n    rtabort!(\"can't destroy tls keys on windows\")\n}\n\n#[inline]\npub fn requires_synchronized_create() -> bool {\n    true\n}\n\n// -------------------------------------------------------------------------\n// Dtor registration\n//\n// Windows has no native support for running destructors so we manage our own\n// list of destructors to keep track of how to destroy keys. We then install a\n// callback later to get invoked whenever a thread exits, running all\n// appropriate destructors.\n//\n// Currently unregistration from this list is not supported. A destructor can be\n// registered but cannot be unregistered. There's various simplifying reasons\n// for doing this, the big ones being:\n//\n// 1. Currently we don't even support deallocating TLS keys, so normal operation\n//    doesn't need to deallocate a destructor.\n// 2. There is no point in time where we know we can unregister a destructor\n//    because it could always be getting run by some remote thread.\n//\n// Typically processes have a statically known set of TLS keys which is pretty\n// small, and we'd want to keep this memory alive for the whole process anyway\n// really.\n//\n// Perhaps one day we can fold the `Box` here into a static allocation,\n// expanding the `StaticKey` structure to contain not only a slot for the TLS\n// key but also a slot for the destructor queue on windows. An optimization for\n// another day!\n\nstatic DTORS: AtomicPtr<Node> = AtomicPtr::new(ptr::null_mut());\n\nstruct Node {\n    dtor: Dtor,\n    key: Key,\n    next: *mut Node,\n}\n\nunsafe fn register_dtor(key: Key, dtor: Dtor) {\n    let mut node = ManuallyDrop::new(Box::new(Node { key, dtor, next: ptr::null_mut() }));\n\n    let mut head = DTORS.load(SeqCst);\n    loop {\n        node.next = head;\n        match DTORS.compare_exchange(head, &mut **node, SeqCst, SeqCst) {\n            Ok(_) => return, // nothing to drop, we successfully added the node to the list\n            Err(cur) => head = cur,\n        }\n    }\n}\n\n// -------------------------------------------------------------------------\n// Where the Magic (TM) Happens\n//\n// If you're looking at this code, and wondering \"what is this doing?\",\n// you're not alone! I'll try to break this down step by step:\n//\n// # What's up with CRT$XLB?\n//\n// For anything about TLS destructors to work on Windows, we have to be able\n// to run *something* when a thread exits. To do so, we place a very special\n// static in a very special location. If this is encoded in just the right\n// way, the kernel's loader is apparently nice enough to run some function\n// of ours whenever a thread exits! How nice of the kernel!\n//\n// Lots of detailed information can be found in source [1] above, but the\n// gist of it is that this is leveraging a feature of Microsoft's PE format\n// (executable format) which is not actually used by any compilers today.\n// This apparently translates to any callbacks in the \".CRT$XLB\" section\n// being run on certain events.\n//\n// So after all that, we use the compiler's #[link_section] feature to place\n// a callback pointer into the magic section so it ends up being called.\n//\n// # What's up with this callback?\n//\n// The callback specified receives a number of parameters from... someone!\n// (the kernel? the runtime? I'm not quite sure!) There are a few events that\n// this gets invoked for, but we're currently only interested on when a\n// thread or a process \"detaches\" (exits). The process part happens for the\n// last thread and the thread part happens for any normal thread.\n//\n// # Ok, what's up with running all these destructors?\n//\n// This will likely need to be improved over time, but this function\n// attempts a \"poor man's\" destructor callback system. Once we've got a list\n// of what to run, we iterate over all keys, check their values, and then run\n// destructors if the values turn out to be non null (setting them to null just\n// beforehand). We do this a few times in a loop to basically match Unix\n// semantics. If we don't reach a fixed point after a short while then we just\n// inevitably leak something most likely.\n//\n// # The article mentions weird stuff about \"/INCLUDE\"?\n//\n// It sure does! Specifically we're talking about this quote:\n//\n//      The Microsoft run-time library facilitates this process by defining a\n//      memory image of the TLS Directory and giving it the special name\n//      “__tls_used” (Intel x86 platforms) or “_tls_used” (other platforms). The\n//      linker looks for this memory image and uses the data there to create the\n//      TLS Directory. Other compilers that support TLS and work with the\n//      Microsoft linker must use this same technique.\n//\n// Basically what this means is that if we want support for our TLS\n// destructors/our hook being called then we need to make sure the linker does\n// not omit this symbol. Otherwise it will omit it and our callback won't be\n// wired up.\n//\n// We don't actually use the `/INCLUDE` linker flag here like the article\n// mentions because the Rust compiler doesn't propagate linker flags, but\n// instead we use a shim function which performs a volatile 1-byte load from\n// the address of the symbol to ensure it sticks around.\n\n#[link_section = \".CRT$XLB\"]\n#[allow(dead_code, unused_variables)]\n#[used] // we don't want LLVM eliminating this symbol for any reason, and\n// when the symbol makes it to the linker the linker will take over\npub static p_thread_callback: unsafe extern \"system\" fn(c::LPVOID, c::DWORD, c::LPVOID) =\n    on_tls_callback;\n\n#[allow(dead_code, unused_variables)]\nunsafe extern \"system\" fn on_tls_callback(h: c::LPVOID, dwReason: c::DWORD, pv: c::LPVOID) {\n    if dwReason == c::DLL_THREAD_DETACH || dwReason == c::DLL_PROCESS_DETACH {\n        run_dtors();\n    }\n\n    // See comments above for what this is doing. Note that we don't need this\n    // trickery on GNU windows, just on MSVC.\n    reference_tls_used();\n    #[cfg(target_env = \"msvc\")]\n    unsafe fn reference_tls_used() {\n        extern \"C\" {\n            static _tls_used: u8;\n        }\n        crate::intrinsics::volatile_load(&_tls_used);\n    }\n    #[cfg(not(target_env = \"msvc\"))]\n    unsafe fn reference_tls_used() {}\n}\n\n#[allow(dead_code)] // actually called above\nunsafe fn run_dtors() {\n    let mut any_run = true;\n    for _ in 0..5 {\n        if !any_run {\n            break;\n        }\n        any_run = false;\n        let mut cur = DTORS.load(SeqCst);\n        while !cur.is_null() {\n            let ptr = c::TlsGetValue((*cur).key);\n\n            if !ptr.is_null() {\n                c::TlsSetValue((*cur).key, ptr::null_mut());\n                ((*cur).dtor)(ptr as *mut _);\n                any_run = true;\n            }\n\n            cur = (*cur).next;\n        }\n    }\n}\n"],[2377,"#![unstable(issue = \"none\", feature = \"windows_stdio\")]\n\nuse crate::char::decode_utf16;\nuse crate::cmp;\nuse crate::io;\nuse crate::ptr;\nuse crate::str;\nuse crate::sys::c;\nuse crate::sys::cvt;\nuse crate::sys::handle::Handle;\n\n// Don't cache handles but get them fresh for every read/write. This allows us to track changes to\n// the value over time (such as if a process calls `SetStdHandle` while it's running). See #40490.\npub struct Stdin {\n    surrogate: u16,\n}\npub struct Stdout;\npub struct Stderr;\n\n// Apparently Windows doesn't handle large reads on stdin or writes to stdout/stderr well (see\n// #13304 for details).\n//\n// From MSDN (2011): \"The storage for this buffer is allocated from a shared heap for the\n// process that is 64 KB in size. The maximum size of the buffer will depend on heap usage.\"\n//\n// We choose the cap at 8 KiB because libuv does the same, and it seems to be acceptable so far.\nconst MAX_BUFFER_SIZE: usize = 8192;\n\n// The standard buffer size of BufReader for Stdin should be able to hold 3x more bytes than there\n// are `u16`'s in MAX_BUFFER_SIZE. This ensures the read data can always be completely decoded from\n// UTF-16 to UTF-8.\npub const STDIN_BUF_SIZE: usize = MAX_BUFFER_SIZE / 2 * 3;\n\npub fn get_handle(handle_id: c::DWORD) -> io::Result<c::HANDLE> {\n    let handle = unsafe { c::GetStdHandle(handle_id) };\n    if handle == c::INVALID_HANDLE_VALUE {\n        Err(io::Error::last_os_error())\n    } else if handle.is_null() {\n        Err(io::Error::from_raw_os_error(c::ERROR_INVALID_HANDLE as i32))\n    } else {\n        Ok(handle)\n    }\n}\n\nfn is_console(handle: c::HANDLE) -> bool {\n    // `GetConsoleMode` will return false (0) if this is a pipe (we don't care about the reported\n    // mode). This will only detect Windows Console, not other terminals connected to a pipe like\n    // MSYS. Which is exactly what we need, as only Windows Console needs a conversion to UTF-16.\n    let mut mode = 0;\n    unsafe { c::GetConsoleMode(handle, &mut mode) != 0 }\n}\n\nfn write(handle_id: c::DWORD, data: &[u8]) -> io::Result<usize> {\n    let handle = get_handle(handle_id)?;\n    if !is_console(handle) {\n        let handle = Handle::new(handle);\n        let ret = handle.write(data);\n        handle.into_raw(); // Don't close the handle\n        return ret;\n    }\n\n    // As the console is meant for presenting text, we assume bytes of `data` come from a string\n    // and are encoded as UTF-8, which needs to be encoded as UTF-16.\n    //\n    // If the data is not valid UTF-8 we write out as many bytes as are valid.\n    // Only when there are no valid bytes (which will happen on the next call), return an error.\n    let len = cmp::min(data.len(), MAX_BUFFER_SIZE / 2);\n    let utf8 = match str::from_utf8(&data[..len]) {\n        Ok(s) => s,\n        Err(ref e) if e.valid_up_to() == 0 => {\n            return Err(io::Error::new_const(\n                io::ErrorKind::InvalidData,\n                &\"Windows stdio in console mode does not support writing non-UTF-8 byte sequences\",\n            ));\n        }\n        Err(e) => str::from_utf8(&data[..e.valid_up_to()]).unwrap(),\n    };\n    let mut utf16 = [0u16; MAX_BUFFER_SIZE / 2];\n    let mut len_utf16 = 0;\n    for (chr, dest) in utf8.encode_utf16().zip(utf16.iter_mut()) {\n        *dest = chr;\n        len_utf16 += 1;\n    }\n    let utf16 = &utf16[..len_utf16];\n\n    let mut written = write_u16s(handle, &utf16)?;\n\n    // Figure out how many bytes of as UTF-8 were written away as UTF-16.\n    if written == utf16.len() {\n        Ok(utf8.len())\n    } else {\n        // Make sure we didn't end up writing only half of a surrogate pair (even though the chance\n        // is tiny). Because it is not possible for user code to re-slice `data` in such a way that\n        // a missing surrogate can be produced (and also because of the UTF-8 validation above),\n        // write the missing surrogate out now.\n        // Buffering it would mean we have to lie about the number of bytes written.\n        let first_char_remaining = utf16[written];\n        if first_char_remaining >= 0xDCEE && first_char_remaining <= 0xDFFF {\n            // low surrogate\n            // We just hope this works, and give up otherwise\n            let _ = write_u16s(handle, &utf16[written..written + 1]);\n            written += 1;\n        }\n        // Calculate the number of bytes of `utf8` that were actually written.\n        let mut count = 0;\n        for ch in utf16[..written].iter() {\n            count += match ch {\n                0x0000..=0x007F => 1,\n                0x0080..=0x07FF => 2,\n                0xDCEE..=0xDFFF => 1, // Low surrogate. We already counted 3 bytes for the other.\n                _ => 3,\n            };\n        }\n        debug_assert!(String::from_utf16(&utf16[..written]).unwrap() == utf8[..count]);\n        Ok(count)\n    }\n}\n\nfn write_u16s(handle: c::HANDLE, data: &[u16]) -> io::Result<usize> {\n    let mut written = 0;\n    cvt(unsafe {\n        c::WriteConsoleW(\n            handle,\n            data.as_ptr() as c::LPCVOID,\n            data.len() as u32,\n            &mut written,\n            ptr::null_mut(),\n        )\n    })?;\n    Ok(written as usize)\n}\n\nimpl Stdin {\n    pub const fn new() -> Stdin {\n        Stdin { surrogate: 0 }\n    }\n}\n\nimpl io::Read for Stdin {\n    fn read(&mut self, buf: &mut [u8]) -> io::Result<usize> {\n        let handle = get_handle(c::STD_INPUT_HANDLE)?;\n        if !is_console(handle) {\n            let handle = Handle::new(handle);\n            let ret = handle.read(buf);\n            handle.into_raw(); // Don't close the handle\n            return ret;\n        }\n\n        if buf.len() == 0 {\n            return Ok(0);\n        } else if buf.len() < 4 {\n            return Err(io::Error::new_const(\n                io::ErrorKind::InvalidInput,\n                &\"Windows stdin in console mode does not support a buffer too small to \\\n                 guarantee holding one arbitrary UTF-8 character (4 bytes)\",\n            ));\n        }\n\n        let mut utf16_buf = [0u16; MAX_BUFFER_SIZE / 2];\n        // In the worst case, an UTF-8 string can take 3 bytes for every `u16` of an UTF-16. So\n        // we can read at most a third of `buf.len()` chars and uphold the guarantee no data gets\n        // lost.\n        let amount = cmp::min(buf.len() / 3, utf16_buf.len());\n        let read = read_u16s_fixup_surrogates(handle, &mut utf16_buf, amount, &mut self.surrogate)?;\n\n        utf16_to_utf8(&utf16_buf[..read], buf)\n    }\n}\n\n// We assume that if the last `u16` is an unpaired surrogate they got sliced apart by our\n// buffer size, and keep it around for the next read hoping to put them together.\n// This is a best effort, and may not work if we are not the only reader on Stdin.\nfn read_u16s_fixup_surrogates(\n    handle: c::HANDLE,\n    buf: &mut [u16],\n    mut amount: usize,\n    surrogate: &mut u16,\n) -> io::Result<usize> {\n    // Insert possibly remaining unpaired surrogate from last read.\n    let mut start = 0;\n    if *surrogate != 0 {\n        buf[0] = *surrogate;\n        *surrogate = 0;\n        start = 1;\n        if amount == 1 {\n            // Special case: `Stdin::read` guarantees we can always read at least one new `u16`\n            // and combine it with an unpaired surrogate, because the UTF-8 buffer is at least\n            // 4 bytes.\n            amount = 2;\n        }\n    }\n    let mut amount = read_u16s(handle, &mut buf[start..amount])? + start;\n\n    if amount > 0 {\n        let last_char = buf[amount - 1];\n        if last_char >= 0xD800 && last_char <= 0xDBFF {\n            // high surrogate\n            *surrogate = last_char;\n            amount -= 1;\n        }\n    }\n    Ok(amount)\n}\n\nfn read_u16s(handle: c::HANDLE, buf: &mut [u16]) -> io::Result<usize> {\n    // Configure the `pInputControl` parameter to not only return on `\\r\\n` but also Ctrl-Z, the\n    // traditional DOS method to indicate end of character stream / user input (SUB).\n    // See #38274 and https://stackoverflow.com/questions/43836040/win-api-readconsole.\n    const CTRL_Z: u16 = 0x1A;\n    const CTRL_Z_MASK: c::ULONG = 1 << CTRL_Z;\n    let mut input_control = c::CONSOLE_READCONSOLE_CONTROL {\n        nLength: crate::mem::size_of::<c::CONSOLE_READCONSOLE_CONTROL>() as c::ULONG,\n        nInitialChars: 0,\n        dwCtrlWakeupMask: CTRL_Z_MASK,\n        dwControlKeyState: 0,\n    };\n\n    let mut amount = 0;\n    cvt(unsafe {\n        c::ReadConsoleW(\n            handle,\n            buf.as_mut_ptr() as c::LPVOID,\n            buf.len() as u32,\n            &mut amount,\n            &mut input_control as c::PCONSOLE_READCONSOLE_CONTROL,\n        )\n    })?;\n\n    if amount > 0 && buf[amount as usize - 1] == CTRL_Z {\n        amount -= 1;\n    }\n    Ok(amount as usize)\n}\n\n#[allow(unused)]\nfn utf16_to_utf8(utf16: &[u16], utf8: &mut [u8]) -> io::Result<usize> {\n    let mut written = 0;\n    for chr in decode_utf16(utf16.iter().cloned()) {\n        match chr {\n            Ok(chr) => {\n                chr.encode_utf8(&mut utf8[written..]);\n                written += chr.len_utf8();\n            }\n            Err(_) => {\n                // We can't really do any better than forget all data and return an error.\n                return Err(io::Error::new_const(\n                    io::ErrorKind::InvalidData,\n                    &\"Windows stdin in console mode does not support non-UTF-16 input; \\\n                     encountered unpaired surrogate\",\n                ));\n            }\n        }\n    }\n    Ok(written)\n}\n\nimpl Stdout {\n    pub const fn new() -> Stdout {\n        Stdout\n    }\n}\n\nimpl io::Write for Stdout {\n    fn write(&mut self, buf: &[u8]) -> io::Result<usize> {\n        write(c::STD_OUTPUT_HANDLE, buf)\n    }\n\n    fn flush(&mut self) -> io::Result<()> {\n        Ok(())\n    }\n}\n\nimpl Stderr {\n    pub const fn new() -> Stderr {\n        Stderr\n    }\n}\n\nimpl io::Write for Stderr {\n    fn write(&mut self, buf: &[u8]) -> io::Result<usize> {\n        write(c::STD_ERROR_HANDLE, buf)\n    }\n\n    fn flush(&mut self) -> io::Result<()> {\n        Ok(())\n    }\n}\n\npub fn is_ebadf(err: &io::Error) -> bool {\n    err.raw_os_error() == Some(c::ERROR_INVALID_HANDLE as i32)\n}\n\npub fn panic_output() -> Option<impl io::Write> {\n    Some(Stderr::new())\n}\n"],[2378,"use crate::ffi::OsString;\nuse crate::sys::windows::args::*;\n\nfn chk(string: &str, parts: &[&str]) {\n    let mut wide: Vec<u16> = OsString::from(string).encode_wide().collect();\n    wide.push(0);\n    let parsed =\n        unsafe { parse_lp_cmd_line(wide.as_ptr() as *const u16, || OsString::from(\"TEST.EXE\")) };\n    let expected: Vec<OsString> = parts.iter().map(|k| OsString::from(k)).collect();\n    assert_eq!(parsed.as_slice(), expected.as_slice());\n}\n\n#[test]\nfn empty() {\n    chk(\"\", &[\"TEST.EXE\"]);\n    chk(\"\\0\", &[\"TEST.EXE\"]);\n}\n\n#[test]\nfn single_words() {\n    chk(\"EXE one_word\", &[\"EXE\", \"one_word\"]);\n    chk(\"EXE a\", &[\"EXE\", \"a\"]);\n    chk(\"EXE 😅\", &[\"EXE\", \"😅\"]);\n    chk(\"EXE 😅🤦\", &[\"EXE\", \"😅🤦\"]);\n}\n\n#[test]\nfn official_examples() {\n    chk(r#\"EXE \"abc\" d e\"#, &[\"EXE\", \"abc\", \"d\", \"e\"]);\n    chk(r#\"EXE a\\\\\\b d\"e f\"g h\"#, &[\"EXE\", r#\"a\\\\\\b\"#, \"de fg\", \"h\"]);\n    chk(r#\"EXE a\\\\\\\"b c d\"#, &[\"EXE\", r#\"a\\\"b\"#, \"c\", \"d\"]);\n    chk(r#\"EXE a\\\\\\\\\"b c\" d e\"#, &[\"EXE\", r#\"a\\\\b c\"#, \"d\", \"e\"]);\n}\n\n#[test]\nfn whitespace_behavior() {\n    chk(r#\" test\"#, &[\"\", \"test\"]);\n    chk(r#\"  test\"#, &[\"\", \"test\"]);\n    chk(r#\" test test2\"#, &[\"\", \"test\", \"test2\"]);\n    chk(r#\" test  test2\"#, &[\"\", \"test\", \"test2\"]);\n    chk(r#\"test test2 \"#, &[\"test\", \"test2\"]);\n    chk(r#\"test  test2 \"#, &[\"test\", \"test2\"]);\n    chk(r#\"test \"#, &[\"test\"]);\n}\n\n#[test]\nfn genius_quotes() {\n    chk(r#\"EXE \"\" \"\"\"#, &[\"EXE\", \"\", \"\"]);\n    chk(r#\"EXE \"\" \"\"\"\"#, &[\"EXE\", \"\", \"\\\"\"]);\n    chk(\n        r#\"EXE \"this is \"\"\"all\"\"\" in the same argument\"\"#,\n        &[\"EXE\", \"this is \\\"all\\\" in the same argument\"],\n    );\n    chk(r#\"EXE \"a\"\"\"#, &[\"EXE\", \"a\\\"\"]);\n    chk(r#\"EXE \"a\"\" a\"#, &[\"EXE\", \"a\\\"\", \"a\"]);\n    // quotes cannot be escaped in command names\n    chk(r#\"\"EXE\" check\"#, &[\"EXE\", \"check\"]);\n    chk(r#\"\"EXE check\"\"#, &[\"EXE check\"]);\n    chk(r#\"\"EXE \"\"\"for\"\"\" check\"#, &[\"EXE \", r#\"for\"\"#, \"check\"]);\n    chk(r#\"\"EXE \\\"for\\\" check\"#, &[r#\"EXE \\\"#, r#\"for\"\"#, \"check\"]);\n}\n"],[2379,"use crate::os::windows::prelude::*;\n\nuse crate::ffi::OsStr;\nuse crate::io::{self, IoSlice, IoSliceMut};\nuse crate::mem;\nuse crate::path::Path;\nuse crate::ptr;\nuse crate::slice;\nuse crate::sync::atomic::AtomicUsize;\nuse crate::sync::atomic::Ordering::SeqCst;\nuse crate::sys::c;\nuse crate::sys::fs::{File, OpenOptions};\nuse crate::sys::handle::Handle;\nuse crate::sys::hashmap_random_keys;\n\n////////////////////////////////////////////////////////////////////////////////\n// Anonymous pipes\n////////////////////////////////////////////////////////////////////////////////\n\npub struct AnonPipe {\n    inner: Handle,\n}\n\npub struct Pipes {\n    pub ours: AnonPipe,\n    pub theirs: AnonPipe,\n}\n\n/// Although this looks similar to `anon_pipe` in the Unix module it's actually\n/// subtly different. Here we'll return two pipes in the `Pipes` return value,\n/// but one is intended for \"us\" where as the other is intended for \"someone\n/// else\".\n///\n/// Currently the only use case for this function is pipes for stdio on\n/// processes in the standard library, so \"ours\" is the one that'll stay in our\n/// process whereas \"theirs\" will be inherited to a child.\n///\n/// The ours/theirs pipes are *not* specifically readable or writable. Each\n/// one only supports a read or a write, but which is which depends on the\n/// boolean flag given. If `ours_readable` is `true`, then `ours` is readable and\n/// `theirs` is writable. Conversely, if `ours_readable` is `false`, then `ours`\n/// is writable and `theirs` is readable.\n///\n/// Also note that the `ours` pipe is always a handle opened up in overlapped\n/// mode. This means that technically speaking it should only ever be used\n/// with `OVERLAPPED` instances, but also works out ok if it's only ever used\n/// once at a time (which we do indeed guarantee).\npub fn anon_pipe(ours_readable: bool, their_handle_inheritable: bool) -> io::Result<Pipes> {\n    // Note that we specifically do *not* use `CreatePipe` here because\n    // unfortunately the anonymous pipes returned do not support overlapped\n    // operations. Instead, we create a \"hopefully unique\" name and create a\n    // named pipe which has overlapped operations enabled.\n    //\n    // Once we do this, we connect do it as usual via `CreateFileW`, and then\n    // we return those reader/writer halves. Note that the `ours` pipe return\n    // value is always the named pipe, whereas `theirs` is just the normal file.\n    // This should hopefully shield us from child processes which assume their\n    // stdout is a named pipe, which would indeed be odd!\n    unsafe {\n        let ours;\n        let mut name;\n        let mut tries = 0;\n        let mut reject_remote_clients_flag = c::PIPE_REJECT_REMOTE_CLIENTS;\n        loop {\n            tries += 1;\n            name = format!(\n                r\"\\\\.\\pipe\\__rust_anonymous_pipe1__.{}.{}\",\n                c::GetCurrentProcessId(),\n                random_number()\n            );\n            let wide_name = OsStr::new(&name).encode_wide().chain(Some(0)).collect::<Vec<_>>();\n            let mut flags = c::FILE_FLAG_FIRST_PIPE_INSTANCE | c::FILE_FLAG_OVERLAPPED;\n            if ours_readable {\n                flags |= c::PIPE_ACCESS_INBOUND;\n            } else {\n                flags |= c::PIPE_ACCESS_OUTBOUND;\n            }\n\n            let handle = c::CreateNamedPipeW(\n                wide_name.as_ptr(),\n                flags,\n                c::PIPE_TYPE_BYTE\n                    | c::PIPE_READMODE_BYTE\n                    | c::PIPE_WAIT\n                    | reject_remote_clients_flag,\n                1,\n                4096,\n                4096,\n                0,\n                ptr::null_mut(),\n            );\n\n            // We pass the `FILE_FLAG_FIRST_PIPE_INSTANCE` flag above, and we're\n            // also just doing a best effort at selecting a unique name. If\n            // `ERROR_ACCESS_DENIED` is returned then it could mean that we\n            // accidentally conflicted with an already existing pipe, so we try\n            // again.\n            //\n            // Don't try again too much though as this could also perhaps be a\n            // legit error.\n            // If `ERROR_INVALID_PARAMETER` is returned, this probably means we're\n            // running on pre-Vista version where `PIPE_REJECT_REMOTE_CLIENTS` is\n            // not supported, so we continue retrying without it. This implies\n            // reduced security on Windows versions older than Vista by allowing\n            // connections to this pipe from remote machines.\n            // Proper fix would increase the number of FFI imports and introduce\n            // significant amount of Windows XP specific code with no clean\n            // testing strategy\n            // For more info, see https://github.com/rust-lang/rust/pull/37677.\n            if handle == c::INVALID_HANDLE_VALUE {\n                let err = io::Error::last_os_error();\n                let raw_os_err = err.raw_os_error();\n                if tries < 10 {\n                    if raw_os_err == Some(c::ERROR_ACCESS_DENIED as i32) {\n                        continue;\n                    } else if reject_remote_clients_flag != 0\n                        && raw_os_err == Some(c::ERROR_INVALID_PARAMETER as i32)\n                    {\n                        reject_remote_clients_flag = 0;\n                        tries -= 1;\n                        continue;\n                    }\n                }\n                return Err(err);\n            }\n            ours = Handle::new(handle);\n            break;\n        }\n\n        // Connect to the named pipe we just created. This handle is going to be\n        // returned in `theirs`, so if `ours` is readable we want this to be\n        // writable, otherwise if `ours` is writable we want this to be\n        // readable.\n        //\n        // Additionally we don't enable overlapped mode on this because most\n        // client processes aren't enabled to work with that.\n        let mut opts = OpenOptions::new();\n        opts.write(ours_readable);\n        opts.read(!ours_readable);\n        opts.share_mode(0);\n        let size = mem::size_of::<c::SECURITY_ATTRIBUTES>();\n        let mut sa = c::SECURITY_ATTRIBUTES {\n            nLength: size as c::DWORD,\n            lpSecurityDescriptor: ptr::null_mut(),\n            bInheritHandle: their_handle_inheritable as i32,\n        };\n        opts.security_attributes(&mut sa);\n        let theirs = File::open(Path::new(&name), &opts)?;\n        let theirs = AnonPipe { inner: theirs.into_handle() };\n\n        Ok(Pipes {\n            ours: AnonPipe { inner: ours },\n            theirs: AnonPipe { inner: theirs.into_handle() },\n        })\n    }\n}\n\nfn random_number() -> usize {\n    static N: AtomicUsize = AtomicUsize::new(0);\n    loop {\n        if N.load(SeqCst) != 0 {\n            return N.fetch_add(1, SeqCst);\n        }\n\n        N.store(hashmap_random_keys().0 as usize, SeqCst);\n    }\n}\n\nimpl AnonPipe {\n    pub fn handle(&self) -> &Handle {\n        &self.inner\n    }\n    pub fn into_handle(self) -> Handle {\n        self.inner\n    }\n\n    pub fn read(&self, buf: &mut [u8]) -> io::Result<usize> {\n        self.inner.read(buf)\n    }\n\n    pub fn read_vectored(&self, bufs: &mut [IoSliceMut<'_>]) -> io::Result<usize> {\n        self.inner.read_vectored(bufs)\n    }\n\n    #[inline]\n    pub fn is_read_vectored(&self) -> bool {\n        self.inner.is_read_vectored()\n    }\n\n    pub fn write(&self, buf: &[u8]) -> io::Result<usize> {\n        self.inner.write(buf)\n    }\n\n    pub fn write_vectored(&self, bufs: &[IoSlice<'_>]) -> io::Result<usize> {\n        self.inner.write_vectored(bufs)\n    }\n\n    #[inline]\n    pub fn is_write_vectored(&self) -> bool {\n        self.inner.is_write_vectored()\n    }\n}\n\npub fn read2(p1: AnonPipe, v1: &mut Vec<u8>, p2: AnonPipe, v2: &mut Vec<u8>) -> io::Result<()> {\n    let p1 = p1.into_handle();\n    let p2 = p2.into_handle();\n\n    let mut p1 = AsyncPipe::new(p1, v1)?;\n    let mut p2 = AsyncPipe::new(p2, v2)?;\n    let objs = [p1.event.raw(), p2.event.raw()];\n\n    // In a loop we wait for either pipe's scheduled read operation to complete.\n    // If the operation completes with 0 bytes, that means EOF was reached, in\n    // which case we just finish out the other pipe entirely.\n    //\n    // Note that overlapped I/O is in general super unsafe because we have to\n    // be careful to ensure that all pointers in play are valid for the entire\n    // duration of the I/O operation (where tons of operations can also fail).\n    // The destructor for `AsyncPipe` ends up taking care of most of this.\n    loop {\n        let res = unsafe { c::WaitForMultipleObjects(2, objs.as_ptr(), c::FALSE, c::INFINITE) };\n        if res == c::WAIT_OBJECT_0 {\n            if !p1.result()? || !p1.schedule_read()? {\n                return p2.finish();\n            }\n        } else if res == c::WAIT_OBJECT_0 + 1 {\n            if !p2.result()? || !p2.schedule_read()? {\n                return p1.finish();\n            }\n        } else {\n            return Err(io::Error::last_os_error());\n        }\n    }\n}\n\nstruct AsyncPipe<'a> {\n    pipe: Handle,\n    event: Handle,\n    overlapped: Box<c::OVERLAPPED>, // needs a stable address\n    dst: &'a mut Vec<u8>,\n    state: State,\n}\n\n#[derive(PartialEq, Debug)]\nenum State {\n    NotReading,\n    Reading,\n    Read(usize),\n}\n\nimpl<'a> AsyncPipe<'a> {\n    fn new(pipe: Handle, dst: &'a mut Vec<u8>) -> io::Result<AsyncPipe<'a>> {\n        // Create an event which we'll use to coordinate our overlapped\n        // operations, this event will be used in WaitForMultipleObjects\n        // and passed as part of the OVERLAPPED handle.\n        //\n        // Note that we do a somewhat clever thing here by flagging the\n        // event as being manually reset and setting it initially to the\n        // signaled state. This means that we'll naturally fall through the\n        // WaitForMultipleObjects call above for pipes created initially,\n        // and the only time an even will go back to \"unset\" will be once an\n        // I/O operation is successfully scheduled (what we want).\n        let event = Handle::new_event(true, true)?;\n        let mut overlapped: Box<c::OVERLAPPED> = unsafe { Box::new(mem::zeroed()) };\n        overlapped.hEvent = event.raw();\n        Ok(AsyncPipe { pipe, overlapped, event, dst, state: State::NotReading })\n    }\n\n    /// Executes an overlapped read operation.\n    ///\n    /// Must not currently be reading, and returns whether the pipe is currently\n    /// at EOF or not. If the pipe is not at EOF then `result()` must be called\n    /// to complete the read later on (may block), but if the pipe is at EOF\n    /// then `result()` should not be called as it will just block forever.\n    fn schedule_read(&mut self) -> io::Result<bool> {\n        assert_eq!(self.state, State::NotReading);\n        let amt = unsafe {\n            let slice = slice_to_end(self.dst);\n            self.pipe.read_overlapped(slice, &mut *self.overlapped)?\n        };\n\n        // If this read finished immediately then our overlapped event will\n        // remain signaled (it was signaled coming in here) and we'll progress\n        // down to the method below.\n        //\n        // Otherwise the I/O operation is scheduled and the system set our event\n        // to not signaled, so we flag ourselves into the reading state and move\n        // on.\n        self.state = match amt {\n            Some(0) => return Ok(false),\n            Some(amt) => State::Read(amt),\n            None => State::Reading,\n        };\n        Ok(true)\n    }\n\n    /// Wait for the result of the overlapped operation previously executed.\n    ///\n    /// Takes a parameter `wait` which indicates if this pipe is currently being\n    /// read whether the function should block waiting for the read to complete.\n    ///\n    /// Returns values:\n    ///\n    /// * `true` - finished any pending read and the pipe is not at EOF (keep\n    ///            going)\n    /// * `false` - finished any pending read and pipe is at EOF (stop issuing\n    ///             reads)\n    fn result(&mut self) -> io::Result<bool> {\n        let amt = match self.state {\n            State::NotReading => return Ok(true),\n            State::Reading => self.pipe.overlapped_result(&mut *self.overlapped, true)?,\n            State::Read(amt) => amt,\n        };\n        self.state = State::NotReading;\n        unsafe {\n            let len = self.dst.len();\n            self.dst.set_len(len + amt);\n        }\n        Ok(amt != 0)\n    }\n\n    /// Finishes out reading this pipe entirely.\n    ///\n    /// Waits for any pending and schedule read, and then calls `read_to_end`\n    /// if necessary to read all the remaining information.\n    fn finish(&mut self) -> io::Result<()> {\n        while self.result()? && self.schedule_read()? {\n            // ...\n        }\n        Ok(())\n    }\n}\n\nimpl<'a> Drop for AsyncPipe<'a> {\n    fn drop(&mut self) {\n        match self.state {\n            State::Reading => {}\n            _ => return,\n        }\n\n        // If we have a pending read operation, then we have to make sure that\n        // it's *done* before we actually drop this type. The kernel requires\n        // that the `OVERLAPPED` and buffer pointers are valid for the entire\n        // I/O operation.\n        //\n        // To do that, we call `CancelIo` to cancel any pending operation, and\n        // if that succeeds we wait for the overlapped result.\n        //\n        // If anything here fails, there's not really much we can do, so we leak\n        // the buffer/OVERLAPPED pointers to ensure we're at least memory safe.\n        if self.pipe.cancel_io().is_err() || self.result().is_err() {\n            let buf = mem::take(self.dst);\n            let overlapped = Box::new(unsafe { mem::zeroed() });\n            let overlapped = mem::replace(&mut self.overlapped, overlapped);\n            mem::forget((buf, overlapped));\n        }\n    }\n}\n\nunsafe fn slice_to_end(v: &mut Vec<u8>) -> &mut [u8] {\n    if v.capacity() == 0 {\n        v.reserve(16);\n    }\n    if v.capacity() == v.len() {\n        v.reserve(1);\n    }\n    slice::from_raw_parts_mut(v.as_mut_ptr().add(v.len()), v.capacity() - v.len())\n}\n"],[2380,"// Original implementation taken from rust-memchr.\n// Copyright 2015 Andrew Gallant, bluss and Nicolas Koch\n\n// Fallback memchr is fastest on Windows.\npub use core::slice::memchr::{memchr, memrchr};\n"],[2381,"#![unstable(issue = \"none\", feature = \"windows_handle\")]\n\nuse crate::cmp;\nuse crate::io::{self, ErrorKind, IoSlice, IoSliceMut, Read};\nuse crate::mem;\nuse crate::ops::Deref;\nuse crate::ptr;\nuse crate::sys::c;\nuse crate::sys::cvt;\n\n/// An owned container for `HANDLE` object, closing them on Drop.\n///\n/// All methods are inherited through a `Deref` impl to `RawHandle`\npub struct Handle(RawHandle);\n\n/// A wrapper type for `HANDLE` objects to give them proper Send/Sync inference\n/// as well as Rust-y methods.\n///\n/// This does **not** drop the handle when it goes out of scope, use `Handle`\n/// instead for that.\n#[derive(Copy, Clone)]\npub struct RawHandle(c::HANDLE);\n\nunsafe impl Send for RawHandle {}\nunsafe impl Sync for RawHandle {}\n\nimpl Handle {\n    pub fn new(handle: c::HANDLE) -> Handle {\n        Handle(RawHandle::new(handle))\n    }\n\n    pub fn new_event(manual: bool, init: bool) -> io::Result<Handle> {\n        unsafe {\n            let event =\n                c::CreateEventW(ptr::null_mut(), manual as c::BOOL, init as c::BOOL, ptr::null());\n            if event.is_null() { Err(io::Error::last_os_error()) } else { Ok(Handle::new(event)) }\n        }\n    }\n\n    pub fn into_raw(self) -> c::HANDLE {\n        let ret = self.raw();\n        mem::forget(self);\n        ret\n    }\n}\n\nimpl Deref for Handle {\n    type Target = RawHandle;\n    fn deref(&self) -> &RawHandle {\n        &self.0\n    }\n}\n\nimpl Drop for Handle {\n    fn drop(&mut self) {\n        unsafe {\n            let _ = c::CloseHandle(self.raw());\n        }\n    }\n}\n\nimpl RawHandle {\n    pub fn new(handle: c::HANDLE) -> RawHandle {\n        RawHandle(handle)\n    }\n\n    pub fn raw(&self) -> c::HANDLE {\n        self.0\n    }\n\n    pub fn read(&self, buf: &mut [u8]) -> io::Result<usize> {\n        let mut read = 0;\n        let len = cmp::min(buf.len(), <c::DWORD>::MAX as usize) as c::DWORD;\n        let res = cvt(unsafe {\n            c::ReadFile(self.0, buf.as_mut_ptr() as c::LPVOID, len, &mut read, ptr::null_mut())\n        });\n\n        match res {\n            Ok(_) => Ok(read as usize),\n\n            // The special treatment of BrokenPipe is to deal with Windows\n            // pipe semantics, which yields this error when *reading* from\n            // a pipe after the other end has closed; we interpret that as\n            // EOF on the pipe.\n            Err(ref e) if e.kind() == ErrorKind::BrokenPipe => Ok(0),\n\n            Err(e) => Err(e),\n        }\n    }\n\n    pub fn read_vectored(&self, bufs: &mut [IoSliceMut<'_>]) -> io::Result<usize> {\n        crate::io::default_read_vectored(|buf| self.read(buf), bufs)\n    }\n\n    #[inline]\n    pub fn is_read_vectored(&self) -> bool {\n        false\n    }\n\n    pub fn read_at(&self, buf: &mut [u8], offset: u64) -> io::Result<usize> {\n        let mut read = 0;\n        let len = cmp::min(buf.len(), <c::DWORD>::MAX as usize) as c::DWORD;\n        let res = unsafe {\n            let mut overlapped: c::OVERLAPPED = mem::zeroed();\n            overlapped.Offset = offset as u32;\n            overlapped.OffsetHigh = (offset >> 32) as u32;\n            cvt(c::ReadFile(self.0, buf.as_mut_ptr() as c::LPVOID, len, &mut read, &mut overlapped))\n        };\n        match res {\n            Ok(_) => Ok(read as usize),\n            Err(ref e) if e.raw_os_error() == Some(c::ERROR_HANDLE_EOF as i32) => Ok(0),\n            Err(e) => Err(e),\n        }\n    }\n\n    pub unsafe fn read_overlapped(\n        &self,\n        buf: &mut [u8],\n        overlapped: *mut c::OVERLAPPED,\n    ) -> io::Result<Option<usize>> {\n        let len = cmp::min(buf.len(), <c::DWORD>::MAX as usize) as c::DWORD;\n        let mut amt = 0;\n        let res = cvt(c::ReadFile(self.0, buf.as_ptr() as c::LPVOID, len, &mut amt, overlapped));\n        match res {\n            Ok(_) => Ok(Some(amt as usize)),\n            Err(e) => {\n                if e.raw_os_error() == Some(c::ERROR_IO_PENDING as i32) {\n                    Ok(None)\n                } else if e.raw_os_error() == Some(c::ERROR_BROKEN_PIPE as i32) {\n                    Ok(Some(0))\n                } else {\n                    Err(e)\n                }\n            }\n        }\n    }\n\n    pub fn overlapped_result(\n        &self,\n        overlapped: *mut c::OVERLAPPED,\n        wait: bool,\n    ) -> io::Result<usize> {\n        unsafe {\n            let mut bytes = 0;\n            let wait = if wait { c::TRUE } else { c::FALSE };\n            let res = cvt(c::GetOverlappedResult(self.raw(), overlapped, &mut bytes, wait));\n            match res {\n                Ok(_) => Ok(bytes as usize),\n                Err(e) => {\n                    if e.raw_os_error() == Some(c::ERROR_HANDLE_EOF as i32)\n                        || e.raw_os_error() == Some(c::ERROR_BROKEN_PIPE as i32)\n                    {\n                        Ok(0)\n                    } else {\n                        Err(e)\n                    }\n                }\n            }\n        }\n    }\n\n    pub fn cancel_io(&self) -> io::Result<()> {\n        unsafe { cvt(c::CancelIo(self.raw())).map(drop) }\n    }\n\n    pub fn write(&self, buf: &[u8]) -> io::Result<usize> {\n        let mut amt = 0;\n        let len = cmp::min(buf.len(), <c::DWORD>::MAX as usize) as c::DWORD;\n        cvt(unsafe {\n            c::WriteFile(self.0, buf.as_ptr() as c::LPVOID, len, &mut amt, ptr::null_mut())\n        })?;\n        Ok(amt as usize)\n    }\n\n    pub fn write_vectored(&self, bufs: &[IoSlice<'_>]) -> io::Result<usize> {\n        crate::io::default_write_vectored(|buf| self.write(buf), bufs)\n    }\n\n    #[inline]\n    pub fn is_write_vectored(&self) -> bool {\n        false\n    }\n\n    pub fn write_at(&self, buf: &[u8], offset: u64) -> io::Result<usize> {\n        let mut written = 0;\n        let len = cmp::min(buf.len(), <c::DWORD>::MAX as usize) as c::DWORD;\n        unsafe {\n            let mut overlapped: c::OVERLAPPED = mem::zeroed();\n            overlapped.Offset = offset as u32;\n            overlapped.OffsetHigh = (offset >> 32) as u32;\n            cvt(c::WriteFile(\n                self.0,\n                buf.as_ptr() as c::LPVOID,\n                len,\n                &mut written,\n                &mut overlapped,\n            ))?;\n        }\n        Ok(written as usize)\n    }\n\n    pub fn duplicate(\n        &self,\n        access: c::DWORD,\n        inherit: bool,\n        options: c::DWORD,\n    ) -> io::Result<Handle> {\n        let mut ret = 0 as c::HANDLE;\n        cvt(unsafe {\n            let cur_proc = c::GetCurrentProcess();\n            c::DuplicateHandle(\n                cur_proc,\n                self.0,\n                cur_proc,\n                &mut ret,\n                access,\n                inherit as c::BOOL,\n                options,\n            )\n        })?;\n        Ok(Handle::new(ret))\n    }\n}\n\nimpl<'a> Read for &'a RawHandle {\n    fn read(&mut self, buf: &mut [u8]) -> io::Result<usize> {\n        (**self).read(buf)\n    }\n\n    fn read_vectored(&mut self, bufs: &mut [IoSliceMut<'_>]) -> io::Result<usize> {\n        (**self).read_vectored(bufs)\n    }\n}\n"],[2382,"use super::{Header, MIN_ALIGN};\nuse crate::mem;\n\n#[test]\nfn alloc_header() {\n    // Header must fit in the padding before an aligned pointer\n    assert!(mem::size_of::<Header>() <= MIN_ALIGN);\n    assert!(mem::align_of::<Header>() <= MIN_ALIGN);\n}\n"],[2383,"#![unstable(issue = \"none\", feature = \"windows_stdio\")]\n\nuse crate::io;\nuse crate::mem::ManuallyDrop;\nuse crate::sys::c;\nuse crate::sys::handle::Handle;\n\npub struct Stdin {}\npub struct Stdout;\npub struct Stderr;\n\nconst MAX_BUFFER_SIZE: usize = 8192;\npub const STDIN_BUF_SIZE: usize = MAX_BUFFER_SIZE / 2 * 3;\n\npub fn get_handle(handle_id: c::DWORD) -> io::Result<c::HANDLE> {\n    let handle = unsafe { c::GetStdHandle(handle_id) };\n    if handle == c::INVALID_HANDLE_VALUE {\n        Err(io::Error::last_os_error())\n    } else if handle.is_null() {\n        Err(io::Error::from_raw_os_error(c::ERROR_INVALID_HANDLE as i32))\n    } else {\n        Ok(handle)\n    }\n}\n\nfn write(handle_id: c::DWORD, data: &[u8]) -> io::Result<usize> {\n    let handle = get_handle(handle_id)?;\n    let handle = Handle::new(handle);\n    ManuallyDrop::new(handle).write(data)\n}\n\nimpl Stdin {\n    pub const fn new() -> Stdin {\n        Stdin {}\n    }\n}\n\nimpl io::Read for Stdin {\n    fn read(&mut self, buf: &mut [u8]) -> io::Result<usize> {\n        let handle = get_handle(c::STD_INPUT_HANDLE)?;\n        let handle = Handle::new(handle);\n        ManuallyDrop::new(handle).read(buf)\n    }\n}\n\nimpl Stdout {\n    pub const fn new() -> Stdout {\n        Stdout\n    }\n}\n\nimpl io::Write for Stdout {\n    fn write(&mut self, buf: &[u8]) -> io::Result<usize> {\n        write(c::STD_OUTPUT_HANDLE, buf)\n    }\n\n    fn flush(&mut self) -> io::Result<()> {\n        Ok(())\n    }\n}\n\nimpl Stderr {\n    pub const fn new() -> Stderr {\n        Stderr\n    }\n}\n\nimpl io::Write for Stderr {\n    fn write(&mut self, buf: &[u8]) -> io::Result<usize> {\n        write(c::STD_ERROR_HANDLE, buf)\n    }\n\n    fn flush(&mut self) -> io::Result<()> {\n        Ok(())\n    }\n}\n\npub fn is_ebadf(err: &io::Error) -> bool {\n    err.raw_os_error() == Some(c::ERROR_INVALID_HANDLE as i32)\n}\n\npub fn panic_output() -> Option<impl io::Write> {\n    Some(Stderr::new())\n}\n"],[2384,"use super::make_command_line;\nuse crate::ffi::{OsStr, OsString};\n\n#[test]\nfn test_make_command_line() {\n    fn test_wrapper(prog: &str, args: &[&str], force_quotes: bool) -> String {\n        let command_line = &make_command_line(\n            OsStr::new(prog),\n            &args.iter().map(|a| OsString::from(a)).collect::<Vec<OsString>>(),\n            force_quotes,\n        )\n        .unwrap();\n        String::from_utf16(command_line).unwrap()\n    }\n\n    assert_eq!(test_wrapper(\"prog\", &[\"aaa\", \"bbb\", \"ccc\"], false), \"\\\"prog\\\" aaa bbb ccc\");\n\n    assert_eq!(\n        test_wrapper(\"C:\\\\Program Files\\\\blah\\\\blah.exe\", &[\"aaa\"], false),\n        \"\\\"C:\\\\Program Files\\\\blah\\\\blah.exe\\\" aaa\"\n    );\n    assert_eq!(\n        test_wrapper(\"C:\\\\Program Files\\\\blah\\\\blah.exe\", &[\"aaa\", \"v*\"], false),\n        \"\\\"C:\\\\Program Files\\\\blah\\\\blah.exe\\\" aaa v*\"\n    );\n    assert_eq!(\n        test_wrapper(\"C:\\\\Program Files\\\\blah\\\\blah.exe\", &[\"aaa\", \"v*\"], true),\n        \"\\\"C:\\\\Program Files\\\\blah\\\\blah.exe\\\" \\\"aaa\\\" \\\"v*\\\"\"\n    );\n    assert_eq!(\n        test_wrapper(\"C:\\\\Program Files\\\\test\", &[\"aa\\\"bb\"], false),\n        \"\\\"C:\\\\Program Files\\\\test\\\" aa\\\\\\\"bb\"\n    );\n    assert_eq!(test_wrapper(\"echo\", &[\"a b c\"], false), \"\\\"echo\\\" \\\"a b c\\\"\");\n    assert_eq!(\n        test_wrapper(\"echo\", &[\"\\\" \\\\\\\" \\\\\", \"\\\\\"], false),\n        \"\\\"echo\\\" \\\"\\\\\\\" \\\\\\\\\\\\\\\" \\\\\\\\\\\" \\\\\"\n    );\n    assert_eq!(\n        test_wrapper(\"\\u{03c0}\\u{042f}\\u{97f3}\\u{00e6}\\u{221e}\", &[], false),\n        \"\\\"\\u{03c0}\\u{042f}\\u{97f3}\\u{00e6}\\u{221e}\\\"\"\n    );\n}\n"],[2385,"use crate::io::Error;\nuse crate::sys::c;\n\n// tests `error_string` above\n#[test]\nfn ntstatus_error() {\n    const STATUS_UNSUCCESSFUL: u32 = 0xc000_0001;\n    assert!(\n        !Error::from_raw_os_error((STATUS_UNSUCCESSFUL | c::FACILITY_NT_BIT) as _)\n            .to_string()\n            .contains(\"FormatMessageW() returned error\")\n    );\n}\n"],[2386,"#![deny(unsafe_op_in_unsafe_fn)]\n\nuse crate::alloc::{GlobalAlloc, Layout, System};\nuse crate::ffi::c_void;\nuse crate::ptr;\nuse crate::sync::atomic::{AtomicPtr, Ordering};\nuse crate::sys::c;\nuse crate::sys::common::alloc::{realloc_fallback, MIN_ALIGN};\n\n#[cfg(test)]\nmod tests;\n\n// Heap memory management on Windows is done by using the system Heap API (heapapi.h)\n// See https://docs.microsoft.com/windows/win32/api/heapapi/\n\n// Flag to indicate that the memory returned by `HeapAlloc` should be zeroed.\nconst HEAP_ZERO_MEMORY: c::DWORD = 0x00000008;\n\nextern \"system\" {\n    // Get a handle to the default heap of the current process, or null if the operation fails.\n    //\n    // SAFETY: Successful calls to this function within the same process are assumed to\n    // always return the same handle, which remains valid for the entire lifetime of the process.\n    //\n    // See https://docs.microsoft.com/windows/win32/api/heapapi/nf-heapapi-getprocessheap\n    fn GetProcessHeap() -> c::HANDLE;\n\n    // Allocate a block of `dwBytes` bytes of memory from a given heap `hHeap`.\n    // The allocated memory may be uninitialized, or zeroed if `dwFlags` is\n    // set to `HEAP_ZERO_MEMORY`.\n    //\n    // Returns a pointer to the newly-allocated memory or null if the operation fails.\n    // The returned pointer will be aligned to at least `MIN_ALIGN`.\n    //\n    // SAFETY:\n    //  - `hHeap` must be a non-null handle returned by `GetProcessHeap`.\n    //  - `dwFlags` must be set to either zero or `HEAP_ZERO_MEMORY`.\n    //\n    // Note that `dwBytes` is allowed to be zero, contrary to some other allocators.\n    //\n    // See https://docs.microsoft.com/windows/win32/api/heapapi/nf-heapapi-heapalloc\n    fn HeapAlloc(hHeap: c::HANDLE, dwFlags: c::DWORD, dwBytes: c::SIZE_T) -> c::LPVOID;\n\n    // Reallocate a block of memory behind a given pointer `lpMem` from a given heap `hHeap`,\n    // to a block of at least `dwBytes` bytes, either shrinking the block in place,\n    // or allocating at a new location, copying memory, and freeing the original location.\n    //\n    // Returns a pointer to the reallocated memory or null if the operation fails.\n    // The returned pointer will be aligned to at least `MIN_ALIGN`.\n    // If the operation fails the given block will never have been freed.\n    //\n    // SAFETY:\n    //  - `hHeap` must be a non-null handle returned by `GetProcessHeap`.\n    //  - `dwFlags` must be set to zero.\n    //  - `lpMem` must be a non-null pointer to an allocated block returned by `HeapAlloc` or\n    //     `HeapReAlloc`, that has not already been freed.\n    // If the block was successfully reallocated at a new location, pointers pointing to\n    // the freed memory, such as `lpMem`, must not be dereferenced ever again.\n    //\n    // Note that `dwBytes` is allowed to be zero, contrary to some other allocators.\n    //\n    // See https://docs.microsoft.com/windows/win32/api/heapapi/nf-heapapi-heaprealloc\n    fn HeapReAlloc(\n        hHeap: c::HANDLE,\n        dwFlags: c::DWORD,\n        lpMem: c::LPVOID,\n        dwBytes: c::SIZE_T,\n    ) -> c::LPVOID;\n\n    // Free a block of memory behind a given pointer `lpMem` from a given heap `hHeap`.\n    // Returns a nonzero value if the operation is successful, and zero if the operation fails.\n    //\n    // SAFETY:\n    //  - `hHeap` must be a non-null handle returned by `GetProcessHeap`.\n    //  - `dwFlags` must be set to zero.\n    //  - `lpMem` must be a pointer to an allocated block returned by `HeapAlloc` or `HeapReAlloc`,\n    //     that has not already been freed.\n    // If the block was successfully freed, pointers pointing to the freed memory, such as `lpMem`,\n    // must not be dereferenced ever again.\n    //\n    // Note that `lpMem` is allowed to be null, which will not cause the operation to fail.\n    //\n    // See https://docs.microsoft.com/windows/win32/api/heapapi/nf-heapapi-heapfree\n    fn HeapFree(hHeap: c::HANDLE, dwFlags: c::DWORD, lpMem: c::LPVOID) -> c::BOOL;\n}\n\n// Cached handle to the default heap of the current process.\n// Either a non-null handle returned by `GetProcessHeap`, or null when not yet initialized or `GetProcessHeap` failed.\nstatic HEAP: AtomicPtr<c_void> = AtomicPtr::new(ptr::null_mut());\n\n// Get a handle to the default heap of the current process, or null if the operation fails.\n// If this operation is successful, `HEAP` will be successfully initialized and contain\n// a non-null handle returned by `GetProcessHeap`.\n#[inline]\nfn init_or_get_process_heap() -> c::HANDLE {\n    let heap = HEAP.load(Ordering::Relaxed);\n    if heap.is_null() {\n        // `HEAP` has not yet been successfully initialized\n        let heap = unsafe { GetProcessHeap() };\n        if !heap.is_null() {\n            // SAFETY: No locking is needed because within the same process,\n            // successful calls to `GetProcessHeap` will always return the same value, even on different threads.\n            HEAP.store(heap, Ordering::Release);\n\n            // SAFETY: `HEAP` contains a non-null handle returned by `GetProcessHeap`\n            heap\n        } else {\n            // Could not get the current process heap.\n            ptr::null_mut()\n        }\n    } else {\n        // SAFETY: `HEAP` contains a non-null handle returned by `GetProcessHeap`\n        heap\n    }\n}\n\n// Get a non-null handle to the default heap of the current process.\n// SAFETY: `HEAP` must have been successfully initialized.\n#[inline]\nunsafe fn get_process_heap() -> c::HANDLE {\n    HEAP.load(Ordering::Acquire)\n}\n\n// Header containing a pointer to the start of an allocated block.\n// SAFETY: Size and alignment must be <= `MIN_ALIGN`.\n#[repr(C)]\nstruct Header(*mut u8);\n\n// Allocate a block of optionally zeroed memory for a given `layout`.\n// SAFETY: Returns a pointer satisfying the guarantees of `System` about allocated pointers,\n// or null if the operation fails. If this returns non-null `HEAP` will have been successfully\n// initialized.\n#[inline]\nunsafe fn allocate(layout: Layout, zeroed: bool) -> *mut u8 {\n    let heap = init_or_get_process_heap();\n    if heap.is_null() {\n        // Allocation has failed, could not get the current process heap.\n        return ptr::null_mut();\n    }\n\n    // Allocated memory will be either zeroed or uninitialized.\n    let flags = if zeroed { HEAP_ZERO_MEMORY } else { 0 };\n\n    if layout.align() <= MIN_ALIGN {\n        // SAFETY: `heap` is a non-null handle returned by `GetProcessHeap`.\n        // The returned pointer points to the start of an allocated block.\n        unsafe { HeapAlloc(heap, flags, layout.size()) as *mut u8 }\n    } else {\n        // Allocate extra padding in order to be able to satisfy the alignment.\n        let total = layout.align() + layout.size();\n\n        // SAFETY: `heap` is a non-null handle returned by `GetProcessHeap`.\n        let ptr = unsafe { HeapAlloc(heap, flags, total) as *mut u8 };\n        if ptr.is_null() {\n            // Allocation has failed.\n            return ptr::null_mut();\n        }\n\n        // Create a correctly aligned pointer offset from the start of the allocated block,\n        // and write a header before it.\n\n        let offset = layout.align() - (ptr as usize & (layout.align() - 1));\n        // SAFETY: `MIN_ALIGN` <= `offset` <= `layout.align()` and the size of the allocated\n        // block is `layout.align() + layout.size()`. `aligned` will thus be a correctly aligned\n        // pointer inside the allocated block with at least `layout.size()` bytes after it and at\n        // least `MIN_ALIGN` bytes of padding before it.\n        let aligned = unsafe { ptr.add(offset) };\n        // SAFETY: Because the size and alignment of a header is <= `MIN_ALIGN` and `aligned`\n        // is aligned to at least `MIN_ALIGN` and has at least `MIN_ALIGN` bytes of padding before\n        // it, it is safe to write a header directly before it.\n        unsafe { ptr::write((aligned as *mut Header).offset(-1), Header(ptr)) };\n\n        // SAFETY: The returned pointer does not point to the to the start of an allocated block,\n        // but there is a header readable directly before it containing the location of the start\n        // of the block.\n        aligned\n    }\n}\n\n// All pointers returned by this allocator have, in addition to the guarantees of `GlobalAlloc`, the\n// following properties:\n//\n// If the pointer was allocated or reallocated with a `layout` specifying an alignment <= `MIN_ALIGN`\n// the pointer will be aligned to at least `MIN_ALIGN` and point to the start of the allocated block.\n//\n// If the pointer was allocated or reallocated with a `layout` specifying an alignment > `MIN_ALIGN`\n// the pointer will be aligned to the specified alignment and not point to the start of the allocated block.\n// Instead there will be a header readable directly before the returned pointer, containing the actual\n// location of the start of the block.\n#[stable(feature = \"alloc_system_type\", since = \"1.28.0\")]\nunsafe impl GlobalAlloc for System {\n    #[inline]\n    unsafe fn alloc(&self, layout: Layout) -> *mut u8 {\n        // SAFETY: Pointers returned by `allocate` satisfy the guarantees of `System`\n        let zeroed = false;\n        unsafe { allocate(layout, zeroed) }\n    }\n\n    #[inline]\n    unsafe fn alloc_zeroed(&self, layout: Layout) -> *mut u8 {\n        // SAFETY: Pointers returned by `allocate` satisfy the guarantees of `System`\n        let zeroed = true;\n        unsafe { allocate(layout, zeroed) }\n    }\n\n    #[inline]\n    unsafe fn dealloc(&self, ptr: *mut u8, layout: Layout) {\n        let block = {\n            if layout.align() <= MIN_ALIGN {\n                ptr\n            } else {\n                // The location of the start of the block is stored in the padding before `ptr`.\n\n                // SAFETY: Because of the contract of `System`, `ptr` is guaranteed to be non-null\n                // and have a header readable directly before it.\n                unsafe { ptr::read((ptr as *mut Header).offset(-1)).0 }\n            }\n        };\n\n        // SAFETY: because `ptr` has been successfully allocated with this allocator,\n        // `HEAP` must have been successfully initialized.\n        let heap = unsafe { get_process_heap() };\n\n        // SAFETY: `heap` is a non-null handle returned by `GetProcessHeap`,\n        // `block` is a pointer to the start of an allocated block.\n        unsafe { HeapFree(heap, 0, block as c::LPVOID) };\n    }\n\n    #[inline]\n    unsafe fn realloc(&self, ptr: *mut u8, layout: Layout, new_size: usize) -> *mut u8 {\n        if layout.align() <= MIN_ALIGN {\n            // SAFETY: because `ptr` has been successfully allocated with this allocator,\n            // `HEAP` must have been successfully initialized.\n            let heap = unsafe { get_process_heap() };\n\n            // SAFETY: `heap` is a non-null handle returned by `GetProcessHeap`,\n            // `ptr` is a pointer to the start of an allocated block.\n            // The returned pointer points to the start of an allocated block.\n            unsafe { HeapReAlloc(heap, 0, ptr as c::LPVOID, new_size) as *mut u8 }\n        } else {\n            // SAFETY: `realloc_fallback` is implemented using `dealloc` and `alloc`, which will\n            // correctly handle `ptr` and return a pointer satisfying the guarantees of `System`\n            unsafe { realloc_fallback(self, ptr, layout, new_size) }\n        }\n    }\n}\n"],[2387,"#![cfg_attr(test, allow(dead_code))]\n\nuse crate::sys::c;\nuse crate::thread;\n\npub struct Handler;\n\nimpl Handler {\n    pub unsafe fn new() -> Handler {\n        // This API isn't available on XP, so don't panic in that case and just\n        // pray it works out ok.\n        if c::SetThreadStackGuarantee(&mut 0x5000) == 0 {\n            if c::GetLastError() as u32 != c::ERROR_CALL_NOT_IMPLEMENTED as u32 {\n                panic!(\"failed to reserve stack space for exception handling\");\n            }\n        }\n        Handler\n    }\n}\n\nextern \"system\" fn vectored_handler(ExceptionInfo: *mut c::EXCEPTION_POINTERS) -> c::LONG {\n    unsafe {\n        let rec = &(*(*ExceptionInfo).ExceptionRecord);\n        let code = rec.ExceptionCode;\n\n        if code == c::EXCEPTION_STACK_OVERFLOW {\n            rtprintpanic!(\n                \"\\nthread '{}' has overflowed its stack\\n\",\n                thread::current().name().unwrap_or(\"<unknown>\")\n            );\n        }\n        c::EXCEPTION_CONTINUE_SEARCH\n    }\n}\n\npub unsafe fn init() {\n    if c::AddVectoredExceptionHandler(0, vectored_handler).is_null() {\n        panic!(\"failed to install exception handler\");\n    }\n    // Set the thread stack guarantee for the main thread.\n    let _h = Handler::new();\n}\n"],[2388,"//! Implementation of `std::os` functionality for Windows.\n\n#![allow(nonstandard_style)]\n\n#[cfg(test)]\nmod tests;\n\nuse crate::os::windows::prelude::*;\n\nuse crate::error::Error as StdError;\nuse crate::ffi::{OsStr, OsString};\nuse crate::fmt;\nuse crate::io;\nuse crate::os::windows::ffi::EncodeWide;\nuse crate::path::{self, PathBuf};\nuse crate::ptr;\nuse crate::slice;\nuse crate::sys::{c, cvt};\n\nuse super::to_u16s;\n\npub fn errno() -> i32 {\n    unsafe { c::GetLastError() as i32 }\n}\n\n/// Gets a detailed string description for the given error number.\npub fn error_string(mut errnum: i32) -> String {\n    // This value is calculated from the macro\n    // MAKELANGID(LANG_SYSTEM_DEFAULT, SUBLANG_SYS_DEFAULT)\n    let langId = 0x0800 as c::DWORD;\n\n    let mut buf = [0 as c::WCHAR; 2048];\n\n    unsafe {\n        let mut module = ptr::null_mut();\n        let mut flags = 0;\n\n        // NTSTATUS errors may be encoded as HRESULT, which may returned from\n        // GetLastError. For more information about Windows error codes, see\n        // `[MS-ERREF]`: https://docs.microsoft.com/en-us/openspecs/windows_protocols/ms-erref/0642cb2f-2075-4469-918c-4441e69c548a\n        if (errnum & c::FACILITY_NT_BIT as i32) != 0 {\n            // format according to https://support.microsoft.com/en-us/help/259693\n            const NTDLL_DLL: &[u16] = &[\n                'N' as _, 'T' as _, 'D' as _, 'L' as _, 'L' as _, '.' as _, 'D' as _, 'L' as _,\n                'L' as _, 0,\n            ];\n            module = c::GetModuleHandleW(NTDLL_DLL.as_ptr());\n\n            if !module.is_null() {\n                errnum ^= c::FACILITY_NT_BIT as i32;\n                flags = c::FORMAT_MESSAGE_FROM_HMODULE;\n            }\n        }\n\n        let res = c::FormatMessageW(\n            flags | c::FORMAT_MESSAGE_FROM_SYSTEM | c::FORMAT_MESSAGE_IGNORE_INSERTS,\n            module,\n            errnum as c::DWORD,\n            langId,\n            buf.as_mut_ptr(),\n            buf.len() as c::DWORD,\n            ptr::null(),\n        ) as usize;\n        if res == 0 {\n            // Sometimes FormatMessageW can fail e.g., system doesn't like langId,\n            let fm_err = errno();\n            return format!(\"OS Error {} (FormatMessageW() returned error {})\", errnum, fm_err);\n        }\n\n        match String::from_utf16(&buf[..res]) {\n            Ok(mut msg) => {\n                // Trim trailing CRLF inserted by FormatMessageW\n                let len = msg.trim_end().len();\n                msg.truncate(len);\n                msg\n            }\n            Err(..) => format!(\n                \"OS Error {} (FormatMessageW() returned \\\n                 invalid UTF-16)\",\n                errnum\n            ),\n        }\n    }\n}\n\npub struct Env {\n    base: c::LPWCH,\n    cur: c::LPWCH,\n}\n\nimpl Iterator for Env {\n    type Item = (OsString, OsString);\n\n    fn next(&mut self) -> Option<(OsString, OsString)> {\n        loop {\n            unsafe {\n                if *self.cur == 0 {\n                    return None;\n                }\n                let p = self.cur as *const u16;\n                let mut len = 0;\n                while *p.offset(len) != 0 {\n                    len += 1;\n                }\n                let s = slice::from_raw_parts(p, len as usize);\n                self.cur = self.cur.offset(len + 1);\n\n                // Windows allows environment variables to start with an equals\n                // symbol (in any other position, this is the separator between\n                // variable name and value). Since`s` has at least length 1 at\n                // this point (because the empty string terminates the array of\n                // environment variables), we can safely slice.\n                let pos = match s[1..].iter().position(|&u| u == b'=' as u16).map(|p| p + 1) {\n                    Some(p) => p,\n                    None => continue,\n                };\n                return Some((\n                    OsStringExt::from_wide(&s[..pos]),\n                    OsStringExt::from_wide(&s[pos + 1..]),\n                ));\n            }\n        }\n    }\n}\n\nimpl Drop for Env {\n    fn drop(&mut self) {\n        unsafe {\n            c::FreeEnvironmentStringsW(self.base);\n        }\n    }\n}\n\npub fn env() -> Env {\n    unsafe {\n        let ch = c::GetEnvironmentStringsW();\n        if ch as usize == 0 {\n            panic!(\"failure getting env string from OS: {}\", io::Error::last_os_error());\n        }\n        Env { base: ch, cur: ch }\n    }\n}\n\npub struct SplitPaths<'a> {\n    data: EncodeWide<'a>,\n    must_yield: bool,\n}\n\npub fn split_paths(unparsed: &OsStr) -> SplitPaths<'_> {\n    SplitPaths { data: unparsed.encode_wide(), must_yield: true }\n}\n\nimpl<'a> Iterator for SplitPaths<'a> {\n    type Item = PathBuf;\n    fn next(&mut self) -> Option<PathBuf> {\n        // On Windows, the PATH environment variable is semicolon separated.\n        // Double quotes are used as a way of introducing literal semicolons\n        // (since c:\\some;dir is a valid Windows path). Double quotes are not\n        // themselves permitted in path names, so there is no way to escape a\n        // double quote.  Quoted regions can appear in arbitrary locations, so\n        //\n        //   c:\\foo;c:\\som\"e;di\"r;c:\\bar\n        //\n        // Should parse as [c:\\foo, c:\\some;dir, c:\\bar].\n        //\n        // (The above is based on testing; there is no clear reference available\n        // for the grammar.)\n\n        let must_yield = self.must_yield;\n        self.must_yield = false;\n\n        let mut in_progress = Vec::new();\n        let mut in_quote = false;\n        for b in self.data.by_ref() {\n            if b == '\"' as u16 {\n                in_quote = !in_quote;\n            } else if b == ';' as u16 && !in_quote {\n                self.must_yield = true;\n                break;\n            } else {\n                in_progress.push(b)\n            }\n        }\n\n        if !must_yield && in_progress.is_empty() {\n            None\n        } else {\n            Some(super::os2path(&in_progress))\n        }\n    }\n}\n\n#[derive(Debug)]\npub struct JoinPathsError;\n\npub fn join_paths<I, T>(paths: I) -> Result<OsString, JoinPathsError>\nwhere\n    I: Iterator<Item = T>,\n    T: AsRef<OsStr>,\n{\n    let mut joined = Vec::new();\n    let sep = b';' as u16;\n\n    for (i, path) in paths.enumerate() {\n        let path = path.as_ref();\n        if i > 0 {\n            joined.push(sep)\n        }\n        let v = path.encode_wide().collect::<Vec<u16>>();\n        if v.contains(&(b'\"' as u16)) {\n            return Err(JoinPathsError);\n        } else if v.contains(&sep) {\n            joined.push(b'\"' as u16);\n            joined.extend_from_slice(&v[..]);\n            joined.push(b'\"' as u16);\n        } else {\n            joined.extend_from_slice(&v[..]);\n        }\n    }\n\n    Ok(OsStringExt::from_wide(&joined[..]))\n}\n\nimpl fmt::Display for JoinPathsError {\n    fn fmt(&self, f: &mut fmt::Formatter<'_>) -> fmt::Result {\n        \"path segment contains `\\\"`\".fmt(f)\n    }\n}\n\nimpl StdError for JoinPathsError {\n    #[allow(deprecated)]\n    fn description(&self) -> &str {\n        \"failed to join paths\"\n    }\n}\n\npub fn current_exe() -> io::Result<PathBuf> {\n    super::fill_utf16_buf(\n        |buf, sz| unsafe { c::GetModuleFileNameW(ptr::null_mut(), buf, sz) },\n        super::os2path,\n    )\n}\n\npub fn getcwd() -> io::Result<PathBuf> {\n    super::fill_utf16_buf(|buf, sz| unsafe { c::GetCurrentDirectoryW(sz, buf) }, super::os2path)\n}\n\npub fn chdir(p: &path::Path) -> io::Result<()> {\n    let p: &OsStr = p.as_ref();\n    let mut p = p.encode_wide().collect::<Vec<_>>();\n    p.push(0);\n\n    cvt(unsafe { c::SetCurrentDirectoryW(p.as_ptr()) }).map(drop)\n}\n\npub fn getenv(k: &OsStr) -> io::Result<Option<OsString>> {\n    let k = to_u16s(k)?;\n    let res = super::fill_utf16_buf(\n        |buf, sz| unsafe { c::GetEnvironmentVariableW(k.as_ptr(), buf, sz) },\n        |buf| OsStringExt::from_wide(buf),\n    );\n    match res {\n        Ok(value) => Ok(Some(value)),\n        Err(e) => {\n            if e.raw_os_error() == Some(c::ERROR_ENVVAR_NOT_FOUND as i32) {\n                Ok(None)\n            } else {\n                Err(e)\n            }\n        }\n    }\n}\n\npub fn setenv(k: &OsStr, v: &OsStr) -> io::Result<()> {\n    let k = to_u16s(k)?;\n    let v = to_u16s(v)?;\n\n    cvt(unsafe { c::SetEnvironmentVariableW(k.as_ptr(), v.as_ptr()) }).map(drop)\n}\n\npub fn unsetenv(n: &OsStr) -> io::Result<()> {\n    let v = to_u16s(n)?;\n    cvt(unsafe { c::SetEnvironmentVariableW(v.as_ptr(), ptr::null()) }).map(drop)\n}\n\npub fn temp_dir() -> PathBuf {\n    super::fill_utf16_buf(|buf, sz| unsafe { c::GetTempPathW(sz, buf) }, super::os2path).unwrap()\n}\n\n#[cfg(not(target_vendor = \"uwp\"))]\nfn home_dir_crt() -> Option<PathBuf> {\n    unsafe {\n        use crate::sys::handle::Handle;\n\n        let me = c::GetCurrentProcess();\n        let mut token = ptr::null_mut();\n        if c::OpenProcessToken(me, c::TOKEN_READ, &mut token) == 0 {\n            return None;\n        }\n        let _handle = Handle::new(token);\n        super::fill_utf16_buf(\n            |buf, mut sz| {\n                match c::GetUserProfileDirectoryW(token, buf, &mut sz) {\n                    0 if c::GetLastError() != c::ERROR_INSUFFICIENT_BUFFER => 0,\n                    0 => sz,\n                    _ => sz - 1, // sz includes the null terminator\n                }\n            },\n            super::os2path,\n        )\n        .ok()\n    }\n}\n\n#[cfg(target_vendor = \"uwp\")]\nfn home_dir_crt() -> Option<PathBuf> {\n    None\n}\n\npub fn home_dir() -> Option<PathBuf> {\n    crate::env::var_os(\"HOME\")\n        .or_else(|| crate::env::var_os(\"USERPROFILE\"))\n        .map(PathBuf::from)\n        .or_else(|| home_dir_crt())\n}\n\npub fn exit(code: i32) -> ! {\n    unsafe { c::ExitProcess(code as c::UINT) }\n}\n\npub fn getpid() -> u32 {\n    unsafe { c::GetCurrentProcessId() as u32 }\n}\n"],[2389,"use crate::os::windows::prelude::*;\n\nuse crate::ffi::OsString;\nuse crate::fmt;\nuse crate::io::{self, Error, IoSlice, IoSliceMut, SeekFrom};\nuse crate::mem;\nuse crate::path::{Path, PathBuf};\nuse crate::ptr;\nuse crate::slice;\nuse crate::sync::Arc;\nuse crate::sys::handle::Handle;\nuse crate::sys::time::SystemTime;\nuse crate::sys::{c, cvt};\nuse crate::sys_common::FromInner;\n\nuse super::to_u16s;\n\npub struct File {\n    handle: Handle,\n}\n\n#[derive(Clone)]\npub struct FileAttr {\n    attributes: c::DWORD,\n    creation_time: c::FILETIME,\n    last_access_time: c::FILETIME,\n    last_write_time: c::FILETIME,\n    file_size: u64,\n    reparse_tag: c::DWORD,\n    volume_serial_number: Option<u32>,\n    number_of_links: Option<u32>,\n    file_index: Option<u64>,\n}\n\n#[derive(Copy, Clone, PartialEq, Eq, Hash, Debug)]\npub struct FileType {\n    attributes: c::DWORD,\n    reparse_tag: c::DWORD,\n}\n\npub struct ReadDir {\n    handle: FindNextFileHandle,\n    root: Arc<PathBuf>,\n    first: Option<c::WIN32_FIND_DATAW>,\n}\n\nstruct FindNextFileHandle(c::HANDLE);\n\nunsafe impl Send for FindNextFileHandle {}\nunsafe impl Sync for FindNextFileHandle {}\n\npub struct DirEntry {\n    root: Arc<PathBuf>,\n    data: c::WIN32_FIND_DATAW,\n}\n\n#[derive(Clone, Debug)]\npub struct OpenOptions {\n    // generic\n    read: bool,\n    write: bool,\n    append: bool,\n    truncate: bool,\n    create: bool,\n    create_new: bool,\n    // system-specific\n    custom_flags: u32,\n    access_mode: Option<c::DWORD>,\n    attributes: c::DWORD,\n    share_mode: c::DWORD,\n    security_qos_flags: c::DWORD,\n    security_attributes: usize, // FIXME: should be a reference\n}\n\n#[derive(Clone, PartialEq, Eq, Debug)]\npub struct FilePermissions {\n    attrs: c::DWORD,\n}\n\n#[derive(Debug)]\npub struct DirBuilder;\n\nimpl fmt::Debug for ReadDir {\n    fn fmt(&self, f: &mut fmt::Formatter<'_>) -> fmt::Result {\n        // This will only be called from std::fs::ReadDir, which will add a \"ReadDir()\" frame.\n        // Thus the result will be e g 'ReadDir(\"C:\\\")'\n        fmt::Debug::fmt(&*self.root, f)\n    }\n}\n\nimpl Iterator for ReadDir {\n    type Item = io::Result<DirEntry>;\n    fn next(&mut self) -> Option<io::Result<DirEntry>> {\n        if let Some(first) = self.first.take() {\n            if let Some(e) = DirEntry::new(&self.root, &first) {\n                return Some(Ok(e));\n            }\n        }\n        unsafe {\n            let mut wfd = mem::zeroed();\n            loop {\n                if c::FindNextFileW(self.handle.0, &mut wfd) == 0 {\n                    if c::GetLastError() == c::ERROR_NO_MORE_FILES {\n                        return None;\n                    } else {\n                        return Some(Err(Error::last_os_error()));\n                    }\n                }\n                if let Some(e) = DirEntry::new(&self.root, &wfd) {\n                    return Some(Ok(e));\n                }\n            }\n        }\n    }\n}\n\nimpl Drop for FindNextFileHandle {\n    fn drop(&mut self) {\n        let r = unsafe { c::FindClose(self.0) };\n        debug_assert!(r != 0);\n    }\n}\n\nimpl DirEntry {\n    fn new(root: &Arc<PathBuf>, wfd: &c::WIN32_FIND_DATAW) -> Option<DirEntry> {\n        match &wfd.cFileName[0..3] {\n            // check for '.' and '..'\n            &[46, 0, ..] | &[46, 46, 0, ..] => return None,\n            _ => {}\n        }\n\n        Some(DirEntry { root: root.clone(), data: *wfd })\n    }\n\n    pub fn path(&self) -> PathBuf {\n        self.root.join(&self.file_name())\n    }\n\n    pub fn file_name(&self) -> OsString {\n        let filename = super::truncate_utf16_at_nul(&self.data.cFileName);\n        OsString::from_wide(filename)\n    }\n\n    pub fn file_type(&self) -> io::Result<FileType> {\n        Ok(FileType::new(\n            self.data.dwFileAttributes,\n            /* reparse_tag = */ self.data.dwReserved0,\n        ))\n    }\n\n    pub fn metadata(&self) -> io::Result<FileAttr> {\n        Ok(FileAttr {\n            attributes: self.data.dwFileAttributes,\n            creation_time: self.data.ftCreationTime,\n            last_access_time: self.data.ftLastAccessTime,\n            last_write_time: self.data.ftLastWriteTime,\n            file_size: ((self.data.nFileSizeHigh as u64) << 32) | (self.data.nFileSizeLow as u64),\n            reparse_tag: if self.data.dwFileAttributes & c::FILE_ATTRIBUTE_REPARSE_POINT != 0 {\n                // reserved unless this is a reparse point\n                self.data.dwReserved0\n            } else {\n                0\n            },\n            volume_serial_number: None,\n            number_of_links: None,\n            file_index: None,\n        })\n    }\n}\n\nimpl OpenOptions {\n    pub fn new() -> OpenOptions {\n        OpenOptions {\n            // generic\n            read: false,\n            write: false,\n            append: false,\n            truncate: false,\n            create: false,\n            create_new: false,\n            // system-specific\n            custom_flags: 0,\n            access_mode: None,\n            share_mode: c::FILE_SHARE_READ | c::FILE_SHARE_WRITE | c::FILE_SHARE_DELETE,\n            attributes: 0,\n            security_qos_flags: 0,\n            security_attributes: 0,\n        }\n    }\n\n    pub fn read(&mut self, read: bool) {\n        self.read = read;\n    }\n    pub fn write(&mut self, write: bool) {\n        self.write = write;\n    }\n    pub fn append(&mut self, append: bool) {\n        self.append = append;\n    }\n    pub fn truncate(&mut self, truncate: bool) {\n        self.truncate = truncate;\n    }\n    pub fn create(&mut self, create: bool) {\n        self.create = create;\n    }\n    pub fn create_new(&mut self, create_new: bool) {\n        self.create_new = create_new;\n    }\n\n    pub fn custom_flags(&mut self, flags: u32) {\n        self.custom_flags = flags;\n    }\n    pub fn access_mode(&mut self, access_mode: u32) {\n        self.access_mode = Some(access_mode);\n    }\n    pub fn share_mode(&mut self, share_mode: u32) {\n        self.share_mode = share_mode;\n    }\n    pub fn attributes(&mut self, attrs: u32) {\n        self.attributes = attrs;\n    }\n    pub fn security_qos_flags(&mut self, flags: u32) {\n        // We have to set `SECURITY_SQOS_PRESENT` here, because one of the valid flags we can\n        // receive is `SECURITY_ANONYMOUS = 0x0`, which we can't check for later on.\n        self.security_qos_flags = flags | c::SECURITY_SQOS_PRESENT;\n    }\n    pub fn security_attributes(&mut self, attrs: c::LPSECURITY_ATTRIBUTES) {\n        self.security_attributes = attrs as usize;\n    }\n\n    fn get_access_mode(&self) -> io::Result<c::DWORD> {\n        const ERROR_INVALID_PARAMETER: i32 = 87;\n\n        match (self.read, self.write, self.append, self.access_mode) {\n            (.., Some(mode)) => Ok(mode),\n            (true, false, false, None) => Ok(c::GENERIC_READ),\n            (false, true, false, None) => Ok(c::GENERIC_WRITE),\n            (true, true, false, None) => Ok(c::GENERIC_READ | c::GENERIC_WRITE),\n            (false, _, true, None) => Ok(c::FILE_GENERIC_WRITE & !c::FILE_WRITE_DATA),\n            (true, _, true, None) => {\n                Ok(c::GENERIC_READ | (c::FILE_GENERIC_WRITE & !c::FILE_WRITE_DATA))\n            }\n            (false, false, false, None) => Err(Error::from_raw_os_error(ERROR_INVALID_PARAMETER)),\n        }\n    }\n\n    fn get_creation_mode(&self) -> io::Result<c::DWORD> {\n        const ERROR_INVALID_PARAMETER: i32 = 87;\n\n        match (self.write, self.append) {\n            (true, false) => {}\n            (false, false) => {\n                if self.truncate || self.create || self.create_new {\n                    return Err(Error::from_raw_os_error(ERROR_INVALID_PARAMETER));\n                }\n            }\n            (_, true) => {\n                if self.truncate && !self.create_new {\n                    return Err(Error::from_raw_os_error(ERROR_INVALID_PARAMETER));\n                }\n            }\n        }\n\n        Ok(match (self.create, self.truncate, self.create_new) {\n            (false, false, false) => c::OPEN_EXISTING,\n            (true, false, false) => c::OPEN_ALWAYS,\n            (false, true, false) => c::TRUNCATE_EXISTING,\n            (true, true, false) => c::CREATE_ALWAYS,\n            (_, _, true) => c::CREATE_NEW,\n        })\n    }\n\n    fn get_flags_and_attributes(&self) -> c::DWORD {\n        self.custom_flags\n            | self.attributes\n            | self.security_qos_flags\n            | if self.create_new { c::FILE_FLAG_OPEN_REPARSE_POINT } else { 0 }\n    }\n}\n\nimpl File {\n    pub fn open(path: &Path, opts: &OpenOptions) -> io::Result<File> {\n        let path = to_u16s(path)?;\n        let handle = unsafe {\n            c::CreateFileW(\n                path.as_ptr(),\n                opts.get_access_mode()?,\n                opts.share_mode,\n                opts.security_attributes as *mut _,\n                opts.get_creation_mode()?,\n                opts.get_flags_and_attributes(),\n                ptr::null_mut(),\n            )\n        };\n        if handle == c::INVALID_HANDLE_VALUE {\n            Err(Error::last_os_error())\n        } else {\n            Ok(File { handle: Handle::new(handle) })\n        }\n    }\n\n    pub fn fsync(&self) -> io::Result<()> {\n        cvt(unsafe { c::FlushFileBuffers(self.handle.raw()) })?;\n        Ok(())\n    }\n\n    pub fn datasync(&self) -> io::Result<()> {\n        self.fsync()\n    }\n\n    pub fn truncate(&self, size: u64) -> io::Result<()> {\n        let mut info = c::FILE_END_OF_FILE_INFO { EndOfFile: size as c::LARGE_INTEGER };\n        let size = mem::size_of_val(&info);\n        cvt(unsafe {\n            c::SetFileInformationByHandle(\n                self.handle.raw(),\n                c::FileEndOfFileInfo,\n                &mut info as *mut _ as *mut _,\n                size as c::DWORD,\n            )\n        })?;\n        Ok(())\n    }\n\n    #[cfg(not(target_vendor = \"uwp\"))]\n    pub fn file_attr(&self) -> io::Result<FileAttr> {\n        unsafe {\n            let mut info: c::BY_HANDLE_FILE_INFORMATION = mem::zeroed();\n            cvt(c::GetFileInformationByHandle(self.handle.raw(), &mut info))?;\n            let mut reparse_tag = 0;\n            if info.dwFileAttributes & c::FILE_ATTRIBUTE_REPARSE_POINT != 0 {\n                let mut b = [0; c::MAXIMUM_REPARSE_DATA_BUFFER_SIZE];\n                if let Ok((_, buf)) = self.reparse_point(&mut b) {\n                    reparse_tag = buf.ReparseTag;\n                }\n            }\n            Ok(FileAttr {\n                attributes: info.dwFileAttributes,\n                creation_time: info.ftCreationTime,\n                last_access_time: info.ftLastAccessTime,\n                last_write_time: info.ftLastWriteTime,\n                file_size: (info.nFileSizeLow as u64) | ((info.nFileSizeHigh as u64) << 32),\n                reparse_tag,\n                volume_serial_number: Some(info.dwVolumeSerialNumber),\n                number_of_links: Some(info.nNumberOfLinks),\n                file_index: Some(\n                    (info.nFileIndexLow as u64) | ((info.nFileIndexHigh as u64) << 32),\n                ),\n            })\n        }\n    }\n\n    #[cfg(target_vendor = \"uwp\")]\n    pub fn file_attr(&self) -> io::Result<FileAttr> {\n        unsafe {\n            let mut info: c::FILE_BASIC_INFO = mem::zeroed();\n            let size = mem::size_of_val(&info);\n            cvt(c::GetFileInformationByHandleEx(\n                self.handle.raw(),\n                c::FileBasicInfo,\n                &mut info as *mut _ as *mut libc::c_void,\n                size as c::DWORD,\n            ))?;\n            let mut attr = FileAttr {\n                attributes: info.FileAttributes,\n                creation_time: c::FILETIME {\n                    dwLowDateTime: info.CreationTime as c::DWORD,\n                    dwHighDateTime: (info.CreationTime >> 32) as c::DWORD,\n                },\n                last_access_time: c::FILETIME {\n                    dwLowDateTime: info.LastAccessTime as c::DWORD,\n                    dwHighDateTime: (info.LastAccessTime >> 32) as c::DWORD,\n                },\n                last_write_time: c::FILETIME {\n                    dwLowDateTime: info.LastWriteTime as c::DWORD,\n                    dwHighDateTime: (info.LastWriteTime >> 32) as c::DWORD,\n                },\n                file_size: 0,\n                reparse_tag: 0,\n                volume_serial_number: None,\n                number_of_links: None,\n                file_index: None,\n            };\n            let mut info: c::FILE_STANDARD_INFO = mem::zeroed();\n            let size = mem::size_of_val(&info);\n            cvt(c::GetFileInformationByHandleEx(\n                self.handle.raw(),\n                c::FileStandardInfo,\n                &mut info as *mut _ as *mut libc::c_void,\n                size as c::DWORD,\n            ))?;\n            attr.file_size = info.AllocationSize as u64;\n            attr.number_of_links = Some(info.NumberOfLinks);\n            if attr.file_type().is_reparse_point() {\n                let mut b = [0; c::MAXIMUM_REPARSE_DATA_BUFFER_SIZE];\n                if let Ok((_, buf)) = self.reparse_point(&mut b) {\n                    attr.reparse_tag = buf.ReparseTag;\n                }\n            }\n            Ok(attr)\n        }\n    }\n\n    pub fn read(&self, buf: &mut [u8]) -> io::Result<usize> {\n        self.handle.read(buf)\n    }\n\n    pub fn read_vectored(&self, bufs: &mut [IoSliceMut<'_>]) -> io::Result<usize> {\n        self.handle.read_vectored(bufs)\n    }\n\n    #[inline]\n    pub fn is_read_vectored(&self) -> bool {\n        self.handle.is_read_vectored()\n    }\n\n    pub fn read_at(&self, buf: &mut [u8], offset: u64) -> io::Result<usize> {\n        self.handle.read_at(buf, offset)\n    }\n\n    pub fn write(&self, buf: &[u8]) -> io::Result<usize> {\n        self.handle.write(buf)\n    }\n\n    pub fn write_vectored(&self, bufs: &[IoSlice<'_>]) -> io::Result<usize> {\n        self.handle.write_vectored(bufs)\n    }\n\n    #[inline]\n    pub fn is_write_vectored(&self) -> bool {\n        self.handle.is_write_vectored()\n    }\n\n    pub fn write_at(&self, buf: &[u8], offset: u64) -> io::Result<usize> {\n        self.handle.write_at(buf, offset)\n    }\n\n    pub fn flush(&self) -> io::Result<()> {\n        Ok(())\n    }\n\n    pub fn seek(&self, pos: SeekFrom) -> io::Result<u64> {\n        let (whence, pos) = match pos {\n            // Casting to `i64` is fine, `SetFilePointerEx` reinterprets this\n            // integer as `u64`.\n            SeekFrom::Start(n) => (c::FILE_BEGIN, n as i64),\n            SeekFrom::End(n) => (c::FILE_END, n),\n            SeekFrom::Current(n) => (c::FILE_CURRENT, n),\n        };\n        let pos = pos as c::LARGE_INTEGER;\n        let mut newpos = 0;\n        cvt(unsafe { c::SetFilePointerEx(self.handle.raw(), pos, &mut newpos, whence) })?;\n        Ok(newpos as u64)\n    }\n\n    pub fn duplicate(&self) -> io::Result<File> {\n        Ok(File { handle: self.handle.duplicate(0, false, c::DUPLICATE_SAME_ACCESS)? })\n    }\n\n    pub fn handle(&self) -> &Handle {\n        &self.handle\n    }\n\n    pub fn into_handle(self) -> Handle {\n        self.handle\n    }\n\n    fn reparse_point<'a>(\n        &self,\n        space: &'a mut [u8; c::MAXIMUM_REPARSE_DATA_BUFFER_SIZE],\n    ) -> io::Result<(c::DWORD, &'a c::REPARSE_DATA_BUFFER)> {\n        unsafe {\n            let mut bytes = 0;\n            cvt({\n                c::DeviceIoControl(\n                    self.handle.raw(),\n                    c::FSCTL_GET_REPARSE_POINT,\n                    ptr::null_mut(),\n                    0,\n                    space.as_mut_ptr() as *mut _,\n                    space.len() as c::DWORD,\n                    &mut bytes,\n                    ptr::null_mut(),\n                )\n            })?;\n            Ok((bytes, &*(space.as_ptr() as *const c::REPARSE_DATA_BUFFER)))\n        }\n    }\n\n    fn readlink(&self) -> io::Result<PathBuf> {\n        let mut space = [0u8; c::MAXIMUM_REPARSE_DATA_BUFFER_SIZE];\n        let (_bytes, buf) = self.reparse_point(&mut space)?;\n        unsafe {\n            let (path_buffer, subst_off, subst_len, relative) = match buf.ReparseTag {\n                c::IO_REPARSE_TAG_SYMLINK => {\n                    let info: *const c::SYMBOLIC_LINK_REPARSE_BUFFER =\n                        &buf.rest as *const _ as *const _;\n                    (\n                        &(*info).PathBuffer as *const _ as *const u16,\n                        (*info).SubstituteNameOffset / 2,\n                        (*info).SubstituteNameLength / 2,\n                        (*info).Flags & c::SYMLINK_FLAG_RELATIVE != 0,\n                    )\n                }\n                c::IO_REPARSE_TAG_MOUNT_POINT => {\n                    let info: *const c::MOUNT_POINT_REPARSE_BUFFER =\n                        &buf.rest as *const _ as *const _;\n                    (\n                        &(*info).PathBuffer as *const _ as *const u16,\n                        (*info).SubstituteNameOffset / 2,\n                        (*info).SubstituteNameLength / 2,\n                        false,\n                    )\n                }\n                _ => {\n                    return Err(io::Error::new_const(\n                        io::ErrorKind::Other,\n                        &\"Unsupported reparse point type\",\n                    ));\n                }\n            };\n            let subst_ptr = path_buffer.offset(subst_off as isize);\n            let mut subst = slice::from_raw_parts(subst_ptr, subst_len as usize);\n            // Absolute paths start with an NT internal namespace prefix `\\??\\`\n            // We should not let it leak through.\n            if !relative && subst.starts_with(&[92u16, 63u16, 63u16, 92u16]) {\n                subst = &subst[4..];\n            }\n            Ok(PathBuf::from(OsString::from_wide(subst)))\n        }\n    }\n\n    pub fn set_permissions(&self, perm: FilePermissions) -> io::Result<()> {\n        let mut info = c::FILE_BASIC_INFO {\n            CreationTime: 0,\n            LastAccessTime: 0,\n            LastWriteTime: 0,\n            ChangeTime: 0,\n            FileAttributes: perm.attrs,\n        };\n        let size = mem::size_of_val(&info);\n        cvt(unsafe {\n            c::SetFileInformationByHandle(\n                self.handle.raw(),\n                c::FileBasicInfo,\n                &mut info as *mut _ as *mut _,\n                size as c::DWORD,\n            )\n        })?;\n        Ok(())\n    }\n}\n\nimpl FromInner<c::HANDLE> for File {\n    fn from_inner(handle: c::HANDLE) -> File {\n        File { handle: Handle::new(handle) }\n    }\n}\n\nimpl fmt::Debug for File {\n    fn fmt(&self, f: &mut fmt::Formatter<'_>) -> fmt::Result {\n        // FIXME(#24570): add more info here (e.g., mode)\n        let mut b = f.debug_struct(\"File\");\n        b.field(\"handle\", &self.handle.raw());\n        if let Ok(path) = get_path(&self) {\n            b.field(\"path\", &path);\n        }\n        b.finish()\n    }\n}\n\nimpl FileAttr {\n    pub fn size(&self) -> u64 {\n        self.file_size\n    }\n\n    pub fn perm(&self) -> FilePermissions {\n        FilePermissions { attrs: self.attributes }\n    }\n\n    pub fn attrs(&self) -> u32 {\n        self.attributes\n    }\n\n    pub fn file_type(&self) -> FileType {\n        FileType::new(self.attributes, self.reparse_tag)\n    }\n\n    pub fn modified(&self) -> io::Result<SystemTime> {\n        Ok(SystemTime::from(self.last_write_time))\n    }\n\n    pub fn accessed(&self) -> io::Result<SystemTime> {\n        Ok(SystemTime::from(self.last_access_time))\n    }\n\n    pub fn created(&self) -> io::Result<SystemTime> {\n        Ok(SystemTime::from(self.creation_time))\n    }\n\n    pub fn modified_u64(&self) -> u64 {\n        to_u64(&self.last_write_time)\n    }\n\n    pub fn accessed_u64(&self) -> u64 {\n        to_u64(&self.last_access_time)\n    }\n\n    pub fn created_u64(&self) -> u64 {\n        to_u64(&self.creation_time)\n    }\n\n    pub fn volume_serial_number(&self) -> Option<u32> {\n        self.volume_serial_number\n    }\n\n    pub fn number_of_links(&self) -> Option<u32> {\n        self.number_of_links\n    }\n\n    pub fn file_index(&self) -> Option<u64> {\n        self.file_index\n    }\n}\n\nfn to_u64(ft: &c::FILETIME) -> u64 {\n    (ft.dwLowDateTime as u64) | ((ft.dwHighDateTime as u64) << 32)\n}\n\nimpl FilePermissions {\n    pub fn readonly(&self) -> bool {\n        self.attrs & c::FILE_ATTRIBUTE_READONLY != 0\n    }\n\n    pub fn set_readonly(&mut self, readonly: bool) {\n        if readonly {\n            self.attrs |= c::FILE_ATTRIBUTE_READONLY;\n        } else {\n            self.attrs &= !c::FILE_ATTRIBUTE_READONLY;\n        }\n    }\n}\n\nimpl FileType {\n    fn new(attrs: c::DWORD, reparse_tag: c::DWORD) -> FileType {\n        FileType { attributes: attrs, reparse_tag: reparse_tag }\n    }\n    pub fn is_dir(&self) -> bool {\n        !self.is_symlink() && self.is_directory()\n    }\n    pub fn is_file(&self) -> bool {\n        !self.is_symlink() && !self.is_directory()\n    }\n    pub fn is_symlink(&self) -> bool {\n        self.is_reparse_point() && self.is_reparse_tag_name_surrogate()\n    }\n    pub fn is_symlink_dir(&self) -> bool {\n        self.is_symlink() && self.is_directory()\n    }\n    pub fn is_symlink_file(&self) -> bool {\n        self.is_symlink() && !self.is_directory()\n    }\n    fn is_directory(&self) -> bool {\n        self.attributes & c::FILE_ATTRIBUTE_DIRECTORY != 0\n    }\n    fn is_reparse_point(&self) -> bool {\n        self.attributes & c::FILE_ATTRIBUTE_REPARSE_POINT != 0\n    }\n    fn is_reparse_tag_name_surrogate(&self) -> bool {\n        self.reparse_tag & 0x20000000 != 0\n    }\n}\n\nimpl DirBuilder {\n    pub fn new() -> DirBuilder {\n        DirBuilder\n    }\n\n    pub fn mkdir(&self, p: &Path) -> io::Result<()> {\n        let p = to_u16s(p)?;\n        cvt(unsafe { c::CreateDirectoryW(p.as_ptr(), ptr::null_mut()) })?;\n        Ok(())\n    }\n}\n\npub fn readdir(p: &Path) -> io::Result<ReadDir> {\n    let root = p.to_path_buf();\n    let star = p.join(\"*\");\n    let path = to_u16s(&star)?;\n\n    unsafe {\n        let mut wfd = mem::zeroed();\n        let find_handle = c::FindFirstFileW(path.as_ptr(), &mut wfd);\n        if find_handle != c::INVALID_HANDLE_VALUE {\n            Ok(ReadDir {\n                handle: FindNextFileHandle(find_handle),\n                root: Arc::new(root),\n                first: Some(wfd),\n            })\n        } else {\n            Err(Error::last_os_error())\n        }\n    }\n}\n\npub fn unlink(p: &Path) -> io::Result<()> {\n    let p_u16s = to_u16s(p)?;\n    cvt(unsafe { c::DeleteFileW(p_u16s.as_ptr()) })?;\n    Ok(())\n}\n\npub fn rename(old: &Path, new: &Path) -> io::Result<()> {\n    let old = to_u16s(old)?;\n    let new = to_u16s(new)?;\n    cvt(unsafe { c::MoveFileExW(old.as_ptr(), new.as_ptr(), c::MOVEFILE_REPLACE_EXISTING) })?;\n    Ok(())\n}\n\npub fn rmdir(p: &Path) -> io::Result<()> {\n    let p = to_u16s(p)?;\n    cvt(unsafe { c::RemoveDirectoryW(p.as_ptr()) })?;\n    Ok(())\n}\n\npub fn remove_dir_all(path: &Path) -> io::Result<()> {\n    let filetype = lstat(path)?.file_type();\n    if filetype.is_symlink() {\n        // On Windows symlinks to files and directories are removed differently.\n        // rmdir only deletes dir symlinks and junctions, not file symlinks.\n        rmdir(path)\n    } else {\n        remove_dir_all_recursive(path)\n    }\n}\n\nfn remove_dir_all_recursive(path: &Path) -> io::Result<()> {\n    for child in readdir(path)? {\n        let child = child?;\n        let child_type = child.file_type()?;\n        if child_type.is_dir() {\n            remove_dir_all_recursive(&child.path())?;\n        } else if child_type.is_symlink_dir() {\n            rmdir(&child.path())?;\n        } else {\n            unlink(&child.path())?;\n        }\n    }\n    rmdir(path)\n}\n\npub fn readlink(path: &Path) -> io::Result<PathBuf> {\n    // Open the link with no access mode, instead of generic read.\n    // By default FILE_LIST_DIRECTORY is denied for the junction \"C:\\Documents and Settings\", so\n    // this is needed for a common case.\n    let mut opts = OpenOptions::new();\n    opts.access_mode(0);\n    opts.custom_flags(c::FILE_FLAG_OPEN_REPARSE_POINT | c::FILE_FLAG_BACKUP_SEMANTICS);\n    let file = File::open(&path, &opts)?;\n    file.readlink()\n}\n\npub fn symlink(original: &Path, link: &Path) -> io::Result<()> {\n    symlink_inner(original, link, false)\n}\n\npub fn symlink_inner(original: &Path, link: &Path, dir: bool) -> io::Result<()> {\n    let original = to_u16s(original)?;\n    let link = to_u16s(link)?;\n    let flags = if dir { c::SYMBOLIC_LINK_FLAG_DIRECTORY } else { 0 };\n    // Formerly, symlink creation required the SeCreateSymbolicLink privilege. For the Windows 10\n    // Creators Update, Microsoft loosened this to allow unprivileged symlink creation if the\n    // computer is in Developer Mode, but SYMBOLIC_LINK_FLAG_ALLOW_UNPRIVILEGED_CREATE must be\n    // added to dwFlags to opt into this behaviour.\n    let result = cvt(unsafe {\n        c::CreateSymbolicLinkW(\n            link.as_ptr(),\n            original.as_ptr(),\n            flags | c::SYMBOLIC_LINK_FLAG_ALLOW_UNPRIVILEGED_CREATE,\n        ) as c::BOOL\n    });\n    if let Err(err) = result {\n        if err.raw_os_error() == Some(c::ERROR_INVALID_PARAMETER as i32) {\n            // Older Windows objects to SYMBOLIC_LINK_FLAG_ALLOW_UNPRIVILEGED_CREATE,\n            // so if we encounter ERROR_INVALID_PARAMETER, retry without that flag.\n            cvt(unsafe {\n                c::CreateSymbolicLinkW(link.as_ptr(), original.as_ptr(), flags) as c::BOOL\n            })?;\n        } else {\n            return Err(err);\n        }\n    }\n    Ok(())\n}\n\n#[cfg(not(target_vendor = \"uwp\"))]\npub fn link(original: &Path, link: &Path) -> io::Result<()> {\n    let original = to_u16s(original)?;\n    let link = to_u16s(link)?;\n    cvt(unsafe { c::CreateHardLinkW(link.as_ptr(), original.as_ptr(), ptr::null_mut()) })?;\n    Ok(())\n}\n\n#[cfg(target_vendor = \"uwp\")]\npub fn link(_original: &Path, _link: &Path) -> io::Result<()> {\n    return Err(io::Error::new_const(\n        io::ErrorKind::Unsupported,\n        &\"hard link are not supported on UWP\",\n    ));\n}\n\npub fn stat(path: &Path) -> io::Result<FileAttr> {\n    let mut opts = OpenOptions::new();\n    // No read or write permissions are necessary\n    opts.access_mode(0);\n    // This flag is so we can open directories too\n    opts.custom_flags(c::FILE_FLAG_BACKUP_SEMANTICS);\n    let file = File::open(path, &opts)?;\n    file.file_attr()\n}\n\npub fn lstat(path: &Path) -> io::Result<FileAttr> {\n    let mut opts = OpenOptions::new();\n    // No read or write permissions are necessary\n    opts.access_mode(0);\n    opts.custom_flags(c::FILE_FLAG_BACKUP_SEMANTICS | c::FILE_FLAG_OPEN_REPARSE_POINT);\n    let file = File::open(path, &opts)?;\n    file.file_attr()\n}\n\npub fn set_perm(p: &Path, perm: FilePermissions) -> io::Result<()> {\n    let p = to_u16s(p)?;\n    unsafe {\n        cvt(c::SetFileAttributesW(p.as_ptr(), perm.attrs))?;\n        Ok(())\n    }\n}\n\nfn get_path(f: &File) -> io::Result<PathBuf> {\n    super::fill_utf16_buf(\n        |buf, sz| unsafe {\n            c::GetFinalPathNameByHandleW(f.handle.raw(), buf, sz, c::VOLUME_NAME_DOS)\n        },\n        |buf| PathBuf::from(OsString::from_wide(buf)),\n    )\n}\n\npub fn canonicalize(p: &Path) -> io::Result<PathBuf> {\n    let mut opts = OpenOptions::new();\n    // No read or write permissions are necessary\n    opts.access_mode(0);\n    // This flag is so we can open directories too\n    opts.custom_flags(c::FILE_FLAG_BACKUP_SEMANTICS);\n    let f = File::open(p, &opts)?;\n    get_path(&f)\n}\n\npub fn copy(from: &Path, to: &Path) -> io::Result<u64> {\n    unsafe extern \"system\" fn callback(\n        _TotalFileSize: c::LARGE_INTEGER,\n        _TotalBytesTransferred: c::LARGE_INTEGER,\n        _StreamSize: c::LARGE_INTEGER,\n        StreamBytesTransferred: c::LARGE_INTEGER,\n        dwStreamNumber: c::DWORD,\n        _dwCallbackReason: c::DWORD,\n        _hSourceFile: c::HANDLE,\n        _hDestinationFile: c::HANDLE,\n        lpData: c::LPVOID,\n    ) -> c::DWORD {\n        if dwStreamNumber == 1 {\n            *(lpData as *mut i64) = StreamBytesTransferred;\n        }\n        c::PROGRESS_CONTINUE\n    }\n    let pfrom = to_u16s(from)?;\n    let pto = to_u16s(to)?;\n    let mut size = 0i64;\n    cvt(unsafe {\n        c::CopyFileExW(\n            pfrom.as_ptr(),\n            pto.as_ptr(),\n            Some(callback),\n            &mut size as *mut _ as *mut _,\n            ptr::null_mut(),\n            0,\n        )\n    })?;\n    Ok(size as u64)\n}\n\n#[allow(dead_code)]\npub fn symlink_junction<P: AsRef<Path>, Q: AsRef<Path>>(\n    original: P,\n    junction: Q,\n) -> io::Result<()> {\n    symlink_junction_inner(original.as_ref(), junction.as_ref())\n}\n\n// Creating a directory junction on windows involves dealing with reparse\n// points and the DeviceIoControl function, and this code is a skeleton of\n// what can be found here:\n//\n// http://www.flexhex.com/docs/articles/hard-links.phtml\n#[allow(dead_code)]\nfn symlink_junction_inner(original: &Path, junction: &Path) -> io::Result<()> {\n    let d = DirBuilder::new();\n    d.mkdir(&junction)?;\n\n    let mut opts = OpenOptions::new();\n    opts.write(true);\n    opts.custom_flags(c::FILE_FLAG_OPEN_REPARSE_POINT | c::FILE_FLAG_BACKUP_SEMANTICS);\n    let f = File::open(junction, &opts)?;\n    let h = f.handle().raw();\n\n    unsafe {\n        let mut data = [0u8; c::MAXIMUM_REPARSE_DATA_BUFFER_SIZE];\n        let db = data.as_mut_ptr() as *mut c::REPARSE_MOUNTPOINT_DATA_BUFFER;\n        let buf = &mut (*db).ReparseTarget as *mut c::WCHAR;\n        let mut i = 0;\n        // FIXME: this conversion is very hacky\n        let v = br\"\\??\\\";\n        let v = v.iter().map(|x| *x as u16);\n        for c in v.chain(original.as_os_str().encode_wide()) {\n            *buf.offset(i) = c;\n            i += 1;\n        }\n        *buf.offset(i) = 0;\n        i += 1;\n        (*db).ReparseTag = c::IO_REPARSE_TAG_MOUNT_POINT;\n        (*db).ReparseTargetMaximumLength = (i * 2) as c::WORD;\n        (*db).ReparseTargetLength = ((i - 1) * 2) as c::WORD;\n        (*db).ReparseDataLength = (*db).ReparseTargetLength as c::DWORD + 12;\n\n        let mut ret = 0;\n        cvt(c::DeviceIoControl(\n            h as *mut _,\n            c::FSCTL_SET_REPARSE_POINT,\n            data.as_ptr() as *mut _,\n            (*db).ReparseDataLength + 8,\n            ptr::null_mut(),\n            0,\n            &mut ret,\n            ptr::null_mut(),\n        ))\n        .map(drop)\n    }\n}\n\n// Try to see if a file exists but, unlike `exists`, report I/O errors.\npub fn try_exists(path: &Path) -> io::Result<bool> {\n    // Open the file to ensure any symlinks are followed to their target.\n    let mut opts = OpenOptions::new();\n    // No read, write, etc access rights are needed.\n    opts.access_mode(0);\n    // Backup semantics enables opening directories as well as files.\n    opts.custom_flags(c::FILE_FLAG_BACKUP_SEMANTICS);\n    match File::open(path, &opts) {\n        Err(e) => match e.kind() {\n            // The file definitely does not exist\n            io::ErrorKind::NotFound => Ok(false),\n\n            // `ERROR_SHARING_VIOLATION` means that the file has been locked by\n            // another process. This is often temporary so we simply report it\n            // as the file existing.\n            io::ErrorKind::Other if e.raw_os_error() == Some(c::ERROR_SHARING_VIOLATION as i32) => {\n                Ok(true)\n            }\n            // Other errors such as `ERROR_ACCESS_DENIED` may indicate that the\n            // file exists. However, these types of errors are usually more\n            // permanent so we report them here.\n            _ => Err(e),\n        },\n        // The file was opened successfully therefore it must exist,\n        Ok(_) => Ok(true),\n    }\n}\n"],[2390,"/// The underlying OsString/OsStr implementation on Windows is a\n/// wrapper around the \"WTF-8\" encoding; see the `wtf8` module for more.\nuse crate::borrow::Cow;\nuse crate::fmt;\nuse crate::mem;\nuse crate::rc::Rc;\nuse crate::sync::Arc;\nuse crate::sys_common::wtf8::{Wtf8, Wtf8Buf};\nuse crate::sys_common::{AsInner, FromInner, IntoInner};\n\n#[derive(Clone, Hash)]\npub struct Buf {\n    pub inner: Wtf8Buf,\n}\n\nimpl IntoInner<Wtf8Buf> for Buf {\n    fn into_inner(self) -> Wtf8Buf {\n        self.inner\n    }\n}\n\nimpl FromInner<Wtf8Buf> for Buf {\n    fn from_inner(inner: Wtf8Buf) -> Self {\n        Buf { inner }\n    }\n}\n\nimpl AsInner<Wtf8> for Buf {\n    fn as_inner(&self) -> &Wtf8 {\n        &self.inner\n    }\n}\n\nimpl fmt::Debug for Buf {\n    fn fmt(&self, formatter: &mut fmt::Formatter<'_>) -> fmt::Result {\n        fmt::Debug::fmt(self.as_slice(), formatter)\n    }\n}\n\nimpl fmt::Display for Buf {\n    fn fmt(&self, formatter: &mut fmt::Formatter<'_>) -> fmt::Result {\n        fmt::Display::fmt(self.as_slice(), formatter)\n    }\n}\n\npub struct Slice {\n    pub inner: Wtf8,\n}\n\nimpl fmt::Debug for Slice {\n    fn fmt(&self, formatter: &mut fmt::Formatter<'_>) -> fmt::Result {\n        fmt::Debug::fmt(&self.inner, formatter)\n    }\n}\n\nimpl fmt::Display for Slice {\n    fn fmt(&self, formatter: &mut fmt::Formatter<'_>) -> fmt::Result {\n        fmt::Display::fmt(&self.inner, formatter)\n    }\n}\n\nimpl Buf {\n    pub fn with_capacity(capacity: usize) -> Buf {\n        Buf { inner: Wtf8Buf::with_capacity(capacity) }\n    }\n\n    pub fn clear(&mut self) {\n        self.inner.clear()\n    }\n\n    pub fn capacity(&self) -> usize {\n        self.inner.capacity()\n    }\n\n    pub fn from_string(s: String) -> Buf {\n        Buf { inner: Wtf8Buf::from_string(s) }\n    }\n\n    pub fn as_slice(&self) -> &Slice {\n        // SAFETY: Slice is just a wrapper for Wtf8,\n        // and self.inner.as_slice() returns &Wtf8.\n        // Therefore, transmuting &Wtf8 to &Slice is safe.\n        unsafe { mem::transmute(self.inner.as_slice()) }\n    }\n\n    pub fn as_mut_slice(&mut self) -> &mut Slice {\n        // SAFETY: Slice is just a wrapper for Wtf8,\n        // and self.inner.as_mut_slice() returns &mut Wtf8.\n        // Therefore, transmuting &mut Wtf8 to &mut Slice is safe.\n        // Additionally, care should be taken to ensure the slice\n        // is always valid Wtf8.\n        unsafe { mem::transmute(self.inner.as_mut_slice()) }\n    }\n\n    pub fn into_string(self) -> Result<String, Buf> {\n        self.inner.into_string().map_err(|buf| Buf { inner: buf })\n    }\n\n    pub fn push_slice(&mut self, s: &Slice) {\n        self.inner.push_wtf8(&s.inner)\n    }\n\n    pub fn reserve(&mut self, additional: usize) {\n        self.inner.reserve(additional)\n    }\n\n    pub fn reserve_exact(&mut self, additional: usize) {\n        self.inner.reserve_exact(additional)\n    }\n\n    pub fn shrink_to_fit(&mut self) {\n        self.inner.shrink_to_fit()\n    }\n\n    #[inline]\n    pub fn shrink_to(&mut self, min_capacity: usize) {\n        self.inner.shrink_to(min_capacity)\n    }\n\n    #[inline]\n    pub fn into_box(self) -> Box<Slice> {\n        unsafe { mem::transmute(self.inner.into_box()) }\n    }\n\n    #[inline]\n    pub fn from_box(boxed: Box<Slice>) -> Buf {\n        let inner: Box<Wtf8> = unsafe { mem::transmute(boxed) };\n        Buf { inner: Wtf8Buf::from_box(inner) }\n    }\n\n    #[inline]\n    pub fn into_arc(&self) -> Arc<Slice> {\n        self.as_slice().into_arc()\n    }\n\n    #[inline]\n    pub fn into_rc(&self) -> Rc<Slice> {\n        self.as_slice().into_rc()\n    }\n}\n\nimpl Slice {\n    #[inline]\n    pub fn from_str(s: &str) -> &Slice {\n        unsafe { mem::transmute(Wtf8::from_str(s)) }\n    }\n\n    pub fn to_str(&self) -> Option<&str> {\n        self.inner.as_str()\n    }\n\n    pub fn to_string_lossy(&self) -> Cow<'_, str> {\n        self.inner.to_string_lossy()\n    }\n\n    pub fn to_owned(&self) -> Buf {\n        let mut buf = Wtf8Buf::with_capacity(self.inner.len());\n        buf.push_wtf8(&self.inner);\n        Buf { inner: buf }\n    }\n\n    pub fn clone_into(&self, buf: &mut Buf) {\n        self.inner.clone_into(&mut buf.inner)\n    }\n\n    #[inline]\n    pub fn into_box(&self) -> Box<Slice> {\n        unsafe { mem::transmute(self.inner.into_box()) }\n    }\n\n    pub fn empty_box() -> Box<Slice> {\n        unsafe { mem::transmute(Wtf8::empty_box()) }\n    }\n\n    #[inline]\n    pub fn into_arc(&self) -> Arc<Slice> {\n        let arc = self.inner.into_arc();\n        unsafe { Arc::from_raw(Arc::into_raw(arc) as *const Slice) }\n    }\n\n    #[inline]\n    pub fn into_rc(&self) -> Rc<Slice> {\n        let rc = self.inner.into_rc();\n        unsafe { Rc::from_raw(Rc::into_raw(rc) as *const Slice) }\n    }\n\n    #[inline]\n    pub fn make_ascii_lowercase(&mut self) {\n        self.inner.make_ascii_lowercase()\n    }\n\n    #[inline]\n    pub fn make_ascii_uppercase(&mut self) {\n        self.inner.make_ascii_uppercase()\n    }\n\n    #[inline]\n    pub fn to_ascii_lowercase(&self) -> Buf {\n        Buf { inner: self.inner.to_ascii_lowercase() }\n    }\n\n    #[inline]\n    pub fn to_ascii_uppercase(&self) -> Buf {\n        Buf { inner: self.inner.to_ascii_uppercase() }\n    }\n\n    #[inline]\n    pub fn is_ascii(&self) -> bool {\n        self.inner.is_ascii()\n    }\n\n    #[inline]\n    pub fn eq_ignore_ascii_case(&self, other: &Self) -> bool {\n        self.inner.eq_ignore_ascii_case(&other.inner)\n    }\n}\n"],[2391,"use crate::ffi::OsStr;\nuse crate::mem;\nuse crate::path::Prefix;\n\n#[cfg(test)]\nmod tests;\n\npub const MAIN_SEP_STR: &str = \"\\\\\";\npub const MAIN_SEP: char = '\\\\';\n\n/// # Safety\n///\n/// `bytes` must be a valid wtf8 encoded slice\n#[inline]\nunsafe fn bytes_as_os_str(bytes: &[u8]) -> &OsStr {\n    // &OsStr is layout compatible with &Slice, which is compatible with &Wtf8,\n    // which is compatible with &[u8].\n    mem::transmute(bytes)\n}\n\n#[inline]\npub fn is_sep_byte(b: u8) -> bool {\n    b == b'/' || b == b'\\\\'\n}\n\n#[inline]\npub fn is_verbatim_sep(b: u8) -> bool {\n    b == b'\\\\'\n}\n\npub fn parse_prefix(path: &OsStr) -> Option<Prefix<'_>> {\n    use Prefix::{DeviceNS, Disk, Verbatim, VerbatimDisk, VerbatimUNC, UNC};\n\n    if let Some(path) = strip_prefix(path, r\"\\\\\") {\n        // \\\\\n        if let Some(path) = strip_prefix(path, r\"?\\\") {\n            // \\\\?\\\n            if let Some(path) = strip_prefix(path, r\"UNC\\\") {\n                // \\\\?\\UNC\\server\\share\n\n                let (server, path) = parse_next_component(path, true);\n                let (share, _) = parse_next_component(path, true);\n\n                Some(VerbatimUNC(server, share))\n            } else {\n                let (prefix, _) = parse_next_component(path, true);\n\n                // in verbatim paths only recognize an exact drive prefix\n                if let Some(drive) = parse_drive_exact(prefix) {\n                    // \\\\?\\C:\n                    Some(VerbatimDisk(drive))\n                } else {\n                    // \\\\?\\prefix\n                    Some(Verbatim(prefix))\n                }\n            }\n        } else if let Some(path) = strip_prefix(path, r\".\\\") {\n            // \\\\.\\COM42\n            let (prefix, _) = parse_next_component(path, false);\n            Some(DeviceNS(prefix))\n        } else {\n            let (server, path) = parse_next_component(path, false);\n            let (share, _) = parse_next_component(path, false);\n\n            if !server.is_empty() && !share.is_empty() {\n                // \\\\server\\share\n                Some(UNC(server, share))\n            } else {\n                // no valid prefix beginning with \"\\\\\" recognized\n                None\n            }\n        }\n    } else if let Some(drive) = parse_drive(path) {\n        // C:\n        Some(Disk(drive))\n    } else {\n        // no prefix\n        None\n    }\n}\n\n// Parses a drive prefix, e.g. \"C:\" and \"C:\\whatever\"\nfn parse_drive(prefix: &OsStr) -> Option<u8> {\n    // In most DOS systems, it is not possible to have more than 26 drive letters.\n    // See <https://en.wikipedia.org/wiki/Drive_letter_assignment#Common_assignments>.\n    fn is_valid_drive_letter(drive: &u8) -> bool {\n        drive.is_ascii_alphabetic()\n    }\n\n    match prefix.bytes() {\n        [drive, b':', ..] if is_valid_drive_letter(drive) => Some(drive.to_ascii_uppercase()),\n        _ => None,\n    }\n}\n\n// Parses a drive prefix exactly, e.g. \"C:\"\nfn parse_drive_exact(prefix: &OsStr) -> Option<u8> {\n    // only parse two bytes: the drive letter and the drive separator\n    if prefix.len() == 2 { parse_drive(prefix) } else { None }\n}\n\nfn strip_prefix<'a>(path: &'a OsStr, prefix: &str) -> Option<&'a OsStr> {\n    // `path` and `prefix` are valid wtf8 and utf8 encoded slices respectively, `path[prefix.len()]`\n    // is thus a code point boundary and `path[prefix.len()..]` is a valid wtf8 encoded slice.\n    match path.bytes().strip_prefix(prefix.as_bytes()) {\n        Some(path) => unsafe { Some(bytes_as_os_str(path)) },\n        None => None,\n    }\n}\n\n// Parse the next path component.\n//\n// Returns the next component and the rest of the path excluding the component and separator.\n// Does not recognize `/` as a separator character if `verbatim` is true.\nfn parse_next_component(path: &OsStr, verbatim: bool) -> (&OsStr, &OsStr) {\n    let separator = if verbatim { is_verbatim_sep } else { is_sep_byte };\n\n    match path.bytes().iter().position(|&x| separator(x)) {\n        Some(separator_start) => {\n            let mut separator_end = separator_start + 1;\n\n            // a series of multiple separator characters is treated as a single separator,\n            // except in verbatim paths\n            while !verbatim && separator_end < path.len() && separator(path.bytes()[separator_end])\n            {\n                separator_end += 1;\n            }\n\n            let component = &path.bytes()[..separator_start];\n\n            // Panic safe\n            // The max `separator_end` is `bytes.len()` and `bytes[bytes.len()..]` is a valid index.\n            let path = &path.bytes()[separator_end..];\n\n            // SAFETY: `path` is a valid wtf8 encoded slice and each of the separators ('/', '\\')\n            // is encoded in a single byte, therefore `bytes[separator_start]` and\n            // `bytes[separator_end]` must be code point boundaries and thus\n            // `bytes[..separator_start]` and `bytes[separator_end..]` are valid wtf8 slices.\n            unsafe { (bytes_as_os_str(component), bytes_as_os_str(path)) }\n        }\n        None => (path, OsStr::new(\"\")),\n    }\n}\n"],[2392,"use crate::cell::UnsafeCell;\nuse crate::sys::c;\n\npub struct RWLock {\n    inner: UnsafeCell<c::SRWLOCK>,\n}\n\npub type MovableRWLock = RWLock;\n\nunsafe impl Send for RWLock {}\nunsafe impl Sync for RWLock {}\n\nimpl RWLock {\n    pub const fn new() -> RWLock {\n        RWLock { inner: UnsafeCell::new(c::SRWLOCK_INIT) }\n    }\n    #[inline]\n    pub unsafe fn read(&self) {\n        c::AcquireSRWLockShared(self.inner.get())\n    }\n    #[inline]\n    pub unsafe fn try_read(&self) -> bool {\n        c::TryAcquireSRWLockShared(self.inner.get()) != 0\n    }\n    #[inline]\n    pub unsafe fn write(&self) {\n        c::AcquireSRWLockExclusive(self.inner.get())\n    }\n    #[inline]\n    pub unsafe fn try_write(&self) -> bool {\n        c::TryAcquireSRWLockExclusive(self.inner.get()) != 0\n    }\n    #[inline]\n    pub unsafe fn read_unlock(&self) {\n        c::ReleaseSRWLockShared(self.inner.get())\n    }\n    #[inline]\n    pub unsafe fn write_unlock(&self) {\n        c::ReleaseSRWLockExclusive(self.inner.get())\n    }\n\n    #[inline]\n    pub unsafe fn destroy(&self) {\n        // ...\n    }\n}\n"],[2393,"use crate::alloc::{GlobalAlloc, Layout, System};\nuse crate::cmp;\nuse crate::ptr;\n\n// The minimum alignment guaranteed by the architecture. This value is used to\n// add fast paths for low alignment values.\n#[cfg(all(any(\n    target_arch = \"x86\",\n    target_arch = \"arm\",\n    target_arch = \"mips\",\n    target_arch = \"powerpc\",\n    target_arch = \"powerpc64\",\n    target_arch = \"sparc\",\n    target_arch = \"asmjs\",\n    target_arch = \"wasm32\",\n    target_arch = \"hexagon\",\n    target_arch = \"riscv32\"\n)))]\npub const MIN_ALIGN: usize = 8;\n#[cfg(all(any(\n    target_arch = \"x86_64\",\n    target_arch = \"aarch64\",\n    target_arch = \"mips64\",\n    target_arch = \"s390x\",\n    target_arch = \"sparc64\",\n    target_arch = \"riscv64\"\n)))]\npub const MIN_ALIGN: usize = 16;\n\npub unsafe fn realloc_fallback(\n    alloc: &System,\n    ptr: *mut u8,\n    old_layout: Layout,\n    new_size: usize,\n) -> *mut u8 {\n    // Docs for GlobalAlloc::realloc require this to be valid:\n    let new_layout = Layout::from_size_align_unchecked(new_size, old_layout.align());\n\n    let new_ptr = GlobalAlloc::alloc(alloc, new_layout);\n    if !new_ptr.is_null() {\n        let size = cmp::min(old_layout.size(), new_size);\n        ptr::copy_nonoverlapping(ptr, new_ptr, size);\n        GlobalAlloc::dealloc(alloc, ptr, old_layout);\n    }\n    new_ptr\n}\n"],[2394,"// This module contains code that is shared between all platforms, mostly utility or fallback code.\n// This explicitly does not include code that is shared between only a few platforms,\n// such as when reusing an implementation from `unix` or `unsupported`.\n// In those cases the desired code should be included directly using the #[path] attribute,\n// not moved to this module.\n//\n// Currently `sys_common` contains a lot of code that should live in this module,\n// ideally `sys_common` would only contain platform-independent abstractions on top of `sys`.\n// Progress on this is tracked in #84187.\n\n#![allow(dead_code)]\n\npub mod alloc;\n"],[2395,"use super::*;\nuse crate::fmt::{Debug, Formatter, Result};\n\n#[test]\nfn smoke() {\n    struct Helper<'a>(&'a [u8]);\n\n    impl Debug for Helper<'_> {\n        fn fmt(&self, f: &mut Formatter<'_>) -> Result {\n            debug_fmt_bytestring(self.0, f)\n        }\n    }\n\n    let input = b\"\\xF0hello,\\tworld\";\n    let expected = r#\"\"\\xF0hello,\\tworld\"\"#;\n    let output = format!(\"{:?}\", Helper(input));\n\n    assert!(output == expected);\n}\n"],[2396,"// Original implementation taken from rust-memchr.\n// Copyright 2015 Andrew Gallant, bluss and Nicolas Koch\n\n// test the implementations for the current platform\nuse super::{memchr, memrchr};\n\n#[test]\nfn matches_one() {\n    assert_eq!(Some(0), memchr(b'a', b\"a\"));\n}\n\n#[test]\nfn matches_begin() {\n    assert_eq!(Some(0), memchr(b'a', b\"aaaa\"));\n}\n\n#[test]\nfn matches_end() {\n    assert_eq!(Some(4), memchr(b'z', b\"aaaaz\"));\n}\n\n#[test]\nfn matches_nul() {\n    assert_eq!(Some(4), memchr(b'\\x00', b\"aaaa\\x00\"));\n}\n\n#[test]\nfn matches_past_nul() {\n    assert_eq!(Some(5), memchr(b'z', b\"aaaa\\x00z\"));\n}\n\n#[test]\nfn no_match_empty() {\n    assert_eq!(None, memchr(b'a', b\"\"));\n}\n\n#[test]\nfn no_match() {\n    assert_eq!(None, memchr(b'a', b\"xyz\"));\n}\n\n#[test]\nfn matches_one_reversed() {\n    assert_eq!(Some(0), memrchr(b'a', b\"a\"));\n}\n\n#[test]\nfn matches_begin_reversed() {\n    assert_eq!(Some(3), memrchr(b'a', b\"aaaa\"));\n}\n\n#[test]\nfn matches_end_reversed() {\n    assert_eq!(Some(0), memrchr(b'z', b\"zaaaa\"));\n}\n\n#[test]\nfn matches_nul_reversed() {\n    assert_eq!(Some(4), memrchr(b'\\x00', b\"aaaa\\x00\"));\n}\n\n#[test]\nfn matches_past_nul_reversed() {\n    assert_eq!(Some(0), memrchr(b'z', b\"z\\x00aaaa\"));\n}\n\n#[test]\nfn no_match_empty_reversed() {\n    assert_eq!(None, memrchr(b'a', b\"\"));\n}\n\n#[test]\nfn no_match_reversed() {\n    assert_eq!(None, memrchr(b'a', b\"xyz\"));\n}\n\n#[test]\nfn each_alignment() {\n    let mut data = [1u8; 64];\n    let needle = 2;\n    let pos = 40;\n    data[pos] = needle;\n    for start in 0..16 {\n        assert_eq!(Some(pos - start), memchr(needle, &data[start..]));\n    }\n}\n"],[2397,"use crate::sync::atomic::{AtomicUsize, Ordering};\nuse crate::sys::mutex as mutex_imp;\nuse crate::sys_common::mutex::MovableMutex;\n\npub trait CondvarCheck {\n    type Check;\n}\n\n/// For boxed mutexes, a `Condvar` will check it's only ever used with the same\n/// mutex, based on its (stable) address.\nimpl CondvarCheck for Box<mutex_imp::Mutex> {\n    type Check = SameMutexCheck;\n}\n\npub struct SameMutexCheck {\n    addr: AtomicUsize,\n}\n\n#[allow(dead_code)]\nimpl SameMutexCheck {\n    pub const fn new() -> Self {\n        Self { addr: AtomicUsize::new(0) }\n    }\n    pub fn verify(&self, mutex: &MovableMutex) {\n        let addr = mutex.raw() as *const mutex_imp::Mutex as usize;\n        match self.addr.compare_exchange(0, addr, Ordering::SeqCst, Ordering::SeqCst) {\n            Ok(_) => {}               // Stored the address\n            Err(n) if n == addr => {} // Lost a race to store the same address\n            _ => panic!(\"attempted to use a condition variable with two mutexes\"),\n        }\n    }\n}\n\n/// Unboxed mutexes may move, so `Condvar` can not require its address to stay\n/// constant.\nimpl CondvarCheck for mutex_imp::Mutex {\n    type Check = NoCheck;\n}\n\npub struct NoCheck;\n\n#[allow(dead_code)]\nimpl NoCheck {\n    pub const fn new() -> Self {\n        Self\n    }\n    pub fn verify(&self, _: &MovableMutex) {}\n}\n"],[2398,"pub const DEFAULT_BUF_SIZE: usize = 8 * 1024;\n\n#[cfg(test)]\n#[allow(dead_code)] // not used on emscripten\npub mod test {\n    use crate::env;\n    use crate::fs;\n    use crate::path::{Path, PathBuf};\n    use rand::RngCore;\n\n    pub struct TempDir(PathBuf);\n\n    impl TempDir {\n        pub fn join(&self, path: &str) -> PathBuf {\n            let TempDir(ref p) = *self;\n            p.join(path)\n        }\n\n        pub fn path(&self) -> &Path {\n            let TempDir(ref p) = *self;\n            p\n        }\n    }\n\n    impl Drop for TempDir {\n        fn drop(&mut self) {\n            // Gee, seeing how we're testing the fs module I sure hope that we\n            // at least implement this correctly!\n            let TempDir(ref p) = *self;\n            fs::remove_dir_all(p).unwrap();\n        }\n    }\n\n    pub fn tmpdir() -> TempDir {\n        let p = env::temp_dir();\n        let mut r = rand::thread_rng();\n        let ret = p.join(&format!(\"rust-{}\", r.next_u32()));\n        fs::create_dir(&ret).unwrap();\n        TempDir(ret)\n    }\n}\n"],[2399,"use crate::boxed::Box;\nuse crate::cell::RefCell;\nuse crate::pin::Pin;\nuse crate::sync::Arc;\nuse crate::sys_common::remutex::{ReentrantMutex, ReentrantMutexGuard};\nuse crate::thread;\n\n#[test]\nfn smoke() {\n    let m = unsafe {\n        let mut m = Box::pin(ReentrantMutex::new(()));\n        m.as_mut().init();\n        m\n    };\n    let m = m.as_ref();\n    {\n        let a = m.lock();\n        {\n            let b = m.lock();\n            {\n                let c = m.lock();\n                assert_eq!(*c, ());\n            }\n            assert_eq!(*b, ());\n        }\n        assert_eq!(*a, ());\n    }\n}\n\n#[test]\nfn is_mutex() {\n    let m = unsafe {\n        // FIXME: Simplify this if Arc gets a Arc::get_pin_mut.\n        let mut m = Arc::new(ReentrantMutex::new(RefCell::new(0)));\n        Pin::new_unchecked(Arc::get_mut_unchecked(&mut m)).init();\n        Pin::new_unchecked(m)\n    };\n    let m2 = m.clone();\n    let lock = m.as_ref().lock();\n    let child = thread::spawn(move || {\n        let lock = m2.as_ref().lock();\n        assert_eq!(*lock.borrow(), 4950);\n    });\n    for i in 0..100 {\n        let lock = m.as_ref().lock();\n        *lock.borrow_mut() += i;\n    }\n    drop(lock);\n    child.join().unwrap();\n}\n\n#[test]\nfn trylock_works() {\n    let m = unsafe {\n        // FIXME: Simplify this if Arc gets a Arc::get_pin_mut.\n        let mut m = Arc::new(ReentrantMutex::new(()));\n        Pin::new_unchecked(Arc::get_mut_unchecked(&mut m)).init();\n        Pin::new_unchecked(m)\n    };\n    let m2 = m.clone();\n    let _lock = m.as_ref().try_lock();\n    let _lock2 = m.as_ref().try_lock();\n    thread::spawn(move || {\n        let lock = m2.as_ref().try_lock();\n        assert!(lock.is_none());\n    })\n    .join()\n    .unwrap();\n    let _lock3 = m.as_ref().try_lock();\n}\n\npub struct Answer<'a>(pub ReentrantMutexGuard<'a, RefCell<u32>>);\nimpl Drop for Answer<'_> {\n    fn drop(&mut self) {\n        *self.0.borrow_mut() = 42;\n    }\n}\n"],[2400,"use crate::sys::mutex as imp;\n\n/// An OS-based mutual exclusion lock, meant for use in static variables.\n///\n/// This mutex has a const constructor ([`StaticMutex::new`]), does not\n/// implement `Drop` to cleanup resources, and causes UB when used reentrantly.\n///\n/// This mutex does not implement poisoning.\n///\n/// This is a wrapper around `imp::Mutex` that does *not* call `init()` and\n/// `destroy()`.\npub struct StaticMutex(imp::Mutex);\n\nunsafe impl Sync for StaticMutex {}\n\nimpl StaticMutex {\n    /// Creates a new mutex for use.\n    pub const fn new() -> Self {\n        Self(imp::Mutex::new())\n    }\n\n    /// Calls raw_lock() and then returns an RAII guard to guarantee the mutex\n    /// will be unlocked.\n    ///\n    /// It is undefined behaviour to call this function while locked by the\n    /// same thread.\n    #[inline]\n    pub unsafe fn lock(&'static self) -> StaticMutexGuard {\n        self.0.lock();\n        StaticMutexGuard(&self.0)\n    }\n}\n\n#[must_use]\npub struct StaticMutexGuard(&'static imp::Mutex);\n\nimpl Drop for StaticMutexGuard {\n    #[inline]\n    fn drop(&mut self) {\n        unsafe {\n            self.0.unlock();\n        }\n    }\n}\n\n/// An OS-based mutual exclusion lock.\n///\n/// This mutex does *not* have a const constructor, cleans up its resources in\n/// its `Drop` implementation, may safely be moved (when not borrowed), and\n/// does not cause UB when used reentrantly.\n///\n/// This mutex does not implement poisoning.\n///\n/// This is either a wrapper around `Box<imp::Mutex>` or `imp::Mutex`,\n/// depending on the platform. It is boxed on platforms where `imp::Mutex` may\n/// not be moved.\npub struct MovableMutex(imp::MovableMutex);\n\nunsafe impl Sync for MovableMutex {}\n\nimpl MovableMutex {\n    /// Creates a new mutex.\n    pub fn new() -> Self {\n        let mut mutex = imp::MovableMutex::from(imp::Mutex::new());\n        unsafe { mutex.init() };\n        Self(mutex)\n    }\n\n    pub(super) fn raw(&self) -> &imp::Mutex {\n        &self.0\n    }\n\n    /// Locks the mutex blocking the current thread until it is available.\n    #[inline]\n    pub fn raw_lock(&self) {\n        unsafe { self.0.lock() }\n    }\n\n    /// Attempts to lock the mutex without blocking, returning whether it was\n    /// successfully acquired or not.\n    #[inline]\n    pub fn try_lock(&self) -> bool {\n        unsafe { self.0.try_lock() }\n    }\n\n    /// Unlocks the mutex.\n    ///\n    /// Behavior is undefined if the current thread does not actually hold the\n    /// mutex.\n    #[inline]\n    pub unsafe fn raw_unlock(&self) {\n        self.0.unlock()\n    }\n}\n\nimpl Drop for MovableMutex {\n    fn drop(&mut self) {\n        unsafe { self.0.destroy() };\n    }\n}\n"],[2401,"cfg_if::cfg_if! {\n    if #[cfg(any(\n        target_os = \"linux\",\n        target_os = \"android\",\n        all(target_arch = \"wasm32\", target_feature = \"atomics\"),\n    ))] {\n        mod futex;\n        pub use futex::Parker;\n    } else if #[cfg(windows)] {\n        pub use crate::sys::thread_parker::Parker;\n    } else {\n        mod generic;\n        pub use generic::Parker;\n    }\n}\n"],[2402,"use crate::sync::atomic::AtomicI32;\nuse crate::sync::atomic::Ordering::{Acquire, Release};\nuse crate::sys::futex::{futex_wait, futex_wake};\nuse crate::time::Duration;\n\nconst PARKED: i32 = -1;\nconst EMPTY: i32 = 0;\nconst NOTIFIED: i32 = 1;\n\npub struct Parker {\n    state: AtomicI32,\n}\n\n// Notes about memory ordering:\n//\n// Memory ordering is only relevant for the relative ordering of operations\n// between different variables. Even Ordering::Relaxed guarantees a\n// monotonic/consistent order when looking at just a single atomic variable.\n//\n// So, since this parker is just a single atomic variable, we only need to look\n// at the ordering guarantees we need to provide to the 'outside world'.\n//\n// The only memory ordering guarantee that parking and unparking provide, is\n// that things which happened before unpark() are visible on the thread\n// returning from park() afterwards. Otherwise, it was effectively unparked\n// before unpark() was called while still consuming the 'token'.\n//\n// In other words, unpark() needs to synchronize with the part of park() that\n// consumes the token and returns.\n//\n// This is done with a release-acquire synchronization, by using\n// Ordering::Release when writing NOTIFIED (the 'token') in unpark(), and using\n// Ordering::Acquire when checking for this state in park().\nimpl Parker {\n    #[inline]\n    pub const fn new() -> Self {\n        Parker { state: AtomicI32::new(EMPTY) }\n    }\n\n    // Assumes this is only called by the thread that owns the Parker,\n    // which means that `self.state != PARKED`.\n    pub unsafe fn park(&self) {\n        // Change NOTIFIED=>EMPTY or EMPTY=>PARKED, and directly return in the\n        // first case.\n        if self.state.fetch_sub(1, Acquire) == NOTIFIED {\n            return;\n        }\n        loop {\n            // Wait for something to happen, assuming it's still set to PARKED.\n            futex_wait(&self.state, PARKED, None);\n            // Change NOTIFIED=>EMPTY and return in that case.\n            if self.state.compare_exchange(NOTIFIED, EMPTY, Acquire, Acquire).is_ok() {\n                return;\n            } else {\n                // Spurious wake up. We loop to try again.\n            }\n        }\n    }\n\n    // Assumes this is only called by the thread that owns the Parker,\n    // which means that `self.state != PARKED`.\n    pub unsafe fn park_timeout(&self, timeout: Duration) {\n        // Change NOTIFIED=>EMPTY or EMPTY=>PARKED, and directly return in the\n        // first case.\n        if self.state.fetch_sub(1, Acquire) == NOTIFIED {\n            return;\n        }\n        // Wait for something to happen, assuming it's still set to PARKED.\n        futex_wait(&self.state, PARKED, Some(timeout));\n        // This is not just a store, because we need to establish a\n        // release-acquire ordering with unpark().\n        if self.state.swap(EMPTY, Acquire) == NOTIFIED {\n            // Woke up because of unpark().\n        } else {\n            // Timeout or spurious wake up.\n            // We return either way, because we can't easily tell if it was the\n            // timeout or not.\n        }\n    }\n\n    #[inline]\n    pub fn unpark(&self) {\n        // Change PARKED=>NOTIFIED, EMPTY=>NOTIFIED, or NOTIFIED=>NOTIFIED, and\n        // wake the thread in the first case.\n        //\n        // Note that even NOTIFIED=>NOTIFIED results in a write. This is on\n        // purpose, to make sure every unpark() has a release-acquire ordering\n        // with park().\n        if self.state.swap(NOTIFIED, Release) == PARKED {\n            futex_wake(&self.state);\n        }\n    }\n}\n"],[2403,"//! Parker implementaiton based on a Mutex and Condvar.\n\nuse crate::sync::atomic::AtomicUsize;\nuse crate::sync::atomic::Ordering::SeqCst;\nuse crate::sync::{Condvar, Mutex};\nuse crate::time::Duration;\n\nconst EMPTY: usize = 0;\nconst PARKED: usize = 1;\nconst NOTIFIED: usize = 2;\n\npub struct Parker {\n    state: AtomicUsize,\n    lock: Mutex<()>,\n    cvar: Condvar,\n}\n\nimpl Parker {\n    pub fn new() -> Self {\n        Parker { state: AtomicUsize::new(EMPTY), lock: Mutex::new(()), cvar: Condvar::new() }\n    }\n\n    // This implementaiton doesn't require `unsafe`, but other implementations\n    // may assume this is only called by the thread that owns the Parker.\n    pub unsafe fn park(&self) {\n        // If we were previously notified then we consume this notification and\n        // return quickly.\n        if self.state.compare_exchange(NOTIFIED, EMPTY, SeqCst, SeqCst).is_ok() {\n            return;\n        }\n\n        // Otherwise we need to coordinate going to sleep\n        let mut m = self.lock.lock().unwrap();\n        match self.state.compare_exchange(EMPTY, PARKED, SeqCst, SeqCst) {\n            Ok(_) => {}\n            Err(NOTIFIED) => {\n                // We must read here, even though we know it will be `NOTIFIED`.\n                // This is because `unpark` may have been called again since we read\n                // `NOTIFIED` in the `compare_exchange` above. We must perform an\n                // acquire operation that synchronizes with that `unpark` to observe\n                // any writes it made before the call to unpark. To do that we must\n                // read from the write it made to `state`.\n                let old = self.state.swap(EMPTY, SeqCst);\n                assert_eq!(old, NOTIFIED, \"park state changed unexpectedly\");\n                return;\n            } // should consume this notification, so prohibit spurious wakeups in next park.\n            Err(_) => panic!(\"inconsistent park state\"),\n        }\n        loop {\n            m = self.cvar.wait(m).unwrap();\n            match self.state.compare_exchange(NOTIFIED, EMPTY, SeqCst, SeqCst) {\n                Ok(_) => return, // got a notification\n                Err(_) => {}     // spurious wakeup, go back to sleep\n            }\n        }\n    }\n\n    // This implementaiton doesn't require `unsafe`, but other implementations\n    // may assume this is only called by the thread that owns the Parker.\n    pub unsafe fn park_timeout(&self, dur: Duration) {\n        // Like `park` above we have a fast path for an already-notified thread, and\n        // afterwards we start coordinating for a sleep.\n        // return quickly.\n        if self.state.compare_exchange(NOTIFIED, EMPTY, SeqCst, SeqCst).is_ok() {\n            return;\n        }\n        let m = self.lock.lock().unwrap();\n        match self.state.compare_exchange(EMPTY, PARKED, SeqCst, SeqCst) {\n            Ok(_) => {}\n            Err(NOTIFIED) => {\n                // We must read again here, see `park`.\n                let old = self.state.swap(EMPTY, SeqCst);\n                assert_eq!(old, NOTIFIED, \"park state changed unexpectedly\");\n                return;\n            } // should consume this notification, so prohibit spurious wakeups in next park.\n            Err(_) => panic!(\"inconsistent park_timeout state\"),\n        }\n\n        // Wait with a timeout, and if we spuriously wake up or otherwise wake up\n        // from a notification we just want to unconditionally set the state back to\n        // empty, either consuming a notification or un-flagging ourselves as\n        // parked.\n        let (_m, _result) = self.cvar.wait_timeout(m, dur).unwrap();\n        match self.state.swap(EMPTY, SeqCst) {\n            NOTIFIED => {} // got a notification, hurray!\n            PARKED => {}   // no notification, alas\n            n => panic!(\"inconsistent park_timeout state: {}\", n),\n        }\n    }\n\n    pub fn unpark(&self) {\n        // To ensure the unparked thread will observe any writes we made\n        // before this call, we must perform a release operation that `park`\n        // can synchronize with. To do that we must write `NOTIFIED` even if\n        // `state` is already `NOTIFIED`. That is why this must be a swap\n        // rather than a compare-and-swap that returns if it reads `NOTIFIED`\n        // on failure.\n        match self.state.swap(NOTIFIED, SeqCst) {\n            EMPTY => return,    // no one was waiting\n            NOTIFIED => return, // already unparked\n            PARKED => {}        // gotta go wake someone up\n            _ => panic!(\"inconsistent state in unpark\"),\n        }\n\n        // There is a period between when the parked thread sets `state` to\n        // `PARKED` (or last checked `state` in the case of a spurious wake\n        // up) and when it actually waits on `cvar`. If we were to notify\n        // during this period it would be ignored and then when the parked\n        // thread went to sleep it would never wake up. Fortunately, it has\n        // `lock` locked at this stage so we can acquire `lock` to wait until\n        // it is ready to receive the notification.\n        //\n        // Releasing `lock` before the call to `notify_one` means that when the\n        // parked thread wakes it doesn't get woken only to have to wait for us\n        // to release `lock`.\n        drop(self.lock.lock().unwrap());\n        self.cvar.notify_one()\n    }\n}\n"],[2404,"//! Implementation of [the WTF-8 encoding](https://simonsapin.github.io/wtf-8/).\n//!\n//! This library uses Rust’s type system to maintain\n//! [well-formedness](https://simonsapin.github.io/wtf-8/#well-formed),\n//! like the `String` and `&str` types do for UTF-8.\n//!\n//! Since [WTF-8 must not be used\n//! for interchange](https://simonsapin.github.io/wtf-8/#intended-audience),\n//! this library deliberately does not provide access to the underlying bytes\n//! of WTF-8 strings,\n//! nor can it decode WTF-8 from arbitrary bytes.\n//! WTF-8 strings can be obtained from UTF-8, UTF-16, or code points.\n\n// this module is imported from @SimonSapin's repo and has tons of dead code on\n// unix (it's mostly used on windows), so don't worry about dead code here.\n#![allow(dead_code)]\n\n#[cfg(test)]\nmod tests;\n\nuse core::str::next_code_point;\n\nuse crate::borrow::Cow;\nuse crate::char;\nuse crate::fmt;\nuse crate::hash::{Hash, Hasher};\nuse crate::iter::FromIterator;\nuse crate::mem;\nuse crate::ops;\nuse crate::rc::Rc;\nuse crate::slice;\nuse crate::str;\nuse crate::sync::Arc;\nuse crate::sys_common::AsInner;\n\nconst UTF8_REPLACEMENT_CHARACTER: &str = \"\\u{FFFD}\";\n\n/// A Unicode code point: from U+0000 to U+10FFFF.\n///\n/// Compares with the `char` type,\n/// which represents a Unicode scalar value:\n/// a code point that is not a surrogate (U+D800 to U+DFFF).\n#[derive(Eq, PartialEq, Ord, PartialOrd, Clone, Copy)]\npub struct CodePoint {\n    value: u32,\n}\n\n/// Format the code point as `U+` followed by four to six hexadecimal digits.\n/// Example: `U+1F4A9`\nimpl fmt::Debug for CodePoint {\n    #[inline]\n    fn fmt(&self, formatter: &mut fmt::Formatter<'_>) -> fmt::Result {\n        write!(formatter, \"U+{:04X}\", self.value)\n    }\n}\n\nimpl CodePoint {\n    /// Unsafely creates a new `CodePoint` without checking the value.\n    ///\n    /// Only use when `value` is known to be less than or equal to 0x10FFFF.\n    #[inline]\n    pub unsafe fn from_u32_unchecked(value: u32) -> CodePoint {\n        CodePoint { value }\n    }\n\n    /// Creates a new `CodePoint` if the value is a valid code point.\n    ///\n    /// Returns `None` if `value` is above 0x10FFFF.\n    #[inline]\n    pub fn from_u32(value: u32) -> Option<CodePoint> {\n        match value {\n            0..=0x10FFFF => Some(CodePoint { value }),\n            _ => None,\n        }\n    }\n\n    /// Creates a new `CodePoint` from a `char`.\n    ///\n    /// Since all Unicode scalar values are code points, this always succeeds.\n    #[inline]\n    pub fn from_char(value: char) -> CodePoint {\n        CodePoint { value: value as u32 }\n    }\n\n    /// Returns the numeric value of the code point.\n    #[inline]\n    pub fn to_u32(&self) -> u32 {\n        self.value\n    }\n\n    /// Optionally returns a Unicode scalar value for the code point.\n    ///\n    /// Returns `None` if the code point is a surrogate (from U+D800 to U+DFFF).\n    #[inline]\n    pub fn to_char(&self) -> Option<char> {\n        match self.value {\n            0xD800..=0xDFFF => None,\n            _ => Some(unsafe { char::from_u32_unchecked(self.value) }),\n        }\n    }\n\n    /// Returns a Unicode scalar value for the code point.\n    ///\n    /// Returns `'\\u{FFFD}'` (the replacement character “�”)\n    /// if the code point is a surrogate (from U+D800 to U+DFFF).\n    #[inline]\n    pub fn to_char_lossy(&self) -> char {\n        self.to_char().unwrap_or('\\u{FFFD}')\n    }\n}\n\n/// An owned, growable string of well-formed WTF-8 data.\n///\n/// Similar to `String`, but can additionally contain surrogate code points\n/// if they’re not in a surrogate pair.\n#[derive(Eq, PartialEq, Ord, PartialOrd, Clone)]\npub struct Wtf8Buf {\n    bytes: Vec<u8>,\n}\n\nimpl ops::Deref for Wtf8Buf {\n    type Target = Wtf8;\n\n    fn deref(&self) -> &Wtf8 {\n        self.as_slice()\n    }\n}\n\nimpl ops::DerefMut for Wtf8Buf {\n    fn deref_mut(&mut self) -> &mut Wtf8 {\n        self.as_mut_slice()\n    }\n}\n\n/// Format the string with double quotes,\n/// and surrogates as `\\u` followed by four hexadecimal digits.\n/// Example: `\"a\\u{D800}\"` for a string with code points [U+0061, U+D800]\nimpl fmt::Debug for Wtf8Buf {\n    #[inline]\n    fn fmt(&self, formatter: &mut fmt::Formatter<'_>) -> fmt::Result {\n        fmt::Debug::fmt(&**self, formatter)\n    }\n}\n\nimpl Wtf8Buf {\n    /// Creates a new, empty WTF-8 string.\n    #[inline]\n    pub fn new() -> Wtf8Buf {\n        Wtf8Buf { bytes: Vec::new() }\n    }\n\n    /// Creates a new, empty WTF-8 string with pre-allocated capacity for `capacity` bytes.\n    #[inline]\n    pub fn with_capacity(capacity: usize) -> Wtf8Buf {\n        Wtf8Buf { bytes: Vec::with_capacity(capacity) }\n    }\n\n    /// Creates a WTF-8 string from a UTF-8 `String`.\n    ///\n    /// This takes ownership of the `String` and does not copy.\n    ///\n    /// Since WTF-8 is a superset of UTF-8, this always succeeds.\n    #[inline]\n    pub fn from_string(string: String) -> Wtf8Buf {\n        Wtf8Buf { bytes: string.into_bytes() }\n    }\n\n    /// Creates a WTF-8 string from a UTF-8 `&str` slice.\n    ///\n    /// This copies the content of the slice.\n    ///\n    /// Since WTF-8 is a superset of UTF-8, this always succeeds.\n    #[inline]\n    pub fn from_str(str: &str) -> Wtf8Buf {\n        Wtf8Buf { bytes: <[_]>::to_vec(str.as_bytes()) }\n    }\n\n    pub fn clear(&mut self) {\n        self.bytes.clear()\n    }\n\n    /// Creates a WTF-8 string from a potentially ill-formed UTF-16 slice of 16-bit code units.\n    ///\n    /// This is lossless: calling `.encode_wide()` on the resulting string\n    /// will always return the original code units.\n    pub fn from_wide(v: &[u16]) -> Wtf8Buf {\n        let mut string = Wtf8Buf::with_capacity(v.len());\n        for item in char::decode_utf16(v.iter().cloned()) {\n            match item {\n                Ok(ch) => string.push_char(ch),\n                Err(surrogate) => {\n                    let surrogate = surrogate.unpaired_surrogate();\n                    // Surrogates are known to be in the code point range.\n                    let code_point = unsafe { CodePoint::from_u32_unchecked(surrogate as u32) };\n                    // Skip the WTF-8 concatenation check,\n                    // surrogate pairs are already decoded by decode_utf16\n                    string.push_code_point_unchecked(code_point)\n                }\n            }\n        }\n        string\n    }\n\n    /// Copied from String::push\n    /// This does **not** include the WTF-8 concatenation check.\n    fn push_code_point_unchecked(&mut self, code_point: CodePoint) {\n        let mut bytes = [0; 4];\n        let bytes = char::encode_utf8_raw(code_point.value, &mut bytes);\n        self.bytes.extend_from_slice(bytes)\n    }\n\n    #[inline]\n    pub fn as_slice(&self) -> &Wtf8 {\n        unsafe { Wtf8::from_bytes_unchecked(&self.bytes) }\n    }\n\n    #[inline]\n    pub fn as_mut_slice(&mut self) -> &mut Wtf8 {\n        unsafe { Wtf8::from_mut_bytes_unchecked(&mut self.bytes) }\n    }\n\n    /// Reserves capacity for at least `additional` more bytes to be inserted\n    /// in the given `Wtf8Buf`.\n    /// The collection may reserve more space to avoid frequent reallocations.\n    ///\n    /// # Panics\n    ///\n    /// Panics if the new capacity overflows `usize`.\n    #[inline]\n    pub fn reserve(&mut self, additional: usize) {\n        self.bytes.reserve(additional)\n    }\n\n    #[inline]\n    pub fn reserve_exact(&mut self, additional: usize) {\n        self.bytes.reserve_exact(additional)\n    }\n\n    #[inline]\n    pub fn shrink_to_fit(&mut self) {\n        self.bytes.shrink_to_fit()\n    }\n\n    #[inline]\n    pub fn shrink_to(&mut self, min_capacity: usize) {\n        self.bytes.shrink_to(min_capacity)\n    }\n\n    /// Returns the number of bytes that this string buffer can hold without reallocating.\n    #[inline]\n    pub fn capacity(&self) -> usize {\n        self.bytes.capacity()\n    }\n\n    /// Append a UTF-8 slice at the end of the string.\n    #[inline]\n    pub fn push_str(&mut self, other: &str) {\n        self.bytes.extend_from_slice(other.as_bytes())\n    }\n\n    /// Append a WTF-8 slice at the end of the string.\n    ///\n    /// This replaces newly paired surrogates at the boundary\n    /// with a supplementary code point,\n    /// like concatenating ill-formed UTF-16 strings effectively would.\n    #[inline]\n    pub fn push_wtf8(&mut self, other: &Wtf8) {\n        match ((&*self).final_lead_surrogate(), other.initial_trail_surrogate()) {\n            // Replace newly paired surrogates by a supplementary code point.\n            (Some(lead), Some(trail)) => {\n                let len_without_lead_surrogate = self.len() - 3;\n                self.bytes.truncate(len_without_lead_surrogate);\n                let other_without_trail_surrogate = &other.bytes[3..];\n                // 4 bytes for the supplementary code point\n                self.bytes.reserve(4 + other_without_trail_surrogate.len());\n                self.push_char(decode_surrogate_pair(lead, trail));\n                self.bytes.extend_from_slice(other_without_trail_surrogate);\n            }\n            _ => self.bytes.extend_from_slice(&other.bytes),\n        }\n    }\n\n    /// Append a Unicode scalar value at the end of the string.\n    #[inline]\n    pub fn push_char(&mut self, c: char) {\n        self.push_code_point_unchecked(CodePoint::from_char(c))\n    }\n\n    /// Append a code point at the end of the string.\n    ///\n    /// This replaces newly paired surrogates at the boundary\n    /// with a supplementary code point,\n    /// like concatenating ill-formed UTF-16 strings effectively would.\n    #[inline]\n    pub fn push(&mut self, code_point: CodePoint) {\n        if let trail @ 0xDC00..=0xDFFF = code_point.to_u32() {\n            if let Some(lead) = (&*self).final_lead_surrogate() {\n                let len_without_lead_surrogate = self.len() - 3;\n                self.bytes.truncate(len_without_lead_surrogate);\n                self.push_char(decode_surrogate_pair(lead, trail as u16));\n                return;\n            }\n        }\n\n        // No newly paired surrogates at the boundary.\n        self.push_code_point_unchecked(code_point)\n    }\n\n    /// Shortens a string to the specified length.\n    ///\n    /// # Panics\n    ///\n    /// Panics if `new_len` > current length,\n    /// or if `new_len` is not a code point boundary.\n    #[inline]\n    pub fn truncate(&mut self, new_len: usize) {\n        assert!(is_code_point_boundary(self, new_len));\n        self.bytes.truncate(new_len)\n    }\n\n    /// Consumes the WTF-8 string and tries to convert it to UTF-8.\n    ///\n    /// This does not copy the data.\n    ///\n    /// If the contents are not well-formed UTF-8\n    /// (that is, if the string contains surrogates),\n    /// the original WTF-8 string is returned instead.\n    pub fn into_string(self) -> Result<String, Wtf8Buf> {\n        match self.next_surrogate(0) {\n            None => Ok(unsafe { String::from_utf8_unchecked(self.bytes) }),\n            Some(_) => Err(self),\n        }\n    }\n\n    /// Consumes the WTF-8 string and converts it lossily to UTF-8.\n    ///\n    /// This does not copy the data (but may overwrite parts of it in place).\n    ///\n    /// Surrogates are replaced with `\"\\u{FFFD}\"` (the replacement character “�”)\n    pub fn into_string_lossy(mut self) -> String {\n        let mut pos = 0;\n        loop {\n            match self.next_surrogate(pos) {\n                Some((surrogate_pos, _)) => {\n                    pos = surrogate_pos + 3;\n                    self.bytes[surrogate_pos..pos]\n                        .copy_from_slice(UTF8_REPLACEMENT_CHARACTER.as_bytes());\n                }\n                None => return unsafe { String::from_utf8_unchecked(self.bytes) },\n            }\n        }\n    }\n\n    /// Converts this `Wtf8Buf` into a boxed `Wtf8`.\n    #[inline]\n    pub fn into_box(self) -> Box<Wtf8> {\n        unsafe { mem::transmute(self.bytes.into_boxed_slice()) }\n    }\n\n    /// Converts a `Box<Wtf8>` into a `Wtf8Buf`.\n    pub fn from_box(boxed: Box<Wtf8>) -> Wtf8Buf {\n        let bytes: Box<[u8]> = unsafe { mem::transmute(boxed) };\n        Wtf8Buf { bytes: bytes.into_vec() }\n    }\n}\n\n/// Creates a new WTF-8 string from an iterator of code points.\n///\n/// This replaces surrogate code point pairs with supplementary code points,\n/// like concatenating ill-formed UTF-16 strings effectively would.\nimpl FromIterator<CodePoint> for Wtf8Buf {\n    fn from_iter<T: IntoIterator<Item = CodePoint>>(iter: T) -> Wtf8Buf {\n        let mut string = Wtf8Buf::new();\n        string.extend(iter);\n        string\n    }\n}\n\n/// Append code points from an iterator to the string.\n///\n/// This replaces surrogate code point pairs with supplementary code points,\n/// like concatenating ill-formed UTF-16 strings effectively would.\nimpl Extend<CodePoint> for Wtf8Buf {\n    fn extend<T: IntoIterator<Item = CodePoint>>(&mut self, iter: T) {\n        let iterator = iter.into_iter();\n        let (low, _high) = iterator.size_hint();\n        // Lower bound of one byte per code point (ASCII only)\n        self.bytes.reserve(low);\n        iterator.for_each(move |code_point| self.push(code_point));\n    }\n\n    #[inline]\n    fn extend_one(&mut self, code_point: CodePoint) {\n        self.push(code_point);\n    }\n\n    #[inline]\n    fn extend_reserve(&mut self, additional: usize) {\n        // Lower bound of one byte per code point (ASCII only)\n        self.bytes.reserve(additional);\n    }\n}\n\n/// A borrowed slice of well-formed WTF-8 data.\n///\n/// Similar to `&str`, but can additionally contain surrogate code points\n/// if they’re not in a surrogate pair.\n#[derive(Eq, Ord, PartialEq, PartialOrd)]\npub struct Wtf8 {\n    bytes: [u8],\n}\n\nimpl AsInner<[u8]> for Wtf8 {\n    fn as_inner(&self) -> &[u8] {\n        &self.bytes\n    }\n}\n\n/// Format the slice with double quotes,\n/// and surrogates as `\\u` followed by four hexadecimal digits.\n/// Example: `\"a\\u{D800}\"` for a slice with code points [U+0061, U+D800]\nimpl fmt::Debug for Wtf8 {\n    fn fmt(&self, formatter: &mut fmt::Formatter<'_>) -> fmt::Result {\n        fn write_str_escaped(f: &mut fmt::Formatter<'_>, s: &str) -> fmt::Result {\n            use crate::fmt::Write;\n            for c in s.chars().flat_map(|c| c.escape_debug()) {\n                f.write_char(c)?\n            }\n            Ok(())\n        }\n\n        formatter.write_str(\"\\\"\")?;\n        let mut pos = 0;\n        while let Some((surrogate_pos, surrogate)) = self.next_surrogate(pos) {\n            write_str_escaped(formatter, unsafe {\n                str::from_utf8_unchecked(&self.bytes[pos..surrogate_pos])\n            })?;\n            write!(formatter, \"\\\\u{{{:x}}}\", surrogate)?;\n            pos = surrogate_pos + 3;\n        }\n        write_str_escaped(formatter, unsafe { str::from_utf8_unchecked(&self.bytes[pos..]) })?;\n        formatter.write_str(\"\\\"\")\n    }\n}\n\nimpl fmt::Display for Wtf8 {\n    fn fmt(&self, formatter: &mut fmt::Formatter<'_>) -> fmt::Result {\n        let wtf8_bytes = &self.bytes;\n        let mut pos = 0;\n        loop {\n            match self.next_surrogate(pos) {\n                Some((surrogate_pos, _)) => {\n                    formatter.write_str(unsafe {\n                        str::from_utf8_unchecked(&wtf8_bytes[pos..surrogate_pos])\n                    })?;\n                    formatter.write_str(UTF8_REPLACEMENT_CHARACTER)?;\n                    pos = surrogate_pos + 3;\n                }\n                None => {\n                    let s = unsafe { str::from_utf8_unchecked(&wtf8_bytes[pos..]) };\n                    if pos == 0 { return s.fmt(formatter) } else { return formatter.write_str(s) }\n                }\n            }\n        }\n    }\n}\n\nimpl Wtf8 {\n    /// Creates a WTF-8 slice from a UTF-8 `&str` slice.\n    ///\n    /// Since WTF-8 is a superset of UTF-8, this always succeeds.\n    #[inline]\n    pub fn from_str(value: &str) -> &Wtf8 {\n        unsafe { Wtf8::from_bytes_unchecked(value.as_bytes()) }\n    }\n\n    /// Creates a WTF-8 slice from a WTF-8 byte slice.\n    ///\n    /// Since the byte slice is not checked for valid WTF-8, this functions is\n    /// marked unsafe.\n    #[inline]\n    unsafe fn from_bytes_unchecked(value: &[u8]) -> &Wtf8 {\n        mem::transmute(value)\n    }\n\n    /// Creates a mutable WTF-8 slice from a mutable WTF-8 byte slice.\n    ///\n    /// Since the byte slice is not checked for valid WTF-8, this functions is\n    /// marked unsafe.\n    #[inline]\n    unsafe fn from_mut_bytes_unchecked(value: &mut [u8]) -> &mut Wtf8 {\n        mem::transmute(value)\n    }\n\n    /// Returns the length, in WTF-8 bytes.\n    #[inline]\n    pub fn len(&self) -> usize {\n        self.bytes.len()\n    }\n\n    #[inline]\n    pub fn is_empty(&self) -> bool {\n        self.bytes.is_empty()\n    }\n\n    /// Returns the code point at `position` if it is in the ASCII range,\n    /// or `b'\\xFF' otherwise.\n    ///\n    /// # Panics\n    ///\n    /// Panics if `position` is beyond the end of the string.\n    #[inline]\n    pub fn ascii_byte_at(&self, position: usize) -> u8 {\n        match self.bytes[position] {\n            ascii_byte @ 0x00..=0x7F => ascii_byte,\n            _ => 0xFF,\n        }\n    }\n\n    /// Returns an iterator for the string’s code points.\n    #[inline]\n    pub fn code_points(&self) -> Wtf8CodePoints<'_> {\n        Wtf8CodePoints { bytes: self.bytes.iter() }\n    }\n\n    /// Tries to convert the string to UTF-8 and return a `&str` slice.\n    ///\n    /// Returns `None` if the string contains surrogates.\n    ///\n    /// This does not copy the data.\n    #[inline]\n    pub fn as_str(&self) -> Option<&str> {\n        // Well-formed WTF-8 is also well-formed UTF-8\n        // if and only if it contains no surrogate.\n        match self.next_surrogate(0) {\n            None => Some(unsafe { str::from_utf8_unchecked(&self.bytes) }),\n            Some(_) => None,\n        }\n    }\n\n    /// Lossily converts the string to UTF-8.\n    /// Returns a UTF-8 `&str` slice if the contents are well-formed in UTF-8.\n    ///\n    /// Surrogates are replaced with `\"\\u{FFFD}\"` (the replacement character “�”).\n    ///\n    /// This only copies the data if necessary (if it contains any surrogate).\n    pub fn to_string_lossy(&self) -> Cow<'_, str> {\n        let surrogate_pos = match self.next_surrogate(0) {\n            None => return Cow::Borrowed(unsafe { str::from_utf8_unchecked(&self.bytes) }),\n            Some((pos, _)) => pos,\n        };\n        let wtf8_bytes = &self.bytes;\n        let mut utf8_bytes = Vec::with_capacity(self.len());\n        utf8_bytes.extend_from_slice(&wtf8_bytes[..surrogate_pos]);\n        utf8_bytes.extend_from_slice(UTF8_REPLACEMENT_CHARACTER.as_bytes());\n        let mut pos = surrogate_pos + 3;\n        loop {\n            match self.next_surrogate(pos) {\n                Some((surrogate_pos, _)) => {\n                    utf8_bytes.extend_from_slice(&wtf8_bytes[pos..surrogate_pos]);\n                    utf8_bytes.extend_from_slice(UTF8_REPLACEMENT_CHARACTER.as_bytes());\n                    pos = surrogate_pos + 3;\n                }\n                None => {\n                    utf8_bytes.extend_from_slice(&wtf8_bytes[pos..]);\n                    return Cow::Owned(unsafe { String::from_utf8_unchecked(utf8_bytes) });\n                }\n            }\n        }\n    }\n\n    /// Converts the WTF-8 string to potentially ill-formed UTF-16\n    /// and return an iterator of 16-bit code units.\n    ///\n    /// This is lossless:\n    /// calling `Wtf8Buf::from_ill_formed_utf16` on the resulting code units\n    /// would always return the original WTF-8 string.\n    #[inline]\n    pub fn encode_wide(&self) -> EncodeWide<'_> {\n        EncodeWide { code_points: self.code_points(), extra: 0 }\n    }\n\n    #[inline]\n    fn next_surrogate(&self, mut pos: usize) -> Option<(usize, u16)> {\n        let mut iter = self.bytes[pos..].iter();\n        loop {\n            let b = *iter.next()?;\n            if b < 0x80 {\n                pos += 1;\n            } else if b < 0xE0 {\n                iter.next();\n                pos += 2;\n            } else if b == 0xED {\n                match (iter.next(), iter.next()) {\n                    (Some(&b2), Some(&b3)) if b2 >= 0xA0 => {\n                        return Some((pos, decode_surrogate(b2, b3)));\n                    }\n                    _ => pos += 3,\n                }\n            } else if b < 0xF0 {\n                iter.next();\n                iter.next();\n                pos += 3;\n            } else {\n                iter.next();\n                iter.next();\n                iter.next();\n                pos += 4;\n            }\n        }\n    }\n\n    #[inline]\n    fn final_lead_surrogate(&self) -> Option<u16> {\n        match self.bytes {\n            [.., 0xED, b2 @ 0xA0..=0xAF, b3] => Some(decode_surrogate(b2, b3)),\n            _ => None,\n        }\n    }\n\n    #[inline]\n    fn initial_trail_surrogate(&self) -> Option<u16> {\n        match self.bytes {\n            [0xED, b2 @ 0xB0..=0xBF, b3, ..] => Some(decode_surrogate(b2, b3)),\n            _ => None,\n        }\n    }\n\n    pub fn clone_into(&self, buf: &mut Wtf8Buf) {\n        self.bytes.clone_into(&mut buf.bytes)\n    }\n\n    /// Boxes this `Wtf8`.\n    #[inline]\n    pub fn into_box(&self) -> Box<Wtf8> {\n        let boxed: Box<[u8]> = self.bytes.into();\n        unsafe { mem::transmute(boxed) }\n    }\n\n    /// Creates a boxed, empty `Wtf8`.\n    pub fn empty_box() -> Box<Wtf8> {\n        let boxed: Box<[u8]> = Default::default();\n        unsafe { mem::transmute(boxed) }\n    }\n\n    #[inline]\n    pub fn into_arc(&self) -> Arc<Wtf8> {\n        let arc: Arc<[u8]> = Arc::from(&self.bytes);\n        unsafe { Arc::from_raw(Arc::into_raw(arc) as *const Wtf8) }\n    }\n\n    #[inline]\n    pub fn into_rc(&self) -> Rc<Wtf8> {\n        let rc: Rc<[u8]> = Rc::from(&self.bytes);\n        unsafe { Rc::from_raw(Rc::into_raw(rc) as *const Wtf8) }\n    }\n\n    #[inline]\n    pub fn make_ascii_lowercase(&mut self) {\n        self.bytes.make_ascii_lowercase()\n    }\n\n    #[inline]\n    pub fn make_ascii_uppercase(&mut self) {\n        self.bytes.make_ascii_uppercase()\n    }\n\n    #[inline]\n    pub fn to_ascii_lowercase(&self) -> Wtf8Buf {\n        Wtf8Buf { bytes: self.bytes.to_ascii_lowercase() }\n    }\n\n    #[inline]\n    pub fn to_ascii_uppercase(&self) -> Wtf8Buf {\n        Wtf8Buf { bytes: self.bytes.to_ascii_uppercase() }\n    }\n\n    #[inline]\n    pub fn is_ascii(&self) -> bool {\n        self.bytes.is_ascii()\n    }\n\n    #[inline]\n    pub fn eq_ignore_ascii_case(&self, other: &Self) -> bool {\n        self.bytes.eq_ignore_ascii_case(&other.bytes)\n    }\n}\n\n/// Returns a slice of the given string for the byte range [`begin`..`end`).\n///\n/// # Panics\n///\n/// Panics when `begin` and `end` do not point to code point boundaries,\n/// or point beyond the end of the string.\nimpl ops::Index<ops::Range<usize>> for Wtf8 {\n    type Output = Wtf8;\n\n    #[inline]\n    fn index(&self, range: ops::Range<usize>) -> &Wtf8 {\n        // is_code_point_boundary checks that the index is in [0, .len()]\n        if range.start <= range.end\n            && is_code_point_boundary(self, range.start)\n            && is_code_point_boundary(self, range.end)\n        {\n            unsafe { slice_unchecked(self, range.start, range.end) }\n        } else {\n            slice_error_fail(self, range.start, range.end)\n        }\n    }\n}\n\n/// Returns a slice of the given string from byte `begin` to its end.\n///\n/// # Panics\n///\n/// Panics when `begin` is not at a code point boundary,\n/// or is beyond the end of the string.\nimpl ops::Index<ops::RangeFrom<usize>> for Wtf8 {\n    type Output = Wtf8;\n\n    #[inline]\n    fn index(&self, range: ops::RangeFrom<usize>) -> &Wtf8 {\n        // is_code_point_boundary checks that the index is in [0, .len()]\n        if is_code_point_boundary(self, range.start) {\n            unsafe { slice_unchecked(self, range.start, self.len()) }\n        } else {\n            slice_error_fail(self, range.start, self.len())\n        }\n    }\n}\n\n/// Returns a slice of the given string from its beginning to byte `end`.\n///\n/// # Panics\n///\n/// Panics when `end` is not at a code point boundary,\n/// or is beyond the end of the string.\nimpl ops::Index<ops::RangeTo<usize>> for Wtf8 {\n    type Output = Wtf8;\n\n    #[inline]\n    fn index(&self, range: ops::RangeTo<usize>) -> &Wtf8 {\n        // is_code_point_boundary checks that the index is in [0, .len()]\n        if is_code_point_boundary(self, range.end) {\n            unsafe { slice_unchecked(self, 0, range.end) }\n        } else {\n            slice_error_fail(self, 0, range.end)\n        }\n    }\n}\n\nimpl ops::Index<ops::RangeFull> for Wtf8 {\n    type Output = Wtf8;\n\n    #[inline]\n    fn index(&self, _range: ops::RangeFull) -> &Wtf8 {\n        self\n    }\n}\n\n#[inline]\nfn decode_surrogate(second_byte: u8, third_byte: u8) -> u16 {\n    // The first byte is assumed to be 0xED\n    0xD800 | (second_byte as u16 & 0x3F) << 6 | third_byte as u16 & 0x3F\n}\n\n#[inline]\nfn decode_surrogate_pair(lead: u16, trail: u16) -> char {\n    let code_point = 0x10000 + ((((lead - 0xD800) as u32) << 10) | (trail - 0xDC00) as u32);\n    unsafe { char::from_u32_unchecked(code_point) }\n}\n\n/// Copied from core::str::StrPrelude::is_char_boundary\n#[inline]\npub fn is_code_point_boundary(slice: &Wtf8, index: usize) -> bool {\n    if index == slice.len() {\n        return true;\n    }\n    match slice.bytes.get(index) {\n        None => false,\n        Some(&b) => b < 128 || b >= 192,\n    }\n}\n\n/// Copied from core::str::raw::slice_unchecked\n#[inline]\npub unsafe fn slice_unchecked(s: &Wtf8, begin: usize, end: usize) -> &Wtf8 {\n    // memory layout of an &[u8] and &Wtf8 are the same\n    Wtf8::from_bytes_unchecked(slice::from_raw_parts(s.bytes.as_ptr().add(begin), end - begin))\n}\n\n/// Copied from core::str::raw::slice_error_fail\n#[inline(never)]\npub fn slice_error_fail(s: &Wtf8, begin: usize, end: usize) -> ! {\n    assert!(begin <= end);\n    panic!(\"index {} and/or {} in `{:?}` do not lie on character boundary\", begin, end, s);\n}\n\n/// Iterator for the code points of a WTF-8 string.\n///\n/// Created with the method `.code_points()`.\n#[derive(Clone)]\npub struct Wtf8CodePoints<'a> {\n    bytes: slice::Iter<'a, u8>,\n}\n\nimpl<'a> Iterator for Wtf8CodePoints<'a> {\n    type Item = CodePoint;\n\n    #[inline]\n    fn next(&mut self) -> Option<CodePoint> {\n        next_code_point(&mut self.bytes).map(|c| CodePoint { value: c })\n    }\n\n    #[inline]\n    fn size_hint(&self) -> (usize, Option<usize>) {\n        let len = self.bytes.len();\n        (len.saturating_add(3) / 4, Some(len))\n    }\n}\n\n/// Generates a wide character sequence for potentially ill-formed UTF-16.\n#[stable(feature = \"rust1\", since = \"1.0.0\")]\n#[derive(Clone)]\npub struct EncodeWide<'a> {\n    code_points: Wtf8CodePoints<'a>,\n    extra: u16,\n}\n\n// Copied from libunicode/u_str.rs\n#[stable(feature = \"rust1\", since = \"1.0.0\")]\nimpl<'a> Iterator for EncodeWide<'a> {\n    type Item = u16;\n\n    #[inline]\n    fn next(&mut self) -> Option<u16> {\n        if self.extra != 0 {\n            let tmp = self.extra;\n            self.extra = 0;\n            return Some(tmp);\n        }\n\n        let mut buf = [0; 2];\n        self.code_points.next().map(|code_point| {\n            let n = char::encode_utf16_raw(code_point.value, &mut buf).len();\n            if n == 2 {\n                self.extra = buf[1];\n            }\n            buf[0]\n        })\n    }\n\n    #[inline]\n    fn size_hint(&self) -> (usize, Option<usize>) {\n        let (low, high) = self.code_points.size_hint();\n        let ext = (self.extra != 0) as usize;\n        // every code point gets either one u16 or two u16,\n        // so this iterator is between 1 or 2 times as\n        // long as the underlying iterator.\n        (low + ext, high.and_then(|n| n.checked_mul(2)).and_then(|n| n.checked_add(ext)))\n    }\n}\n\nimpl Hash for CodePoint {\n    #[inline]\n    fn hash<H: Hasher>(&self, state: &mut H) {\n        self.value.hash(state)\n    }\n}\n\nimpl Hash for Wtf8Buf {\n    #[inline]\n    fn hash<H: Hasher>(&self, state: &mut H) {\n        state.write(&self.bytes);\n        0xfeu8.hash(state)\n    }\n}\n\nimpl Hash for Wtf8 {\n    #[inline]\n    fn hash<H: Hasher>(&self, state: &mut H) {\n        state.write(&self.bytes);\n        0xfeu8.hash(state)\n    }\n}\n"],[2405,"#![allow(dead_code)]\n\n#[cfg(test)]\nmod tests;\n\nuse crate::fmt::{Formatter, Result, Write};\nuse core::str::lossy::{Utf8Lossy, Utf8LossyChunk};\n\npub fn debug_fmt_bytestring(slice: &[u8], f: &mut Formatter<'_>) -> Result {\n    // Writes out a valid unicode string with the correct escape sequences\n    fn write_str_escaped(f: &mut Formatter<'_>, s: &str) -> Result {\n        for c in s.chars().flat_map(|c| c.escape_debug()) {\n            f.write_char(c)?\n        }\n        Ok(())\n    }\n\n    f.write_str(\"\\\"\")?;\n    for Utf8LossyChunk { valid, broken } in Utf8Lossy::from_bytes(slice).chunks() {\n        write_str_escaped(f, valid)?;\n        for b in broken {\n            write!(f, \"\\\\x{:02X}\", b)?;\n        }\n    }\n    f.write_str(\"\\\"\")\n}\n"],[2406,"#[cfg(all(test, not(target_os = \"emscripten\")))]\nmod tests;\n\nuse crate::marker::PhantomPinned;\nuse crate::ops::Deref;\nuse crate::panic::{RefUnwindSafe, UnwindSafe};\nuse crate::pin::Pin;\nuse crate::sys::mutex as sys;\n\n/// A re-entrant mutual exclusion\n///\n/// This mutex will block *other* threads waiting for the lock to become\n/// available. The thread which has already locked the mutex can lock it\n/// multiple times without blocking, preventing a common source of deadlocks.\npub struct ReentrantMutex<T> {\n    inner: sys::ReentrantMutex,\n    data: T,\n    _pinned: PhantomPinned,\n}\n\nunsafe impl<T: Send> Send for ReentrantMutex<T> {}\nunsafe impl<T: Send> Sync for ReentrantMutex<T> {}\n\nimpl<T> UnwindSafe for ReentrantMutex<T> {}\nimpl<T> RefUnwindSafe for ReentrantMutex<T> {}\n\n/// An RAII implementation of a \"scoped lock\" of a mutex. When this structure is\n/// dropped (falls out of scope), the lock will be unlocked.\n///\n/// The data protected by the mutex can be accessed through this guard via its\n/// Deref implementation.\n///\n/// # Mutability\n///\n/// Unlike `MutexGuard`, `ReentrantMutexGuard` does not implement `DerefMut`,\n/// because implementation of the trait would violate Rust’s reference aliasing\n/// rules. Use interior mutability (usually `RefCell`) in order to mutate the\n/// guarded data.\n#[must_use = \"if unused the ReentrantMutex will immediately unlock\"]\npub struct ReentrantMutexGuard<'a, T: 'a> {\n    lock: Pin<&'a ReentrantMutex<T>>,\n}\n\nimpl<T> !Send for ReentrantMutexGuard<'_, T> {}\n\nimpl<T> ReentrantMutex<T> {\n    /// Creates a new reentrant mutex in an unlocked state.\n    ///\n    /// # Unsafety\n    ///\n    /// This function is unsafe because it is required that `init` is called\n    /// once this mutex is in its final resting place, and only then are the\n    /// lock/unlock methods safe.\n    pub const unsafe fn new(t: T) -> ReentrantMutex<T> {\n        ReentrantMutex {\n            inner: sys::ReentrantMutex::uninitialized(),\n            data: t,\n            _pinned: PhantomPinned,\n        }\n    }\n\n    /// Initializes this mutex so it's ready for use.\n    ///\n    /// # Unsafety\n    ///\n    /// Unsafe to call more than once, and must be called after this will no\n    /// longer move in memory.\n    pub unsafe fn init(self: Pin<&mut Self>) {\n        self.get_unchecked_mut().inner.init()\n    }\n\n    /// Acquires a mutex, blocking the current thread until it is able to do so.\n    ///\n    /// This function will block the caller until it is available to acquire the mutex.\n    /// Upon returning, the thread is the only thread with the mutex held. When the thread\n    /// calling this method already holds the lock, the call shall succeed without\n    /// blocking.\n    ///\n    /// # Errors\n    ///\n    /// If another user of this mutex panicked while holding the mutex, then\n    /// this call will return failure if the mutex would otherwise be\n    /// acquired.\n    pub fn lock(self: Pin<&Self>) -> ReentrantMutexGuard<'_, T> {\n        unsafe { self.inner.lock() }\n        ReentrantMutexGuard { lock: self }\n    }\n\n    /// Attempts to acquire this lock.\n    ///\n    /// If the lock could not be acquired at this time, then `Err` is returned.\n    /// Otherwise, an RAII guard is returned.\n    ///\n    /// This function does not block.\n    ///\n    /// # Errors\n    ///\n    /// If another user of this mutex panicked while holding the mutex, then\n    /// this call will return failure if the mutex would otherwise be\n    /// acquired.\n    pub fn try_lock(self: Pin<&Self>) -> Option<ReentrantMutexGuard<'_, T>> {\n        if unsafe { self.inner.try_lock() } {\n            Some(ReentrantMutexGuard { lock: self })\n        } else {\n            None\n        }\n    }\n}\n\nimpl<T> Drop for ReentrantMutex<T> {\n    fn drop(&mut self) {\n        // This is actually safe b/c we know that there is no further usage of\n        // this mutex (it's up to the user to arrange for a mutex to get\n        // dropped, that's not our job)\n        unsafe { self.inner.destroy() }\n    }\n}\n\nimpl<T> Deref for ReentrantMutexGuard<'_, T> {\n    type Target = T;\n\n    fn deref(&self) -> &T {\n        &self.lock.data\n    }\n}\n\nimpl<T> Drop for ReentrantMutexGuard<'_, T> {\n    #[inline]\n    fn drop(&mut self) {\n        unsafe {\n            self.lock.inner.unlock();\n        }\n    }\n}\n"],[2407,"use super::*;\nuse crate::collections::HashMap;\n\n#[test]\nfn no_lookup_host_duplicates() {\n    let mut addrs = HashMap::new();\n    let lh = match LookupHost::try_from((\"localhost\", 0)) {\n        Ok(lh) => lh,\n        Err(e) => panic!(\"couldn't resolve `localhost': {}\", e),\n    };\n    for sa in lh {\n        *addrs.entry(sa).or_insert(0) += 1;\n    }\n    assert_eq!(\n        addrs.iter().filter(|&(_, &v)| v > 1).collect::<Vec<_>>(),\n        vec![],\n        \"There should be no duplicate localhost entries\"\n    );\n}\n"]]}}